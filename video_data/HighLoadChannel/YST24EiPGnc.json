{
  "video_id": "YST24EiPGnc",
  "channel": "HighLoadChannel",
  "title": "Архитектура Vitastor. Тёмная сторона моей распределённой СХД / Виталий Филиппов (Личный проект)",
  "views": 1153,
  "duration": 2710,
  "published": "2023-01-19T07:01:38-08:00",
  "text": "ну да я сегодня мы попробую рассказать еще раз про свой велосипедик такой небольшой который за названием как я уже сказал я далеко не ходил вот в общем история такая я напомню что это что такое у меня был прошлый доклад на делюкс comfy если кому то интересно то я в конце дам ссылку на телеграм-чате ктам он в закрепи там можно презентацию прочту и сам доклад посмотреть ой сейчас я просто не буду сильно останавливаться на там мотивации зачем это все на каких-то общих словах просто общие слова были в прошлый раз вот если я их опять буду повторять то я просто ничего не расскажут я сегодня постарался подготовить какие-то технические детали вот и в меру того насколько получилось а это сейчас какого бы рассказать в общем что это все такое в конце история такая я долго занимался цехам ну тут вообще вообще я web-разработчик как бы был в общем но еще я занимался цехам у меня немножко впитываем задолбал своими тормозами и настолько задолбал стоил пришлось переписывать ну то есть я просто рассудил если они вот такое делают и это настолько популярна в мире то типа почему я не могу тоже попробовать что это такое это распределенное блочное программное система хранения данных то есть это система для хранения образов дисков там виртуалок ну и возможно контейнеров вот у нее две основные черты которые в общем-то и ресторан которых я учу старался добиться это скорость и простота ну просто то в частности потому что я не была простая вы просто не написал в одно лицо вот а скорость но потому что иначе бы смысл не было писать вот при этом у нее архитектуру цеха подобное симметричная без единой точки отказа вот поддерживается использовать можно в связке с либо с голым кому-либо на его основе я это сделал за драйвера для прочного пластика вот и также можно монтировать ядром через н б д л н б да это натур блок девайс на самом деле работает как блочное устройство в пространстве пользователя и на его базе есть cabernet свой драйвер ну то есть модули ядра писать свои я пока настолько не упоролся но в общем какой-то способ монтирования был нужен поэтому там вот ну и да все это рассчитано на ssd жки потому что виртуалке бизнес с дошик типа там в 2022 году деньги на ветер ну то есть как минимум вам нужны и создашь key для журналов и метаданных чтобы запустить иначе она будет очень грустно работать вот на ssd + хдд то есть когда данные на жестком диске и журнала метаданные на ssd но нормально работает я тестировал весьма неплохо собственно хранил и как на самом деле вот сто-ой а тут ничего нет да простите о чем хоронил их собственно говоря вот столько разных но проблем и то есть и казалось бы зачем писать еще одну но проблема на самом деле в том что они все либо имеют как бы какие-то ущербные алгоритмы которые в которых заложена потери данных либо они тормозят либо они платные либо не мертвые либо все вместе вот есть отдельные экземпляры например написанные вообще наукам ли это мне очень понравилось когда я заметил когда это увидел этого толку инвестор джон то много камни частичному keys ну вот в общем собственно переписываемся чтобы не сойти с ума в переписывании этого миллиона строк кода надо не как я уже сказал немножко надо ограничить скоб значит и мы не будем переписывать вообще все включая файловую систему реестре а ограничимся блочной хранил кай в том числе собственно почему это еще хорошо еще это хорошо потому что у цеха нижний слой объектный поверх него реализован блочный и вот когда ты блочный слой реализуешь поверх объектного то выходит достаточно странное криво вот то есть это даст нам сбросить некий архитектурный груз вот ну и второй момент это то что с 3 хранила как в общем-то довольно много но на самом деле не прям очень много но они есть то есть тот же c в принципе нормально нормально использует побыстрей вот и еще есть например севидов с который тоже в общем неплохо быстрее вот и поэтому писать ещё один ис-3 ну типа совсем не хочется вот а вот блочную но почему бы не написать вот при этом также общие черты архитектуры я в общем то сразу не думаю я просто скопировал слова sf а то что они меня устраивают общие черты это симметричная архитектура и симметрично распродан архитектуру то есть имеется ввиду что есть просто какие-то сервера они в них какие-то диски каждому диску соответствуют слой запущенный демон хранения всд вот и все это друг с другом работает как бы нет никаких никто никаких центральных точек входа никаких там там актив ps этом резервирование никого нету ничего вот этого нету то есть такая симметрично архитектура где клиент сразу конектится к тем демоном которые собственно занимаются хранением данных льда вот еще из терминологии pg в цехе если кто-то там не в теме это placement группа это такой типаж арт кластера на которые делится весь кластер и каждом уж орду там назначается своя там пара или тройка sd шик на которых хранятся данные допустим реплицируются вот еще есть монитор мониторами в цехе называется управляющий делом у всех он наверное тоже называется как-то по-своему но понятно что в принципе в любой системе какое какой-то управляющий слой гарантированно есть и без него как бы никуда поэтому это тоже там логично и вполне часть архитектур вот ну и последний момент важный который я тоже заимствую там слове который сильно упрощает жизнь это все через первичный с д а вот то есть как в цехе так и у меня весь вот вывод и чтение и запись клиент осуществляет через первичную езды назначенными placement группу то есть у каждый пояс мангруппа у каждого шарда у него есть условно говоря мастер и есть какие то там реплики и вот клиент всегда работает там с набором мастеров всех place of group вот в каком порядке собственная все это перил когда я на это наконец решился ну сначала сначала естественно пришлось запилить блочный слой какой-то упрощенный причем отличительная особенность то что там я сразу предусматривал семантику razer кодов но на самом деле в изначально в виде к ссора ну потому что самый типа простой там raid5 это типа ксор ну то есть два диска и данных один диск просто четности вот потом пишется сетевой уровень потом пишется монитор пишется драйвер qui lui уже получается в принципе какой-то минимальный прототип который можно закончить и понять вообще как-бы задумка она вообще имеет смысл вот это велосипеде или никакого смысла нет и мы написали вот что то она в общем также тормозит как все остальное вот но забегая вперед скажу что вроде получилось ну и поэтому собственно разработка продолжилось после того как разработка продолжилось я потом допилил туда добавил уже как бы упростил алгоритм для репликации с одной стороны и с другой стороны добавил абстрактные ветры и жир кодов вот ну и потом там прочее то есть там что то чтобы монтировать ядром там снапшоты потом меня сильно волновал вопрос и рукопись эти плагины для разных облачных систем там интерфейс командной строки там что-то для пиратов из последнего прям вот в общем понятно что тут много чисто технических вопросов всё это размазывает смысла нет вот но на некоторых моментах остановиться стоит вот и вот моменты на которых мы остановимся в этом докладе это вот они перечислены то есть и первый из них это собственно производительность то есть как вообще ну то есть во первых первый вопрос да то есть почему я говорю что все тормозит то есть что тормозит но если в принципе вы смотрели прошлый доклад там то там вот про это как раз было я опять же сильно повторяться не буду углубляться но общий смысл в том что если вот с позиции там тупой пользовательской позиции взять и сравнить задержку например записи и чтения с глубиной очереди 1 то есть губной очереди один это когда мы просто отправляем операцию ждем завершение полон отправляем следующую операцию мы не отправляем 2 параллельно ну то есть такой самый жесткий режим для системы вот если это сравнить то примерно вот получается вот так то есть в общем общий смысл в том что все там облака они и цех они все ну там на уровне 1000 abs плюс-минус ну то есть и тысячи операций в секунду там может 2000 вот примерно так при том что там самая за штатная нонэйм avaya создашь к она выдает там 20 тысяч операций секунд вот ну то есть и их вот гонка она выглядит вот в принципе примерно вот так вот почему так происходит то есть в чем источники тормозов ну то есть как мы все наверно там привыкли в мире web-разработки или там еще где-то вот самые большие источники тормозов это должно быть потому что типа код быстрые сети диск медными вот на самом деле когда начинаешь работать с издержками там и что то такое вот писать тепла система хранения данных то там все на самом деле не так диски у нас становится быстрыми создали м.е. сеть у нас тоже быстро этом 10 гигабит altan 25 гигабит вот и основные тормоза если мы конечно там нем какую-то глупость полную не сделаю там 10 походов по сети на одну операцию там запись не знаю вот то на самом деле в все эти диск мы не так сильно упираемся на самом деле проблема начинается в логике то есть в алгоритмах которые жрут все пьют вот ну то есть вот как это как говорится было очень трудно сделать так чтобы логика тормозило сильнее чем сети диск на общем они смогли авторы танцев этого не смогли как не повторить нам этот успех чтобы не повторить этот успех собственно ну первое что мы должны помнить в процессе разработки это то что у нас узкое место цепью и поэтому нам сложные алгоритмы например какой то там копии он рай файловую систему свою изобретать там новую с сборкой мусора еще там чем-нибудь там деревьями в общем в общем лучше это не изобретает что-то попроще вот потом следующий момент что не надо использовать иди романтичные плюс и потому что ну не знаю это моё личное мнение возможно холивар ный такой немножко пункт вот но для меня это выглядело так пошли я когда пытался профилировать cf там верхних строчках были например локации памяти вот просто банально там количество локаций память оно такое что она начинает быть заметным вносить вклад автор мало вот и поэтому мы вот короче не будет вот а избавиться от них нельзя потому что они там скрыты каких-то там конструктор и деструктор их в чем-то вот этом все вот и избавиться от этого очень сложно вот в общем слоёный пирог поэтому будем писать на чем-то таком ту помните то есть из класса вот без тяжелых зависимостей и без многопоточности вместо многопоточности будем использовать на хорошо вот его sync раньше не нам поможет такая штука которую недавно добавили глину называется you wearing это новый наконец-то нормальный интерфейс асинхронного ввода-вывода что имеется ввиду под нормальным это то что он во первых быстрый он быстро и вплоть до того что его автор уже там выжил дает 10 миллионов loops через него это правда с очень большими стероидами то есть он это делал там на об тонах и с дополнительным там потоком который опрашивает в ядре этом эту очередь вот и там с регистрации буферов с регистрации файловых дескрипторов там что-то еще там вот но тем не менее он этого достиг более там скромные цифры они достигаются без таких извращений ну то есть про это можно сказать то что ну как бы как это dpd к больше не нужен если кто то знает да по такой а это такая штука от impala которая позволяет там со сетью и ой сетью и сетью и мвм яшкино работать в пространство пользователей раньше вот эти цифры только на ней можно было достичь вот сейчас они в общем достижения мощные сколько вот больше если кому то интересно тут есть ссылочкой thermal дикою ринг pdf там можно почитать что это вообще такое и как это работает вот следующий момент собственно алгоритм записи как все как мы в еще что то будем писать на диск ну то есть первый момент мы уже поняли что у нас система распределенная то есть в этом каждый блок будем сохранять на пару серверов ну то есть казалось бы вроде там чего самый простой приходит голову давайте подключимся к двум сервером просто отправим на них блок вот но потом может произойти непредвиденное вот и выключится питание ну там не знаю фильмы наложат санкции на дата-центр вот он отключится вот о том когда он включится в общем мы можем легко ну то есть когда не там порешают контрактом дата мы можем обнаружить в такую ситуацию когда у нас половина блока записалась на один сферу половину блока на другой сервер как бы после этого клиент будет читать свои данные он сначала увидит одну версию а потому что сервер упадет он увидит другую версию в общем ноги немного обидеться потому что типа что-то данные то не очень на месте в общем иными словами это в этот момент становится нужна синхронизация вот и как делать эту синхронизацию но самое тупое решение это то что делается в рейдах там ну там в том же энди одни в программном рейде это мы просто будем принят штатном отключение целиком вычитывать все данные сравнивать вот но это понятное дело очень медленно хотя и кластерные системы которые там в это пытаются играть они тоже есть но это просто те кто там не удосужился типа сделать что-то более сложное вот другие варианты которые приходят в голову можно допустим писать контрольную сумму так делает из мдф с причем он их не только там печные диски он их еще на мастер сыр и отправляет причем это все без какой-либо консистентной что это тоже даже за товарности что тоже нам приводит к я скажу чему-либо можно еще намерений записи либо можно просто журнале рует все операции что популярные в общем то же решение плюс к этому всему нам еще нужно уметь делать ребаланс то есть уметь переносить какие-то блоки данных с одного сервера на другой плюс к этому нам нужно просто распределять места на диске плюс к этому у нас есть райт холл про right отдельно я про него всегда люблю рассказывать вот это такая штука что если у нас не реплики леджер коды но там типа условного и 5 то ну понятно что у нас там каждый блок данных делаться на 2 половинки одна половинка на один сервер другое полнитель на другой сервер считается четность пишет внутри сервер вот клиент хочет обновить одну половинку он эту половинку пишут на второй сервер и параллельно он должен записать новую версию четности вот а дальше опять у нас злые фильмы отключают питание вот короче и оказывая потом после включения оказывается что четность прописалась новой версии блока не прописалась еще параллельно один из серверов не пережил как бы отключение и на нём на данные устанавливаете когда мы будем пытаться установить то из старой версии блока из и новой версии четности мы получим кафе вот эта штука она называется райт холл и она и от нее не помогают журнал простой же land не помогает потому что здесь кара птица блок который вы не трогали при записи журнал он женой как бы пишем блок сначала в том него копируем вот тут как бы мы коробки не тот блок который пишет вот значит ну в общем общий смысл в том что есть вот некие метаданные и для их записи нужно товарность ну то есть вот в lizard офисе например как я уже сказал у них это мордасти нет и у них когда блок обновляется checksum не обновляется или наоборот чиксу но обновляется блок не обновляется то он просто сваливает блок данных и говорит что он потерян в состоянии потеря вот ну понятно что это происходит как бы редко и большую часть времени у вас там три реплики ну там больше там обычно повезет и такого не произойдёт и как то она будет жить но ну теле не вот как-то нехорошо получается вот как это решается соответственно нам нужно делать либо просто журналирование то есть традиционный right ahead logging когда мы пишем будут данных сначала журнала потом копированию в основное расположение либо копи он райд или redirect right вот но он как бы тоже не бесплатен с одной стороны прикрытую найти мы не пишем блок данных дважды и в этом смысле выигрываем двойной записи с другой стороны мы проигрываем в объеме метаданных там все блюз торы ну тут уж торт движок границах а вот а также там за tfsi btrfs и как известно что они со своим копии он рай там они страдают от райтом профи тишину притом особенно при мелкой записи вот это именно потому что в общем купил райтон тоже не бесплатен вот но как бы делать то что надо вот поэтому я в итоге пришел к такой схеме итоговая схема берем все объекты считаем по 128 килобайт то есть у нас диск делятся на какие-то кусочки эффективного размера типа объекты и виртуальные диски тоже делится на вот эти объекты у объекта будет идентификатор и идентификатор объекта это по сути просто вот лишних виртуального диска плюс смещение плюс еще у него будет номер версии про это чуть попозже вот и вот эта штука она отражается на собственно адрес на физическом диске вот если как собственно каждый из этих элементов он по восемь байт в итоге получается что если все это перемножить то получается там типа 256 мегабайт метаданных на 1 терабайт данных что в общем-то немного потому что там в тех же рекомендациях цеха рекомендуется типа там гигабайт на терабайт ну так или иначе если совсем жмет можно объекты побольше сделать вот повлияют это только на то когда будет активироваться полная перезапись когда будет активироваться частично перезаписи то есть ну тебе чуть хуже будет рай там политики вот против райт холла razer кодового сделаем такую штуку ну то есть вообще как rightful закрывается чтобы его закрыть нам нужно до момента пока новая версия не пропишется на все там 3 сервера хранители версии то есть по сути нужен такой некий механизм двухфазного комитет когда мы сначала отправляем там типа новую версию а потом говорим что все окей новой версии у всех уже есть или можешь удалять старую вот но собственно так и сделаем и как раз под эту цель тоже будем использовать по сути журнал ну то есть либо журнал либо вот этот redirect нюанс этой простой схемы в том что пилить в нее например сжатие уже так конечно просто не получится потому что со сжатием перезаписывать данные на месте как бы уже нельзя и тогда придется делать уже полноценный копии он райт и дефрагментацию и там в общем в общем изобретать свою прошивку ssd по сути только которая будет работать не в ssd вот теперь выпнул зачем нужны версии объектов как я уже сказал то есть нужно как-то делается на организацию какие-то там тупые методы и типа tecsun когда просто надеемся что у нас там чиксу на на разных себя совпадут нас не устраивают вот с другой стороны реализация всех записи не в один какой-то большой липицы равный лог нас тоже не устраивает потому что это будет тормозить это ну как бы на практике это действительно тормозит потому что вместо параллелизма ты должен у только кто линейно выстроите в том же порядке это реплицировать это неудобно поэтому в общем идея такая будем синхронизировать по номерам версия объектов просто у каждого объекта будет некий номер 1 или там при записи он будет увеличиваться на единичку и в принципе очевидно что в этой схеме если у нас там поднимается какой-то кусок класс тирану тепло рода поддержка поднимается смотрит на состояние объектов но выезда то в принципе понятно что вы становитесь рискует объектом в там инверсия и каждая из них лежит каких-то своих езда то в принципе умозрительно понятно что из этого сделать вывод какая версия правильное какая неправильное в общем-то довольно просто ну вот собственно что и делается ну то есть да как я сказал просто версия увеличивается при записи при подъеме по без уверяют в полные списки объектов вот это опять же это не занимает много времени то есть если кому-то там страшно от того что вот мы там берем и всю базу сканируем ну как бы на самом деле нет она не такая большая единственно как бы если чуть-чуть подумать то у этой схемы если вот совсем в тупую сделать и просто увеличивать версии на единичку то у неё там есть некие проблемы из-за которых нужно внутри еще один момент и с этим моментом все становится совсем хорошо вот этот момент эта история placement групп или эпохи в общем-то и на самом деле когда их внедряем то получается каире факты так как то реверс инжиниринг antique тура цифра потому что они на самом деле делают уж сам момент 1 момент первые если у нас есть какой-то блок данных он записан на 2у издержках от 3 лежала вот то после того как то если у нас упадут допустим эти две издержки поднимется 3 те кто вот на ней одной поднять ту же по игре нельзя потому что если мы так сделаем мы забудем что этот объект в еще существует вот вопрос то есть как то есть вопрос как эту ситуацию предотвращать но вот это я такое что нужно хранить все наборы на которых она поднималась то есть если она прошлый раз поднималась на 13 то надо хранить что вот прошлый подъем был на 13 если следующий подъем на 2 2 2 и 1 ты не пересекается то как бы изменить поговорим что статус типа неполной об игре in комплит а вот второй момент если у нас версия это просто целое число то могут быть колье вот такая вот интересная ситуация допустим у нас есть объект на 2-ую задачках и дальше происходит такая штука клиент одновременно в него пишет этот момент выключается питание вот его заключение питаем так получается что новая версия которая как 2 версия 2 она на один но езда прописывается on другую сдано не прописывается вот после чего опять же все включается обратно но первый возле поднимается не первым то есть первым поднимается 2 аноним вот этой новой версии 2 нет но он соответственно считает ok у меня есть объект там в версии номер один и тут злобный клиент присылают ещё один запрос записи и говорит второе сделан так как понимаете локальной версии он просто интернете и на единичку и пишет себе локальная версию допустим 2 вот но это другая версия 2 и потом если возвращается в строй уже 1 то получается что у нас две версии с одним номером а вот чтобы такого не было нужно как раз тоже хранить эпохи п.г. то есть нужно понимать что вот прошлый подъем он был на 2у издержках а следующий подъем на которой записалась вот версия 2 штрих он произошел на выезды только два вот и тогда как бы вот эта версия два штриха на перебьет версию 2 и будет всю но вот третий момент это такой самый спорный момент я его на самом деле в текущей версии которыми выложены его вообще не лишал я его просто запретил неполное удаление то есть если у меня типа там какие-то издержки выключены вот то в этот момент удалять ничего просто не взять не удалять объекты из прыгай которые там одной ногой на них находится их просто нельзя вот но на самом деле эту штуку ее тоже можно решить с помощью тех же самых и пол то есть если у нас есть четкое соответствие версии объекта эпохи п г то есть мы знаем когда этот объект и sauce он писался на состав уже вот такой-то то мы точно знаем что если из этого состава на одной из дшк его нет то значит этот объект по тулу дали а если словесно он есть на всех просто о издержки не все ну то есть у нас в норме должно быть тыс но вот был такой подъем что она была только одна вот и туда записали объект на эту одну вот но тем не менее то есть мы можем сопоставить что она поднималась на 1 и у вас объект есть на 1 значит типа все нормально значит ну то есть и таким образом можно отличить неполное удаление он полный запись вот но я это тоже уже на самом деле сделал скоро вольем просто до тестировать хочу вот следующий момент это монитор то есть управляющий слой кластера ну монитора есть две части как бы понятно первая часть это хранилище и вторая часть это логика но в принципе тоже то есть там не знаю наверно в любой системе так и тут от этого никуда не денешь вот для хранилища нужна некая б д на основе ровд это в общем уже общепринята чтобы был типа там консенсусу иголок гарантии в тёплом гарантии consistent насти в кластер он там общепринятые уже механизмы то там ровд вот варианты как это сделать были такие то есть есть в принципе есть библиотеки то есть реализация ровд рак виде библиотек есть баров тот байду есть там еще какие то есть какую-то недавно вот я помню лапала индекс выкладывал там что-то еще вот но в общем вот это туда лезть я решил туда не лезть и с этим не заниматься как бы велосипедизм еще одним вместо этого решил взять либо консул либо это cd сначала попробовал консул в общем выяснилось что у консула а фишки гораздо хуже и не удобнее чем явится сюда в итоге это cd вот ну и логика то есть логика тоже был выбор рыбы и там написать на плюсах любые написать на какой-то скрипта те и заодно затащить скрипт эту вот я решил затащить скрипта ту вот конкретно в какую скрипта ту ночь с чтобы там потом случайно не пролез питон вот собственно что мы там хранимый какая логика там будет вот ну хоронить мы там будем конфигурацию какую-то общую кластер ну который я на самом деле там минимум ну понятно что ты просто общая конфигурация там полу и поиск группы какие-то может отдельные настройки отдельных всд мож там веса допустимость о том что то такое вот потом второе это состояние то есть вид отсюда также будет использоваться как . которая имеет авторе то тивная имеет авторитет состояние в части состоянии кластер а то есть в частности предотвращает failover предотвращает спред брайн то есть чтобы так не получилось там что одна и та же поиском группа допустим взялась двумя разными издержками вот ну и логика основная часть это распределение и перераспределение данных то есть просто мы смотрим какие у нас есть и из башки есть как какие пользователи создал пула и на основании этого там рассчитываем какие должны быть песен группы и какие у них первичные езда теперь собственно как распределять данные вот картинка нами как картинка намекает на то что их надо либо нарезать либо размазывать вот собственно распределять данные можно в принципе двумя способами либо мы все будем где-то хранить то есть мы будем хранить что вот объект есть такой то он хранится там носить на серверах там 123 либо второй вариант это какие-то вариации консистентную пещеру не используют или там не совсем к систему например как это сделано в цехе то есть берется хэш иди объекта у них эти объекты эта строка а вот он делится просто берется остаток из его деление на число плазмиду получается номер placement группу потом из номера плеснул группу с помощью краж хорошо получается набору sdk рожков это вот как раз то самое консистентная хеширование то там разновидности рандеву хэш а вот но проблема в том что он не идеален и он не обеспечивает полную равномерность распределения а из-за архитектуры которые собственно тоже у меня точно такая же получается что какой-то кусочек место он теряется впустую из-за того что просто равномерности полный полная равномерность остальных данных по кластеру нет и вот с этим делать но идея такая значит берём так же точно также считаем номера place in group ну разница только в том что у нас айтишники объекта другие если у них это строка меня это там типа два числа по сути просто идиш ник образа и смещения а дальше some place мой группы просто сохранил в гетто cd их немного то есть place мы группы это их там порядка 100 на один диск у словом там стандартные рекомендации в общем это небольшой объем данных его легко сохранить и легко с ним работать вот а вот чтобы сгенерировать это распределение мы будем решать задачу рюкзака задачу рюкзака можно решить с помощью сведения йога задача линейного программирования для задачи линейного программирования есть сервер и теперь писал и подобные вот собственно как мы это хотим как эту задачу записать ну довольно просто мы берем просто говорим что вот мы хотим максимизировать там распределенное место при том что на каждому из до занятое место меньше нарвал размеры этого езды вот ну собственно это по сути эквивалентно вот такой задачи когда сумма весов всех вариантов pg ну здесь имеется ввиду что ты где-то ни одна единица вот как бы ни один шар то по г это некое число которое говорит что вот на это сочетание ruiz de ton столько-то пешек надо создать в общем вот сумма весов pg максимизирует а при том сушеную весов pg которые попадают на один из sd на одну из звездочек на каждую она меньше или равна размеру этих это издержки там 2 ну и понятно что все они больше или равны 0 в общем вот такой забавный подход он на самом деле отлично работает по крайней мере там до какого-то числа с дошик ну там наверное донецких тысяч я думаю он работает потом может быть она захлебнется просто в силу числа неизвестных переменных вот когда мы изменяем x при делении то в принципе та же самая задача легко расширяется она расширяется и и просто нужно расширить что мы максимизируем не только распаренное место но еще перемещение данных чтобы типа там поменьше данных гонять но так как два критерия у нас линия не оптимизируют то мы просто короче вот такой фокус применим мы вместо веса pg будем видим две переменные типа pg добавить побил удалить вот и введём веса которые будут штрафовать как бы плотную группу за ее непохожесть на предыдущие placement группы которые были в кластере вот ну и там стандартные те же самые ограничения добавляем типа что занятое место но из-за меньшего размера вас там типа потом второе то что нельзя удалить больше чем было и мы в принципе нельзя удалить добавить меньше 0 вот это как бы отлично работает и особенно на небольших кластерах ну там на небольших средних кластер их это обеспечивает там при наличии технической возможности как правило стопроцентную эффективность размазывания стопроцентно равномерность следующий момент на котором остановиться тоже хочется это снапшоты но зачем ну просто потому что хранил кабестан фото в день деньги на ветер то есть не понятно зачем это писать этом даже не умеет слушать snapshot это ну если опять же там кто-то вдруг не в теме это мгновенный снимок диска ну я думаю все в теме вот это мгновенный снимок диск если прямо ну так допустим у нас работает край виртуалкой мы говорим прямо на ходу говорим типы создай стал счет и у нас создается консистентной снимок состоянии что там было с этим мужиком плене все время оборачиваюсь извиняюсь да я думаю что у меня сзади кран до в общем что было с этим мужиком в фильме я думаю там те кто смотрел помню там вот в общем как реализуется снапшоты если у нас внутри купил райт файловая система типа за tfs btrfs то они реализуются очевидным образом потому что у нас там каждый файл или там образ или там что-то еще там в волне знаю у нас понятное дело что это у нас купила и целости он представлен набором ссылок на блоки которые там хранятся где-то еще и понятно что в этом случае у нас есть просто два набора ссылок и как бы все легко то есть единственно что нелегко что надо эти ссылки сами учитывать и типа считать число ссылок но плюс в том что до то есть такую в такой схеме snapshot легко и удалить и легко откатить вот но как бы overheat купил райта и как это описать нашу архитектуру ну так сходу убьем в голову не приходит поэтому переходим к вопросу а как же делается всё это без купил райт внутренней а тут на самом деле есть только два пути вот и условно их можно озаглавить вперед или назад первый вариант это условно вперед когда вот у нас есть старый область диска потом мы создали снапшоты потом в него идет новая запись происходит то есть создание какого-то пустого контейнера где нету ссылок ни на что и туда пиццу новый блок и плюс добавляется что но типа все остальные блоки смотри в предыдущем вот это вперед + и быстрый откат то есть создать новый пустой слой очень легко ты просто ну то есть создать еще раз новый слой из старого snapshot олег потому что просто страшно в пустой слой и опять него там пишут вот минус в том что удаление удаление не быстро и потому что при удалении нужно данные ну как минимум метаданные нужно перенести вот второе это то что называется назад вот и во многих как раз система где есть отчет и вот они реализованы так то есть допустим там гнатов допустим даже хранил типом они так реализован и здесь происходит следующее то есть вот у нас был образ мы говорим что у нас теперь должен создаваться snapshot при этом создается какой-то пустой опять же слой но он создается условно сзади образов типа снизу под образом вот и при записи мы блок то пишем на тоже самое место куда он должен был записаться но при этом старую версию бы copen вот это хранилище как бы назад вот минусы этой схемы минусов из ямы в том что теперь нам откатиться сложно потому что для отката нам нужно теперь блоки переносить и snapshot а в новую версию образы вот второй минус еще в том что у нас вот этот задний слой он как бы не имеет никакого смысла он просто там тепло лодки это копии содержит но сам по себе он не является сам по себе он не содержит какое-то константное состоянии и из-за этого здесь нельзя ветвиться то есть если типа не ну то есть нельзя допустим создать snapshot а потом от стоп фото там малой кровью типа создать еще один образ который его наследовать будет так не получается вот в общем это вот на самом деле той самая ситуация когда цех при реализации смог усидеть на двух стульях вот и сделать о болгарии по вот и у них есть rds на тв от и которые сделаны через назад есть от беды клоны которые сделаны вперед и каждая работает по-своему криво потому что то есть вы работы snapshot of ужасный откат вот и заткнуться из-за того что схема не позволяет нормальный откат сделать там причем еще и они там через глобальные там ссылки на через ссылку на глобальный snapshot в радость и сделаны то есть что то еще ухудшает вот либо клоны а в клонах у них немножко райтом прыщики еще на потому что когда вы пишете в свежий 4 мегабайт ный объект то 4 негабаритный объект копируются полностью даже если в этом пишет 4 килобайта ну то есть и пара этом прежде чем 1024 получается ну в общем вот так короче не надо и надо как-то по-другому делать вот что сделался snapshot им я я сделал так что ограничился одной системой они у меня всегда вперед то есть из из плюсов это позволяет снапшоты и клоны сделать с одним способом как бы при этом чтобы не было лишнего райт amplify конечно просто схема то то же самое то есть объект поверх него тип там новой версии какое-то объекта которая должна как-то просвечивать до старого либо копироваться но чтобы она чтобы не нужно было копировать целиком она у меня сделан так что типа может типа дырявой быть и просвечивать до предыдущей версии для этого типа хранятся в bitmap и блюд в том что чтение быстрая на этом прилетишь на при записи нет вот слияние как бы не мгновенное но там есть один фокус который в популярном там кейси когда у нас просто вот стопчут для бекапа он это ускоряет вот ну и можно еще там улучшить тебя через именно обновление метаданных просто это еще не сделал следующий момент про которые я хочу рассказать это зиру копи сеть я так немножко галопом по всему пробегаю но он просто я когда презентацию делал я понял что я иначе не успею вот поэтому ну как это если если тяжеловесно тонн извините следующий момент в тазе руку api сеть то есть очень волнует вопрос почему нужно программе все время копировать данные вот она занимается то есть по сути вот это то есть когда я профилирует славится сторону я все время получается так что если линейная запись то там в профиле большая часть времени тратится тупо вот на копирование памяти как бы этого избежать в общине была копирования памяти какие варианты вот я в общем попробовал в общем пол все варианты которые сейчас в linux доступны вот но из них из всех получилось сделать только rdma про который я там тоже расскажу но общему что какие в принципе есть варианты 1 и написать свой модуль ведра вот это единственный вариант который я еще не пробовал и наверно не буду потому что специфическими потом дальше есть до пдк есть rdma есть поддержка эти цепи зиру копий на отправку и на прием которая на отправку называется нас газе рукой на прием зиру копите переселить вот есть короче такая такие костыли от solar flare то упаду мот есть похожие костыли отмела нокс это либо яма в общем и так ну во-первых до пдк ты пока это такая модная молодежную штука любят стартапы в области стороны говорить что мы основаны на dpd к и за это их все короче должны сразу полюбите дать много денег инвесторы вот представляете себя до пдк ну и там еще и спотыкаясь часть которой два мешка там для дисков это в общем по сути это работа с сетевыми картами с ремешками в пространстве пользователя то есть вообще в обход ядра программа типа забирает свое пользование полностью девайсы крутиться с ним в пространстве пользователя в полно то есть в режиме опросов вот как бы да это модно но программировать под это на самом деле очень грустно потому что во первых там нету родного тисе пи вообще то есть если хотите делать сеть то получается что приходится какой-то свой транспортный слой либо придумывать либо какую-то стороннюю реализацию брать которые там тоже не прям идеально ну и там остальные проблемы они вот тоже есть этом сильно останавливаться не буду в общем короче проблем много пишутся под это довольно тяжело если говорить конкретно эти цепи я вот попробовал incipio н.с. попробовал и встык и попробовал впп в общем все сводится к тому что все это либо не работает типа как анти цепи либо или вот как все стали там я хотел найти пост с критикой там какой-то чувак критиковал этот старый статистике за то что он там типа вообще никакие граничные кейсы не обрабатывают типа 2000 строк извините чем вы вообще хотите ловить с двумя тысячами строк там против ядерной реализации типе которые там выиграна годами вот в общем смысл в том что до той все это либо не работает либо она быстро но возникают вопросы как это использовать в жены там в рамку только одного процессы и нужно как-то поверх этого монстряшек свое там разделение и как-то это смешивается с работы с ядерными устройство нити приветствую вас sata либо это впп в котором сразу заложен заложенными в процессная коммуникация но зато у него и скорость как бы в общем не лучше чем у ядра все это оптимизирована под пропускную способность а под задержку но не оптимизирован в общем резюме это все хорошо если вы пишете firewall или ты пайку какую-то но хранил q как бы нет вот следующая то зиру купите себе в ядре linux она представлена что там тебя уже время прям вот буквально минут очка наверно заканчивать и вопросы перейдем в этот раз про скачи немножко тогда сразу махина нити в общем тогда эту суб 1 кучу ну по-моему тут и не осталось уже ни чего честно говоря тут тут осталось про - это да да но тут осталось короче про rdma да и про и наша чуть-чуть в общем но это уже неважно ладно да можно заканчивать на этой позитивной ноте ну в общем короче пробуйте может кому то будет интересно"
}