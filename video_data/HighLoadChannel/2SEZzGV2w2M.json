{
  "video_id": "2SEZzGV2w2M",
  "channel": "HighLoadChannel",
  "title": "Обрабатываем терабайты данных в кредитном скоринге / Евгений Смирнов (Альфа Банк)",
  "views": 849,
  "duration": 2902,
  "published": "2024-04-17T01:10:23-07:00",
  "text": "мы переходим к следующему докладу это Евгений Смирнов из альфы Женя давай Готовьте вопросы друзья Судя по всему пора обновить фотографию это действительно я Итак давайте перейдем докладу критскоринг является традиционно очень консервативной областью и там используется очень простые модели по типу логистической регрессии в силу интерпретации но в альфа-банке все давным-давно уже не так мы совершили революцию в кредитном скоринге и уже обрабатываем терабайты данных при помощи нейронных сетей сегодня Вам расскажу зачем нам это нужно как мы к этому пришли и какие результаты это дает банку но сначала Давайте познакомимся с аудиторией поднимите пожалуйста руки кто хоть раз сталкивался своей жизни с кредитным скорингом Ага не все подняли У меня для вас есть некая тайна вас на самом деле ваш банк спорит регулярной основе и вы узнаете сегодня зачем а теперь поднимите пожалуйста руки Кто из банков отлично это доклад вам будет полезен для того чтобы узнать как трансформировать кредитный скоринг ваша организации А теперь Поднимите руки кто хоть раз строил нейронную сеть своими руками лес рук видимо чат gpt нам тут помог но Не обманывайтесь Если вы писали только промт соответственно для вас доклад будет полезен тем что вы узнаете как можно использовать нейронные сети финтехи а не только для хайповых задач типа обработки текстов картинах видео аудио и так далее с аудиторией познакомились теперь пару слов о себе Меня зовут Евгений лаборатории машины обучения но так было не всегда сначала я закончил из тех по направлению интеллектуального анализа данных затем успел поработать на линейной позиции в Тинькофф через полтора года я успел стать таким лидом дорастил свою команду до десяти дата сантехнистов затем перешел в Альфу в составе команды из одного человека делать революцию в кредит в хоринге она успешно прошла я стал руководителем лаборатории машинного обучения Теперь мы не только зарабатываем банку деньги не но и улучшаем сервис для клиентов со мной можно связаться и в оффлайне после выступления но также меня можно найти в онлайне в линке тыне можно найти меня в соревнованиях по анализу данных какие-то статьи можно почитать на хаббре от меня и даже можно найти в рейтинге Forbes Итак О чем сегодня пойдет речь Сначала я вам расскажу о постановке задачи кредитного скоринга затем расскажу как он эволюционировал в альфа-банке потом мы поговорим о данных для кредитного скоринга потом уже перейдем к нейронным сетям я расскажу подробно тех архитектурах которые мы используем в продакшене вы узнаете как эти архитектуры можно эффективным образом обучать Расскажу конечно же об основных результатах о том как устроен наш продакшн и о планах на будущее Итак начнем с постановки задачи кредитного скоринга с бизнесовой точки зрения задача звучит так банк хочет научиться определять если он клиенту выдаст кредит то вернет он его либо Нет банку понятно почему это интересно потому что он не хочет возвращать деньги Он не хочет давать деньги тем кто их не вернет тут экономика очень простая но у клиента есть даже сразу три мотивации первая мотивация банк по-отечески о вас думает и если вы не способны удовлетворить обязательства то он вам кредит не дает но конечно Вам в таком случае придется приходится идти в МФУ если вам кредит очень нужен вторая мотивация для клиентов Это зрелость кредитной политики банка если банк выдаёт кредиты по зрелой политике то он разорится и ваши вклады не сгорят и третья мотивация Посмотрите на процентную ставку Она состоит из трёх ключевых факторов первый фактор - это ставка Центробанка второй фактор это маржа банка и третий фактор это риск Кост соответственно если кто-то не платит за кредит то по экономике продукта платите за него вы давайте рассмотрим задачу поподробнее для этого рассмотрим пятерых клиентов майка Джека Лери Кейт и Вильяма Надеюсь произношением все было хорошо и также Надеюсь что таких клиентов нет зале Если кто-то есть и я его назову ненадежным ненадежным заемщиком то Пожалуйста поднимите руку я извинюсь Будем считать что банк по какой-то схеме научился оценивать вероятность невозврата кредита и после того как он всех уже научился оценивать ему нужно проводить черту после которой он кредит не выдает ну и соответственно до которой он кредит выдаёт до черты мы называем клиентов надежными заёмщиками после черты называем их ненадёжными и тут перед это санктистами стоит амбицио задача прогнозирования будущего так именно говорят журналисты когда рассказывают про дейта-сайнс хакатон на самом деле предсказываем будущее но делаем Это с погрешностью в отличие от Ванги и конечно же нужно поговорить о метриках качество которое мы используем для оценки наших моделей Как вы могли заметить нам нужно разделить Хороших клиентов от плохих То есть отранжировать их Ну подобно тому как Яндекс выдает вам поисковую выдачу нам нужно отранжировать всех клиентов и понять где проходит черта где мы клиенту кредит выдаём А где не выдаём для этого мы используем метрику Джинни она показывает то насколько правильно упорядочены пары тех кто кредит вернёт и тех кто не вернет давайте рассмотрим на примере у нас будет две модели одна идеально другая плохая Будем считать что мы оцениваем результаты модели уже на Ретро данных то есть тот факт выдал ой вернул нам человек кредит либо нет уже известен э в первом случае в случае идеальной модели У нас есть некая монотонность Чем выше вероятность невозврата кредита тем больше людей которые его не вернули в случае плохой модели у нас получают Следующая история Независимости от того высокая вероятность либо низкая вероятность могут быть клиенты которые нам кредиты вернули и не вернули и на примере слайда видим что тут такая болтанка происходит и модель на самом деле получается не умеет ранжировать клиентов на самом деле те кто занимается анализом данных могут спросить а есть же такие классные модели ой такие классные метрики как престижен реколы F1 для сдачи бинарной классификации Они ведь на них тоже можно смотреть почему они не подходят Дело в том что макроэкономика может меняться стремительно А например вспомним ковид в случае ковида банку нужно было делать так называемая закрутки это не что-то запрещённое закрутка в Кореи там скоринге означает то что банк выбирает более консервативную политику и теперь выдает кредиты под меньший уровень риска А если банк делает раскрутки а то он делает наоборот То есть он хочет захватить какую-то долю рынка и теперь готов выдавать более рискованные кредиты теперь поговорим как улучшение моделей кредитного коринга влияет на бизнес улучшение модели влияет на два фактора первый фактор это количество выдачи второй фактор это уровень риска соответственно мы можем фиксировать один параметр и варьировать другой если мы зафиксируем количество выдачи то очевидно мы снизим риск при повышении качества ранжирования это настолько очевидный кейс что я его даже не поместил на отдельный слайд на слайде представлен второй случай когда мы фиксируем уровень риска и варьируем количество выдачи Давайте посмотрим внимательно на слайде представлены две модели Мы видим что модель два лучше Почему Потому что зеленая клиенты это те клиенты которые кредиты нам вернут они находятся по модели 2 сильно выше чем по модели Один Вы видите что зелёные клиенты во втором случае они выше соответственно фиксируя уровень риска у нас может вырасти количество выдачи и таким образом мы можем посчитать на самом деле чисто опера доход от внедрения модели и в данном случае на примере Мы видим что и слева и справа количество клиентов одинаковое и модель 2 по сравнению с моделью 1 позволяет на 25 процентов выдавать больше соответственно чтобы посчитать чисто персон доход нужно взять до выдачи умножить их на маржинальность одного продукта и так посчитать эффект Зачем Я вообще об этом рассказываю на highload чтобы совершить революцию в критном скоринке нужны очень сильные аргументы для бизнеса то есть снижение риска Это все хорошо но это интересно тем кто работает в рисках бизнес интересно зарабатывать деньги Поэтому вне зависимости от того банки используют улучшение модели по первой либо по второй схеме нужно использовать такую аргументацию для защиты финансовых эффектов Вот и когда вы научились читать финансовый эффект вы вряд ли найдете в коммерческой организации такого топ-менеджера который не захочет увеличить чистую операционный доход банка Это всегда можно использовать в качестве железобетонного аргумента теперь мы поговорим о том как трансформировался кредитный историк в альфа-банке в далеком 2000 году все было на ручном приводе соответственно вы приходили в банк там сидел специально обученный человек вы в бумажном формате заполняли анкету человека оценивал ваш scoreal мыслил примерно так если у Вас есть семья то это плюс если у вас есть стабильная работа это тоже плюс если у вас есть судимость это минус примерно такого уровня были признаки в 2005 году мы начали использовать уже машинное обучение на самом деле классическая регрессия тоже нейронная сеть но очень простая но мы все-таки считаем что это классические методы они нейронные сети Вот и на тот момент мы начали использовать статистику и на основании статистики И которая получалась из анкеты Мы научились строить модели по типу логистической регрессии которая также линейным способом для каждого Фактора получала некий спорт баллы из курбаллы складывались если объяснять на пальцах и таким образом принималось решение выдавать кому-то кредит либо нет затем за 10 лет банк начал накапливать большое количество данных ну во-первых появились мобильные телефоны люди стали чаще платить картами появилась Бюро кредитных историй и у банка появился помимо кредитной истории дополнительный источник данных это данные по клиенту которые накоплены в банке соответственно данных стало очень много и модели с большим параметром например такие как градиенты и бустинг оказалось что стали работать сильно лучше то есть градиентным бустинге используются порядка десятков тысяч параметров при принятии решения логистической регрессия используется просто десятки параметров Затем в девятнадцатом году начала зарождаться лаборатория машинного обучения все банки знали что Ну вот есть какой-то хайп вокруг нейронных сетей нужно как-то их применять в банке Но никто не знал Зачем как раз Это команда ответила на этот вопрос На данный момент у нас в банке уже сложные источники данных обрабатываются нейронными сетями и сейчас нейронные сети являются основным классом моделей в принятии решений сейчас у нейронных сетей вес 70 процентов За счет внедрения нейронных сетей мы улучшили метрики качества кредитного скоринга на 9 процентных пунктов Джинни это нам стоило новых вызовов нам пришлось докупить железо нам пришлось научиться нанимать более квалифицированные сантехнистов и еще лучше мониторить модели на их стабильность теперь поговорим об источниках данных Вы помните что для больших моделей нейронных сетей которые обучают внутри себя сотни тысяч параметров в лучшем случае нужно иметь большое количество данных чтобы все эти параметры выучить перечислены Какие основные большие Данные есть в банке это всевозможные транзакции раз дальше это кредитная история клиента 2 различные логии сайта и мобильного приложения и банк очень часто коммуницирует с клиентами и клиент с банком это последний тип источников данных если посмотреть на карточную транзакции например то у нас в банке ежегодно собирается порядка пяти миллиардов транзакций по всей клиентской базе но это уже можно называть модным хайповым словом дата либо Big Data Если хотите правильное произношение Надеюсь теперь перейдем от источников данных построению модели а если вы хотите дать заем своему другу то что первому делом вы сделаете Вы скорее всего сходите к другим его знакомым Спросите А раньше у вас этот друг брал кредит А если брал то возвращал либо не возвращал и как он себя раньше вообще вел там были у него просрочки по платежам не были когда банк выдает кредиты он соответственно идет в такое хранилище называется Бюро кредитных историй там по сути вся эта информация содержится Что где когда и На какую сумму брал человек в качестве кредита были у него просрочки платежам либо не были А следующий источник данных который говорит о платежеспособности потенциального заёмщика это его транзакции Банк знает Что Где Когда я на какую сумму вы приобретали В некоторых случаях он даже знает состав чека а если вы делаете переводы юридическим лицам например за оплату крупных покупок таких как не жимость либо автомобили либо платье за обучение лечение либо за ремонт в это делаете переводом по расчётному счёту банк такие транзакции тоже умеет анализировать это второй крупный источник данных и третья История - это абьюзинг поговорки Скажи мне кто твой друг и я скажу кто ты соответственно если вашем окружении очень много людей которые кредиты не возвращают то скорее всего вы тоже его не вернете Как можно устанавливать эти связи первый самый надежный тип связи Это поручительство по кредитам если кто-то за вас поручился скорее всего вы очень близко с ним знакомы Ну либо имеете на какое-то на него влияние Вот и скорее всего либо близкие родственники либо очень хорошие друзья следующий способ это анализ переводов между физическими лицами Вы можете переводить деньги маме можете переводить деньги вашим любимому продавцу на рынке за вашу любимую клубнику это тоже всё можно анализировать дальше это всевозможные акции Переведи друга и работа в одной организации скорее всего внутри организации у вас кредитный рейтинг похожий Итак все источники данных которые я перечислил Они обладают последовательной структурой То есть транзакции это данные по транзакциями это последовательность ваших покупок данные по Бюро кредитных историй Это последовательность ваших платежей либо не платежей соответственно и получается что на вход по клиенту У нас есть большое количество последовательных данных если мы работаем с классическими методами машинного обучения то нам нужно начинать придумывать на временных рядах как мы будем строить признаки Давайте вместе подумаем на примере транзакций первое что в голову придется скорее всего если у клиента есть деньги Он часто тратить то наверное по нему риск будет пониже вы придумываете средний чек Затем вы зайдете мобильное приложение посмотрите что есть некая категоризация по MC категориям потом вспомните что Ага а что Сейчас крутят по телевизору ставки на спорт чаще всего и соответственно Вы можете придумать признаки по различным категориям трат клиента а затем можно подумать следующее что наверное если человек давным-давно ставил на спорт уже не стоит то наверное это тоже какой-то важный признак Вот после того как какой-то сет признаков и придумываете вы закинете его ваш классический метод например градиентный бустинг render Forest Логистическая регрессия и так далее затем оперативно будете придумывать новые признаки обучать новые признаки обучать новые признаки Ну вы поняли то есть нужно придумать очень много признаков и протестировать их всех в каком-нибудь классическом методе Но если вы используете нейронные сети то вам не нужно больше придумывать признаки вам нужно понимать Какие архитектуры подходят под ваш э источник данных и как показывает практика все вот эти признаки придумывать невозможно раз и правильно их реагировать при помощи классических методов тоже не очень хорошо получается иначе нейронные сети не работали бы лучше а теперь поговорим о том как мы Какие архитектуры мы используем для решения этой задачи и Итак на вход у нас есть некая последовательность событий нам нужно построить нейронную сеть которая будет решать задачу бинарной классификации то есть отвечать на вопрос вернет человека кредит либо не вернет В общем случае нам нужно для каждого элемента последовательности придумать некие betting либо некая векторное представление а затем эти данные закинуть какую-то Модель которая умеет работать в какой-то слой который умеет работать с последовательной архитектурой и режиме обучить ее кажется это нам что-то напоминает например Когда вы ищете курсы по диплом в Яндексе то происходит то же самое для каждого слова получается Он обрабатывается какой-то архитектурой для работы с последовательностью и затем используется ранжирующий лосс соответственно возможно взять все архитектуры которые есть в НЛП и переиспользовать их для домена последовательностей за одним исключением у нас Каждый элемент последовательности является не словом а целым вектором векторе содержится как категориальные признаки атаки вещественные признаки вещественные признаки можно легко перевести в категориальные методом обойти зации по 20 квантилям например затем получив mbning для каждого из признаков можно их заканчивать просто и таким образом у вас получится для транзакции Давайте посмотрим на самую элементарную архитектуру с использованием рекурентной нейронной сети на вход у нас мэтнике дальше реку рентная сеть потом мы берем последний hidden State накидываем на него несколько полных связанных слоев и обучаем на задачу бинарной классификации в такой парадигме у нас качество будет не очень высокое мы можем эту архитектуру улучшить например использовав направленную рекуррентную сеть далее мы можем обратить внимание на то что мы используем рекурнятной сети только последний выход Давайте использовать сразу все Но тогда у нас повысится размерность и чтобы ее снизить нужно использовать различные пудинги например макспулинг далее вспомнил архитектуру по типу резнета она помогает регулировать вашу сеть сделаем похожую архитектуру добавив пробросив и Макс пулинги из слоя мм Ну это у нас первый тип регуляции Давайте раскрутим регуляризацию например вспомним ее из классических методов это L1 и L2 регуляция это тоже повысить наше качество и последний но очень важный способ как можно улучшать качество сдачи кредитного скоринга Нужно вспомнить о том что ваш выборка собирается продолжительный период времени обычно это 3 года и соответственно Когда вы учитесь на исторических кредитах которые выдавали 3 года у них вес должен быть меньше чем у тех которые выдавали совсем недавно что очень Разумное тоже улучшает качество Как показывает практика теперь поговорим о том как эти все модели можно учить быстрее если вы помните доклад называется обрабатываем терабайты данных в критном скоринге Вот они появились откуда они берутся если посмотреть только на транзакции то у нас получается 2 миллиарда транзакций Это примерно пол терабайта данных это на этих данных моделей учится порядка 10 часов и на этапе инференса у нас данных становится в два раза больше потому что мы собираем данные по всем клиентам Это уже как раз получается старбайт случае кредитных историй получается аналогичная история чуть поскромнее в два раза Ну порядок остается тот же то есть в целом данных очень много получается и мы хотим чтобы модели работали очень быстро иначе Нам нужно будет переинвестировать закупку железа так с этим можно жить Давайте посмотрим на примере транзакций у нас есть различные клиенты например Иван Олег и Дима по Ивану очень много транзакций Мы о нем много знаем Поэтому он такой жирненький по Олегу мы знаем чуть меньше Дима всего совершил 10 транзакций за последний год когда мы обучаем нейронной сети важно чтобы у нас тензоры на внутри батча были одного размера Поэтому чтобы обучать на трех таких клиентов нужно падать соответственно в нейронных сетях это значит Вам нужно будет добавить некое количество нулевых элементов Если вы берете Ивана то вам нужно добавить нулевых элементов Если вы берете Олега то вам нужно добавить 900 нулевых элементов А в случае Димы 990 но Давайте вспомним что каждая транзакция это не слово а Целый Вектор он состоит из 20 признаков и результате вы добавляете порядка 20 тысяч нулевых 20 тысяч ну И это не очень хорошо как с этим можно бороться первый способ это использовать Пак сиквенс из торча торч это библиотека для построения нейронных сетей но у этой этого метода есть минус он плохо работает откуда NN реализациями Давайте посмотрим на распределение Какое количество транзакций клиентов и долю таких клиентов мы видим что у нас очень много клиентов совершает так много транзакций и отсюда можно сделать следующий вывод надо вспомнить что внутри Бача только должен быть одинаковое количество примерно одинаковое количество транзакций точнее одинаковое соответственно мы можем сгруппировать всех клиентов по длине транзакций и делать Бачи Так что внутри одного Бача было были клиенты сконцентрированы примерно одним количеством транзакций Это позволяет нам не так сильно па рить Мы в итоге можем учить модели в три раза быстрее мы добавляем сильно меньше нулевых транзакций раньше это было 95%, сейчас это всего 10%. и как результат можем проводить все больше и больше экспериментов чем больше экспериментов тем лучше итоговое качество теперь поговорим о результатах Привет Сегодня я вам рассказывал о том что у нас продакшене используется нейронные сети на сложные структурированный источниках данных Но рядом есть еще хорошо положенные табличные данные которые хорошо используется табличные данные в плоской структуре для них State of duart решением по-прежнему является градиентный бустинг соответственно на них нужно продолжать строить градиентный бустинг и у нас есть два направления одно занимается нейронными сетями другое использовать градиентный бустинг эти команды работают у нас Независимо это очень удобно с точки зрения разработки с точки зрения внедрения с точки зрения мониторинга а затем мы смешиваем при помощи логистической регрессии теперь поговорим об основных результатах у нас на момент 22 года в продакшене было тренировок сети и один градиентный бустинг Как показывает показывают результаты нейронные сети втроем лучше чем один градиентный бустинг Несмотря на то что градиенты бусинки используют в том числе и транзакции и данные бки а поверх градиентного бусинга мы добавляем 6 процентов пунктов жене это на состояние 22 года двадцать третьем году мы добавили все больше источников данных мы добавили чеки операторов фискальных данных социальной связи клиентов некоторые табличные признаки и научились смешивать нейронные сети по новому То есть раньше мы это делали при помощи логистической регрессии Теперь мы это делаем на уровне бензингов смешивание на уровне бензингов нам добавила два дополнительных пункта Дженни и сейчас нейронные сети поверх бустинга дают 9,5 процентных пунктов Джинни в результате с точки зрения моделей мы повысили качество ранжирования с точки зрения бизнеса мы зарабатываем дополнительно более 1 миллиарда чистого операционного дохода каждый год мы дополнительно отказались от части внешних источников данных и тот подход который мы разрабатываем разработали он хорошо переиспользуется для других банковских корб бизнес задач например Это склонность и отток А теперь поговорим про Production в продакшене у нас работает большое количество нейронных сетей все вместе они отрабатывают примерно за день в Пике мы используем дискового пространства примерно полтора терабайта на ходупе мы используем 300 CPU на этапе перед обработки и чуть больше одного терабайта оперативной памяти мы проходим следующий этап это сбор данных предбработка их inference модели и записываем результаты в хранилище В итоге нам на вход приходит полтора терабайта данных мы их сжимаем до одного гигабайта и в результате можем для каждого клиента сделать решение спрогнозировать тот факт если мы ему кредит вернем дадим то вернет он его нам либо нет теперь немножко про историю расскажу как это все вся история эволюционировала в двадцатом году мы внедрили первое нейронные сети в Production как у Первопроходцев у нас были проблемы не было никакого сервера Нам его пришлось найти сами организовали Production стенд мы занимались как и внедрением так и поддержка etl процессов так и поддержка инфраструктуры и мониторинга модели самый красноречивый пример это отсутствие интеграции У нас не было его полтора года и поэтому мы раз в месяц ручками передавали Файлик по почте да именно так работал скоринг самом крупном частном банке в России но ничего не упало за этот промежуток времени мы взяли на себя ответственность и благодаря этому мы перешли в полноценный провод сейчас у нас есть выделенная среда исполнения моделей у нас три контура помимо продал это тестовые нагрузочный контур это сантехни занимаются разработкой внедрения моделей поддержка etl занима ются датой инженеры поддержка инфраструктуры эмальсы а мониторингом выделенная команда так получилось что те модели которые мы разработали в криком скоринге они заходят во все бизнес направления для всех сегментов бизнеса и для всех Core бизнес задач напомню это помимо кредитного скоринга склонности отток получается так где они построишь нейронную сеть она хорошо работает и увеличивает качество существующих решений И что же делать дальше Наверное нужно нанять больше людей и нас должно было бы быть не 20 человек а 120 по такому пути идут некоторые компании Но э-э в силу того что ресурсов у нас было немного у нас э разработка нейронных сетей А сало уже некой рутиной То есть когда вы строите нейронную сеть на одном из источников данных которые я перечислил первое время это очень интересно но затем это становится некой рутиной и с рутиной надо бороться Очевидность способ это менять новых людей Им будет не рутина и они будут счастливы но это не наш подход Если Вы посмотрите на картинку справа наш подход это переход на сервисную архитектуру То есть если мы что-то уже хорошо отладили и моделька строится запуском джипайкер и ячеек запуском ячеек пати в ноутбуке то мы можем перевести это на сервис который на вход принимает обучающую выборку на выходе строят модель под конкретную задачу диплоид ее в продакшн и в итоге мы таким образом масштабируем нейронные сети на все сегменты бизнеса на все задачи бизнеса повышаем покрытие и избавляем статистов от рутины какие у нас остались вызовы Извините а важно что сейчас мы этот сервис разрабатываем Он у нас точно получится потому что мы его назвали именем жены руководителя команды теперь им можно заниматься внеурочное время без нареканий Да какие вызовы у нас остались после того как мы разработаем сервис нам нужно его масштабировать на все ключевые задачи банка дальше за счет того что будет все унифицировано мы сэкономим на железе как на этапе работы с базой данных так и на этапе разработки моделей дальше мы все данные с агрегируем в одном месте все задачи закрепим в одном месте поэтому мы с точки зрения машинного обучения можем пойти в мульти-таргет и делать наши модели еще лучше и дальше добавлять новые новые последовательные источники данных в эту модель и последний очень важный пункт очень часто этот статистов ругают то что они вроде как и не до Разработчики если они работают бизнесовых направления что они еще не до ресерчеры вот мы как раз от этого уйдем у нас будет два направления одно направление будет улучшать сервис то есть ребята станут полноценными разработчиками раз а второе направление будет заниматься исследованием то есть мы станем ценными исследователями Вот такая трансформация нас ожидает ближайшее время чтобы ее не пропустить подписывайтесь на телеграм-канал Нескучный это сайт Там можно будет из первых одним из первых узнать о том как трансформируется наш сервис как трансформируется кредитный скоринг в альфа-банке дальше там Также можно будет узнать о всех грядущих мероприятиях Мы также запускаем этапы запускаем соревнования по анализу данных И что самое важное Вы можете найти в закрепленных сообщениях обучающий трек как повторить революцию в кредитном скоринге в вашем банке все обучение естественно бесплатно Если кто-то вдруг сомневался Спасибо за вопросы голосуйте за мой доклад Спасибо за внимание вопрос еще не было голосуйте за мой доклад Буду рад видеть на все ваши вопросы Спасибо Спасибо большое девчонки у нас первый вопрос вон там такое бывает друзья Напоминаю что когда вам qr-код в конце доклада дают на обратную связь чем подробнее вы обратную связь останетесь оставите тем лучше будет контент в следующий раз потому что программный комитет правда спикеров со словом со знаком плюс дрючит так у кого микрофон признавайтесь Вот раз потом два пожалуйста Сергей компании X5 я обратил внимание на то что вы работаете над тем чтобы ускорять обучение модели при этом вроде как обычная модель потом просто выдает результат да то есть приходит человек его там отправляют в модель и она выдает ответ выдавать ему кредит или нет соответственно Ну как бы а в чем смысл ускорение обучения модели пусть она там получится за полгода и потом 10 лет работает выдает результаты зачем ей обучаться за считанные часы как будто у вас стоит задача переобучать ее 8 раз в день спасибо за вопрос первое с точки зрения клиента если модель возвращает результат быстро это тоже очень важно потому что у нас среда Газпромбанк выступал тут некоторые коллеги из других банков сидят Поэтому если мы отвечаем клиенту медленно то он может уйти в другой банк А раз с точки зрения этапов обучения модели чем мы больше чем мы быстрее обучаем модели тем и больше экспериментов можем сделать чем больше экспериментов мы проведем тем слушаем качеством будут работать модели потому что машинное обучение это немножко еще и исследовательская область Спасибо Спасибо большое так вот теперь левая часть зала Привет Спасибо за доклад у меня такой вопрос Ты когда рассказывал про эволюцию моделей прозвучал один из вызовов то что модель должна быть интерпретируемой и кажется что после бустинга из сетей это очень сложная задача интерпретировать такую модель что в итоге с этим вызовом научились ли вы интерпретировать Либо вы объяснили бизнесу что это невозможно Спасибо интерпретация модели действительно требуется но не всех все модели которые требуются чтобы они были интерпретируемые по мнению регулятора они остаются в банке интерпретируемыми а бизнесовые модели они могут быть на уровне черного ящика а бизнесу самое важное чтобы они просто работали стабильно если они работают стабильно то бизнес счастлив это мы покрываем мониторингом этих черных ящиков Спасибо Привет Спасибо большое за доклад очень интересно было послушать так как сам банке работал и подобным занимался смотри вы упомянули что у вас использовались Типа эластиэм белости вы пробовали смотреть сторону Трансформеров для того чтобы как-то учитывать весь предикт и у меня сейчас несколько вопросов если можно я последовательно буду отвечать да конечно пробовали Мы даже проводили два соревнования по анализу данных не только мы пробовали А еще порядка 500 участников вот практика показывает Так что Трансформеры в этом случае работают хуже чем конкурентные сети если было иначе у нас бы конечно бы продакшне работали Трансформеры Окей Следующий вопрос ЦБ тут уже задавали Центробанк обычно просит интерпретируемся от многих моделей используемых банках из-за этого люди придерживаются как раз классических моделей потому что их там как-то можно объяснить вон там дерево туда пошло дерево сюда пошло Вот и как вы с этим боролись не давил ли вы на вас регулятор с этим Да это повторение вопроса ответ такой что те модели которые должен быть интерпретированы они остаются интерпретируемые для регулятора и строится с точки зрения методологии регулятора а внутри бизнесовой модели они могут быть очень сложными Но главное чтобы они стабильно работали и довольно такой провокационный вот вы говорили что у вас был эффект вы его посчитали от внедрения модели Как вы его считали потому что кажется что мы можем модель либо внедрить либо не внедрить если мы внедряем то мы получаем больше денег если не внедряем то как бы деньги теряем но мы не можем одновременно это сделать И непонятно как это оценивает таким образом а на самом деле очень просто первое мы можем делать оценку качества на Ретро данных раз она очень сильно коррелирует с будущим два мы можем запускать тесты в рамках AB теста можно поток разделить на части потока оценить финансовый результат и его максимировать на весь поток и затем после успешного теста можно раскатать сразу на всех Окей спасибо большое спасибо признавайтесь Так ладно тогда вот смелый мужчина в розовом Да спасибо за доклад для видео Вставайте пожалуйста Спасибо большое а вопрос такой вот у вас есть получается классическая машина обучение нейронная сеть сверху стоит какой-то решающее правило вот я бы хотел узнать как вообще вывод сделали то есть я так понимаю это просто типа вес какой-то вы придаете результату модели складываете делите пополам и вот в итоге смотри у нас есть нейронные сети есть классическая машина обучение и есть поверх дополнительная модель логистической регрессия тоже из класса классических моделей которые их смешивают то есть по сути мы по данным этот вес определяем Какой вес уходит на нейронные сети а какой вес уходит на классические модели и у этой логистической регрессии два параметра типа от одной модели результат другой не проще было сделать какой-то тупое решающее правило типа там вот этой модели там 0,6 потому что она там хуже работает например А это там 0,8 только эти веса подбираются на основании статистики а не на основании чего-то экспертного мнения Спасибо Спасибо за доклад вопрос возможно будет глупый потому что я с анализом данных только рядом но в нейронках лучше работает подход как микросервисная архитектуры то есть зоопарк разнообразных специализированных сетей или наоборот одна большая монолитная которая все внутри себя обрабатывает очень хороший вопрос практика показывает что в данном случае у нас зоопарк работает также как и Монолит мы проводили эксперименты пока мы не смогли построить мононить лучше и здесь мы уже сталкиваемся с тем что данных становится очень много если мы делаем Монолит то уже получается там несколько терабай данных Вот это всё учится сильно дольше и пока практика показывает не работает лучше как только будет работать лучше конечно же мы перейдём в Монолит будь добры вот Раз два три и так далее Добрый день спасибо за доклад У меня на самом деле несколько вопросов если даже выписал вопрос первый прозвучала фраза что вы полтора терабайта входящих данных ужимаете до гигабайт это вот как хотелось бы понять чисто технически Zip нет имеется ввиду следующее нейронная сеть принимает на ход полтора терабайта данных и нужно ответить на вопрос конкретному клиенту выдать кредит либо не А после фильтрации гигабайт остается то есть нейронная сеть на основании этих данных сначала выучивает набор правил по которым нужно преобразовать финальный ответ вот на вход мы получаем кучу данных а на выходе получаем ответ то есть мы не занимаемся зипированием данных а мы по данным просто делаем предсказание предсказания они занимают тысячи раз меньше места я понял Следующий вопрос допустим как нейросеть будет принимать решения о новом клиенте к примеру или вот человек я не знаю получает в Альфе зарплату но продуктами Альфа он не пользуется То есть у него просто зарплатный проект Да ему пришли деньги он их вывел как по этим людям будет приниматься решение смотрите есть источники данных которые доступны по клиентам только это Например транзакции но есть источники данных которые идут а из анкеты то есть человек нам сама себе рассказывает б и из Бюро кредитных историй Когда вы заполняете заявку на кредит то внизу стоит галочка и там вы соглашаетесь с тем что банк идет Бюро кредитных историй и узнает о том как вы раньше себя вели относительно кредитов брали не брали возвращали не возвращали уходили в просрочки либо не уходили понятно и последний вопрос вот у вас было слайде написано что более миллиарда чистой прибыли А вы сказали операционный это разные понятия все-таки хотелось бы понимать чисто операционный доход а чисто операционно все хорошо спасибо понимать Спасибо за доклад пару вопросов Это я правильно понимаю оффлайн решения то есть мы заранее готовим данные потом на базе этих предсказаний что-то делаем а то что я рассказывал Да это действительно Flight решение но за это время мы успели внедрить нейронность этим онлайн и сейчас одна из моделей работает в онлайне это необходимо как раз в случае Бюро кредитных историй потому что вы получаете данные моменте И вам нужно в моменте по ним сделать расчет но например в случае транзакции Нет смысла считать в онлайне потому что у вас за предыдущий год по клиенту среднем 200 транзакций и еще одна доптранзакция за текущий день она сильного профита на оценку кредитного риска не несет Спасибо еще вопрос есть ли Как устроена валидация Ну то есть например мы считаем предсказание У нас могли фичи как-то сломаться поменяется распределение предсказания как вы это контролируете и контролирует контролируете ли Да конечно двумя способами есть отдельная команда мониторинга она мониторит входное распределение в продакшене и конечно же по традиции в банке есть выделенный отдел валидации которые перепроверяет модели перед их внедрением друзья у нас три минуты поэтому мы все вопросы не успеем но спикер доступен в кулуарах я вам обещаю Да пожалуйста Да спасибо за доклад было очень интересно приятно осознавать что я буду жить в то время в котором нейронки будет зарабатывать там деньги теперь к вопрос был похожий вопрос уже Занимается ли ваша модель оценкой входящих данных уже на рабочем примере на рабочем пришел человек если у него мало данных или если они противоречивы например у него Абсолютно нет там реальной работы но он уже как-то кредит один или два закрыл Занимается ли это ваша модель или эти другое занимается или это человек принимает решение Хороший вопрос мы этим занимаемся и прямо и косвенно прямо у нас для этого есть отдел верификации То есть если вы Вы скажете что вы Евгений Смирнов Вы скорее всего не Евгений Смирнов посмотрят на вас сравнят паспортные данные и вам кредит не выдадут это прямой способ верификации косвенный способ верификации это через данные То есть если раньше так случалось что к нам приходили клиенты с противоречивыми данными и кредиты не выдавали Ой не возвращали то соответственно статистически получается так что этим клиентам в будущем похожим клиентов будущем Мы кредиты не будем выдавать То есть это косвенное влияние прямое влияние в ручном режиме тоже дополнительно проверяем спасибо спасибо Слушай а как взломать этот Можешь ли ты дать 2-3 совета как вот Лично мне мой Score сделать лучше очень хороший вопрос а недавно коллеги из ВТБ проводили даже соревнования вот чтобы взломать кредитный Score нужно знать веса модели нужно уметь разрабатывать модели и соответственно можно если этим всем обладаешь то под модель подогнать какой-нибудь количество транзакций которые могут повысить твой скор но все бы было плохо если было так просто для банков транзакционный модуль он имеет не такой большой вес как модули из Бюро кредитных историй потому что данные о том как ты раньше действовал по похожей ситуациях они более говорящие взломать Бюро кредитных историй Ну наверное нужно купить свое скорее всего другие способов Я не знаю но я тебя запомнил Да можно просто Промсвязь отдать микрофон да буквально полтора вопроса друзья Будем ставить книжку Спасибо за доклад Как вы готовитесь к экстремальным ситуациям То есть если случилась какое-то событие и явно нейросеть жизнь к этому не готовила То есть например 24 февраля 22 года вы отключили Всё к чёрту или вот что вы делали запретили выдачу кредитов или вы как-то стали быстро обучать сеть там им хорошо вопрос об этом рассказывал мы просто понизили риск аппетита то есть мы с 24 февраля начали выдавать пониженным риском только кредиты то есть какой имеет значение кредитной истории если человек на фронте Да очень хороший вопрос но это решается на уровне снижения риска и не более того то есть моменте у нас данных не может прийти соответственно мы никакие решения на основании этого принять не можем и все что можем сделать это закрутить рис политику Как показывает практика в том числе случае к вида Там тоже были похожие события которые нужно было отлавливать это практика Рабочая потому что на большом количестве клиентов ужесточение кредитной политики с этим справляется а нет какого-то запасного дерева решения на этот случай что переключиться на более Простые правила а смотри получается так что у тебя и простые правила и сложные правила такие как нейронная сеть работают примерно на одном источнике данных и от того что переключиться на Простые правила У тебя точнее не станет вот поэтому мы нейронные сети в таких случаях не отключаем Спасибо Спасибо большое Все кто задавал вопросы махните рукой чтобы можно было легче определиться помнишь вопрос про взлом нейронной сети отлично Мне кажется да книжка про компьютерные сети в компанию которая занимается железом прямо бабам А тебе тоже памятные призы конференции друзья прямо сейчас берете спикера уводите в Клары на улице до задаете вопросы и следите за программой в каком зале вам быть через 10-15 минут хорошего дня"
}