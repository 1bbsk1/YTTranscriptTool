{
  "video_id": "3gClNhiw57k",
  "channel": "HighLoadChannel",
  "title": "Как создать дата-платформу с нуля / Павел Тарасов (ЦИАН)",
  "views": 2464,
  "duration": 3074,
  "published": "2018-08-16T03:53:10-07:00",
  "text": "так ну что коллеги всем привет я думаю что можно начинать меня зовут пошто раз я представляю компанию сам думаю что сам в москве и в питере знаю точно все наверно многие по всей россии мы крупнейший сайт по онлайн недвижимости в россии у нас аудитория более семи с половиной миллионов уникальных пользователей не более 2 миллионов активных объявлений на сайте я вам расскажу как мы строим эту платформу как можно построить эту платформу и зачем вообще это нужно подать начнем сначала зачем вообще то может быть ну прежде всего когда компания вырастает у нас появляется много данных мы хотим получать от этих данных какой-то пульт самая очевидная как можно получать от этих данных пользу это использовать их в машинном обучении для самых разных кей ну прямо может хотим оптимизировать какие-то сервис это могут быть рекомендательные сервисы это может быть ранжирование это может быть умной коммуникация с клиентами когда мы хотим понимать в какой момент что именно клиенту надо предложить чтобы повысить какие-то наши целевые метрики другое использование это может быть информация для наших пользователей как раз пример том что что перед нами коллега рассказывал да вот мы показываем какую-то статистику статистику можно показывать не только просто там просмотра чего там гораздо более расширенную давать какие-то сложные аналитические отчеты пользователи как правило будут эти мурадов и соответственно второе наверное очень важно что здесь можно сказать это если особенно когда компания это лидер какого-то сегмента то как правило у вас могут быть какие-то уникальные данные которых нет ни у кого но для нас в недвижимость это так соответственно опять же давайте эти уникальные данные вашим клиентам это очень полезно и здорово последние наверное про то что буду сегодня рассказывать что также эти данные которые вы собираете можно использовать для классического business intelligence то есть до когда мы строим отчеты на классические схеме типа olap кубов там есть все ссылки некоторые ограничения по размеру в данных мы не можем спуститься до каких-то минимальных деталей все-таки это действительно нужно пользователю который открывает отчет видеть что что то не так ему нужно спуститься ниже ниже ниже уровня чтобы разобраться что происходит ну и последнее что нужно в без intelligence это возможность по абсолютно любой информации которую абсолютно что угодно что вас происходит собрать какие-то txeq запрос соответственно вся эта информация должна быть доступна это не должно быть так что бизнес-аналитик бежит куда-то к разработчикам спрашивают где данные получает их месяцами к тому моменту ты данный уже могут от неактуальной все должно быть под рукой начнём мы с инфраструктуру которая нужна именно для машинного обучения значит что такое нам этому циклу ну вы прежде всего данные нам нужно получить получить их нам нужно в хорошем видим чтобы их можно было использовать нам их нужно уметь хранить это должны быть какие-то большие данные например потому что мы в какой-то момент мы можем захотеть использовать абсолютно все действия которые наш пользователь производит на сайт вот он там зашел куда-то кликнул куда-то там мышки провел мы хотим все это дело логировать записывать хотим ищут информацию о 100 как мы все это научились логировать и сохранять нам нужно научиться это обрабатывать данных у нас получится много поэтому нам нужно уметь это обрабатывать распределена на большом количестве машин и также полезны хочешь чтобы это бросалось несложно для разработчиков мы не хотим думать о том что данный не влезает в оперативную память еще у нас какие то могут быть проблемы мы написали короткий кусок кода а каким образом размазывается на эти машины и там исполняется за нас должно лишать библиотека которому и спорт ну и последнее когда мы научились уже обрабатывать большие объемы данных наверное на этом мы научились строить какие-то модели машину обучение хочет научиться эти модели применять смотреть на пулемете хвалил тайна какой может быть предметом опять же рекомендательный сервис вот у нас есть карточка объявление на сайте пользователь заходит видит карточку объявлений а также мы уже знаем про этого польза ли кучу всего что он искал что он смотрел можно порекомендовать ему другие объявления это будет этим персональной рекомендации вот это вот как раз real-time используй это ясно я сейчас немножко расскажу сначала похорони рование сохранение и загрузку потом на низких полимерах как можно использовать баев вычисления и тут как раз наши кейсы про модерацию по серым коммуникацию с клиентами пропуск роботов на сайте и потом расскажу как мы устроили рекомендательный сервис это же как родился я в отличии от предыдущего докладчика наоборот очень люблю об очистке стек сок ходу по и считаю что эта единая единственная такая эта система которая позволяет вот все вот это вместе делать на одной и той же системе и чтобы все вместе живы интегрировалась на ну и естественно священник трое облачное хранилище но они как правило стоит заоблачные деньги по сравнению с ходу поэтому есть вы всерьез собираетесь всем этим делом заниматься то гораздо выгоднее полевых она и так на начало prada гузку то есть очень известное много про него слышали дата like подход когда мы собираем данные складываем их при этом мы даже не всегда понимаем полезность этих данных изначально мы происходит как ему на пользу и совершать какие-то действия на сайт мы не знаем а нам эти действия потом вообще когда-то пригодятся или нет а давайте их запишем для того чтобы это все можно было потом использовать нам нужно конечно иметь описание того и всех этих событий которые мы сохраняем нам нужна вторая очень важная вещь нам нужно ведь очень быстро добавлять новые события почему ну потому что если у нас действительно идет большая разработку нашего сайта куча всего меняется она добавление новых событий мы тратим кучу времени то не на что больше времени у нас не останется соответственно к самокритике дата лейка что как правило это такая штука превращается из хранилище данных в такое кладбище данных которым потом невозможно за но если это делать с умом не опять же чтобы этому скажу то такое дело не происходит а вот в тот момент когда мы уже какое-то время складируем данные и нашли в них ценность мы должны иметь возможность эти данные разложить красивый формат сделать их типизированные если в начале мы ну прям могли ходить просто джисона конечно типизации потом но обязательно будет нужна нам возможно будут нужны разные агрегации по этим данным разные среза ну например есть у нас есть какая-то информация как у нас меняется объявление на сайте мы сначала захотим просто складывать всю эту информацию как она менялась потом какие эту информацию за это утилизирует раскладывать красивых и этой табличке а потом например считать агрегат что нас сколько за месяц раз это объявление менялась условно или текущей срез вот средств на 12 ночи какой был эд объявлению потом аналитики могли делать какие-то txeq запрос кайт мутил в чем большой плюс когда мы загрузили данные сыры они уже сразу всем доступны времени потратили нашли ценность поскольку данные доступны перезагрузили все работают быстрый хорошо известная как мы реализовываем то что мы не тратим время на загрузку у нас для этого написана своя библиотека она основана на спарке и на sparkasse квелли тут коллега несколько докладов назад я рассказывал про альтернативы если к что как гоблин от линкдин как раз которая как раз занимается выгрузкой из кафки five little tony сплошную кафка кафка это очередь сообщение которое поддержит очень большой объем то есть мы действительно можем в нее складывать все что угодно и мы так и делаем мы складываем все 40 ден данных кафку из нее уже перегружаем дальше входу в х dfs распределенные файловые системы чем собственно плохо гоблин почему он на мне нравится во первых тем что для того чтобы в гоблине настроить каждую новую перезагрузку данных нам нужно написать новый класс на джаве который будет делать эту трансформацию перекладывать этот время время которое давать мне хочется что делает наша библиотечка она представляет каждую очередь как табличку с одной колонкой на который смотрит spark успел из куяльник может написать абсолютно любой человек который даже не имеет программировать аналитик кто угодно соответственно из клиник выполняется данные записываются в один из источников который указан просто в конфиге если у нас речь идет о какой-то регулярные перегрузки больших данных условиях и the hive либо х dfs при этом мы записываем какой кусочек данных мы уже успели записать и поэтому этим обеспечиваем экзо клево nsa доставка другая очень важная штука этой библиотеке что в отличие от 5 лет того же google на поддерживать streaming режим spark чем хорош я тут как раз одна из тех утках свой раскол библиотек которые мы можем написать код запустить его на кластере и он за нас делают параллели ты и намного большое количество машин и мы не думаем о том где этот код и как исполняется соответсвено также спарку теперь может работать больше режиме раз там в несколько часов взять предложить данный может а вот стринги и когда мы поняли ценность вот в этих наших данных которым мы лилит просто так в pdf с мы на можем начать их лежит лить в 3 мин к режиме например в кафку назад в очередь если мы хотим только какие-то часть событий или как-то трансформируетесь событий на искре или можем складывать назад и кто-то другой будет дальше заливать это очень можем какие-то вещи лить в кассандру феникс значит кассандра феникс это касалось но искали хранилище я думаю все про ним конечно слышали феникс это искренняя настройка на дождей на мою вам во многом удобнее использовать чем hbs напрямую поэтому как правило мы пишем не и он сам не все данные хранится ваш быть соответственно и после этого мы сразу получаем в реал тайме доступные данные и вот таким образом например вот как только что рассказывали про счетчики таким образом мы можем есть у нас есть очередь про действий пользователя на сайте реализовывать инкремент счетчику в кассандра просто вот с помощью вот этой улитки следующая задача котором мы должны решить после того как мы научились брать сырых данных перегружает их хранить это трансформировать и выделять действительно туда нужны и важны и куски данных здесь нам нужно некоторых и дулю которая будет выполнять последовательность данных то здесь самое важное что вот эта перегрузка она постоянно помню как я только что рассказывала вам про объявлений у нас сначала пришли сырые да потом мы их с помощью этой библиотеке наши переложили в pdf с потом мы их разложили в красивую структуру следующая ступень уже это второй уровень сложности мы из них посчитали агрегаты пощекотали текущей слои есть третий уровень сложности мы наверное на этом еще захотим дальше учиться то есть машины обучение тысячи вытаскивать на этому захотим кита отчета строить это вот уже следующего все вот это нужно делать по следу то есть несколько разных версий scheduler несколько раз вариантов scheduler в которые позволяют делать основные их цель это как раз выполнять задачи по так директ а цикле газ здесь у нас вот есть что-то выполнилась что-то следующая вот эти зависимость они разрывают мы используем для этого уйдет спать и фай самые известные альтернативы это airflow ну и из старого такого ходу busco вас т.к. такую мы пробовали это это но судья основная проблема это вот этими реальные xml реки которые надо написать ему конфиге чтобы что-то выполнялось то очень сложно очень тяжело еще и глючит кромешную очень плохо air flow из коробки вот то что пишется на сайте все замечательно он умеет что угодно лучшую не кофе когда вы с ним начинаете разбираться как очень много проблем что в какой-то момент джо бы не запускаются здесь грабли здесь грабли ну там в чем грабли какие довольны и неочевидные читаешь читаешь читаешь почему-то не запускается оказывается что все время на машине время в базе данных время все должно быть ведетесь и почему витязь и ну потому что эрбен by сидит в амстердаме и и у них you to see извините но таких очень грабли достаточно много нас мы делим мы на этом деле забили луиджи не умеет сам запускает джаббы он умеет только выполнять правильной последовательности следить чтобы два отжимания запускались одновременно очень просто все остальное за вас сделает команд об удобно и описание графа на питоне то что ну соответственно что он запускает он запускает либо hive на тези значит хаев обычно старые времена запускался нам определюсь и запуска вот эти вот монструозный большие джипы которые очень долго работали с это в некотором смысле наследник mapreduce вход aux который позволяет выполнять сколько быстрее тут немножко расскажу вторая альтернатива это spark ну про спорте в двух словах сказал это фреймворк для распределенных каких-то вычислений с премом члены джебов он принципиально отличается от но придется идти за тем что он может поднять большой массив данных и после этого оперативки его крутить и дело к нему несколько проходов это нужно прежде всего для алгоритмов машинного обучения которые делают несколько проходов подан к данные могут быть не такие большие но достаточно большой шубами вы можете это сделать на одной машине ему где он пони низко проход и соответственно нет алекс это все более-менее стандартном центре отлавливают ошибки графа на мониторе на что у нас вообще все запустилось сколько времени отработала как все это дело прошло таким образом мы научились выполнять трансформацию вот этих данных лаут мы уже сделать или у нас есть некоторые transform так да вот исход значит итоговая схема того что получилось значит слева у нас стоит самая первая часть это вот и сырые данные которые нам загрузили загрузили их кафку дальше мы взяли сырые данные разложили их и dfs они у нас доступны для исхака но неудобный опять же чосон и по ним можно бегать иску или мы с парком чем угодно но долго следующий степень данные которые мы поняли что они полезны и нужно и мы их разложили в hive в красивом уже формате по нему уже работают production джо бы все хорошо последний деталь на этой схеме про который мне рассказал этот друид про неё тоже был один из первых докладов и сегодня это колоночный сторож который по очень большим данным может отдавать sap секунд ответы по запросу он умеет делать разную придвигаться и благодаря этого мы можем использовать его например в берри или в каких-то запросу когда нам нужно быстро получать ответ я потом чуть-чуть привожу по виду поэт пример итак мы научили загружать данный тебе надо учиться с ними обрабатывать но прежде всего тот и screen это язык который знают абсолютно все его знает аналитики дата-сайентистов разработчики и конечно есть на ходу пион к эш не такой как античный стиль но когда обычно говорят hadoop представляйся такие вот портянки логов мапри deus которой вы пишите какой то запрос он поднимается в течение минуты и потом только начинает считать считает за 3 секунды отдает ответ сейчас изменилась во первых тест позволяет делать запросы гораздо более хитрые хитрые join и передает данные между трассами в памяти поддерживает практически все аналитические функции которую придумать в любой базе данных если чуть не хватает вы можете написать либо на джаве либо питоне свою функцию во вторых хранения данных это уже далеко не логе это могут быть красивые бинарным и проколам таблицы в которых или точно вычислить в огромный таблице 1 столбец не нужно читать все вычитаете вот нужный кусочек поэтому для классических запросов аналитика который не выглядит как select в автомате равно 123 а действительно join там низких больших таблиц это работает замечательно да конечно есть ограничение что действительно маленький запрос будут работать долго ну универсального решения вы не бывает 2 штуку которая происходит и здесь есть это прессом пресса это фейсбук узкой библиотека которая на самом деле так косвенно относится к допуск mustek он очень хорошо работает ходу то есть это искренний движок у которого есть свойств стройный ширли он гораздо более гибкий чем шедевр ходу по позволяет запускать много маленьких запрос 8 вас может одновременно работать 100 пользователь и соответственно тоже поддерживать даже еще больше аналитические функции таким образом вы можете запустить обычный бизнес-аналитиков работа с вашими данными в том числе они смогут копаться в этих сырых данных которых вы еще не понимаете что там сами вы знаете описание но никогда не пытались их использовать дальше более хитро keys to the senses которым нужно не просто не социальный запрос я сделал с ним какую-то магию нам написать и произвольные трансформации как-то данные вот так вот преобразовать чет обучить здесь пример spark значит это морда юпитера ноутбука и питон я покажу как очень быстро буквально несколькими командами можно опробовать большой массив данных произвольной функции первое что мы делаем но мы импортируем нужной нам зависимости запускаем spark говорим что spark будет работать в режиме явных клиента да значит он запускается нашим ходу близком кластере дальше мы пишем некоторых хитрую произвольную функцию но поскольку это пример то хитрый произвольно функций будет выдавать просто название машины на которой мы запустились и дальше эту хитрую фунту мыши и встраиваем в иску или sparks и теперь оно доступно на тульской вот так вот буквально двумя к мы запускаем съемник который по достаточно большой таблицы посчитает количество записей и для каждой записи выполнить нашу функцию вот он выдал ответ там по моему что то типа полтора миллиарда но еще мы видим что он одновременно спускался на 6 машинах если посмотреть что-то получился то тут как раз морда sparkasse но вот мы видим нижней стричь который показывает что он обработал 10 гигабайт данных работал при этом 10 минут но то что он вызывал и туда питанию функцию вкусное для каждого строчки с полутора миллиардов и вот на 6 машинах он для этого сыграли мы при этом написали вот буквально десять строк кода соответственно таким образом мы можем научиться большого обрабатывать и строить какие-то модели давайте пересмотреть например если начала модерации ну мультифрукт это очень важный тема для многих компаний для нас том числе к нам приходят разные нехорошие люди и размещает у нас fake твое объявление чем самым мешают как тем кто у нас ищет объявление на сайте тнк тех новых размещает чем характеризуется эти объявления но они должны быть таких шубы их пользователь смотрел вы можете придумать описание цену место что угодно но фотографии надо откуда-то взять соответственно если фотографии у вас украдены значит объявления скорее всего украни вот этот простой pipeline который позволяет нам искать украденные фотографии что мы делаем у нас есть карта с кето пи где мы записаны все те же самые заменить объявлений наша библиотека laughter актуализирует в фениксе информацию по этим объявлением то есть мы всегда знаем последний статус и тоже сама библиотека помните там говорил что она может a real-time грузите ставки в кафку она выкидывает какие картинки есть в этих объявлениях дальше следующий job тоже работает на spark стриминге который берёт каждую картинку проверять что мы ещё не обшиты вале и считает для нее некоторым бединге некоторые виктора которые характеризуют эту картинку отдает их дальше следующий job опять же нас парк стриминге ищет а где еще были встречались вот такие картинки ищет уже по вот этим посчитаем виктором ну дальше нам находит где это произошло определяет кто же собственную более вероятно украл картинку но и применяет тут это нарушение вот этот нехитрый pipeline где-то на начало года давал нам по моему чуть больше половины найденных вот таких вот машенька сейчас конечно немножко мы доделали инструменты мы люди немножко догадались но тем не менее он встроен сеанс леса очень эффективно следующий пример это как раз она и коммуникации с клиентами это один из pipeline of которые у нас работают значит мы должны взять данные вот левая часть это как раз то что рассказал pipeline по загрузке взять данные выбрать кому что хотим us коммуницировать посчитать для них какие-то фичи и отправить здесь еще мы рекомендуем какие-то объекты которых клиенту нужно посмотреть соответственно мы их скорем тоже это делается на спарке отправляем коммуникацию например почтовую рассылку либо может быть push in mobile и назад собираем информацию в hive все в какой-то следующий момент pipeline повторяется таким образом соответственно мы можем использовать довольно сложные модели машину обучения для того чтобы поскольку на всю ту распределенной считается на всем кластере для того чтобы повышать конверсию мы разные другие наш показатель это наш коммуникаций последний эта борьба с робот это очень актуально для нас тему но наверное если здесь зале есть люди которые занимались это сансом наверное многие из вас просили объявление сайта цон удивительно информации много информация хорошие полезная и роботов может быть от 5-ти до 90 процентов на сайте в разное время здесь я привел пример запросов друиду как раз вот это колонна чно хранилищ который привел которая ищет и печеньки с очень простым правилам кто больше всего сделал запрос в за последний час что у нас написано обратись к колонке и джобс логин джинса сделай по метре по метрике каунт и по айпишник us группе рой вытащи топ 10 тысяч тех у кого больше всего запросов за несколько долей секунды отрабатывает и мы можем написать несколько таких вот ручных правил которые очень топорные но очень действенные а можно написать гораздо более хитрый вещи который нам вытаскивать кучу информации после этого мы делаем по ним поиск аномалий и тоже с помощью уже более читов инструментов отлавливаем этих самых роботов и так теперь мы научились делать модели ну и вообще использовать данные в таком матче режим посмотрим как их использовать реал тайме на сайте я расскажу это на примере рекомендательного сервиса который у нас есть то что уже рассказывалось и взойдете на наше объявление на сайте у нас будет показываться похожий бьюли мы это используем приличная это сервис для внедрения моделей машина обучения на сайт не будущий дата-сайентистов имея разрабатывая большое количество кода мы можем легко используя какие-то шаблоны можем потом написать свои сделать рекомендательный сервис либо и ранжирование либо поиск похожих текстов шаблонов достаточно много уже сейчас написано вот сейчас пример как сделать простейший коми дательный сервис ип чем надо сказать что-то рекомендации сей раз хотим простейший он будет во первых персональные рекомендации выдавать им зависимости от того что поезд выдает во вторых будет как правило лучше чем то что вы купите на рынке в аутсорсинг значит вот это же настройки для шаблона универсале комментах самого часто используют устроишь шаблонов причиною для рекомендации что мы здесь видим мы создаем приложение под названием сам дальше две настройки это соответственно мы используем elastic все еще потом расскажу зачем индекс власти все еще дальше на должно быть таблицы в базе в которой есть два типа событий пользователь посмотрел какой-то предмет пользователь купил в нашем случае пока посмотрел телефон какого-то предмета на этом мы можем учиться понять что пользую было интересно вот такой джейсон мы скармливаем universal рекомендую запускаем просто ваш скрипт он поднимает spark опять же поднимает его на вашем кластере несколько часов считает посчитал модель как мы потом будем использовать личное работать microserver практик туре мы поднимаемся тысячу микро сервис который опять же по росту принимает вот такой вот простой запрос о чем мы хотим здесь мы хотим получить рекомендации для пользователей вася но если информацию пользователю в осени тут у вас сейчас смотрит объекты 123456 тогда мы хотим рекомендаций для этого объекта есть похоже но при этом и еще про васю знаем что вообще-то смотре сейчас жилую недвижимость поэтому нам пожалуйста только квартиры и комнаты но еще мы хотим чтобы те объекты за которые нам деньги заплатили они как-то поднимались наверх поэтому пожалуйста топ 3 premium этот наш премиальные услуги подними наверх всю эту штуку можно разворачивать на низких контейнерах внедрять в прод пожалуйста она работает но конечно этого ганса раз поэтому звучит немножко красиво она сама и надо будет немножко что подпилите напильником шуман работала но поскольку код открытого подпилить их домов насчет какая архитектура этой штуки мы через кафку java скрипта напрямую получаем поведение пользователя что он смотрел какие телефоны смотрел после этого мы за мной нашей библиотеке обрабатываем это дело складываем ваш быть дальше у нас идет тот самый первый джейсон который был там про обучение если помните идет обучение модели ночь только обучение модель это мы для каждого объекта на основании вот того что мы видим по истории пользователя ищем список наиболее похожих объектов и складываем потом такую штуку власти клещ объект списка объектов сложили дальше начинает работать микро сервис который отдает рекомендации когда к нам приходит пользователь мы заходим ваш bass получаем оттуда информацию о том что уже этот пользователь смотрел что клику идем в elastic search и среди вот этих списков которые нам были присвоены каждому объекту ищем наиболее похожий объект дальше применяем на них какие-то наши правила помните мы хотели там только аренду квартиру там же применяем эти правила а даем рекомендации вот вот такая вот очень достаточно простая структур который позволяет действительно сделать хороший комментарий сервис опять же это я рассказал сейчас про рекомендательный сервис но также у нас он уже при dictionary можно делать другие вещи ранжирование классификацию там для этого даже есть готовые шаблоны но всегда вы можете написать свой очень удобно и действительно хорошо работать значит теперь давайте про другие использования от платформ ну прежде всего это бей черт я уже рассказывал что даю им нужны olap кубы когда у нас бизнес пользователь открывает так вот большой отчет есть кучу фильтров он нажимает на эти фильтры ему очень быстро отдаются все эти результат другой стороны нужны подход запрос когда вот только выкатили какую-то новую фичу еще ни к чему это в кубы никакие не попала уже хочет чудо посчитать на запрос к своим данным пожалуйста иногда нужны real-time и даже борды с этим опять же у нас будет справляться друид и вот садятся небольшая схемка как высоту строим у нас есть 2 vip морда не совсем не только веб там есть клиенту то блок табло этот классический клиент люби где устроить все эти отчеты там удобно строить фильтры тренды все что угодно он через парковку шкиль смоллет михайловские таблицы и позволяет собственно уже пап редактировано таблицам выдавать или буду любой отчет чем проблему проблема в том что когда какое-то время spark не работал то есть учетом кто не смотрел таблицы выгружается из памяти и следующий раз когда пользуется опять табло туда приходит опять таблицы надо поднимать на это уходит никто не соответственно 2 может супер-сет это тоже разработкой бемби она менее классный для бизнес-аналитик но тоже красивые дэш барды и кроме того самой большой плюс что на полезно к друидам то есть мы можем прямо вот в реал тайме считать что угодно у нас только только это событие пришли мы сразу их получаем друид вторая вещь это опять же то что говорил про love друид пальто реагирует данные соответственно любые изменения фильтров моментально отражается в нашем отчете вами нужно чужды вот красными стрелочками здесь написано то что у нас еще не работает но на самом ли уже реализованы и работать можно все это единый стек и тот же друид он хранит может хранить свои данные поможет быстрее хранить может неких локальных машинах может хранить в х dfs соответственно hive можно повязать напрямую к друиду hive можно привязать напрямую к табло и тогда мы получим идеальную составляющей табло уходит в хай хай хоть друид мы получаем доступ к большому объёму данных мы можем спуститься на минимальных деталей и одновременно мы можем применять фильтры и они быстро применяются это сейчас уже реализовано для hive 2 это действительно работать но у нас пока не дошли руки это нора следующая доработка в этой системе которую мы будем делать порты стиль но пока еще не модель есть еще альтернативы в принципе друиду это колин это такое тоже olap на ходу пи он немножко работают по-другому у них как раз он заточен под бей по идее должен быть у них есть интеграция с табло данные он сам уголь food at high овская табличка построй по ней куб такие-то измерения у прямо в юо и такие-то метрики он это делает и взять пульт расчитанный данный кладет habeis чем получается проблем ну во-первых он действительно кладет данные fps в ходу игры которые используют другие вещи ах bass у нас уже используются на сайте туда ходит вообще-то вот там за рекомендациями с фронта ходит ну и соответственно лишняя нагрузка на habeis которому и так в пиковые часы не всегда здорово живешь дальше это интеграция с тобой якобы она есть на самом деле мы посмотрим на запрос который интегрирует который генерирует табло там кода генерацию таких запросов где поставленные всевозможные китае значения в р1 равно 1 еще что то там результате колин не в состоянии понять чего чего от него хотят начинает считать пересчитывать вместо чтобы взять просто один большой агрегат пересчитывать по кучу мелких данным их суммировать на лету ну и рано или поздно загибается потому что там есть таймаутов абедин ну и последнее это плохой аппетит если мы хотим по каким-то большим данным на perl агам что-то считать мы наверное хотим блоги не хранить в кубе за года а там очень сложно сделать так чтоб старые данные удалялись практически невозможно вообще друиды где мы просчитаем одну галочку говорим что все что дальше месяце все удаленно в к нам это уже не интересно про прошлое соответственно эта штука с которой мы довольно много провели времени пытаясь ее настроить побегали на граблях так и не получилось поэтому все же но сейчас правду переписывают колин вторую версию возможного станет когда то лучше пока я всё-таки рекомендую остановиться на друиде хави потому что вот этот стопудовый работать если вы слушали первый доклад сегодня там вообще рассказывали про то что в друиде какие-то там совсем космические объемы данных можно хранить я брал этому действительно быстро последние то что я рассказывал применение это как раз информации которым можем давать пульт это может быть простые вещи как статистика вот у нас из того что тут придушу доклады был редис как real-time хранилища и верьте к как соответственно к его offline хранилищем от страха hive и кассандра то есть мы инкрементируем счетчики кассандры а пересчитываем все в ходу вот она очень хорошо вместе живем это пример когда мы можем предложить пользователям уникальные данные куда например граф совместных просмотров жилых комплексов на севере москвы как бы мог ли вот например вы не знаю работаете в жилом комплексе петр первый хотите знать кто ваш конкурент как можно сделать но можно погуглить какие жилые комплексы есть еще можно поспрашивать клиентов можно провести issues or парус организовать а у нас информация доступна саранск вот здесь и пружина размер это количество вообще просмотров ребра этого графа совместный просмотр вот мы сразу видим кто конкуренты у этого комплекса пётр первый и при этом есть какие то не очевидны зависимым что чтобы клиентам green park live ботанический сервера ниши находится рядом но при этом green park севера фактически совместных просмотров вместе не имеет прелестно конкурентами их может наверное не считать и так резюмируя все это дело о том какая получилась архитектуры как все это дело работать значит слева эта часть которая нам данные загружаются у нас есть кафка единая шины в котором мы получаем все сообщения все грузится через нее и тот же сон и которые имеют понятное описание при этом на совершенно не волнует мэр если в джейсона добавились новые данные добавились хорошо если они нам когда-то понадобится мы их разложим а так ну окей просто в описании добавили мы просто их складируем дальше справа верхняя часть это то что мы обрабатываем вэба чужим мы их перекладываем в hive анализируем анализировать помощью х его с помощью пресс то выводим в табло вводим super set the schedule или работает это все через луиджи чтобы у нас последовательное выполнялись правильные джаббы также там стоит друид друид который у нас выполняет сразу несколько функций это во первых во вторых вот один из примеров это как раз поиску роботов когда нужно быстро иметь запрос из и какой-то агрегации ну то что по одной конкретной операции вы не можете понять робот это нижняя часть это real-time соответственно кассандра феникс используется в разных сервис ты рассказывал кассандра эта статистика феникс например это то что мы используем для модерации ну и великими дательный сервису prediction а ее который тоже ходит с habeis и получает оттуда списке объектов тоже смотрю под это дальше отдается напрямую на сайт сбоку там еще такая стрелочка к видеокартам где карта у нас машина сидя карту нас не стоят кластере ходу по хотя это тоже возможно этом там разводится через ресурс менеджер но чуть проще это поставить отдельный настраивать через api но если будет интересно потом почему-то скажу почему так вот в общем вот такой вот инфраструктуру получается она достаточно цельная то есть это не набор сервисов когда вот здесь стоит одно здесь то и другое здесь стоит 3 выгоняйте данные между ними а все действительно лежит в ходе эфесе еще один мухаммад такие выводы из это верх чудил ну во первых не верить к нам расскажешь вход туда к монструозная сложная система в которой не production трейдинга не работает она решать большинство ваших проблем действительно вот и бачили алтаем и хранение данных дешево быстро хорошо вторая вещь что говоришь невозможно используется одновременно один и тот же класс table аналитики и для продаж возможно мы используем с помощью ресурс менеджер все the dice ep хорошо разводе с ума с одновременно работает аж bass в котором лежат боевые данные куда мы ходим для рекомендательный сервис одновременно там же работают аналитический запрос никаких проблем ну и последнее это вот такие презентации очень часто бывают что бей на ходу и это очень сложно невозможно это презентация джетро это очередная версия алла полях от для больших домах не верьте возможно да мы не можем делать какие-то классические скрины и запросы типа select по одной записи надо будет наверно чему-то научиться что-то переписать но вылью котором это то получим возможность провалиться как угодно возможно сделать от фокин о гигантской поэтому пробуйте я думаю вас получится спасибо здравствуйте вот у вас появился табло да вот мне вот кажется во-первых немножко выбивается из общего open source тренда да только прекрасный инструмент красивые репорты бизнес-пользователей его очень любят и тут же вы говорите про olap серверов а почему не использовать великолепные memory и возможностей табло то есть там прекрасные экстракты одни причем и как бы сводится на диск то есть там там очень хорошо с этим вот почему нет почему идет разговор о future салаты ну во первых можно использовать используя кисть и местами используются для некоторых отчетов действительно используется дата экстракты то есть мы заходим в хайфу забираем кусок данных и вот этот отчет на нем работать но все же таблоид а один сервер физический к почему но там опять таки он великолепный класть и рисуется но хорошо на 10 великолепным кристаллизуется на это надо тратить отдельные ресурсы поднимать под это отдельные сервера да то есть это не будет то же самое что вот у нас через ресурс менеджер одновременно разводится что здесь могут быть запросы которые используются там каким-то do the sun тестом который считает продакшеном которую что-то пересчитывает и одновременно здесь же работает olap такого быть уже не может здесь все на одном соответственно почему вообще табло это историческая штука посуда это у нас был мой сильный olap ему спилила попаду но кажется что ничего не мешает на вре мен на его конвертик друиду и для каких-то маленьких источников опять же выгружать данные на этот сервер и использовать autoblog понятно спасибо и вот я вот не очень как так у меня вот вопрос про граф вылетела вот где вот в этот графу держитесь я психопат взял бы просто его бы удалил бы в него 4j и он богатом бы жил бы сам по себе но он не 4g он выбивается из hadoop стек а вот у вас как он живет граф у нас именно как графом не хранится то есть он считается только в тот момент когда он нужно то есть графом и базам и никакой не используем по долго считается нет недолго у нас есть но как же как этот граф посчитать нам нужно просто посчитать какие объекты хранились вместе у нас вот есть табличка которая используется в том числе для рекомендация в котором мы знаем какой пользователь смотрел какой объект загружаем joining собираем граф не так много у него спасибо спасибо за доклад очень интересный вопрос такое как вы пришли друиду достаточно нестандартное решение друиду пришли следующим образом вот собственно 1 ну мы решали 1 момент 2 задачу и почему другие это значит вопросы на шубе а потому что мы не хотели уже дальше масштабировать olap не хотели как раз заниматься всякими коммерческими штуками типа тентом табло хотели все впихнуть в единую систему во вторых мы решали проблему борьбы с роботами потому что когда мы это делаем какими-то нам нужно поднимать очень большой объем данных чтобы понять является ли этот конкретный айпишник чем-то я цель понял и даже не к тому а какие были альтернативы то есть рядом стоящей конкуренты но есть есть нами клик house и стоящие конкурентов ну наверное в тот момент когда мы начинали и они даже не помню грузил клик house или нет ну кликал с плохо интегрируется со всей этой штукой мы у него если честно даже не пробовали вот пробовали колин которую тоже металле алтаем я уже объяснил почему это дело не залетело noise друидом все полетело довольно быстро и хорошо все замечательно работать просто такой вопрос подскажите пожалуйста характеристики нагрузки то есть сколько в пике пользователи идут в табло например хочется понять и насколько тяжелая там запроса и еще я правильно понимаю что вы табло используйте в режиме когда на сервере собственно каши руются данные то есть не директ discovery нет спасибо значит во первых директ discovery у нас когда вы короче the blocks парку вы можете написать там чтобы spark закрышевал таблицу соответственно таблицы поднимается на память и на ходу кластере есть q или работают там работает очень быстро потом когда-то была отключается через какое-то время спарки из каши таблицу убирают ресурсу освобождаются их занимают другие другие какие-то job он их а тут да мы через это проходили единственное все потом упирается в количество одновременных пользователей которые пришли в обе а систему то есть вот сколько у вас в пике пользователей 100 блок у нас немного там 34 пользователи в пекин понял спасибо добрый вечер я тут спасибо большое за доклад у меня некоторое количество вопросов там вот был слайд про взаимодействие там именно вот в рамках машинного обучения почему модели хранятся в ластики значит почему вы ластики как это хранится у нас есть объект есть набор объектов которые на него похоже значит есть набор объектов которые смотрел пользу вот мы считаем по всем вот этим набором объектов похоже у нас есть одна вершинка есть соответственно то что из него выходит либо вот по вот этому множеству смежных вершин мы ищем похожий и вот эти вершинки отмечаем мы пересечение множеств делали это elastic умеет делать из коробки хорошо и быстро ну то есть это не модель машинного обучения вот в таком виде как допустим нет машины мучение так да все правильно машинное обучение это как построить вот эти похожий объект там вот если я еще даже не году страх раньше результаты результаты да поскольку там его фактически хранятся результаты и по ним быстрый поиск по этим результатам то есть когда мы говорим про переобучение модели мы говорим про актуализацию данных они про изменения модели на основе которой происходит предсказания там рекомендация да можно сказать и так то есть у нас пересчитывается на спарке вот этот список похожих объектов понятно тут вопрос сразу отпала и производительность prediction а ее расскажите пожалуйста чуть-чуть хотя бы prediction ее как правило ничего пехом микро сервисный поэтому мы можем сколько угодно этих не красе русов развернуть он упирается как правило в производительность habeis elastico то есть соответственно с какой скоростью может отдавать данные хабы саму сансом личной легко масштабировать у нас кажется это 3 или 4 контейнера с самим прилетишь наем ну и соответственно в пике не боюсь наврать не помню точно сколько пират в частности нескажу потом если есть если за эти вопросы вам потом отвечу понятным спасибо добрый день у меня такой первый вопрос вот утилитка ваша секу laughter как-то так она на класс не работает да она работает на классы и управляются чем но и в ходу есть ресурс менеджер ярл я полимерную когда по делу второй раз про у вас есть и через и кассандра окажется это такие похоже решающие система задачи то есть значит исторически сложилось что есть кассандра и есть habeis . сандер было изначально на ней работают в основной сайт habeis потому что нам на порядок удобнее работать с теми данными которые у нас есть уже hadoop и мы можем генератор наш файл положить его сразу в как кажется сказали что у вас сайт работать на жизнь у нас я теперь да теперь у нас уже части и зажгли за используется для рекомендации счет лишь это основной сайт работает наказаны и последний вопрос какой размер команда вас а сколько времени потребовалось разработку этой архитектура сейчас у нас уже команда по моему человек семь в основном все то что я сейчас рассказал было сделано меньше чем за год начиналось наверно из 2 человека под конец было читы здравствуйте спасибо за доклад скажите просто сколько у вас вообще железо падают и все то есть какое количество вот это вот у меня есть заготовка соответственно ходу это два мастера 8 рабочих not с этой с мидла мастера обязательно для heavy любишь мусю нас одна машина вылетает все работает дальше замечательно соответственно отдельные машины с видеокартами отдельные ластика севочка под которым там разными штук ну и сервер для собственно каких-то экспериментов вот все все наши администрирует это сколько минут именно системный администратор а то есть не разработчика имена обмена ну примерно половину или четверть системный администратор понятно спасибо здравствуйте а вот такой вопрос по поводу как раз совмещение нагрузки аналитическая real-time накласть и вот не сталкивались с проблемами что их bass там ну и нагрузку который приходит из письма придется там из ярно по его сильный комплектует собственно над это модах на вот на worker ах да пасибо это очень актуально для нас проблема действительно по иоанну достаточно сильно конфликтует для dfs а можно настраивать тип хранения данных это может быть жесткие диски обычные могут быть ssd может быть in memory слой соответственно сейчас мы в процессе переноса хэбэй сон на ssd и тогда проблему с его само собой от вальс rss я здесь очень интересный доклад спасибо тоже на самом деле возник вопрос связанный с нагрузкой вот вы сказали то что продакшен кластер аналитический кластер там у вас спаркой сказку ель плюс как я так понимаю в юпитере там дата-сайентистов на питоне что этапе тонет вот первый вопрос можно ли чуть чуть более детально раскрыть настройки ярно используете в динамический пула статические мастер как-то порезали или или этого не делали и второй вопрос как вы боретесь зависшими приложениями потому что зачастую бывают там написали код открыли spark контекст сделали какую-то выборку в панда си построили какую-то статистическую обработку spark контекста остался висеть на кластере аналитик 2 открыл рядом еще один блокнот еще spore контекст и пол кластера съеден а как вот вы с этим боретесь спасибо да пасе барыш хорошо вопрос как мы прежде всего самое наверное чувствительная к тому что надо оберегать на кластере это стриминговый джо бы чем они хороши тем что они занимают вполне понятно и количество ресурсов здесь у нас есть отдельная вырезанная очередь в которой могут лазить только стриминговый джо бы который вот занимается real-time а перегрузки данных их не съедают хайфский запросы те самые аналитики любителям и все работает с 1 замечать теперь дальше что делать с заряжающим джебами есть кстати очень неплохая статья вот недавно на хабре выходила у rambler и на эту тему у спарка можно настроить такую штуку что во первых мы всегда используем динамит ресурсы локэйшн это значит что когда вы запускаете jopu она сначала запускается с минимальным ресурсам одним контейнером потом когда что-то нужно он занимает больше иисус потом соответственно до ресурс ненужным контейнер из опять съедаются единственной проблемой почему могут происходить зависит джо бы это если кто-то поднял в память что-то и там оставил но и на этот случай у спарки есть замечательная настройка если но до нее если в к экзекутору не приходило никаких задачи определенное время даже есть у него в память что-то вынесет убить you по-моему начиная с 15 ну у нас на 161 она точно уже работал всем спасибо"
}