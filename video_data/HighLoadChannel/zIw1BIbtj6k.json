{
  "video_id": "zIw1BIbtj6k",
  "channel": "HighLoadChannel",
  "title": "Данные как продукт: зачем покрывать DWH метриками и что можно из этого получить / Евгений Ермаков",
  "views": 2996,
  "duration": 2873,
  "published": "2021-10-04T02:14:12-07:00",
  "text": "меня зовут евгений ермаков как написано слайде вы можете мне знать по рассказам на конференциях охраняющих данных еще и люблю побеседовать о нашем детальном слове он такой сложного ты как смеси якорной модели do the world а чем вы можете меня знать полюбив же ленточкам но сейчас жарковато поэтому by жилетки может меня не знать тоже про хорошо поэтому приятно познакомиться я сейчас руковожу хранилищем данных индекс г и расскажу вам зачем мы покрыли наше хранилище данных метриками и что мы из этого получили я не буду проводить эксперимент как сеть мобилу с утра насчет индекс go я уверен что у вас у всех он установлен всех я сюда добрался точно индекс дом не много интересных чисел индекс гоф части такси во всех случаев 700 тысяч водителей активных 18 ран присутствие на самом деле сейчас стран больше сейчас она остро норвегию я думаю и тысячи городов из них 300 крупных но сейчас я наверное скажу какую-то такую банальщину современном мире но такой бурный рост а вот этот рост он свершился по моему лет за 67 такой бурный рост он невозможен без анализа данных без принять решение на базе данных data древом культура в яндекс go это не миф действительно так и очень много решений принимаются исключительно базируясь на данных но и по суду моему личному убеждению хороший аналитика данных невозможно без хорошего хранилища дано а наше хранилище данных это больше 500 уникальных пользователей месяц почти тысяча отчетов 4 крупного бизнес юнита и почти три петабайт накопленной информации по всему и вот где-то полтора года назад мы взяли и покрыли наших хранилище данных вот такие метриками да не сдашь к кухне мы еще вернемся смотрим на такие графики делаем какие-то выводы и в общем-то весь мой доклад посвящен ответы на следующие вопросы зачем вообще хранилище данных метрики всех случае как мы ответили на вопрос как мы это реализовали что получили и очень стоил летом всего того маленький спойлер раз я тут выступает он точно стоило значке выступал falcon и начну я с зачем 2-х метрики и здесь мне придется немножко рассказать как устроен у нас хранящий данных института меня слушал это будет как тавтология повторению не уходите дальше будет интересно а для всех остальных я продолжаю вот наша платформа данных тендер сгон это слайд из выступления владимирского на руководитель разработки платформы очень крутые выступления очень советую посмотреть он рассказывать про платформу прям в два раза круче чем я нажимаю в 3 я не знаю какой у вас вопрос возникает когда смотришься на схему но лично у меня возникает такое почему так сложно на самом деле не сложно я вам сейчас за 5 слайдов можно 10 скажу что яд на самом деле срочно легко все это от архитектуры слоев данных и от действий которые бы с данными совершаем три хранилище данных мы собираем стандартизируем сохраняем и предоставляем для анализа все просто прозрачно именно так устроено наше слои первый слой роу здесь мы захватываем птицу информации источника и складываем прям как есть затем мы и очищаем калибруем стандартизируем нормализуем это наши операционные данные с источник на операционный потому что здесь мы не храним историю для истории у нас есть детальный слой если мы накапливаем данные сущность в доменной модели и смешиваем с собой источники из чего потом делаем витрины данных засолению для анализа и храним отчётные среза никаких нить отчетов но все просто слева направо но здесь логичный вопрос а это все виртуальные свои данные как-то ложится на физику на систему как слои связаны с системами вначале у нас есть сервис забора изменений с источников сертификации на на ночь внутренняя разработка забирает инкременты не snapshots источников и преобразуют их устойчивы к изменениям формат дальше мы это всё складываю в нашем озере данных в и те и те думаю все знакомы такой ходок на максималках да простят меня разработчики это не смог все складируем в пол структурированных данных красного придешь и всевозможные аналоги нашим утренника система ходу дальше у нас есть аналитическое хранилище на гренками 10 коп запросы большое количество join мало время откликов и в итоге все это визуализируется в нашей учетной часть это губы данных и отчеты дошло до всевозможных вот соответственно четыре основных блока источники do the lake да и твинхаус и reporting и фактически классическое хранилища при максимальная классика современной всех случайно мой вкус если мы немножко системы транспонируем и так размажем свои к этим системам то увидим примерно такую картинку не во всех системах есть с лаем есть отдельно очередь оттуда мы складываем данные нашего zero данных и там фактически ровный слой этот vds слой в какой-то частью редуцирует sun green план и ногами по меже хранятся сердце хранилищ детальный слой витрина в основном создаются на гринд вами но при этом я все три ног создаваться найти если не сложный крупный и так далее если мы эту картинку еще раз перерисуем на относительно систем то и получим нашу платформу данных как я уже проговаривал нас есть разные системы здесь и наши внутренние типа очереди репликации есть и такие внутренние яндекс и на знаменитый на рынке то видите есть open source видео реклама есть проприетарной систему виде universe адских кубов и табло еще один вопрос который может возникнуть да мы смотрим на этот слайд как-то развивать если вы были утром на докладе федора лаврентьева то вы примерно знаете ответ на этот вопрос как мы два года и фактами хранилище как подошли к задачам платформы дано на самом деле их можно разделить на два блока эта инфраструктурная задачи всевозможные внедрение новых инструментов повышение качества работы с данными и продуктовой задачи они такие более 2-х шины построения витрин добавление новых источников данных оптимизации тель процессов развития на мена на самом деле такое разделение она достаточно естественно и просто потому что сами задача разные для инфраструктуры важно сделать качественно осмысленно и максимально масштабно при этом у них долгосрочные проекты и это оправданно при этом для продуктов двух важных задач и скорость внедрения инициативе достаточно высокая и как бы мне не было больно это произносить быстро результат в точке 2 важнее качество важно предоставить какой-то продукт пользовать чем закопаться сделать его качественно мало никому не нужен здесь я ввел понятие нами на развитие домена сейчас немножко присутствует такое у нас данное сгруппированы в домен и по такой предметной области все объекты данных это домена за несколько доменов стучат команда и домена могут быть разных видов мы выделили таких 3 у нас есть домены-источники домена ядра ibiza знамена домены-источники связаны с источником данных и структура фактически подобрана под этот источник ядро связано с крупной областью бизнеса с нашим пониманием этой крупной области бизнеса и структура подобно под минимизацию изменений хранилище данных и от как раз смесь я кредо таволга и бизнес домена здесь полная связь потребителями данных этот комплект аналитические задачи и структура подогнан под удобства использования этих данных и вот если мы возьмем наши домены источника ядра и бизнес и наложим их на слои то выйдет примерно вот такая картинка на смогу доменов-источников они изолированы не связанными с собой на их базе строится для меня ядра наш детальный слой и на базе эти доменах игра строится уже бизнес домена при этом корр доменах могут быть тоже витрины каким-то крупной ампир витрину по поездкам для твоих им понятно что это должно быть что-то в entry плюс мы не перемешиваем меж собой источники всей с точки смешиваются именно в центре из можно выдохнуть я примерно рассказал все про наше хранилище что нужно знать и понимать хотим и дальше буду вести речь и перейду к проблематике чем проблема-то была в общем то проблема в этом как управлять беспорядкам и без то скобочках специально то что на самом деле все что и до этого рассказывал такой строгий системный порядок у нас есть слои данных у нас есть домен и все прекрасно все организовано на самом деле жизнь это не так жизнь у нас больше 200 доменов данных и это три с половиной тысячи объектов хранилища натаска еще больше потому что не сказки не связаны с объектами хранилище у нас что-то окружающую и так далее у нас 200 комета в день и 300с между полами квестов в месяц при этом лично цикла у нас быстрый раз в день может быть два релиза в день к нам пули квеста могут писать не только разработчики 2а но и аналитики мы работаем яндексе все знают про эти тысячи собеседование на код это все правда но приятная сторона этого что всем умею писать код даже меньше может написать код замерз tool request и что-то изменить в данных пройдя там всевозможные просмотры отсюда проблема которую мы столкнулись полтора года назад на самом деле можно достаточно банально но тем ни менее развитием такого крупного хранилища сложно управлять хочется концентрироваться на максимально важных вещах хочется делать именно то что нужно пользователям а с таким количеством объектов это сложно на самом деле я думаю клевый слушатель понял на что похоже наша организация я думаю все видит статью это за маг дыхание я очень надеюсь что правильно произнес время достаточно сложно было есть хороший перевод статьи на хабре наша организация например на похоже на дейтемир если вот так и дорисовать наши блоки внутри замены данных как-то связаны между собой внизу инфраструктурная команда которая повышает качество работы с данными и есть продуктовый команды готовы команды вырабатывают стандарты работы с данными и они же отвечают за какие-то важные домены за домен и могут отвечать и другие команды аналитически команды бэг-энда и так далее полный dj smash чистом виде а что основной в дайте меж но основное наверное с моей точки зрения с этим можно поспорить на тем не менее важная часть нет меж данный продукт это прям постулат данный это продукт те домена данных которые внизу ются не можно пользоваться ног именно как продуктом и если мы рассмотрим данные к продукту они должны обладать определенными свойствами важным свойством которым можем замерить измерить и как-то оцифровать или соответственно вот оно решение нашей проблемы если мы относимся данным как продуктов да давайте покроем работает аллаха метриками под полным метриками тогда витрины измерения любой набор данных это тот продукт который мы предоставляем пользователям аналитики на центристы 0 специалисты менеджеры это пользователь нашего продукта поток должен быть удобно в использовании легким для обнаружения должен быть качественным но должно быть понятно описание семантики и так далее все вот эти отважные для на свойства вопрос покроем метриками будем смотреть что происходит с нашими данными при этом раз данный этап андерсон какая-то продуктовый команда которая продукта развивает здесь инженер данных по классике становится разработчикам продукта данный продукт а системного аналитика такую классическую для хранилище данных профессию добавляя туда ответственность менеджер продукта или владельцы данных моего у себя переименовали в партнеры по дана вот такая у нас готовая команда и ее работу будем оценивать через метрики посмотреть какие продуктовые метрики не повышают как быстро и какого результата достигают в общем то все понятно есть проблема есть решение дело за малым все это реализовать здесь мы шли от минимизации своих затрат bros получить результат максимально быстро никаких внедрений здесь можно подискутировать на тему того что и внедрить какой-нибудь внешней инструмент или внедрить нам инструмент который покрывает часть наших задач для этой discovery систем нет мы не хотели чего внедрять мы хотели сделать это минимальными затратами здесь нам в голову пришла достаточно элегантно идея на мой взгляд субъективный но мне она нравится использовать данная система 2-х целом 2-х очень просто 2-х для 2-х почему бы и нет в общем то 2-х генерит абсолют такие же данные как и любые другие системы источники нас есть навигационная информация тема про что происходит всевозможные логе обращения колин плану котел то блок и массу многие ошибок по объектам информации обоснования на на вас есть такая статической информации типа срезав с чем от происходит то что происходит метаданные систем данные системы учета пользователями к данные из нашей платформы и так далее идея хорошая и мы реализовали место 2а вот он на картинке по нашим доменом видно что здесь несколько доменов-источников такой большой core домен и несколько бизнесов доменов понятно что они не бизнесовые но в наш этими ноги вполне себе новый домен если мы методы ваха рассмотрим как бизнес может вывели сложновато но на самом деле вы реализовали мы все достаточно просто все благодаря такой модульной системе нашего детального слоя смеси до того это якорь и которым называем гибридным отойдем значит мы сгорим flama осталось вирт вами есть логе использование метаданные объектов логе использованию мы снимаем постоянно метаданные объектов рассудке теряем безусловно ти метаданные которые те объект которые создались внутри суету к исчезли но они нам целом не очень интересны для всего этого целиком что мы отсюда можем получить можем получить запрос на рекламу мы партию что это был запрос каким объектам и из метаданных получаем по ли объект плюс есть персоны у нас все системы провязаны через единой steam авторизации и аутентификации мы получаем логина систем там где логин и то можно прикрутить и оргструктура получить полную информацию по профилю все ту же структуру получили департамент так потихоньку нанизываем берем ведь там обсудить то же самое и слоги использования с метаданные объектов кладем рядом тот хороший может быть вопрос почему не в одно и то же на самом деле они сильно разные ну то есть запрос в и те запросы грантами они достаточно разные то же самое с метаданными объектов из полями тут вопрос такой генерализации или расщепление сущности черепа это пойти по вот этому пути потому что попроще но и плюс не думаю что у нас частенько было добавляться новую систему поэтому можно оставить их раздельно что у нас еще есть мы красовский кубы приторная система здесь мы поляне смотрим просто есть кубы и использование кубов и на самом деле уже из этой информации можно получить какой-то быстро результат эта витрина по размеру данных в разных системах по слоям и по витрина по потреблению ресурсов никакие ресурс мы тратим нам немножко не хватает да ведь вины по использованию потому что нас есть табло табло ходят не только экстрактами мой лайв канале нам поэтому мы их тоже загружаем у нас есть в руки использованию буков и в целом обладая всей этой информации можем уже прийти к витрине по использованию кто когда какие объекты использовал и также кто когда какие отчеты используем оба из каких объектов напоследок я оставил самое интересное то наша платформа масочку той платформа еще растут по рекламирую к смотрите доклад про эту платформу как она создавалась оттуда мы можем получить метаданные наших объектов и фактически у нас получается нет общих нами the field который провязывать между собой вообще все объекты которые у нас есть такой бы это объекты найти объекты в blind вами тоже самое с полями если получаем наши домены то виртуальное понимание как данный скопированы между собой хоть он и мы можем построить идти ну по метаданным объектов но эта маловата для полного место 2-х не хватается них to suck нагружаем сюда логе запусков метаданные таз и в колоде проверок и получаем полную картину у нас есть тоски лог запуска to suck это все возможные запросы наш не наши некоторые тоски у нас проверочные результаты проверок и из этого мы можем получить наш мир 2-х человек рено по танцев и витрину по результатам проверок реализовав такое что мы получили на самом деле мы получили достаточно ценные мы получили возможность делать аналитику по работе развитию само хранилище дано и первым делом мы начали смотреть о чем пользоваться хранилище сделали вот такой вот отчет профиль объекта что здесь можно увидеть здесь можно увидеть такую общую информацию и она лежит какому домену относятся какие-то наши флаги и общее использование сколько пользователей когда использовать чаще всего можно посмотреть разбивку по департаменту и по пользователям них здесь немножко заборе умно знаете они там есть вот именно пользователей ну и такая информация типа полей которые можно ли документации посмотреть но здесь вам тоже вполне удобно посмотрели на один объект неплохо посмотреть целиком на все вот наш дашборде по использованию вообще всех объектов такой helicopter view вычеркнул термину рому бунина это наш гуру визуализации можете погуглить и он очень много интересного пишут что здесь можно увидеть объекты кто чем пользуется развития по слоям можно увидеть департаменты кто чем пользуется соответственно все это фильтруется по клику на объект по клику на департамент то пользователей топ доменов какая-то общая информация сколько у нас объектов использовали usa что у доля между грим по мы идем и доля по нашим слоям на самом деле здесь у такой информации есть и более не знаю не визуальное на практическое применение . cipro изменения у нас более 500 пользователей в месяц уникальных три с половиной тысячи объектов если мы хоть немножко что-то потрогаем и не уверуем кого-то понятно что все начну сразу быть хорошим нет скорее в плохом смысле этого слова при этом мы можем зная кто чем пользовался интеллектуально уведомлять об изменениях широковещательные изменения по объектам на 500 человек сто процентов не работают их просто читают индивидуальное читают и вот здесь пример письма которые мы рассылаем где-то какой-то объект правим дата и это приходит всем пользователям объект не просто некоторые даже аналитики узнают что они пользуются этим объектам и не знают что такое не стояло они забыли более интересно как оценить работу продуктовой команды когда мы поставили перед собой этот вопрос мы стали думать о что нам вообще важно на самом деле нам важно что результаты нашей работы пользуются за нашей работы это объект mi-2a поэтому мы посчитали уникальные пары пользователи использованный объект за каждый день убрали оттуда те объекты которые пользуются ровно 1 пользователю ну пусть пользуется то песочницы и так далее но при этом те песочнице которые которым пользуются все аналитиками тут остаются и вот на этих результирующих данных мы посчитали разные метки но ключевая соотношение обращений к про ты не плод объектом project это те объекты 2-х которые мы сделали не провод объекты это всевозможные песочнице которые можно сделать либо венности все меня программируют очень много умных людей каждый может туда собрать и положите в песочницу потом показать другу и вот так и возникают теневой 2-х также мы меряем соотношение депре кейт дики кейт от объекта в какие-то объекты у нас устаревают и соответственно не хотел чтобы пользовались технические объекты против всех технический объект это роуз ловим мы не рекомендуем туда обращаться все остальные слои пожалуйста можно и самое главное наверное для нас эта система реп это наши презентационный свой бизнес домена нам бы хотелось чтобы туда ходили чаще всего как вы думаете сколько мы получили провод не провод когда посчитали полтора года назад вопрос доля доля 2820 на восемь двадцать двадцать двадцать провод 80 близко но нет было меньше пяти процентов просто я когда увидел эту цифру тут защемило сердечко защемило пять процентов 2-х целая 2-х работа кресту нет еще объект это было поменьше но все равно лан на самом деле в общем то полтора два года назад начался процесс рефакторинга всего этого хранилище мы начали считать вот такие вот метрики сейчас 54 процента на самом деле какое важный вывод мы сделали мы увидели что на объектами 2-х пользовать всего 5 процентов 5 процентов это мало не пять процентов людей имели пять процентов запросов идет к объектам пвх и это плохо каким бы классным не был 2-х каким качеством не были объектом все обвешаны дейта кволити все сверяется просто нашим объектам не пользуются здесь мы поступились качеством и поставили все количество метрики почему их называю количество теперь команд потому что они нацелены на количество нашими данными должны пользоваться если можно где-то немножко пренебречь и не повесить проверку никому в этом не скажем потом доделаем главный принести результаты чтобы аналитики начали этим пользоваться как видите за получается таро году мы перешагнули запись от процентов рассказывай про этот дошик потом перейду дальше а здесь можно увидеть доли по слоям видно что сэндбокс падает остальные слои потихоньку нарастают основные наш страдавшим тебя и сколько ходят в продакшн если остальные метрики тоже нас важны на самом деле отсоединяю реп очень важны 20 процентов запросов идет туда это очень плохо значит что все пользуются нашими сиднем а было вон там семь процентов когда-то был еще меньше можем поставить все это в разбивке по командам и там фильтровать по объектам но нельзя вечно заниматься количество отказов переходить качеству здесь кажется сейчас мы этот рубеж перешагнули и мы решили оценить качество домен если мы можем вести метрики которая на самом деле косвенно оценивает качество доменов мы их разбили на три блока то архитектура здесь больше соблюдения мин конвенсион такая интероперабельности данных что внутри все одинаково понимают как пользоваться данным качество данных это отсутствие падает на самом деле блокер есть где-то из под этого не знаю расстреляют всех с меня 1 ночь на скорость поставки данных качество коммент ации покрытия но и качество расчетов понятно что я тут широко написал optima теперь процесс на самом деле не посчитали это сложно не знаем как правильно посчитать мы считаем там сколько потратиться мы можем посчитать там объем данных но вот прям оптимальность intel процесса пометьте оптимально нефти они пока не можем все но итоговая оценка качества домена это здешняя сумму критериев то по-хорошему должен быть слайд с доменными данных мы не могу показать потому что домена данных эдак объективно сложная штука плюс вы увидите насколько они вас не качественно но могу ответить на вопрос сколько у нас меня на длина комментарий мы посчитали медианная длина комментарии в нашем доках сколько я напомнить делит пополам да я увижу от коллеги он показывает ok но это не окей это 0 медиана дина комментария 0 вы просто не писали комментарии сейчас уже это не так плохо но когда-то это было 0 над этим работаем ладно если более техническое применение вообще есть но то есть у нас есть такие движки как размер объекта в 2-х ест можно увидеть по разным уровнем по слоям прирост так так принципе можно точно находить такие не оптимальные кусочки когда вроде данных немного весь это непорядочно потребление ресурсов действие то же самое леске вывел средние время запуска тоски также по слоям по доменам здесь можно посмотреть титан найти сложные участки ладно на самом деле вот диска интересней можно ли применить знания для оптимизации всего 2 х в целом да можно но для того чтобы сюда погрузиться во всех существующих которые хочу показать мне придется немножко порассказывать на наш детальный слой да этот слайд он из от личного доклада николай граббе щековые ермакова евгения это я они рассказывали про детальный слой он ключевое для хранилище данных вот есть всевозможные по ходу проектированию от никакого подходы и какой подход тоже подход вполне себе подход просто его нет звезда снежинка до того это якорь и когда в яндекс глава решили создать детальный слой соли выбирать между do the world и маяками там было страшнейшая дилема двух стульев в итоге решили не убрать ни один на сделать свой сделали свою свой подход храни информации такая смесь якоре дата volta выбираем оптимальный формат хранить в каждом по этому случаю из data vault и на старте мы взяли таблицы то ли ты группы и там спец таблицы point and which case акари взяли некачественная который хоп вот этого lte и связи только через отдельные таблицы никаких атрибут запрещено например это объявление сущности в нашей платформе взял питание чем классом здесь видно что из какой-то layout потом много-много-много но относительно много разных полей и все это трансформируется в мир такой вид центре хоп и вокруг одна таблица один атрибут чистый якорь но ведь тот же вид можно представить его так центре хоп но какие-то атрибуты мы сгруппировали меж собой сделали сателлиты если по дата волка ноги группу как но это все называем и на самом деле это достаточно интересный вопрос как сгруппировать атрибуты по сателлитом или по группам таким образом чтобы это было оптимально самом деле это позиционная задачу кто-то может то что это искусство но мы говорим что это надо все замерить положить 2 а потом получить какой-то результат и сделать обоснованный выбор у нас есть место 2-х уже всевозможными за данные объектов маппинге полей загрузчике и информация количество строк в объекте понятно она достаточно точные но тем не менее у нас есть ограничения набор полей метаданных объектов и группа должна загружаться из одного источника потому что мы с когда два из двух источников это собирать достаточно сложно но и здесь мы будем оптимизировать минимально занимаемое место на диске потому что у нас конкретно тогда болела green план был не достаточно большой мы хотели по оптимизировать место на диск и детально свое нас на принтами вот синтетический пример чтобы показать синтетический пример пришел чтобы показать что это вообще важно вот у нас например какой-то поток информации там есть business data ключи триполи field 123 с каким-то весом 80 2830 просто подобрал business data это изменение но соответственно нас идет какой-то поток изменений есть дополнительный порядок он сильно понять то что мы добавляем когда что джон деталей слой мы генерируем суррогатный ключ это у это 16 байт у нас есть несколько дат это до 33 загрузки если это из kd-2 двигаться и по действий по восемь байт еще source айди храним откуда загрузили и вот если мы это начнем разбивать три поля то у нас есть пять вариантов можем все закинуть в одну группу можем выделить по одному атрибуту f1 f2 и f3 в отдельный а можем все 31 и положить от нас есть три варианта допустим вас приходит миллион строчек по два изменения в каждом поле это приходит дед по миллиону сущностей соответственно если вы все их посчитаем с учим с учетом добавочных полей то выгоднее всего положить в одну группу f1 и f2 f3 почему потому что если мы раскидываем на разные таблицы где одна таблица 13 будут просто добавляем очень много лишней информации технической сорвана ключ ведь я храним 2 на ты везде храним source они видео храним это дорого из получается в 280 против двухсот понятно что пример синтетические я тут не учитывал сжатия не учитывал рлд который у нас там очень неплохо играет потому что мы проецируем высоко d2 выносим портится актуальных в отдельную партицию тестом там дата действие до всегда одна и она неплохо выжимается это такой пример допустим теперь мы поменяли 2 поля 32 изменению на ключ получается что за миллион строчка нам приходит меньше сущности раньше был полмиллиона сейчас 31 тысяча двести пятьдесят если мы считаем то теперь это поле вынести отдельно становится выгодно просто потому что измене остальных полей мы не храним рядом как типичные скд 2 если мы добавим третьему пользуешься 4 изменения сущность станет еще меньше потому что у нас очень много изменений приходят новых сущностей но здесь начинает становиться выгодным разделить на отдельный атрибут соответственно наше решение этой проблемы мы вводим атомарные операции которые меняют схему физического хранения но самом деле меняет логику то есть можем менять атрибуты можем разделять трибут и с точки зрения нашего подхода это гибридной модели все абсолютно одинаково мы просто пользуемся сущность как она есть физическое хранение нас не интересует ну одинаковы ну а дальше мы проходимся генетическим алгоритмом берем генерируем пусть возможной популяции считаем нашу оптимальность ну в плане веса потом все это скрещивать между собою добавляем мутации все эти операции тоже мутации при подозрении на сходимость останавливаемся получаем итоговое состояния которое лучше по нашей метрики здесь по хорошему надо бы еще на героические по миграции но нет пока мы до этого не доросли мы просто они метаданные и миграции как оно проходит прям отдельный вопрос для большого доклада здесь может быть вопрос почему так сложно его вертел на самом деле смотреть только на объем данных это не очень интересно интересно смотреть еще одна оптимальный запросов потому что с одной стороны мы меняем место которое хранится с другой стороны мы добавляем большое количество джайнов ну чтобы воссоздать эту сущность нравится больше join если еще и это добавить в нашу концепцию модель устанет прям супер круто но мы пока до этого не доросли наскоро дорастем надеюсь и так стоило ли это того вообще все напомню что того нас была проблема развитием крупного 2-х сложно управлять родилась решение по читали статью про дата мешал 1 поизучали литература не то что родилось или потом вернулась нет почитали нашли что можно покрыть работу 2-х медиков на самолете не простая и банальная идея но тем не менее а дальше мы решили использовать данный system 2 оксану 2-х сделали такую белуха для 2-х речь прекрасно почему нет она стала команда 2 а которая помогает аналитиком готовить данным почему не можем приготовить данной схеме для себя никаб результат получили аналитику по работе и развития самого хранилища данных создали вот такой от методах а тут получается у нас 6 доменов-источников один большой социальный домен еще три бизнесов домен со всевозможными tring по которым мы построили наш отчет в целом отвечать на вопросы или того нечестно если не расскажу сколько нам это стоило нас не было никаких дополнительных внедрений мы буквально ничего не внедряли просто взяли все готовы и сделали рядышком счет 2х для реализации необходимо разноплановые специалисты тут нужен партнер по данным остин аналитика вещью на самом деле в 1 м2 они уже все есть надо никого искать они есть вот они рядышком абстрактно в вакууме то что я пишу нам где-то 2 человеком квартал если я скажу что так и было я совру потому что так не было это не бизнесовая задача достаточно сложно было погибать ресурсы поэтому работало порядка десяти человек где-то за 20 проц и данной нагрузкой то есть потихонечку там ноги сложили еще тут доделали вот примерно так модульном как я шел своем докладе что мы получили мы получили аналитику по ключевым аспектом для себя всех случае целевые метрики и принятия этих решений это то что рассказал про наш уклад метрику когда мы и увидели поплакали в подушку у игры не решения конструировать именно том чтобы нашим данным пользовались через это пошло управление реализацией теперь наших команд и txeq запросы по использовать без хранилище всегда можно посмотреть кто когда что использовал и зачем наверное после технически узких мест оптимизация и интеллектуальный модификаций пользователь вот то что мы сделали и на мой взгляд это строго больше наших затрат и самый главный вывод это возможно ли заводь вообще на любом 2 а если у вас есть рабочие 2-х вы можете собирать логе не важно где и систему на самые разные системы есть наша система из афонсу орз и что-то внутренняя и что-то внешнее проприетарное 87 можно собрать логе сложить их как источник для отдыха и обработать их под тем же принцип в котором вы обрабатывать любые другие данные и все вы получить свое место 2-ой сможете смотреть что как вас происходит и того 2-х может быть источником данных для 2-х это может быть банальный вывод но не у всех это в голове есть методы ваха создать не слишком трудоемкая задача особенно если у вас есть выстроена рабочие 2-х достаточно обработать просто логе запросов вы уже поймете чем у вас пользуются люди в хранилище а это важно важно понимать для кого делать продукты вообще чем пользуется у вас что вы не делаете что-то там гигантская рядом чем несут чем никто не пользуется более сложную систематизация домена слои команды как у нас позволит вам поставить при газовом метрики этим командам и рисовать свое хранилище как продукт и плюс все это можно использовать и технические искать узкие места и модифицировать детальный слой как лет продемонстрирована такому синтетическом примере но тем ни менее спасибо готов ответить на ваши вопросы это коллеги у нас серия вопросов наши студенты гости спасибо большое за доклад очень интересно было доклад получился очень масштабным массивным таким познанием не вот например очень понравились графики и вот этот момент про парсинг логов из разных систем очевидно же что это зоопарк какой-то вот и вот чем ползти логе и чем рисуете графики просто муж these проекте рисуем в табло ну то есть у нас табло куплен можно рисовать чем-то еще не суть важно насчет парсинга логов все индивидуально понятно что система разные все индивидуально тот же green там мы хотели сперва прекратить искали партии что прям красиво все было но честно говоря они не сумели заставить его работать на каталанском синтаксисе поэтому просто регулярка me да немножко там где то теряется но тем не менее больше часть данных нормально а в случае с мсм который соску бы там то же самое там mdx запросы их парсим тоже примерно по такому же принципу спасибо большое и день у меня несколько вопросов да доклад действительно интересный загружены вот первый вопрос похожая задача стоит а как бы вы решали года задача используя накопленный опыт хотел бы получить то что вы сейчас рассказывать в терминах да это больше подходит для инфраструктурной команды на мой взгляд я так понял вот если для продуктовые команда это посмотреть допустим у меня и задачи точно так же мне нужно собирать метрики реагировать на метрики которые пользователь сам себя придумывают ему нужно знать 20 процентов таблицы поменялось и я хочу увидеть а лед на это действие там или модель задача работала больше чем три часа я хочу видеть а лед или blitz появились хочу видеть а лед и более того я бы хотел дать продуктовая команде такой вот инструмент который они смогли бы создавать свои собственные метки и не было таких ограничений что вы можете там только какие-то такие виды доделать а именно что-то произвольное вот используя данный опыт используя данный подход используя данные методы х как уйти в эту сторону ли у вас уже все есть по поводу мониторинга именно такого чтобы была реакция у нас есть отдельная систему куда платформу отправляет событие можно увидеть отставанию данных grafana джанглер и на него можно настроить возможно уведомление примерно значит лишь на инструмент здесь больше такой ретроспективный анализ чем пользоваться когда пользовались что возникла когда возникла все то что вы спросили в вопросе есть но через отдельности мы не через otg он там извините этот гибрид ancora это того это насколько приносят свои плюсы преимущество сравнивать с нашими решениями насколько я увидел вашим объяснение что вы решаете там экономия места или экономию там дельтав а вот если взять колонию таблицу колоночный формат это мы тоже все решено берем плоскую таблицу одинаковые в момент сжатия вот это вот оптимизация которую вы показывали я там ее не увижу то есть если взять тот же 20 лиц с одной структурой когда все поля будут лежать в одном месте момент сжатия мы так все и сэкономим на сколько или это специфика грин плант а тут нам арки паркет и там это используется еще сколоченного хранение согласен но здесь когда мы грузим поиска d2 то есть у нас этом не знаю 100 полиэстер разные частота меняются постоянно дублируем строчки и не обязательно у нас будет большая последовать в одинаково идущих значений какое-то поле которая не меняется нас будет одинаково ведущем значении мы давно сомкнется как р.е. но чем больше у нас всевозможных разных частот тем чаще встречаться эти изменения в данных и здесь колочь нажатие будет не таким классным плюс в любом случае тут зависит уже оптимизаторы если мы берем какую дверь текут а там колонны воссоздание кортежа из колонки происходит на максимальный поздних этапах это удобно принтами не там принтами из колонок все вас создается например на сразу соответственно все вот эти наши сжатия ним и создадутся и всегда будут мешать спела хлев памятник для запроса этого создание она проигрывает куча joy на искусстве например пряность мы редко используем прям кучу joy ну ну то есть обычно когда строить с витрину выбирать какой-то набор полей только они вычитывают к сожалению сейчас моментом не позволяет все это сделать красиво как я каждой модели не to join elimination который условно мы покрываем вот эту нашу таблицу как им какой интервью sky обращаясь данным полям оптимизатор понимает что не нужно все остальные джонни внуками сейчас такого нет но когда появится возможность семерки они обещают у нас есть своей оптимизатор для этого то есть можно написать что ты используешь только такие тополя и сущности помощи нашу платформу тебе правильно сгенерирует узкие запросу но я оптимист и джайнов так у кого есть еще вопросы есть ли у нас вопрос из онлайна традиционно нет и так наверное а я здесь еще вопрос давайте были ближайший поменяемся немножко да привет я бы хотел спросить насчет запросов на сколько я понял посети сами запрос для того чтобы понять статистику использования и все это единственно что вы просто берете влаги запросов сделал не собираетесь подай таблица да да да мы понимаем какие там таблицы используются на соответственно запросе используется вот такой набор таблиц и таблиц могут быть наши могут быть этот год ты сам бог сам который мы не распознали на этом все строится но все очень просто спасибо так девушка сзади не совсем по теме но вот 2-х делали ли вы мониторинг данных качество данных делаем это есть нас платформе у нас есть специальные тоски проверки мы проверяем фактически вход с источником то есть что получили все данные вход-выход ему что пойти по пути ничего не потерялось и выход выходом ну что у нас непротиворечивый результат и плюс есть еще дает calc firewall который не пуская данные внутрь но про это лучше расскажет каких платформ есть в планах именно мониторинг уже качество данных смысле от вов аномалий есть на этот 10 с этим сложно то есть с точки зрения техники несложно мы можем посмотрите на мале найти что что-то там увеличивал себе вступление поменялось а просто окна это реагировать вот больше вопрос скорее административно процессный что с этим делать может оно и должно было измениться может не изменилось может это правильно с этим странновато а у команды ты не знаете есть ли это у них скорее всего больше кейсов яндекс яндекс еды и все преимущества нашей платформы вообще все тоже ну может быть и сверху еще вот они уже следят заново лимита ну просто там тоже контента больше может быть но с нашими инструментами до могут следить так у кого есть еще вопросы повторно еще вопрос можно вот якорем нато вот ваш гибрид он приносит какие-то плоды с точки зрения автоматизации когда на источнике еще либо там на приемник меняются структуры если структура источников меняется если у вас какая-то автоматизация которая позволяет на это все реагировать онлайн без участия специалистов потому что ответ на вопрос виду частей да у нас есть система мониторинга и нет мы это не делаем автоматическим то есть дома вина что что-то изменилось на пока наш платформ не доросла до того чтобы это автоматом потрогать сущность на самом деле есть здесь дрова и потому что нас есть объекты в которых там тысячи полей и не все они нужны прямо нашим детальные условия то есть они остаются у нас в роу слой потому что там собираемся как есть но они проходят дальше не просто не нужно и мы понимаем что они есть но не нужно когда ты можем загрузить поэтому здесь наверное автоматический свет подгружать не нужно разного с точки зрения мониторинга все это есть нельзя было сверху нашел итак у нас закончились вопросы так еще есть вопрос добрый день вы сказали что каждый день внедрять изменение в про там 200 комментов день у вас не обязательно вообще во все наши у нас единая единое место единой репозитории каждый может что-то поправить платформе и в данный момент что все это проходит через review и так далее но тем не менее кстати комнатах одессе каждый день происходит то неловки комментам на нижнем слое можно сломать север кислое как бы от этого страху не может как как оценку влияния проводите можем ловим боремся с этим пока не пока мне нет ответ на этот вопрос да мы от этого страдаем есть такое и здесь мы можем оценить что на что влияет быстренько через все эти графы все это есть но тут скорее предотвратить этого не можем автоматизированным что смотрим код тестируем но не более того нечего есть тесты есть есть даже тесты на этой процесса местами есть индукционный тест на но у нас не стопроцентное покрытие тестами то есть дед стреляют как я рассказывал мы смотрим посмотрели больше в количество не в качестве есть только сейчас будем прям активность покрывать ну и наверное последний вопрос скрыть просто поводу репозитория контроля версий и изменение модели данных и как понял вы делаете вещи какие-то про типизацию хранения с моделью там добывается но бывает например такие вопросы такие изменения модели данных которые например нельзя откатить узор рынок там удаление колонки или что-то в этом роде да вот как вы эти вот вещи обходите но вот эта птица который показывал там нет деструктивных изменений там только группировка с группировкой ничего не удаляем и фактически не добавляем просто перегруппированы такие миграцию нас есть но не просто с удалением отдельный контроль проходят то есть то шаг и все остальное но то есть это в ручном режиме каком-то в жилья да да да да да вот а тоже в ручном режиме там понятно что хотелось бы это можно автоматизировать но мы не сделали спасибо итак давайте поблагодарим евгения за очень интересный доклад сидений теперь тебе слово какой вопрос заслуживает подарка в виде книги уже заслужил подарок за я кому спасибо это лучшему вопросу бумажка я вот вам вопрос про детально слой да вот вам вам вам да нет нет нет нет да да да да вот он ваш билетик на книжку поздравляю"
}