{
  "video_id": "M20tzOy36rs",
  "channel": "HighLoadChannel",
  "title": "Горизонтальное масштабирование что, зачем, когда и как / Александр Макаров (Yii, Stay.com)",
  "views": 7230,
  "duration": 2973,
  "published": "2017-07-29T12:57:50-07:00",
  "text": "пара немножко объявление потом расскажу про конференцию это самая крутая наша конференция самое необычное сейчас расскажу почему из всех что здесь происходит на площадке если кому-то кажется что у него чего-то в пакете не доложили вот чему там окажется вот я хочу вот это вот этому меня нет подходите к нам на информационную стойку мы разрулим ситуацию но здесь а давай небольшой небольшой локальный отбыл с утра по поводу логистики ну вот поэтому чисто теоретически возможны какие-то недочеты так по поводу конференция в чем фишка этой конференции обычно мы как делом обычно объявляем прием докладов и все кто хочет приезжать все кто хочет предвещает подает заявки мы из них выбираем лучше здесь было все наоборот программа комитет я в частности я объездил все технологические конференции россии этого года я был в екатеринбурге ульяновске новосибирске в москве и так далее везде я ходил на все технические доклады и смотрел на всех докладчиков и самые лучшие докладчики собранные здесь мы собрали конференц мы собрали конференции вот как как пазл вот сейчас первый рассказ первый рассказ это некая вводная о том что вообще высокие нагрузки что такое высокие нагрузки а потом каждый следующий доклад будет разворачивать какой-то кусочек доклад про хранение файлов так рад про хранения видео доклад про тот это как про балансировку трафика и так далее так далее так далее так далее на самом деле это программа офигенно она лучше хай-лоу до осеннего она более цельно она более осмысленная здесь можно реально сидеть от начала до конца если все внимательно вникать все записывать ну ты концу выйдешь реальную как не знаю ты в теме будешь ориентироваться как минимум поэтому желаю вам удачи следите записывайте учитесь ловите докладчиков ну всё поехали александр те слова здравствуйте а я александр макаров скорее всего вы можете знать меня в фреймворка и я один из разработчиков вот ну и есть у меня и full-time работа это уже уже не стартап стоит точка ком который занимается путешествиями вот сегодня буду рассказывать про горизонтальное масштабирование но очень-очень в общих словах то есть как уже сказал олег тему раскроют дальше начнем итак что у нас такое вообще масштабирование масштабируем эту нос возможность увеличить производительность проекта за минимальное время путем добавления ресурсов то есть это обычно не включает себя какой-то переписывание кода это просто достали бы доставили сервер либо соответственно нарастили ресурсы существующего вот по этому самому типу выделяет вертикальное и горизонтальное масштабирование вертикальной от у нас как раз к добавляют там побольше оперативки диск и так далее на сервер которая 1 и уже есть а горизонтально это когда ставят больше серверов вот это центр и они как-то между собой взаимодействуют вот самый классный вопрос который обычно возникает вообще но зачем она да у меня на одном сервере все классно работает все замечательно на самом-то деле надо проверить что будет то есть сейчас он работает но что будет потом есть две утилитки замечательные первое это абэ второе это съесть что они делают они нагоняют как бы тучу пользователей конкурента которые начинают долбить сервер пытаются запросить страничке там послать какие-то под запросы get новые должны указать что им делать и соответственно они формируют вот такие замечательные отчеты главные два параметра это n на то сколько запросов делаете c это сколько одновременно делать в запросов то есть они проверяют конкурентность вот серж в принципе примерно так же работает вот но и на выходе мы получаем рпс то есть request секанс то есть сколько у нас вообще может запросов в секунду обработать наш сервер от этого будет понятно сколько соответственно пользователей мы можем выдержать но все конечно зависит от проекта все это бывает немножко по-разному но обычно на этом надо смотреть плюс есть еще параметр response times то есть это время ответа за который в среднем сервер отдал нашу страничку она бывает разные но все мы знаем что где-то 300 миллисекунд это норма а что выше уже не очень потому что мало того что у нас серверная часть отработают 300 миллисекунд еще где-то 300-600 миллисекунд обычно и обрабатывает клиента пока все загрузится стиле там картинки все остальное тоже проходит время вот ну бывает на самом деле что пока и не надо нам забыть о масштабировании идем на сервер обновляем печки получаем 40 процентов прироста производительности и вообще все круто но если у нас какой-нибудь 53 а мы обновимся на 56 там что-нибудь такое если мы обновимся на семерку то будет вообще красота но семерка пока у нас еще не стабильно вот настраиваем appcache теням его appcache к статье тянется так же как и об отце замечательным скрипте com его можно найти разум солер торфа в репозитории он показывает у нас хиты и мисс и то есть хиты это сколько раз ты пошел в кэш амиса это сколько раз он пошел файловую систему доставать этот тот файлике и если прогнать весь сайтик то есть ну либо запустить туда какой-нибудь краулер по ссылкам либо вручную там потыкать у нас получится что будет статистика по вот этим хитом ими сам и если у нас хитов сто процентов миссов ноль значит все нормально если есть месси то соответственно до выделить больше памяти чтобы весь наш код в лес в appcache этот частая ошибка которую вроде appcache и есть но что то не работает вот а еще часто начинают масштабировать но не не смотрит вообще из-за чего все работает медленно чаще всего лезем в базовом смотрим индексов нет используется там join и и не join и ставим индексы 1 все залетала еще на два года хвалят красота вот ну включить пеш заменить apache и nginx и пить пиво мем чтобы сэкономить память все классно все классно далее будут еще на доклады на тему оптимизация конкретно по пожгли и мая сквере вот все это очень достаточно просто и дает вам время время на что время на то что когда то этого станет мало и надо готовиться сделали мы на самом деле не совсем все как вообще понять в чем проблема в чем проблема либо у вас уже настал highload но халат вообще то что это когда у вас это не обязательно там бешеное число каких там запросов и так далее ты когда у вас собственно ваш проект уже не справляется с нагрузкой и тривиальными способами то его уже но не решается это не как надо либо там вырастив шире либо вверх либо что-то делать и скорее всего мало на это времени что-то надо придумывать как-то извращаться вот ну первое дело первое правило это то что вслепую делать никогда ничего нельзя то есть нам нужен отличный мониторинг мониторинг как это все делается сначала мы выигрываем время какой-нибудь очевидной оптимизация типа там включение кэш или там кэширование главное или еще чего-нибудь такого потом настраиваем мониторинг он нам показывает чего не хватает и все это дело повторяется повторяется повторяется останавливать мониторинг и доработку никогда нельзя вот что у нас может показать мониторинг мы можем упереться в диск то есть файловую систему в память процессоров в сеть и может такое быть что вроде все более-менее но какие-то ошибки валюту все вот эти штуки они разрешаются по разному можно ту же проблему допустим с диском решить тема что доставить там еще один диск в тот же сервер можно заменить диск на ssd а можно поставить второй сервер который будет там заниматься только файлами на что нужно обращать внимание прямо вот сейчас при мониторинге это 1 доступность то есть жив ли вообще сервис или нет нехватка ресурсов как я уже говорил про dice там процессор и так далее но и ошибки как это все мониторить вот здесь списочек из замечательных штук толс которые все это позволяет мониторить и показывать в очень очень удобном виде вот манит zabbix мунин nagios это штуки которые можно поставить к себе на сервер мощные классные бро zabbix по моему будет здесь в параллельном потоке но кажется в то же самое время что и сейчас но в любом случае автора zabbix и где-то здесь бегает можно его захватить вот и server density эта штуковина которая хостится у кого-то то есть мы за него платим деньги она можно собирать серверов кто-то остается плагин чеки все данные и соответственно показывает все для анализа вот для ошибок есть два классных сервиса roll bar & sundry смысл в чем обычно как мы делаем ошибки мониторим мы берем либо пишемся в лук и смотрим его либо соответственно дополнительно к этому начинаем email этом или смски слать разработчикам это все нормально но как только у нас набегает туча народу на сервис и есть там какая-нибудь ошибка она начинает повторяться очень большое количество раз начинает бешено с память имейл либо он вообще переполняется либо просто у разработчика теряется полностью внимание начинает письма игнорирует типа но опять эта фигня пришла потом вот и роутера центре они что делать они берут и ошибки одного и того же типа собирают в одну большую пачку плюс они считают сколько раз оно произошло сколько раз за последнее время и в приоритетах автоматом поднимают все это дело а ну и центре она ставится к себе на сервер можно есть исходник орал барнетт на робар души потому что он берет деньги за количество ошибок то есть стимулирует их исправлять до класная штука вот про notification уже сказал что с память на самом деле не стоит теряется внимание вот ну и что вообще надо анализировать request and response times то есть если у нас начинает время ответа падать надо что то делать вот количество процессов количество потоков и размера череде и все это если она начинает плодиться забиваться и так далее что то здесь опять не так надо анализировать более детально что застряло и как-то менять инфраструктуру подробно про мониторинг будет еще завтра вот так же стоит смотреть на бизнес-анализ то есть google analytics для сайта вых типов отлично подходит амикс пенал для вообще логирования винтов он работает на доступных приложениях на мобильных на веб и можно конечно и на основе каких-то своих данных и вписать но если есть возможность использовать какими такие сервисы и бы их использовал смысл в чем смысл в том что наш мониторинг может показывать что сервис жив что все работает что общий response time нормальный но когда мы допустим регистрация в xp 0 начинаем трек это вам показать что тут их мало маловато будет вот и надо тогда смотреть на определенные какие-то ивенты какие-то страницы и уже смотреть насколько быстро они отрабатывают в чем вообще проблема то есть проект всегда должен быть обвешан анализом по самой чтобы вообще знаешь что происходит они работать вслепую вот нагрузка вообще она возникает или запланировано или нет может возникать постепенно может не постепенно обычно это какая-то сезонная рекламы новости акции но бывает что кто-то там на поезд какие-то линки на хабре или показал по телевизору вас и пошло-поехало как вообще бороться с нагрузкой вот здесь есть одна засада решает все бизнес и важно только цена вопроса то есть важно первое это чтобы сервис работу а второй чтобы это было не сильно дорого не разорил вообще компанию это вот все что важно остальное не очень вот если дешевле поправь и лить по оптимизировать записать там в кэш поправить какие-то конфиге то надо это делать и не задумываться пока там и масштабирую куба том чтобы покупать железо и так далее но бывает что железо у нас становится дешевле чем работа программиста особенно если нос программисты очень хорошие и подкованных вот в таком случае уже начинается масштабирование типичная схемка типичная схемка надеюсь здесь не очень мелко нормально супер вот вот эта вот синяя штука это у нас интернета с которого идут запросы ставится балансировщик единственная задача балансировщика это распределить запросы на отдельные вот эти вот фронтон до сервера и соответственно принять их ответы отдать клиенту смысл тут в чем в том что 3 сервера могут обработать раза больше в идеале в 3 раза больше запросов мол исключает какие-то накладные расходы на сеть и на собственно саму работу балансировщика что она дает во первых это вот как я уже сказал возможность обработать больше запросов во вторых надежность вот в этой схеме если у нас но если он традиционной схеме валится там и джинс или еще что-нибудь или приложение или там в диск уперлись все все встало здесь если у нас один frontend свалился ничего страшного балансировщик по скорее всего это поймёт и отправить на оставшиеся два людей ничего не упадет но может быть чуть помедленнее но это не страшно вот а вообще php штука отличная для масштабирования потому что он следует принципу шея натан по умолчанию что это вообще означает если мы возьмем допустим джаву для веба как там строится приложение приложение запускается читает весь код записывает по максимуму данных память причем в памяти именно программы вот ну и соответственно все это там крутится работать на request уходит очень мало времени очень мало ресурсов но дополнительных но есть зоосада так как у нас приложение написано что вот на одном инстансе оно должно все работать кэшировать и читайте свои же памяти то ничего нас хорошего при масштабировании не получится а в печке у нас все по умолчанию ничего общего нет и это хорошо то есть все что мы хотим сделать в общем мы там пихаем memcache и так далее так далее но монтаж можно читать там с нескольких серверов поэтому все замечательно вот то есть достигается слабая связанность для слоя серверов приложений это прекрасно вот чем вообще балансирует нагрузку вот этот балансировщик начали чаще всего это делали с quidam или х прокси но до этого года в этом году индекс взял и портировала его автор из engine с плюс балансировщик в яндекс так что теперь он может делать все то что раньше делали сквидом и х прокси соответственно если она начинает не выдерживать можно поставить какой-нибудь крутой дорогой замечательной аппаратная балансировщик вот проблем вообще которое решает балансировщик это как выбрать сервер и как хранить сессии но это чисто вот вторая проблема чисто переспишь на сервер может выбираться либо по очереди из списка либо по географии каких-то и печников либо по каких-то там какой-то статистика вот он поддерживает допустим лист connected то есть к какому сервером меньше коннектор на тот она будет ориги давать и как то еще но то есть мы можем на самом деле написать для балансировщик какой-то код который будет у нас выбирать как ему работать вот по этой ссылочке как раз описан балансировщик свежий портированный в дженкс всем рекомендую он там очень простые конфиге все максимально просто указывается просто там по полу серверов все предельно замечательно что если мы упремся в балансировщик есть такая штука как dns round robin это замечательный трюк который позволяет нам не тратиться на аппаратный балансировщик что мы делаем берём dns-сервера но обычно dns-сервера вы себя никто не хочет это дорого не сильно надежно если выйти из строя ничего хорошего не получится все пользуются комменты компаниями во первых снижаем the tail ада пара минут и соответственно а записей прописываем ни один сервер а несколько это была та записи наших разных балансировщик of соответственно когда браузер туда идет но гарантии на самом деле этого нет но все браузера современно так действуют они выбирают по очереди какой нибудь айпи адрес из рекордов и соответственно попадает либо на один балансировщик клип на второй вопрос конечно размазываться может неравномерно но по крайней мере она размазывается и балансировщик может выдержать немножко побольше что у нас делать с сессиями сессии у нас по умолчанию файлах это не дело это не дело потому что каждый из серверов front end of у нас будет держать сессии в своей файловой системе пользователя у нас может попадать то на один тон 2 на 3 и ничего хорошего из этого не выйдет то есть сессии он будет каждый раз терять возникает очевидное такое желание сделать общий файл и система подключить нфс но делать так не надо она до жути медленно вот можно записать в базу данных можно но тоже не стоит на самом деле база данных она не оптимальная для этой для этой работы но если у вас нет другого выхода то в принципе сойдет вот можно написать memcache но очень-очень осторожно потому что вам кажется это все-таки кэш и он имеет свойство вытираться как только у него мало ресурсов или не куда писать в общем новые ключи он начинает тереть старые без предупреждений даже пока они еще не за испарились то есть нормальный ключей сессии начинают теряться за этим надо либо следить либо соответственно выбрать тот же редис райтис это единственное нормальное решение ну не совсем единственно кивали баз данных много да как насчет кукисов можно да можно писать cookies но соответственно никаких вообще хранилищ не будет все хорошо но во первых у нас куда-то надо все еще девать данные сессии то есть если мы начнем писать куку она может разрастись и не влезть в хранилище в тех же страха и она сильно ограничить темпом 2 килобайтами что-то такое если мы запишем больше она потеряется вот ну и можно писать хранить cookies только айди и соответственно если вы там будет храниться только один нам все равно придется бегать базу за каким-то с зелеными данных принципе это нормально это решает проблему если это не упомянул действительно вот но что касается редиса смысл в том что у нас редис получается на отдельном сервере и все наши там фронтэнда они ломятся туда и начинают связи со своей сессии считывать но radisson нас однопоточный то есть рано или поздно в родиться это дело может хорошенько упереться и тогда делают снимки сессии смысл в том что но ставить допустим тот же джинкс и джинсы говорят что нам нужно сделать соси так чтобы user как только он пришёл на сервер ему выдалась сессионная кука чтобы он дальше попадал только на этот сервер чаще всего это делает по айпи хочу это опять же вот в этом балансировщик engine jesus in женском новом добавили очень приятная штука ну и получается если red ясно каждом инстансе соответственно сессии там свои и пропускная способность чтения-записи будет гораздо лучше вот есть классная штука прокси для мы им каждый релиз они вроде как поддерживают распараллеливание из коробки но соответственно делается это но не сказала бы чтобы прям сильно оптимально а вот это вот штука твоим прокси она работает примерно как и джинкс с пепе то есть он как только ответ получен он сразу выплевывает наши данные из а там соединение уже закрывает фоне получается быстрее меньше ресурсов кушает очень хорошая штука вот никогда не стоит писать своего аналога сессии то есть очень часто такая ошибка велосипеде рование когда берут и начинают писать типа вот my sassy не нужны я сейчас сделаю замечательные talking которым я бы туда сюда передаваться но если так потом это в принципе это опять же сессия вот и и в печке есть такая механизм как сашан finder то есть мы можем поставить свой хендлер и соответственно писать на втулку в базу в рейде с куда угодно все это будет работать со стандартными спешим стартом и так далее так далее вот c синод закрывает session райт класс вот этим вот замечательным методом как только мы и сессии все прочитали мы не собираемся описать ее надо закрыть но что сессия частенько блокируется но она вообще должна блокироваться потому что без блокировок был проблемы с конкурентности на файлах это видно вообще прям сразу на друге хранилищах блокировщики бывают не на весь файл сразу и немножко с этим попроще что у нас делать с файлами с файлами можно справляться двумя штуками первым это какой-то специализированное решение которое у нас дает абстракции мы работаем с файлами как вот с файловой системой все получается так замечательно но tata что-то вроде нфс но нфс не надо вот и второе это сортирование средствами php специализированное решение вот из того что действительно работает от глаз рфс это то что можно поставить себе она работает она быстрая но дает тот же интерфейс принципе что нфс только работать с нормальной терпимой скорости вот ну и соответственно amazon s3 это если вы в облаке amazon у этого тоже хорошие файловой системы со стороны печки если вы реализуете есть замечательно библиотека fly систем покрыта отличным тестами ее можно использовать для работы с вообще тучей тучи тучей всяких разных файловых систем что очень удобно если вы сразу напишите все работы с файлами с ней то потом перенести с локальной файловой системы на там amazon из 3 или так далее это будет просто в конфиге строчка переписать как вообще это работает пользователи с из браузер загружает файлик он может попадать либо на front-end и оттуда расползаться по файловым сервером либо соответственно на каждом файловом сервере делается скриптик там для apple о да и соответственно заливается сразу в файловую систему ну и параллельно в базу пишется какой файл на каком сервере лежит соответственно мы читать можем его прямо оттуда раздавался файлы лучше всего их раздавать anjing сам или вор не ш-о-н дженкс так как мы все все любим и дженкс все его используем лучше по максимуму делать все индексом он он справится он хороший вот никогда не храните файлы в базе и это постоянно встречаю это что то что то жутко вот можно в принципе хранить на каждом из frontend серверов локальный кэш например там для какого-нибудь рафтинга запросов то есть то что не обязательно то что то что может сама создаться и то что на каждом из фронтов в принципе нам не критично чтобы она там лежало не лежала вот эту трогать особо не надо что у нас происходит с базой данных с базой данных в принципе если у вас все уперлось в пищу пышный код мы делаем коучем front end of и все еще лезем в одну базу база справиться достаточно долгое время очень долгое время сказал если у вас нагрузка не страшная база живет хорошо например мы делали join и по старше 60 миллионам строчек в табличке все было замечательно да все бегло хорошо но там правда оперативки надо побольше выделить ему на buffer in a cage вот тогда будет все хорошо что делать с базы если мы все таки в нее уперлись есть вот такие вот замечательные техники как репликация репликация обычно делается мастер слоёв есть репликация мастер мастер можно репликацию делать руками можно делать шарнира вание и и можно делать протезирование про которая говорить особо не буду про него будет далее доклада что такое у нас мастер slave а выбирается один сервер главным и куча куча серверов второстепенными на главные пишется вот идет красной стрелочки это то что мы пишем зеленое то что мы читаем а читаем мы можем считать с мастер можем считать соответственно вот этих слоев то есть если у нас но в типичном проекте у нас операция чтения гораздо больше чем операция записи бывает не эпичные проекта вот-вот в случае типичного проекта у нас вот большое количество слоев она позволяет разгрузить как мастер так и вообще увеличить скорость чтения так же это дает отказоустойчивость если у нас упала один из слоев вообще ничего делать не надо все классно если у вас упал мастер мы можем достаточно быстро сделать один из слоев мастером но правда это автоматически обычно не делается это такая нештатная ситуация но возможность есть вот ну и backup & backup с life базы все делают по-разному иногда это делается мой сколь дампом при этом он фризит весь проект намертво это не очень хорошая штука а вот если делать бэкап со с какой-нибудь слева предварительно его остановив то пользователя ничего не заменит это вообще прекрасно ну и можно делать на словах тяжёло вычисления чтобы не затронуть соответственно основную базу основной проект есть такая штука как или драть сплит делается два пола серверов мастер склеив соединения по требованию и бойко выбора соединений варьируются в чем вообще смысл смысл в том что если мы будем читать всегда со слайдов описать всегда в мастер то будет небольшая засада засада это то что репликация лагает то есть там выполняется не немедленное гарантий что она бы уже выполнилась когда мы делаем какой то запрос нет и иногда данные попадают на слив с задержкой поэтому есть два типа выборок 1 выборка для чтения или там для вывода для чего-то там а вторая выборка для записи то есть когда мы что-то выбрали и нам вот это что-то надо потом изменить и записать обратно вот если это выборка для записи то мы можем либо всегда читать счастливое писать-читать мастера писать мастер либо мы можем вот такую штуку выполнить то есть шоу слои в статус и посмотреть там секунд михаил мастер он покажет нам но и для подвеса он там супер такой запросик он покажет нам что он бы каждом число если это ноль значит все у нас уже реплицировать окей можно читать смело счастливы если у вас больше валя там уже надо смотреть это значение либо она стоит подождать немножко и читай прочитать сасло его когда там реплицируется все либо соответственно сразу читать с мастер ну и ну это и если еще не реплицировали если что-то там застрял надо смотреть влоги причина вот эта влага это либо медленно сеть либо не справлять цель реплика либо слишком много слоев если и больше насти то начинаются обычно такие хорошие проблемами вот но медленно сеть понятно наносить ускорять как-то собираюсь в один дата-центр и так далее так далее не справляется реплика это значит надо еще доставить реплик и если слишком много слоев то надо что-то уже придумывать интересных скорее всего делать какую-то иерархию вот что такое мастер мастер это когда у нас и стоит несколько серверов и везде и пишется читается плюс в чем она может быть быстрее она отказу стоящую но в принципе все то же что и у сливов но логика вообще простая то есть мы просто выбираем ран данное соединение с ним работаем на мне интересно реплицировать но там не реплицировать ну как не совсем неинтересно то есть пола гриб ли кации у нас выше есть шанс получить какие-то не консистентные данные и ещё одна классная штука что если произошла какая нибудь поломка она начинает раскидываться по всем мастерам и все уже не знает какой мастер нормальный какую поломался вот ну и все это дело она начинает реплицироваться по кругу то есть забивает сеть очень неслабо вообще если мастер мастер пришлось делать надо сто раз подумать и скорее всего мастер слова можно обойтись репликация расскажет андрей активов лучше него об этом мало кто знает стоит его послушать вот можно всегда делать руками репликацию ну то есть просто организовать пару connection of и туда писать сразу два сразу три либо что-то делать фоне что такое у нас сортирование шарнир мне это фактически размазанной данных по нескольким серверам сортировать можно отдельные таблицы то есть берем допустим таблицу фототаблицы юзера таблицы пастора стаскиваем на отдельные сервера но если у вас таблицы были большие соответственно все это становится меньше памяти жрет меньше все красота только нельзя joy нить приходится делать запросы deep in сначала выбираем тучу адэшников потом все эти орешника представляем запрос но уже к другому коннекта к другому серверу вот а можно реплицировать можно сортировать часть одних и тех же данных то есть мы берем и делаем несколько баз данных с юзерам с юзерами как вообще выбирается сервер можно достаточно просто выбрать остаток отделение на количество серверов всем прекрасно альтернатива это завести карту то есть для каждой записи и держать в каком нибудь там родители так далее ключ-значение то есть где лежит какая запись есть вариант попроще то есть попробовать разделить на части которая используется вместе но не пересекаются так делает например есть у вордпресса хостинг а я там хоть тут юзовский блоге вот там сделано примерно такая такое сортирование то есть они берут и для какой-то группы юзеров выносят все таблички на отдельные сервера соответственно они не пересекаются если что там по логике приложение отличается то выбрать список всех юзеров на помаду этого делать не дает так что когда мы работаем с каким-то одним юзерам смотрим углов там теги после и так далее всё работает вообще с тем же самым кодом то есть там можно joy нить можно сортировать все все классно вообще все просто замечательно посложнее ты когда не удается сгруппировать таким образом данные и тут уже все очень-очень весело нужно знать о лишних домах чтобы дал и доставить никаких join of никаких ордеров ничего такого но и фактически мы сводим наш там майского лили под грез пузыри square в севилью хранилище может мы с ним ничего делать не можем и обычные задачи они становятся очень необычными то есть вот эти вот задачки вообще со скорым решаются с полпинка выбрать топ-10 постранично разбить данные выбрать там с наименьшей стоимостью что-нибудь там товары какие-нибудь выбрать после юзера x если мы за шар де равале таким образом что все вообще разлетелась по всем серверам это уже начинает решаться очень нетривиальных и на самом деле вот когда такое настает во-первых придется перестроить muse хорошо это достаточно дорого вот это обходится как работодателю дорого так и программиста это на это тратится много времени нервов ну и еще возникает один классный вопрос а зачем нам в сквере то есть не писатель нам какой-нибудь редис сразу правильно ли мы выбрали хранилищ из коробки шар ник поддерживается такими штуками как мамка shreddies кассандра kassandra говорят с какого-то момента уже не справляются начинают падать вот про монтаж resist не слышал такого вроде все с ними хорошо прошла родирование будет в докладе низ иваново ну а мы переходим к статистике часто статистику любят считать с основного сервера с единственной сервера баз данных это прекрасно но запросы в статистике обычно жуткие многостраничные с дикими там uni my joy нами и так далее так далее не всегда при этом хочется индекс оттуда доделать ну что вы снова пробили проекте они не используется но и сразу скажу что вот так вот считать статистику по основным данным это большая большая ошибка для статистики большинстве случаев real-time вообще не нужен так что мы можем настроить мастер слоя верификацию из осло наслаиваю же эту статистику посчитать или мы можем взять что-нибудь готовыми но то есть миг п.а. google analytics или что нибудь такое фоновая обработка все что не критично сделать прямо сейчас можно обработать фоне это вот основная такая замечательная идея которая помогает раскидывать все по разным серверам и масштабировать очень замечательно во первых от этого сразу виден профиль даже если у вас один сервер вы начинаете фоне что-то выполнять user получает response гораздо быстрее но и впоследствии впоследствии можно размазывать нагрузку то есть мы в этот фон мы можем его перетащить всю эту обработку на другой сервер можно обрабатывать это даже не на печке например в том же стоит кому нас обрабатывается на картинке ресницы нога вот как как можно сразу взять ger men at который последний в списке это в общем то готовая штука для обработки фоне есть подписи библиотечки драйвера все все классно замечательно можно использовать очереди то есть активы мку ребенку но тогда придется как-то очереди они у нас пересылают только сообщения с вами обработчики они вызывают не выполнять то есть что-то нужно в этом с этим придумывать вот но общий смысл всегда один есть соответственно основной по которой пихает в очереди какие-то данные обычно это что сделать и данные для этого вот ну и какой-то сервис он либо это достает либо ему прилетает если очередь умеет активно себя вести а вот эти вот данные он все дела фоне обрабатывать опять же подробно будет дальше теперь к архитектуре архитектура это важно самое главное при масштабировании это в проекте сделать как меньше как можно меньше связанности чем меньше связанности тем соответственно проще менять одно решение на друга и тем проще вынести к часть на другой сервер связанность у нас бывает как в коде вот эти вот две аббревиатуры solid игра с по ней как раз это принципы которые позволяют масс избежать связанности именно в коде но в коде связанность это ладно она в общем там а именно вот разнос на сервера она конечно влияет но не на столько на сколько связанность доменного слоя с нашим окружением смысл в чем что домины слой то есть как там взаимодействует наша предметную область с тем вот как пользователи нам что отдает и так далее вот если мы в коде там в контроллере пишем много много кода соответственно у нас получается то что в другом месте мы это использовать скорее всего не сможем то есть мы нам не очень просто будет переносить из веб контроллера все это дело там в консоли и так далее и так далее и соответственно гораздо сложнее все это дело утаскивает в какие-то другие серверы работают по-другому а сервис аренды архитектор что это у нас такое смысл в том что есть дисциплина domain-driven девелопмент она учит нас о том как правильно бить наши проекты вот на отдельные вот сервисе части вообще то есть два подхода первый это когда бьется на технической части то есть вот есть у нас очередь вынесли сервер очередей есть у нас там еще что то вынесли там сервера обработки изображений все это классно но когда у нас вот эти вот очереди сообщения изображения взаимодействует в рамках двух доменных областей то есть допустим есть область sails в проекте в crm-ки и есть область область костюмер это немножко две разные области с ним работают разные юзеры но эти у тех и тех есть очереди и так далее и так далее когда все начинает заваливаться кучу проект превращается в такое классное месиво вот ну и на самом деле правильным решением это бить на отдельные логические части то есть мы выбираем sails выбираем допустим к саммерс и даже если вы и там и там используется модель юзера мы создаем две модели user они могут идти лезть там читают одни и те же данные но представляют о них немножко по-разному и вот если так разбить то получается все гораздо лучше но лучше воспринимается и намного проще все это дело раскидать ну и еще одна главная штука это то что часть всегда должны вы занимаетесь через интерфейс а вот эти вот как раз логические части то есть если там сел с чем-то ещё взаимодействует он у нас некий не пишет там в базу не использует одну и ту же модель quo друг с другом разговаривать через определенный контракта в доме нам слоя что получается в принципе сам доменный слой у нас разбивать на какие то там сервисы на что такое правильное проектировать это для именно для масштабирования не очень-то и важно это важно для самой разработке приложений но для масштабирования наделали фигни можно в принципе с ней жить вот и что сверхважно это отделить его от именно среды то есть от контроллера от какой-то от камы консольного кружения от всего вот этого то есть чтобы всем нашей модели и все вот это можно было использовать любом контексте про доменный слой есть две книжечки которые всем-всем-всем советы это domain-driven design pro комплексе дрк эванса и еще одна примерно с таким же названием другого автора вот ну и вот ссылки внизу кстати на доклад ссылка там было и она и дальше там будет проскакивать всем кому хочется я дома у себя в блоге запустили ссылочки можно будет по ссылкам которые синеньким походить вот бан тут контекст это как раз то что я говорил что если вас две области вроде как пересекаются на ней разные то стоит никакой сущности продублировать такие как модель user вот но и продать это в общем там ссылочки еще на одну книгу в архитектуре стоит опять же придерживаться принципов и она-то то есть если вы хотите что-то сделать общем делайте это всегда сознательно логику предпочтительно закидывать на сторону приложения но они всегда все-таки стоит знать в этом меру то есть никогда не стоит делать допустим храним ки хранимой процедуры там в особой д потому что масштабировать это дело очень очень тяжело если это перенести на сторону приложения то это сделать просто он просто сделать низкий серверов все это выполняется там вот ну и не стоит недооценивать браузерной оптимизацию как я уже говорил из тех там 300 600 миллисекунд который выполняется на сервере к ним прибавляется еще 300 600 миллисекунд который выполняется клиенте клиенту в общем-то совершенно пофигу это наш сервер работает быстро или у нас клиент сайт отработал сверх быстро за десять миллисекунд сервер даже если он купил все равно в общем получается быстро и хорошо то есть браузерной оптимизация не заценить не стоит стоит пользоваться google pagespeed и так далее как обычную абстракция дробления со всеми бесплатно если мы разобьем сервис то чудовище микро сервисов во-первых мы больше не сможем работать с новичками то есть придется много много платить нашей команде которая будет во всем этом как-то рыться там все эти слои перебирать но и в принципе она может немножко еще и помедленней работ если в компилируем их языках это не страшно то в печке по крайней мере до семёрки это не очень никогда не действуете вслепую всегда мониторьте всегда анализируйте вслепую практически все решения по умолчанию не правильно думайте то что рассказывает остальные на доклада говорят что там либо редис это серебряная пуля либо ещё что-нибудь серебряная пуля не верьте всегда проверяйте вот еще немножко материалов есть рукой лодкам там в супер доступной форме расписаны практически все принципы там очень поверхностно но классно с рисуночками карандашиком и так далее так далее сделано классные считайте там обзоры того как большие всякие компании сделали интересное решение но и если поискать по highload в рунете вылезет много всего в английской интернет не выглядит ничего ну что они знают слова хайло ты у них это называется scalability вот ну и как все это попробовать до часто это пробует на лайв серверах делать этого ни в коем случае не надо есть такие классные что и как digital ушам и ли но то где можно поднять ногу развернуть там любое окружение любой сервер все потестить заплатить за это там один-два бакса максимум вот ну если есть вопросы задавайте слайды доступного по вот этому от гориллу в блоге я их выложу по адресу мкр эти вру по силам доброе утро вопросец в следующем на одном из первых слайдов у вас было написано что sopa стоит прийти на и джинсы + php-fpm что делать если мы уперлись в количества маркеров pig пфп мы сейчас смотрим сторону синхронных языков но это все нужно переписывать может быть вы предложите какое-то более простое решение но во первых его был карась в количество warcraft пичкает прямо в пределах одного сервера мы всегда можем поставить балансировщик и сделать два сервера вот принципе все а так количества маркеров она вычисляется из количества доступной памяти ну и ресурсов процессор так что ли либо вам надо увеличивать эти ресурсы либо соответственно доставлять сервера здравствуйте мне кирилл зовут вот как на примере у и 1 быть сосед сами может мы уже осознали что выберу мы делали не очень хорошо поэтому во втором у нас есть замечательная штука отключить менеджмента сетов фреймворком и и подключить туда какой-нибудь гарант или gulf и делать все как делают матерые фонтанчики вот но в первом это тоже можно сделать то есть просто вырубить все его ассеты и соответственно сделать это руками через гольфа legrand можно было бы но если мы пользуемся сторонними расширениями то там приходит соответственно в эти сторонние расширения прописывать все нашего дойдет пути в том же гольф или гранте и делать это руками спасибо я хотел спросить насчет bouncer для паз gresso например pg bouncy релизы вы не упоминали ничего об этом а потому что использовать и вообще это лучше раздать следующем докладчику которая будет рассказывать как раз право производители запросов по английской или он расскажет по про это гораздо лучше чем я вам еще есть александр здравствуйте хочу поблагодарить за многолетний вклад в open source пальцы спасибо большой вопрос следующим вот пары desu интересно вы предлагаете в общем-то хранилище на одно если чуть-чуть подключить географию но каждый раз ходить на один сервер будет дорого есть ли какие-нибудь предложите решение но вот я показывал дам ссылочку давал на практик для редиса и вот если их поставить много штук за вот этим прокси то они обрабатывают гораздо лучше чем в одиночку он просто начинает раскидывать на несколько и он сам насколько я помню многопоточный то есть вот эту узкое место если у вас один родис она убирается вообще да но если мы привязываем yuserg одному айпишник у к одной сессии стики сессии они распределяют у нас нагрузку часто неравномерно но вот из практики это не такая большая проблема александр им спасибо вам большое за доклад"
}