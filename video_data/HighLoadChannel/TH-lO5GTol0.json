{
  "video_id": "TH-lO5GTol0",
  "channel": "HighLoadChannel",
  "title": "Спасение 6 миллионов файлов в условиях полного Хецнера / Даниил Подольский, Дм. Симонов (Setup.ru)",
  "views": 675,
  "duration": 1712,
  "published": "2017-04-25T08:02:58-07:00",
  "text": "этот доклад заставил поспорить даже бывалых членов программного комитета дмитрий симонов и даниил подольский расскажут о хранение картинок в postgresql ребята грозились прийти с бенчмарками проверим внутри сильно поработал компания setup.ru сейчас домой подольске расскажем на кучу интересного еще так добрый вечер для начала что такое сетапе русь эта про эта система быстрого создания сайтов по шаблону зачем я об этом говорю чтобы описать так сказать тот контекст в котором возникла задача быстрое создание сайтов page 1 а означает во первых что у нас будет много пользователей ну собственно эта система создается для того чтобы не было много пользователей во вторых это означает что у нас будет много мелких файлов потому что шаблон простой шаблон никакого пользователя не порадует так давайте нажмем вот значит простой шаблон никакой пользователи не порадует соответственно должен быть сложным состоящим из множества мелких элементов для того чтобы быть большое количество сайтов от большого количества пользователей нам требуется горизонтальные масштабированием пока я рассказываю очевидную совершенно вещи горизонтальное масштабирование это в общем случае статический контент тоже понятно любая динамика масштабируется очень хорошо горизонтально во всяком случае значит да действительно все так и вышло как вы планировали год назад за этот год не приобрели 30 300 тысяч пользователей эти пользователи создали хотя бы по одному сайту результате мы получили 6 миллионов файлов все эти статьи и файлы статические отдаются angel eg сам с диска отдавались engine exams диска все у нас было хорошо значит серверов отдача у нас было несколько в первую очередь для того чтобы обеспечить отказоустойчивость и во вторую для того чтобы распределить нагрузку значит стандартный совершенных у тут все так делают файлы были распределены по нескольким уровнем вложенности директорий для того чтобы ускорить поиск файла при открытии как известно большая директория открывается долго будут вызывались развивались пустимся в одной известной немецкой компании на букву х оборудование у этой компании как известно тоже на букву х хорошее оборудование пока не очень надежная поэтому в этом августе мы в очередной раз были вынуждены клонировать наш сервер с контентом пользователей для другой соседние сервер потому что один из двух в кластере сдох дети для нас тогда нас удививший проблемой значит наши 6 миллионов файлов оказались распределены по 6 миллионов директорий это скорее всего ошибка или в коде или в даже в проекте потому что ну на 6 миллионов файлов не надо делать из директории на файл не делайте так как мы сделали тем не менее открытие каждый директория означает 1 руб его получение стад информация о файле это еще один его вот в результате мы обнаружили что обход дерева из 12 то есть обход дерева занимает 12 миллионов по операции ввода-вывода там по моему даже есть циферки следующие до дисковый кэш оказался малоэффективен в этой ситуации потому что каждая директория из шести миллионов занимает 4 килобайта это двадцать четыре гигабайта памяти на той машине нет столько на тех машинах нет столько по за каши ровать просто все содержимое директории мы не справились обход дерева занимаю нас шесть часов синхронизация с помощью арсенка 20 часов почему прошу заметить оно занимает 20 часов даже если обновилась 10 файлов мы все равно должны пробежаться по всему дереву и сравнить м тайма для для всех файлов что мы обнаружили что мы него не не не справляемся поддержи поддерживать актуальность реплики в процессе так сказать то есть пока мы и планируем исходник меняется но его еще расклонируем он еще раз меняется вот в общем то ситуация показалась нам тут моим безвыходный что там это было на два слайда назад но я скажу об этом сейчас быстро быстро изучение проблемы показалось что главный наш враг иерархическая файловая система никакой ничего кроме быстрого поиска она нам здесь не добавила а проблемы создала довольно много минеральные иерархические файловые системы канули в прошлое наверное если бы fat12 нам подошел по каким-нибудь ещё параметрам мы могли бы использовать его на нет fat12 не годится потому что у нас полтора байта пользовательских данных вот что возможные решения мы стали их искать первое что приходит в голову это включить на x4 индексирования директории нет ни не подошло потому что оказалось что очень глубоко в приложения зашита вот это вот структура древесная в которой лежат файлы ну кроме того индексируется только имена соответственно для того чтобы получить м time at файла нам все равно то есть во первых нам пришлось бы переложить все файлы в одну директорию пусть и индексирован а во-вторых для получения им time нам все равно пришлось бы делать еще один вызов еще один год открылась смотреть на еноту соответствующую вот мы стали глядеть на распределенные файловые системы потому что если у нас проблема в том что синхронизации синхронизацию нам не устроить клонирование то может быть использовать файловую систему которая его не требует да действительно несколько моих на ней на несколько из них поглядели подробнее всех наглости рф 1 значит не достаточной производительностью эти решения обладают на сегодняшний день настраиваются довольно сложно добавление удаления но до из класс тирану такая операция как бы сказать то получается то не получается в общем распределенные файловые системы использовать отказались ну-ка значит следующее что написано в учебнике что можно сложить в африке не только на файловую систему ну и в базу данных понятно да что у базы данных базы данных индексируется как захочешь отдельно мне лично нравится вот здесь не раз на этой конференции звучало что мы любим новые технологии я люблю старые технологии я люблю технологии которым 10 а то и 15 лет до такой вот субботы это проверенное временем технологии за этим стоит довольно простая идея в отличие от той же распределенные файловые системы чтобы понять досконально как она работает надо обладать некоторой квалификацией для того чтобы понять как работает субботы квалификации в общем не требуется это преподают в институте ну и индексирование что мне лично очень понравилось что мне лично нравится что я могу построить индекс пути по всему чему угодно там по позже в докладе я скажу почему мы построили индексы некоторые против нетрадиционный подход до файлики не принято складывать в базу данных приняты работать с файлами с файловой системы камис файловой системы ну и что будет когда у нас скопится 3 терабайта пользовательских данных и соответственно 3 разделить на по 6 у 636 миллионов файлов мы вы пока не знаем как доберемся посмотрим может быть нам придется придумывать новое решение но скорее всего нет значит из субботы и субд м ну все-таки я один наш команде ретроград поэтому мне пришлось потестировать кей вылью базы в качестве ну значит я знаком с кассандры и в естественный выбор и гипер ты был для того чтобы его потестировать сразу скажу что ничего у нас не получилась но тем ни менее гипер трибун и вообще key и value базы созданы под эту задачу хранить по ключу доставать они неструктурированные данные тем не менее тем не менее чуть позже про то почему не получилось да и до должны быть быстрыми должны быть быстрее чем традиционные реляционные субд с реляционными субд и проще они проверены времени и правда любой студент умеет поставить какую-то реляционную свободы ни одно так другую и настроить ее по мануалу из интернета гипер ты был оказался очень быстро и правда то есть я сейчас не помню цифр потому что давно это уже было в августе но очень быстро значительно быстрее чем решение на пост грехи и действительно очень гибок у него есть некоторые проблемы для нас но оставим потому что до проблема не добрались гипер ты был падает на большом количестве мелких вставок а у нас мелкие довольно вставки потому что мы вставляем в информацию астат стать информацию от файла м time размер и sha1 праша один будет еще речь оказался ну то есть правда у него у них гипер табло к конкретно есть проблема с фрагментацией памятью памяти гипер теперь думает что он использует там не знаю 100 мегабайт а в памяти в результате из-за фрагментация используют 500 не знаю как этому этому удалось но тем не менее это то что я наблюдал за троллинг приходе тонкий мир и все это известная проблема предлагается собирать гипер трибулуса правильным локатором памяти которые вот все делает как надо монотонности интересно покушение на сами с этим локатором не собирают ведь марсе он делает как надо вот вот это решение предложил я как настоящий ретроград позу нас действительно мы тестируем уже 15 лет это случайность я не знаю что я буду здесь уступать а что здесь будет под гнездом но тем не менее можно ли пузырь из почему из всех свободно распространяемых субботам предложили нам стрел интерфейс к большим объектом маску минут еще где-то еще на что-то я смотрел на ту она в поясе есть машины назад прототип на сложно до такой проект был на пару дней назад против напрасно . для того чтобы хендлер сразу в баню достал файле пилота его отдаленно целаканта есть него целиком из базы а отдаем сегодня вы не моими выпусками раз нас есть интерфейс стрим подобный то моего кусочками вынимаем на совсем так на самом деле мелкие файлики до мегабайта мы храним прямо в строке потому что тогда мы в одну операцию получаемой информации о том что файл есть если он есть то его контент большие файлы ну там размер вашего объекта в прогрессе до двух гигабайт но у нас таких нет у нас до 500 мегабайт файла кладутся туда но тем не менее вот новый прототип и боли что нам придется поэтому прототипу потом построить взрослую системы если окажется что сама концепция работает так вот не пришлось оказалось что возглас сокращена на первом написаны сотни строк кода обеспечивает все наши потребности там куда дальше будет об этом мы целиком выедаем гигабитный интерфейс нам не надо больше с одного сервера значит штамм это дало но по результатам после того как наши 6 миллионов файлов оказались в база мы обнаружили что вся эта информация именно ш1 все тот же сейчас объясню зачем он нужен в рано дефекации еще там некоторое количество плюс все индексы какие только мы построили по этим полям они все давай два гигабайта то есть они все ввезли в памяти сразу и в памяти же и остались очень удобно работают быстро то есть в sony вернемся к началу от чисто чего мы начали обход дерева значит 2 минуты формирование из полного полного списка имеющегося у нас файла противо тех самых че 6 часов плюс плюс возможность отсортировать сортира работает подольше чем длина ты начала меня возможность отсортировать дорогого стоит поиск новых файлов а также секунд если их надо секунд если их много на пол на голову на новых файлов уходит по моему три секунды на их поиск на соответственно после этого их можно начинать копировать синхронизировать чем она не получили синхронизации между двумя сервера нет как было вступала в секунду так она и осталась в этих серверов у нас дешевые сорта диски ну понятно та самая компания на букву х вот дешевый sata диски столбцов я была на что это 80 но оказалось что теперь они ставят немножко другие диски и теперь на этих дисках стою abs of map тем не менее вот сколько их есть столько их и есть сто файлов в секунду вот то что задаром вот теперь настало время новый протез сказать про ш1 про это не болезнь это способ зарабатывать деньги с каждый продукт сохраним его контрольную сумму для того чтобы в любой момент когда кому-то покажется что файлики побились в базе ну а кто же так не делает файлы по за не складывает недоверие к этой технологии присутствует так вот этот момент когда кому-то покажется что она поднялась чтобы она не проверите сказать нет не побилась вас махра от контента ш1 мы важно выяснить когда нам запихивают новый файл есть он у нас уже в базе или нет если он у нас в базе есть мы можем это не не запихивать можем просто взять соответствующую запись version as this version as нам досталось от другого не от ш1 от возможности создавать несколько записей с одним и тем же именем в таблице и быстро выбирать последнюю из них вот это без базы точно получается но тем не менее то есть обычно виртуальность реализуется с помощью 7 рингов на файловой системе у нас оно есть само по себе это то что нам досталось за даром это то что мы планировали что получим еще до того как это все попала в продакшен задача на дедупликации была поставлена решена в течение 2 часов задача на аверсе масть потребовало больше время я маску но тем не менее она была поставлена было решено о производительности собственно решения первый вопрос который который первое что говорят люди когда об этом слышат это же будет медленно медленнее чем на файловой системе нет не будет непонятно чего бы это был этому быть над медленнее чем на файловой системе на примерно так значит компьютер по на 16 гигабайт оперативной памяти а сейчас я не знаю там четыре ядра с hyperthreading были просто 8 не помню вот и два sata диск 1 ради которой можно обычный десктопный трэш вот и тысячу соединят больше просто я протестировал на 1000 1 гигабит загружены полностью 1200 запросов в секунду она отрабатывает это прошу проверить прошу заметить запросах и почему не к индексу который конечно у нас перед а почем стоит для того чтобы медленных то ли клиентов поддерживать подработать стабильная надо просто потому что я все это так настроил чтобы всю память который ему нужна она съела сразу при старте там стоит профорг стоит в макс кац понятно да чем я вот значит при этом загрузка цикла составляет 30 процентов загрузка дисков по оттоку составляет наше 10 процентов раньше понятно версия к любой загружал диски на 95 процентов 0 и соответственно отдача на этот момент становилась немножко трудный значит полагаться на нас не поломалось сколько моего не тестировали как бы мы его не тестировали дают мне понятно с чего бы ему поломаться технологии проверены и давно используемые значит здесь на хотите это результат из хеджа я знаю интересный коммент на них смотреть или не интересна потому что то что там написано я уже поговорил единственно что вот масса всяких файликах после того как мы реализовали version ность оказалось что этот контент который мы отдавали создаю мочи при можем попробовать отдавать с из базы просто потом в надежде на то что он за кэшируются здесь производитель нас немножко . паттерн трогая производительность немножко отличается здесь почти две тысячи запросов в секунду то есть здорово ножками починила так уже уже можем себе позволить и создаете сервера не ставить а поставить еще один сервер вот да вот загрузить добить не получилось если посмотреть то 18 мегабайт в секунду и все ну зато , назад и зато за пять минут мы отдали больше чем полумиллиарда нет больше чем полмиллиона хитов извините вот значит выводы которые мы сделали для себя состоят в следующем во первых надо было лучше подумать когда мы собирались построить систему быстрого создания файлов по шаблону нам надо было подумать что мы через год станем делать с шестью миллионами пользовательских файлов и что мы станем делать когда нам придется их клонировать копировать к нам придется по ним искать нам как-то вот у провал надо ними это важно еще десять лет назад даже 5 лобова пользователей столько данных чтобы управлением птенца что-нибудь ибо решала у нас все получалось на тогдашних компьютерах сегодня это не так вот который мы на греет душу лично и технологии каменного века они вполне себе актуальными сегодняшний день и способна решать современные задачи так унося это будет огромное количество вопросов потому что тема спорные и прежде чем платить этот поступок хочу предупредить о том что это история про то как управлять и хранить данные они пока подавать с тем как одна из проблем нет заданы и так первый вопрос как обойтись вообще не вопрос извини пожалуйста как но есть соответствующие функции в паз грехи использовать раздает который здесь не применимо ну потому что у нас компания на букву х с соответствующим оборудованием один сервер мы себе позволить не можем типа сначала потому что стыковка стыковки с индексом send файлом нету потому что я нет вкус гриша соответственно все файлы какие мы отдаем отдаем через память но ним посмотри у нас гигабитный интерфейс уже загружен то есть нам нам всегда нужен новый сервер еще один нам надо быстрее отличным проблема согласно чтобы ну пока не было сначала скачиваться актуальность данных на всех серов чем обеспечивается на самом деле такие тоже то есть колхозные методы на каждом из сервировка работает скриптик который обходит все и всех его соседей нас выбирается со всех соседей все те файлы которые отдали обновились его последнего посещения после чего их синхронизируют тоже такой ну так внутри часа было потрачено со всей обработка ошибок на этот скрипт мне стыдно об этом говорить но актуальность обеспечивается вот так следующий вопрос фабр эффект что будет если придут 1000 пользователей одновременно попросят один и тот же mail он закрыл он с первого же запроса запиши руется на самом деле что тысяч одновременных коннектов было написано на доске в ровности can act of конечно значительно меньше у apache там очень длинный бы club palm 3000 вот но всего apache работает 64 соответственно первые 64 для первых 64 пользователей файл извлекут в память после чего он будет модным именно и из памяти это будет стремительно и если это большой файл если это если это большой файл то тогда все будет как обычно с той скоростью которая по нарисовано на доске что прошу вас пройти по адресу следующий вопрос значит этот вопрос интересует людей уже которые вдумчиво подошли к докладу расскажу о том как файлы удаляются значит что нам нужен сделать можно удалить запись в таблице стад которая показывает на записи таблицы контент потом у нас есть скрипт из четырех строчек который пройдется по таблице контент и удалит из нее на самом деле из из одной строчки просто для удобства разбита на четыре который удалит все записи с таблицы контент в которых для которых нет соответствия в таблице стад напоследок во запустим вакуум и ло который удалит из таблицы с большими объектами все объекты у которых нет соответствия ни в одной из таблиц в базе это стандартная процедура то есть вакуум и ло стандартная а то что наша таблица контента она просто связано со стандартный суши нет такого что над людям по задали дать позадавать вопросы на шторах домой вас которого обязательно вместе со склада удалён да есть еще одна таблица я забыла об этом сказать собственно удаления файла начинается с помещение флага в таблицу удаленные у нас остановили счет диска момент тут буквально несколько вопросов саму а вот тут у аудитории еще один вопрос даваться будет так вот вопрос такой вы бэкап и как-нибудь делаете если да то как если нет то объяснить почему что особенно на делаем после того как и ввели эту систему в строй потому что у нас есть version насти у нас есть соответственно от ошибки оператора на защищает верность пацана флаг в таблице дэвид от от сбоев оборудования на совсе защищает duplicate дом был hetzner чем тесть если бамбук his не что я не знаю куда девать ударом об аде дело в том что hex на это хоть и компания на духах пока там этих буквах и по моему что ну да да я все знаю на на всей массы гора центра у вас там 10 лет на 18 zero то как они на буквах они постоянно мигрируют нам нужно две бомбы ну а если две то все да интересно подождите пока бесплатная система создают бесплатных сцене не бывает бесплатных систем ладно с нашим на должности которые они проектировали не я приоткрою тайну на самом деле компании сетов . это международная компания и у нас сервера не только на дата-центра дата-центре на букву х но и дата-центрах на букву а хорошо и вы будете решать вас закончится места на дисках когда вы вставите туда 10 у нас вообще над реляционной субд а нас есть такое файловое хранилище из неважно но на базе у этого файлового хранилища реализована как вы будете масштабировать это горизонтально вот вопрос хорошо дольки я отвечу дело в том что компания setup.ru оперирует с сайтами соответственно просто порежем хранилища по именам а имени и соответствующие запросы будут приходить сразу же на сервера по shorten ее кого-то минами вины так как очередной вопрос этим окажется не такой тест который означает время помещения файлов базу и он реплицируется между база этого времени там есть time stamp которая означает помещение файлов базу и к концу который означает помещение файлов это базу и вот как-то инстинкту мы определяем актуальность файла спасибо задать в кулак продолжаем"
}