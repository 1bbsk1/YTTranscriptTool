{
  "video_id": "YANolrn4PYc",
  "channel": "HighLoadChannel",
  "title": "Микросервисный фронтенд / Вячеслав Слинько (ЦИАН)",
  "views": 2754,
  "duration": 3173,
  "published": "2018-08-16T03:54:15-07:00",
  "text": "ok всем привет сегодня мы поговорим о том как мы разрабатываем frontend именно подходит микросфер нас frontend с то как мы его называем немного о докладе я буду рассказывать о том как мы это делаем буду затрагивать плюсы и минусы этого подхода то как мы это видим и в целом вообще все весь этот подход которые буду рассказывать он нацелен на то чтобы делать задачи и новые фичи быстро и качественно вот в таких условиях которых работаем мы а мы работаем в условиях следующих мы разрабатываем один большой продукт этому продукту уже 16 лет в большой истории всего над этим продуктом работает более 90 разработчиков и все они поделены на много различных продуктовых команд которые параллельно разрабатывают фича для этого продукта перед тем как перейти к непосредственно подходу о котором я буду говорить я немножко расскажу истории то какие в принципе вот подходы есть и можно использовать первый самый древний это разработка на готовых виджетах например джек вере скачал добавил ссылочку на этот виджет немножко походе вы все заработало можешь скачать любой виджет который есть и очень много но проблема в том что если мы начинаем эти виджеты как-то связывать как-то уже делать над ними собственную большую логику то это все превращается в код который очень сложно поддерживать и сложно ним разбираться следующий шаг это переход на разработку single page applications of это позволило делать уже настоящему большие проекты так же это дает возможность разрабатывать параллельно фронт-энд разработкой бэг-энда но все все равно сводится к тому что она ли поздно такой проект становится большим и очень сложным еще один подход это разработка через библиотеку компонентов начиналось это все для того чтобы конечно эти компоненты можно было переиспользовать в разных проектах разных сингл пиджак частью сложностей как вы есть по этого проекта выносится в этой воли отёку но проблема заключается в том что это либо библиотека получается только из каких-то базовых компонентов и не особо много сложностей выносятся из проекта либо и библиотекой становится этим проектом я все находится все эти блоки которыми мы работаем соответственно мы переходим перешли переходим к следующему подходу суть его заключается в том что мы делим весь наш проект на блоке простые фрагменты из которых проект собирается главное отличие особенность в том что они полностью и радикально друг от друга изолированы между ними нету жестких связей никаких что такой микро сервис что вообще называем этим словом на фронтэнда во первых это некий репозиторий один для конкретного блок отдельный в этом репозитории находится все что касается этого блока это и верстка это и стиле это из скрипты работы в браузере это это тот и pr который доставляет серверы рендеринг для этого блока и этот блок вот через этот и отдает как в описании этого блока в виде уже готовых чем или который можно взять там на какую пустую страницу добавить и он будет работать что же дает вот нам такой подход первое это то что соответственно кодовая база конкретного блока или конкретного сервиса резко уменьшается соответственно так как он очень маленький и он очень легко усваивается и помещается в голове разработчик разработчики становится понятно что как сделать любую задачу в этом сервисе и соответственно оценить задачу то как долго он будет и делать становится гораздо проще это позволяет также разделить некие задачи по поддержке система в целом на разные части например обновление какой-нибудь большой зависимости раньше могло приводить к тому что мы нам требовалось останавливать там какую-то про то разработку на какой-то срок пока мы все обновим чтобы не было конфликтов и всего остального сейчас же мы можем делать это порционно маленькими кусками и в принципе не блокировать разработку и диплом продуктовых задач также за счет маленького размера архитектура конкретного сервиса становится понятно в принципе любому даже там новому разработчику и новым приходящим разработчикам можно давать сразу какие-то задачи достаточно сложные для реализации конечно есть и проблемы первая проблема что многие фичи могут хотеть менять разные блоки на сайте разные сервисы соответственно вам необходимо думать о том как синхронизировать релиз этих сервисов что должно выезжать первым вторым и более того это может приводить к тому что вам необходимо будет разрабатывать эти сервисы учитывая что какая-то зависимость какой-то там опять например еще даже не выехал на бой а выйдет чуть позже предусматривать это иногда все таки приходится нарушать изоляция например у нас есть список объявлений на сайте их можно добавить в избранное хотелось бы конечно чтобы в шапке там где есть список избранного циферка обновлялась когда мы нажимаем на эту кнопку соответственно архитектура по умолчанию от если мы все полностью за леру им такого позволяет не может и приходится делать решение для того чтобы не портить using спирин с пользователем также если вот у нас блок полностью изолирован фрагмент изолирован и он зависит какой то библиотеки например react мы используем и другой такой же блок изолированный зависит от разжевали отёки то по умолчанию если мы просто добавим эти два блока на страницу у нас будет загружаться две копии 1 библиотеки на страницу что конечно же приводит к замедлению ее загрузки но как бы с этим можно и бороться и мы с этим боремся как чуть позже расскажу о том как мы это делаем как это работает и начну я сказ с примеры того как запрос пользователя начинает свою обработку на сервере во-первых запрос как есть попадает на некую точку входа . фонда мог бы быть обычный там и джинсы которые robotic запросы на нужный миг раз сервиса но мы разработали свой сервис и это связано с необходимостью как то умное это делать роутинг например у нас есть страницы которая зависит от тома типа пользователя и соответственно хочется в этом сервисе иметь эти знания ходить там выпей в базу данных и так далее и задача этого сервиса по всем входящим данном запросы определить какой же микро сердца запрос должен попасть и одна из будущих вич который мы хотим получить это микро сервиса это то чтобы притом каком-то обновление тепло и конкретного не маленького блока который как-то меняет роутинг он также менялся динамически без там необходимости пинать админов и сказать вот у нас новая ссылочка появилась там добавьте я за работе и и так далее после того как запрос был определён куда его доставить он доставляется так же как есть в следующий сервис который отвечает за конкретную страницу его задача собрать эту страницу из независимых вот этих блоков выстроить из него правильный лай out и обработать проблемы ошибки если они возникают например если какой-то блок на сервере отломался то мы можем его просто убрать со страницы если он является там неважным или не приоритетным либо если это там основной контент то соответственно всю страницу фейлим и отвечаем там 500 и лагером все это и этот сервис который отвечает за страницу он отправляет свои запросы вот в разные сервисы которые реализуют конкретные уже различные блоки эти блоки они принимают запросы уже не как есть от пользователя виде определенного и пей который описан в схеме и в этом пей мы избегаем передачи вот оригинальных данных например там юзер агента или ссылки потому что рано или поздно потому что в коде появляются какие-то iv и какие-то зависимости от этих данных этот код и этот блок уже сложно будет на переиспользовать различных частях сайт поэтому место визир агенты например мы можем отправлять конкретный тип устройства для которого нужно как-то изменить то как будет от блок выглядите так далее соответственно этот сервис отвечает не только за рендеринг он отвечает еще из-за все что касается работает во блока на клиенте то есть он раза даёт статику он раздает там стиле скрипты и так далее и на быка не делает запросы еще к api уже бы концом в итоге вот все таким образом через такую цепочку через такое дерево собирается в итоговую страницу при этом эти блоки эти фрагменты передаются пользователю потоково блок за блоком мы можем не ждать пока там отрендерится какая-то часть отдать то что находится выше на странице пользовались быстрее этого видит кроме того некоторые фрагменты страницы могут загрузок загружаться синхронно то есть без какого-либо стерна рендеринга просто так скрипт который сделает уже на клиенте запросы все заданными тем самым ускоряя именно серверную часть работы по генерации страницы проблему связывания фрагментов вот тот случай когда нам нужно обновить там шапку избранное из выдачи мы решаем с помощью классического pops up учитывая что у нас все все эти фрагменты они как бы плоски the pops up хорошо для этого подходит нету проблемы которым там раньше могла возникать когда мы делали большие приложения на событиях ничего не понятно что откуда такие события ходят вот но все-таки мы еще добавляем ограничение на эти события во первых они должны описывать то что произошло нечто должно случится после этого на и второе это то что эти события должны быть очень очень минималистичные там не передается какая-либо эта информация которая не нужна только факт того что чтобы случилось проблему дедупликации мы решая с помощью малоизвестные фичи вы пока вы покрыли суть заключается в том что мы можем отдельно собрать отдельной выборгской сборкой то что является общим независимости отдельные распространять и отдавать пользователям при этом выпад генерирует еще описание метаданные этого этой сборке что в ней содержится где ну там лежит эти метаданные можно передать другому в попу вот уже который собирает конкретно вот этот фрагмент и в таком случае этот фрагмент он как бы из своей сборке этих зависимостей удалит и будет использовать общий зависимость это все можно вот правильно настроив и правильно автоматизировав реализовать таким образом чтобы при тепло и зависимости подключались автоматически из максимально оптимального файлика откуда это нужно откуда-то можно вообще скачать следующее свойство которое мы получаем это быстрый deployment без какой-либо болен сейчас у нас есть монолит большой который еще работает и чтобы его чтобы выкатить какой-то новой фичи в нем мы во-первых планируем релизы мышь мы должны к определенному времени там следующего дня до 14 часов чтобы фича которым мы хотим что выехал на бой должна быть уже протестирована и готова вот для выкладки после этого собирается может это все в конкретный релиз собирается долго сборка проходит автоматические тесты проходят тесты всего интеграционного проекта проходит ручные теста некоторых задач и новых фич например и вдруг если началась какая-то проблема в одной из фич то нам приходится проходить это все заново выкидывать эту фичу либо ее до фиксировать пересобирать перед тестировать все таким образом вот вы написали код и ваша фича может доехать на будет там не через день через два даже непонятно когда вот соответственно за счет того что сервис и они маленькие и быстро собираются быстро проходит тест и по ним мы можем быстро их доставлять на бой можем доставлять на бой вплоть до конкретного коммита каждый коммент делаем тестируем собираем отправляем на бой и так далее соответственно это дает нам возможность экспериментировать делать новые фичи эксперименты то что любят проджект-менеджеры и также можем гораздо быстрее реагировать на какие-то проблемы которые там на bayou происходит какие барричини но это накладывает определенные требования и в первую очередь это требование к архитектуре и инфраструктуре обязательно наличие деплоя который работает без downtime а так как у нас будет очень много комментов очень много сборка очень много дипломов параллельно в любое время необходимо чтобы пользователь от этого никак не страдай также у нас должна инфраструктура быть устойчива к проблемам если там какой-то сервис 1 или instant сервиса 1 упал то у нас не должно падать ничего остального все страница должна уважать работать и мы должны узнать об этом что она упала или в браузере если какая-то часть отвалилась не должен весь вся страница ломаться и также инфраструктура должна масштабироваться так как у нас вот как только возникает желание делать все маленьких сервисах они очень быстро начинают появляться новые админы сложные будет следить за тем как быстро не появляется и соответственно in структура должна быть заранее уже готова к тому что нужно ей масштабироваться как мы добиваемся этого сад для начала мы реализовали шаблон проекта который мы можем использовать создавая микро новый микро сервис для того чтобы убрать вот всю лишь не ненужную работу этот шаблон он содержит все что нам нужно от конкретного сервиса будь то то как он собирается или тепло и ца будь то все необходимые требования к лагера ванию сообщений ошибок там телеметрии всякой информации о скорости работы и так далее и этот шаблон на самом деле это не какой-то buller плед который мы копируем из проектов проект это на самом деле библиотека который мы распространяем через mpm которым мы обновляем поддерживаем но по сути это такой набор библиотек минивэн work который реализует вас всю базовую логику собираем и все ну я уже упоминал через вы пак мы запрещаем конкретным сервисным кастомизировать эту сборку мы реализуем ся вот в общем вместе в шаблоне необходимо это для того чтобы во первых можно было внедрять фичи новые в этот шаблон без необходимости все во всех сервисах менять и поддерживать это во вторых чтобы ну да в общем для того чтобы нормально все это поддерживалась и обновлялась и для того чтобы реализовать тепло и без дон тайма мы добавляем всем файлам которые генерируются время сборки браузер нам уникальный хошимине соответственно если после впадает там на какую-то новую версию или старую версию то он точно попадет и скачать этот файл клиентский который совпадает с версией которую отдал серому страниц диплом мы все через такие инструменты как докер консул нам от и задача для того чтобы вас на бой проходит несколько этапов первый этап это тепло и надев и тестирование надев где мы тестируем конкретно этот сервис то как он работает то как реализована эта фича в этом сервисе поставок это прошло успешно это все уходит на некий station где уже настроено грубо говоря копия боя где уже интеграционный все сервисы между собой правильно связаны и там мы тестируем то как этот сервис работает уже в каком-то контексте например контексте странице конкретный где он используется и после того как это все уже пройдено все тесты пройдено мы решили плыть на бой мы диплом через на мат через стратегию которая называется blue green то есть мы сначала все подготавливаем все машины новые все инстанции сервиса убеждаемся что они все работают потом моментально switch-ем стороне что новый для пользователя это проходит мгновенно без каких-то либо проблем третье свойство которое мы получаем вот наши системы это локализация проблем в конкретном сервисе в конкретном месте в первую очередь дает нам то что если что то где то сломалось то это не влияет на всю систему целиком например если на сервере сломался серный рендеринг какого-то блока мы его просто исключаем если на клиенте как произошло это исключение этого но не affected всю страницу целом что часто наблюдается там в сингл пиджак а не знаю я раз несколько месяцев захожу на кого это сервис и там просто белая страница потому что какой-то 1x epson случился и это дает нам еще возможность деплоить и наши новые фичи тестирует только вот эти фичи не проводя полноценное тестирование всего приложения так как мы уверены в том что она не affected какие-то соседа не соседней странице среднем блоки и так далее если какой-то разработчик и за использовал новую библиотеку которая очень много весит например то это также не affected всё весь сайт всю страницу все приложение целиком оферте то только конкретный блок ну и до конкретную страницу где этот блок находится и кроме того понимание вот что в каком блоке есть у нас проблемы нам позволяет приоритизировать правильно от работы по оптимизации делать конкретно то что именно важно там учитывая молярность этого блока учит его полярность этой странице и так далее микро сервисом также нужен хороший мониторинг может учиться такое что какой-то непопулярный микро сервис если нет мониторинга может иметь в себе какую-то проблему и мы об этом будем долго не знать не реагирует ни соответственно вот в такой архитектуре когда у нас много сервисов хороший мне the ring просто жизненно необходим и также мониторинг должен масштабироваться мы релизе им часто новые сервисы новые сервисы начинает слать новые данные в мониторинг и без от без закладывания того что у нас будет появляться очень много сервисов и много логов но это не просто будет лежать все это время как мы реализуем вот работу с ошибками работу с мониторингом во-первых мы собираем все ошибке собираемых как с сервера так и из браузеров есть например готовая система называется центре она дает библиотеки одном и пастбища на серваках одно мы подключаем на клиентскую часть блоком и эта система перехватывает все ошибки в которой происходит на странице и отправляет их вот в некий сервис который все агрегирует представляет дополнительной информации метра информацию и также эта система например поддерживает source map и то есть отдавая пользователь инфицирован исходники если не происходит ошибка мы будем видеть где-то ошибку в конкретном коде происходит и эти 100 см об и более того не привязаны к версии то есть все очень хорошо но недостаточно просто сделать мониторинг ошибок необходимо еще правильно научиться на них реагировать например когда мы вот первый раз подключили сбора ошибок с браузеров мы получили огромный поток ошибок там непонятных которые вообще могли быть без сообщения какого-то или на русском на русском языке там интернет эксплорер что-то пытался нам рассказать биссектриса вот нужно правильно поставить процесс чтобы во первых не заставить себя этим ошибкам во вторых реально решать проблемы которые есть у пользователей знаю что пользу не всегда жалуются если происходит проблема могут просто уходить так же мы собираем все кроме ошибок быть то сообщения будь то описание каких-то произошедших произошедших событий в системе различные метрики там производительности все это тоже собирается как сервера так и из браузеров и все это складируется в различные базы данных и мы это все анализируем также для понимания того где у нас есть проблемы на чем нужно работать и так далее например с браузеров мы собираем данные с использованием новейшей тайминг и пей и дтп предоставляет информацию о том каким как загружалась страница у пользователя какие были этапы загрузки сколько каждый этап занял временем и каждый вот загрузку страницы пользователя и то как она загружалась как хорошо или плохо мы отправляем на сервер и сохраняем после чего анализируемый понимаем что у пользователей сайт работает там не в 2 раза медленнее чем на моем макбуки не в три раза медленно и может быть даже на порядок или там на полтора по явка медленней это очень такой неожиданное было именем следующий по которым мы используем очень интересно это юзер тайминг теперь он предоставляет возможность мониторить время которое тратится на какие-то конкретные процессы там мы покрываем например во первых только грузится страница не на основе предыдущего и 5 какие-то блоки дом интеллекте в дом ради и так далее а уже понятно и нам например вот это время которое там скачивался этот скрипт это время которое там реактор рендерил это время ушло на то что там все картинки подгрузились и так далее и анализируем уже их анализируем понятные нам метрики и того чтобы понять как хорошо работает конкретный сервис на конкретный страниц также это теперь предоставляет доступ к внутренним некоторым метрикам браузера например храма дает нам информацию о том когда произошел повисла 1 отрисовка страница для пользователя в какой момент времени он увидел какую-то картинку начиная с момента когда он нажал enter там в браузере или в этом пия хранится в информации о всех запросах ко всем а сетом ко всем и пиарим который просто из браузера сколько времени заняли эту информацию мы также мы собираем отправляем на backend и можем понять что например какая то какой 35 на сервере мы видим что там занимает не знает 100 миллисекунд ответ она клиенте секунду что это значит не знаю например то что у клиента плохой интернет вот еще этот это и очень хорошо использовать для уже непосредственно отладки производительности потому что он интегрируется в chrome dev тут вкладке перформанс мы можем увидеть не только вот метрики которые есть в браузер и там стектрейсы java скриптов или момент отрисовок а вот эти вот метрики которые мы самостоятельно добавили отметив какие так понятные нам блоки и процессы в приложения кроме этого в докладах про микросфер устная культура бэг-энда часто упоминается что необходимо отмечать помещать как-то запросы пользователя и этот индикатор отправлять прокидывать через все сервисы на бэг-энде которые работаю для того чтобы дать ответ для того чтобы мы понимали там вдруг если запрос был медленно почему он давно не какой сервис сделал его медленным какая там запрос базу данных деловым медленным вот мы конечно то реализовали но кроме того мы этот индификатор отправляем ещё и клиент в браузер таким образом мы можем посмотреть то как страница работала для конкретный запрос пользователя работал начиная от самого первого момента как он нажал enter заканчивая загрузки всех ассетов браузере и как долго работали дальнейшее его действие на странице там какие-то бизнес процедуры которая там кнопочки нажимал и так далее все это можно связать и построить виде диаграммы проанализировать в итоге что мы получили вот делая такие независимые микро сервисы и разрабатываю подобно яхте тура мы получили то что они эти сервисы маленькие соответственно мы можем разрабатывать быстрее понимая что где надо сделать мы получили быстрый continues deployment и соответственно все наши фича доезжаю до пользователи быстрее пользователи рады и продукт менеджер и рады что могут делать какие-то эксперименты и мы сделали так что проблемы который возникает системе во-первых они не влияют на всю систему сразу влияет только на конкретные части и мы сразу понимаем что это за часть и как с ней что с ней необходимо дальше делать мы получили следующие проблемы то что эти сервисы они как бы изолированные но иногда связывать их нам надо и соответственно об этом надо как-то отдельно думать нужно избавляться и тратить на это ресурсы от дублирования нужно разрабатывать эту систему чтобы ресурсы загружались максимально оптимальна для пользователя это что в целом вообще вся инфраструктура вас в плане там бэг-энда или архитектура в плане понимания того как все это в целом связано становится сложнее и соответственно нужно специально люди которые будут об этом думать почему же это вообще для нас подошло для понимания так как у нас много под команд продуктовых которые занимаются одним проектом параллельно теперь вот с помощью этой архитектуры они могут делать это не блокирует друг друга тот пример который я говорил про релиз монолита если какая-нибудь команда допустила ошибку это не влияет на фича другой команды они просто их deployed соответственно доставка фич для этих команд стала быстрее и это то чего мы хотели добиться в первую очередь и мы от этого не страдаем в плане если это шип какая-то проблема произошла то мы понимаем кто за нее ответственны кто и чинит и как и это еще работает потому что у нас есть ресурсы для того чтобы реализовывать вот эту идею архитектуру в нашей компании что можно сделать дальше дальше можно прочитать о таком проекте как мозаик вот компания zalando это очень похожая архитектура вот но в отличие от нашей у них есть ли какие то проекты в source и можно них посмотреть почитать возможно даже за использовать и есть еще больше там статей и докладов которые тоже могут служить дополнительной информации все ссылочки будут на последнем слайде можно будет скачать презентацию и по кликать по ним как бы стоило начинать вот внедрять такую архитектуру во первых стоит попробовать сделать конкретно вот один фрагмент один маленький блог сделать его как отдельно сервиса салин repository в отдельном репозитории там со своей сборкой и попробовать интегрировать на какую-то уже и существует существующих страниц например там в монолит куда-то внедрить и посмотреть вот то как вообще выглядит как конкретный вот этот блок его размерность подобрать там под под свой проект дальше следующим шагом можно сделать какую-то одну страницу полностью целиком состоящую из фрагментов тот сервис который занимается сборкой страницы как я рассказывал ранее и после вот этих экспериментов можно уже задумываться и нужно задуматься о том как бы это все стандартизировать какие шаблон из пользователи делают свой и так далее на этом в принципе все спасибо вам вопрос 1 раз престо вопрос есть смотри куда я здесь вижу следующий вопрос как во первых кто вас не ценит сервисы каждая команда команда тату спилил service to time in the new да и лёшкой довольно команда которая мой день интервью если говорить про вот сервис и продуктовые вот эти микро сервиса туда-то команды которые издавал это сервис она его поддерживает в том числе на его обновляет если есть необходимость решает проблему ним и так далее какие а если сервис нужен для нескольких команд мы и стараемся во-первых сделать так чтобы у разных команд были свои сервисы если это невозможно но например не знаю там какая шапка то есть путь что один сервис используя другой сервис для того чтобы строить там часть себя тоже мы изолируем либо если совсем не получается то этот сервис он как бы закреплен за конкретной командой так скажем так который больше вклад него делает вот но при этом туда есть возможность комитете другим командам вот а есть некая стандартизацию вас автосервиса последний слайд про стандартизацию ну например то что есть у вас get описание что сервисы себя представляет как он должен выглядеть с кем его там согласовывать например если это соседний команде хотят сделать что-то аналогичное time говорят смотри чуваки у нас есть уже такой сервис вы или использовать его или ну например без вариантов использовать его просто безопасно дарте зации у нас есть во первых на основе шаблона то есть в нем заложены все требования к сервисам то как он должен работать как он должен быстро работать как он должен качественно работать там логирование все эти вещи соответственно создавая сервисы ты уже используя все эти стандарты и используя шаблон является обязательным для создания novaservis если говорить вот про стандартизацию какую-то уже с точки зрения бизнес задач решаемых этих сервисов то ничего какого-то конкретного инструмента для этого нет просто все все знают о том какие блоки есть на сайте и если им хочется как-то с этим блоком работать они с ним работают если не хочется они делают свой блог то есть принципе скажут like определенное количество копипаста вообще не пугает то есть то что там каждая команда будет запиливать за сто пятьсот своих аналогичных блоков из своих аналогичных сервисов ну это зависит от их похожести вот в принципе не особо пугает то что да они сначала скопируют его но в итоге они все равно будут развиваться параллельно и в разные стороны скорее всего и это ещё даёт нам то что мы избавляемся от каких-то участках кода в которых сто пятьсот и fav потому что все команды хотели в этот в 1 место что свое добавить какие-то свои хотелось у вас нет какого-то определенного человека или команды которая отслеживает изменение то по сервисам и говорит смотрите но вот есть сервис он вдоль вылезем на так и не надо копировать крепость потому что здесь например изменения могут быть незначительные вот и зачем нам три например микро сервиса которые будут выполнять одно и то же по факту но там буквально отличаться не знаю там марджи намибия между какими ультом in the dome но на такое уровне у нас нету какого-то отдельного человека тоже не занимается потому что мы все таки не супер большая компания вот и достаточно понимание у каждого что где примерно есть и что как выглядит как работает такие все пасибо мне все расскажи пожалуйста сколько у вас сотрудников компания небольшая компания тех кто занимается разработкой я упоминал вначале более 90 человек а вот людей которые войти отделе а которая связана с разработки а сколько все таки на данный момент различных микро сервис от вас есть же библиотека в и наведите re ну как бы реестр сервисов если говорить вот фронтэнда вай части то есть исключая бэг-энда выпей которые в принципе на другие докладах обсуждается то фронтэнда вых ну где там больше 20 по моему вот при этом мы начали этот подход использовать где-то где-то полгода назад чуть больше наверно но тогда понятно когда вы отвечали на предыдущие вопросы коллеги но когда у вас их станет 150 когда станет тогда мы будем решать эту проблему спасибо за выступление те же самые вопросы мучили мне уже ответили на вопрос что такое о чем отличается от видится в подходы которые вы в начале упомянули не получается и так что вы вернулись назад в к первому шагу у меня был пункт вот на этом складе про микро сырую что это очень похоже на виджеты единственное такое корневое отличие в том что во первых это все изолированно друг от друга во вторых это и салливан не только на уровне вот только браузера что у нас java script и изолированы но еще на уровне сервера потому что серный рендеринг является от одной из наших требований ко всем этим фантомным сервисом поэтому это ну вот в этом есть отличие а сколько у вас именно фронте от разработчиков и сколько команд насколько разделена front-end разработчиков немного 10 штук вот команд команд в которых есть frontend разработчики два три 4 5 а раз серверный рендеринг можно тоже спросить вот о странице рендерится на сервере те которые редко меняется если страница часто меняется под каждого пользователя там насколько это эффективно рендерить на сервере ну то есть там кэшируется же да получается у нас все по умолчанию рендерится на сервере если мы видим что этот блок он на серы например медленно рендерится и он не является обязательным там на прием он не сверх находит страница снизу то мы делаем клиентский рендеринг как я говорил синхронный то есть только так скрипт который там уже на браузер и все реализует еда в некоторых местах у нас есть кэширование вот на уровне сервиса который отвечает за конкретную страницу разборка есть частей он может реализовать кэширование конкретного блока ну вот на примере главной страницу на заказ и равана все кроме шапки где пользовательские данные есть соответственно мы отдаем ее быстро а еще такой просто точки зрения дизайна если разные команды рисует на разные margin и в этих шаблонах то есть вы отказались от библиотеки компонентов вам это сейчас не мешает нет ли требования чтобы все было согласно строго по дизайну во-первых дизайнеры у нас работает как отдельная команда они нас нет дизайна в каждой команде на данный момент поэтому проблемы с консистенции зайна и не решается вот на этом уровне с дизайне между собой понимают что они делают если говорить паблик про библиотек компонентов то мы от нее не отказались у нас есть библиотека которая но она это не библиотека у нас есть компоненты базовые совсем базовые там кнопки input и вот эти и каждый из компонентов это тоже 1 га территории один пакет а как version ность поддерживайте всего этого какой-то все контролируется чтобы она там не расходились версии чтобы одно что-то ушло другой не поломался version ность если говорить про конкретный пакет то есть библиотеки то там просто silver просто релизы потом на уровне сервиса нет никакого жесткого требования чтобы если там за визой новые кнопка все должны на ментальном на лица все обновляются постепенно мы с этим согласны мы на это идем и следит за этим процессом во-первых команда дизайна они смотрят затем как выглядит наш сайт в итоге и они ставят задачу там на обновление какого-то компонента в каком-то конкретном сервисе если видит что в этом есть необходимость спасибо привет у меня вот мне интересно как решается у вас одна простая задача вот если к примеру у авторов одного сервиса есть задача к изменениям в другом сервисе как реализован в этом случае процесс ставится ли задача команде сервиса в котором нужны изменения либо у заказчиков есть возможность некоторого такого консорциум вмешательства в сервис другой другой команды и как в этом случае реализуется релиз кто отвечает за него да мы идем по подходу когда каждая команда может комитет в каждый сервис требованием дополнительным к этому является то что этот парик вес должен быть обязательно от review in о той командой теми людьми которые это сервис оригинально делали чтобы понять что как оно соотносится с тем что они вкладывали вот конкретного архитектур этого сервиса до соответственно от некоторую получить при review ну и плюс до того же вообще начать разрабатывать просто человек подходит к разработчикам сервиса говорят я хочу пить фичу запилить какие нить особенностью расскажешь как мне лучше сделать если говорить про бизнес процесс то задача если это необходимо сделать вот одной команде чужом микро сервиса то эта команда отвечает за релиз этой фиче добоя и за качество спасибо добрый день спасибо за доклад вот есть такой вопрос а как происходит взаимосвязь между сервисами и как происходит вставка этих сервисов я просто объясню допустим у вас есть некие layout вы кликаете на что-то и вот то что загрузится это будет другой сервис как происходит коммуникация и как происходит вставка вот этого 2 сервиса они происходят при загрузке страницы сразу либо после клика имеется ввиду в браузере уже до в браузере браузер уже приходит как бы готовила я у заготовленные от рендерингом блоками на сервере и browse это просто каждый блок инициализируется и подхватывает определяет логику этого блока то и смогли извиняюсь то есть вы сразу загружаете все что потенциально может быть открыто по папе или как-то отображено браузером я правильно понимаю или это динамическая загрузка но большая часть страницы до загружается сразу если говорить про какие-то попапы и что что совсем асинхронная то это уже реализуется на уровне сервиса если он хочет открыть попап то он может ее выделить там с помощью в папских вич в отдельный блог и там при клике скачивать дополнительные скрипты стиле и так далее но общего решения по этому поводу нет то есть присутствовать динамическая загрузка да конечно присутствует а вставка происходит просто показывали что ты css свой и скриптовой файла это все вставляется в учит или какую-то часть кода но мы экспериментировали порадую мы по разным экспериментировали но вообще блоки вставляются туда где они должны быть чтобы как бы от рендерилось там так как надо если говорить про стиль это сейчас они оставляются всех head мы пробыли вставлять их перед конкретным блоком чтобы у нас как бы не надо было скачивать все css и перед тем как антенна дарит первый блок но это плохо работает фаерфоксе например он мигает не стилизованным контентом иногда кроме это работает отлично он понимает этот подход и соответственно он рендерит блоки по кусочков вот и сколько знание дальше будут работать над тем чтобы это стало еще лучше спасибо скажете вы говорили про роутинг да и что можно его сделать на их женщину вы запилили свой роутер и получается что эта единая точка отказа правда да так и есть если он упадет the sun как бы не будет работать так и есть вы его масштабируете как-нибудь конечно а как образом как engine просто много разных инстансов так как этот сервис он стриппластика состояние можно масштабировать легко непринужденно там хоть на сотни машин и это такой же сервис да как и все остальные сервисы по та же технология , у него есть конечно отличие вот именно тем требования которых не определяется потому что он принимает запросы как есть от пользователя и возвращает ответ пользователи также вот как он его ожидает то есть там ретривер xbox получает спасусь и да по сути да я говорю что это то же самое как engine только с нашими док фичами которые мы не захотели вынужден встраивать понятно а как осуществляется собственное управление роботами они и в каком виде женщина пример это прокси посада или там чем стёпа этого а у вас как это делается сейчас это сделано вот императивным образом самом этом сервисе то есть мы описываем что то есть url то какой то до определенной ну там используется мы написали его на ноги там express и вот если это тур мочиться то мы делаем описано что мы делаем запросы к этому к этому к этому собираемых таким образом мы отдаем пользователи то есть от прокси пост у кого что куда большим и вот хотим сделать чтобы эти роботы определялись динамично декларативно в конкретного сервисе и потом каким-либо образом она регистрировалось про она регистрировалась в нем и сразу подхватывать без необходимости комете перелететь и так далее да и последний вопрос у вас микро сервиса сами масштабируются конечно на уровне собственно роутинга вы как это ну решаете но я упоминал что мы используем консулу и соответственно он решает в конце лондона уроки спасибо еще один вопрос так привет я такой мне такой вопрос как вы работаете с данными каждый сервис они данные в себе если да то как происходит взаимодействие между сервисами если например другому союз и нужны данные от того solus если говорить про клиентскую часть да да та они также полностью изолированы нет никакого общего старое так далее соответственно если разным сервисам нужны одинаковые данные то они скорее всего дублируются в этих сервисах у нас не не используется rest у нас конкретные 5 конкретные отдают данные для конкретных блоков вот и соответственно таким образом мы с ними работаем а если данные были одним союз модифицированы и мне нужно обратиться уже к тем данным которые уже модифицировались но если это вот такие простые случае которых я рассказывал типа избранного то мы решаем сможешь событий если ты это сложный случай типа много различных данных меняются и так далее то с такой проблемой сейчас мы ещё не сталкивались но есть идеи как ее решать будущем спасибо спасибо вячеслав к сожалению у нас не хватает времени для того чтобы вы задали еще вопросы поэтому вы свои вопросы можете дать лично вячеславу не аудитории спасибо"
}