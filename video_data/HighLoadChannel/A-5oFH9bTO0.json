{
  "video_id": "A-5oFH9bTO0",
  "channel": "HighLoadChannel",
  "title": "Машинное обучение в продакшне – это просто! Нужно только... / Михаил Марюфич (Одноклассники)",
  "views": 1304,
  "duration": 3183,
  "published": "2021-10-04T02:45:36-07:00",
  "text": "привет меня зовут миша я работаю инженером по машинному обучению что это значит разрабатываю мать решение внедряя их продакшн и вообще-то много усилий трачу на улучшение инфраструктуры работаю в одноклассниках это крупнейшая одна из крупнейших россии социальных сетей там более чем 40 миллионов пользователей которые довольно активно пользуется сайтом и с точки зрения железо одноклассники это более пятиста сервисов которые за тепло и на почти на 10 тысячах машин 6 дата-центрах каждый день генерируется более 24 терабайт новых данных в общем настоящий пилот но говорить мы будем михайло die hatte на такой конференции присутствием абум или почему у нас в мыле большая экспертиза и не просто так мы его используем для множества задач от рекомендации постов групп музыки друзей и многого другого до таких приложений как защита пользователей от неприятного контента и распознавания лиц все это не просто так все это для того чтобы увеличивать части пользователей чтобы они получали больше удовольствия и всего у нас более 100 моделей который мы постоянно поддерживаем и развиваем какой будет стиль повествование в этом докладе о чем будем говорить мы на примере одной из наших задач и рассмотрим как может выглядеть вполне себе работоспособный продакшен если мы пойдем по пути минимального сопротивления или это просто и почему это не работает если у нас есть много моделей которые нужно поддерживать и немножко ответственности начнём с видения в каком сервисы мы будем водить эмаль это сервис рекомендации многим знаком такой сервис в социальных сетях кто пользуется это место где мы показываем самый интересный контент среди всего контента одноклассников которые нашли персонально для пользователя и моль задача какая основная среди более чем 11 миллионов источников это авторы и группы найти наиболее интересной для каждого пользователя что такая задачка как работает productions вообще схема его такая абстрактное более менее у нас есть сервис офицер комендор который реализует бизнес логику построения ленты рекомендаций у нас есть сторож в котором хранятся уже заранее заготовленные рекомендации для каждого пользователя пользователь заходит на сайт сервис достает рекомендации стороны загружает нужные посты строит ленту показывает пользователю он счастлив вот так просто это работает сторож в качестве стороны мы используем свою разработку для нас он сейчас будет как черный ящик но вот он работает мы его как используем он умеет очень быстро втягивать данные с кафкой отдавать данные по ключу фронтами это у нас играет роль в час тора моего используем для хранения различных отключился меня различных вещей ну и можем там также сохранить список рекомендуемых групп виктор интересов пользователя и другое и так зафиксируем чтобы показать пользователю рекомендации чтобы это все работало в продакшне и нам нужно просто сделать так чтобы в хранилище по нужного юзера иди были записаны нужные рекомендации вопросы немножко риторически где же тут имел где тут эмаль m-elle стоит немножко в стороне это схематический какой-то процесс который делает так чтобы эти рекомендации там появились и малия по конец давайте разберемся как он может там появится на слайде вы видите схему как вообще работает разработка в m-elle как сделать и male model is и доставить его на продакшен у нас есть специалист по машинному обучению которую мы выдаем задач улучшить систему рекомендаций затем он собирает данные используя технологию apache spark потому что у нас более 80 петабайт данных находится там нужны какие ему хочется для решения этой задачи затем он применяет свои математические знания и современные питоновские пакеты такие как python и придумывает какую модель он будет разрабатывать он и разрабатывает используя мощные development окружении с видеокартами с множеством оперативной памяти все такое в общем рай для the scientist а какое то время он на этом этапе проводит и затем наступает такой этап когда он решает что модель пара доставят на продакшен и он каким-то образом доказывает бизнесу что вот модель получилось хорошее смотрите метрики оффлайновые такие если мы это выкатим то мы заработаем ну там несколько миллионов столько-то денег он строит отчет доказывает с тем что нужно модельку деплоить и казалось бы наступает модели момент когда модель нужно за тепло и что значит за деплоить это сделать так чтобы она работала в продакшн окружении правильно ну наверное а нужно ли нам вообще это делать давайте подумаем наша цель сзади плоть модель ну нет у нас нет такой цели наша цель это не за деплоить модель а сделать так чтобы пользователи стали счастливы как можно быстрее вот прямо сейчас а лучше ещё вчера до путь до счастье пользователей разрабатываем хорошую модель она начинает выдавать классные рекомендации пользователь счастлив будь прямолинейно ведет тому что модель нужно за деплоить но а как проверить что рекомендации классная такими траки оффлайновые которые эмаль специалист получил она на самом деле в задаче рекомендации но не так чтобы ролик единственный нормальный способ проверить заходят рекомендации или нет это взять и показать их реальному пользователи мы можем это сделать давайте посмотрим на схему на свой продакшн и поймем можем или нет вполне себе я как и мой специалист беру формирую файл с предсказаниями где по юзер айди записано список итоговых рекомендаций беру и руками заливаю для четверти пользователи эти предсказания зачем чтобы провести абэ чтобы посмотреть насколько пользователям она нравится поддержали этот обед с недельку и получаем результат знакомьтесь результатом результат отличный ключевое здесь плюс 15 процентов ко времени с по секрету говоря такой результат достигается достаточно редко и для нас это сигнал что модель действительно хороша и какое желание у всех сейчас возникает но сделать так чтобы эта модель баттлы не на четверти пользователей да вообще на всех чтобы этот результат он был зафиксирован так сказать и что нам нужно сделать чтобы все пользователи получили этот результат как вы думаете если у меня способ сделать так чтобы рекомендации стали доступны всем вот прямо сегодня поднимите руку кто считает что да я могу сделать это прямо сейчас ну на самом деле да мало людей подняли руку почему-то а мне что запретит кто-то то есть я просто беру и уже для всех пользователей заливая предсказания модели руками и что что я получаю ну и сразу же на продуктовых графиках коих у нас много я вижу что стало плюс 14 времени сильно выросла лайки в общем пользователи все все 40 миллионов стали намного счастливее то есть и результат какой у меня сейчас достигнут в этот момент все счастливы пользователь счастлив потому что вы рекомендации стали намного более интересные машины ник инженер счастлив потому что он разработал хорошую модель и его менеджер счастлив потому что ему удалось презентовать классный результат вышестоящему начальству и все бы ничего все хорошо в этой счастливые картине но есть один нюанс рекомендации устаревают то что мы показали пользователю сейчас то что ему понравилось то что привело к приросту совсем не факт что таковым же останется через неделю через неделю ему уже наверное ну не котиков захочется смотреть а может быть собачек что-нибудь другое и по идее наша модель она может быть к этому адаптивно и рекомендации нужно обновлять ну хотя бы раз в неделю абсолютный минимум лучше почаще но нужно обновлять хотя бы раз в неделю и на самом деле мы незаметно а может быть и заметно перешли к проблеме проблеме которая звучит так эта схема которой я писал за схема которая может быть вызвало кого-то отвращение она будет работать оно будет работать прекрасно то есть никаких видимых проблем не будет но так скрыто для поддержания работы продакшена потребуется ручные действия где то раз в неделю если у вас какой то маленький сервис небольшое число модели 1 2 3 то вы вполне себе будете жить довольно долго с такой схемой и это такая беда но когда модели много то очень сильно возрастает вероятность пока по я думаю понимаете о чем я говорю как пример пока по расскажу историю вот ваш линк инженер другой также проводил эксперимент точно также залива в предсказании в базу и он получил уже ну не такой замечательный результат плюс 15 процентов а минус 20 и вывод не очень хорошую модель разработал а на самом деле было просто бага в коде и сколько таких ситуаций может возникнуть это на этапе эксперимента сколько более невероятных ситуаций может возникать дальше поэтому мы приводим приходим к идее логично что нам все таки нужно за деплоить модель нужно для чего но не просто так а чтобы обеспечить именно стабильное поступление хороших рекомендаций как мы можем это сделать но сразу разберемся что за модель как она работает эта модель нейронная сеть принимает на вход различные фичи такие как пользоваться я активность так не носить его друзей на кого он подписан различные характеристики пользователя такие как пол возраст и многие другие виды признаки источников и на выходе она возвращает вектора пользоваться их интересов кстати внизу приведена ссылка на классную статью от нашего ведущего специалиста по не растем рекомендации можно ее изучить дальше про математику ничего не будет но это онлайн на сайте highload так от нерон очки мы получаем вектор пользоваться их интересов который потом используем как кроме вектора пользоваться их интересов есть также вектор источника то есть автора или группы мы их сравниваем по какой-то по кому ты расстоянию например костному и чем ближе тем выше вероятность того что ему этот источник понравится чем дальше тем меньше такая вероятность соответственно берём те которые поближе еще один момент который стоит учитывать это нейронная сеть и для использования нам понадобится видеокарта потому что иначе ну довольно медленно получается затем разберёмся с тем что сейчас делает этот специалист чтобы в этой нашей схеме чтобы доставить рекомендации до продакшена у него есть инструмент какой-то интерактивный в котором у него написан способ поставки модели не моделей результатов ее предсказания на продакшен как это работает но в первой ячейке считываем данные которые необходимо подать на вход нейронной сети также мы изготовим все это с помощью спарка конечно же работает затем сохраняем наш dfs далее ну потому что ему так удобно мы идем на специально выделенную машину где есть видеокарта заходим в определенную папку где лежит код и файл с моделью и получаем пользоваться интересы там запускается inference нейросети и заливаем результат предсказания куда-нибудь наш dfs ну и затем последний этап когда мы считаем уже итоговые предсказания то есть соединяем виктора пользоваться их интересов и интересов источника и получаем список рекомендаций которые нужно залить базу и заливаем ее в базу какие недостатки можно выделить в этом процессе ну конечно же целую кучу но давайте обратим внимание на ключевые самые абстрактные это она не под контролем система контроля версий на него никто никогда не смотрел а зачем зачем они усмотреть если метрики плюс 15 процентов я вам скажу да ну незачем смотреть на самом деле стоит посмотреть и это решение она нестабильна в первую очередь то есть если все работает без ошибок то как бы ну и так сойдёт а вот если где-то в середине допустим тачка отвалилась где лежал длинный за комичный год то уже как-то вот беда то есть пользователи будут несчастливы они не получат свои рекомендации сегодня и вот такая ловушка поэтому мы автоматизируем этот процесс достаточно очевидно понятным правильным способом и просто переносим содержимое этого ноутбука в spark of ski & joe бы и пройдемся по этапу итак первый этап подготовить данные для не рамки с парков ская jobo далее получить вектор интересов используя не ромку запускаем контейнер в системе регистрации контейнер стандарте который быстрым год он все интерет на хорошей машине затем опять на спирте получаем итоговое предсказание и на вход это джеба берет файл с модели уже который ds разработал и виктора источников и заливаем предсказания в базе наконец этапов много ошибиться можно в каждом он и они об этом в общем мы это все review им этапов много на каждый мост просите ошибка поэтому чтобы удобно это дело managed мы используем apache airflow такая система для регистрации данных одна из самых популярных отлично подходит для батч сценарий f там есть встроенная работа с расписаниями запускать рассудке раз сейчас 1 неделю допускать когда данные готовы и многое другое позволяет выстраивать зависимости даже намного более сложные чем было на предыдущем слайде и как раз таки удобен для работы в гетерогенной среде когда не только sparkle не только кубер найдется скажем и то и другое сразу где мы сейчас находимся давайте зафиксируем наш прогресс наш процесс мы улучшили систему рекомендации путем разработки нейронной сети которую машин лёнинг инженер помещает вместо доступная для production а в нашем случае это hd fs в ином случае может быть из 3 или иное хранилище данных и затем используя patcher слов обеспечиваем inference модели выводы из этого блока на продакшен не должен влиять человеческий фактор даже если ну кажется что ничего страшного не произойдёт при этом при этом для экспериментов такой подход вполне имею имеет место быть когда мы разрабатываем что-то совсем новое когда мы можем проверить какую-то гипотезу за день вместо неделя такие ситуации они на начальных этапах разработки могут возникать на самом деле какие решения поэтому и приняли по этому поводу во первых без автоматизации мы раскатываем максимум на четверть аудитория и только для временного оба эксперимента то есть это допустимо но держится под пристальным контролем и конечно стремимся минимизировать такую ситуацию чтобы даже на этапе самых первых экспериментов не было необходимости делать так сразу автоматизировали использование модели на данный момент автоматизировали более 90 процентов от всех экспериментов которые запускаются такая ситуация стала крайне редкой дальше мы автоматизировали использование моделей у нас казалось бы есть production который приносит денежки и что нам теперь хочется но немножко наверно успокоиться отдохнуть хочется стабильности поэтому наша система сейчас находится в стабильном состоянии хорошим и нам нужно понимать если состояние системы вдруг деградирует мониторинг и другие вещи давайте разберемся сразу как это вообще в одноклассниках делается так тоже на примере вот есть production который мы ранее разбирали что нам здесь важно нам важно чтобы хранил к старец отдавал быстро нам важно чтобы лента строилась не более чем за 100 миллисекунд нам важно чтобы у запроса шли и чтобы ошибок не было на все это мы смотрим на графиках и если какая то из этих характеристик в двоится из нормы то мы либо знаем почему это произошло но сервер отвалился и он автоматически восстанавливается либо создается инцидент и специально обученные люди идут и чинят эту ситуацию да ну нормально так же мы следим за жизнью сайта так насколько хорошо он работает есть продуктовые имеет раки такие как количество лайков прямо сейчас сколько комментариев на сайте прямо сейчас сколько пользователи находятся на сайте в среднем за последние сутки и всякие другие вещи за которые мы следим и понимаем что все сейчас хорошо ну так же мы эти характеристики мире мвб тестах но речь не об этом общем если какая из этих характеристик вдруг резко идет вниз там и опять-таки начинаем расследовать что же могло пойти не так приводим система в стабильное состояние и вот наш airflow pipeline ну новой сущность которой мы сюда вводим сущность которая делает так что пользователей оказываются свежие рекомендации которые важны для работа сайта и на этом этапе мы контролируем что каждый из частей pipeline и отрабатывает во первых на слайде вы видите airflow и ой там мы видим список всех pipeline of которые нас есть вообще и также мы видим из каких стадион состоит и если какая-то из стадий вдруг падает то точно также идет alert и специально обученный человек с этой ситуации разбирается и вот казалось бы все нормально мы следим за стабильностью нашего продакшна если что-то идет не так то мы об этом узнаем и сразу чонин да и мы знаем как это делать но однажды в1 в1 теплое летнее утро когда то вдруг резко упала количество классов и комментариев ну так процентов на 10 15 м серьезно и все технические метрики которые описывал они как бы в норме и все pipeline и отработали ну просто причина этого падения может быть техническая но отвалился сервис в котором который отвечает за то чтобы лайки ставились ну с кем не бывает починят но вот нет все это в норме но как то вот падает и замечаем что подозрительно время падения совпадает с очередной выгрузкой в базу данных рекомендаций замечаем смотрим что она там выгрузила и видим что визуально но вот как-то похуже стала лично для меня рекомендации как будто бы не тешьте раньше на всякий случай откатывает на предыдущую версию рекомендации и буквально там через пять-десять минут график начинает выравниваться мы как бы молодцы мы нашли причину потом начали долго копаться в итоге поняли что в этот раз просто поплыли значение фичей но вот при обучении было от 0 до сети сейчас стало там 100 из по той или иной причине и нехорошо было такие рекомендации допускают до продакшна это было очевидно что будет такой инцидент и проблема при внешней стабильности системе у нас могут выкатиться некачественный рекомендации и и главное принять понять для себя что вот технических метрик недостаточно на этой картинке айсберг уходит вниз с мониторингом мэл и что мы сделали по этому поводу это вели проверку небольшие проверки на качественно данных следим за изменением статистик данных которые идут на вход затем что нейрон к выдает на выход но и другие модели коих у нас более сотни допустимое значение фичей и предсказания и работает в pipeline это так что в том же плане air flow добавляется стадия проверки данных типовые проверки он всякие реализованы и в случае если все успешно the pipeline продолжается идет inference модели затем они заливаются на продакшен если нет то высылаются alert и ну человек с этим делом разбирается ну или забивает сегодня завтра уже нормально может быть будет зависимости от ситуации вот такая история еще одна тема который мы реализовали это считаем и драки машинного обучения в онлайне насколько точно мы предсказываем источники по постам которые кликают случай когда мы занимаемся задачи классификации мы собираем разметку и проверяем что ну точность что методе машинного обучения совпадают в онлайне с тем что было на оффлайне таким образом замечаем момент когда но вот система при внешней кажешься стабильности но все alert of нет всеми против норме на самом деле медленно и постепенно деградирует и так вот на этом этапе какие выводы можно сделать мы поверили в то что мониторинг данных действительно важен и предотвратить или предотвратили некоторое количество потом в будущем похожих инцидентов которые бы мы если бы такое не написали тяжело расследовали и ну главное еще мораль что вот но многие знают что проверьте на качество данных они жены их нужно делать но вот советую их сделать до того как подобный инцидент произойдет полезная тема и идем дальше следующий этап но так куда мы пришли давайте посмотрим опять на процесс разработки эмаль модели какой у нас сейчас есть и так да это сайт специалист разрабатывает модель используя все свои знания и затем помещает ее вместо которое доступно для production а затем хорошо тестировано и джабба который мы к тому же еще и мониторим использует ту модель каждый день и доставляет надежно стабильно рекомендации на продакшен на самом деле на этой схеме многие уже останавливаются она опять таки когда модели не очень много достаточно достаточно классическая я бы сказал но давайте обратим внимание на парочку следующих наблюдений наблюдения один не буду говорить очевидную но и моль модели устаревают а устаревшую модель следует обновить причем устаревают широком смысле об этом мы поговорим чуть чуть дальше первое наблюдение на устаревают устаревают все говорят передачи модели передачи модель ну вот а второе наблюдение вот в этом нашем процессе где присутствуют да это сами специалист мы на самом деле вообще не знаем чем он там занимается как это выглядит даем ему задачу он что-то делает вообще не важно что и в итоге модель оказывается на продакшне так или иначе вот такая схема и казалось бы ну и ладно так так и работает это же ну дайте сантис ну главное что модельки делал к и разница что он там чем он занимается пусть хоть кофе пьёт главное чтобы денежки приносились но расскажу по этому поводу одну опять-таки историю прихожу я значит такой на работу в одноклассники года 3 назад и одна из первых моих сдачи такая михаил мог бы ты улучшить каким-то образом модель которая распознает непристойный контент вот мы не знаем что с ней случилось она буквально там недели две назад нормально работала сейчас что-то вот удаляется слишком много лишнего сделать что-нибудь с этим ну не знаю что но вот то что вы ds обычно делаете ok беру в работу начинаю спрашивать у коллег а кто вообще ее делал а ну вот тот коллега делал он уволился где-то полгода назад тебе как раз вместо него и наняли ты что не знал и что я имею как человек который хочет решить задачу у меня есть продакшен где обеспечивается inference модели модели помещена вместо доступная для продакшна hd fs потом просто создана папка там порно3 разбирайся ну и все и пришлось на самом деле но делать все это дело с нуля то есть вот такая проблема но нужно не помнить знать что она вот может возникать если вы придерживаетесь такого процесса когда-то так было и в одноклассниках но сейчас мы немножко это дело под улучшили почему эмаль модели вообще устаревают две причины первое это изменяющийся мир меняется пользовательское поведение появляются новые источники информации который мы сейчас не учитываем то есть это говорит нам о том что нужно уметь переобучать модель на новых данных одно требование раз второе требование появление новых идей ну придумал новую фичу придумал новый способ собрать datasette новую фичу там учитываем не только полную возраст но вы понимаете лику это более сложную касается собрать другой ну от простых эвристик как использовать ни одну неделю а 2 так какие-то более сложные гипотезы проданный например почистить и вышла новая статья нужно срочно ее реализовать части но блажь да нет все это ведет к увеличению счастья пользователей случай правильная реализация и второе требование которое сейчас появляется нужно уметь эффективно экспериментировать зачем нужна ну чтобы конкуренты нас не загрызли чем быстрее экспериментируем тем быстрее хорошие модели тем быстрее части пользователя и так для продакшна графично у меня переключать модель на новых данных и у меня эффективно экспериментировать обладает ли наш продакшен таким свойством нет потому что ну вот рассказал вам историю проблемы фиксируем процесс ручной процесс экспериментирования непрозрачный даже нет способа воспроизвести production модель а следовательно ну как я могу улучшить модель перемкнуло внести какое-то конструктивно изменение если для любого изменения мне приходится что-то делать с нуля по сути только человек который делал модель может этим заниматься никакой другой коллега с этим быстро не справиться это невозможно и так ну вообще вот если спойлерну что корень проблемы здесь такой многие считают все еще что д.с. какая роль которая разрабатывает модель на самом деле ну вот она ведет к этому то что мы описали а вот если да то синтоисты будут разрабатывать pipeline и которые хотя бы берут на вход данные и гарантированно отдают модель то все изменится то есть это корень проблемы именно так и ее нужно решать как написать такой pipeline почему это сложно это сложно потому что ну эмаль модель она эта сущность немного более сложная чем просто кот например из которого jar ники собираем тут нужно как минимум взять данные те же самые которые были когда-то соединить их с кодом зафиксировать все зависимости ну не то чтобы это супер сложно но вот тем не менее и только тогда у нас получится та самая эмаль модель который мы когда ты разрабатывали и ну почему мы почему у нас не хватает знаний почему наш процесс плохой потому что на каждом из этапов этого классического процесса собрать данные обучить модель право лидировать модель мы сохраняем слишком мало информации но вот нет у меня знания о том как этот человек собирал данные значит я не могу ему помочь как-то и есть классическое решение такое же ну давайте но если мало информация давайте поступим как будет больше информации давайте крамола код начнем коммитить или может быть будем писать хронику эксперимента вики то есть я сегодня запустил такой эксперимент как-то его описываю писать инструкцию как запустить обучение в git репозиторий и все это имеет смысл и опять таки если у вас мало моделей то но это будет работать нормально прекрасно то есть один человек возьмет репозитория другого человека почитает что написано с третьего раза запустят и переобучить модель нормально но не то что подходит нам когда у нас более 100 моделей и сейчас мы на примере заполнение этой табличке как у нас было как она стала немножко приблизимся к тому состоянию чтобы модели стали все-таки воспроизводимыми пройдемся по всем стадиям первая стадия собрать данные как было собираю данные где-то их сохраняю но где-то где-то ну где хочу сохраняю например есть у меня машина ноутбук мне компания предоставила там и сохраню пойдет что где-то же сохранил ну или еще где-нибудь или даже наш dfs положу но никому не скажу где это будет лежать такая проблема многим может быть знакомо и решили используем но заведением такой сущности когда это рейдерстве мы теперь versio ниром datasette с использовать девисе сохраняемых наш dfs и главный принцип то есть реализация неважно принцип такое что для обучения мы используем только данные которые потом будут доступны для продакшна то есть должен быть способ чтобы любой мой коллега взяла нажал кнопку и у него такой же тест на компьютер и очутился ну или в под принцип понятен способ достать тот сам этот сет который использовался при обучении модели и так было где-то сохраняем данные они теряются сохраняем данные в дайте реджи стр и теперь человек любой знает какие данные могут быть использованы может по ним можете их восстановить далее на следующем этапе будет прямо несколько проблем обучение моделей самое интересное потому что самой большой проблемой 1 звучит я не буду говорить код коммитить но проблема так звучит то есть кот за комичный он находится в отдельных картах или ноутбуках ноутбуки это вот такая штука но можно охарактеризовать так лучшим сущность но скрипт или ноутбука эта сущность которая решает только одну задачу для которой его написали и может быть если в течение обстоятельствам складываться звезды благоволят а он отрабатывает начала до конца без ошибок отказываемся от этого принципа более нормально оформляем pipeline и для написания pipeline of на бетоне мы используем фреймворке 9 или daxter но это так посмотреть на просто если понравится принципе такое что нужно нормально вот писать почему почему нужно нормально вход писать стараться давайте посмотрим на задачи которые у нас есть спектр и решенных если посмотреть вот так невнимательно то кажется они все разные спам или нет что изображено флота кита абсолютно разные задачи что и про них хочу сказать их в разное время решали разные люди используя ну разный код на самом деле разные скрипты но если чуть-чуть повнимательнее посмотреть то все эти задачи которые мы решаем они похожи друг на друга чуть ли не как две капли воды тут есть pipeline для классификации текстов эти три задачки сгруппировались pipeline 2 рекомендации еще три задачки сгруппировались для классификации еще задачки сгруппировались у нас более десятка таких pipeline of и как мы используем этот pipeline есть сущность пир использует pipeline она принимает на вход это сет и параметры в зависимости от того какой то свет и параметры она приняла мы получаем решение самых разных бизнес-задач перри использование кода во всей красе практике обязательно review кода здесь знаете печальная ситуация общаясь с друзьями какими-то из разных компаний спрашивай code review эти модели к ожидая услышать ответ ну ну не моделек от сатанинского 3 beauty и они говорят да нет зачем с вот код который провод идет мы review им а это шиташ игрушки зачем это ревью эти ну так вот на этом ревяко да мы как раз таки обращаем внимание на то можем ли мы переиспользовать какие-то наработки коллег то есть ускоряем вывод моделях продакшн и покрываем тестами эмаль компоненты за счет того чтобы ну вот коллеги ds и могли жить вместе дружно и используется один общий pipeline а не писать каждый на на самом деле одинаковые задач не писать другой на задача которая уже ранее было решено codes ноутбуках минус перри используем pipeline еда следующая ситуация это параметры запуска параметры запуска сейчас стали еще более важной сущностью потому что теперь в зависимости такие параметры я передам я вообще получаю решении самых разных бизнес-задач раньше они хранились где-то вики ну вот как я вам описывал процесс кто-то что-то написал запустить python train . по и потом там напиши 05 и все будет классно ну вот параметры стали гораздо более обширными теперь параметра это и используем для защиты и параметры обработки данных и какую модель использовать какие-то тонкости обучения ну например если говорить про неровные сети сколько эпох там как градиент и затухать должны и все это дело фиксируется в git фиксирует затем чтобы потом быть доставлены мда pipeline и рекомендации он там используя эти параметры будет обучать модель разные люди видят параметры которые используется для обучения моделей и так теперь параметры фиксируется rigid не теряются есть способ понять соединить как кот кот с параметрами соединяешь получается модель код параметры плюс данные получается модель вроде нормально сошлась история но есть ещё одна большая проблема такая никто не контролирует процесс обучения ну как никто как никто вот этот человек единственно контролирует который машин реальных специалист вот у него есть перри используем код dataset зафиксированных параметры тоже зафиксированы и есть специальная тачка большая мощная куда он заходит и он там царь и бог делает все что ему пожелается ставят пакета питоновские запускают докер образы все что хочешь и когда есть такая свобода то большая вероятность что кто-то что-то сделает маленький пример пакет установят да и потом забудет его зафиксировать где-то запустят обучение модели от начала до конца у него на получится моя как бы в про доставим но потом следующий человек он столкнется с этой проблемой что не доставлено какая-то липко решение тут ну простое это не должен делать человек просто это должен делать какой-то робот робот должен взять и ttc параметры под соединить все это вместе и на выходе отдать ему модель такой принцип которого можно использовать в качестве роботов мы используем либо связь иди инструмент тем city для стиля работы когда мы просто комитет параметры затем по нем обучается моделька то есть такое у нас getfloat окская для модели есть и более классический да просто в flow в docker и образе или еще где то спаркс орбиты всякие запускаются стадия примерно как с batch inference он только быть день и главный принцип зафиксировали обучение происходит контролируемой среде раньше не понятно как а теперь мы моделька можем воспроизвести раньше нет один раз она если обучилась начала до конца значит мой второй раз вероятно следующий этап это отчет то есть отчет очень важен потому что именно по нему мы принимаем решение допускать модель до продакшена или нет и раньше это как было ну вот я разработал модель и потом подготовил отчет я считаю что она классная там ну как-то это доказывает основы и скидываешь допустим в с менеджером он такой ну да давай и все и потом впоследствии когда я буду эту модель переобучать уже но наверное я и слез этот отчет может быть не достану должно быть какое-то другое место где могу смотреть отчеты метрики понимать почему та или иная модель была выпущена на продакшен и в качестве такого места мы используем эмаль flow есть и другие системы трейдинга экспериментов но вот мы его используем какую функцию он выполняет там хранятся все эксперименты и запуске обучения моделей сохраняются метрики и какие-то ключевые параметры с цели чтобы мы потом в я могли посмотреть какие метрики были при обучении той или иной модели и уже не будет такого что я не знаю какие метрики бы лютой модельки которую неделю назад обучила я просто захожу сюда и смотрю главное все это потом месте сохранить но это другая история также сюда можно записывать артефакты через пятнадцать интерфейс в качестве хранил ки могут использоваться разные вещи самые от дефиса ds3 ну там еще несколько в общем сюда можно записывать как файлы самой модели так собственно отчеты что мы делаем и так в ходе работы pipeline который запускает робот он также дополнительно публикует все эти метрики то есть а на кнопку нажимаю потом вы мой flow захожу и вижу обучение и кровь и 95 нормально вот так вот разница не понятно где отчеты хранятся хранятся в мой flow можем если мне нужно вернуться и посмотреть что там была и последний этап такое же advanced может на сказать этап это что не так на стадии когда мы помещаем модель место доступны для prado все раньше было нормально на самом деле создаешь папочку наш dfs пишешь модель 1 модель 2 модель 3 все понятно потом оно подгружается так или иначе на продакшен в разных способах использование модели и работает там ну вот тут такая проблема что я когда со стороны продакшна смотрю я вот вижу модель 3 работает ну влогах записано потом иду наш dfs смотрю там модель 3 что я вижу я вижу konig файл где купить аж еще что то у меня нет доступа не камея треком не коду у даже если но где то есть у меня прямого доступа нет мне надо будет пойти и спросить кого-то как-то это узнать и для решения этой проблемы мы используем другой компонент намуль flow называется а мой flow модуль реджис 3 как это работает вот у меня есть запуск модели uiaa там метрики артефакты всякие лежат есть способ какое-то из артефактов зарегистрировать так сказать так это выглядит я пишу модель а ну или там модели рекомендации музыки и потом в общем я и одном я вижу список всех моделей которые меня есть их актуально статус на продакшене на стринги или не где сейчас не используется их версию и ну отсылочку в общем к метрикам и коду и таким образом я если мне это to do not важное вы видели как ну кто-то в юар штаты колу на самом деле можно все это делать с помощью кода там есть rest api можно настраивать это как часть соседи pipeline а или airflow pipeline а так мы и делаем через api никто не клацает вот состояние текущей системы метрики в ходе работы в мали слова помещается модель в моду registry метрики смотрю модель ну от артефакты могу перейти к метрикам и коду нормально состоянии модель сохраняется verse не раз его мать фло модуль реджистер перо тиф просто папочка наш дефис и откуда нет доступа ко всем предыдущим артефактом работы и итоговая схема получается с одной стороны особо ничего не изменилось другой стороны кардинальное изменение теперь в центе ст у нас не разрабатывает модели или моль инженер он работает программистом по сути он комитет код он комитет параметры данные и потом уже этот код кто-то используя вместо него получает полезны для бизнеса артефакт что это дает но то что это дает решении озвученных ранее проблем и счастье на самом деле для специалиста который чем занимается с которого скинули и ручной труд и ответственность так результаты по этому блоку мы научились воспроизводить обучение моделей за счет перри использования кода это тоже важная штука мы снизили тайм ту марте для типовых моделей это либо новая версия модели которая уже на продакшене обычно на новых данных или с новыми параметрами либо какая-то простая модель как и это назад а - классе fire большинство моделей сейчас wog прошли через описанные процедуры то есть мы начали за дело получается ну давненько я где-то уже ну вот как год все точно этот процесс приняли и на данный момент но он более 90 процентов опять-таки полученные таким способом то есть очень только редкие модели там самые какие-то заковыристые может быть ненужную по старому там за тепло и на придёт момент их либо перепишет либо они умрут и организационные принятое решение важно то есть тут со стороны не знаю если вы менеджер какой-то и летим ли должно быть принято поощрение для специалистов что внимание качество кода и тестов нужно уделять не меньше чем исследовательской составляющей не нужно говорить человеку вот что я хочу сказать в общем раньше как ты делаешь модели тебя ожидают модель который работает хорошо всем вообще все равно какой-то там кот писал но это обидно не хочется вкладывать в это усилие зачем делать то что всем все равно если это как-то поощряет то потом и результаты в этом деле хорошие time to market увеличивается и фиксирована также что мы ну не разрешаем мы попадать на продакшен моделям которые не прошла через автоматическое обучение ну вот нельзя и все то есть и люди это принимают и это на самом деле не ведет ни к какому замедлению только к ускорению повышению счастья как специалистов так и собственно пользователей потом последствия более подробно про историю про воспроизводимость можно послушать другом моем докладе он специально этой теме посвящен здесь как бы побочно и подведем итоги вообще всему докладу целиком процесс вывода и мальки в продакшен может быть как очень простым прям супер простым как вначале и это будет работать но не поддавайтесь в эту ловушку не попадайтесь автоматизации автоматизация автоматизация и результаты будут технический процесс также важен как части пользователей потому что если технического процесса не будет то пользователь будет счастлив недолго и конечно же результат работы не модель pipeline принимаем это это новый стандарт я думаю сто процентов сегодня мы пришли так через истории автоматизация бачин firenze мониторингу данных и автоматизацию обучение модели не поговорили о том как мы используем модели как сервис и в streaming режиме общем онлайн паттерн использование модели может быть других докладах и на самом деле в более старых докладах можно найти про это уже была на этом у меня все готов ответить на любые вопросы по теме спасибо за то что остались на последний доклад конференция в опусе больше михаил спасибо тебе большое за доклад было очень интересно и приступаем к вопросам добрый день спасибо за доклад вот такой вопрос вас там красивая финальная схема когда значит дата-сайентистов ботает программистом pipeline вот все отлично огре в этой схеме место для экспериментов дата-сайентистов потому что он может забрать данные к себе но тогда приди плэев pipeline что-то может пойти не так а давать ему для экспериментов отдельный pipeline как ну накладно нормально нормально конечно но это просто слишком в ответ зависит от конкретной реализации но просто должна быть такая же среда например на по характеристикам то есть чтобы была возможность делать то же самое просто но без эффекта на провод более подробный ответ получается зависит от того как в компании безопасности относятся и так далее но в любом случае это можно порешать просто нужно не допускать результатах production чтоб они не эффект или на пользователей а насчет но собственно затрат ресурсов но в эти машины с которыми они экспериментируют они же но как бы не так уж дешево стоит и может быть даже если будет возможность как вы и ws например и создавать там себе instance на него заходить посчитал поработал погасил это может быть даже экономически более выгодно окажется в некоторых ситуациях до в другой вопрос если ответил на этот вопрос 1 раз мне слышно да да спасибо за презентацию на самом деле я хотел уточнить вопрос вы храните данные получается для каждого эксперимента в условиях того то что данные там быстро устаревает новую рекомендацию приходится для каждого эксперимента хранить сэмпл данных данных бога и вот когда вы понимаете что может быть данные придется почистить или как из этой проблемы справляется но мы стараемся хранить snapshot datasette а для каждой модели которая когда-либо была обучена почему ну на данный момент так потому что мы обычно работаем работаем большинство наших моделей из этих сотни они такие которые не нужно очень часто переобучать поэтому мы позволяем себе хранить насчет версии для каждой данных для вот pipeline of каких-то более рекомендательных где нужно переобучать модельку 1 недели мы полетели храним то есть последние запусков 5 данные для них хранятся остальные там последствий удаляются сути спасибо за доклад и такой вопрос вы упоминали data quality мониторинг оркестрацию как в этих вещах в одноклассниках разделяется ответственность между e-mail инженерами и даты инженерами дат инженеры в одноклассниках это зверь особый у нас их не так чтобы много есть команда платформа который отвечает за такие вещи как работоспособность hadoop кластера за там рада склонность кафки и подобные вещи есть некоторое количество дата инженеров которые обеспечивают качество продуктовых метрик ну вообще общем данные которые имели имеют отношение а посреди но есть команда do it all up в которой работают и моль специалисты там мы отправила совмещаем себе эту роль то есть у нас просто вот один человек который делает задачу отвечает за все это с поправкой на то что есть опытные коллеги которые в случае вот если у тебя что-то не тривиально что-то прям не знаешь как сделать идёшь к ним и плюс какое-то reviews их стороны что но и молить специалист не делать какой-то совсем плохую штуку по возможности эти ответственности стараются совмещаться когда это возможно и слишком много от этого беды не случается спасибо за доклад было интересно вопрос такой как вам удалось автоматизировать оп оп и тесты с учетом того что рекомендательную систему вы оцениваете глазами и второй вопрос по поводу inference она вроде у вас получается inference он занимается мой flow или что то другое и что-то другое понимаете версию модели которую нужно интернете отвечая во первых такой вопрос был apts ты автоматизированное нет я не говорил что они автоматизированы к сожалению у нас они пока что создаются вручную что мы тестируем обычно а.б. тестамент задачи рекомендации мы оба тестами тестируем выходку какой-то новой модели совершенно другое то есть другая методика получения модели и потом еще мы дополнительно иногда когда это нужно проверяем как быстро на устаревают чтобы ну не следить за метриками устареванием или модели сложно просто по кулдауну их обновлять там 1 2 недели перри обучаем пруд модель нормально так это 1 то есть оба они не автоматизированы а впоследствии новые выкатки они как бы без оба теста выкладываются просто новая версия потом он эльф flow это компонент который не занимается inference а мы-то компонент который хранить себе информацию о том как модель обучалась это так называемый ну это сторож если в терминологию углубляться инферн сам собственно занимается контейнер запущенный в системе регистрации контейнеров я не стал углубляться у нас используется такая штука как вон клауд проприетарной разработка ближайший аналог обернитесь ну вот эта сущность встречает и либо стриминговый отжима и либо чего джеба на кластере apache спарка так потом как мы а собственно откуда мы знаем что там верфи cmn flow как раз таки предоставляет тут компонент его которой модуль реджис 3 там есть api и там можно говорить ему дай мне последнюю модель который имеет статус production он отдает или дай мне модель номер три и потом пологом все это понятно как бы и мы настраиваем либо так что вот если выходит новая модель то при следующем запуске badge бы уже будет подгружена другая либо там в онлайне обновиться что-то слеза перезапустится как бы модельки с одной версии на другую вот так вот устроена спасибо за доклад можно два маленьких вопроса первый вот ты сказал про то что теперь вот когда вот новый процесс сделать то теперь уже год покрывается тестами насколько я понимаю это папой pineapple покрывается тестами да ну по возможности да что там тестировать а у спортсмена или вы допустим допустим как это как модульный теста вы просто протестировали как бы что вот и пойми но не грубо говоря смотрите то есть но это типично вопрос то можно тестировать bio в ноутбуке все работы в без всяких тестов но так как вы сказали первый уровень модульные тесты но на самом деле один из самых важных то есть что я вношу изменения в код и мы же все вместе как бы один кот используем и там элементарно кто такой то от и меняет и потом у меня уже поэтому там модель по-другому учиться и потом такие штуки как то более интеграционный тест когда на продакшене запускается что-то на каком-то сам сэмпле данных но какие-то такие истории на самом деле вот в этой истории про эмаль код я имел ввиду больше всего модульные тесты тесты интеграционные на сам pipeline что он в принципе там корректный принимает параметр и на выходе у него какие-то правильные артефакты образуются я вот этот слой имел ввиду но и все что дальше важно просто его обычно нет он как бы сама базовый без него уже ну как бы жить нельзя то есть правильно понимаю что смысле что как бы он в принципе не взорвался но вы не проверяете какие-то метрики что они как бы что-то хорошее дает но на этом этапе как бы нет алкей понятно но ежели длину другой уровень следующий где мы как раз таки можем обучить на каком-то golden 5 city и посмотреть что метрика не поплыла но признаться то есть не то чтобы прям короче это мы еще не внедрили до конца эта тактика над этим работа ведется суши можно еще пожалуйста там пому 49 слайд был там где у вас был контроль данных где ты рассказал про то что паб или этот вот он 48 48 48 следующее вот собственно в чем заключалась проверка данных осинская просто я не очень понятно почему как бы там каких случаях мы можем использовать nero кафки случаем понимаешь высоты не так и нам нужно звать олег это вот история она была привязана к тому что пошло не так на против прошлый раз of в тот раз пошло не так что поплыли конкретно там знать они фичей то есть там проверка на то что там распределение фичи такой же как было раньше там не поплыла то есть дата дрифта то что нет плюс проверка на то что учетом я написал вот вспомнить допустимое значение что там принципе там нету значения которое больше чем том что то вот такие простые проверки как имеется ввиду гей спасибо спасибо за ваш вопрос михаил спасибо большое за твое выступление"
}