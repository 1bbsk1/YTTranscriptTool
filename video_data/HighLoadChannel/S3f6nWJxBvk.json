{
  "video_id": "S3f6nWJxBvk",
  "channel": "HighLoadChannel",
  "title": "Масштабирование в масштабе Amazon / Василий Пантюхин (Amazon Web Services)",
  "views": 5620,
  "duration": 2863,
  "published": "2019-12-05T08:23:36-08:00",
  "text": "давным-давно моя первая машина была на ручке но я имеют автомобиль механической коробкой передач не то жутко нравилось потому что было такое ощущение что я могу управлять под полностью контролирую свою машину еще мне нравилось то что как мне казалось что я понимаю как она устроена и съесть меня от представлял это так достаточно примитивно то есть наверное ту же самую коробку передач и вот представлял вот так вот но как бы то ни было все было замечательно кроме одной вещи мы жили тогда в ленинградской области это пригород питера юридически нам северную столицу на было по делам езди и вещь которая меня реально вымораживает а питерские пробки ты вроде сидишь на попе ровно и вроде ничего не делаешь но вот это необходимость постоянно нажимать на сцепление газ переключать передачи я реально уставал поэтому когда у нас появилась следующая машина мы с женой так подчесали конечно не спортивно ну ладно купили автомат и в принципе проблема пробок но она частично решилась потому что в пробке у меня появилось время подумать о чем то там аудиокнижку послушать а еще моей жизни появилось загадка потому что я вообще перестал понимать как работает моя машина то есть современный автомобиль эта штука достаточно сложное одновременно она адаптируется десятком различных параметров то как я нажимаю на газ на тормоз качество дорожного покрытия мой стиль вождения и так далее для меня это загадка вообще к чему это все к тому что когда я начал заниматься облаком amazon для меня это тоже было загадка только загадка следующего порядка потому что водитель он машине 1 а в амазоне одновременно миллионы пользователей рулят нажимает на газ и над тормоз и что самое удивительное для меня это чудо они едут туда куда им нужно то есть система как то автоматически внутри себя адаптируется с масштабируется эластична подстраиваясь под каждого пользователя таким образом что ему кажется что он вообще один в этой вселенной и на самом деле только тогда когда я уже пришел инженером в и архитектором в amazon чуть-чуть вот это вот магия на чуть-чуть развеялось потому что я увидел с какими проблемами мы сталкиваемся как мы решаем эти проблемы как мы развиваем наши сервисы и когда ты чуть чуть больше понимаешь как это работает но у меня лично появилось еще больше доверия к этому сервису поэтому вот сегодня мне хотелось вам с вами немножко поделиться теми вещами что находится под капотом сервисов облачных сервисов и дпс а я вот выбрал такой диверсифицированный подход то есть выбрал 4 как мне кажется интересных сервиса которых стоит поговорить то есть первое это сервер и понятно что облако эта вещь такая эфемерная да но у этой эфемерности есть естественно физическое воплощение тут есть физически да это центры где стоят физический сервер они гудят греются и так далее вот об этом я расскажу я расскажу вам еще об одной штуке наверное самая масштабируемый самый масштабируем и сервис в облаке это сфера для функции лямды что находится у них под капотом в качестве примера будет рассказ о том как мы строим свои собственные масштабируемые базы данных и в конце я вам расскажу о том как устроена наша сеть потому что это реально какая-то чудесная вещь каждый пользователь облака считает что он в облаке один он вообще не видит других tenant of и так поехали серверы был шел 2012 год то есть уже 6 лет как мы взлетели публично мы работаем архитектура физических серверов на тот момент она была достаточно стандартная то есть естественно сами сервер мы собирали самостоятельно это уж слишком дорого покупать но компоненты были все стандартные то есть был intel новый чем set мы покупали где-то сити в ушки все это дело с собирали с точки зрения софта архитектура тоже была стандартная достаточно то есть это был linux это был слой виртуализации гипервизор xen замечательное решение и это были там гостевые операционки которые мы запускали виртуалке все работало очень хорошо но стал очень серьезный вопрос проблема дело в том что accent ну еще раз скажу что это классный гипервизор но у него есть один большой недостаток там дом зиру для тех кто разбирается в этом до компонент который отвечает в частности за эмуляцию устройств у него очень высокие накладные расходы именно на умаляться этих устройств и на 12 это год все было нормально но вот как мы будем дальше жить когда появляются новые слышал ее быстрые диски новые сетевухи там десятка двадцать пять мегабит и так далее то есть а там уже вот этот процент он будет жрать слишком много и амиду накладные расходы на эмуляцию устройств поэтому мы решили что нужно неким образом трансформировать нашу архитектуру и мы пошли следующим путём мы решили одновременно разделить две вещи первое это оптимизировать железо при этом и решили чем меньше мы покупаем тем лучше мы решили разрабатывать свое собственное железо хватит делиться с дядями давайте работать на себя а я разработка своего производства где это возможно и вторая вещь это оптимизировать слой виртуальность и второй принцип который мы решили руководствуется это эволюционный принцип развития то есть можно как бы все сломать и заново построить что-то такое замечательное но мне кажется что этот подход он не работает когда мы говорим о таких больших масштабируемых вещах поэтому что мы сделали мы стали выделять кусочки важные кусочки например сторож да ну и столь же никогда не бывает там light вас тоже никогда и не бывает слишком мало хочется все лучше и лучше сити лоха безопасность до security опять же нужно за этим очень серьезно следить мы брали один кусочек и серьезно над ним работали после чего выбрасывали новый тип in стаса в продукте и смотрели какими проблемами столкнулись как относится к этому наши заказчики и так далее то есть такой эволюционный подход из 13 года у нас получилось что вот вы по этой вестники мы забирались и у нас каждый следующий instance тип инстансов он чем-то отличался кстати как вы думаете сколько сейчас вообще различных типов инстансов в облаке amazon ну так порядок кто-нибудь может сказать порядка 200 сейчас порядка 200 различных типов инсеями ну семейства и размеры и в итоге к семнадцатому году мы пришли к тому что у нас вообще другая система появился получилось то есть you мы назвали нитро и все после ноября семнадцатого года системы которые выходят и виду новый типа виртуальных машин где новый тип иисуса они все идут под меня к таким зонтичных названием метро машины за полтора года вышла уже достаточно много таких машин то есть этой машины intel ах это машина на md мы сами себе варим arm процессоры это бы а металл машины кто из вас знает что можно заказывать не только виртуалке в облаке а просто настоящие железные машины ну вот я вижу несколько рук класса я и я вижу больше чем ожидал спасибо друзья как устроены метро машины мне трам у них у таких систем три основных компонентов то есть первый компонент это nitro kart и а если говорить про нидра карты то нужно понимать это этикет это чипы которые мы сами варим сами программируем под определенные нужды какие нужны есть первое это сеть это взаимодействие с сечу вот в четвёртой части сегодняшнего доклада я расскажу как работает сеть и будут там такие слова как инкапсуляция маршрутизация но это сети понятно так вот у нас всем этим занимается железяка то есть overheat 0 на уровень виртуализации кто знает что такое security группы из вас класса опять кучу рук для тех кто не знает это стоит full firewall и которую вы назначаете просто на инстанции так вот security group и у нас работает тоже на физических чипах это кстати тоже это подход да вот это не сломать изменю вторые второй тип который это чип которые относятся к работы со стороны со сторожем и б.с. это блочные storage capacity единственн 100 рычат тот сторож все диски непосредственно которые вставлены в сервер что там надо делать ну там надо как минимум или русь устройство это чаще в этой но не чаще здесь в данном случае это envy me это очень частый случай сейчас многие flash-драйвы подключаются через envy me ну стандарт уже будем считать чем еще занимается чуть-чуть в частности например шифрованием шифрования у нас при работе с дисками тоже делается на железном уровне а еще все эти nitro kart и эти чипы security чен и гипервизора которым я расскажу буквально через минуту все они на самом деле объединены некую сеть и есть такой отдельный компонент это контроллер который всю эту сеть а контролирует еще раз коллеги я повторю у нас гипервизор умеет варить железом ну и соответственно все вся вот эта обвязка она делается на одних и тех же типа хищников в них фирма ри и есть общий код и так далее вот эта красивая гора вернее горный массив находится в гималайях называется она аннапурна почему я об этом сказал потому что вот когда мы решили что нужно варить свое железо мы пришли к компании небольшой компании а которая называлась она порно labs почему она называлась потому что теперь их логотип выглядит вот так вот ну это часть амазона сейчас потому что ребята действительно делают классные вещи ну и теперь просто мы их купили цитируйте чип еще один важный компонент который отвечает реально за многие аспекты безопасности в частности за загрузку например операционной системы на этот сервер гипервизор вот я когда разговариваю с заказчиками вот один из частых таких вопросов тех кто недавно начинает только пользоваться облаком василия а какой у вас гипервизор мне три ответа на этот то есть если говорить про старые типы instance of the и токсин я уже об этом сказал если говорить о nitro инстанция tanita гипервизор это кастомизированный квн что я веду под кастомизации естественно это не вся обвязка линуксовые мы взяли просто отдельные модули модули ядра и специальных заточили конкретно под наши нужды а третий ответ никакого я уже сказал проблемы машины там просто нет никакого гипервизора вы получаете полноценный доступ к железу кстати во у нас есть например партнерское решение вместе своим в так вот ли вы живет на b металл таких машинах без гипервизора потому что мест от виртуализация до виртуализация внутри виртуализации это ну вещь скажем так неэффективно неправильно поэтому они пользуются прямо вот всеми возможностями железа я думаю что не многие из вас видели эту картинку многие наверно в первый раз вообще видят как выглядит нет 1 сервер это nitro сервера которые будут поставляться в рамках решения который называется all posts кому интересно я расскажу то есть облака спускается на землю вот такие шкафчики будут но это лабораторный вариант но уже его можно показывать давайте поговорим их функциях о сервер для с функциях лямда они появились 2015 году и на тот момент архитектура вы выглядело следующим образом лямда работала поверх виртуальных машин ну а сверху это соответственно там висит у инстансе метро инстансе по сверху был контейнер сверху была наш секретный соус лямда runtime об этом я думаю что такое алемдар on time вам уже не скоро расскажут многие вещи они под индия ну и соответственно ваш код на на питоне надо еще на чем-то все замечательно есть одна проблема не то что даже проблема а нюанс не он заключался в следующем каждому аккаунту мы выделяли для лямды отдельную виртуальную машину или несколько и представьте себе то есть вы запускаете на бриолин ду который отрабатывает еще раз функция до февраля функция она родилась сделала дела и быстренько умерла то есть вся суть в том что она быстро сделала дела и умерла так вот вы запускаете функцию она отработают например за 200 миллисекунд но и запускаете и 1 минуту предположим и для этих целей вам выделяют где-то под капотом целую виртуальную машину по сути получается состав в течение часа она работает буквально там минут нисколько не то не факт что она утилизирует там до конца процессор и так далее в общем с утилизация у нас была беда то есть вы это как пользователи не чувствовали а мы а то чувствовали конкретно в том что слишком много ресурсов теряется какой риск какой подход мы решили здесь использовать здесь задачу можно разделить на две вещи на две таких части то есть что нам нужно было сделать первое tennant и пользователи облака они ни в коем случае не должны знать друг о друге то есть это должна быть железобетонная изоляция workle оводов это с одной стороны с другой стороны нам нужно максимально быстро запускать этим эти workflow да ну понятно лиам должна быстро запустится отработать и умереть и когда мы говорим о технологиях то получается что есть две технологии которые вроде как похоже можем могут нам в этом помочь с точки зрения изоляции это виртуальные машины точно у виртуальных машин есть проблемы они долго грузится с точки зрения быстро ты загрузки это контейнер и но контейнер тоже есть нюанс это shad керна разделяемые ядро нам не позволяет гарантировать даже если сейчас все хорошо по теории вы все равно можете пробить когда-нибудь эту изоляцию и в общем будет беда для нас до облако должно полностью изолировать tenant of поэтому получилось что но нужно взять хорошие вот из обоих этих миров и решение которое нам бы подошло на тот момент мы не нашли на мы решили его сварить самостоятельно и это решение называется fair крекер оно используется в ли андах она используется все ролях контейнеров or gate она вы его тоже можете использовать потому что это open source сходите на git можете посмотреть код и так далее как мы поставили задачу во первых это решение микро виртуалок должно базироваться на к время почему квн а потому что мы знаем как уже его варить потому что мы недавно его сварили именно для нет ромашин мы знаем этот гипервизор знаем его нюансы использования еще есть требования по собственным performance у насколько быстро мы должны запускать эти микро with all kinds сотни миллисекунд при этом слое виртале зонный он должен быть максимально тоненький буквально мегабайты а еще должна быть плотность вы должны реально уметь максимально плотно упаковывать эти микро виртуалке в железо как таргет у нас цель такая была это 5 микро виртуалок на ядро в секунду ну и в итоге мы решили варить свое решение архитектурно мы подошли к нему следующим образом максимально все упростить с точки зрения архитектуры с точки зрения каждой компоненты с точки зрения эмуляции устройств то есть мы эмулируем минимальное количество устройств и даже то что эмулируем это максимально просто например клавиатура мы решили все таки сделать с одной кнопкой reset ну потому что хардверным reset это все-таки полезная вещь и так далее и уже в 12-ой прошу прощение восемнадцатом году у нас появился fair крекер в прошлом году что и поменялось внизу теперь мы используем диаметр машины нормальные настоящие железные машины поверх них идет слой соответственно виртуализации и запускается собственно вот этот workload наш нам доски завернутый в far cry 3 тем самым мы получили как раз ту самую изоляцию и тот самый performance с точки зрения утилизации это огромный выигрыш то есть это там несколько порядков мы выигрываем с точки зрения утилизации мы очень плотно сейчас можно упаковывать наши наши work лорды я не скажу как это работает в лямки эти цифры но я могу сказать просто профи greger тесты которые мы там доступный вам вы можете даже их найти публично 4000 микро виртуалок запускается за 50 секунд столько кто-то 50 одну секунду мне кажется очень неплохо хороший параметр давайте поговорим о базах данных 14 год ну понятно что у нас уже в то время были базы данных rds это называется relational database services но есть нюансы вы вообще в архитектуре классических баз данных то есть если говорить о классике то есть понятно что это очень примитивная модель мира но вот так можно для наших целей то есть это такой свои 100 пирожок сиквел уровень то есть уровень диспетчеров клиентских диспетчеров диспетчеров запросов это уровень транзакции и сид это уровень кэширования буферные пулы и соответственно уровень виду логов случае там масик ул например это называется беллоне я в случае по отгрыз а это называется рай тихо и блоге ряду логе ну и нижний уровень это сторож где-то нам надо хранить все это как это дело масштабирует какие есть классические способы ну так что если я уверен что многие из вас например используют формирование кто там используются возможно решение с архитектурой шей 1 финк есть кто-нибудь в то использует oracle rac реле при конечный кластер вот я не вижу ru и по понятным причинам есть тебя кто-то это как раз рак этот типичный представитель sheath сторож вот мы рассматривали все эти варианты для решения проблемы масштабирование и решили что у каждого из них есть свои нюансы частности монолитная структура базы данных она в каждом из этих случаев сохраняется поэтому что мы сделали мы решили отщепить уровень логирования история от соответственно условно говоря самой базы данных в итоге у нас появилась возможность масштабировать отдельно сторож и отдельно саму базу данных хоть забегая вперед скажу что кэширование мы тоже чепель и так вот сторож нашего решения которое называется amazon авроры то база данных которая поддерживает масик вал postgres совместимо сторож там лоб bass то что называется то есть вы в сторож кидаетесь не блоками данных а вы кидаетесь ряду лагами и сторож умные настолько чтобы взять этот redo log ну и соответственно правильным образом записать внутри себя сделать бэкап и оптимизировать механизмы клонирования если это нужно и так далее и так далее как это работает под капотом как как это масштабируется на самом деле и вы это сегодня будете слышать вновь и вновь и вновь это распределенные сервисы сторож это распределенный сервис распределенный путь сотням а то и 1000 то в зависимости от региона not сторож нот и каждый каждая запись она происходит всегда 6 разных мест опять же распределенных между и вы label эти зоны между зонами доступности то есть там максимальный параллелизм как масштабировать саму базу данных давайте порассуждаем то есть у нас из приложения у нас есть мастернода нашей базы данных что вы сделаете чтобы ее например от отмасштабировать вертикально ну что нужно взять еще один сервер у которого будет наверно там больше процессора больше памяти после этого переключится со старого мастера на новый мастер чем нюансы что что что в этом решении не идеально а в том что у нас во первых для того чтобы каждая из этих приложений переключить который пользуется этой базы данных нужен downtime а еще есть такая проблема этой холодной кашей наша новая база данных у неё кришне прогретый то есть ей нужно какое-то время чтобы подсосать данные которыми которые будут пользоваться потребители как можно решить эту проблему ну давайте рассуждать можете на самом деле в промежуток между приложением и базой ставить прокси и тем самым нам приложением уже не нужно перри прописывать эту базу томате npn нашей базы данных ну и соответственно переключение она будет скажем так более мягким то есть будет там очень короткий фриз в воде увидят но при этом мы вообще никак не решаем проблему холодного кэша и мы получаем новую проблему это то что наш прокси это синга палата фил и соответственно если прокси завалится доступ базы данных тоже будет завален как решаем эту проблему решаем опять мы делаем распределенную систему делаем распределенной прокси который состоит из очень большого количества нот мы второй компонент этого решения это пол теплых инстансов то есть это инстанции которая уже стоят под парами загружены при этом разных размеров маленькие побольше и так далее то есть инсты которым можно масштабировать гранулярный наши базы данных и ключевой компонент это мониторинг то есть мониторинг он все время смотрит на состояние базы данных и если что-то происходит там его не нравится в частности повысило у тебя повысилась утилизация процессора происходит следующая магия мы из теплого пола выводим новый мастер instance делаем трансфер буферный полов кэша с этого мастера надобно новый мастер потом делаем легкий легкий фриц зачем нужен фриц затем что нам нужно коннекта со старого мастера на новый перевести поэтому нужен очень короткий фриз ну и после чего приложение начинает работать то скажите vasily ногу до короткие friso там где доказательства то может он не знает многие минуты занимает на самом деле вот данные того как это работает то есть голубой график это график нагрузки красный график это график скалирование масштабирования нашей базы данных то есть видите вот эти вот рейтинга это там где вот происходил этот процесс который я только что описал именно в перегибе этой лесенке вы видите как это пик вниз очень короткий это тот самый фриз ну хотелось бы чтобы без него было но вот к сожалению вот таких уже чудес уже не бывает и это принципиально другой порядок там задержек чем если бы вы это делали руками или занимались бы велосипеда строением самостоятельно давайте поговорим о сетях 2006 год это именно то время когда облака это был я стало публичным когда мы сделали его этот это давно было уже давно да как выглядел тогда сеть на самом деле в то время была плоской реально плоской сеть то есть естественно разные тянут и они не видели друг друга разные пользователи оба облака но при этом их адресант и назначались уникальные в рамках этой сети ну приватная сеть каким-то рандомом просто назначался и тут на самом деле кучу проблем потому что наши заказчики хотели самостоятельно выбирать себе сеть потому что ну кому хочется там например при связи облака с землей получите удар лад по диапазонам айпишник of да и вообще ну я хочу вот десятку а я хочу 172 я хочу 169 тот и так далее нужна связь между облаком и другими компонентами да и очень важный момент нужно возможности масштабирование сети до миллионов или даже десятках миллионов потребителей него клоунов а именно пользователи tenant of ну что но solution здесь очевиден до нужно виртуализировать эту сеть какие были на тот момент решения сегментация сети ну наверное все вот кто сетью занимается кто скажет ну можно этом вилла на использовать можно вверх использовать да ну звучит вроде как перспективно но есть нюанс и он заключается в том что даже если например мы говорим про vila vila найди это всего 12 бит он позволяет нам делать всего 4000 независимых сегментов сети а нам нужно десятки миллионов то есть если бы разница была бы в разы много чего не придумали но здесь разница на четыре порядка и вот здесь уже ничего придумать невозможно да то есть это технологии и в принципе нельзя использовать нельзя просто взять купить там у циски или джунипер а большие коробки и использовать их есть еще один нюанс если бы мы пошли путем уже небольших мортиза тароф мы бы стали зависимы от них стали бы зависимые от циклах их разработки от их вообще ведения сетевого мира ну и есть кстати здесь кто не сетевики кто знает какие цены на примеру маршрутизаторов на большие циски тут цифра не нужны то есть это это много правда этот реально дорого а теперь умножьте это эти цены на масштабы amazon и представьте себе какие были бы нас цены ну то есть это вообще не реальные вещи то есть мы решили что готовы их решение нет нужно варить что-то свое и уже 2009 годы уже через три года у нас вышло свое это на самом деле очень быстро ли писин это вот тасс а это такой для тех кто не пользуется облаком amazon это вот цель бокс до песочница ваша конкретная сетевая песочница вы живете в писе и считаете что другого мира в облаке не существует кстати в термин гопи сейчас используется на наверное большинством клауд провайдеров и других так вот формула пор стоит ли писин это sdn software define не только мы сделали уже коллеги в 2009 году у нас был sdn в продакшене в масштабах amazon что мы сделали ну понятно виртуализация да мы решили что нижний слой мы менять не будем там новые эти протоколы железо и так далее мы не будем трогать мы оставили ethernet мы оставили айпи ну и понятно что поэтому гонять пользовательский трафик тоже нельзя потому что он должен быть изолирован потому что и пи просто пересекается и так далее то есть мы а пользовательский трафик инкапсулируем специальный нами разработанный протокол обертку записи до который указывает из какого записей уникальными беседе этот трафик ну и соответственно дальше передаем по нашей сидит там опять разворачиваем делаем де капсюля цию ну и вроде как хорошо вроде опять же звучит легко но на самом деле это очень сложная техническая задача почему потому что вы должны знать а еще раз вот представьте себе просто какое количество виртуальных машин сейчас живет в облаке amazon бешеное количество где живет каждая виртуальная машина какой записи она принадлежит и на каком физическом сервере она живет для того чтобы делать вот эту виртуализацию которой мы сказал это огромная таблица которая должна быть постоянно доступна всем сетевым сервисам это называется mapping сервис при этом кто-то еще должен делать эту инкапсуляции юдика популяцию ну я уже на самом деле рассказал об этом это nitro kart а это специальный физический чип чтобы и избежать вообще хоть какого-нибудь оверхеды на на вот эти системы и штуки ну здесь очень быстро понятно что там механика более сложная но на уровне 2 на уровне ethernet а вы соответственно делаете запрос заворачиваются mapping сервис делает ответ пост и объясняя куда на самом деле трафик на какую другую физическую машину вы должны ее отправить ну а там из этого пакетика извлекаются нужные данные нужно найти и дальше уже постиг выпускается сразу вопросы еще один вопрос который мне регулярно задает василий слушая а вот хотя бы теоретически есть такая возможность на там получить например или не пить можно в сети мы можем чужой трафик услышать на самом деле даже в теории это невозможно на не драхма на nitro машинах например трафик который не позволено выходить из сетевухи он не просто не выйдет она его просто не выпустит но как это так двойная защита у нас есть еще validation ну это более даже к наверно актуально для машин который предыдущее поколение до метро где это было софтверная регулировалась так вот трафик на таргет машине на ту которая приходит пакеты он обязательно вы лидируете на mapping сервисе и только в том случае если он валидный он соответственно пропускается дальше атака набрасывается то есть у вас вообще нет никакой возможности например там подделать например ай пи адрес или войти в другой описи если у вас нет таких никаких примесей дануна или три в принципе там тоже похоже просто mapping сервис работает как раутер не буду здесь какие-то детали особо вдаваться здесь опять есть проблема и проблема заключается просто в банальных законов физики и эту проблему не победить для того чтобы каждый раз обратиться к mapping сервису у нас скорость света на сожалению очень небольшая в нашей вселенной у нас всегда есть гарантированная лет инси и эту в пенси нужно как-то победить ну подумайте коллеги как побеждается самый простой побеждать в пенси способ хэш супер это действительно кэш мы просто это каширу им и тут следующий вопрос василий ты же сказал что это огромная таблица вы чук к на каждой физической машине кэшировать и эту таблицу ну и конечно нет а потому что это не нужно потому что если вот посмотреть например вот на эту машину то вы видите на этой физической машине есть 2 записи это голубой и зеленый и получается что эта машина может разговаривать только с другими машинами на которых есть голубой либо зеленый в писе и поэтому мы должны только небольшой кусочек этого большого mapping сервиса кэшировать все остальное нам не нужно случае там випе теперь он и так далее ну соответственно дополнительно подгружается данные как нам работать с внешними сервисом так на послать на преданный в интернет ну вы же не можете инкапсулированным приватным протяну проприетарным протоколом послать эти данные конечно нет здесь нам помогает black wood black suit это пингвин такой он живет в южной африке с черными лапками на кой забавное животное и мы так назвали свой сервис который именно занимается связью с внешним миром почему потому что наша команда которая разрабатывал этот сервис она в южной африке часть южноафриканского пингвина что делает блок food black suit делает достаточно банальную вещь он-де капсуле рует трафик и потом делает то что нужно если это интернет просто туда в интернет бросает если это repent он заворачивает в писек и бросают по каналу и так далее есть еще одна вещь нам обязательно нужно как-то трек от flow нам как-то нужно трогать connection и куча сервисов это требует flow лакс security group и и the state full firewall я уже говорил да балансировщик над и так далее везде нужны нужно отслеживать connect и нужно отслеживать flow и для этих целей есть еще отдельности раз который называется гипер play on он появился не очень давно гипер плейн это сервис который мы начали строить на базе стрелу от балансира и здесь я заодно кстати вам секрет cs3 выдаю до с3 это сервис который размазан по сети то есть этом бешеном нога но давая конфигурация есть отдельное количество много бы кондо вых фронтэнда вы есть балансировщика ис-3 так вот мы решили что это тоже будет похоже что-то на ис-3 и пропилен работает здесь не тумане и он работает на их счету машинах только на этих этих штук и всю ту машина много памяти зачем а затем что нам нужна минимальная лет инси египта пленом обеспечивают latency в десятке микросекунды коллеги еще раз повторю десятки микросекунд это на два порядка меньше чем миллисекунды которую вы уже можете заметить это очень быстро при этом каждый гипер play но да это многие тысячи до этих нот у каждой у нее достаточно высокая пропускная способность 5 гигабит в секунду и агрегированные способность таки это бешеные терабайта получается ну естественно мы имеем возможность миллионы коннекта в секунду обрабатывают так вот многие наши современные сервисы такие как например разит gateway elastic file system это нфс да на самом деле это не какая-то коробочка которая там или несколько серверов которые стоят а это сервис который размазан виде гипер плейна тонким слоем по сети можно сказать что эти сервисы и есть сама сеть такое решение давайте поговорим вообще насколько насколько большая у нас сеть напомним что на текущий момент у нас 21 регион ну скоро будет еще на 4 больше мне кажется достойная цифра вот в каждом регионе несколько и в label эти зон зон доступности где-то 5 где-то 3 в каждой зоне доступности несколько да это центров каких-то до восьми до это центров 1 и выловили сезона до восьми до это центров в каждом да это центре стоит просто огромное количество серверов в некоторых до трёхсот тысяч серверов в одном да это центре а теперь математическая задача это все усреднить перемножить и вы получите приблизительное количество просто даже серверов в наших дата центров мне кажется этот это реально большой масштаб масштабирование масштабе а естественно все эти компоненты они связаны естественно они связаны избыточно redundancy у нас обязательно есть у каждого например а регионы есть минимум два транзитных центра которые связывают регион с остальным миром и собственно получается что у нас есть глобальная своя сеть которая принадлежит нам за исключением китаец правда ну по понятным причинам эта сеть принадлежит нам нам принадлежат эти кабеля и вот интересный тренд есть это как раз вот зависимость и в не видно что количество интернет backbone провайдеров количество трафика чик который через них проходит он все время уменьшается а через контент-провайдеры все время увеличивается что здесь стоит а стоит за этим следующее вы обращаетесь к какому-то ресурсу который находится в amazon так вот через интернет вы идете только до ближайшего points of presents до ближайшего седин точки а после этого весь этот трафик идет через атлантику идет в да это центр и падает на конкретный ресурс через наши сети которые полностью контролируются нам и обращаю ваше внимание мы не провайдеры мы частная компания и это касается и других больших ребят в том числе подумайте как меняется интернет настоящему буквально несколько слов про кабеля вот про физику да вот это вот современный оптический кабель который мы используем порядка 7000 оптических волокон да такие кабели они там по земле duty сесть на у нас есть кабель и которые полным под океанами там какие-то частично нам принадлежат какие то вы целиком некоторых странах мы кстати адаптируем эти кабели например в австралии эти кабели очень сильно полюбили с термитом кушает их просто и мы конкретно для австралии например анти термитные делаем кабеля вот ну вот такие нюансы да и естественно все это хозяйство она ведет разными путями резонансе избыточность и так далее итак коллеги время подошло уже концу наверное как-то надо закругляться вот смотрите мы сегодня начали разговор с загадки да с какой-то магии и но вот надо понимать что на самом деле даже когда вы знаете когда что-то работает магия она не отменяется вот я по образованию физик я знаю что такое закон бернулли я в принципе понимаю почему самолеты летают но каждый раз когда я вижу как критик мы нога тонны и железяка летит по небу для меня api реально чудо реально чудо знаменитый футуролог писатель-фантаст артур кларк сказал что любая развитая технология неотличима от магии на самом деле ну в магию я не верю но то что я зверю это в магов в людей которые при помощи технологии делают удивительные вещи друзья удачи спасибо большое дорогой культурная столица прямо хлещет философ и поэт я кстати хочу отметить что вот вы видели вот эти медведи которые они идут цвета вот этих медведей я прошу культурная столица но офиса amazon в россии его нет он в люксембурге я в люксембурге мне пришлось переехать туда из питера так вот пришлось пришлось да дружище я страдаю а вот и сказал климат похоже нашел а там такой же как в питере такой же пик фидере там все время дождя так вот а вот эти медведи который вот я не вижу здесь логотипа нету они идут ровно а как люксембургский флаги это было причиной она почему задается жертвами зритель любит всегда друзья вопросы погнали доброе утро да здравствует доклад у меня два вопроса первый вопрос продолжаете ливаю разработку своего жилета и второй вопрос когда вы придумали виртуализацию делали вы как-нибудь эксперимент где были конкретной метрики почему тайною схему виртуализацию лучше вопрос продолжаем ли мы варить свою железо до однозначно да вот более того я уже говорил что мы например начнем вот в конце года было объявлено что мы варим например свои arm чипы мы начали варить например отдельные еще сетевые модули когда вы можете подключать например специальные сетевухи для из писи до high performance for кладов то есть это еще дополнительно чипы то есть вот набор этих чипов он все время растет что касается были ли какие-то метрики мерили - здесь намерили естественно они были ноут к сожалению деталей я здесь ими поделиться сейчас не могу хотя вопрос конечно правильный просто все поясницу угла и была система борг из которой рада за каберне this они очень хорошо описали как они собственно пришли в горку и потом почему перешли на повернуть с да вы совершенно правы и про борки и про то что google наверно больше рассказывает про то что внутри я вот наверное в россии первая ласточка кто вообще пытается о чем-то рассказать как работой что-то в amazon ну мы как-то больше это держим держим себе эту информацию бородатый мужик назвался ласточки запомните момент да спасибо за интересный доклад спасибо вам а вот такой вопрос у нас несколько лет назад был там маленький проект был в общем у нас был бы baby born socket сервер и клиент и изначально у нас просто один был обсудит сервер там на одном на одном лице 2 потом мы как задумывались о том как немножко это чуть-чуть масштабировать там 2 3 сервера в общем если это поставить падла балансиры не совсем было понятно как как сохраняется connect с определенным сервером определенного клиента потому что если одного и того же клиента его постоянно между разными серверами балансировать то в случае постоянного соединения но вы об sockets соединения это как бы ну достаточно дорогостоящая я понял ваш вопрос я когда решаются года я я предлагаю конкретно вот это решение просто вывести вынести и там пообщаться вот потому что не всей аудитории это будет интересно но почему потому что у нас только одних лот балансе f3 и нужно сейчас мне уточнять какая по каком балансировщик и вы говорите и так далее то есть наверное это нлп я так предполагаю вот ну в общем давайте просто там встретимся и обсудим это вопрос я вопрос конечно классный первые пошли выйдем и отлично 1 раз привет василий спасибо за доклад меня зовут anton kovalenko из яблока собака у меня очень простой вопрос вот момент сервис в сети он где я хранить свои данные какую технологию используют если не секрет секрет неё ну правда колени поймите что даси есть вещи которые деле а есть вещи которые я просто не знаю то есть гнев хранить данные то есть распределенная система по даже то есть для тебя секрет или для не 8 ну ты здесь два уровня секретности встретились amazon было просто интересно это использует какие-то в рот и нос мысли тот же самый сервис который может купить внешние покупатель amazon или какой-то нет мнения это полностью то есть вы же понимаете что там требований они совершенно другие то есть даже просто сетевые требование там другие понятно спасибо попробуйте перри задать этот вопрос через полтора часа после начала of the party мы кстати да это тоже подход кретинская ты секретный уровень секретности после afterparty сразу падает пожалуйста добрый день меня зовут дмитрий нет такой вопрос и может послышалось вы говорили что технически невозможно подметить адрес поэтому я сказал что не подменять и пожалуйста это просто не сработает что не сработали потом он говорит что морган сервис тоже проверяют привилегии и если вы не стоите привилегий то он не a toast мы не привилегия он проверяет он смотрит он он видит от кого пришло то есть вот смотрите на том примере у вас оранжевый ли писин пытался подь-ка послать фейковый пакет все ниве писи и на машине на таргет машине где находится синий репетитор нет машина когда ее просто еще вот еще где капсуле рует даже не начала она просто берет от пакет смотрят от кого он пришел и он видит что она он пришел с другой машины то есть в оранжевый синий записи может ходить машины один два и три а он пришел с машина номер 10 и он просто говорит такого не бывает и все и его отбрасывает полномочий чтобы он выдал неправильно нет не нашел какие полномочия ну то есть на этом уровне ничего здесь не управляется еще есть пару минут на вопросы не стесняйтесь или все уже поняли что в автопати давай сели бы мучить вопрос с подвохом меня зовут максим спасибо за доклад amazon у россии дата-центра будут ну давайте так то есть нет есть если как бы без шуток то есть набор вопросов которые мы реально не не имеем права отвечать ближайшие полгода до это центров не будем с кантами если у коллеги сразу прошу прощения на вопрос про ркн я тоже отвечать не буду ну вот так но я был приятным в апреле прошлого года именно в россии вы можете себе представить что мне говорили мои заказчики вот по силе надо выбрать кому еще хотите спросить что в клара да да кому подарим за вопрос а мне понравилось как коллега индекс облака пытался выведать суперсекретный вот это хороший вопрос сейчас под аплодисменты тогда коллег из яндекс получается утешительный приз книгу по силе теперь спасибо большая за за то что подготовился и так красиво от танцевал тебе тоже утешительные призы как обычно эта коробочка орешков и глаза на при главе operate яндексе да спасибо а дело друзья"
}