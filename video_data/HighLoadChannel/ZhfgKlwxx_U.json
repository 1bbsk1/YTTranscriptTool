{
  "video_id": "ZhfgKlwxx_U",
  "channel": "HighLoadChannel",
  "title": "Надежное взаимодействие в распределенных системах / Михаил Курмаев (Badoo)",
  "views": 2268,
  "duration": 2426,
  "published": "2019-01-14T00:08:02-08:00",
  "text": "всем при от меня зовут михаил маев я работ в компании буду ее рук этим наш отдел инфраструктурный и мы делаем backend для бэг-энда сегодня мы поговорим о надежном взаимодействие распределенных системах настоящий момент наверно практически любая система является распределенная если у вас есть апликэйшен сервисы базы данных вам уже нужно настроить какое-то взаимодействие между ними с ростом компании при увеличении количества пользователей компонент становится все больше и таких взаимодействий становится еще больше и любая любая ошибка любая любая проблема этих взаимодействиях может катастрофический обернуться для всего проекта в целом мы теряем деньги за простоя чем больше проект тем больше денег он приносит и самое главное мы теряем репутацию пользователи к нам больше не вернуться именно поэтому очень важно сформировать четкие правила для подобных взаимодействий у нас баду 4 дата центра больше трех тысяч серверов где-то 50 наверно все можно сервисов часть из которых самописный и 390 миллионов пользователей поэтому нам очень важно чтобы наш сервис работал 24 часа в сутки 7 дней в неделю только представьте себе сколько судеб может сломать не работаешь из течение всего одного часто dating service поэтому основываясь на нашем опыте а также посмотрев как подобные проблемы решаются в других популярных фреймворков и продуктах я представлю вам рецепт построения надежного взаимодействия и на первый взгляд этот рецепт довольно прост нам нужно взять хороший connector подумать о том как мы будем переключать нагрузку и не забыть о пользователях сделать так чтобы им по отображались ошибки правильно но программный комитет и лично олег бунин сказали что тут не кулинарный мастер-класс а серьезный highload конференция поэтому я добавил немножко хардкора и в конце я расскажу вам о нашем видении паттерна circus breaker я его реализации итак начнем хороший коннектор что такое вообще коннектор коннектор это кусок кода который работает на applications сервере он занимается собственно коннектом к базам данным и сервисом а также желанием и приемом запросов и ответов от этих сервисов во всех популярных френ горках уже есть подобные коннекторы и мы уже есть но вопрос что же такое именно хороший коннектор идеал как известно недостижим поэтому я выбрал три самых главных правила хорошего коннектора первое это наличие конфига второе логирование ошибок и третье это сбор телеметрия что касается конфига мы сейчас не будем говорить о конкретной его реализации в простейших случаях это могут быть файлы в отдельных директориях либо можно использовать специальные сервисы для этого на priority сиди консул элизу кипер самое главное нам сейчас понять для чего же нужен коннектор конфиг конфликт нам нужен для того чтобы менять поведение соединения не влезая в код таким образом конфиг становится неким соглашением между различными людьми отделами между людьми и машинами то есть пишут его разработчики в него могут писать админы и вот читают админы и разработчики также его читают собственно машины я взял пример такого конфига из одного популярного фреймворка он в принципе довольно неплохо но что мне сразу бросается в глаза мне сразу не нравится и печники в хвостах понятно что скорее всего это просто пример и в реальной жизни все не так но очень важно чтобы в конфигах не было и печников айпишник они понятны представьте что у вас 50 хвостов в конфиге все они и печники рано или поздно вы в них запутаетесь и ошибетесь для решения этих проблем давным-давно придумано служба dns поэтому придумайте именование хвостов вашей системе и пользуйтесь ей в качестве хорошего качества хорошего именования можно придумать например такую систему когда у вас есть название сервиса и какой-то индекс но не стоит слишком сильно обобщать и называть например все хасты с базами как д.б. в конце концов у вас будет 50 басы вы тоже запутаетесь них то есть также какая пишем запись никами а тут сожалению в разделе хорошо напишем один хост без без индекса на самом деле индекс очень важны и даже сейчас вас всего один сервис отвечающий за что-то лучше поставьте ему индекс 1 потом вполне возможно он добавится еще один и у вас не будет головной боли и также старайтесь избегать неоднозначных чтений у нас например был хвост который назывался скриптик с czech но почему-то сейчас его все читают по другому следующим важным параметром которого нету в приведенном конфиге это тайм-аут и тайм-аут и бывают разные бывают тайм-аут и на коннекта на чтение на ожидание важно понимать что тайм-аута это максимальное время которое мы ожидаем самое время которое по сути дела ваша программа не работает и нет смысла ставить тайм-аут в минуту если максимальное время работы скрипта у вас полминуты а в печке по умолчанию это именно так поэтому обязательно ставьте тайм-аут и и выставьте их небольшими одну-две секунды и дальше по необходимости уже увеличиваете следующим параметрам в конфиге является паролем от базы данных либо каких-то других сервисов как я уже говорил а конфликт что такое куда смотрят все все их читают все видят с другой стороны пароли это такая очень личные вещи некому смотреть на них не надо поэтому отсюда напрашивается вывод что боролись в конфиге быть не должно и действительно если компания маленькая то все знают пароль и все ходят под одними паролями все вроде хорошо но пароль в этом случае такая как бы видимость безопасности при росте компании появляются какие-то роли разработчики начинают ходить под своими паролями появляется добей скрипты и ходят уже под своими паролями у нас например веб-скрипты не имеют прав надо del запросы также не имеют прав на дэвид запросы таким образом мы делаем дополнительную защиту от и сквален лекции соответственно вопрос а где же хранить пароли но мы у себя пароля храним отдельно у нас есть специальная машин из которых идет раскладка кода соответственно там есть набор пользователей и каждый день ровно 2 часов ночи мы перегнили порой для очередного пользователя поставок моего пить грилем и раскладываем все кайден шился на базы данных после этого порой становится активной и логин пароль становится активным и он подмешивается в билд в auto-key деленный файл на следующий день берется следующий пользователь и так по кругу таким образом пароль и постоянно у нас ротируется и даже если разработчик каким-то образом увидел пароль он будет валиден всего в течение нескольких дней следующим важным свойством confide является его структура если вы делаете с вы используете коннектор из фреймворка скорее всего структура у вас записано в документации и вероятность что-то сделать не так общем то нет у вас структура четко определена но если вы делаете коннектор свой саммита очень часто возникает соблазн добавить туда побольше гибкости хочется сделать задела на будущее напихать туда куча всего сделать какой-то может быть туда бы даже под с условиями напихать но этого делать не стоит наверняка многие из вас видели конфиге иван джон x а через какое то время с ростом проекта эти конфиге настолько разрастаются что человек неопытный и залей залезая в них вообще не понимают что там происходит он закрывает и уходит но мужчины все в принципе это оправданно потому что это целый язык программирования веб-сервиса в коннекторе такого в общем-то не нужно нам нужно только всего несколько параметров поэтому придумайте четкую структуру и следуйте ей структуру можно проверять с помощью unit тестов либо как-то еще мы у себя пришли к такой структуре то есть у нас есть на верхнем уровне виртуальными сервиса и дальше именованный список хостов в этом конфиге обязательно параметры хосты порт по ним ведется мониторинг также обратите внимание на секцию common она очень удобно для того чтобы не повторять повторяющиеся параметры следующие наверное самое важное свойство confide является его независимость от кода я уже говорил о том что конфиг нужен для того чтобы что-то поправить и его использует все и поэтому править смысл его просто так не то нужно чтобы эти изменения разложились на продакшене и маленькой компании когда все просто обычно у всех есть право все раскладывать все могут очень быстро поправить конфиг и быстренько его раскидать по production машинам в большой компании появляется целый процесс тепло и то есть появляется релизы по расписанию стретчинг сервера тестирования и диплом кода он становится такой большой сложной машиной и очень часто получается что выкладка конфига в эту машину она не совсем вписывается админу для того чтобы добавить новый сервер в кластер нужно ждать еженедельные выкладки что скорее всего не очень хорошо поэтому сделайте так чтобы конфликта складывался отдельно чтобы это была отдельная отдельную процедуру раскладка независимо от процедура складки кода у нас конфиг раскладывается через web-интерфейс в нем видно на 3 нему настраиваются право кто может рассказать во вторых видно кто раскладывал когда раскладывал и видно все изменения это удобно и так конфиг должен быть независимый и структурированный следующее важное свойство коннектора является сбор ошибок дело в том что сами тексты ошибок и влогах обычно воспринимается как некое тучи на небе то есть хочется от них как-нибудь избавиться и сделать так чтобы угол было пусто на самом деле ошибки берлогах это всего лишь следствие проблема она на самом деле в чем то другом и важно понимать что наш коннектор он действительно пишет все ошибки важно понимать что если у нас не получился коллекция либо случилась какая-то ошибка на сервере мы увидим это все влогах поэтому очень важно проверять что все проблемы приводят к ошибкам во влогах лучше там будет три ошибки чем ни одной вторая важная часть касающийся ошибок это информативность ошибок представьте ситуацию у вас будет в три часа ночи боишься что-то сломалось вы листья влоги а там вот такое остаток ночи скорее всего будет безнадежно испорчен поэтому очень главном очень важно чтобы в текстах ошибок была максимальной информацией чтобы было понятно что же случилось когда случилось почему случилось в ошибке очень часто смотрят в каких-то экстренных случаях когда а когда уже все плохо и вот такими вот текстами ошибками мы делаем ситуацию еще хуже в качестве примера я взял пример из наших а разлогов тут в принципе все понятно понятно что случилось куда мы коннекте лись понятно что случился тайм-аут собственно размер этого тайм-аута и бак trace который я спрятал для наглядности следующее важное свойство хорошего коннектора является сбор телеметрия любой запрос можно разбить на две условной части первое это внутреннее время это все что делается собственно процессор второе это внешние внешне и время это когда программа ждет исполнении где бы запроса либо это может быть ожидании диска либо это может быть конце концов команда слив и для того чтобы собирать телеметрию нам нужно при каждую каждый запрос померить время начала время конца вычислить разницу и отправить на какой-то агрегируются сервер таких агрегированных серверов есть на рынке несколько есть стадо есть графит мы используем pingu которую сами написали такие агрегации позволяют получить нам понимание из чего же у нас состоится собственно это внешнее время то есть сколько времени уходит на общение с базы на коннекта на запросы с малышом с другими какими-то сервисами и это понимание очень важно во первых для того чтобы знать что же можно оптимизировать во вторых в случае каких то проблем мы сразу видим что ж у нас выросло и уже быстро точечно решаем конкретные проблемы pingo позволяет строить нам отчеты примерно такого вида то есть мы видим сколько времени идет на какие команды количество запросов и среднее время кроме среднего времени очень важно смотреть на пирсинг или на большие пирсинг или типы 99 95 пирсинг или потому что среднее время она в принципе хорошо но иногда оно как средняя температура по больнице пока пожар не начался она сильно не меняется при ценители же помогают нам выявить проблему гораздо раньше пинбол позволяет нам строить вот такие вот отчеты но все они строятся в реал тайме то есть мы видим что происходит сейчас для того чтобы видеть динамику мы покажись такой цифры рисуем график и одна из самых крутых фишек наших графиков является возможность увидеть любой график с наложенными на него событиями эти события это могут быть выкладка кода выкладка конфига какие-то патчи и даже футбольные матчи таким образом очень легко можно связать какие-то роста или падения на графиков с какими-то событиями кто-то что-то выложил тут же видно кто выложил можно связаться с этим человеком и узнать зачем это сделал этот инструмент у нас так и называется а что же случилось или сокращенно в атф и так хороший коннектор состоит из конфига который должен быть структурируем независимые от кода он должен собирать ошибки и собирать телеметрию следующем градиентом надежно взаимодействия является переключение нагрузки мы говорили о том что коннектор под конектится но он собственно должен конектится к чему-то и это что-то должны построить каким-то образом мы мы должны построить какие-то отказоустойчивые сервисы для того чтобы построить такие сервисы нам нужно ответить на 2 вопроса как то ли включать нагрузку и как же понять что после переключения нагрузки хуже не стало сейчас есть очень много всяких пластин их решений и с такими вещами они в принципе отчасти справляются сами например кассандры делает это через свой коннектор клик house может ответить на любой сервис из сервер из-за plaster можешь ответить на любой вопрос запрос если же вам не подходит ни одной из пластин их решений придется строить что-то свое для построения своего свои отказоустойчивой сетей может помочь прокси сервисы типа in вой инвайта такой сервис который ставится на апликэйшен оду он знает о класс тире ваших сервисов и а знает куда можно коннектится как пристрелять нагрузку случае выпадения какой-то из моды и нго и между собой общаются и эта информация довольно быстро распространяется также январь позволяет отключать конкретные ноды например если они начинают сыпать какими-то ошибками такой паттерн называется иркут breaker а нашему видение я расскажу чуть попозже но после того как мы построили какую-то систему нужно понять что она действительно работает что приключение происходит нагрузки происходит правильно давайте представим себе что мы построили систему из двух серверов мы случайно коннектимся к одному из них делаем запрос если не смотри не смогли приконнектиться делаем запрос другому такая система выглядит как вполне устойчиво и действительно если один из серверов падает вся нагрузка переключается на другой и он как бы обслуживает но до тех пор только пока нагрузка на каждый сервис меньше 50 процентов то есть суммарная нагрузка меньше 100 процентов если же нагрузка большую при падении одного сервиса сервера вся нагрузка переключается на 2 и 2 тоже начинает падать то есть очень важно понимать какой запас прочности у вас есть нужно понимать что оставшиеся сервера они смогут пережить падение одного из серверов другая ситуация у нас есть уже 4 сервера и каждый из них загружен например там на 60 процентов то есть суммарная нагрузка на весь кластер двести сорок процентов если падает один то оставшиеся три наверное выдержит эту нагрузку ну скорее всего так если нагрузка переспит лица равномерно но может случиться так что после падения одного сервера нагрузка с него перепадает на другой сервер он тоже падает потом переходит на другой сервер тот падает и все у вас очень красивого лица я намеренно не говорил в чем именно изменяется нагрузка в данном случае мы измеряли ее вам индексах но обычно нагрузка измеряется либо нагрузки на циpкa либо занимаем памяти это может быть и обсе на диске сетевые пакеты либо какой то сложные комбинации из этих всех пунктов и действительно важно понимать что же у вас на что же тратится нагрузка но на самом деле есть только единственный способ понять что у вас действительно все хорошо это уронить что-нибудь если вы построили отказывай устойчивую систему возьмите уронить один сервер у вас либо будет доказательство что все хорошо и у вас система отказывал стой чего-либо вы поймете где вы облажались и начните быстро это чинить итак для надежного взаимодействия нам нужно понять как мы перестреляем нагрузку нужно рассчитывать как нагрузка будет перераспределяться и попробуйте что-нибудь хранить это добавит вам уверенности следующем инцидентом является обработка ошибок в нее скорее погас ошибок до этого мы говорили о чисто технических вещах мы говорили о серверах конфигах и тайм-аут ах но самое главное в нашей системе это наши пользователи пользователям на самом деле все это не очень интересно им нужен сервис и нужно чтобы сервис работал все было хорошо но к сожалению как мы не строили системы все равно невозможно построить на сто процентов отказа устойчивую систему у вас все равно где то будут какие-то проблемы и нужно помнить о них нужно к ним готовиться давайте посмотрим на пример я взял скриншот с нашего сайта это один из главных экранов слева внизу виден блок который называется spotlight этот блок на самом деле очень важен для нас вернем важен в первую очередь для пользователей потому что помогает пользователей продвигать их профайлы ну естественно он важен для нас постольку поскольку продвижения не бесплатная но бывает ситуация что сервис отвечающий за этот блок он не доступен что же в этом случае делать мы просто его и потихонечку скрываем пользователи этого особо не замечают и они не пугаются но тем не менее нужно быть очень аккуратно со всякого рода списками и счетчиками представьте себе ситуацию что на этой странице у нас показаны и список подписчиков пользователя у него 500 23 подписчика и он этим гордиться и радостный и заходит на сайт и видит что у него 0 подписчиков скорее всего он сильно огорчиться еще более более сложная ситуация если такие списки формируются из двух различных сервисов и один из этих сервисов недоступен и мы показываем пользователю что у него не 523 подписчика а только 128 он заходит видит что у него подписчиков очень мало и в этом случае он огорчается еще больше потому что думают что дело в нем они у вас соответственно в этом случае просто стоит показать честно пользователю что сейчас у нас кусочек не работает но как бы можно пользоваться спокойно всем остальным пользователь видит это понимает и идет дальше но бывает ситуация когда вообще невозможно ничего показать не работает какой-то самый главный сервис в этом случае нельзя не в коем случае показывать какие-то страшные ошибки с рейсами либо с чем-то ещё пользователи это видят и очень сильно пугаются покажите им красивую страничку в котором написано что все хорошо лучшие специалисты уже работают над проблемой и очень помогает на этих страницах сделать счетчик обратного отчета пользователи видят прогресс и считают что все прекрасно в этом случае вы еще имеете дополнительный benefit в том что пользователи и постоянно не refreshed ты не создают вам дополнительную нагрузку вопрос том каким же какой же размер выбрать этого счетчика выбирайте что то более менее похоже на правду например если вы реагируете среднем час на проблему какую то поставьте час также этот счетчик очень поможет при каких-то глобальных мантийцев но в этом случае вы уже время четко знаете и так третьим важным самым важным ингредиентом надежно взаимодействия являются наши пользователи самое главное правило их не пугать скрывайте аккуратненько функционал не показывайте пустые списке и показывайте красивые страницы с ошибками и счетчиками как я обещал дальше я расскажу вам о нашем видении паттерна циркус breaker ну давайте поймем для чего же нам нужен этот паттерн у нас php-fpm с фиксированным количеством worker of в принципе схема с фиксированным количества маркеров она полезна не только спички но и на других системах другими языками программирования но у нее есть одна проблема собственно она и заключается фиксированным количеством бургере маркеров если у вас есть какой-то сервис который начинает начинает тупить то может создаться такая ситуация что все worker и заняты ожиданиям этого сервиса то есть мы больше не можем никак обрабатывать не какие запросы поэтому мы хотим сделать наш цирк брекером таким чтобы он не позволял больше чем какое-то число n worker of ожидать какого-то определенного сервиса это н можно выбрать например как половину количества маркеров какие инструменты у нас есть для общения между маркерами в печке у нас есть shared memory и конкретно его реализация опцию давайте посмотрим как можно решить эту проблему в самом простейшем способе проблемы является фактически классическая она решается через счетчик мы заводим счетчик в котором есть имя хоста и перед отправкой запроса к сервису мы инкрементируем его после отправки де клементи ruim в случае достижения счетчика числа нашего н нашего лимита мы не делаем запросы к сервису принципе это такая реализация была нашей первой версии мы ее запустили все вроде более-менее работала circuit breaker стал отключать сервиса если они купили но через какое-то время мы заметили что отключение происходит слишком часто что иногда даже не то пищи сервис отключается мы стали разбираться в чем же дело и поняли что в данной схеме у нас не гарантируется то что счетчик садик ремонтируется может случится где-то какая-то фатальная ошибка по дороге может скрипта превысить максимальное время исполнения результате счетчик постоянно накапливается ошибку и тем самым все работает не совсем так как мы хотели поэтому мы взяли весь временной интервал разбили его на куски по пять минут и добавили время начала этого интервала вы не счетчика таким образом ошибка у нас не накапливается но тут у нас появилась другие проблемы во первых у нас есть проблемы на границах счетчиков на границе не интервалов потому что в это время счетчики показывают не совсем то что нужно нам и вторая проблема это то что если даже сервис отключился при наступлении нового интервала счетчик сбросится в ноль и сервис опять включится мы решили эту проблему следующим способом мы добавили некий флаг который назвали дизайн болт 7 х 100 х 100 и выставляем его когда когда счетчик до достигнет своего лимита мы выставляем его этот флаг на некое определенное время скажем минут на десять соответственно таким образом мы избавились от некоторых проблем но дело в том что в этом случае мы очень поздно реагируем на введение в строй обратно h100 и мы к сожалению не можем уменьшить время жизни этого флага до каких-то да чисел тип этом 10 секунд либо каких-то таких времени времен меньше максимального время жизни скрипта поэтому мы подумали еще усложнили код мы добавили еще один флаг и вот зачем он нам нужен мы точно также оставили предыдущие флаги но теперь мы его ставим ни на какое то время жизни а на постоянку и делаем так чтобы раз какое-то время только один из маркеров пытался конектится к сервису и смотрел в порядке с ним что-то или не в порядке это нам позволяет специальная команда поцелуй она называется id то есть 1 мм гарантирует что у нас только один worker добавить этот флаг все остальные получат ошибку таким образом мы сократили время введения в строй и в принципе решили большинство проблем примерно в таком виде у нас код сейчас ее работает мы подумали о том чтобы выложить этого пан source но потом решили собственно чё тут выкладывать я уверен что у вас займет пару часов а может быть и меньше реализация этого псевдокода поэтому давайте считать нашим вкладом open source этот слайд и так для надежного взаимодействия нам нужен хороший коннектор у которого должен быть независимой структурирование конфиг он должен собирать ошибки мы должны собирать телеметрию также нам необходимо понимать как мы переключаем нагрузку что будет после ее приключения а так же не забывайте о пользователях не пугайте их большое спасибо за внимание с удовольствием отвечу на вопрос так давайте вот что вопрос просто михаил спасибо большое за доклад грызть скрыть просто чтобы вот вы сказать что что максимум 50 процентов worker of вас будут залившим если один сервер залип и а если два сервиса залипнем что случится в этом случае вашей системе спасибо за вопрос на самом деле мы думали об этом и у нас даже была примерно и решение мы хотели сделать еще некую надстройку над всей этой системой чтобы у нас был отдельный пул fpm worker of из одного worker а который проверял что действительно сейчас мы занимаем не слишком много не слишком много worker of в 10 ожидания всяких разных хостов и отключать по возможности некоторые из них но мы подумали что это слишком сильно усложняет систему и сейчас на самом деле отключение хостов происходит не так часто то есть это буквально там ну может несколько случаев за месяц поэтому поэтому пока ничего ещё есть вопрос о кого-то надо войти а подождите сейчас выкопал что было слышно трансляция спасибо за доклад вопрос такой вы говорили относительно нежелательности использования прямых айтишников вместо этого соответственно танец я так понимаю что у вас каким-то образом реализован отказоустойчивый dns может вкратце рассказать каким смотрите у нас прям отказоустойчивый dns вы имеете ввиду у нас он не падает осмотрите ну во первых есть каши для dns и честно говоря ну выпадения для нас это такая очень странная вещь у нас он не падает и с таким проблем мы не сталкивались скажем так насколько я знаю нет этот вопрос лучше адресовать нашим админом антон турецкий будет выступать по моему по моему завтра если я не ошибаюсь можно задать этот вопрос ему если будут еще у кого то вопросы то можно будет позже их задать на дискуссионной площадки которая находится снаружи зала сейчас скажем большое спасибо михаил за доклад"
}