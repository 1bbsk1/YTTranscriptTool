{
  "video_id": "ledECib4y0E",
  "channel": "HighLoadChannel",
  "title": "Проблемы эффективного использования MySQL на современном оборудовании / Алексей Копытов (Percona)",
  "views": 478,
  "duration": 2621,
  "published": "2017-04-22T14:47:46-07:00",
  "text": "меня зовут алексей копытов я работу разработчикам в компании бекона некоторым возможно известные честно разработки перка на сервера перга на x3 backup для которого также по совместительству являюсь лидером как правильно руководителем проекта и немножко перк он из фсб кластера рассказывайте сегодня буду про проблемы производительности mysql на современном оборудовании ну и как времен железе ну и как следствие проблемы на высоких нагрузках поскольку одни только проблемы разговаривать грустно то иногда я буду указывать способы как можно эти проблемы обнаружить и соответственно какие-то способы для их решения до небольшой экскурс в историю майский майский разработки моей спел началась примерно в девяносто пятом году но некоторые участки коды были заимствованы из других проектов более старых и там истории тянется что 79 год изначально разработка велась на солярис из пар потому что на тот момент эта платформа была наиболее перспективных с точки зрения бонте тоже народ кино тебе началась примерно в то же самое время в девяносто пятом году в 2000 году он тебе было включено интегрирована в москве изначально разработки велась на windows nt но видимо потому что на тот момент эта платформа была наиболее перспективных с точки зрения хикки туре и да это старые проекты по меркам айти в общем в этом не было бы ничего страшного но дело в том что многие критичные с точки зрения производительности участки кода были написаны совсем других реалиях для совсем другого железа и для других операционных систем я участвую натыкаюсь на подобные комментарии в коде на debian например вот там какие-то константы которые управляют примитивными синхронизации например мьютекс от они были рассчитаны на pentium 100 мегагерц и visual си плюс плюс или там вот эта операция она там занимает какое-то время и поэтому работает таким образом исходя из вот реалии sparco в девяносто третьем году и какие основные проблемы у моей sqweel есть современным железом ну во-первых память размер памяти на машинах постоянно растет на скорость доступа к этой памяти растет не так быстро поэтому у нас есть большие объемы и как-то эти большие объемы оперативной памяти не помещается больше данных на эти данные нужно как-то эффективно обрабатывать алгоритмы как правило они не заточены падают они были написаны для совсем других объемов памяти архитектура numa встречается все чаще я про нее будут говорить подробнее в процессор и безусловно больше лошадиных сил но их нужно как эффективно использовать я бы не сказал что моя скала эффективно работает с кэшем с какими-то векторами инструкции например процессора практически не используются хотя могли бы в некоторых местах ssd безусловно требует нового подхода для организации чтения и записи данных ингибин делает довольно много глупых вещей с точки зрения ssd который не имеет никакого смысла я об этом тоже подробно буду говорить наконец блокировки сервере они совершенно неадекватным высоким нагрузкам да то есть когда у нас высокими нагрузками для москве считалось там 1020 активных соединений то было совершенно нормально брать какие-то большие блокировки и по долго обрабатывать кита данным данные погасим ее блокировками а когда у нас активных соединений может быть там 1000 2000 8 тысяч эти блокировки уже просто не работают сервер не масштабируется такие нагрузки эффективно мы переходя к практически по практическим вопросам начну с самых простых вещей g moll op те кто программировал когда-нибудь на сессии плюс плюс знакомы с такой функцией молоке разными вариантами и функции фри это функции для управления динамической памятью да вот та реализации этих функций которые присутствуют стандартной библиотеки geely psy она но не не самая плохая но проблема с ней в том что она не масштабируется на большое количество активных соединений и вот здесь такая библиотека джима лог разработанная джейсоном эвансом который сейчас работает в facebook она масштабируется гораздо лучше чем дефолтная реализации в деле psy и двигать эко используется по умолчанию firefox при бензин и объезде и в общем тут даже думать особо нечего если вы как-то используете мая sqweel на больших нагрузках то нужно использовать джема лог а не дефолтный локатор с одной каморке джима лог работает эффективно в том случае если количество активных потоков соответственно количество активных соединений превышает количество ядер суммарное количество ядерного системе это значит что при меньшем количестве потоков и при меньшем количестве активных соединений он будет работать эффективно но для этих нагрузка куда ты его целевая нагрузка для более для меньшего количества потоков возможно можно найти coin специализированного кадр который обработают будет работать чуть чуть эффективнее но не сильно и вот эти графики показывают насколько эффективен бывает же молок левый график это нагрузка резонные только на чтение право это чтение и запись как видно при небольшом количестве активных соединений ну где-то там до 64 какой-то особой разницы между дефолтным локатором между дефолтной реализации молока и джема лог в общем-то не наблюдается но с другой стороны джема лоб и не хуже это тоже важно с другой стороны при высоких при большом количестве активных соединений при высоких нагрузках есть некий интервал в котором же молок дает трехкратное увеличение производительности что в общем не мало для такой простой вещи как замена локатора ну а где то там на 4000 соединение сервер и умирает это не связано никак сжимал оком это друзья проблемы которые мы решили позже и они тоже буду рассказывать до свежей версии джамала всегда доступна в репозиториях беркана ну потому что в тех репозиторий которые доступны в дистрибутивах могут быть старые версии джамал окон активно развивается и разница функциональности и производительности между разными версиями может быть значительный она всегда свежая версия и есть такая удобная опция называется мало клип который можно сказать в конфигурационном файле она просто делает eldepryl от вот указанной библиотеки перед тем как запустить сервер поговорим про баффер пулы проблемы связанные с производительностью баффер pull a better пол это такой краеугольный камень производительности моя склеил и на тебе каждый кто хоть раз настраивал настраивал мой успел знает что очень начинать нужно с настойки water polo посмотри насколько он адекватен доступной памяти и дать им повод по сути свой дисковый кэш на для и на тебе каждый раз когда она тебе хочет прочитать или модифицировать какую страницу у нас начало считает данные с диска в буфер pull этот процесс довольно простой дал называется чтение обратный процесс когда и на тебе записывает модифицирована страницу обратно на диск называется флашинг и вот алгоритмы которые управляют этим процессом они уже нетривиальные там есть много разных критериев и алгоритм довольно сложное и проблема которая возникает вот с чтением и флангам на высоких нагрузках это неэффективно и вычисление контрольных сумм на тебе используют контрольной суммы для страниц для контроля целостности страниц каждый раз сказал стране сочетается с дисков баффер пол не проверяет вычисляет контрольную сумму сверяет с тем значением которые записаны в заголовке страницы если они спадают на странице неповрежденные каждый раз когда я на тебе записывай страницу на диска но опять же вычисляют контроля суммы записывает значениях заголовок и когда у нас по система дисковая подсистема выполняет скажем сотни вепсов да это вот операции ввода-вывода то проблемы с неэффективным вычислением контрольных сумм она ну скажем так теряется на этом фоне они так заметно в тех случаях когда вот например на из езде и современные там промышленные ssd обеспечивают сотни тысяч iops of операции ввода-вывода секунду то проблема с эффективными неэффективным алгоритмы вычисления которыми ум становится заметной и то реализация контрольных сумм который используется в нози би по умолчанию она не особо эффективно аспекту проблемы обнаружить что вот на вашем сервере то проблема присутствует но если вы посмотрите в результате вывод результат работы какого-нибудь профилировщика типа там пурман профайлер или о профайла ле перф то вы увидите где-нибудь тамбов cold функцию баф paltalk passionate sex он где-нибудь верхних строчках дата эта функция бы занимать какое-то нетривиальное количество от общего времени выполнения с помощью performance кима пока не как это нельзя обнаружить там просто соответствующие участки клода не инструменте раваны что делать в этом случае если вы вычисление контрольных сумм для страниц является узким местом в purple на сервере уже давно начиная с версии 5 1 а может быть и раньше не проверял если коррупции на тебе fast чек сам которую можно включить но она требует полного полной полной перезагрузки данных да потому что она меняет дисковый формат и нужно да все данные будет перезалить заново это не очень удобно и вот в москве 56 в принципе rcon сервер 56 появилась опция и на тебе чек сам алгоритм который можно поставить значение crc32 когда это опции установленных такое значение то и no debe будет использовать во первых более эффективный алгоритм crc32 для вычисления контрольных сумм но вдобавок к этому если процессор поддерживает аппаратное впечатление контрольных сумм я специально инструкции современных процессорах которые это делают то был использован и бы были использованы аппаратный подсчет контрольных сумм да это опция выключена по умолчанию видимое соображений совместимости какой-то обратный хотя я честно включил evil по умолчанию потому что ну нет на самом деле каких серьезных причин помимо обратной совместимости не использовать эту опцию документация говорит что если вы включите если вы установите эту опцию в значения стрельцы в центре согласно будет немножко побыстрее работать но это неправда я рекомендую устанавливать значение sfc 32 стрельцы центре зала просто говорит что и на тебе будет не будет принимать в контрольной суммы записаны в старом формате это значит что если вы становитесь это значение это опция в значении стрик ттт трясла нам придется перезалить все данные если вы установите просто значение crc32 то новые страницы вновь модифицирована странице был использовать новые контрольные суммы старые данные которые не модифицируются будут использовать старый контрольной суммы но я не вижу никакой проблемы дак я уже говорил это это ухты используют аппаратную скорее не если доступно работает только для одной страниц и почему-то обошли вниманием разработчики в oracle те контрольные суммы которые записываются в ряду лак я об этом подробнее расскажу позже что снова но вот традиционной архитектуры организации взаимодействия процесс раз памятью показано слева ее можно назвать условно ума или unipharm memory access организовано таким образом да у нас есть общая память общая для всех общая шина и все процессоры которые есть системе общаются с памяти через эту шину это архитектура плохо масштабирует своем потому что скорость доступа к памяти не растет такими темпами какими темпами увеличивается скажем количество ядерном процессоре да и количество процессоров системе то есть память и собственно и и так является довольно медленным устройством с точки зрения процессора а при увеличении количества ядерных процессоров нам оказываемся ситуации когда процессоры большая часть времени просто простаивают и ждут доступа к памяти и эта проблема собственно будет обостряться потому что до тех пор пока не пройдет каунтом революционного скачка скорости доступа к памяти поэтому производители оборудование лишь решают эту проблему следующим образом они сегментируют систему да тут вместо 1 1 какой-то общей памяти у нас есть несколько сегментов все процессор определенные сегменты и памяти норвегии сегменты эти сегменты называются ноды соответственно доступ процессорах памяти в своем родном сегменте crm и своей родной ноги он быстрый а вот доступ к чужой памяти памяти в удаленных нотах она очень медленная потому что это делается через другую шину и казалось бы все хорошо у каждого процессора своя быстрая память и они друг друга не мешаются ну или мешаются меньше чем если бы они все имели доступ к общей памяти точки зрения баз данных это очень неудобной архитектура потому что любой базы данных есть как минимум один общий буфер который желательно чем больше тем тем лучше да собственно некий кэш данных и в любом случае мы хотим чтобы у нас все соединения выполнялись на любых процессорах и это значит что в любом случае будет доступ к удаленным но там будет доступ медленной памяти ну вот как здесь данный пример показан на запрос месте где надо по 16 гигабайт в сумме 32 гигабайта и и на тебе бофор пол с configuring двадцать восемь гигабайт значит часть из него будет размещена на одной ноги мы не можем разместить его на какой-то одной ноги часть будет в другой ноги каждый процессор теоретически имеет шанс обращаться к памяти в отдаленной ноги это будет медленно еще одна проблема с этим связаны заключается в том что память всегда выделяется на текущий ноги по умолчанию то есть если при старте сервера мы выделяем какой-то большой буфер пол ядро по умолчанию использует всю доступную память на текущий ноги и только оставшийся кусок который там сколько нам не хватило будет выделен на на удаленный но dido это означает что в том случае если у нас практически не будет свободной памяти на одной из нот потому что там будет занято все полностью под бафф apple если там процессу какому-то потребуется память то у нас начнется с popping несмотря на то что в другой ноги у нас полно свободной памяти ну вот так ядро linux работает это поведение сильно зависит от версии ядра linux но в любом случае это негативные эффекты обеспечены при вот такой схеме то и единственное что придумали пока что для решения проблемы это использовать interlink чередование памяти то есть выделять память не одним большим каким-то куском непрерывно на 1 1 is not чередовать блоки небольшие блоки блоки небольшого размера на каждый из нот так чтобы память на каждый из нот использовалась равномерно некоторые машины поддерживаю такую штуку как чередование interlink на уровне bios это плохо это нужно это некий режим совместимости для тех операционных систем которые ничего не знают про numa но на уровне бьюз представляет ядру информацию очень притворяется машиной с одной ноты то есть не новой системой и как правило ничем хорошим это не заканчивается мы как-то раз потеряли несколько часов когда за ночь у нас каким-то образом сбросились настройки bios мы потеряли несколько слов на то чтобы понять почему у нас сегодня это совершенно не похоже на вчерашние результаты тестов до файлы и конечно самом деле тоже мешает дело в том что даже если мы используем интер leaving the может так оказаться что файловый кеш на одной из ног занимает большую часть памяти и в итоге мы все равно получим некий некое не равномерное заполнение not bother полом да ну в решении здесь простое можно просто сбросить файла кэш перед тем как запускать сервер в этом случае мы если мы используем interlink мы получим гарантии того что по-крайней мере файлом баттер пул распределён равномерно по каждый из нот и за счет того что мы используем interlink мы практически просто усредняем время доступа у нас не будет пить очень медленных запросов вас не будет очень быстро запросов на просто сглаживаем среднее время доступа и наконец еще одна проблема в линуксе такая штука как мемориал верка мид в перевозе на но простыми словами это означает что память выделяется только по по мере доступа по мере обращения к ней если мы делаем налог это не значит что мы выделяем сразу какой-то ядро выделяя сразу какой большой блок памяти и применении к но мы это означает что и поскольку память выделяется на локальный но дина по умолчанию то за заполняемость заполняемость каждый из нот определяется тем на какой ноги будет выполняться запрос как какие скажем так какие ноты будут читать страницы в баттер пол это может оказать привести опять же к неравномерному заполнению поэтому представьте мой скил где можно сделать нем все для того чтобы выделить память сразу а не ждать пока она выделиться потом под конкретные запросы обнаружить проблему довольно сложно потому что тормозит все равномерно и как правило можно дать большой разброс в результатах то есть одинаковый казалось бы запросы выполняются мог заполнить занимать очень маленькое время могут иметь очень большое время и какой-то система найти в какой в зависимости найти очень тяжело и swapping да то есть ядро может уходить слаб при казалось бы большом количество свободной памяти вот все эти все эти проблемы и методы их решения были описаны человеком по имени джереми кол на тот момент сотрудникам twitter честно работает в google и они реализовали некий патчи для twitter которым из пластин люди в пику на сервер но они просто нужны для автоматизации всех тех шагов которые я описал ранее да не нужно было какие-то там шаманские пляски делать каждый раз при запуске сервера можно вот указать некие опции в конфигурационном файле и все все эти операции будут выполняться автоматически скриптом моя скулди сейф или вот самим сервером еще одна проблема с производительность на высоких нагрузках связаны с баффер полом это проблемы с медленным выполнением драпали тонкий тайбл проявляется при включенной опцией тебе файл ты был то есть когда каждая индиви таблица хранится в отдельном привел спейси и баффер по у нас но большой допустит они не мегабайта не сотни мегабайт десятки может даже сотни гигабайт в чем суть при удалении ты был space а и no debe должна пройти по всему баффер полу и выбросит оттуда те страницы которые принадлежат этому уже несуществующем это был space у чтобы когда вдруг она чтобы не возникла ситуация что на тебе решит за флашей страницу которые при нажатии был space уже не существующему до проблема в том что эта операция она линейная нужно пройти по всем страницам который в баттер пуля что еще хуже эта операция выполняется под глобальным ютэк сам который защищает соответствующую структуру данных бар пуля список страниц ну когда bowl исчислялся там мегабайтами сотни мегабайт это в общем не было большой проблемой когда был пул стол 16 гигабайтами десятками и сотнями оказалось что от сканирования списка всех страниц буфер пули да еще падла больным ютэк сам это очень плохо и медленно нужно сказать что глобальный мьютекс если мы значит держим глобальными legs сканер их выполнение операций сканирования я значит что все запросы которые так или иначе что что-то делаются в нози би они блокируются но тот список багов соответствующих на бак с моей скалком первый баг он в общем об этом говорит что удаление даже пустых она тебе таблица с большим баффер полон может занимать очень большое время в пир клона сервера тоже с давних времен начинает 651 была опция не ведро pebble пошло то проблема был было исправлено в москве и в 51 из 55 и 56 это все еще линейное сканирование всех страниц бофор пули но глобальный баффер полный текст периодически отпускаю чтобы дать другим потоком шанс что-нибудь сделать мы тестировали эту реализацию отправления от oracle и в общем она работает вполне себе неплохо как-то проблем мы не обнаружили но впоследствии была обнаружена другая проблема что тоже с те же самые симптомы существуют для компрессировал их таблицы и патч для оригинального бага эту проблему не исправляют но позже тоже исправили но тару жил что танки ты был страдает от той же самой проблемы и здесь в силу некоторых причин какого-то легкого исправления сделать не получится разработчика oracle обещаю что это будет правилам искала 57 еще одна проблема связана с бабкой пулом это глобальный мьютекс значит in тебя баффер клуб оставляет себя комбинацию некоторых структур данных и почти все они защищены одним глобальным ютэк сам получается что если запрос модифицирует или читает хотя бы одну из этих структур данных он вынужден значит блокировать мьютекс и и блокирует таким образом блокирует доступ ко всем остальным структура для всех остальных запросов которые обращаются может быть совсем другим структурам данных да то есть вот например есть ваш лист у него отдельный выделенный мьютекс а есть другие списке есть там лору лист есть плейлист есть пэйдж все эти структуры данных баттер поле защищены одним глобальным ютэк сам решение проблемы который предложил оракулу чего моя спел 55 звучит так давайте просто buffer pool возьмем и сегментируем то есть вместо одного большого зеркала + нас будет несколько маленьких баттер paul af да и у них у каждого совместно будет свой набор new кексов и свой набор структур данных но проблемой здесь как бы это решение но не не идеальная до которых неравномерно использование алгоритм который определяет в какой buffer pool пойдет каждая страница он незатейливый это просто по по очереди round robin до первой странице которая читается в баттер пол это в 1 пол 2 во второй и так далее но в этом случае нужно как-то убедиться что баффер полу опять же все эти сегменты за плане используется равномерно и на тебе не делает для этого ничего то есть может так получиться что при каких-то операциях при удалении их таблицы или при фланге 1 бар пол оказался практически пустым дорога казалась полностью заполненным если на тебе решает прочитает новую страницу во второй buffer pool а там уже нет места она начнет делать флашинг причем в том что первый buffer pool практически пустой это типичная проблема сегментирования да как убедиться что каждый сегментов используются равномерно это решает проблему тоже вести лишь частично потому что нет никакой нет никакой гарантии что скажем два запроса будут толкаться вокруг это новый того же мьютекс а в одном и том же башир пол ну ничего нет не гарантирует она тибета и в некоторых случаях это может даже ухудшить производительность вот я привел ссылку на бак когда включения нескольких когда сегментирования формулы ухудшает производительность с бак до сих пор не справляемся решение вот проблемы с глобальным youtube сам которые мы предлагаем в преклонных сервер и уже довольно давно это вместо сегментирование использовать отдельные new три сына каждую структуру данных это не так просто реализовать как кажется потому что в некоторых случаях сутки на тебе хочет прочитать или модифицировать какие-то структуры данных а там арно ну скажем при удалении страницы одновременно ее нужно удалить из испечёшь если руль из например поэтому в некоторых случаях приходится но этот почин довольно сложно его не сложно поддерживать но плюс в том что он абсолютно ортогонален решение проблемы от oracle можно использовать несколько сегментов баттер пула и в каждом из них будет свой набор люверсов которая охраняет кажу структур данных отдельно все-таки сломался о да решение вот проблемы с главами баффер помню рексом было реализовано еще для 51 мы как-то сомневались стоит ли переносить его на 56 потому что как я уже говорил патч довольно большой его сложно очень поддерживать сложно мерзнуть изменений из оракла но когда мы начали подготавливать при клан сирого 56 мы увидели в том что на самом деле это проблема все еще актуально вот на этом графике можно посмотреть эффект синяя синяя линия это purple на сервер 56 с включенным баттер полу mutex сплит пачках мы его называем и для сравнения мой скил 756 без этой функциональности и до кучи этой компании для компании перк lancer 55 тоже без с выключенным borer пол не 300 лет еще эта проблема с которой сталкиваются пользователи и клиенты на высоких нагрузках связано с мульти version ностью вы на тебе чтобы объяснить чем суть нужно немножко поговорить про то как мыть и version если на тебе реализовано мульти version ность это средство для организации изоляции транзакций есть разные на тебе поддерживает четыре уровня изоляции транзакций самый популярный из них то 2 рипит колорит и рядками тот уровень золя цей ребята был вид говорит что как только вот так же у нас есть две транзакции параллельно выполняющихся как только одна из транзакций сделала select и увидел какое данных каком-то состоянии то независимо от того что другие транзакции делают параллельно 1 транзакции текущая транзакция будет видеть данные в том же состоянии уровень заняться рядками тут говорит что это состояние может изменяться текущая транзакция может видеть новые данные в том случае если они параллельны закончен и другими транзакциями и да это концепция теперь или зова на с помощью reviews каждый раз когда скажем для реки табло рид для уровня изоляции реке дарит транзакция делает select и на тебе создает review который по сути является неким атомарном снапчатом текущего состоянии данных по сути это список транзакций которые в настоящий момент активный но еще не закончены в этом случае текущая транзакция можно свериться с review который ассоциировался с которой ассоциирован для того чтобы понять стоит ли видеть какие-то изменения сделаны другими транзакциями если в момент создания риту транзакция не было замечено значит мы эти изменения не видим вот когда происходит в сервере в nozbe есть список всех активных транзакций и в силу 1 причин там могут быть как законченные так еще не законченная транзакция значит мы учим глобальный мьютекс делаем молок чтобы выделить память под ритм для текущей транзакции после этого мы сканируем весь список фильтруем те транзакции которые в данный момент не закончен и переписываем их вновь созданные reviewed и по сути массив состоящий из индикаторов транзакций и отпускаем ютекс ну да понятно что если у нас параллельных соединений там несколько тысяч т.е. длина списка вот транзакции который активно на текущий момент можем слова этом не сто тысяч если пример оборудование вас позволяет выполнять сотни тысячи транзакций в секунду то вот эту сканирование списка мы будем совместно выполнять сотни тысяч транзакций в секунду сотни 1 секунду при глобальной new такси это в общем не масштабируются и решение проблемы который предложил oracle в москву 56 это резонные транзакции если транзакции ничего не изменяется только читая данные то и нет смысла вообще учитывать ее в для при создании reviews ответ на ее можно просто не добавлять в этот глобальный список транзакций я даже хорошо но это решает проблему только через частично этой же проверю только в том случае если у нас нет из нас чистая редон не нагрузка если знал эти транзакции только читаю данные но нет транзакты которые что-нибудь пишут как только он появляется какое-то нереальное количество пишите в транзакции системе мы возвращаемся в исходное состояние улучшение которое сделано было еще в москве 57 то что редон и транзакции не нужно явным образом помечать как виду only они определяются автоматически да мы обнаружили проблемы с это реализациями сообщили в oracle что это решая проблемы лишь частично oracle нам не поверил поэтому нам пришлось сделать свою собственную реализацию показатель ничем арки после этого их убедили что проблема все та еще осталось как это работает как-то организация работает у нас у нас это оптимизации получила кодовое название телек дескрипторы значит вместо того что мы сканируем список активных транзакций а почему вы постоянно не поддерживать как бы актуальный массив незаконченных транзакций каждый момент в этом случае процедура создание риту превращается просто в блокировании копирование просто блока памяти знала места в другое кроме того если мы используем например заранее выделенный блок памяти мы можем избежать молок под глобальным сексом по столу как мы реализовали эту организацию и показали бенчмарки урок но согласился что да есть проблемы и наше решение тоже подходит по сути в маскел к 7 будет то же самое решение ну с некоторыми вариациями но фундаментальных то же самое вот тебе не марки которыми мы убедили оракал изменить свое мнение зеленая зеленая линия copper клан сера 55 потому что то есть эта оптимизация и делали еще лепрекон сервер 55 включенной оптимизации терек дескрипторы синяя линия например маски 56 без этой оптимизации как проблем обнаружить ну в шоу интернете статус вы увидите вот много таких строчек будет много транзакции будут ожидать на curl new такси это в 55 и 56 20 алексей смеют экс в персона в пурман профайлер много будет много таких серы будет тратить много времени на функции на близко метлу ну это в японский мы тоже можно увидеть контентом на kirkyard x-rite риксис мьютекс что можно сделать этом случае можно попробовать же мало опыта в порядке увеличение трудоемкости до самбо что варианта дорогу джима лог таким образом и хотя бы устранить и вот эта проблема с масштабируемости проблемы со стабильностью молока из уравнения да если это не по мне помогло то можно использовать данные транзакции но это в том случае если в 56 если вас есть возможность модифицировать код приложения если вас есть возможность по памяти транзакции явным образом как readonly или если даже это не помогло или нет возможности по памяти транзакции изменить кого-то вложения можно протянуть руку на сервера или марийки без экстра тебе там до проблем решена еще одно узкое место с в производить с высокими нагрузками и too dark age индекс значит суть в том что и на тебе может если скажем у нас есть обращение из нас есть поиск по какому-то значению ключа этот поезд повторяется часто и nozbe может построить хэш яндекс по этому значению ключа и указателю на запись в качестве значения до чтобы не выполнять каждый раз поиск по дереву можно просто включу сразу достать нужную запись иногда даже из-за эта оптимизация пишут что вы надели поддерживает кэш индексы это очень неправда но действительно не тебе может использовать кэш для поиска по индексу некоторых случаях а проблема в том что вот эта структура вот этот хэш он глобальный он для всех он содержит данные для всех таблиц и совместно возникает он защищается глобальным you take сам совместно запросы которые даже выполняется для разных совершенно не связанных между собой таблиц могут все застрять на одном и том же меню такси решение которое мы предложили только на сервере это просто ну сегментирование по аналогии с сегментирования акула давайте сделаем несколько адаптер из индексов и будем выбирать там каким-то случайным образом какой какие значения пойдут какой какой сегмент ну это решение идеальная до возникает точного проблема фрагментации ресурсов и работает только при доступе нескольким таблицам еще то проблемы которые очень часто встречается это индекс лог суть в том что в индии есть два механизм обновления индексов один этот мистический когда мы можем значение поменять непосредственно на странице без построения дерева индексного дерева и пессимистически когда нам нужно выполнить некое перестроение на случай когда нужно сделать перестроением и и на тебе блокирует индекс практической превращается в табличную блокировку потому что если другие запросы читают или обновляют даже совершенно несвязанные участке таблицы то они блокируются тоже на вот этом индекс локи вот определить можно так например пинки покажут много времени что что много времени потрачено в бтр курсе о что and level ну пока что вот текущими версиями ничего не особо нельзя сделать только использовать партий shining и эта проблема это исправить в большинстве случаев в мае скалка 7 но мы посмотрим насколько это будет исправлено еще эта проблема связанная на больших нагрузки которые часто честно больших нагрузках это проблема среду логом если но ряду лог это транзакционный локоны д.б. он имеет кольцевую структуру то есть in гриба перезаписывает проблема в том что это все по умолчанию попадает файловый кеш отец для и на тебе совершенно это не требуется чтобы этого исключить в финансировании сколько он тебе флаш method of a direct в этом случае и на тебе будет использовать в директ и для файлов данных и для ряду logo то есть нет ни файлы данных не получишь ни был попадать в в ряду лог связано с этим проблема проблемы с чтением при записи заключается в том что размер блока предлог в ряду логе ставить 512 bad person ядро person система работы с блоками 4 килобайта поэтому если мы записываем что-то в в ряду лог до блоком 512 байт он эта страница не находится еще в кэше ядро сначала нужно прочитать ту страницу с диска чтобы записать 512 байт решение которое есть только на сервере для этого можно увеличить размер лог блока до четырех килобайт маска 57 будет похожее решение но она взгляд не страны вместо того чтобы увеличить размер блока то можно будет указать специальный опыт опций конфигурации и соответственно с с каждым блоком в 512 байт тебе будет записывать виду локти из половине килобайта нулей чтобы выровнять общий размер записи на 4 килобайта я в общем заканчивается время мне придется здесь промотать закончен на несколько минорной такой ноте 1 поточная производительность я вот разговаривал с некоторыми людьми по по этому поводу дело в том что вот все оптимизации в на тебе и всей найти оптимизации которые о которых я здесь рассказывал одним основном относятся к производительности на большом количестве активных соединений да ну стой или больше почему-то никто не смотрит за производительностью на небольшом количестве соединения активных на правительство одно соединение хотя производились в одном сайте не соединений определяет время отклика для некоторых людей это даже важнее репликации например работает в один поток многие административные задачи такие как импорт данных или изменение схемы тоже работает в один поток и в конце концов большинство в большинстве случаев сервера работой с небольшим количеством соединений практически никаких усилий по оптимизации не делается есть такой человек известную масел комьюнити марк аллаха можем уже много лет пишет об этой проблеме и публикует результаты тестов вот можно прочитать подробности в его блоге и вот эта картинка показывает вот чувствует там боги в куче бенчмарка в куче графиков куча слов написано но все это вот можно по суммировать такой картинки тут видно что каждый мажорный релиз мой скил процентов на 5 на 7 медленнее чем предыдущий что общем-то не так уж и много но все равно обидно сознавать что кроме тон новой москве 56 процесс может быть процентов на 20-30 медленне чем какой-нибудь древний майского 3 323 на 1 поточных нагрузках сложны и все если у вас есть вопросы я так здрасте спасибо большое за доклад меня зовут станислав подскажите пожалуйста вы сказали что допустим при запуске москве ряда при выделении и no debe буфера буфер пула мы делаем малак соответствие операционная система не выделяет нам стоит сделать мам смм set мы можем сделать только из процесса из самого процесса что-нибудь предусмотрено уже в перка не для какая-нибудь опция чтобы делать от мам сад или от нужно вручную дописывать при выделении нет есть как раз опция которая управляет именно этим поведением называется и нози би баффер полк папиллит если установить у единицу то сервер при старте сделает немцы от названной да не совсем все там некий системный вызов которые 8 является оптимизированная версия мем сердце и ясно хорошо спасибо танец на слайде телефон скачать посмотрим там насладиться есть здравствуйте правильные и я понимаю что в москве в прикольно сервер все что вы рассказываете будет правильно работать из коробки с дефолтом ими настройками нет у нас такой принцип что все при клан серы с духовными настройками ничем не отличается от москве но чтобы но это сделать сооружение совместимости все дополнительные функции ключается специально до явно то есть получается нужна куча информации дополнить на при рыть чтобы сделать вещи которые ну 80 процентов случаев надо делать если где-то вот эта информация сведена и в одном месте чтобы не копать весь интернет и не ходить там на кучу конференции и все да я думаю что если вы зайдете в раздел документации по purple на сервер волосы специальный раздел комментарии оптимизации производительности там будет вся информация довольно сжатом виде можно посмотреть опции включить те которые для вас кажутся важными здравствуйте и спасибо за доклад меня зовут андрей подскажите пожалуйста такой момент вот описанная вами стратегия с выделением нескольких баффер полов для того чтобы сбежать единственному глобального beautix а она как живет вместе с интерны вин гамма между нотами то есть она дополняет или случае если выделяется несколько баффер полов то каждый из этих баффер паула все равно должен интер levice между нодами каждый баффер полов будет автоматически интерфейсы между волнами но при условии что соответствие обсе опция включена в конфиге"
}