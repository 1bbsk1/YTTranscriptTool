{
  "video_id": "liQVI5JK11Y",
  "channel": "HighLoadChannel",
  "title": "SmartMonitoring - мониторинг бизнес-логики в Одноклассниках / Сергей Шарапов (Одноклассники)",
  "views": 740,
  "duration": 1993,
  "published": "2017-04-22T14:48:25-07:00",
  "text": "здравствуйте еще раз меня зовут сергей я работаю уже 6 лет одноклассниках начинал я с установки серверов потом их там делал первичную настройку поработал в команде мониторинга короче прошел все круги райан и теперь я работаю системным аналитиком mail.ru и в одноклассниках разрабатываем внутренние системы в основном про одну из систем как раз сейчас и пойдёт речь это мониторинг бизнес логики в одноклассниках я надеюсь что многие отцу здесь кто мониторит свою бизнес-логику своих проектах вообще кто-то мониторит поднимите руку ну отлично больше половина это радует даже очень мы ее не просто мониторим мы ее анализируем это следующий уровень то есть мы автоматически анализируем нашу бизнес-логику ну и перед тем что начать выступление я расскажу что вообще такое одноклассники масштаба чтобы вы понимали сейчас одноклассники это 4 дата центра территориально территориально находящиеся в разных расположениях 11 тысяч серверов более тысячи сетевых устройств 180 сервисов по сервисам и мы понимаем фото видео музыка лентам и так далее ежедневно у нас десятки миллионов уникальных пользователей и за этим затем нужно хозяйством следить поэтому у нас есть вот такие вот команды это инженера которые устанавливают оборудование меняю диски решают инциденты некоторые команды мониторинга которые как раз ищет эти инциденты и подкидывают работу другим командам про нее я чуть-чуть по почве побольше расскажу сетевые администраторы с ними все понятно работают сетью настраивают оборудование системные администраторы они администрирует порталы настраивают его и программисты которые пишут код то есть это полный цикл то есть сервера наши все сами делаем сами устанавливаем но так как у нас очень много серверов на свою структуру очень большая это неизбежно каждый день что то у нас ломается и именно и самая главная наша задача узнать что у нас сломалось быстрее мы узнали об этом пользователя поэтому у нас есть целая команда которая занимается мониторингом она отвечает за работу портала всего просматривают графики ищут какие-то аномалии в них создают заводят инциденты распределяют авто инцидента авто инциденту на созданные на связке zabbix и жира zabbix детектив аномалия жира создает авто инциденты остановимся на втором и третьем пункте просматривают графики ищут аномалии что такое вообще какие у нас графики что такое аномалии что такое инцидент здесь показана время загрузки лентой нашей красным цветом показан текущий день другими цветами другие дни чтобы видеть тренд того как это происходит и вот мы видим скачок произошел загрузки для нас это инцидент потому что большие все инциденты начинаются именно вот с таких вот скачков сначала 1 потом два и потом все ломается поэтому команду мониторинга должна во-первых сначала обнаружить этот скачок а потом просмотреть всем создать инцидент просмотреть все наши сервисы все наши базы то есть найти причину пока мы не знаем что сломалось мы не знаем что нам нужно чинить то есть нужно просмотреть там десятки бывает даже сотни графиков чтобы найти причину этого скачка ну вот как выглядит типичный день команда мониторинга это графики графики графики давайте я вам расскажу как у нас был мониторинг устроен до того как мы запустили вот эту нашу систему по которой сейчас рассказываю раньше когда портал был еще небольшой мы сделали даже гордой с графиками их было немного там 20 где-то штук 30 и потихонечку портал рос и развивался добавлялись новые сервисы графиков становилось все больше больше больше больше то есть новый сервис это новые графики допустим есть какой-то запуск нового сервиса программист который выпускает заинтересован в том чтобы этот сервер сервис мониторил си со всех сторон и поэтому он даёт команде мониторингов там много графиков теперь вы ребята смотрите за ними но мы не можем не могли на тот момент смотреть вот большущее количество то есть на каждый сервис если по 20 графиков это будет просто нереально поэтому про или как-то выделить самые основные то есть мониторили не все но иногда бывало ситуацией кардинально противоположно и то есть кто-то запускает новый сервис и забывает добавить мониторинг графике это наверное даже ситуация еще хуже то есть мы пропускали инцидента и мы видели что мы не что-то не только после того как этот инцидент сам произошел ну как вы думаете сколько командование туринга просматривала графиков в час то есть каждый человек в час сколько графиков просматривал чтобы мониторить как вы думаете в 200 маловато конечно ну в итоге получилось 650 картинок в час то есть за смену 8-часовую дежурный просматривал 7000 график среднее значение иногда было больше с этим надо было что-то делать тут имели много проблем нужно мониторить большое количество графиков инциденты это действительно сложно и долго и времени уходит не только монитор щиков но и подключаются программисты админы дорого расследовать инциденты было мониторинг глазами это всегда пропуск событий то есть сначала когда 650 картина 1 час смотришь вроде бы как бы реагируешь на все когда 2 3 4 час идет уже что-то пропускается сейчас какую-то аномалию тебе не нужно расследовать получался и человеческий фактор ну и новый это новые графики который мы иногда забывали добавить до 2016 то есть 2015 поэтому мы решили сделать систему которая будет который бы решал а вот эти вот наши проблемы мы стали логировать запросы между серверами между конкретными двумя серверами что мало героем это направление связи какой сервер ходят какому количество запросов количество ошибок этих запросов среднее время этих запросов и сервис как выглядит приблизительная картинка того как взаимодействуют два сервера это вот график взаимодействия веб-сервера с сервером бизнес-логики как-то так имею вот эту всю статистику то есть мы знаем как общаются наши сервера мы могли бы построить граф того как работает наш портал и он бы мог выглядеть приблизительно вот так но есть проблема у нас 11 тысяч серверов этот граф был бы очень большой он был бы его сложно было вообще построить даже но каждый сервер зашли играет какую-то роль в инфраструктуре то есть у него есть свой микро сервис их 280 штук большие микро сервисы типа в баф мы разделили по дата-центром точно нас есть один сервис выбор мы его разделили на то количество сколько у нас дата-центров и в итоге получили две с половиной тысячи связи между этими микро сервисами и нам удалось построить граф того как работает одноклассники это как то вот так ничто не напоминают давайте разберемся что здесь нарисовано он по кругу расположена микро сервисы линия это как раз как их взаимодействие их связи я выделил 1 microserver справа наверху и зеленым линиям линиями показаны связи куда ходит этот микро сервис а коричневыми кто к нему ходит ну вот так сложно действительно работает портал вот с этим графом из что-то пытались сделать по-разному построить сложно было что-то как-то его использует и решили посмотреть на этот граф во время проблемы то есть у нас было реальные проблемы и мы решили в этот момент построить этот граф и оставить только те связи в которых есть аномалия микро сервиса между собой общаются и получили вот такой вот другую графу поменьше синими линиями здесь показана время между двумя микро сервисами желтые запросы количество и фиолетовые ошибки давайте разберемся что как это все выглядит время от мобильных веб-серверов до серверов бизнес-логики увеличивать это на пользу полмиллисекунды далее от серого в бизнес логики дал мастер джим просит прокси время увеличилась на 10 миллисекунд и самое главное запросы в базу время увеличилось на 40 миллисекунд и так как здесь есть еще слизь запросов значит упали запросы и у появились ошибки какая же это была проблема пользователь когда хотел написать сообщение кому-либо открывал переписку и долго погружалась история переписки то есть вот упали провалились запросы из-за того что кто то видимо передумал писать и закрывал нам вообще вот эта вся идея очень сильно понравилось то есть получается как-то рабочий механизм действительно вот в конце мы видим проблему проблема именно в базе которая хранит историю пески и поэтому мы решили развивать систему связи между микро сервисами не описывают весь функционал то есть всю работу портала потому что есть контент который отдается с неба мы решили добавить графиков то есть все что мы отдаем отдача контента это видео фото музыка деньги считаем конечно же каждого нашего агрегатора мы мониторим сами мы сообщаем агрегатор о проблеме они они нам пишут что у нас есть проблемы мониторим влаги на по сторонам как на мобильные так и на веб версии мы добавили разные технические графики и в итоге сейчас мы мониторим в режиме реального времени 100000 графиков это много как же мы это все делали архитектура системы все логе пишутся в нашу data warehouse это реализована система хранилища логов за сутки туда пишется 3 триллиона записей 3 и 12 нулей это действительно много это 600 гигабайт каждый день service data collector забирает необходимые для системы данные потому что мы не все же графики мониторим какие-то нужны ну для каких-то других целей созданы и кладёт их в наш сторож аномалия детектор забирает данные и анализируют их еще аномалию с числовых последовательностях если он видит аномалию он ее помечает и кладет ее обратно сторож applications сервер ходит к дополнительным сервисам типа жир и подготавливает всю эту информацию и передает веб-клиент у самый интересный модуль здесь наверное аномалия detector про него сейчас нужно очень много все в интернете их очень много уже но мы решили писать сами написали свой и когда мы писали свой так получилось как раз twitter выложил свой алгоритм в открытый доступ мы его попробовали но к сожалению он чуть-чуть был написан для других целей twitter как я по нему понял он мониторит активность своих твитов то есть он ищет популярные твиты и у них не так много графиков механизм был написан на r со 100 тысячами графиками он конечно же не смог бы справиться чтобы постоянно их обрабатывать поэтому мы написали его сами вот как работает этот аномалий директор давайте прокажу покажем у пройдемся входные данные то есть чем что мы должны давайте системе как обучающие данные в учении идут те данные которые значения которые были в этот же промежуток времени 7 14 дней назад итак берем 6 дней то есть если сегодня понедельник в буче в обучающую выборку у нас идут все понедельники которые были в это же время плюс два соседних значения как слева так и справа это мы делаем чтобы выборка было нормально распределена если какие-то значения в тот момент система отметил отметила как аномальные то они не идут выборку то есть они убираются замечающих данных далее мы применяем тест grabs а математика в принципе одна если рассказать что там делается то есть ты сыграться ищет выбросы в числовых последовательностях и говорит это аномалия или нет аномалия то есть вот есть пример аномалий это график времени загрузки какого-то компонента в 6:30 произошла аномалия как тест grabs и и анализирует слева значение которые были раньше в это же промежуток времени плюс-минус два значения слева справа и снизу текущее значение id с градуса говорит что да это аномалия есть выброс далее мы делаем фильтрацию фильтрация это как бы как сказать борьба с ложными срабатывания me потому что ты граф со все находят но не всегда для нас эта аномалия то есть по цифрам да действительно это выброс но мы его за выброс не считаем и нам ничего не надо с этим делать вот какие бывают аномалия ложные сейчас я про каждую расскажу в отдельности незначительные отклонения от тренда вот мы видим здесь вот вот допустим чуть чуть выше красные линии идет здесь действительно есть выброс но для нас он не критичен это совсем немного тут как бы ситуация двоякая нам главное обнаружить аномалию но не обнаружить не аномалию то есть чтобы не было ложных срабатываний и опытным путем мы пришли к такому мнению что от процентов по времени для нас не критично и 15 процентов по запросам и но не на всех связях а только на таких основных далее зашумленных графике то есть вот на каждый выброс это оно я тогда было бы очень много ложных срабатываний в таких графиках мы смотрим чтобы было 15 минут превышение то есть чтобы 15 минут алгоритм говорил что до в этом графике anomaly это некритично что мы узнаем о проблеме чуть позже но мы узнаем по крайне мере что это точно проблема апдейты во время апдейтов выводятся какая-то группа серверов и останавливать 107 запросы от нее и к ней падают в ноль система показывает вот таких вот пауков для нас это считается ложные срабатывания но для пользователей действительности эффекта нет никакого как это выглядит все по настоящим вот 8 групп серверов выводится по 2 2 вывелось и вся нагрузка перешла на другие группы по настоящему то есть вот график суммарный то есть эффекта нет поэтому мы сделали рубильник во время апдейтов мы включаем и смотрим тем микро сервисы которые мы разделили по дата-центром в сумме чтобы не было таких у срабатываний работы с сетью работы сетью во время работы с сетью происходит частенько клиника с шторм который засоряет сеть и поэтому время взаимодействие двух микро сервисов почти всегда подскакивает кратковременно и смотреть пользователю вот на такой вот картинку как бы не очень наверное эффективно здесь мало что можно понять поэтому мы мониторим дата-центры на то что было ли там unicast шторм то есть было ли много пакетов сразу атосу ну если это было тогда мы показываем пользователю в каком дата-центре был самый не кастор и вот такого вот не показываем сезонное отклонение активности эта картинка за 30 апреля то есть перед большими праздниками народ уже поехал отдыхать и акте это онлайн и или народ поехал отдыхать и красная линия чуть-чуть пошла ниже и так пошли все вся активность то есть по всем по всем сервисам и поэтому вот такой вот мы видим здесь сюда тоже как бы смотреть бесполезным мы понимаем что сейчас идет отклонение активности нужно как-то перестраивать алгоритм поэтому мы в тоже включаем другой рубильник который знает приблизительно и отклонение пользовательской активности относительно посмотря на онлайн и и другие метрики тоже с учетом отклонений переосмысливает и таких срабатываний показывает это как бы все ложные срабатывания с которыми мы боремся как же работают системой то есть пользователю приходит какой-то граф либо просто связь и он может сделать четыре вещи с ней то есть он отметить ее как известно и аномалии просто чтобы она ушла на какое-то время допустим он что почему она произошла какой-то программе сказал я сейчас включу этот функционал здесь время возрастет я учусь до часа выключу и он спокойной душой описывает это все нужных полях и это больше не alr мид то время на которую убрал либо создать инцидент инцидент создается в самой системе и автоматически появляется в жире с этим все понятно новый тренд допустим программист дополняет свой сервис чем-то и у ожидает там увели увеличение времени которая ожидаемо с этого момента времени нужно по-другому анализировать график и пользователь ставят что вот с этого момента пошло новый тренд либо ничего не делать если допустим в какой-то ложное срабатывание проскочила такое тоже бывает фичи системы которые помогают нашим монитор щекам работать с ней если уже были проблемы с таким графом то система подскажет что это было вызвано в прошлый раз этим связь жир и я уже говорил что инцидент и создаются из системой из системы и появляются в жире также все авто инциденты система сообщает что создался новый авто инцидент также система взаимодействует жир и она смотрит статус инцидентов потому что бывают такие моменты что пользователь создал инцидент и и вот как бы забывает немного обновлять проблема ухудшилось тогда система скажет что вот в этом инциденте проблема усугубилась так же работает из известной молитвой спрятал ее на два-три часа но там проблема усугубилась также система подскажет тому чтобы он посмотрел вот эти вот графики потому что там что то происходит хуже все стало связь системы конфигурации у нас есть систему конфигурации в котором программисты вносят изменения на портал то есть пользователь видит какой-то граф не может посмотреть что в этот момент был какие изменения были то есть кто изменял и что изменял то есть он знает кому сразу жить и какому именно программисту идти как у которой будет решать эту проблему ну он может быть выделить этот граф и создать уникальную ссылку и дать ему уже уникальную ссылку на графа если какому-нибудь админу или программисту интересно что с его микро сервисом было может его вбить и посмотреть какие аномалии были с его микро сервисом допустим ночью или за всю неделю обнаружение усугубив шихся проблем про который я рассказывал и совместная работа могут системы могут работать несколько пользователей находясь даже не рядом если один пользователь отмечает как известная на маленькую то связь то другой сразу же видит почему и что именно и кто отметил я отношу интерфейс кафе чем вот так выглядит этот интерфейс он разбит на три части слева таблице справа сам граф сверху шапка таблицы и граф это не дублируют себя по содержанию только визуально на граф как бы поприятнее смотрите сразу видно в чем проблема над графом есть активность по рунету и по нашему порталу это нужно чтобы отслеживать так это же отклонение активности мы видим что происходит вообще сейчас в интернете слева наверху авто инцидента инциденты на себе когда мы ввели систему наших коллег появилось время им добавили мониторинг сети не только одноклассников ну и mail.ru жиры разные поэтому появились еще и значки mail.ru жира и одноклассники справа как раз усугубление проблем если в известной аномалию что-то усугубилась появляется значок тут пользователь заходит и видят какие именно метрики и графики усугубились что же мы в итоге получили запустив такую систему теперь мы мониторим 100000 графиков и не пропускаем инцидентов не тратим время на расследование что очень для нас важно все новые сервисы автоматически попадают потому что если кто-то заводит новый сер сервер в продакшн это логирование у нас по умолчанию должно быть включено логирование между серверами ну и выросла команда производительность команда мониторинга но это на время пока нам не добавили сеть из теперь как бы она уровнялась сеть mail.ru яме и ведут любой админ или программист может зайти в систему и посмотреть еще что сейчас происходит если какие-то крупные проблемы либо вообще если какие-то проблемы но это помогу жить и админом и программистам ну если вернуться в начало слайд теперь вот командам можно добавить как раз эту систему она и всем он помогает жить если кому то понравился доклад если кто-то будет это что-то делать что-то подобное снизу ссылка мы собрали туда весь материал который будет полезен для создания подобного рода систем также недавно я писал статью на наш блог о чуть-чуть другой нет парень для мониторинге операционных показателей именно серверов тоже советую почитать спасибо за внимание готов готов ответить на вопросы да пожалуйста вопрос таков при крупных масштабных событиях в мире делаем ли мы что-то с нашим мониторингом нет мы ничего не делаем у нас есть запас достаточный да мы видим допустим все падение даже вот для нас масштабнее то падения нашего партнера вконтакте мы видим их падения у себя и мы спокойно все падения переживаем то есть нет мы ничего не делаем мы видим да иногда там допустим самое что интересное олимпиада когда начиналась дал наш у нас активность от рекламы рекламы проседала чуть-чуть еще вопросы общее состояние интернета это состояние по данным liveinternet то есть количество пользователей за сегодня и их активность и также у нас у меня вопрос я здесь сколько заняло в человека днях разработка подобной системы и как долго вы тестировали просто решение похоже на классы пьем бесплатные дай no trace и экшн что-то похожее я сам пробовал внедрял но за деньги просто сколько стоит такая open source на я вещь в людях им спасибо за вопрос получилось так систему создавали втроем я едва программиста спасибо им большое миша романов и сергей алексеев мы работали это был не единственный наш проект в компании то есть мы тратили где-то 20 процентов времени на него на реализацию ну я может быть чуть побольше тратил времени то есть мы делали это все в параллели с другими задачами и мы за четыре месяца наверное сделали ее сергей здравствуйте я хотел спросить вы мониторите только увеличение времени отклика между сервисами 200 когда просто часто возникает ситуация когда сервис может ответить двухсотым кодом но внутри как раз есть ошибка в бизнес логики которая не видна именно с технической точки зрения вот в эту сторону вы как-то смотрите ну и плюс 500 и вы наверно тоже смотрите правильно анализируйте ну вдаль то есть если что-либо происходит это влияет на активность я просто вы начали рассказывать что вы смотрите увеличение времени отклика системы это единственный критерий которая анализируете или же в том человечество запросов и ошибки да точно ошибки то есть если будут какие-то ошибки то мы это увидим тоже на графиках это фиолет фиолетовая линия есть отдельные тренде 500 есть отделяем тренды времени отклика да а вот третий вопрос который если все-таки приложение 200 дает но внутри очевидно что то сломалось примеру какой нибудь партнера ли еще что то то есть вы по цепочке анализируйте до того сервисы который упал до да как раз для этого и нужна была система чтобы найти источник проблемы которые потом за собой потянул всем спасибо на разные метрики выставили параметра допустим отклонения чтобы минимизируется на страны ложные срабатывания другой стороны пропустить инцидент и приводили примеры где-то там 15 минут облигацию стали где то еще что то вопрос такой а если вы понимаете крузак метрики по опыту окей а вот а вот какая то еще есть знание что вот это общение или еще что-то допустимый диапазон это такой вопрос не очень правильно я считаю разгуливать и правильно потому что разные сервисы разное время то есть там может отличаться значительно то есть сколько миллисекунд для разных сервисов для какого-то это нормально для какого-то это ненормально допустим от серверов фронтов фронтов до серверов бизнес-логики время как бы не должна меняться это такой основной показатель то есть как быстро веб-сервер получил всю необходимую информацию что передать ее пользователю показать поэтому здесь очень критично любое отклонение на других график когда пусть им незначительное отклонение они не критичны чем чем дальше он от находится тем менее не критично небольшие отклонения не существует you some спасибо это мы в процессе то есть мы видим что что-то у нас a liar мид чаще чем должно или совсем неправильно то мы добавляем фильтр и да вы рассказали про упомянули что у вас есть какая-то сторож не могли бы вы рассказать поподробнее что заставишь но насколько там не знаю если не секрет много машин храните ли вы какие-то теги к метрикам там метров 20 вот это все и как спасибо за вопрос у нас весь мониторинг на двух серверах ничего такого интересного в этом стороже нету это друид берем из друида и кладем в друид там как бы ничего такого сверхестественного просто даже не знаю что рассказать обычный сторож данных там немного но это ничего не весит почти вопрос родился вы говорили что пользователь в основном выставлены выставляет фильтрации да то есть как минимум они работают на фильтрацию кто работает на именно создание инцидентов то есть как я понимаю то есть grub сада определяет если люди и какие-то эвристики которые можно внести в систему и дополнительно она молить детектировать аномалий который примеру тестом рапс они заселяются то есть работают ли пользователи на поиск этих аномалий а не только на фильтрацию вот такой нет пользователь не работают на поиск аномалии потому что тест тест игра пса достаточно наоборот он даже немного нам дает излишки поэтому мы фильтруем даже то что нам не нужно этого достаточно то есть мы более не ничего не просматриваем бывает иногда конечно деньги ну платежные графики иногда надо посмотреть потому что ну как бы нету то задание смотреть постоянно то есть иногда люди сами просматривают чтобы точно ничего не пропустите реальных живых денег мы не сталкиваемся такой ситуации когда аномалий есть и она не задохнулась это было бы провалом до скорее дополнение к предыдущему они происходят ли у вас такое что вы просто перестали смотреть глазами на графике и поэтому вы видите только те аномалий которые ловят тест grabs а все остальные вы просто не видите спасибо за вопросы как раз вот по-моему вы задавали задавали как мы долго внедряли и это вот вместе вопрос понятное дело что мы махнули мечом и сказали все ребят больше графики не смотрим теперь вот смотрим сюда это было бы как бы не очень логично мы внедряли система какое-то время и смотрели и на графике на те которые у нас были то есть мы ничего не меняли плюс эта система да да как быстро мы находим аномалии мы находим аномалий быстро пять минут тут не нужно гнаться за минутами потому что это не тот мониторинг который вот раз и все значит беда произошла тут мы заранее узнаем что где-то что-то может отвалиться или что-то сломаться и потащить за собой все потому что обычно сам большие инциденты начинаются с какого-то сервиса вам потихонечку барахлит прах ли ты потом он берет за собой другие сервисы и все ломается а вот про стоишь уже сказали druid-а про первую фазу сбора медик тоже интересно в каком виде вот это конечно я не компетентен а это рассказывать вот у нас есть программистом все расскажет вам спасибо большое за внимание хотелось бы получить от вас фидбэк в приложении оцените плохой фидбэк для меня тоже фидбэк спасибо"
}