{
  "video_id": "EHOpoCckIig",
  "channel": "HighLoadChannel",
  "title": "GeeseFS ФС из S3, или Параллелизм гусей в природе / Виталий Филиппов (Yandex Cloud )",
  "views": 208,
  "duration": 2738,
  "published": "2023-10-06T07:16:38-07:00",
  "text": "так Всем привет Меня зовут Виталий Филиппов я сегодня буду рассказывать про троллейбусы с буханки Ну про файловую систему из-за S3 в общем Итак О чем я расскажу я расскажу про gisfs giffs это наша попытка сделать файловую систему поверх S3 которая в отличие от всех остальных попыток В общем допускает использование без слез потому что она гораздо быстрее их Ну естественно не может преодолеть там все ограничения S3 но тем не менее Вот кроме того Кроме того что просто я про неё расскажу я также попытаюсь сделать такой лирическое отступление во-первых Зачем это все надо Зачем делать такое там Зачем скрещивать уже и как вообще делать файловые системы в том числе То есть как делать файловую систему из ис-3 как просто вообще то есть чем вообще отличается файловый Эхо это нормально эхо Ну ладно в общем Окей Я хочу жестко В общем Ну и буду тогда также расскажу просто про аспекты реализации файловой системы То есть например люди там часто говорят про посик совместимость А что это такое Обычно никто не уточняет ну то есть какие-то отдельные аспекты там как правило все могут назвать Вот Но хотя бы там базовое какое-то общее понимание обычно редко об этом говорят Ну в общем покажу что получилось Там Какая скорость у этого И что еще планируется вот собственно первый вопрос зачем то есть мотивация Ну как известно из буханки можно сделать троллейбус Да но вот типа зачем мотивация В общем такая то есть S3 оно есть во-первых у всех Ну во всех облаках есть есть свои реализации там пинсорные ну там у кого-то Да свои есть просто пинсорсные то есть там тот же C все виды FS и так далее вот S3 как правило дешевле файловых систем там где есть файловая система как сервис и S3 сходу распределённое по датам файловая система они зачастую в рамках центра живут просто исходя из требования лучшей задержки вот при этом файловая система всё равно нужны То есть сейчас по факту прошло там уже больше 15 лет с момента того как амазон впервые этот свой стрит запустил но файловую систему нужны до сих пор есть применение которое до сих пор используют Там те же вычисления например то что я условно называю HP C типа Hyper formance компьютер Вот кроме того в моем личном понимании Ну и не только в моем понимании то есть рыночный опыт говорит о том что это не только мое понимание это некий такой логичный Вектор развития То есть как конвергентная эволюция когда вот два животных Они в разных местах живут одну нишу занимают они становятся очень похожи Вот то есть если мы берем файловую систему просто из неё начинаем делать сетевую файловую систему И если мы начнём если мы возьмём S3 и тоже начнём из него делать файловую систему то на самом деле есть такое ощущение что может получиться какая-то одна и та же примерно зверюшка Вот и отличия естественно есть но вот можно ли их преодолеть вот об этом пойдёт разговор значит Ну вообще Начнем с того что такое файл файл это не напильник Хотя это напильник Да в английском но у нас это именованная последовательность байт вот файловая система она хранит файлы как бы что очевидно и в принципе наверное в научном определении ничего и больше не найдете просто файловая система то что хранит файлы Да логично Что делает аббревиатура от Simple storeg Service Вот она изначально была у амазона сейчас она уже у всех это объектное хранилище объектное хранилище хранит объекты А что такое объект Объект это вообще-то файл То есть это тоже некое именованная последовательность а ну вы сразу ответите В чем разница первое там нету иерархии типа файловые системы иерархические стрин не иерархическая но на самом деле это не совсем так потому что в API листинга объектов есть листинг условно директории с помощью префикса плюс разделителя Вот раньше допустим у амазона и вроде изначально Даже у нас тоже изначально была консистентность слабая то есть имелось ввиду что вы обновляете объект и вы не видите сразу это изменение вы его видите только через некоторое время через какое-то Вот но на самом деле это было настолько Грустно что люди изобретали свои там какие-то обёртки там S3 называлась В общем Ну вот люди изобретали обёртки которые превращали типа слабые три сильные Стрим В итоге в амазоне уже сделали сильную консистентности у нас уже тоже сильная конструкция вот Казалось бы нет никакой мутабельности объектов но это тоже не совсем так есть мультипарт копии то есть копирование на стороне сервера можно взять там кусочек файла и скопировать в другой файл или даже в тот же или даже в то же самое место Ну и по сути в таком смысле это просто изменение там по месту какой-то частичное вот нету метаданных там нету атрибутов но это тоже не совсем так там есть юзерный то дата 3 Ну её там в листингах вот нету это там да В стандартно смотри есть такая небольшая проблема но тем не менее метаданные есть вот ну что реально реальное отличие это нет переименования другой реальное отличие - это там чуть больше как правило задержка потому что S3 - это как правило такое холодное хранилище Ну или там такое тёплое хоронилище на жёстких дисках как правило Никто там не делает из него какого-то супер быстрого Вот Но при этом при всем при том быстрее всегда отличная масштабируемость то есть смысле просто пропускной способности и как бы для больших файлов Это должно быть Окей Ну или просто если вам там в основном нужно читать писать целиком вот ну собственно Да вот конвергентная эволюция это Вот пример это вот ежик ехидный ежиные типизация Типа если будем делать сетевую файловую систему у нас будет ежиные типизация вот примеры собственно этой самой типизации от конкурентов видимо все как-то примерно в эту сторону думают потому что например у амазона есть storage Gateway причем их целых четыре штуки они довольно безумно сделаны это там какая-то штука на базе Java + NFS Ганеша я там скачал поковырял вот у эйджера есть иерархические бакеты то есть можно у них не S3 у них там свой интерфейс но он по сути как S3 вот ну в нём можно переключить баки твои иерархический режим и в нём появляется типа переименование там и до запись Вот и у них есть NFS Gate то есть тоже можно по инфу монтировать вот у Huawei и у берклауда который этот Huawei продаёт у них тоже есть иерархические бакеты и до записи Гугла вообще своё растопишь в котором можно там объекты с кусочков собирать и у них там есть своя тоже Fuse обёртка чтобы это монтировать вот ну собственно была у нас такая мысль сделать Сначала тоже storage 2 но потом посетила такая мысль что юзерам не нужен гейтвей им нужно само хранилище им нужен сам сторож поэтому Fuse как бы тоже норм вот примеры Юз кейсов которые вот могут прийти в голову именно когда Стрим можно использовать как файловая система Ну мне лично вот такие приходят в голову то есть во-первых это какое-то программное обеспечение где нет поддержки S3 Ну там например репозитории потом возможно какие-то быкапы возможно хранить какие-то там промежуточные результаты сборки ну или там не промежуточные результаты сборки конечные то есть где довольно много данных и нужно такое Прохладное хранение вот ну просто файла помойка То есть когда какой-то общий доступ к какому-то там хранилищу с файлами в которые тоже там пользователи в основном просто забирают целиком и там кладут обратно целиком вот ну и последнее такое самое условно Наука ёмкое это HTC но нюанс в том что там как раз обычно нужна частичная перезапись А тут все-таки есть ограничение на сервере Но об этом тоже дальше пойдет речь как это обойти В общем далее теперь собственно файловой системе Что такое файловая система Но говорят вот по Six файловая система абстрактная в вакууме как бы ну вот что это такое Что за пофиг совместимости Ну я основные черты условно выписал которые можно выделить и они делятся на такие четыре блока У меня первый блок это базовые черты во-первых файловая система иерархическая то есть директории есть файлы во-вторых там есть частично перезапись файла всегда То есть можно кусочек файла в серединке поменять есть строгая консистентность имеется то же самое что после того как вы записали Вы же сами точно прочитаете то что вы записали и атомарное переименование в том числе каталогов То есть это в части Ну это как бы к иерархии дополнения вот второй блок это условно про атомарность во-первых то есть когда вы одновременно читаете каталог его меняете То есть он создает или удаляете файлы у вас ничего не должно поломаться в листинге То есть он может отдаться как старый так и новый но файл не должен попасть в лифтинг два раза и не должен там попасть 0 раз который уже был файл Ну на момент начала редира Вот и также есть какие-то кукорейки про томарную запись в стандарте но с ней на самом деле ситуация как бы такая что Ну вот типа видите атамарную запись файловой системе Ну вот вы видите её на самом деле нет И на самом деле во всех файловых системах запись как правило не атомарная просто в угоду производительности То есть пока вы не сделали в Синг данные физически на диск скорее всего могут не попасть вообще вот ну поэтому атомарную запись мы зачеркиваем и на самом деле вспоминаем профсинг Ну либо можно вместо finco открывать файл Там типа с флагом усинк или одессинг примерно работает то же самое но просто вам вообще производительность становится то есть на каждый в рай будет вот ну и есть там транкейт То есть файл можно взять и поменять его размер можно поменять причем размер в меньшую сторону можно принять размер в большую сторону То есть можно сказать там транкейт на 10 гигабайт файл станет 10 гигабайт вот а я вот не знаю дальше будет ладно дальше следующий блок это про атрибуты и про всякие специальные там файлы здесь Ну что значит символические ссылки права пофиг сосели всякие специальные файлы то есть файлы устройств там соки ты нами Три разных Times тампа которые по-разному обновляются и два из которых может сам пользователь установить Что например делает Вот и расширенный атрибуты или стендах а вот и последний блок это такие совсем хардкорные фичи то есть жесткие ссылки То есть то что вы можете сделать что там два файла физически ссылаются на одни и те же данные и через стату Вы можете посмотреть Сколько реально у текущего там файла еще есть ссылок жестких есть блокировки то есть flock И вот этот контент блокировки которые позволяют система еще блокироваться например там тот же почтовый сервер там код используют есть разреженные файлы То есть вы можете писать в дырку Вы можете писать за пределы файла То есть можно там на 10 гигабайт сделать это должно работать есть фалло Кейт который позволяет выделить место заранее под файл и там последние допустим есть там асинхронный вот вывод интерфейса синхронного ввода вывода в линуксе правда используется примерно так а собственно и теперь вопрос такой вот есть другие реализации файловых систем поверх ис-3 Почему они все медленные Ну то есть посик совместимости у них разная там Ну допустим совместимости хорошая там Практически все возможные фичи они поддерживают но он просто катастрофически медленный Ну то есть там дальше у меня будут тесты Но примерно порядок такой что там взять директорию от маленького сайтика со статикой Там шесть файлов и скопировать три через острие фс это занимает там час через занимает 25 секунд Вот почему так медленно но ответ на самом деле кроется в том что стриф юзы все синхронны в отличие от обычных файловых систем всем привычных локальных и в отличие от самих дисков синхронно все файловые системы Вы когда пишите ваша запись как правило сначала попадает в кэш потом там как-то асинхронно сбрасывается диски то же самое делают Там если вы возьмете рандомную десктопную sd-шку на нее натравить ФИО с рандомным врайтом то вы увидите там 100 тысяч Может на nvme 300 тысяч но если вы при этом Включите всем кто вы увидите одну тысячу причем почти на любой десктопной sd-шки это такая Константа магическая единственное вот у вас нет конденсаторов здесь вот на это ssd-шки желтенькие это они это конденсаторы они как встроены бесперебойник работают И когда у него есть бесперебойник он кэш просто не сбрасывает никогда вот в общем основная проблема этих всех остальных фьюзов том что они синхронные Ну Вторая проблема Это просто некие Странности в реализации вот Ну примерно вот такие но там еще есть но я вот примеры привел например там в стрессе когда там есть поддержка вот частичного изменения файла через копирование на стороне сервера но при этом если ты его меняешь то он всё равно диск тебе скачивается сначала целиком Ну понятно что быстро не будет Вот то же самое там Street Face ради поддержки атрибутов у них листики делают так сначала делается запрос списка а потом ещё на каждый объект делается по запросу вот Ну естественно если у вас будет миллион один запрос типа на листинге то быстро тоже не будет ну и там разные другое там разные глюки за- зависающие кэш и так далее вот ну в общем вывод из этого был сделан такой Что надо сделать свою реализацию и один из вопросов который тоже посетил это вообще на основе чего ее делать вообще способов реализации файловых систем в Linux их всего по сути вас 4 Ну во-первых вы можете напилить модуль ядра Если вы умеете но я лично не умею ядро это отдельная какая-то боль мне этим заниматься желания нету вот далее Далее есть NFS на самом деле неплохая опция потому что NFS Клиенты есть везде и даже не только они даже в винде есть клиент и например в фейсбучной монорепе у них монтирование монорепы сделана именно через NFS вот проблема НФ Правда в том что нет библиотек нормально то есть там что-то есть но оно глючное ну там есть допустим либо NFS но в нем баги я его сразу там у себя в проекте вид истории я это пробовал но в итоге В общем я это выкинул и свою реализацию написал Ну и Facebook то же самое то есть допустим у них в этой монопе Вот это на 7 у них тоже там своя реализация на c++ В итоге вот ну далее собственно Fuse Который наш любимый у него на самом деле есть некоторые проблемы Но для ис-3 там можно считать что они не критично Одна из таких больших проблем Это то что сокет между ядром юзер спейсом Он всего один и поэтому ограничено пропуская способность И вообще там какие-то операции Ну то есть когда делается сначала процесс там типа делает обращение к файловой системе оно пробрасывается в ядро из ядра обратно на самом деле сильный достаточно верха это тоже там в бенчмарках будет видно вот но в принципе там до какой-то степени производительность адекватная и можно там ограничениями для S3 пренебречь Ну еще одно ограничение например тоже такое странное ограничение про которое никто почти не знает обычно там не работает параллельно синхронная запись в один файл и поэтому например Когда вы там цепь монтируете через Fuse то всё очень медленно будет если там дай Бог пост запустить то будет всё очень медленно Почему так потому что просто в исходниках ядра стоит там блокировка в этом месте и всё вот ну зато В общем Ну как-то для ис-3 это в общем не критично потому что там параллельно мелкая запись в большой файл это там вообще не сильная сторона S3 Ну в общем Поэтому был выбран Fuse еще есть вирты оффс но это типа только для виртуалок То есть можно тот же самый фьюз Ну почти тот же самый фьюз если протокол его пробросить через разделяемую память там и через очередь то его можно подключать напрямую к адресному пространству qm и в общем это быстрее работает и параллелизм даже там есть уже ну нам это по понятным причинам не подходит вот ну в общем план реализации В итоге образовался такой берем уже существующую Go реализацию S3 фьюза под названием гуфис она самая адекватная оказалась доступного отпиливаем от нее все что не нужно болгаркой для труднодоступных мест вот добавляем буферизацию добавляем там какие-то недостающие фичи Тестируем бенчем и потом думаем Во что мы на самом деле уперлись и что ещё сделать на сервере Ну картина по поиск совместимости она в итоге получилось Вот такая я сильно Останавливаться не буду я скажу только что в основном всё работает кроме вот атрибутики которая именно из-за того что в стандартно 3 юзер это дата не отдается в листингах а делать отдельные запросы при листинге на каждый отдельный файл я себе позволить не могу У меня кровь из глаз от такой производительности вот поэтому это поддерживается только у нас потому что мы их добавили в листинге вот все остальное типа работает и список оптимизации но это тоже я сильно там Останавливаться не буду на паре моментов только остановлюсь вот столько всего то есть там параллельное чтение параллельное запись там случайно отключение упреждающего чтения при случайном чтении Ну там и всё такое вот на чем я здесь остановлюсь на чем я хочу остановиться это собственно эмуляции перезаписи эмуляция перезаписи она в S3 превращается во что-то такое Почему Потому что собственно перезаписи нормальный до вас 3 ее нету вот собственно понять как ее делать Понятно В S3 есть мультипарта плоды мультипарта плоды работают так вы сначала инициируете как бы загрузку потом в нее загружаете сколько-то частей и потом ее завершаете у вас файл пересобирается из этих частей при этом в процессе часть можно перезагружать Вот Но при этом при этом часть во-первых должны быть хотя бы 5 мегабайт во-вторых до того как вы Завершите загрузку прочитать обратно то что вы только что залили вы не можете в-третьих номера части идентифицируются по номерам и номера обязательно должны быть последовательные то есть от одного до Хотя в запросе завершения вы потом передаете явным образом список номеров и даже с етагами То есть вы с уникальным идентификатором передаете Казалось бы API располагает к тому что можно просто любые части загрузить и в любом порядке завершить но это не так на самом деле вы обязаны только строго последовательно их загружать и более того что то есть вплоть до того что вы если загрузили допустим часть номер там 10.000 То вам придется загрузить 10.000 частей Ну или выкинуть всю загрузку потому что оно вам не даст завершить допустим загрузить частей там 10 загрузить допустим не все части но номер последний чтобы был большой вот или там допустим загрузить там 100 частей 10 оно так не даст сделать Ну опять же вернее нюанс звездочка Почему стоит звездочка стоит потому что амазон так разрешает сделать а вот допустим Яндекс и цеф так не разрешает сделать ну поэтому можно считать что запрещено В общем и я просто хочу показать как это прикольно получается то есть ну вот представим У нас есть файл мы его просто пишем в конец пишем в конец и соответственно у нас есть какой-то кэш кэш ограничен Ну там по умолчанию допустим гигабайт Ну то есть мы там данные держим какое-то время в памяти вот Ну вот мы пишем в кэш пишем в конец файла а потом из кша заливаем на сервер постепенно логично что после того как мы залили и она нам не нужно а место нужно уже под новые данные нам данные старые приходится из кэша удалять вытеснять Ну то есть получается что сначала файла уже вытеснилось потом какой-то кусок уже записался отправляется на сервер и там В конец вот только пишется вроде все окей но Допустим мы дописали его до какого-то большого размера а потом нам пришло в голову перезаписать кусочек в начале не знаю может FM бег не знаю в бег что-то такое делает там какой-нибудь Маловато там не знаю Нет вот что-то подобное Вот и мы перезаписываем маленький кусочек в первой части а часть у нас 5 мегабайт А что в этих 5 мегабайтах мы уже не знаем потому что мы их выгрузили на сервер и обратно мы их прочитать не можем такого опила стри нет И вот получается что чтобы нам опять поменять нам приходится доливать все до конца дожидаться значит завершения читать кусочек обратно обновлять и пересобирать заново приходится завершать мультипард чтобы обновить кусочек то же самое если мы дописали и хотим кусочек сначала прочитать будет то же самое чтобы прочитать нам тоже придется сначала завершить мультипард потом прочитать вот так чет как-то это еще раз Ну ладно что-то некрасиво Ну ладно в общем так или иначе Да значит Ну потом мы завершили до прочитали наш кусочек заново и опять продолжили запись и после того как мы продолжили запись нам опять придется все части на стороне серверов себя скопировать Ну единственно немножко греет душу что сервер в принципе может это уволен внутри себя это оптимизировать и физические данные не копировать но тем не менее приходится еще раз копировать себя вот еще смешнее ситуация это вот с номерами портов допустим произошло такое мы вот создали большой файл Там Гигабайт на 50 залили Ну там что-то записали залили кусочек в конце и залили кусочек в начале после этого кусочек вначале выгрузился мы его забыли И после этого мы делаем танки то есть мы обрезаем файл Там до 20 килобайт от 50 ГБ прикол в том что нам придется сначала загрузить все 50 гигабайт Иначе мы не сможем завершить загрузку они завершив загрузку мы не сможем обратно прочитать наш кусочек в начале В общем конечно После всего этого можно сказать что да мутация все-таки не сильная сторона стрифьюза в любом случае но она по крайней мере работает для тех применений Где часто обновлять мелкие кусочки не надо Все нормально Ну а для тех вещей где надо такие обновлять кусочки Надо все-таки подумать реализации патча на сервере То есть просто частичного обновления объекта без вот этого всего извращения Ну и безлимита размера объекта потому что в обычном Астрид там номера частей тоже от 1 до 10 тысяч что соответственно создает лимит размера объекта который архитектурно непонятно зачем нужен потому что внутри ну просто части как бы все с номерами Почему их должно быть 10 тысяч непонятно В общем вот это мы сделаем через какое-то время и тогда появится нормальный патчи нормальная перезапись и станет Оно еще чуть-чуть ближе к файловой системе Что еще можно сделать на сервере чтобы облегчить жизнь файловой системе Ну патчи уже сказал потом есть еще один момент который уже сделан это собственно метаданные в листингах по его поводу У меня есть такая мысль на самом деле его внедрить в аппенсорс взять цех короче туда я тут поддержку такую же добавить импуль request отправить а потом может остальные растащат я не знаю вот может такое попробую сделать Ну и другие фантазии это сделать на стороне сервера переименование то есть то чего в принципе сильно не хватает И то что допустим там в том же ли в их иерархических бакетах уже есть вот у них это правда вот только в специальных бакетах но в принципе кто мешает сделать и не в иерархических Ну понятно там нюансы архитектурные там шарнирование Но посмотрим может быть получится и ещё есть такая фантазия то есть чтобы тот же ГИС FM можно было монтировать в классе и чтобы инстансы видели изменения друг друга быстро можно сделать через какую-то доставку изменений это даже в баги на гитхабе уже предлагали но очевидное в принципе идея И в какой-то из реализации фьюзов она в каком-то зачаточном виде даже есть Видел есть какой-то питоновый фьюз который типа через может обмениваться вот этими сообщениями правда только сам от себя но тем не менее вот ну в общем с эмуляцией закончили теперь это надо как-то тестировать тестирование делится на две части первая производительность второе стабильность или наоборот первое стабильность второе производительность это кому как нравится просто стабильность я сильно рассказывает там сильно углубляться не буду есть просто пара тестовых наборов то есть там самый взрослые серьезные тестовые набор это XS которыми тестируют обычные люксовые там X4 xfs и так далее вот также есть какие-то там другие наборы Ну вот есть один из примеров это pjdf с тест Он по моему из freebesda там откуда изначально происходит Вот он просто тестирует там разные по сексуации типа семантику операций есть там просто свои тесты там которые остались частично в офис частично там сами написали это понятно само собой теперь производительность производи файловых систем Ну во-первых первое понятно что приходит в голову Просто ручные какие-то операции поделать то есть там что-то покопировать что-то поудалять просто запустить DD там из деф зиру или там где внул вот но в принципе самый такой нормальный инструмент Да тестирование файловых систем это ФИО то есть вернее даже не так для тестирования ввода вывода в целом Обычно им тестируют вообще-то блочный девайсы и поэтому на самом деле у него движка Для нормального именно для тестирования системы у него как бы нету Ну вот некоторые суррогат я какое-то время назад у себя еще родил Я его назвал Сервер это там позволяет более-менее эмулировать какой-то потом доступ типа как вот файловый сервер делает Ну что файловый сервер обычно делает там какие-то папочки какие-то под папочки создает и у них там читает либо пишет файлы либо удаляет вот с какой с какой-то частотой но там частота запросов она стандартными ФИО а вот интерфейс просто вот еще есть бенчмарк джуса фесса это мдтест Juice FS это еще одна файловая система поверх острие но не совсем поверхность 3 она метаданные хранит в редисе и поэтому Ну и типа легче живется в общем вот от них еще есть бенчмарк для операции с метаданными Ну и такое тоже еще что все любят делать это засунуть туда ядро линукса и там его собрать что естественно тоже порождает много нагрузки на файловую систему причем нагрузки именно которая не требует частичного обновления в основном в основном это просто там чтение исходников целиком и запись результатов сборки целиком вот собственно тесты Ну начнем с копирования удаления когда я говорю что giffs самый быстрый то вот да она вот примерно вот так на операциях которые именно в сторону сервера работает то есть когда от вас изменение идут в сторону сервера она там быстрее в огромное число раз вот в принципе то же самое вернее Там сначала подтормаживал тоже но там после каких-то оптимизации после того как листинги по оптимизировали там то тоже стало хорошо В общем Ну во сколько раз я даже не знаю я считать не буду то есть по сравнению со стрельфом даже как-то сравнивается стыдно В общем можно не дождаться как правило вот второе это мдтест тут прикольно то что этот самый Just FS они у себя в документации приводят Ну примерно такой же график как бы только где синий этот juce FS а красное это S3 FS то есть они сравниваются То есть в принципе Juice FS он быстрее стрельфс А примерно настолько же раз во сколько гисфс быстрее Джус эфеса вот а здесь на самом деле Красная это амазоновская эластик файл System которая Ну вот как-то что-то не очень эластик это я язык документации цифры взял то есть я сам вот АВС не проверял цифра avs взята из этих бенчей из бенчатов вот я не знаю может там что-то они умудрили но что-то мне кажется какой-то он не очень ластик короче Вот соответственно желтенькая сам Just FS Синенькая дисс где вот столбики в небо ушли там на самом деле 100 тысяч но просто и у меня на график Не влезло вот дальше линейной скорости те самые там ddf ddrf вот с ними ситуация такая они зависят естественно от всего там включая погоду на Луне вот ну загад загрузки сети на виртуалке от нагрузки там хвоста той же самой вашей виртуалки с которой вы проверяете просто там от нагрузки сети и просто от текущей нагрузки на сервисы стоит там и так далее и так далее То есть поэтому Ну не надо воспринимать так что вы вот Повторите у вас та же цифра будет это всё зависит от там текущего состояния Но по крайней мере про линейной скорости Можно сказать что они там точно не хуже чем у офис в смысле линейных скоростей она такой своеобразный Эталон потому что она максимально тупая и именно вот последовательная запись последовательное чтение там максимальная оптимизировано просто берётся кусок от пользователя и отправляется на сервер сразу и всё вот если говорить о рекордах которые у нас получались Но эти рекорды получались железные машины у которой 25 гигабитная сетка была И там ну процессора тоже там нормальное количество Вот то получилось раскачать чтение до двух с половиной гигабайт в секунду запись до 1,6 Гб в секунду вот как это все получается но все то же самое то есть параллелизм и там оптимизации Fuse bending которые там лишнее копирование данных убирают Ну он у нас собран с оптимизированным да как я уже говорил что это такое Это там типа эмуляция паттерны доступа файлового сервера Ну тут именно тут я в основном именно прочтение тут много цифр у меня нет я один там тест условно провел но показатель он в том плане что я его сравнил с локальным диском виртуалки в амазоновском Облаке вот здесь ну параметры параметров там ну то есть это параметры означают Короче говоря что берется 10 гигабайт в виде файлов по 128 килобайт сколько-то там их получается ну там у меня поделите Я не знаю вот ну в общем смысл в том что диск виртуалки выдаёт 900 там 77 вот здесь FS в принципе тоже близкую цифру просто за счёт То есть это такая иллюстрация работы кэша Ну и самый жесткий тест в котором поучаствовал мой домашний днище цеф который видно на Вот он в общем попал на highload мой домашний днище цепь можно сказать увековечен это сборка ядра до тут я его сравнил Ну как с локальным диском я его сравнивать не стал потому что грустно вернее его сравнил но я вставлять результат не стал потому что на nvme оно там распаковывается за 2 секунды по моему нет по-моему за 10 секунд короче удаляется за две собирается за минуту там с половиной по-моему вот ну с этим стыдно сравниваться Я с этим не стал сравниваться вот если нашёл других мальчиков для битья вот в качестве мальчиков для битья у меня выступил cfs и гисфс поверх того же самого Цефа вот цепь уже есть как бы файловая система S3 вот интересный вывод в частности что S3 цефовая медленнее чем cfs ну здесь в общем каким-то мистическим образом gisfs Обогнал все трицефа если смотреть вот по суммарному показателю но в принципе и просто по самой сборке То есть просто там Make Mini g16 Он на kiss Face поверх S3 Яндекса он ну там процентов на там 15 типа наверное да медленнее то ли медленнее чем вот там цеф локально подключенный по сети причем локально подключенный через ядерный драйвер вот А например через юзовый драйвер сразу видно что цефт еще гораздо медленнее стал то есть интересно здесь то что по всей видимости там интерфейс подключения системы там ядро или Fuse он влияет больше чем самого диска чем то что у вас там это SSD там не знаю там создание знают но В общем это чем сам сервис или диск вот для сравнения типа с локальным диском есть тоже то есть зачем NTFS 3G Затем что там тоже Fuse вот Ну и в принципе тоже видно что там даже NTFS 3G на локальном жестком диске он в принципе тоже медленнее чем giffs поверх Яндекса Вот еще одна иллюстрация работы кэша это то что вот при сборке там 99 и 8 процентов запросов к файловой системе giffs отдает из кэша в памяти Вот и только там вот 0,2 процента они только обращаются на сервер вот Ну в общем статус этой штуки такой что стабильно она примерно с ноября прошлого года ну считается стабильной и люди в принципе пользуются какие-то баги иногда исправляются но в общем таких каких-то там крупных вроде уже не было в Облаке больше 500 пользователей есть для губерната соси Саи который позволяет монтировать стрижки как ну и соответственно как я уже сказал мы неизбежно сделаем патч для HTC применений чтобы была нормальная перезапись Ну типа не переключайтесь вот Ну примерно вот так у меня на этом в общем-то все А сюда почему-то не попал qr-код сюда не попал qr-код если сделать F5 я не знаю где компьютер тот с которого Вот это идет но если там нажатие в 5 то появится qr-код Отлично так любом случае спасибо тебе за доклад отличный гусь Давайте поблагодарим так и если есть у нас значит соответственно в зале вопросики то можно их задавать поднимать руки и тогда у нас девушки с микрофонами подойдут пока у меня вопрос такой вот смотри понятно что пришлось поисследовать там ходить в разные облака разные реализации и понятно что везде отличается понятно что это всегда там вот где-то мелкие нюансы Вот какую-то какой-то ты предполагаешь сделать в конце концов вот для того чтобы потом это всё тестировать чтобы S3 тестировать Ну собственно говоря свое решение чтобы потом когда следующей версии будут все появляться FS у меня вся и прикручена у меня вся и прикручена там свои тесты и вот эти XF тесты взрослые так сказать тесты X4 по крайней мере в той части которая применима потому что там есть какие-то операции допустим жесткими ссылками жёстких ссылок понятно там нету И никогда не будет Вот поэтому эти тесты пропускаются вот а те которые применимы они прогоняются Они всегда проходят вот там основных два самых жестких это там дир стрессов и стресс это просто тесты которые там мучают файловую систему кучей там операций над метаданными разными Вот это все проходит все прикручено Спасибо большое так если вопрос вопросов не вижу Давайте еще раз о пожалуйста пожалуйста микрофончик пожалуйста молодому человеку Извините микрофон у меня следующий вопрос собственно говоря мотивация показали несколько мотиваций Зачем это делать конкретно В вашем случае как это сейчас используется и второй вопрос какие дальнейшие вы сказали патч как бы дальше хотите развивать именно продукт Ну я говорю то есть в моём случае я лично его делаю не использую но пользователи из того что Ну вот приходил народ первое Что используют это вот губернатосе просто ну там просто условно под какие-то Рандомные данные там под статику кто-то под рпм пакеты кто-то там еще под что-то Ну под Рандом такой вот и несколько Стоит ли использовали под Ну такое некое подобие HPC То есть под массовую обработку там каких-то в общем у одних По моему это были видео файлы Вот они пробовали у других еще там что-то но в общем смысл типа как замена распределенная FS там где воркером не надо по данным сильно пересекаться то есть там где нету такого что они там одно и то же пишут или одно и тоже читают вот этого еще допустим внутри используют кто-то под бэкапы Ну я вот это в принципе всё и перечислял в принципе применение более-менее реальное так применяют Ну я еще один сценарий накину в сервере с архитектуре Например можно какие-то данные между отдельными функциями Через три через файловую систему подгружать перегружать чтобы можно было так сказать распределённое FS в разные стороны пихать Спасибо большое за вопрос договорил про про развитие да Ну соответственно развитие что хочется сделать в первую очередь хочется сделать вот патч вот возможно еще там переименование еще что-нибудь на стороне сервера Ну то есть хочется приблизить это именно к файловой системе Вот и в принципе ну я как уже тоже сказал То есть Есть идея чтобы это вот не оставалось чисто там Яндекс специфик реализации протолкнуть это как-то там допустим через цепь то есть импульквесник заслать ну допустим там те же метаданные в листиках отдать Но это я не знаю Там должно быть строчек 10 кода вот просто его надо влить а допустим из Стефани потом расстались и тогда это будет какая-то уже там совсем универсальная вещь Спасибо так вот на первом ряду пожалуйста Добрый день спасибо за доклад у меня такой вопрос вот помимо пусикса в линуксе есть например Айна Tefal его нету на фьюзе Но вот вопрос есть ли у вас планы по развитию какие-то чтобы не надо было на ивенты S3 подписываться А через ваш драйвер так скажем получать идентификации о том что что-то изменилось они перечитывать то есть мы вот например на фьюзе кластер фейсом пользуемся и вынуждены каталоги перечитывать непрерывно что Ну конечно неправильно по сравнению который мы можем нативных файловых системах использовать Я вообще такое скажу вещь что в фьюзе есть на tefi там есть опишки которые позволяют подключить идентификации там некоторые других вещей нет например вот то что в консоли это Синг набрать оно должно все данные сбросить вот в случае фью не работает его просто в ядре вообще нету этого хука вот но конкретно на тифай он есть и то что его там власть или нет Это значит что он просто нереализован соответственно Но в нашем случае получается что сначала нужна какая-то поддержка сервера если ее сделать вот типа вот как когерентность кэш условно когерентность кэшей тогда можно идентификация сделать потому что сам хук там есть вот ну как запишем себе в вышли из скажем так спасибо большое Так может быть ещё какой-то вопросик есть так хорошо Кстати тебе какой из вопросов больше всего понравился то что с небольшой подарочек Ну давайте проноте фай про натефай так девушки Пожалуйста передайте подарочек ронативай все Если вдруг еще есть да остальные вопросы можно будет задать в экспертной зоне прям сразу на выходе у нас находится где можно будет тебя поймать заловить так сказать да и Давайте поблагодарим докладчика Спасибо тебе большое было очень круто Виталий гуси Великолепные Спасибо всем большое До скорых встреч встретимся в этом зале Спасибо"
}