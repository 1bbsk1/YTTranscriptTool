{
  "video_id": "0M0gDXBauD4",
  "channel": "HighLoadChannel",
  "title": "Как мы готовили поиск в Delivery Club / Иван Максимов (Delivery Club), Евгений Исупов",
  "views": 828,
  "duration": 2192,
  "published": "2023-01-19T06:59:53-08:00",
  "text": "что ж Всем привет Рад выступать на этой сцене как сказали уже ведущие буду выступать Я в оффлайн режиме Меня зовут Иван и будет выступать мой со докладчик Женя он будет в онлайн режиме и мы будем рассказывать как мы готовили поиск в компании Delivery Club для начала пару слов о нас как я сказал Меня зовут Иван Максимов на момент построения поиска я был ML тимлидом в рекомендациях и або тестировании и Недавно я стал руководителем клиентской аналитики и emil в целом чем я занимаюсь в Delivery Club я делаю Delivery персонализированным строю и внедряют я где-то уже 6 лет в дата сансе закончил собственно skoltech по Data Science довольно много где преподавал Возможно вы меня видели и я веду свой Telegram канал ML for value искренне верю что лучше делать не сото решени а более простые которые работают быстро дёшево и приятно и во многом именно об этом и будет наш доклад про поиск если что вы можете написать мне в Telegram попозже и задать любые вопросы а мой со докладчик Женя он EX поисков Delivery Club он довольно долго работал в Кэн разработке и закончил вмк МГУ Также вы можете написать жене в Telegram в конце презентации будут наши контакты ещё раз Если захотите можете их записать и нам потом написать а теперь я включу небольшое видео от Жени про то как у нас устроена архитектура поиска и с какими проблемами мы столкнулись при дизайне новой архитектуры Всем привет Меня зовут Евгений супов и сегодня расскажу вам как мы перестраивали н часть поиска dely Club поизд год назад имел ряд проблем так в топе появлялись непопулярные нерелевантные рестораны с медленной доставкой также почайне дого секунды на дено дем НТИ с технической стороны для исправления отпечаток использовался фузи поезд поэтому сервис чал так долго для расширения контекста использовались синонимы они заполнялись вручную поэтому это приводило к большому количеству ошибок и сложно решаемым кейсам для ранжирования результатов использовалась только текстовая близость и за ластик сёр перед нами поставили цель сделать быстрый поиск который будет соответствовать запросам и клиента и бизнеса для достижения данной цели мы поставили следующие задачи Первое - это быстрое исправление печаток второе расширение контекста не только с помощью синонимов И третье - это ранжирование результатов с помощью не только текстовой близости но и популярности удалённости контекста а также персональных предпочтений пользователя В поисках решений мы проанализировали как лидеры рынка разрабатывают архитектуру поисковой системы так дош вводит понятие палана поискового запроса получая запрос на входе в стадии происходит исправление печаток понимание расшире контекста а также полу докумен не полученных результатов мы адаптировали результаты нашего анализа и создали архитектуру поиска Здесь также есть две стадии recol и prision где с помощью готовых инструментов и внутренних разработок происходит быстрое исправление отпечаток расширение запроса контекстом и ранжирование полученных результатов На мой взгляд особое внимание заслуживает расширения контекста Ведь именно оно позволяет нам находить по запросу пьяная бабушка не только бургер пьяная бабушка но и другие бургеры далее о внутренних разработках по расширению контекста расскажет Мой коллега Иван Максимов что ж Спаси Спасибо жене за такое небольшое введение здесь на слайд я выл вывел архитектуру поиска про которую говорил собственно есть поисковый запрос пользователя например пьяная бабушка далее мы исправляем опечатки с помощью сервиса опечаток и далее Идёт уже более интересная стадия мы называем категоризация запроса или стадия Rec на самом деле на этой стадии мы категорируется получаем документы условно топ 50 документов и с помощью некоторой ML модели о которой Расскажу чуть позже мы их перен и показываем нашим пользователям и Для начала я расскажу про стадию Rec собственно зачем вообще делать категоризацию запроса Ну во-первых потому что иногда не работает поиск по словам печатками например по запросу пицца вы никогда не найдёте левую картинку с аппетитной курочкой 30 см Несмотря на то что даже по названию и описанию вполне понятно что это пицца тут не работает ни поиск по словам ни фузи поиск ни какая-то семантическая близость собственно при этом категория блюда как будто бы очевидно Да здесь я выявил специально карточки блюд в общем-то Это всё что мы знаем о блюде У нас есть фотография блюда У нас есть его название некоторое писание которое может быть в виде веса ингредиентов может быть в виде того что ресторан просто сделал какое-то красивое описание может его просто не быть и мы знаем ещё цену блюда собственно Да почему точнее Зачем категорирование Понятно Но почему делать именно классификацию по тегам А например не использовать динги которые так популярны ВК сече Ну во-первых потому что так во-первых можно во-вторых гораздо проще измерять качество тегов Мы точно можем сказать насколько хороша наша классификация можем мерить как классические метрики precision Rec так и что-то более сложное во-вторых вес тега как правило меньше веса динга эмдин - это некоторый Вектор он может быть 128 флотов может быть 256 чуть больше чуть меньше тем не менее это довольно много цифр тег - это как правило три-четыре цифры под айдини нашего тега Ну и самое главное теги очень легко дебажить потому что зачастую приходят менеджеры с вопросами почему же на запрос суши в выдаче появляется шаурма Если у вас есть тег то вы можете легко посмотреть какой же тег у рола куриная грудка если окажется что это тег суши а не тег шаурма то в общем-то понятно что делать и примерно понятно почему так происходит далее про метрику качества модели на стадии recol собственно здесь мы делаем достаточно просто мы фиксируем некоторый уровень prision он у нас более 70% это гарантирует нам что при прогнозе тега поке в более 70% случаев это блюдо действительно является поке то есть поиск в целом релевантен и При таком ограничении мы естественно максимизирует больше таких блюд в Delivery Club чуть ниже приведена формула как точно можно считать две эти метрики далее возникает естественно логичный вопрос хорошо Мы хотим классифицировать блюдо какие классы или теги нужны У нас есть только блюда их довольно много нет никакой разметки никаких тегов нам самостоятельно нужно это придумать Ну что мы сделали мы сделали довольно просто мы посмотрели на популярные поисковые запросы посмотрели на популярные фильтры объединили их и получили примерно 50 самых низкоуровневых тегов например суши бургеры пицца шаурма и так далее но тем не менее мы поняли что просто завести 50 тегов не очень хорошо работает хорошо бы заводить некую иерархию тегов она выглядит примерно так есть самые низкоуровневые теги например чу хочупури хинкалий манты и так далее которые объединяются в более высокоуровневые например в кухне Кавказская русская и так далее Также оказалось довольно полезно делить не только по типу блюда и по кухне но и также по типу Прима пищи например первое второе сусат и более ников и так далее В итоге мы получаем Четыре типа тегов это тег по кухне Кавказская русская азит и так далее Это самый низкоуровневый тип блюда например хачапури Хинкали Ман и так далее Чуть более высокоуровневый тип мясо рыба и так далее и уже такой финальный тип по приёму пи суп салат второе и прочее иде определять все четыре типа этих тега мы делаем достаточно просто мы прогнозируем самый низкоуровневый тег это который хачапури Хинкали маты шашлыки и потом просто объединяем их в более высокоуровневые это позволяет достаточно хорошо повышать наш рекол поиска потому что Например если человек вбивает хачипури в поиск а в каком-то разумном радиусе доставки ха Нет мы не просто не показываем ничего ему что-то из кавказской кухни это достаточно просто при этом очень хорошо работает далее возникает логичный вопрос хорошо мы поняли На какие теги нужно классифицировать блюдо Но где брать данные для обучения У нас есть просто данные от ресторанов как я говорил это фото блюда название блюда его описание и цена и больше ничего Где же можно взять наши таргеты наши целевые классы дёшево и быстро Ну во-первых естественно можно разметить вручную и мы разметили примерно 20 блюд и стали считать что это наш то чему Мы точно верим это критерий истинности всех классов и далее Мы решили использовать некоторые простые вещи чтобы собрать побольше данных Ну во-первых естественно можно использовать простые регулярки Например если в названии блюда есть слово пи категории меню paring мы дополнительно проверяли на prision на Golden сете ручной разметки и Мы проверяли чтобы prion такой дополнительной разметки был больше 95% чтобы мы могли точно этому доверять что ж про пусты регулярки Я сказал также у нас рестораны присылают категории меню они не структурированы рестораны могут называть их как угодно ресторан может название назвать категорию меню блюда из авокадо или назвать категории меню вторые блюда как ему нравится но тем не менее из некоторых названий категорий тоже регулярка можно вытянуть типы блюд Таким образом мы до собрали ещё дополнительно примерно 300.000 размеченный данных также мы парсли сайты с рецептами и категориями блюд Это дало ещё примерно 70.000 наблюдений В итоге у нас есть датасет примерно из 600.000 блюд уже размеченный и ещё больше 10 млн нужно разметить с помощью ML модели далее я наверное буду рассказывать чуть поподробнее про то как же обучать нашу ML модель потому что дело в том что ту выборку размеченный которую мы собрали она может очень сильно отличаться от реальных данных на которых мы будем применять модель поэтому модель должна быть очень-очень устойчива ко многим вещам Ну например модель должна быть устойчива к отпечаткам модель должна улавливать смысл слов потому что слова суши и сушки отличаются всего в одну букву Если вы будете делать полнотекстовый близость то суши сушки очень близки но по смыслу это очень далёкие слова также мы должны улавливать новые слова Например пицца пинца потому что регулярка мы вытаскивали только пиццу нцу допустим нет а моде это понимать собственно поэто не с словами А с некоторыми грами букв например слово л можно на и и слово ро с одной с ошибкой разделить на и и они будут похожи по первой грамме в общем-то примерно так работает предобработка слов в популярных моделях ВТО Дале так как мы собирали наш датасет не очень аккуратно с помощью регуляр и прочих вещей то нужно уметь бороться с заучивания Например если мы регуляр кой по слову пицца в названии можем понять что блюдо - это пицца естественно ML модель может выучить то же самое и в общем-то просто повторять наш способ разметки нас это не очень устраивает потому что модель должна размечается поэтому мы делаем следующий способ мы делаем дропаут слов при обучении то есть мы случайным образом из названия плюс описание блюда выкидываем некоторые слова и модель обучается уже на неполных названиях плюс описаниях блюд Таким образом мы заставляем модель улавливать смыслы а не заучивать например определённые слова в названии вроде тоже есть такая особенность Иногда у нас бывают очень короткие названия плюс описание блюд а иногда очень длинные Ну и в коротких как правило Суть в начале например бургер с говядиной первое слово бургер понятно что это а иногда смысл размазан по тексту вот как в этом случае с рекламой бигмака мы можем понять что Это бургер по словам котлеты соус булочка которые находится в разных частях описания также помимо очень важен контекст Ну например рол Калифорния штук - Это суши а тотже самый рол с вем летом - Это сэндвич помните несколько слайдов назад Я показывал ошибку Почему на запрос суши удаются роллы именно потому что тогда очень давно не учитывался контекст и появлялись вот такие ошибки чтобы учитывать контекст глобально есть таких два популярных спосо это моки моки с короткой памятью Я чуть поподробнее расскажу о том как мы Их использовали и как выбирали между ними чуть позже также что стоит отметить Мы собирали наш обучающий датасет очень специфичным образом и распределение классов в обучающем датасете и в тестовом очень сильно отличаются то есть вот Golden Set это пря Случайный 20.000 блюд из всего Delivery CL Как видите зены л синие очень не похожи Да например вот что здесь есть горячие супы в обучающем датасете их почти нет а в реальности в Delivery Club их довольно много также как вы можете обратить внимание есть дисбаланс классов даже внутри обучающей выборки например бургер самый популярный класс может быть в несколько сотен раз популярнее чем какой-то другой тег и с этим тоже как-то нужно бороться в целом как мы с этим боролись и как верхнеуровнево чуть упрощенно выглядит архитектура модели У нас есть название плюс описание блюда например Филадельфия штук мы используем выкидываем некоторые слова из этого названия и делаем токенизация чилось у нас всё далее У нас идёт несколько слоёв blm BM - это двунаправленный СТМ который идёт от начала названия до конца а потом от конца до начала либо какой-то из слоёв Attention ну после этого всё это агрегирующие предсказания классов как же эта архитектура связана с теми проблемами которые я говорил чуть раньше Ну во-первых два вида дропа аута помогают бороться с заучивания слов а предобработка слов помогает немножко бороться с отпечатками и улавливать смысл и например работать со словами которых не было в обучающей выборки как я говорил контекст важен и у нас есть короткие длинные тексты с этим помогают работать либо бе либо а баланс классов мы учитываем на уровне весов функций поте что ещ стоит сказать пожалуй про архитектуре модели она достаточно тяжёлая То есть она достаточно долго обучается и у неё достаточно долгий иренс при этом поиск должен работать как вы понимаете быстро что же с этим можно делать здесь мы пошли немножко хитрым путём мы посмотрели сколько у нас здесь всего блюд поняли что их грубо говоря 15 мл вроде бы много но в целом не настолько много чтобы не сделать предсказание классов на все блюда заранее и хранить просто айдини блюда список классов собственно мы делаем оффлайн предсказание классов на все блюда и просто их храним в индексе чтоб в Реал тайме дёргать уже индекс а не саму модельку это в разы быстрее и очень эффективно также Мы подумали Хорошо можно расширять название блюда категориями Но что если как-то расширять поисковые запросы категориями и тут была тоже идея Наверное нужно поисковой запрос в рел тайме кидать в модельку получать предсказания но это очень долго и мы решили посмотреть А вообще как много поисковых запросов И как часто они повторяются то есть мы взяли все поисковые запросы за последние полгода из них выделили один последний месяц и всё остальное предыдущие пять на предыдущих пяти месяцах посчитали там топ самых популярных запросов и оказалось что за последний месяц из предыдущих пяти примерно 94% повторяются то есть в целом Мы также оффлайн можем взять поисковые запросы за последние N месяцев сделать предсказание их категорий хранить где-то в индексе и потом просто дёргать индекс в реалтай а не модельку это будет гораздо быстрее это покрывает оказывается 94 поис про поисковых запросов что в общем-то очень мощно а ради 6% делать не хочется и наверное смысла в этом особо и нет что ж какие у нас были эксперименты с моделями Мы начинали с чего-то очень простого с обычной логистической регрессией Фаст текста И оказывалось что это давало действительно довольно низкий скор Таким образом мы начали потихонечку переходить к более сложным модем последние три модельки то общем это как раз модель с предо динга предпоследние - это модель с предо динга которые мы размораживая обучения динги могли меняться мы брали динги текста и последняя моделька это уже обученный практически с нуля в общем оза Доча ну работает примерно также какр обучается сильно быстрее в общем-то её мы и взяли Так что в итоге мы выбрали модель с динга которые у нас просто размораживаются во время обучения что ж Давайте посмотрим на интересные примеры здесь я подчеркнул слова на которые модель больше всего определя Больше всего обращает внимание при определении левых классовые вы уже видели но тем не менее Вот например про аппетитную Курочку 30 см оказывается модель определяет что это пицца по 30 см Ну действительно вряд ли вы в категории Суши или шаурма встретить слово 30 см довольно необычный кейс в случае с суши модель обращает внимание на такие специфические слова как маки и лосось рис чтобы определить что это суша Ну а в случае с роллом это уже класс шаурма моделька обращает внимание не на слово рол А на слова лепёшка и соус которые действительно лучше определяют это блюдо как шаурму что ж на этом мой рассказ про стадию Rec закончен Напоминаю что это нам помогает выбирать Больше блюд для дополнительного ранжирования результатов и собственно стадия prision помогает эти результаты как пережить Почему стадия в целом важна зачастую бывают очень широкие поисковые запросы например поисковый запрос бургер в центре Москвы вернёт вам возможно 100000 бургеров как их аранжировать совершенно непонятно по слову бургер в общем-то все бургеры примерно одинаково релевантны и Сейчас я расскажу как же мы Тае поис зажи вот так выглядит архитектура поиска и ранжирование результатов - это наш последний шаг в общем-то мы долго думали как это сделать очень быстро и дёшево в общем-то не хотелось разрабатывать отдельную модельку для поиска потому что это время на поддержку на разработку и так далее Мы подумали что если сделать это очень-очень дёшево Дело в том что у нас уже есть ML моделька которая рекомендует рестораны пользователя для ленты рекомендаций и мы подумали что если её переиспользовать в поиске давайте я скажу Пару слов про нашу ML модель которая используется для рекомендаций ресторанов в Ленте ресторанов в общем-то эта модель для каждой тройки пользователь локация и ресторан прогнозирует вероятность заказа и далее те рестораны у которых вероятность заказа выше показываются в Ленте много признаков подробно про неё можете почитать в нашей статье на хаб я расскажу только про несколько наверное самых интересных для поиска Ну во-первых ML модель естественно учитывает популярность ресторана согласитесь на запрос бургер Скорее всего вы хотите получить бургер из каких-то популярных сетей чем из ресторанов во-вторых то что очень важно для достав моделька учитывает время доставки буста горячий вкусный замечательный бургер доставленный за 2 часа скорее всего вам уже и не нужен Ну и также модель учитывает некое ценовые категории пользователя и ресторана потому что кому-то нужны условно бургеры из макдональд или KFC а кому-то дорогущие бургеры за 800 руб ну и также модель учитывает ещё очень-очень много признаков ещё раз може х вше просто мы считаем некоторый финальный скор который складывается из двух условно прогнозов есть скор по текстовой близости запросов и документов из сеча который в общем-то показывает насколько документ релевант на запроса и есть скор модельки которая показывает то насколько документ релевантен пользователем влом без Ута запроса влом можно с поисковой запрос пользователя это просто ещё одна фича в ML модели и можно как-то это дело учитывать Мы решили учитывать с помощью вот такой функции А если вы занимались экономикой Скорее всего вы её знаете это функция Коба дугласа который довольно неплохо описывает пользовательские предпочтения примерно также например работает fbas В ML и собственно мы просто взвешиваем текстовую близость из elas сеча и вероятность заказа из модели через коэффициент Альфа который просто подбирается в тестах собственно Почему мы делаем так ну потому что это просто и быстро не нужно разрабатывать какую-то ещё одну модель не нужно её поддерживать и так далее во-вторых текстовая близость запроса документа можно рассчитывать как просто ещё один признак в Ну и наверное самое главное потому что можно Независимо развивать поиск то есть elastic Search и независимо развивать ML модель ранжирования и Действительно это довольно полезно потому что это развивают разные команды и не хотелось бы делать лишние зависимости между ними что у нас В итоге получилось новая архитектура поиска ускорило время ответа более чем в два раза для девяносто девятого процентили она что наверное самое важное повысила конверсию из поискового запроса в заказ на чуть больше чем 5% что на самом деле довольно много и она снизила среднюю позицию клика примерно на Две позиции как это всё дело можно интерпретировать Ну ускорение время ответа понятно Это скорее некая Техническая Метрика а повышение конверсии наверное можно интерпретировать Как улучшение Rec Ну потому что у нас меньше доли пустых выдач поэтому пользователи чаще находит то что им нужно а снижение средней позиции клика можно интерпретировать Как улучшение ранжирование финальных результатов потому что релевантные результаты теперь находятся выше в поисковой выдаче чем нерелевантные что ж на этом У меня всё Если вам понравилось выступление Вы можете задать вопросы Сейчас либо подойти на стенд Delivery Club пообщаться об этом Если хотите пообщаться про вакансии в Delivery тоже подходите На СН Delivery Club Спасибо за внимание жду ваших вопросов Спасибо большое за Огромное спасибо Так я вижу уже кучу вопросов в зал много-много вопросов Добрый день меня зовут Сергей вопрос А как вы используете категорию То есть вы сначала категорирование кроме этой категории там на самом деле мы тестировали несколько вариантов мы создавали дополнительный индекс категории или просто добавляли название категорий В название блюда и оставался один индекс в итоге остановились на том что просто название категорий конкатенировать А можно Малей вопро вот сза там ну на последней стадии ранжируйте только 50 товаров А вот ну 50 блюд а вот с последними Что делаете выкидывается или или в хост отправляете насколько я помню там есть ограничение поисковой выдачи оно как раз порядка 50 или 100 товаров то есть мы показываем некоторые топ результатов Ну просто потому что условно 90% пользователей не стают дальше дй позиции поэтому нет смысла показывать там Топ 1000 реу потому что никто до них просто не доливает Здравствуйте здесь Спасибо за доклад вопрос про коэффициент Альфа с помощью которого вы взвешиваемое он фиксированный для всех пользователей или для каждого он может быть свой подобранный там пото по каким-то предпочтением потому что кто-то например готов дольше ждать а кто-то готов там меньше платить или больше платить и вос Как часто Он пересматривается ведь там с течением времени тоже могут меняться предпочтения что там люди подстраиваются Ну под сервис Там готовы больше ждать наоборот меньше ждать да хорошо смотрите коэффициент Альфа он фиксированный для всех он подбирается в тесте один раз как учитывается персональные предпочтения пользователя через ML модель собственно она достаточно часто обновляется поэтому она и учитывает персональные предпочтения и за С Е обновления учитывает некоторые изменения предпочтений коэффициент не пересматривается Мы скорее обновляем то что внутри То есть например модель либо развиваем здравствуйте по вашей модели вот из сре попробовать как это работает действительно не новояз а Итальянская пицца И вот он мне нашл салфетки духи рулетку и ни одной пиццы можете рассказать что с вашей рекол моделью случилось Что с нашей моделью Дело в том что в какой-то момент в deliv CL помимо еды появилась не только еда например салфетки очень тяжело классифицировать в один из тех тегов Потому что те 50 тегов все про еду нужно нам добавить пся первый тег не продовольственные товары мы в процессе этого да здравствуйте А смотрите А вы по умолчанию для пользователя не имея для него ML модели как себя система ведёт То есть у вас новый пользователь А смотрите собственно ML модель - это некоторый ML сервис у которого естественно есть лбк на нового пользователя как я говорил моделька предсказывает на тройку пользователь локация ресторан если пользователь новый то как правило Мы про него знаем только локацию и там есть некоторый лбк по локации условно про популярность и расстояние от про популярность ресторана в этой локации и расстояние до пользователя поэтому там действительно такой не персонализированный флк для новых польва используете нные для подготовки когда не пользовался сервисом регистрируюсь у вас регистрируюсь через рекламу доставки еды что мне по слову пицца попадёт опять возьмём эту историю По идее я как пользователь который пришёл с рекламы по заказу еды должен увидеть в ответе пицца если я выхожу с какого-то сервиса с рекламы по заказу тех же салфеток я должен увидеть салфетки учитываете ли этон нные которые вам поступают они в любом случае вас поступают отве это понятно у нас на самом де были некоторые эксперименты по учёту дополнительных данных о пользователе Но оказалось что это не очень хорошо работает и допустим просто популярность ресторана в локации это условно там 95% успеха Можно конечно добавить другие данные Это для нового поляново Поэтому пока что мы не добавляли ихва геопозиции учитывать смотрите Эта история не разовая дальше на основании геоданных посещаемости любых Других данных из открытых источников Вы можете корректировать выдачу я приезжаю из одной квартиры в другую к друзьям Я хочу сделать заказ Если я езжу часто на какое-то место предпочтения в новом месте должны соответствовать тому что я чаще всего заказываю учитываете ли эти данные справились вы с этой задачей или не справились потому что ну прогнозирование не всегда хорошо иногда работает SQL просто обычный запрос работает лучше любого смотрите геоданные конечно учитываем Потому что при заказе Даже новый пользователь Дон указать ареда достав собре заказа всегда учитывается в ML модели и для нового и для старого пользователя одна из фичей в ML модели - это естественно популярность ресторанов в некотором гексагон в который входит этот адрес Так что да используется как одна из фичей в модели Да что последний вопрос А можно я от себя тоже вопрос задам а то что у меня просто компьютерное зрение в анамнезе и у меня такой вот интерес Ведь вы же ранжируйте вот ну карточку товара некоторую Да доставку там же всегда есть картинка кажется что это такой прямо хороший ортогональный сигнал взял какую-нибудь любую обученную на инете модель Да обучил там несколько слоёв и вот тебе классный классификатор запроса и результат не пробовали А думали об этом немножко экспериментировали действительно улучшает модель пока не так чтобы супер критически чтобы сразу это добавлять но в планах добавить есть Да Действительно это помогает классно больше компьютерного зрения везде L"
}