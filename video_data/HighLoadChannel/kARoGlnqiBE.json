{
  "video_id": "kARoGlnqiBE",
  "channel": "HighLoadChannel",
  "title": "На творчестве Линуса Торвальдса NGFW не построишь / Денис Кораблев (Positive Technologies)",
  "views": 9555,
  "duration": 2396,
  "published": "2024-10-29T02:38:14-07:00",
  "text": "И следующий спикер Денис кораблёв расскажет чем их не устроил стандартный сик о Lin Приветствуем Денис привет экспресс вопрос уже традиционный А для чего кратко что Для чего Почему не стандартный и для чего нужно что-то другое кратко для тех кто не жда 30 минут а не на самом деле это кликбейт най заголовок я сразу признаюсь то есть мы просто думали чтобы народу побольше привести но смотрите Сколько пришло так что в принципе работает сработал да да А сейчас мы наверное узнаем настоящую суть прош доклад слова да всем привет На самом деле Оценил название зала там намёк на то что в принципе здесь аутсорс должно быть много да дали дали Ката А смотрите Про что поговорим а Next Generation Firewall такой класс продуктов я расскажу что он делает как он устроен и в принципе тут как это две крайности есть linus tards с самого левого края Да там linus ядро и спра с самого правого сделать всё железе вот как пройти посередине про это и будет история пару слов Почему я про это вообще Рассказываю я сам по себе программист с восьмого класса код пишу плюсы мой любимый язык я писал наверное там всё что бывает в худе от Low laten и это доч банковская была система Алга трейдинга до распределённого бэнда скапа когда это ещё был Skype а не Microsoft который потом всё это к сожалению потерял Вот и всякие хафт системы которые занимались законным перехватом трафика Да может это не очень там с точки зрения морали но зато как это круто технически делать Ну то есть это прямо очень сложный продукт и я делал их несколько разных и в принципе я как-то доволен этим своим опытом вот ну и сейчас в текущий момент я занимаюсь больше стратегией продуктов придумывания их делать так чтобы они вообще случились и сложились при этом меня одно из любимых направлений защита приложения Я мечтаю чтобы разработчики хоть чуть-чуть научились секюрити тогда жизнь станет безопасней но ещё помимо этого конечно же Next Generation Firewall - это там ну для меня это наверное пик После него Нужно уходить на пенсию то есть вот после того как сделаешь такой продукт потом всё вот в Нирвану всё следующее будет пресно вот ну и я немножко пишу там свои мысли делю Сими вот есть ссылка QR код Если хотите почитайте мой Telegram канальчик вот переходим к тому что такое Firewall и что такое Next Generation Firewall раньше лет так 15 назад в целом все пользовались файлами шники под ВСети порты пулы портов То есть можно было там запретить какой-то айпишник какой-то порт это значило Что кому-то запрещено пользоваться каким-то приложением в современном интернете так вообще не работает потому что все приложения работают через 443 порт всё https и если так сделать то заблокирует интернет человеку вот поэтому вместо айпишник I подсетей есть пользователи группа пользователей вместо портов полу портов приложений группа приложений Ну то есть я всегда привожу тако пример что если например есть девчонки вре И хотите им запретить пользоваться Ден сайтами там знакомство днём то в принципе вотже это может сделать во-первых он знает Такие девчонки из Чара из лпа там по группе А во-вторых он знаешь что такой дейтинг сайта там tinder там не знаю ма ну я давно темо не интересовался не знаю какие там есть вроде tinder ушёл Ну в общем вот короче вот такие вот истории он может делать но параллельно с этим есть ещё секюрити фичи не буду подробно рассматривать главное что он ловит атаки так будем называть и всякие айтиш нае то есть роутинг VPN консы какие-то такие вещи делаю то есть не просто там Firewall но ещё Firewall с функциями Security с функциями там если говорить про технические задачи которые за ним стоят вот совершенно на пальцах чтобы глубоко не вдаваться в детали потому что дальше для рассказа это важно с одной стоны есть две сети которые здесь нарисованы он стоит Посередине между ними неважно пока какие сети дальше там рассмотрим Какие вариант вот он сессию на себя принимает он её Термини ет инициирует новую и соответственно если Сесиль нужно инспекцию сделать то соответственно инициирует ю поэтому он может классифицировать протоколы разобраться в них поискать атаки Ну и как бы запретить или разрешить доступ Где применяется вообще четыре сценария И вообще я как бы очень в душе стартапера люблю делать продукты по частям Сначала сделать ему шку потом добавить потом добавить потом добавить у снф так вообще не работает потому что вот условно есть четыре сценария и если не сделать какой-нибудь один из них то в Российский энтерпрайз идти бесполезно потому что условно российский бизнес он устроен Так что филиальная структура там покупали всё подряд в конце концов какой-нибудь там Грес купили и там АТП стоит и если там нету у фа Wall возможности стоять на этом трафике то Ну в общем-то нечего ловить потому что система управления она как бы единая никто не будет ради одной инсталляции покупать другого вентера поэтому вот эти все четыре сценария важны что тут нужно понимать то что периметр - Это самый тяжёлый с точки зрения нагрузки трафик потому что там нужно ssl детерминировать и так далее но интернета слава Богу не так много у всех То есть в принципе 10 Гигабит - это потолок того что я видел даже я скорее видел максимум 7 Гигабит вот у одного крупной российской компании вот а ядро сети дата центра и так далее там трафика больше но защиты меньше обычно включают и апш история она супер маленький трафик ну супер древние протоколы то есть там Бывают канальные там не знаю которые я такие только в книжках про сетевые технологии за шестидесятые годы видел но это всё нужно поддерживать иначе ну нечего ловить Вот соответственно как я и рассказывал есть две крайности едро Linux и ускорение на железе То есть можно вообще железку новую сделать которая только трафик обрабатывает можно взять классический Linux и там очень много реализовано и допили только то что не хватает а но как известно у Linux ядра есть подводные камни вот я по ним пробегу подробно не буду сейчас каждый из них зачитывать главное что следует из этого это то что две вещи невозможно сделать Точнее ну как бы невозможно всё возможно наверное в этой жизни но невозможно сделать High AV ability - Это скорее Про что Про то что вот F Firewall - это та штука которая отвечает за интернет если он не работает Не работает интернет то есть это вот не похоже на другие средства там защиты или безопасности очень важно чтобы оно работало Там пять девяток и не дай Бог там что-то когда-то ляжет поэтому их обычно ставят две и самый показательный сценарий как это проверить это вот там С разбега выдернуть провод у одной и по идее коннекшн основные не должны пропасть то есть понятно что какие-то сессии может быть даже и порвутся но приложение переустановит соединение пользователь этого не заметит но большинство сессий должны на другой коробке а подхватить и вот для этого нужно с одной коробки на другую реплицировать состояние а оно в ядре и я не видел ни одной имплементации того чтобы сделали Linux kernel две коробки и как-то состояние сетей силя то есть всё все вот эти реализации они обычно не на Linux ядре я такого не видел это сложно То есть просто потому что нужно всю ядерную структуру заревать на соседнюю коробку Ну и медленно и вот почему медленно Вот как раз пять пунктов мы по ним сейчас пробежимся а Да это то ограничение которое в принципе Гугли Ну эмпирическим путём его тоже можно выяснить первая история IP Flow Table То есть в принципе есть таблица потоков Каждый раз когда прилетает новый пакетик есть два варианта сессия уже была и тогда ну просто нужно продолжить её обрабатывать либо сесси ещё не было для того чтобы поискать считается вот такой ключ как там написано нул классика да то есть это сумма айпишник портов остаток отделения на размер Ну мапы и по сути мы получаем какую-то секцию Ну понятно что могут быть коллизии и так далее но не суть суть такая что хш мап это Обычно она во всех там системах одинаково устроены плюс-минус никакой там магии нету но при этом поскольку в ядре текст обработки зависит от того Какое приложение позвал системный вызов мы не знаем С какого треда будет аксс в какой момент а таблица она как бы общая и получается что она защищена блокировкой я не нагулино но я видел на прошлом хайлоу парень делал доклад когда он замерял с увеличением количества ядер количество приложений Как растёт пуд условно да и у него были такие результаты что начиная четвёртого ядра уже ничего не добавляется потому что эта блокировка она сжирает всю производительность это как раз следствие того что мы не контролируем то на каком ядре на самом деле вызывается Ну вызывается аксс вот к этой таблице вот TP IP декодинг Ну и сот API то есть в целом как бы операционка сделана таким образом что вот эта вот последовательность обработки пакетов Она вся приводит копированием то есть сначала на уровне IP пакеты могут фрагментированное точке они собираются все вот и соответственно когда эту штуку ловит линуксом что ну нужно скопировать собрать только потом передать та же самая история с туннелирования при этом тунели Ну хорошо вот гтп - это там условно мобильные сети там это редкий кейсы только там мобилка встречается а вот Виланы псы ipnp Ну то есть много где есть в лисовом ядре там везде копирование дальше опять сборка tcp вот как справка Да там иллюстрация то есть условно когда собираешь tcp поток пакеты могут пере ться могут прилететь с пропусками могут наложи это все истории прямо постоянно встречаются в ином ядре сделано так что просто пишется новый поток байтов в новый буфер Вот и соответственно с точки зрения API сокетов когда мы зовём какой-нибудь вызов типа Рид вот на самом деле мы говорим о том что мы готовы прочитать ядро Нам его копят и потом отдаёт и говорит сколько байта оттуда можно забрать то есть по сути ещё одно копирование То есть я не готов гарантировать что х там будет четы Но 2-т точно будет в зависимости от того В какой последовательности пакеты прилетели это тяжело вот переключение контекстов это прямо отдельная история потому что ядро в керна все структуры в керна сборка идёт в керна приложение в юзер спейсе вот когда мы условно зовём какой-нибудь вызов типа Рида или там райта в этот момент приходит переключение контекста в линуксе это достаточно тяжёлая операция там вот эти все языки типа Гош Там они конечно же создают легковесные потоки контекст у них лёгкий А в линуксе это там все регистры это часть состояния стека это куча всего то есть переключение контекстов оно не бесплатное Каждый раз когда мы что-то читаем мы переходим прыгаем из режима в режим это прям тяжёлое операция вот при этом я видел тоже доклады на лоде на прошлом и позапрошлом когда брали и переносили само приложение в ядро типа ну чтобы контекст не переключать с одной стороны это доказывает тот факт что это важно и сказывает ну на перформанс влияет а с другой стороны эти ребята потом на вопрос А типа что вы делаете с ошибками они говорят Ну ничего у нас же две коробки там ну од там Кер паник мы тли как бы ну и поднялась вот ну то есть в целом как бы так тоже можно но отлаживать это ад но как бы если кто-то пошёл этим путём то как бы безумству Храбрых там и вот это всё по тексту вот переключение нь текстов Да любой слип любой переключение операционной системы любое прерывание приводит к тому что на какое-то время Ну в линуксе там 10 миллисекунд по-моему не утик вот забирается управление от потока который действительно читает пакеты в сетевой карточке буфер маленький там 64 Кб в современных картах плюс-минус за то время 10 миллисекунд пока управление было не у того ядра которое читает пакет они гарантированно теряются это можно математически посчитать то есть любое переключение контекста всё до свидания Вот в линуксе нету возможности это проконтролировать мы можем убрать прерывание Да действительно с ядра это возможно можно прибить его гвоздями к ядру вот и не звать слипа Ну то есть это собственно я уже решение рассказываю но вот если этого всего не сделать и любой Рид позвать то в этот момент то есть вот вызов любого системного вызова он приводит к переключению контекста операционка вольна на это ядро зажили что угодно вот это прямо сказывается и с этим надо бороться вот а вторая крайность про которую можно тоже Поговорить то есть вот как бы как история развивалась А где-то в двенадцатом году компания пальта назвала класс продуктов своих НФ и она как раз-таки пыталась решить софтвер проблемы Но ВМ году x86 не был так хорош как сегодня и по большому счёту они взяли и выделили ряд задач которые а они хотят решить в железе и по большому счёту вот те четыре задачи которые здесь описаны роутинг TS decryption CP декодинг и регулярки вот они научились делать со скоростью Wi Rate То есть это значит что вот входной поток идёт сигнал с с какой-то скоростью и с этой скоростью Он успевает обрабатываться это очень круто очень долго и очень дорого то есть по большому счёту время на разработку железа - это Ну то есть это цикл очень длинный дело вы там не знаю СД чуть-чуть поменяли ш деплой апдейт и всё поехало железом Как бы не так то есть там нужно изготовить протестировать проверить это прямо растягивается а то что дорого Ну разработка Понятно дорогая А с другой стороны ещё нужно карточки эти ставить в каждую железку и одно дело паль которую тираж на весь мир или там foret а другое дело как бы ну компания которая там ориентируется на несколько рынков и понятно что экономика там сильно не сойдётся Но это всё пока лирика то есть по большому счёту вот есть четыре задачи которые на железо уко Для чего делается например роутинг железе это прямо интересный вопрос потому что он актуальный То есть он актуальный на самом деле я даже пример приведу когда он до сих пор стреляет у большинства вендоров которые не занимаются тем что его пытаются решить на ЦП вот в таких хардвар решений попадают только начало сессии то есть Вот сины первые пакетики и так далее для того чтобы сессию классифицировать после того как принято по ней решение после этого в таблицу на железке записывается решение и уже на на сервер никакие данные не передаются То есть это замыкается в карточке пока не случился Фин CP сесии либо там тайм-аут какой-то и так далее Это дико круто потому что очень большой кусок трафика просто срезается То есть он просто не идёт на цпу не знаю там падение объёма трафика там кратное понятно что таблицы одинаковые по объёму что на цпу что На железке потому что ну начало сессии раз там сохранили а здесь уже есть решение Ну то есть они идентичные Вот Но в железке если мы делаем там на плисе там на FP да или там ну потом в результате на асики Эта таблица может быть размеров таких которых нужна вот и это достаточно крутая оптимизация для чего это вообще нужно вот есть конкретный Корнер кейс который часто бахает до сих пор то есть вот есть намер цот да и в нём происходит какой-то бэкап п какой-то инфраструктуры большой и за ночь он должен осуществиться И вот он гонится просто без НФ напрямую и он работает со скоростью ширины канала вот есть один порт второй Вот они там как-то Смурова и всё то есть там терабит Гигабит а поставили фв дальше там софтвер фв забаланс это на одно ядро и на одном ядре оно работает со скоростью обработки одного ядра То есть это там не знаю там Гигабит или два там сколько ядро может вывести и получается что эта сессия между там вместо нескольких часов бе Капица сутки и как бы не успевать бе капить до следующей ночь мы прямо много раз это видели Вот теперь другая история называется tls description вообще раньше в двенадцатом году а не было вот этой технологии Quick assist Technology да то есть это сопроцессор в ксеоне ваты в любом интеле который позволяет ускорить математику оес ную И вообще вот генерацию ключей самая тяжёлая операция в этой всей истории - это генерации ключей то есть пришло соединение мы его Термини надо инициировать новое для инициации нового соединения по слю нужно сгенерировать ключ вот там современный атом Аксион может генерировать 9900000 тире тыя ключей там в секунду на одно ядро это очень мало потому что сесси там инициируется сотни тысяч в секунду в хорошем нагруженной сети и вот если раньше эту генерацию сделать в плисе и даже мы ловили такую историю когда смотрели на западных венро и вот там например есть железка какая-то заранее подготовлена её же дорого менять и в какой-то релизе эта железка Вообще пустая то есть там вообще нет прошивки а потом Бах и там акселерации то есть они подумали и решили что Ну тогда сейчас вот это будем ускорять остальное уже там x86 смог Вот и соответственно если посмотреть на то как сейчас устроены акселераторы крипта то это обычно пиная карточка в которой надо тыка куча атомов потому что у атома точно такой же сопроцессор как у атом Девы ядерный которые 5 баксов стоят или сколько там 10 этих атомов много и там используется исключительно вот этот Quick assist то есть по сути он не делает быстрее но он увеличивает пуд то есть цпу там скидывает на эту карточку а объём генерации ключей оттуда Там они генер возвращаются обратно это можно делать заранее в принципе классный подход эти карточки продаются их можно купить втыкать просто они денег стоят Ну то есть в целом ничего плохого нету но факт в том что это уже в x86 есть как сопроцессор понятно что если хвать много Ну будет быстрее и лучше вот CP декодинг самая такая низко профитная тема потому что в целом вот я не знаю там в десятом двенадцатом году были такие карточки которым на вход подаётся сигнал а на выход чистый который уже собранных сессий Ну там они пронумерованы как-то там шники у них есть и там сняты все заголовки кроме последнего и идёт Вот Но по большому счёту то есть эта штука реализуется в FP её можно переложить на Асик но Профит от этого ну не колоссальный в том плане что сама по себе оптимизация ше даёт схожие эффекты особенно если протоколы парсить достаточно красиво и хорошо Ну то есть правильно реализовать алгоритмы Ну и как бы регулярки регулярки - это очень классный способ который делегирует на железо То есть это вот нгф в наверное какко человек на сколько там на 80% состоит из воды так нгф в там процентов на 80 состоит из регуляр вот ну не впрямую там цере регуляры а всякие паттерн матчинг там какие-то ну вот в общем формы по которым что-то нужно найти это используя в классификации протоколов это в поиске Атак антивирусный движок который на потоке работает не тот который на эндпоинт там начинает каким-то голосом орать коронавирус увидел а вот тот который по кусочкам файл принимает и у него там сигнатурки он тоже также Патер маним делает л фильтрация это сравнение урловский паттернов и вот эта задача она очень классно решается в железе потому что ну по сути железо такая большая-большая Матрица там действительно можно на вход направить много сигналов сделать вот эту вариативность и в плисе там ну как бы всё супер так можно делать оно действительно ускоряет на цпу тоже можно сделать быстро и в принципе тут вот немножко математики про то как это в Классике работает то есть вот условно Вот например выражение А упросить на знак б когда там Вопросительный знак Это неизвестный символ он там вот в таком автоматом можно представить да то есть по символу А в первое там по-любому в второе по б в третье И третье - это хорошее состояние то есть то в котором мы замачивая объясняет как эти автоматы объединить в один потом развернуть его обратно в детерминированный и получается что за длину входной последовательности То есть в принципе очень быстро мы можем зама любое количество регуляр но это математика а на практике получается что как только там регуляр больше 20 и сами по себе регулярки длинные и сложные компиляция очень долгая памяти жр много и так далее То есть в целом на x86 тоже есть подход как это сделать быстро но есть нюансы вот а в железе прям нативно классно делается Вот мы постарались пройти по тонкому лезвию и совместить эти две истории есть с одного оптимизации железа которые нам доступны сегодня в коммодити железе Ну вот мы их прямо использовали как могли то есть софт железа наш продукт А если говорить про архитектуру это наверное там основной слайд Вот про который собственно надо было говорить с самого начала всё это была Прелюдия вот сетевая Карточка commodity какая-то у неё есть буфер буфер в который складываются пакетики они там летят со скоростью ну то есть условно там 64кб там буфер стандартный карточка иловая носовская но та которая комоде это не какая-то супер Промышленная не супер дорогая без всяких там жев Ну вот та которую можно купить в магазине которых много и как-то шутил один бывший заместитель министра связи говорил Кто придумал сервера из Казахстана возить возите из Индии их там миллиард Никто там их не найдёт Зачем из Казахстана там их мало Вот так и с этими карточками то есть в целом во всём мире их полно Вот они классические у сетевой карточки есть классная фича называется то есть э фи позволяет балансировать трафик между раз ите в зависимости от вот этого tle фильтра я про него рассказывал то есть это сумма I пор IP пор L4 протокол Вот то есть это как бы если трафик не тяжёлый а тяжёлым я называю трафик который с туннелями она может баланси между обработчика сама если трафик тяжёлый Приходится вводить новый слой называем балансировщика софтвер то есть у нас там на коробке крутится процесс который принимает пакеты заглядывает заголовки и сам баланси между обработчика естественно сами пакеты нужно куда-то сохранить и они сохраняются Ну вот грубо говоря мы используем dpdk классический фреймворк для обработки пакетов Мне кажется все кто делают на железе ой на на этом на софт используются сейчас уже это dpdk у dpdk есть там пейсы они там по 2 МБ большие в них можно вот настроить дома так чтобы все эти пакетики из сетевой карточки летели то есть Они прилетают туда через дома то есть вообще там без участия грубо говоря центрального процессора попадают в балансировщик балансировщик раскидывает их между потоками чтения через очереди dpdk То есть у нас получается такая архитектура при которой балансировщик либо же сразу на прямая карточка через рсс раскидывает каждому из потоков таким образом то есть вот есть процесс в нём потоке таким образом как будто бы каждый из них а абсолютно друг про друга не знает за редким исключением то есть есть такие потоки которые связаны их мало они их немного То есть например там ctp там или fpc тпд когда в одной сессии говорится про другую это исключение Для чего э шина нужна но в принципе если вот про эти протоколы забыть они живут в парадигме как будто каждый про второй не знает у них свои таблицы свои обработки мы их прибивает к ядрам убираем их из операционной системы выводим из планировщика и прямо на 100% они полят пакеты Потому что если этого не сделать теряется прямо 100% да да мы в этот момент грустим живём ресурсы Вселенной Но что поделать Ну то есть вот вот вот только так оно действительно нормально работает вот а это собственно то как мы подступили к решениям тех проблем про которые я говорил мы взяли стек это это фришный ФБ сдш най клон который в в userspace клонированные по сути он работает по принципу что там сокеты API мы убрали сокеты засунули туда свои колбеки и решили сразу две проблемы То есть по большому счёту мы могли бы собрать пакет сами и в других проектах мы так делали но нам нужно ещё инициировать соединение и мы не можем как бы мы всегда вносим изменения в в сам Pay да то есть Нам нужно не только принять сессию но и инициировать её для этого мы используем и такой ну и в этом случае в этом случае свой стек вот этот вот Клон стека мы его немножко запали немножко поменяли и в результате решили две проблемы То есть с одной стороны у нас нет переключение kernel Space и userspace это всё работает в userspace у нас вообще ничего нет в келе а с другой стороны нет этого лишнего копирования и в целом копирование там по минимуму Ну и вот этого копирования из сокетов нету вот балансировка нам решает проблему IP флока Flow Table лока потому что каждый из этих вот процессов потоков Да в процессе он получает нареза функци и по большому с ему нет зада и смысла синка и лочи что-то то есть у него вообще там лока нет каждый которая приходит она Ну записывается в таблицу Кстати тут нет это на слайде важный тоже момент потому что вот iow мы используем тоже он использует в свою очередь s42 и возможность векторного поиска по таблице там можно одной операции найти сразу 64х при расчёте на один пакет получается что примерно в два раза выиграешь то есть вот если в цикле 64 поискать Если одной операции 64 поискать Вот суммарное время за одну операцию в два раза Ну как бы быстрее это тоже классная оптимизация которая позволяет современный Н сделать а переключение задач как я уже говорил мы прибивает и мы убираем их с линга и на 100% полем у нас получается что ни одно из ядер не может быть вытеснены никем ну и соответственно это помогает нам решить эту проблему Да И роутинг вот это тоже интересный момент на самом деле во всех карточках Коди таблица это есть и просто ей мало кто пользуется она маленькая то есть там Ну например нормальное количество соединений в секунду которые в среднем энтерпрайз происходит вот новых сессий Да там может быть 500.000 например А размер таблицы 10.000 Вот то есть взять Один в один сделать эту таблицу не получится Это достаточно сложно но для самых жирных са сесси это сделать можно и поэтому мы что делаем у нас Эта таблица она вытесняющая то есть когда у нас на цпу уже заехала сессия которая идёт Достаточно долго мы какую-то выкидываем из этой таблицы засовываю туда вот это позволяет решить проблему Ту самую с Корнер кейсом про которую я рассказывал то есть какая-то одна очень долгая очень жирная сессия она точно окажется в этой таблице Ну и 999 9.999 других окажется там то есть по большому счёту даже Пользуясь классическими карточками эта проблема решаема Просто она не так красиво решаема как в железе зато мы не вынуждены делать свои карточки и вот это всё вот таблица меньшего размера Да и получается что вот если за мапить одно на другое То есть роутинг мы делаем таблицу которая в карточке уже есть TS description мы используем к асист у процессора который у нас уже есть tcp IP декодинг мы никак не акселем мы используем просто к но как бы прирост там реально незначительный мы его сравнивали а для регуляр мы используем Intel Gan когда вот я говорил про ту математику Что начинает там с ДТИ там регуляр уже начинает долго компиляция много памяти жрать и так далее вот эта библиотека Она эту проблему решает то есть на самом деле мы её там смотрели внутри она если видит что тяжёлый автомат получается она их делает несколько там будет чуть-чуть медленнее Зато они будут очень быстро меняться Ну генерироваться новый Ну и так далее То есть в принципе Эта библиотека она решает на x86 большинство проблем с поиском регуляры на лету то есть вот очень здорово работает используют всякие инструкции ссш нае и оптимизированы под Ил процессора вот если там пытаться как-то метафорично выразить что у нас получилось то вот если кто-то программировал девяностые то вот я помню эту открываешь книжку программирование VIN AP там да там нужно создать кисть там потом канву потом что-то там настроить потом ещё куда-то и вот эта абстракция на абстракции с абстракции это вот то как Linux ядро с точки зрения сети устроено Вот а если хочется прямо красиво то нужен Direct X вот Direct X - это то примерно как мы эту штуку и сделали то есть ну идея та же самая да то есть мы просто в эксклюзивное пользование забрали сеть и всё что нужно сделали самостоятельно Ну основываясь на тех примитива которые нашли про них я сегодня рассказывал вот это как бы цифры сейчас я объясню В чём суть теста то есть на самом деле мы взяли в сравнение две железки одна па другая for Gate А в принципе два топовых западных венде здесь две платформы маленькая и большая маленькая платформа вот в нашем случае это атом с четырьмя ядрами в их случае там разные процессоры в одном из них это какой-то а в другом это mips или что-то в этом роде Ну то есть я точно не помню И на самом деле они от версии к версии варьируются Но вот есть две платформы Одна маленькая а другая классическая серверная Ну там нак Сионе у них у нас вообще абсолютно одинаково Вот есть разные тесты три теста по сути да а к - это в классический трафик котором тестируют практически все железки вот есть Connection per Second то есть на установление новых соединений H однобайтовый соединений вообще сколько она может выдержать тут ну как бы мы видим по цифрам что где-то мы лучше где-то мы хуже так-то вот а Ну ещё важ важная Ремарка что можно целую лекцию прочитать про то как делать дата шиты это теперь маркетинг Эксперт я могу как бы написать такие цифры что будут рвать всех но здесь они честные вот а вот for Gate он там немножко хитрит То есть он когда фик он такой раз 64 КБ А здесь как бы не http а itcp а здесь Не это а то и и не в покера буру и не выиграл а проиграл Ну вот в общем Примерно вот так вот эти все даты делаются Но вот мы постарались сравнить цифры Похожие и видно что где-то нам есть что ещё подтянуть но мы этим занимаемся год и у нас ещё там серия оптимизации намечены и мы эти цифры точно вытянем Но что важно И пала и for Gate сделаны в железе То есть это прям хардвар солюшен со своими специализированными картами со всем сложной логистикой и так далее У нас чисто софтверная история с Коди железом И это прям ну наш основной как бы наверное Профит Я не знаю как его назвать вот а Я попытался уложиться в короткое время ещё не заканчиваю Да но есть у нас вот три серии на юбе каждый из них там по час с лишним и примерно Вот про технику как это устроено под капотом прямо совсем-совсем в деталях там есть И можно их посмотреть То есть мы с одно первую сессию рассказывали как вообще в целом Ну пакетики обрабатываются Примерно вот то что сейчас отдельно как это тестировать потому что это тоже там Задачка со звёздочка и система управления там скорее про распределённые базы данных про то как сделать отказоустойчивость и так далее вот общем ели интересно Посмотрите Вот это собственно мой Контакт для связи Если вдруг кто-то программирует на c+ Plus и думает Вдруг ему там сменить работу на какую-то более интересную Вот это прямо вот это Можете писать я только счастлив буду вот Ну и как бы голосование за мой доклад вот эта вот ссылочка я закончил Спасибо вам большое Денис большое тебе спасибо за замечательный доклад маленький президент от организатора компании онтика и от нашего подарочного спонсора Газпрома и у нас первый вопрос Здравствуйте чтобы нас было видно Вопрос такой вы использовали ли в проработке линуксе только на x86 может быть Ну в сторону Арма тоже стоит хотя бы посмотреть Окей тогда два разных вопроса прямо по отдельности отвечу первая История сфом ebpf - это ну в общем неплохо и нехорошо просто они мне кажется Вполне себе конкурентные ebpf и dpdk То есть можно так а можно так мы выбрали dpdk потому что он нам привычнее и мы его больше использовали наверное на bpf можно было бы получить сравнимые цифры надо Просто попробовать вот ну то есть мы как бы на маленьких тест посмотрели сравнимые нам ближе и понятнее понятнее мы взяли его а касательно Арма мы какое-то время на него всерьёз смотрели особенно в тот момент когда А ну вот пошли вот проблемы с поставкой меловых серверов и так далее но но Ар тоже он же ведь лицензируется на каждую как бы на каждое ядро его достаточно сложно покупать Мы сейчас больше на риск пятый смотрим и на то чтобы его научиться использовать для этих задач он конечно ну по икш сету по предикшн по всему тому что он даёт с точки зрения оптимизации слабее Но если уж нам на что-то и переходить то наверное на него а не нам вот в целом Мы в исследованиях используем работаем с ва для того чтобы потыкать посмотреть потестить сейчас пока цифры сильно печальнее Вот но наверное когда на будущее тоже ждт Поэтому готовимся спасибо спасибо за вопрос детальный ответ и у нас следующий вопрос а у меня следующий вопрос Денис Спасибо большое за доклад Я здесь у меня такой вопрос Вы есть ИТ компиляция например в популярной библиотеке pcre вот смотрели вы на такой вариант использования регулярных выражений А да конечно И при этом вот когда я говорил про Intel gcan он их тоже компилирует просто вопрос времени компиляции и того сколько футпринт в памяти Потому что если засунуть те регулярки которые реально используются в фв по C скорее всего при компиляции ещё помрёт а потом ещё и в памяти выжит столько что ну то есть там количест ну чтобы понимали Да там приложений должно поддерживаться Ну не менее 3.000 плюс ещё улов там 150 Ну короче там количество регу который нужно проверять на потоке параллельно очень большое поц этих нагрузк не выдерживает вот Intel что он делает он их не компит как один автомат он их пытается так разделить на несколько чтобы каждый из них в параллель Ну давал не больше чем по объёму и это даёт возможность ещё и не помереть по памяти то есть очевидно это делать надо это делать умеет но когда большой объём не вывозит А вот гипер помогает понял спасибо и на следующий вопрос а Здравствуйте скажите пожалуйста вот вы сказали что вы используете стек FreeBSD а Пейс Вот Но есть но чем он чем обусловлен выбор Дело в том что есть всякие другие же технологии Open onload всякие offload там и прочее разные Почему именно этот вы выбрали и как бы ну вот с одом с технологией Ну то есть по сути насколько я помню я просто не супере Эксперт именно в Open Аде насколько я помню Там просто через dma был mapping userspace обработка как раз CP пакетов на карточке и получение чистого уже там в приложении эта технология была конкретно вендер сетевых карточек на которые мы затачивать не хотели и был была софтверная имплементация того же самого можно было взять на любой карточке и получить такой же результат но нам ещё нужно было при этом и генерировать соединение то есть Нам нужно две части и принять и отдать Вот и как будто бы вот вторую часть она делать не умела Может я сейчас конечно ошибаюсь Но вот когда мы смотрели вот именно инициацию соединения она делать не могла а нам нуже было и то и то поэтому мы взяли мы выбирали между стеми которые спортива в мы смотрели их несколько и получился лучше по производительности мы просто пользуемся сами Open Open вернее Ну у нас этот мы использовал карточки соответственно там всё это да там это всё делается Вот Но так как вы сказали что вы используете Milan а там эта технология называется Off наоборот и там тоже это всё тоже есть И там тоже приводит к тому что мы на не затачиваем мы ещ используем и мы ещ используем BRC мы ещ используем кучу других карточек Поэтому стараемся Ну вот именно технологию вот эту прямо к ней не пробиваться но интересная мысль надо будет посмотреть Спасибо ну это интересная тема для дискуссионной зоны и у нас следующий вопрос Спасибо Очень интересный доклад Спасибо два вопроса Первый Прошу прощения может быть все знают Я нет dma - это разве userspace или речь идёт о том чтобы скинуть именно потоковый трафик в userspace но часть вызовов в ядро остаётся нет он работает как его можно настроить и сказать вот из этого адресного пространства ты сам копируй мне вот в это адресное пространство Ну то есть мы именно в ядро прокиды вызов именно конфигурационный получается а потом уже веон один раз в самом начале А потом они просто как труба льются Да всё отлично Понятно второй вопрос получается мы оставили только два копирования нам в любом случае нужно расшифровать зашифровать и главное что мы Pay не копируем когда идёт наша внутренняя обработка об этой оптимизации речь идёт именно об этой при этом там всё равно есть кейс когда скопирую всё равно надо Вот Но их уже остаётся сильно мало а в Linux carn они практически всегда копируются без особой там выбора Понятно спасибо спасибо за ответы у нас следующий вопрос А здравствуйте Я хотел уточнить о том что конкретно представляет ваш конечный вот этот софтвер най продукт То есть это запа ядро Linux я правильно понимаю а не совсем то есть тут нужно немножко лирическое оцепление сделать У нас есть регулятор называемый в стеком который принял решение что фв - это программный апарат комплекс То есть это железка плюс софт Вот потому что нужно это всё делать на железе которая православная там вот мы с ним всё вот при этом мы делаем чисто софт то есть мы делаем чисто софт это по сути инсталлятор который может заката на Linux его перенастроить и в принципе работать на любом линуксе Да вот но варианта поставки два это либо железка при том У нас их две то есть маленькая такая коробочка которая на столе убирается с двумя двухядерный или четырёхъядерный атомом либо большой серк Вот и там и там закатан наш одинаковый софт который можем ещё заказать на виртуалку там отдать инсталлятор который можно установить на сервер и так далее это просто такой процесс в котором много потоков каждый из которых за что-то отвечает вот там их много симметричных про которые я говорил и балансировщик Если нужен Ну и там какие-то сервисные Ну и второй вопрос на который вы частично уже ответили это про доступность этого продукта То есть мне кажется он мог быть интересен не только в фоер волах но и например банкам для HT на замену тех же самых ров Вот и вопрос не продаёте ли вы это как программный продукт или может быть опенсорс Ну про Open Source Мы думали но пока до этого не дошли у нас просто ну как бы вот чтобы вы все понимали Я понимаю что мало кто в теме информационной безопасности но чтобы вы понимали момент когда 24 февраля случилось в России было там три вендора которые делали на Generation Firewall сейчас их 26 притом они появились буквально там за 3 недели потому что все посчитали количество денег поняли что это офигенно выгодно вот следующий шаг был такой мы короче берём сурикат рисуем свой UI у нас продукт несём его там ну грубо говоря сертифицировать онда не работает но это второй как бы момент вот поэтому Ну что сделали мы Да мы решили что мы как так не хотим мы хотим сделать классный фундамент рюшечки потом ну и при этом Если сравнивать западных винде они по фич сету не отличаются Там вся разница вот по фундаменту Да вот мы в это вложились а история с он Сорсо история с тем чтобы сделать его доступным скачем по сайту мы прямо очень хотим но очень хотим хотя бы до первого добежать момента потому что тех ребят есть что потрогать А мы такие классные Мы в лаборатории там производительность показываем всем там ну и притом как бы доказываем да Ну так вот чтобы завершить законченный продукт мы пока ещё этого не доделали мы год этим занимаемся у нас там следующий там какой-то рубеж в марте будет когда мы его начнём массово отдавать мы его только у себя поставили и всё вот как бы то есть сейчас Это середина разработки Денис ждём Вас через год на Open треки и в зале не Индия обязательно и у нас последний короткий вопрос Денис Спасибо за доклад Сергей компания ядро а у меня вопрос больше про технологии вот у вас там пу affinity rq balancing все дела Я так понимаю что вы там одно пару ядер оставили под Linux но под остальные всякие процессы там SS вот это вот всё чтобы на систему можно было зайти вы не сталкивались с такой штукой что когда в линуксе какой-нибудь pf случается Linux начинает с помощью протокола когерентности кэше тормозить все доступы к шине не пробовали ли например там на гипервизор отдельно ваши dpdk закинуть типа того да у нас были всякие разные такие эксперименты при этом Ну вот у одна из самых распространённых проблем когда её под потолок загрузить трафиком после этого на неё не зайдёшь потому что ну даже учитывая то что ты развёл это по affinity там ces используешь всё вот это там всё сделал красиво но всё равно эта проблема есть и Да у нас есть эксперименты с гипервизоров так чтобы вообще убрать операционную систему из этого всего оборота Вот но как бы кажется что ну условно Мы же как бы немножко контролируем процесс внедрения мы понимаем какой там трафик мы можем немножечко там подстраховаться на первом этапе Но следующий этап точно в ту сторону Да ну просто я вас там 10 миллисекунд видел на слайдах и это тяжело да Да да я знаю мы стараемся А спасибо за замечательные вопросы за подробные ответы кто не успел задать либо хочет пообщаться после доклада у нас открывается дискуссионная зона это слева от меня за дверью и те традиционный вопрос Выбери Два лучших вопроса один подарок от вас один от нас Угу Ну я бы навер про Open Open один отдал Мне кажется это такая тема выйдите пожалуйста на сцену Спасибо выйдите к нам боятся и второй вопрос второй вопрос второй вопрос Сейчас бы Вспомни от компании подарок от компании Газпром Газпром Газпром Ну давайте про гипервизор выйдите пожалуйста на сцену чтобы в прямом эфире"
}