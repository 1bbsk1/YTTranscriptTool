{
  "video_id": "vx22ZvQ3iEQ",
  "channel": "HighLoadChannel",
  "title": "Контроль качества высоконагруженных систем / Андрей Дроздов (Avito)",
  "views": 2069,
  "duration": 2819,
  "published": "2017-12-11T01:37:05-08:00",
  "text": "всем привет хорошо меня слышно добрать хорошо меня зовут андрей дроздов я работаю в компании авито в отделе поиски поиска и сегодня мы поговорим про контроль над качеством скана грозных систем сразу расскажу что опыт аккумулированные за несколько лет из разных компаний и поэтому будет особенно интересно рассмотрим все множество багов которые могут случиться в нашем нашей программе их в общем случае может быть очень много когда мы пишем тесты и нагрузочные обычные функциональные и юнит-тесты как правило мы начинаем задуматься о какой баг вообще может произойти соответственно есть подмножество в списке наших богов проблем который мы можем себе представить когда мы пишем обычные тесты функциональные или нет мы покрываем это подмножество и разумеется это подмножество оно не такое большое и большой интерес представляет эти баги которые находятся вне его пределов на помощь приходит интеграционное и нагрузочное тестирование которое залезает и в то и в другое подмножество поэтому говорить был в основном именно нагрузочным интеграционном тестирование разумеется у кого-то в зале могут возникнуть вопрос мы видим как бы еще беленькие кусочки нашего множество как быть с остальными богами которые мы не можем себе представить есть еще альтернативный способ это фазирования этот метод покрывает вообще все возможное множество багов однако очень сложно и требует много времени и он не всегда используется тем не менее в информационной безопасности иногда в базах данных он тоже используется решает определенный ряд проблем но это тема для отдельного доклада поэтому его мы трогать не будем для чего мы проводим нагрузочное тестирование в первую очередь мы хотим получить некие ключевые показатели производительности и дать всей команде информацию для принятия решений подходит нам система не подходит вот bittorrent на требованием или не удовлетворяет и самое главное как я уже говорил проверить и найти те ошибки которые не попадают в то множество проблем которые мы можем себе представить это самое интересное поскольку неизвестно кто насколько глубоко копал тем накручено тестирование имеет смысл освежить в памяти те самые основные показатели производительности которые мы хотим измерить и поэтому быстро-быстро их освежим насчет самое понятное и простое это емкость и время отклика это самые такие ключевые показатели для примера представим что мы хотим покушать знаю вот я например очень хочу кушать и не завтракал и мы думаем куда нам пойти за круассанам мы можем пойти в локальный магазин можем пойти в какой-то более дальний до ближайшего магазина 15 минут лейтон си до дальнего полчаса мы думаем ну куда у нас ближе пойдем ближе приходим ближе представим что круассан готовится пять минут очередь шесть человек круассан получили через 45 минут если бы мы взяли на машине доехали мы до большого магазина to cas много тот набор нагрузки который обслуживает большой магазин выше мы получили бы консон через 35 минут то есть быстрее очень-то в этом весь вопрос про емкость и legacy да еще и не произнес самое важное что леденцы это транспорт и игреки уж он-то что значит время которой мы ехали до магазина и время приготовления круассана идем дальше стабильности доступность тоже очень важные показатели самый простой это само по себе отказоустойчивостью пришли мы в магазин звуку раз она вдруг коса сломалась может ли магазин в принципе выдержать такое если он сможет то как быстро продавец не знаю дойдет кассового аппарата начнет на листочке что-то записывать принимать заказы дальше очевидно по что поскольку мы записываем все на листочке в этом случае то у нас будет какая-то деградация в производительности это та же величина которая нас интересует и четвертое не менее важно если мы записываемся на бумажку не пропадут и данные после дня работают магазины в таком случае отдельный момент про availability то есть как долго мы постоянно обслуживать клиентов без потерь и соответственно обратно начиная как долго магазин не обслуживает клиентов эту табличку на холоде показывают довольно часто я тоже решил ее показать классический вариант допустим четыре девятки мы не работаем 50 2,56 минут в год и семь девяток мы не работаем три минуты 15 соток в год это вроде как разные показателями если вы например новостной сайт четыре девятки отлично на час год вы не поработали так суммарно ну и ладно а если вы например банк и у вас огромное количество транзакций нагрузка в тот 100 тысяч запросов в секунду то даже если у вас 7 9 выйди делать огромное количество усилий для того чтобы минимизировать проблемы то все равно 300 тысяч запросов вы зафейлите это очень важный показатель про него тоже нужно помнить и последние два понятия который мы должны вспомнить это масштабирование ограничений емкости соответственно если на нашем примере мы добавим еще одну кухню будут горизонтальное масштабирование если мы на старой кухни поставив более мощную плиту будет вертикальные и самое интересное то capacity blockers это такие ситуации в которых у нас случае какие-то завтраки but i'll make те самые баты лыки которые мы ищем про которые делаются огромное количество докладов и собственно этот доклад тоже про них как выглядит типовой тест очевидно что у нас есть наше приложение скорее всего стоит нас есть набор хранилищ данных приложений обозначена буквы а хранилище буква s и из некий генератор нагрузки большой буквы г который создает нагрузку после чего мы проводим тесты то раскладываем и собираем какие-то метрики анализировать результаты поднимите руки в зале те кто сейчас сделаю подобной нагрузочный тест если такие есть это уже отлично я думаю что вот те кто руки поднялись она согласятся иногда этого недостаточно потому что когда мы выкатываемся в продакшен мы сталкиваемся с такими ситуациями что завтраки возникают на стыках систем то есть сам все сервис может хорошо работает а где-то между сервисами возникают проблемы которые были учтены непродуманные так далее что мы должны искать если мы делаем нагрузочный тест ну вот здесь пример скрина индекс танка мы увеличиваем нагрузку и в какой-то момент в этом си очень сильно деградирует вот такой горб это идеальный нагрузочный тест пусть мы просто взяли и свалили наших систем что еще мы можем искать мы можем искать вот такое дрожание graphic arts не всегда это будет такой город как был на предыдущем слайде тем не менее если мы видим что все шло ровненько вот есть у нас такая ступенчатая нарастание нагрузки и вдруг что-то задрожала скорее всего на графике latency мы тоже увидим небольшие горбыли спайки или что-то еще это значит система начинает не справляться целом все очень просто но на практике все сложнее и последнего просто как искать обычно как происходит нас есть куда разработчик петя которому 1 неделю говорят ну вот тебе билд в общем проверь он все это раскладывает запускает нагрузочную утилиту и понеслась после этого принимается решение там прошел на говорю что это стали нет однако в реальности люди забывают что совсем идеально иметь такой же workflow как и с обычной разработкой есть если мы например пишем код написали код патент запустили тесты проверили все ли хорошо точно так же должно быть и с накрученным тестирование на очень маленьких наборов данных очень мало может быть даже малыми нагрузками но достаточными для проверки определенных багов можно делать фа стран быстро запущу запустились к фиделю систему поняли что происходит может какие-то ошибки есть команд есть это тот же самый случай с обычным нагрузочным тестированием отдельный случай есть ошибки который проявляется только на больших интервалов времени утечки памяти все всякое подобное если в вашей системе есть там горячее-холодное хранилища данных из одного в другой прикладываются нам нужно запускать план же ветеран то есть тест на примерно две недели в котором мы проверяем как именно поведется системы на длительном интервале времени совсем идеально если мы собираемся писать и поднимайте систему контроля качества в компании нам нужна возможность сравнивать по веткам допустим я пишу какую-то свою разработчику ветку я сделал новую фичу менеджером не только что ее принес я ее очень спешил сделать если иметь возможность сравнить с мастером и быстро увидеть что она деградировал какой-то набор функций если пишем базу данных там select и просели если пишем какой-нибудь сервис там не знаю хендлер какого-то конкретного запроса просел это тоже хорошо и естественно контроль качества появляется тогда когда мы можем проверять это пока нет на возможно хотя был мастер или в каких-то особо сложных случаях прям на все ветки в этом случае мы можем вести диалог с менеджерами архитекторами показывать просто зависимость производительности от времени от коми то это тоже важно далее я расскажу некоторое количество историй которые случились со мной в моей жизни связанных с нагруженным тестированием и я постарался собрать из этого некий чек-лист о чем нельзя забывать когда мы делаем нагрузочное тестирование вот собственно первый случай самый простой не получается выдать нагрузка у нас их нет действитель это типа там яndex танк и мы разложили на тестовом стенде наши пола начинаем стрелять вместо тридцати тысяч запрос в секунду видим 10 предполагаем сервис тормозит наверное что-то у нас не так начинаем копать вот у нас такая типовой случай допустим есть несколько хранилища одно приложение и нагрудный генератор начинаем смотреть на первую точку думаем наверное что-то в модуле связанном с базой данных не так там с клиентом шарден гам еще с чем-то строим профиль и смотрим как то при поиске кто простых утилит там типа пасты к что происходит вроде никаких проблем на самом деле выяснилось что конкретно в этом случае у нас была слабая сетевая карта и она просто в полку стояла не выдерживала того трафика который приходил это какая уже горел самый простой случай тем не менее начинать всегда надо железо нужно посмотреть что тот тестовый стенд на котором мы работаем в принципе может справиться с нагрузкой которую мы хотим через него гонять раз уж я заговорил про разные утилиты их есть очень много для анализа тем не менее мы можем разделить их на 3 группы вот проще всего оценивать визуально например мы запустили нагрузочный тест зашли на стенд и запустили не знаю хотя бы h top и как минимум мы можем посмотреть разницу между system time i use our time допустим юзер time будет зеленый в топ system time будет красный если у нас состоит в сотку мало красного много зеленого явно какие-то проблемы в коде или garbage collector или еще что то то есть это скорее всего проблема в том что мы написали если все красное есть много system time скорее всего много и сколов или чего то подобного мы как минимум какую-то часть проблем как когда мы начинаем анализ сразу можем отсечь второй случай по-быстрому если мы например понимаем что у нас все зеленое это изо рта им неплохо было понять что происходит вот утилиты типа пас так позволяет просто быстро заглянуть под капотом сейчас происходит вот ошибки с горбач коллектором так очень легко найти ну и естественно если вот по-быстрому что-то не помогло разобраться мы можем построить профиль и такие telit как вопроса этому помогают в итоге про первые случаи мы начали смотреть с уровня железа для того чтобы проверять нас с вообще корректно проходит в данном случае требовалось сделать тюнинг буферов ядра сетевых и собрать бунта сетевых карт то что карточка была слабая пришли к администраторам поговорили настроили все получилось типичная похожая ситуация если мы используем сценарной утилиты там где должны использовать хит bass о том чем отличается сонарное ответ быстрее чуть позже расскажу значит вывод мы не продумали ограничение инфраструктуры или модель нагрузки теперь мы попробуем записывать наш чек-лист выводы из каждого конкретного случая добавили модель нагрузки добавили инфраструктура и железо что такое модель нагрузки она бывает открытая и закрытая закрытая модель нагрузка это простую случаю представим что мы пишем сайт с объявлениями но как авито например и у нас есть какая-то админка очевидно что у неё тоже к из какой-то свой latency есть какой-то набор администраторов который добавляет туда это данные тем не менее если вдруг у нас поднялась light нас и но администратора могут в общем-то и подождать поэтому в закрытые модели нагрузки по сути дела у нас сама нагрузка зависит от like a открытая нагрузка и самое интересное то тот самый халат где сама нагрузка никак не зависит от lights если мы выложили объявление не знаю там какая-нибудь звезда продает свою вещь и пол стороны ринулась на него смотреть если вдруг у нас возрастает light если людям в общем-то все равно нагрузку все равно будет идти на это достаточно очевидный такой момент так вот сценарные утилиты подходят для закрытой нагрузки больше ahead без для открытой и поэтому устном будем говорить именно о них второй пример тоже очень простой грустный теста не выявляет проблему то есть мы все собрали делаем тест но при этом в продакшене нас есть градация тоже типовая проблема у всех случается думаем наверное мы тестируем не все может быть нам добавить там еще какой-то базу данных или увеличить объем данных возможно но в данном случае достаточно для начала просто взять и посмотреть на то как мы тестируем какие вообще данные гоняются во время нагрузочного теста вот такой типа например представишь у нас есть сервисом и в пользу запросе шлемом у некий джейсон где стены фамилии параметры и люди когда составляет нагрузки тест иногда думают ну ладно оставим там по дефолту пусть будет но если мы посмотрим на продакшен увидим что на самом деле здесь может быть там десятки килобайт этих самых параметров условно говоря и даже носи реализацию этого джейсону уходит какое-то количество времени наши тесты просто показывают погоду на марсе это очень плохо поэтому какой как бы вывод мы должны всегда приводить тестовые данные к боевым насколько это возможно в идеале просто тестировать на боевых вывод данном случае мы не подумали не продумали профили данных и раз уж мы заговорили о данных есть еще один такой важный момент представим что мы не просто пишем сервиса скажем мы банк и мы проводим нагрузочный тест после этого решаем выкатывает нашу новую версию банковская система или нет очевидно что если мы отвечаем за транзакции то просто после нагрузочного теста как-то стрёмно принимать решение готовы накруток что нет поэтому проводить на грустный пес без проверки корректности данных не очень логично поэтому любой научный тест хорошо обувь чтобы после него мы могли каким-то образом проверить данный самый простой случай с банковской системой мы раскладываем какое-то количество сортов приложений загружаем в них условной данные щитами вот как мы видим на картинках то есть есть кучу пользователь у каждого из них есть свой баланс после чего запускаем транзакции и после проведения нагрузочного теста мы просто берем и выгружаем все эти данные к себе смешиваем их с разных узлов получаем одно большое один большой файлик в котором написано все баланса и берем некие талон и сравниваем если данные все сошли значит я спрашивал корректно в чем проблемы что составить этот эталон может быть очень сложно потому что во первых если мы берём данные с продакшена никто не гарантирует что у нас нету баги в продакшене или если делать это руками достаточно сложно при этом иногда может просто невозможно все выгрузить поэтому мы рассмотрим второй пример представим что вы пишете аукцион что например авито решила добавить себе не только возможность продавать кит вещи но и делать аукцион у нас такой аукцион популярный и проходит один миллион аукционов в каждом аукционе еще один миллион участников очень высоко нагруженная система и в итоге каждый делает ставку и нагрузка такая что мы не должны по сути лишний раз человеку дать сделал ставку если кто-то раньше его его сделалось должна быть введена оптимистическая оптимистичная традиционно семантика в этом случае человек который пришел раньше получат 2 сотку и сделать ставку тот чьи данные уже не актуальны получит 409 conflict и соответственно все будет хорошо как тестировать такую систему допустим у нас очень много сортов и мы не можем все выгрузить в этом случае мы можем просто посчитать сумму всех ставок на сторонах запустить некую храним q на самих шар doch а поскольку у нас есть нагрузка утилита и она может вести лог то мы можем посчитать количество в 200-х 409 их ответов если сумма на 100 раджаф будет равна сумме положительных ответов то достигается корректным то же самое про банковский тест мы можем не выгружать все данные если мы знаем что адресаты транзакция играется корректно то нам достаточно посмотреть что общая сумма в банке не меняется напрягать загрузили мы там миллион рублей транзакции побегали у нас не прибавилось не убавилось денег значит у хорошо таким образом мы в наш чек-лист сразу добавляем данные то есть это профиль данных он должен быть приведён к боевым должны быть требования консистентной sti и проверки корректности самого теста и травник избыточности то есть если у вас есть фактор избыточности больше одного нужно проверять что каждая запись который вас интересует хранится не только на одном условно жерди так же оговоримся что есть понятие допустим и деградации вот так выглядит типичный тесты допустим все хорошо latency маленькой но мы видим какие то два больших спайк один в начале один середине мы все знаем что есть авторизация каши и все такое поэтому мы просто должны так говорить и считать это нормально в некоторых случаях просто запись теста начинается чуть позже чтобы это учесть некоторые любят оставлять предположим там второй пик это бизнес topshop мэра в полчаса откладываем вот тем не менее это тоже надо запомнить и записать наш чек-лист соответственно допустимая деградация дальше более сложные случаи значит у нас есть более сложная система с горячим и холодным хранилищем и во время теста мы видим хорошие показатели все продумано у нас в тест не синтетический тем не менее в продакшен через несколько дней тереться данные мы думаем что подозреваем что это какие-то настройки киселев харон холодном хранилище возможно данная ту дупло и слишком рано хотя вроде такого нет начинают смотреть сначала мы исследуем приложения думаем что что-то не так с настройками sharding а потом думаем что что то не так short функций и дальше начинаем рассказ идет цепочку и видим что на самом деле какой-то администратор странным образом настроил холодное хранилище sharding настроена неправильно сесть на проблема была в самом низу какой анализ и вывод можно сделать значит мы ты злился допустим 30 минут а проблемы начинается там через день или позже и соответственно мы в продакшена шею ситуацию раскопали очень пришли к выводу что отдел план же ветеран тот о котором я говорил до этого если бы у нас какие-то 100 гонялись мы бы нашли эту ошибку намного раньше и не поймали бы ее в продакшене разумеется это такой пример спорный кто-то мог бы сейчас сказать что вы уменьшите теле проверьте все намного быстрее да тем не менее выложи ветеран тоже полезная штука какой вывод из этого можно сделать мы не продумали проект профили нагрузки с учетом специфики сервиса теста в наш чек-лист мы должны добавить профиль нагрузки ну постоянная нагрузка понятно пиковой это как тот случай когда полстраны ломанул смотреть объявления и особый случай и так как как я сейчас рассказал какие-то специфические моменты в вашем приложении очень болезненный случае с проведением приемочного тестирования navi vr начинаем проводить тест все хорошо тем не менее попытаем случается спайки лестнице или фрезы циpкa как как честные разработчики начинаем думать что наверное проблема в одном под модулей нашей системы начинаем копать ничего не находим как на самом деле обстояло дело тест проводился на vmware ace ics такой операционной система в которой мы запускаем виртуалке и если мы используем ее очень активно то есть у нас там все под соточку стоит потому что то на грустный тест и сами генератор нагрузки используют много циpкa и само приложение база то есть подсистема мониторинга самой проценко которая будет постоянно трогать контейнер это создает определенные спайки и проблемы производительности просто на виртуалка также был быстро данный момент параметр транспорт хедж пэйдж если он включён это тоже создает спайки в подсыпал vr потому лучше отключать вывод стали копать до уровня операционной системы и нашли вот эти проблемы с мониторингом и транспорт хедж пейджер тут как бы есть 3 решения первые мы могли уменьшить нагрузку или поменять клю нет то есть тот объект который мы исследованием тоже нам просто не хватало железо третий вариант мы могли тестировать на реальном железе и не имеет никаких проблем но допустим если это приемочная тестирование вы не можете ничего сделать вам нужно именно так проводить тест то в нашем случае отключили мониторинг и параметр транспорт бриджес вывод мы не учли особенности инфраструктуры на которые мы тестировать это очень важный момент потому что можно поймать огромное количество более ну и естественно как бы понятно что мы должны снимать метрики потому что все это мы увидели благодаря метрикам и телеметрии то есть полу памяти сети диску и так далее самый волнительный момент я назвал его полный ступор значит представим что мы делаем тот банковский теста которым я говорил до этого мы загрузили какое-то количество наших исследуемых пользователю каждого из них и счет и в ходе нагрузочного теста мы делаем 10 миллионов транзакций и не сошлось 3 транзакции из 10 миллионов смотрим ничего непонятно непонятно что делать непонятно как искать в конкретно в этом тесте у нас был фактор резервирования 3 большой класс татшар дав было много приложений и тем не менее абсолютно непонятно что делать и для этого как бы от безысходности начали просто вводить некие продуктовые метрики то есть не технические метрики такие сколько пришло наш арт сколько находится таком-то буфере сколько транзакции сейчас обработалось там в конкретной по системе и так далее и в итоге пришли к которому выводу нашли решение значит сердце кришны тот же самый тест банковский про который говорил раньше в которой мы делаем мир сортотип если кто-то в своей компании хочет попробовать такой тасс провести есть утилита джексон которая в принципе с анализом распределенных систем и вот посылки приведён пример такого банковского теста для того чтобы его разобрать на мастер-классе который сегодня состоится 3 часа мы тоже будем подробно его разбирать в итоге про проблему значит поскольку мы начали вводить дополнительные метрики рано или поздно мы обнаружили что нас есть буфер так называемых оставшихся транзакций на шортах и в самом конце низко транзакции там остается получал что действительно от 1 до 10 транзакций не обрабатывалась в итоге это была ошибка в коде моё пофиксили вывод мы не продумали продуктовые метрики и не имея их по сути мы были в каком смысле степы и вот как только мы их начали вводить что-то увидели это тоже важно продумывать соответственно тоже добавляем это в наших лезть еще одна отдельная тема значит отказ узлов в продакшен в хорошей хорошим процессе контроля качества мой обзор должна это проверять здесь уже более сложный случай значит у нас есть тесты на отказ узлов внутри центра обработки данных и там проблем нет даже в продакшн и тут вдруг у нас production отказывает весь сад вырубается все мастера и мы должны переключится на резервный возникает какие-то проблемы непонятно что происходит сама проблема понятно непонятно как тестировать потому что у нас есть тестовый стенд нам все настроено просто на тот скилл юн с которым мы работаем при этом варят как вы избрали свести если наша система тестирования достаточно удобно конфигурируем а то мы можем в течение 5 минут все превратить в 22 цента у нас есть какая-то нагрузка есть генератор нагрузки приложение сторону после чего мы просто меняем конфигурацию и пытаемся воспроизвести стал с двумя сторонами уменьшая нагрузку в 2 и получаем нашу ситуацию воспроизводим тут скорее это просто требование к самим тут зам которыми мы тестируем то есть я имею ни яндекс танку а то утилита который в итоге создается внутри компании для проведения тестов вот согласно мы не продумали все точки отказа и самая печальная когда такая ситуация случается в продакшене а мы даже воспроизвести не можем поэтому это тоже надо продумать если говорить про отказ узлов типичный график на проверку отказывай слов выглядит примерно так то есть мы запускаем тест он идет на полном кластере потом вырубается какая-то часть системы вот характерные пикового видно и после тест продолжается ширина этого пика и то есть то самое время перерегулирование которыми огрел в первых слайдах соответствие мы видим во время пика дрожание на графике рпс и the legacy который будет после пика это деградация но в данном случае видимся в деградация практически не было соответственно тоже добавляем в наш чек-лист 4 момента это время перерегулирование это задержки и возможные точки отказа в это центром то есть как бы внутри дата-центры между центрами и самое главное не забыть учесть как быстро данные переходит из одного в другой если у нас задержка в какой-то сложной логической репликации час готовы ли мы потерять этот час если у нас отрубится главный дата-центр еще один такой момент тоже жизненный значит кубер ниц всем он нравится такой классный модный начинаем его использовать и раскладывая на тестовый стенд или даже в продакшен деятельности у нас меняется приказы при каждой раскладки все вроде хорошо тоже все продумано тем не менее так происходит начинаем копать смотреть как устроен q бернейс выясняет следующие уку бернайс и какое в любой системы есть тоже даст свои узлы на которых он разворачивается и так получается что если у вас допустим есть больше одного кода поту могут случайном порядке попасть на разные узлы если между узлами плохо настроена сеть или если не дай бог мы тестируем чищу на виртуалка hе там разные сетевые контроллеры то каждый раз у нас будет действительно разной лет инси и это очень сможет нам результаты в итоге как бы какой анализ мы просто развернули тестовый стенд отдельно на железе проверили что конкретно в нашем приложении все хорошо что на самом деле сомнительно потому что мы просто поверили что что у нас хорошее решение как можно выйти из этой ситуации подробно о том как тюнить кластер губернатора рассказывал мишу прокопчук но в данном случае еще простой хак тут до того как его пофиксили целиком можно если это возможно внести просто контейнер в под и вы не будете попадать на разные узлы тем самым вот это прыжки лотосе их просто не будет и как бы морали какая мы вышли ограничение инфраструктуры здесь я хотел добавить такой момент мы не можем быть доступнее чем наша инфраструктура то есть представим ситуацию вы пишете супер надежное приложение у которого не знаю там фактор надежности 7 девяток и запускаете его на инфраструктуре у которой четыре девятки как бы вы ни старались вы зачем четыре девятки вы не получите это надо помнить и в общем не забывать и самый тяжелый такой случай значит все продумали у нас есть план живите есть обычные тесты в есть супер это утилиты которые все тестируют тем не менее через неделю или через 2 или произвольными интервалом в месяц случается огромная деградация ли dc и догадок нет ну думаю наверно это какая-то более долгоиграющая бага нужно сделать ланже взят с длиной в месяц но как сказал всё намного сложнее значит как было устроено схема о самой системе я рассказывал весной горит там достаточно был объемный доклад ну короче у нас есть класс торгашей некий битвой которые ходят в такие enterprise системы назовем ее сервис и наше приложение у нас очень много точек которые мы можем подозревать в том что они нам что-то тормозят начали думать про кластер к шее сделали профиль все проверили все хорошо непонятно в чем проблема начали копать само приложение и увидели что у нас есть огромное количество открытых соединений socket лимит и все такое то есть мы просто в это уперлись стали думать почему так нашли у себя багу для того чтобы ее найти нам пришлось запустить и себе дам поскольку это очень большая enterprise система у нас был во первых большой кластер был очень много соединений которые мы не должны были анализировать плюс был очень сервис авторизацией куча сторонних сервисов типа там сервис discovery и прочего и нужно было почти там один терабайт этих логов отфильтровать и не знаю если в заливаясь ослушников но спасибо ему за помощью вот он помог решить эту ситуацию что был на самом деле на самом деле за этим сервисом находился некий прокси через который сервис шел в очень такой legacy сторож пропали тарные которые невозможно был как то сейчас развернуть от этого создавались тайм-аута соки ты висели мы пофиксили у себя богуна таймаутов как бы количество не перестала быть не уменьшилась но выяснилось что кто-то еще ходит в этот самый сторож legacy сторож от этого возникает там тайм-аута в сервисе от этого проблемы в нашей системе от этого открывается огромное количество китов такая очень сложная ситуация которая сразу с двух сторон породила проблему в итоге мы используйте фидом и нашли проблемы с сокетами но все проблемы это не решило и мы опять же от безысходности начали изучать внешний подсистем и их профиль и нагрузки их потребителей и как бы начали больше общаться с архитекторами чужих систем значит решение мы можем потенциально попробовать включить в наш тестовый контур вот это самое хранилище если это возможно ли написать и эмулятор и начать тестировать вывод мы не корректно выбрали скилл юнит и как бы ту модель на который мы всю нашу систему тестируем это самое страшное почему потому что если мы выбрали неправильно то как бы все теста бесполезно вот в принципе на этом чек-лист мы собрали мораль в том что если мы не продумываем перед тестом все это тут с показывает погода на марсе иногда можно совпасть а иногда нет и очень важно это соблюдать из этого следует что допустим мы хотим технически построить систему которая может проводить такие гибкие теста с разных углов и так далее половина работы которые нам нужно сделать уже сделал есть огромное количество инструментов о которых больше я буду говорить на мастер-классе по 6 класс доклад на самодельные два часа и сюда мы решили вынести сам подход ана мастеркласс именно инструменты единственно что важно сделать если совсем вкратце это возможность очень гибкого конфигурирования тестовой системы возможность настройки data set of чтобы запускать как быстрые так и средние так очень длительные тесты автоматизация отключение узлов и автоматизация проверки результатов после этого как бы мы можем запускаться какая мораль из этого следует очевидно что вы таком в идеальном вакууме разработчик пишет помимо обычных тестов еще и генератор i am a файлов или чего то подобного для нагрузочного тестирования все так аметист репозитории все это попадает некую специальную очередь на грустного тестирования и зависимости от того какие тесты мы хотим провести там longevity ли обычная все это ульта это нужный тестовый стенд мораль в том что мы можем проводить быстро эксперименты на для того чтобы принимать хорошие решения то есть у нас на троих случались ситуации когда приходит несколько идей и мы тоже не знаем как надо сделать можно даже не очень может быть хорошим кодом его написать но проверить быстрой отсечь сразу огромное количество неправильных идей или неправильных подходов и второй такой момент что когда у нас все это автоматизированный у нас есть графики производительности каждой части нашей подсистемы это упрощает диалог как с менеджерами так и с архитекторами менеджером сложно мыслить там в таких технических абстракциях и конкретные цифры и графики производительности помогают им наоборот на таком уровне общаться с на диалог между менеджером и разработчикам упрощается архитекторы как правило они намного выше летают и смотрят на всю систему целиком и их как раз надо приземлять на конкретные цифры чтобы легче вести с ним диалог такая система это позволяет сделать и как бы самое важное чек-лист выстроен в продакшен и грубо говоря прописан кровью второй момент если в зале вдруг свет руководители и думают что наверное одна нить я делаю вот сейчас будем делать на груше на тестирование для этого достаточно вот если там действует назад нужно было нанимать отдела писать свой луна-парк два года назад это там 34 неделя работы нескольких инженеров то сейчас мы можем просто 15 20 процентов времени 1 инженер которые работают непосредственно от проектом который оттестировать потратить и сделать подобную систему третий момент это быстро эксперименты и принятие решений только на основе цифр это очень хорошо и соответственно для любителей кровавого энтерпрайза этот подход значительно помогает увеличить шансы в выигрыше технических тендерах если кому то интересно на мастер-классе мы рассмотрим полный пример такой системы банковский тест попробуем по использовать яндекс танка 6 врк отключать узлы и вообще всю эту руками покрутить по ссылке доступен исходный код вот мастер класс 3 часа на стенде авито а 12 это все очень мило с твоей стороны оставить 20 минут на вопросы готовы либо можно устроить нагрузочное тестирование прямо здесь без микрофона как бы выбирайте девушки да вот смотрите смотрите прямо ближайшими проходим пожалуйста если можно привстаньте спасибо за доклад очень интересно иван волков от и стоит его скажите как вы ловите баги в продакшене плавающие баги в продакшене но у вас есть тестовый стенд надо хорошо а выкатывать и в про ты там периодически возникают какие-то проблемы как выехал ловите ну скорее всего мы можем выдвинуть ряд предположений и носить их отсекать как правило мы можем добавить чаще всего на самом деле помогает вот такие подобные продуктовые метрики я называю продуктовыми условно потому что не сушки зрения продукт менеджеры могут быть совсем не продуктовыми но для технарь они такие чтобы хотя бы помочь отсечь огромное количество решений после этого если вы смогли воспроизвести ситуацию на тестовом стенде вы соответственно сможете и пофиксить если не воспроизводится копать глубже во всех этих случаях мы начинали копать самого простого то есть последние там два примера про вот эту большую систему с любите кластерам этот месяц шла ушел весь процесс с там шарден гаммы транзакциями тоже это могла быть неделя то есть в принципе естественно это процесс не быстрый но это возможно спасибо за доклад у меня пара вопросов есть первый это какой объем железом или виртуалок у вас используется для тестового стенда который постоянно крутит вот эти вот но если говорить про вид а значит нас есть production in close to cooperate и есть в кластер cabernet я к сожалению не знаю какой там объем железо но это набор виртуалок условно в других случаях когда это были железки это было порядка 1 2 3 4 там 24 ядерных машины на нагрузку 1 нам приложение там едва под хранилище данных чтобы с репликации арам сколько память сколько памяти но если у нас там допустим и на море решение то памяти будет многое то есть если нам действительно важно ну не знаю там порядка 80 гигабайт оперативки спасибо и второй вопрос по поводу снятия профиля трафика с продакшена и фидбэка какого-то когда вот проблемы с prada а у вас тестов нет покрывающих такую модель трафика вот про профиль вы как-то автоматизируйте профилированием и в плане того что вы пример привели джейсону с атрибутами его руками смотрите что а вот там такие атрибуты такая модель трафиком надо нам сделать или как-то автоматически это очень зависит от системы о которой мы говорим в таком случае мы можем знать просто этот джейсон в каком-то случае мы можем пособирать время налоги здесь допустим можно врубить на часть какой-то процент трафика кв оба тесте и просто сохранять все там будет запросы которые приходят вы собрали какую-то ленту поняли как она устроена и дальше начали тестировать вот на самом деле приходите на мастер-класс об этом там тоже поговорим вот сожалению не смогу но хотелось бы даст спасибо за доклад я здесь спасибо за доклад у меня вот несколько вопросов первый вопрос насколько продолжительно вот этот был сбор всего этого чек-листа их там вопрос какой прирост по показателям вы получили в итоге сбор чек-листа начался сколько три года назад наверное но это я условно говоря то что каких-то вещах мы знали сразу показатели качества и насколько увеличились отказоустойчивость доступность вот эти вот основные показал я могу привести два примера один раз продакшене случился серьезный крыш хранилищ данных из тем его пережила без каких-либо проблем и потом просто места всю откатили обратно и все поехала дальше при этом какого-либо простой в работе системы не было то есть я считаю что вот то что то ситуация так отработала это заслуга исключительно подобных тестов второй момент мы смогли поймать большой ряд багов которые возникали в продакшене тем что их воспроизводили и плюс вот я говорил про технические тендеры когда идет очень быстрая разработка и нам скорее важные идеи то есть просто сами подходы у нас могло быть такое что не знаю нас пришло три идеи быстрых все три реализовали посмотрели какой лучше isikli две лишние поехали дальше и такими превращениями получается мы строили tasty может быть речь не только о контроле качества самого приложения но и при создании чего-то с нуля вот как случае с прототипами стендарами и там с кем-то конкурсами это тоже работает отлично большое спасибо андрей здравствуйте спасибо большая за классный доклад а может быть я пропустила в начале они могли бы полностью свои регалии представить это первое выведем его руководителя направлении дальний разработки и во-вторых какая команда какого размера этим занимается или нету выделенной команды совы и чар вы хотите их пригласили себе я еще хуже яркого если управление я скажу следующее я просто разработчик в команде поиска и как-то сильнее свой регалий рассказать не вижу смысла если вам интересен подход и интересно поговорить о нагрузкам тестирование подходить я вам расскажу но в принципе я работу в команде авито у нас команда поиска и там пять человек плюс мы активно работаем с команда архитектуры этот ну еще какой-то там порядка там петича который вовлечены в процесс там командах которые проводили другие тесты до lavita там тоже команда была из разных компаний но тоже не очень большая тыс человек десять примерно так спасибо большое за доклад вопрос такой вы сказали что 20 процентов 20 30 процентов времени разработчика достаточно чтобы это построить я стал как с построением подобных систем и я правда не могу поверить в то что эту систему можно построить исключительно усилиями 20 процентов времени разработчиков алтае много да это вопрос наверно сколько разработчиков привлекается и дальше я думаю что не меньше времени потребуется на поддержка такой системы вы можете охарактеризовать сколько суммарно людей работало и сколько времени одежду на мкс на разработку и сколько дальше уходит на поддержку чтобы было понятно в целом сколько нужно времени на то что построить и поддерживать ну говоря про тот проекта на мастер-классе мы будем разбирать более за такую новую версию того что приложил как как раз которую можно сделать достаточно быстро том случае который был в примерах из слайдов мы действительно потратили на первоначальную версию такой системы примерно две недели и дальше по ходу дела развивали я бы не сказал что это занимало много времени это как правило в основном менялись сами этот кейс и что-то изменялась там в теле запроса или какие-то сложные случаи для этого мы добавляли новый генератор нагрузки но если система поддерживает не просто там am a file а прямо генератор ленты мы берем вот такого теста у нас генератор такой-то у нас там будут такие-то запроса адреса для другого теста у нас будет другой генератор-то в целом как бы div только в новом генератор ленты происходят но я так понимаю что тот набор технологий которые в результате получился в конечном итоге да он будет достаточно высокого происхождения вас вред я подозреваю что вряд ли изначально специалисты знали все чтобы построить систему такую как начальном этапе да и здесь потребовалось еще наверное в начале достаточно много специалисты уже знают вы что-то построить и дальше достаточно много учиться и наверное еще это составляющая должна быть учтена время он безусловно процентов ну не знаю вот если говорить про какие-то инструменты то индекс танкан sibl поэтому да ну то есть то есть чего изначально стали часто можно сказать что это q бернейс и по необходимости танка или к 680 того проект над которым мы работаем ну это же питон то есть и при этом сейчас все поддерживаться исключительно разработчиками как раз вот в этом процентном соотношении как искатель 23 цента ваша что да пока чтобы спасибо это роль компании зайца станиславский не верю еще есть вопрос друзья или хорошо а вот пожалуйста с первого ряда на а вот у вас есть какие не сложности с этим с количеством данных вот у вас на продакшне там данные постоянно обновляются и тестировать вы должны на каких то там данных отстающих по времени насколько это вообще реально получить production данные и как вы что вы делаете с проблемой которыми production они взрываются на тесты и не взрываются потому что данные просто другие если в системе и для тестирования отставания в данных критично но естественно пока что с таким вот случаем чтобы это было невоспроизводимые не встречался с обычно всегда можно снять какой-то дамп наверное если это как какой-то вот такой характерный случай то можно подумать как это решить можем про способ доклад поговорит со мной даже интересно я вам дают прям production данные для тестирования со всякими приватными данными пользователей ну если мы говорим про поиск нам вас нам интересный текст объявлений вот они в общем то на вид и так доступны так что они не такие уж приватных ok андрей спасибо большая можно тщательный вопрос где а вот смотрите спасибо большое за доклад плюс вопрос такой вот смотрите а в случае если у нас при навязать нам тестирование да то есть мы вынуждены обращаться к стороннему сервису никому до то есть к сторонним от и они предоставляют нам тестовую среду и на тестовой среде все хорошо когда мы идем соответственно в production of production у них нагружен сильнее объем данных соответственно которое они там на продакшене обрабатывают большие проблемы начинаются именно на продакшене как вот такие ситуации обрабатывайте и возможно ли их обрабатывать вообще в принципе потому что когда мы начинаем бегать по внешним альбина который вот сложно влиять практически как вашим кейси да это вот отличный вопрос как раз про последний случай из презентации когда по сути мы подумали что но как нам быть вот такой ситуации поставил mockup на самом деле вот этот сервис он был mako по мы на нашем тестовом стенде все хорошо работал вот если мы включаем где-то в тестовый контур магов мы должны всегда помнить что вот такая штука может произойти и хорошо бы пообщаться с теми кто разрабатывает или эксплуатируют ту систему с которой мы будем работать вот спасибо за доклад вопрос и нагрузку когда даете тестовую это вас от продакшна сколько там x1 x2 там x10 как вообще подбирайте здесь это зависит от железа если у вас шикарные железки у вас там не знаю 4 24 ядерных машины мы можем дать нагрузку вот ровно такую как нам надо если мы каким-то образом уже ты по железу то естественно должны как-то и уменьшать но вот как играл про выбор скилл ею то есть допустим если у нас нагрузка 100 тысяч рпс у нас там не знают 3 отлично серверы как же идет там свой кластер то мы можем взять только одну эту маленькую часть и тестировать только ее с нагрузкой второе меньше ну вот как вариант ну да просто вопрос был про то что дорого давать полную нагрузку даже в сосново класс сторона тестовый вы решаете это просто там на глазок режьте какие-то более это та методологические подходы это спасибо спасибо друзья андрей спасибо"
}