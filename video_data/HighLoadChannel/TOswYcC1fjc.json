{
  "video_id": "TOswYcC1fjc",
  "channel": "HighLoadChannel",
  "title": "Резервное копирование нагруженных СУБД / Андрей Бородин, Георгий Рылов (Яндекс)",
  "views": 1332,
  "duration": 2824,
  "published": "2020-04-14T11:17:55-07:00",
  "text": "да мы разрабатываем системы резервного копирования в яндекс облаке я смотрю что про резервное копирование хоть хочет знать уже больше людей чем про connection pulling видимо более распространенный вопрос скажите кто делает резервной копии много кто делает резервные копии с восстановлением во времени так кто инфицируют резервные копии как вас много я хотел подарить какой-нибудь из одному человеку ну вы слишком хорошая аудитория вы уже все знаете все умеете но постараюсь рассказать что-нибудь новое да я рассказываю все время про это резервное копирование даже если ко мне кто-нибудь подходит спросить времени я не могу остановиться и начинаю говорить про окно восстановление я разгоняю рассказывал про это раньше и расскажу но расскажем мы с георгием сейчас у нас доклад будет состоять из двух вещей я расскажу немножко про теорию и наши фичи в позы груси георгий расскажет о том что общий говори копирование всех накипи же не актуальна и для других баз данных не только для прогресса вот но а я как попал грешный человек все будут про него postgres у вас много в облаке если в яндексе если вы вдруг не были на предыдущем докладе то у нас несколько петабайт индекс облаке в основном от сервисов яндекса многие из них живут уже в яндекс облаке в почте у нас там миллион запросов в секунду ну или там много писем ну вы знаете вот нас в первую очередь интересует тема point in time recovery в чем отличие point in time recovery восстановление на . во времени от любого другого быка по в том что нам проще сформулировать чего мы хотим ну как проще у нас две основных целей нам нужно максимально дешево бы капица и максимально быстро восстанавливаться вот звучит очень просто но на самом деле то есть и ресурсы сложно сформулировать из чего состоят и что за время тоже не нетривиальное объяснить когда мы говорим про ресурсы почему-то все в первую очередь думаю этом месте которые займут бы капаем на самом деле место сейчас крайне дешевая я зачеркнул конечно это неправда место по-прежнему имеет значения и когда вы платите по счетам ис-3 или другого облачного хранилища вы понимаете что это не ноль это какие-то деньги но тем ни менее ресурсы которые значимы для системы резервного копирования это и локальное место желательно чтобы система резервного копирования использовал никаких лак не создавала никаких локальных файлов потому что если у вас пользователь создал кластер на 100 гигабайт у мне совершенно не ожидает что сколько-то гигабайт вы можете использовать под свои какие-то системные нужды он ожидает что там до 97 там процентов он может дойти это путь все его место важно использовать как можно меньше центрального процессора дну потому что вообще говоря в облачных базах данных значимая стоимость значит ночами компонента стоимости кластер это именно центральные процессоры в этих вот в них в итоге транслируется попугаи всех облачных сервисов часто для кластера имеет значение утилизации сети почему в том чтобы копыто система которая мой это операция которая может создать много трафика на ровном месте а сеть это репликация сеть это входящие запросы и неожиданно все может стать медленнее и если у вас сервис которые используются везде в россии от владивостока до калининграда вас возникает проблема с тем что у вас нет ночи все в риме где-нибудь люди делают запрос в вашу базу данных и времени когда было бы безопасно затормозить и иную просто нету ну и конечно же стоит экономить операции ввода-вывода с диском потому что в конце концов база данных она должна хранить что-то надежное а что-то ноги хранить надежно надо все-таки на диске читать с диска если вас съедается все в себе вся пропускная способность дисковые системы бэкапом это нездорово время восстановления тоже нетривиальная операция время восстановления для лап системы это как быстро вы сможете открыться для читающий нагрузки как быстро аналитики смогут перейти к выполнению запросов на вновь созданной вами реплики для lti pestana бая это время до того как как как стендбай подключиться к синхронный подключиться потоковой репликации для праймари когда вы создаете новый кластер с backup а это время до выполнения последней транзакции и открытия на за оба базы на запись на самом деле возможно и совершенно другие цели часто в системе резервного копирования очень важно иметь возможность защититься от оператора операторы делают ошибки чаще чем делают ошибки программы и для этого конечно система должна быть максимально простой кроме того некоторые системы резервного копирования имея в себе функциональность по смог тестом по определению что с базой что-то не так что данные кажется идут не туда что возможно требуется внимание оператора вашей базе данных стоимость администрирования по сути это количество документации вашего сервиса и вашей системы и под системы и пожалуй вот это очень сложная цель которое кажется не достигает ни одна хорошо не достигает не 1 плюс 40 на я система резервного копирования мониторинг состоянии базы пытаются иногда вкрутить в зерна и копирования но для меня это не совсем понятная цель иногда нужно интегрировать под системой которые занимаются обслуживанием базы ваши обвязки должны взаимодействовать друг с другом система которая обеспечивает высокую доступность connection кулер мониторинге и восстановление из резервной копии по сути это все ну и сам по сгрыз от и сама база данных это все единое целое которое обеспечивает хранение данных и должно уметь общаться друг с другом ну и последнее важное достаточно часть это расширяемость единообразие подходов которые вы используете в различных системах чего вы точно не хотим в системах резервного копирования мы не хотим никаких локов флаш тейлз ритлок это не подходит к резервному копированию мы не конечно же не хотим потери данных при чем защита от потери данных в системе резервного копирования тоже не тривиальная вещь потому что часто люди пытаются на системой зерно к 1 неисполненным time recovery возложить функции асинхронной репликации установление последних секунд перед падением про эмалью в кластере это задачи которые не решается система зерно и копирование это задача решается есть только алексей кухне вот его решается и вот злой патроне и другими системами высокой доступности вот кроме того если вы используете базу данных в режиме изоляции сериала и забыл возможны различные аномалии но к нему пожалуй близко сейчас подходить не будем выкопав много хороших и разных они все прекрасны по-своему матрица фич не выражена то есть в каждой системе резервного копирования свои уникальные вещи каждая система развивается по-разному и исторические при мы пришли к тому что мы поддерживаем системам северного копирования который называется во лжи система с открытым исходным кодом вы можете взять ее на гитхабе если вам чуть не хватает прислать будут парик вас мы его конечно же превью им и с большой вероятностью покажем вот устраивается довольно просто эта система резервного копирования в облака вы создаете bucket создаете ему сервисный аккаунт создаете ему ключ доступа всего три клика в браузере дальше ним в карлом скачиваете во лжи и это консольная утилита которая принимает на вход секреты и вы например можете выполнить команду backup лист который перечисляет все бэкапы и вызвать тут вот тут вот написано backup уж указав где лежит ваш кластер и быка будет сделан единственно что не забыть еще включить архив то есть сохранение истории изменения вашей базы данных в archive команде но у волги вам об этом напомнит вардинга минск если вдруг вы этого не сделаете в целом бэкап с point in time recovery почти всегда это некоторая база восстановление и история изменения базы данных но вход в пузыре сия история изменения базы данных может быть накачан а только последовательно это так называемый райт их и блок если у вас 80 процесс данный сервер вы восстанавливаете его с backup а вы смотрите топ и плачете потому что загружена но ядро которые последовательно медленно-медленно накатывает историю для того чтобы радоваться у нас есть дельты бэкапы то есть раз в определённый промежуток времени мы снимаем разницу с предыдущим бэкапом и эти дельты быка помогут наказываться последа параллельно на все деньги одновременно столько сколько ваш диск может писать в основном дельты backup это средство ускорения восстановления это не средство снижения количества данных на в хранилище ну понятно что трейдов вы можете часто делать полный бэкап и они будут восстанавливаться еще быстрее чем накатываться дельта backup у нас используются lnb с дельта backup это означает что мы понимаем какие страницы изменились в базе данных между быками и сохраняем только те страницы которые были изменены таким образом мы экономим и сетевое сетевые ресурсы и ускоряем восстановление кажется что это фича есть только у пробы копа и у валдис и и система резервного копирования сейчас идет активное обсуждение этой фичи в hackers возможно в 13 14 под грейси будет какая-то нативная поддержка и таки этой технологии пока вот у нас такая уникальная фича есть но если это фича вдруг появится об стримит у нас есть другая уникальная фича мы имеем парсить вал и формировать так называемые дельта файлы то есть мы вместе с вашим валом складываем историю того какие странички изменялись зажатой конечно же историю которая позволяет нам дельты бэкапы сделать максимально быстро не перечитывая весь кластер с диска просто из ис-3 получить информацию о том что поменялось с прошлого быка по и быстро восстановиться каких вич у нас не хватает но я выбрал самые фичи про которые меня часто спрашивали в последние два-три дня нет больше конечно ну в общем я взял две наиболее важных которые мне кажется часто люди которые пользовались базой данных на букву спрашивают про catch up у вас есть реплика которая отстаёт допустим на месяц или на 2 вы могли бы ее переноситесь быка по но вы не знаете вдруг восстановление из бекапа займет тоже месяц или два хотелось бы чтобы реплика могла сообщить мастер усвоился мастером или какому-то другому христу свой лосин на котором она находится после этого должен быть сделан дельта backup именно тех данных которые необходимы чтобы быстро и параллельно догнать реплику до текущего мастера после чего наложить дельта backup не поверх другого быка по а поверх уже существующего кластера конечно же потушив его принять при этом потому что писать в базу данных когда база данных включена это опасно вот я думаю что 1000 будет сделано потому что уже пришел человек который начал писать код и сделал work in progress поры квест про это еще одна фича которую показать даже не обсудили как она должна выглядеть джим может делать в верхней копии с реплики и по идее когда вы делаете связной копию вам нужно выбрать асинхронную реплику с минимальным лагом сейчас в яндекс облаке это работает как у нас есть питон скрипт который при помощи которого всех мастера собираются зуки перри и начинает голосовать кто из них отвечает за то чтобы сейчас сделать резервную копию ну закипит он конечно не надо лишний раз притаскивать но в целом звучит как функциональность которую гости протоколом во лжи мог бы сам реализовать у себя то есть если вы одновременно запустить и 3 кроме джо бы они договорятся друг с другом кто сейчас отвечает за резервную копию и сделал и отвечающий за резервную копию сделает ее так чтобы минимально эффекте в вашу продуктовую систему вот на этом я передаю слово георгию которая расскажет о том как мы сделали во лжи решаем довольно много ну давайте перед тем как говорить чего вообще мы такого на расширяли во лжи давайте вообще посмотрим на процесс резервного копирования в принципе вас есть какие то данные но и вы хотите их сохранить чтобы потом не потерять вот мы и вы куда-то ходить положить это может быть файл на диске от может быть другая базу данных или например облака ну если данных у вас довольно многое то наверное вы еще хотите эти данные как-то сжать чтобы не делать полноразмерную копию точнее чтобы не сохранять полноразмерную копию все-таки дороги вот но вы еще можете хранить что-то важное например приватные данные например данные пользователей для вас добавляется еще уровень шифрования вот кажется что это примерно весь процесс который происходит но и процесс восстановления абсолютно симметричны так как мы разговариваем здесь в целом про базы данных то ну соответственно и данные мы берем не святого духа из базовых данных здесь в голубые рамочки по сути обведены блоки которые можно назвать независимыми то есть что это значит вот мы можем например взять один кодек сжатия поменять его на другой и в целом процесс резервного копирования у нас никак не испортится мы просто что-то поменяем вот ну вот эти четыре рамочки 4 этих блока это по сути есть точки для расширения в нашей backup tool я например изначально во лжи и задумывалось как backup tool который потоковое сохраняет backup в облако и облако было поддержано только одно тогда это было из 3 ну пользователи становилось больше контрибьютором тоже ну и как-то количества облаков разрослось и стало аж 4 штуки и на всякий случай поддержали сохранение на файловую систему вдруг захочется ну подобная участь настигла и и шифрование тоже на сейчас поддержана два способа шифрования и один сейчас ну нам по крайней мере его обещают сделать умываться свято верим также у нас поддержана довольно как мне кажется большое количество способов сжатия мы сами проволился разные в итоге сами остановились на брод ли пользователи которые к нам приходят они в целом пользуются не только братли потому что видимо у них специфика данных такая вот кроме тех четырех блоков про которой я уже говорил был еще один в самом самой левой части слайда он был про базы данных вот это наверно самое интересное как база данных то расширить это нужно научиться как-то снимать данные с базы под нагрузкой звучит как-то сложно непонятно как можно было в одну backup tool за это все прихоть ну че у нас в сервисе есть не только postgres наша команда менеджеры это базис поддерживать много разных бас позарез mais quel манга редис там еще есть другие базы данных но продолжу говорить в целом правитель вот у этих баз данных их всех объединяет то что нам нужно было их бы копить и поддерживать backup tool для каждой базы но это не самая большая проблема проблема были например такого рода что мы хотим также потокового сохранять бэкапы в облака все утилиты этого не умеют или умеют как-то плохо то фейс разный или мы например хотим point in time recovery который говорил андрей в начале вот из point in time recovery общая штука сложная и и очень хотелось поддержки и не было вот и какой-то момент мы подумали что возможно нам просто внешних утилит не хватает вот что вообще нужно для того чтобы делать point in time recovery но нам нужно архивировать данные и нам нужно архивировать журнал истории как-то так это может выглядеть то есть вот у нас есть наш кластер где мы реплицируется и снимаем резервную копию например с реплики в целом такая красивая картинка была у нас в погрейся вот и для других глаз мы тоже хотели красивые картинки как это все выглядело изначально когда мы захотели бы копить mais quel в облака с поддержкой point in time recovery то андрей просто решил попробовать как все это реализовать и в форте в тот же самый во лжи там же рядышком добавил команды в целом получилось туза с дополнительными командами для mais quel вот и как бы все хорошо только нам приходится придумывать новые название которое не очень соответствует тому что происходит и вообще у нас код который для прогресса и для мы иску или находится настолько рядом что если мы поправим код для миску или мы можем случайно задеть код для пост gresso пользователей по зарисовок у нас очень много и обидеть их вообще очень не хочется вот поэтому мы пытались придумать каких-нибудь решение как нам всего этого избежать первой идеей как этого не допустить это было воспользоваться той же моделью что используется вас grease quelle то есть там есть модель sixteen шинами когда с помощью динамических библиотек подключаются экспаншен и вот мы здесь была какая-то такая же мысль что мы вот у нас есть пауза ну и дополнительные штуки которые мы туда допилим чтобы не обидеть вас перестав мы будем подключать как динамические библиотеки вот но тут сразу видно несимметричность подхода то что у нас например на базу с подогревом будет приезжать полноценная бы копилка например на базу с моей спилим будет приезжать бы копилка для подогреться с прицепом в виде достаточно для моей школе звучит как-то так себе но идея это было в целом полезно и потому что она позволила выделить общий интерфейс который в итоге попал в итоге вы решение и найти ряд проблем зависимости мини исправить их к текущему моменту вот собственно итоговым решением стали разные сборки и общая и 5 которым пользуется ip-адрес новая часть и части для остальные базы такой подход позволил поддержать консистентной интерфейс и не сломать обратную совместимость за пользователи postgres и вот так выглядит этот интерфейс который удалось сохранить у нас есть всего две сути самых главных команды для снятия резервной копии ну и для восстановления backup уж быкович вот и теперь к тому как вообще все это реализовано изначально как я уже говорил нас не было такой проблемой что нам нас чешутся руки и мы хотим написать еще там три бы копилке с нуля у нас была проблема то что мы хотим петр то что мы хотим бы капец в облака отлично в остальном нас бы копилке устраивали ну поэтому мы решили окей раз мы отделили отдельная api то мы можем просто в текущих сборках использовать как источник данных существующие усилитель для снятия бэкапы то есть для моей цели мы используем экстра backup для манга тебе используем он годам для ради сайт который еще в процессе у нас нет восстановления вот там используется редиски настраивается это все тоже не очень сложно то есть нужно просто прописать прописать настройку вал g-string рейд команд которая будет который будет написано команда которая снимает данные с вашей базы вот это все уже потокового будет вылетом по сжатая по шифрованной а улетать в облака теперь к архивации журнала с историей здесь уже так абстрагироваться от той логики которое у нас осталось во внешних тузах мы не можем потому что архивацию журнала не то чтобы другие базы вообще как-то хорошо поддерживают и backup утилиты тоже вот поэтому здесь есть специфичные для каждой базы команды которые также входят в общая api вот собственно с архивации журнала которое нужно для points in time recovery например была такая проблема что в подогреве это все делается с помощью archive команд в майской лимон г нет встроенного механизма для архивации журналы и хранить кучу лишних данных на быстрых январе дисках не очень-то хочется вот мы у себя эту проблему сейчас решаем не то чтобы очень хитро мы используем крон в целом нас это устраивает если когда-нибудь разработчики маску или манги поддержат archive комнат или что-нибудь подобное то мы будем очень рады другой проблемой с которой мы столкнулись например в миску или это то что на каждом христе свои берлоги вот здесь можно воспользоваться руки таинством вот здесь может быть видно что берлоге называются немножко по-разному вот вот собственно почему это проблема ну потому что вот у вас есть история которая пишется и у вас есть репликация вот и история которая вас записалась на мастере а по сути с одним таймлайну когда у вас это проиграли реплики они проиграли эту историю с мастера и написали своих блогов у них другой timeline получился который вы на самом деле сравнить с исходным не можете вот это приводит к таким проблемам если у вас края кластер и вы хотите чтобы у вас была высокая доступность а мы на записи и чтения все время тогда вас происходит свеча веры и flower и вы не можете просто так продолжать стримить из свою историю с того же самого h 100 вам тоже нужно все это дело переключать вот и нужно каким-то образом либо сравнивать эти timeline и либо научиться распознавать ситуацию архивации журнала как не консистентными вот сравнивать timeline и кажется что но я не знаю если кто-то в зале сейчас придумает как это делать скажите об этом обязательно вот мы пошли вторым путем то есть сейчас когда нам нужно переключить архивацию журнала с новых астана другой мы по сути сравниваем фактически время окончании записи блога или во блага вот время у нас на холстах синхронизируется с помощью ntp сервера вот и если рассинхронизация во времени становится слишком большой то загорается мониторинг и мы распознаём эту ситуацию как не консистентными пока что решение у нас сейчас такие в целом мы уже пользуемся mais quel им сколько уже наверное почти что год как и все это у нас поддержана и кажется точнее еще до того как мы зарелизили это все начали у себя пробовать и вроде бы с этим у нас проблем пока не возникает то есть дрифт на несколько минут которые может возникнуть из-за рассинхронизации smtp сервером все еще кажется ни разу не случился как всем этим начать пользоваться но вам нужно просто зайти в наш репозитории клонировать его и про следовать инструкциям для сборки указанными в ридми для каждой из баз мы сейчас поддерживаем другие базы данных в статусе бета что это для вас значит мы у себя это все попробовали и у нас это работает и применяется вот но так как сейчас мы все еще продолжаем разрабатывать эту функциональность то мы можем менять пока что api вот но если вы хотите это попробовать вы можете все это собрать посмотреть что мы вас не обманываем что все действительно так вот на этом кажется у нас все андрей просим вас на сцену выражаем вам благодарность то что выступили у нас вам двое андрей вот и теперь действуем по старой схеме у кого есть вопросы спасибо большое за доклад меня будет вопрос по поводу extension of и конкретно по по домой screen я так полагаю что скорее всего у себя москве ли вы используете с репликации на основе gt1 правильно сюда ваш утилита работает только для детей айти или она еще поддерживает старую версию позицию бы из интерпретацию только шутит стыковка вот этих переходов да да да я прямую взлетает ну это я так понимаю что вот эти вы видимо таймлайна вы наверное как раз на джетте одесситах и как-то проверяемую парсим берлоге и разбираем там времена так и последний вопрос ваши утилита как-то с предлогами работает нет то есть она только снимает система на чтение в случае под колеса у нас реализуется через старт-стоп api в случае смазку или мы шли не писать и используемых c backup но соответственно и starbuck а позже использовать реология вот эта команда стрим печь она называется раньше оно не называлось в альфа версиях стрим это был именно из за того что мы просто из x 3 bk позабирали ассистента собранную версию которая до умеет себе предлогом восстановиться мы понимаем что заведу лог там есть и ego vyzova то есть польза выдаваемые консистентную какой в итоге получить чтобы нагадить получить получается в принципе то как обертка да по сути торы рэпер который позволяет единообразно хранить бэкапы разных баз данных и единообразно восстанавливать их в point in time recovery нас как для управляемых база данных это очень важно что мы не нашим слишком много машин или вокруг использование системы резервного копирования спасибо большое просто у меня больше такой организационный вопрос вот в этом на добавляли наш поддержку но если озон есть яндекс и такое облако есть еще теперь дтп и вы часто еще четыре база сделали сколько сколько всего час мэн тренеров и сколько у вас разработчиков и как вы будете справляться со всем этим вот зоопарком сейчас у нас кажется 4 моим тренера проекта вот ну и в целом пока что количество контрибьютором анону растет примерно так же как и раньше то есть мне кажется что я хочу проблема на самом деле актуально но сейчас 50 ищу , как мы будем справляться как-то будем и вот прям честно как бы есть проблемы которые нужно решать мы намерены их решать потому что мы сами живем на этой системе не все баги нас касаются то есть баги там совместили 7 совместимости с какими-то старыми системе свал и например для нас не так актуально потому что мы на сто процентов съехали спал и но мы намерены поддерживать все эти проблемы до сообщества их решать сообщества к счастью хорошо находит баги даже те которые нас не касается и заставляет нас ценить вот проблемы достаточно ортогональные комбинаторного взрыва здесь не возникает есть проблемы с подьемы с и садур с ажуром решают у нас коллегии скупки без банка дерзкой компании они сами принесли и же и жирном и сами его чинят это очень удобно и мы написали просто так случилось не знаю захотелось в определенный момент поддержать google и клауд все-таки коллеги все такое вот мы видим а мы его будем поддерживать поддержка других баз данных нам необходимо потому что они подвижны в индекса облаке не все системы сейчас в бьем их собаки копируются вол'джин но возможно когда-то в будущем все будет копироваться именно именно во лжи вот короче самое главное что не возникает комбинаторного взрыва то есть не возникает взрывов где-то на стыке именно с джи си пи ломается именно редис обычно вот гляди сломается в такой ситуации аджисепт ломается в такой ситуации вот спасибо за вопрос еду здравствуй спасибо за доклад а такой вопрос вы сказали что вот интерфейс для баз данных он более минетом устаканилось а стабилизировался что касательно добавление ну вот если нам захочется добавить другие охранники и тот же самый cf за ланды задара и так далее то есть какие-то такие и дал мне время стандартный интерфейс полистать что не будет положить файл удалить файл считать файл что то еще да ну то есть там есть выделенная интерфейс для стороны вот просто нужно реализовать интерфейс и тогда это будет поддержан и даже не то чтобы много кода то есть это стабильно уже интерфейс его можно зашиваться это это через белен и вот по моим оценкам внутренним реализация какого-нибудь и чувствует же то есть у нас есть стандартный набор тестов вы которому вы даете когда мчался он прогоняет этот набор но против вашего хранилища и говорит вам ok или мелкий вот по моим оценкам реализации чего-то в почту и раз реализовывали это где-то там и день в субботу выделили что сегодня я хочу могу пописать где они потратили и получили функциональность которую хотели с другой стороны ну то есть день это существенно меньше чем то что от нас потребуется чтобы сломать эту совместимость потому что нам надо сейчас стоит же выделены в отдельную библиотеку нам надо переписать тысячу вызовов во лжи и тысячи десяток реализации в этой библиотеке то есть нам сломать совместимость больше чем вам сделать что-то новое в этом плане наверно уже api и стоит жить стабильнее чем api например редиса того же вот с другой стороны к нам приходил человек который сказал я хочу сделать поддержку с и через цепи что вот степи было как стоит я сейчас сделаю начал писать код и кот пропал ну то есть есть вот такой случай когда нормально для в конце сада на просто выдумали что-то совсем просто нет это не совсем просто программирование сложно программисты в принципе уже как бы ну знаете там профессия все такое за это деньги обычно платят вот спасибо особенно гошке если не знаешь дают отошла хайповая чётенько посему еще есть у к вич вопроса здравствуйте спасибо за доклад не вот такой вопрос а в волге я просто им никогда не пользовался есть какая-то встроенная функция по работе со старыми быка по ми су значит вторые ну например в том же парменида есть такое понятие что он например держит определенное количество бэкапов а старые стирает да у нас есть две политики поддержания окна восстановление либо по количеству бэкапов либо подать из который вам не нужен point in time recovery ну то есть удаление бэкапом у нас есть удаление по какой-то политики мы не просто так все удаляем у нас долго не было не было поддержано функция удалить все ну недавно ее сообществом сообщества или мы сами случайно реализовались что-то такое случилось сейчас есть команда del это в rising если вдруг вам надоело что-то хранить а в интерфейс облака вы не хотите идти вот и еще у нас есть функция которая позволяет отметить backup перманентным то есть у вас случается что-то что ну кажется на надо хранить долго вы отмечаете определенную зеркальную копию экстремизма в москве возможно не поддержит они это поддерживает такие функции визуал класс ну вот вы можете отметить какой-то backup нужным и даже когда вы будете что-то удалять она не удалится само собой единственно штамм возникают всякие edge кейс с дельта пикапами потому что у вас дельта нужная для нее надо еще и базу хранить не знаю как это работает ну короче у нас много разных политик хранения которые позволяют что-то старое хранить что-то новое хранить как-то так спасибо за вопрос да это работает с дельта пикапами системы не удалит ваш дельта backup если он не удалит вашу базу или david & backup если вам нужно для другого дельта backup а то есть например у нас настроено резервное копирования которая гарантирует окно восстановление в семь дней по факту это означает что на у нас делается база раз в неделю и дельты кажется каждую ночь как каждый maintenance window это означает что вас может храниться до 13 бэкапов по сути то есть какая то база которое нужно дельте которая попадает в окно восстановление и вот тут старую базу мы тоже храним потому что она нам нужна но по сути мы храним треба максимум две базы в в самом крайнем случае почти во всех случаях вот первое что хочется сказать большое спасибо очень крутая утилита нас здорово выручили вопрос такой можете немножко поподробнее рассказать как работает инкрементальный быка потому что услышал по поводу того чтобы парсить и вол и и на основе этого понимаете что поменялось но допустим если мы не быка пинбола мы же можем делать только full и инкремента мы просто иногда так и делаем и тогда непонятно потому что мы заметили что элемент работает значительно меньше по времени чем full и если бы мы предположим продолжит при пользовании собой учитывали все базу да и сверяли но коротал например делает а то было бы дольше вообще там типа два подхода есть по поводу снятия meter ментальных бэкапов вот тот который из дельта файлами рассказал андрей это фича поддержана с того года вот на эту она выключена по дефолту до погибать если вы отдельно не включили должиль тогда юзом дельта то вы сейчас делаете дельта backup чтением всех дата файлов то есть без пар совала то есть о по-честному ты вычитываешь наберешь только изменивший зам вот 4 хотел прокомментировать если вы не архивируйте вал у кого не может быть но мы делаем хитрого вот мы думали про то чтобы поддержать и вот эту хитрость но то есть во лжи час будет ругаться если вы архивация волан настроена он будет писать вам вардинге если у вас archive молодому в пункт просто откажется делать резервную копию скажу что вы можете сделать не консистентную копию так делать ноги его зачем вам не консистентной включая world of на время bk вот мы хоть думали о том чтобы поддержать возможность удаления вала который не нужен для консистентной sti то есть удалить вал который нужен для point in time recovery но при этом хранить вал который нужен для вас просто восстановления из резервной копии ну звучит как что-то для сообщества короче нам это не надо вы с удовольствием привьем код давайте в там микрофон нужно микрофон отдать вопрос сейчас там трансляция запись вот эта история там здравствуйте я так понял что система резервного копирования довольно универсальная а возможно ли шлюз для файлов чисто файловый нагрузки то есть для чего есть специфические там студийной записи звука вы где очень много кусков например чанков аудио их терять не хочется и хочется их так же ловко бы копить в облака причем ну что-то да записали на мель ему про то еще не слышали ни на самом деле лишь яблок говорил короче про то что я тебе предлагал короче данную штуку что видим мы могли бы выделить ну и скорее всего это сделаем чуть попозже выделить от кусок а в отдельную библиотечку которого можно будет им портить для того чтобы ну просто вот таким pipeline нам засылать в облака примерно что угодно когда ты просто данные суешь он их жмет шифруется и кладет файлики эта штука будет конкурировать с яндекс диска посадка конечно но то есть идея да интересная про не услышал впервые георгий говорил мне об этом не рука слушал я буду слушать лучше вот я и прокомментировать никак не могу намеки говорит что мы будем их но в целом типа да то есть короче может мы это напишем это вроде не то чтобы очень тяжелая работа там еще вопрос спасибо большое за доклад первые вопросы которые звучали кто делает backup а кто не делает бэкап и последний был кто во лидирует backup вот что-то в во лжи для валидации бэкапов задумывается я так понимаю что в текущей функциональности этого нету допустим в утилите вот пост про есть какие-то наработки движения в эту сторону а с вашей стороны что-то в этом задуман задумка какая-то имеется спасибо да смотрите что делает про бэкап он проверяет контрольные суммы ну страниц которые считывают контрольные суммы могут не сходиться и это нормально ну то есть если вы считали половинку странице старую половинку новую то пробы копыта заметит скажет контрольная сумма не сошлась пойдет в по сброс откроют там шеррид буфера попробует найти там страницу попробует перечитать то есть вот у нас тут было про простоту все вот это перепроверка контрольных сумм это сложная операция которую кажется что не должна делать система вот с нашей точки зрения не должна делать системы резервного копирования с другой стороны перепроверка контрольных сумм не гарантирует вам целостность то есть если например у вас какую-нибудь хитрая ядро linux которая потеряет какую-нибудь страничку таза и или или у вас просто баг вол'джина пример который потеряет какую запись потерять какую-то версию страничек контрольная сумма там по-прежнему корректная то есть у нас есть задача да по верификации бекапа но оно не делается системе зерно копирование верификация должна выглядеть как полное восстановление кластера проверка возможности чтения данных которые уже в себя включает проверку контрольных сумм после чего выполнение аптекам проверки инвариантов на индексах то есть вот сейчас эту задачу реализовывать средствами в лодже мы не хотим потому что она хорошо скрипт улица bach скриптами плохо скрипту ица горчичным кодом блинковаться одновременно с папус готовой базой нам существенно сложнее чем пробы капу потому что пробок об написан на си это не сделать просто вот то есть короче мы используем показ остальные во лжи полноценная верификация backup они поддержана и кажется что никто над этим не работать ну то есть мы делаем это другими средствами потому что мама мало общего контекста системе вас резервного копирования восстановления там вопросов 1 да наверно постоять не уже задавать вопрос понежиться лучше вопросе да хорошо мы по крайней мере я запомнил тот который мы привнесли то есть спасибо за доклад планируется ли поддержка cliff house ли мы к потому что есть то за клик house backup которая тоже многолики написано там поддерживает ac3 и тоже поддержки ментальная backup она по-моему не поддерживает point in time ну короче вообще идея такая была вот мы общались со своими коллегами из команды которые занимаются как хаосом и немножко с людьми из команды и хаос и вот идея попробовать поддержать в виде такого же в рокера она есть и и даже ну пытался взять студент в качестве дипломы как-то приходил к на мной в итоге не взял вот поэтому пока она не пишется вот мы хотим не никто над этим не работает да спасибо за ваши вопросы теперь вам нужно выбрать соответственно вопрос который вам понравился понравился больше всего ну я в общем то я ждал вопросу про поддержку ряду логов на его собственно задали вот ни за что я сомнение я дни для до 11 раз точно пойду логе это хороший вопрос потому что он прояснил наш доклад 2 я вот не знаю все таки pro crack house да пусть пусть пока house"
}