{
  "video_id": "bDXEeoCkHOw",
  "channel": "HighLoadChannel",
  "title": "Чтобы всех отыскать, воедино созвать: система трейсинга событий в VK Звонках / Алексей Шпагин",
  "views": 224,
  "duration": 2488,
  "published": "2024-10-29T03:08:41-07:00",
  "text": "Итак здравствуйте коллеги сегодня я хотел бы вам рассказать про то как мы сделали трейсинг в наших ВК звонках а два слова про меня Меня зовут Алексей Шпагин я руководитель команды бэнда проекта ВК звонки в целом в IP телефонии в средствах видеоконференцсвязи Я работаю более 10 лет начинал как c+ разработчик впоследствии ушёл в менеджмент и сейчас прокачиваюсь по рско ветки Вот к чему такой необычный портрет будет понятно буквально через несколько минут а по поводу аудитории на кого я так сказать рассчитывал свой доклад Дело в том что вот в тех методах и идеях которые мы применили в своей системе трейсинг нету особо именно звоночка специфики глубокой а и в то же время я думаю что почти каждый разработчик наверное хотел бы знать больше про свой сервис уметь траблшутинг она не доклад не узко специфичный Итак что О чём же мы сегодня поговорим Значит первое мы посмотрим С какими трудностями при поддержке наших пользователей мы сталкиваемся и это и будет предпосылками для нас к тому чтобы сделать систему Рейсинга затем посмотрим Собственно как мы сделали систему Рейсинга какими требованиями мы задавались а третье посмотрим на результаты То есть а что нам дала Вот эта система рейтинга которую мы сделали и внедрили и в конце Немного поговорим э коротко про планы развития у нас ещё много идей Как говорится а Итак какую же проблему мы решаем а значит Дело в том что ВК звонки - это сервис для видеосвязи можно звонить р to Пир можно собирать групповые звонки э в том числе наш сервис часто используется для обучения э Мы кстати говоря сами ВКонтакте используем свой сервис для проведения всех рабочих совещаний ээ Значит у нас есть различные клиенты под различные платформы Я имею в виду клиентские приложения То есть это и мобильные iOS Android это и для компьютера ээ Windows Mac Linux и даже есть э специализированная мм специализированное клиентское приложение для конференс комнат Аа у нас достаточно большое количество фичей А вот этот слайд выполнен специально в провокационно таком стиле чтобы было ничего не прочитать аэ просто фичей много И вот это этот факт нам потом пригодится сейчас чуть позднее вот а у нас м примерно 4 млн звонков в день э очень большое количество это и групповые звонки и Пир to Пир поэтому пользователей соответственно там ещ больше И конечно приходят люди с некоторыми жалобами их нам обращениями вот типовые обращения я вот выписал несколько то есть ну самый такой распространённый не могу подключиться к звонку нет видео там не слышно там что-то какая-то фича не работает не включается там скрин например и нам бы хотелось чтобы эти обращения были оформлены следующим образом был идентификатор пользователя у которого были проблемы Ну имеете в виду ID который Ну там в браузере можно скопировать Значит мы хотим идентификатор звонка естественно чтобы найти нужный нам звонок мы бы хотели более-менее точное описание проблемы Что именно плохо Ну в идеале ещё какие-то п to То есть я нажал сюда сюда сюда и у меня там отключилось видео например ну и клиентские логи тоже были бы крайне полезны но как говорится Нельзя просто так взять и составить обращение на практике А значит айди ников нет имена то есть есть имена у Ивана Ивановича там пропал звук например значит нет айди Ника звонка Ну это правда вот это всё-таки народ Join Link кидает это не такая не та не такая частая проблема но встречается значит описание проблемы часто примерное то есть было плохо было плохо слышно например да то есть а что это значит не очень понятно Значит нет ну шаги воспроизведения это Экзотика Это только ки могут написать фактически другие и клиентские логи тоже не всегда бывают ну их можно запросить но иногда не бывает А И значит вот с такими обращениями Приходится работать и в начале при разборе обращения нужно проделать ряд некоторых рутинных операций которые делаются Ну практически для каждого обращения например Ну сначала нужно определить сколько человек вообще было в звонке это групповой звонок рту Пир если групповой то сколько было народу дальше мы нужно установить соответствие имён участников и идентификаторов этих участников Ну чтобы соответственно дальше что-то грепан понять С каких клиентских приложений Эти люди заходили потому что могут быть одни проблемы в одних приложениях другие известные например какие-то проблемы в других приложениях и так далее этот список такой так сказать длинный и в ЧМ же собственно сложность из складывается Точнее говоря сложность разбора обращений для нас вот Первое это самое наверное страшное - это количество участников потому что мы должны прогреть условно говоря каждого человека в логах и если это два человека три человека четыре человека Ну такое обращение разбирается относительно быстро Вот Но если это какое-то совещание в команде там на не знаю там 50 человек вот то это просто значит ну целый день можно греть А если такой по компании там в 1500 человек ну это ад разбор такого обращения вот значит дальше что влияет ещё на сложность Это количество фич потому что обращения могут быть связаны с разными аспектами что-то не включается там какая-то фича конкретная Не работает Чем больше фич тем соответственно нам сложнее и третье - это количество платформ мы косвенно уже об этом говорили то есть Может на нам допустим на Андроиде воспроизводятся одни проблемы на айосе другие проблемы вот поэтому количество платформ тоже жизнь усложняет немножко а инструментов для работы у нас раздва я пчёл по большому счёту у нас есть админка простенькая и логи бэнда а логи клиента иногда бывают и они нам помогают но в общем случае мы так на них не очень не всегда можем рассчитывать поэтому железобетонно у нас есть только логи бэнда Итак что же нас подтолкнуло к тому чтобы с делать систему трейсинг Значит у нас достаточно большое количество фич А значит у нас различные платформы на которых Люди работают а у нас много типовых одинаковых операций по разбору обращений и инструментария недостаточно И что же мы сделали А мы сделали систему трейсинг которую мы назвали палантир а этот термин пришёл к нам из Вселенной Джона толкина А собственно говоря скриншот на экране это скриншот из трилогии Питера Джексона Властелин колец А и логика выбора этого название очень простая вот этот камень Это если кто вдруг в начале девяностых не в начале двухтысячных не смотрел трилогию я поясню значит этот камень или книжку не читал вот этот камень палантир Он позволяет так сказать пронзая в какие-то скрытые уголки с кем-то пообщаться на другом конце А И вот логика выбора э название была именно такая некий некий Волшебный инструмент который нам всё сейчас покажет а и я должен сделать два дисклеймера на этом моменте дисклеймер номер один Дело в том что в Соединённых Штатах Америки есть такая компания она называется палантир латинскими буквами а это именно компания это не продукт вот а они в свою очередь делают продукт А по сбору пользовательских данных и отправки их некоторым своим Штатов Ским ээ государственным структурам вот дисклеймер заключается в том что мы никакого отношения не имеем к тому палантир Штатов вот просто так сказать совпадение названия обусловлено скорее всего просто тем что разработчики и мы и они смотрели примерно одинаковые в детстве фильмы и читали одинаковые книжки Вот дисклеймер номер два мы не сохраняем Никаких чувствительных пользовательских данных то есть мы не кпм аудио мы не кпм видео не кпм Мы работаем только с некоторой технической информацией А с какой именно мы собственно сейчас познакомимся но там нельзя Ничего как бы суть вашего звонка там как бы нельзя послушать или увидеть а Итак какими же требованиями мы задавались когда начинали работать над нашей системой Рейсинга значит первая часть требований - это некоторые такие чисто технические требования А значит нам важно чтобы система Рейсинга не влияла на основную систему То есть если система Рейсинга падает окей Просто не будет Трей сов но звонки должны продолжать работать и это касается производительности и капасити То есть если вдруг закончилось место в базе там для Трей сов то О'кей Но это не значит что мы меньше звонков там можем обрабатывать например то есть Никак не должна технически влиять система трейсинг это первая часть и вторая часть можно сказать продуктовая То есть это хоть и внутренний но продукт у него есть продуктовые требования так вот они следующие значит вот чего нам не хватает в логах и в админке Значит нам нужно чтобы наша система показывала различные события в звонке последовательно на неком таймлайне чтобы можно было легко увидеть вот что происходило с пользователем в звонке и нам нужно иметь средство поиска и фильтрации по конкретному звонку по конкретному пользователю э чтобы соответственно не грепайн вот Итак э перейдём к технической части То есть как мы собственно это сделали м значит э первое хочется договориться о терминологии те кто работали когда-то в телекоме А вот эти термины так сказать пугать и смущать не должны Но значит для остальных я поясню Вот сигнали - это такая штука это некий набор протоколов по которому мы осуществляем инициацию соединения потом управление этим соединением и в конце завершение соединения Вот то есть это некий Ну условно API или условно Control Plan некоторый Вот то есть вот такая вот связь которая в течение всего звонка позволяет нам контролировать что происходит но это не видео это не аудио это не скрин это именно управляющая такая линия значит А вот аудио видео снн На некотором таком жаргоне но профессиональном называется медийка вот вот это вот две разные вещи Силинг и медийка мы с ним эти терминами дальше будем встречаться поэтому я счёл нужным соответственно их объяснить так вот по поводу архитектуры А значит вот на схеме представлена архитектура нашего сервиса в максимально упрощённом виде и это до трейсинг то есть то как Мы работали до трейсинг соответственно есть микросервис который обрабатывает Силинг есть набор микросервисов но я их объединил просто для упрощения одним большим квадратиков идёт аудио-видео есть некоторая бизнес логика которая это всё объединяет и там стрелочки во все стороны показаны А И что же мы сделали значит первая версия первая версия она наивная немножко а мы просто поставили рядом базу данных отдельную и бизнес логика просто часть данных туда м в эту базу данных записывала Вот Но мы так сказать поняли что это так сказать Такой вариант не самый лучший и мы достаточно быстро перешли к версии номер два это уже более зрелый вариант Значит в этой версии бизнес логика также пишет на самом деле Это упрощение что только бизнес логика это мы сейчас посмотрим тоже значит рейсы пишутся сначала в некий микросервис который называется понр он там что-то делает и соответственно записывает уже в базу данных опускаемся на уровень детализации ниже значит Как это работает значит в каждом из наших условных Таких вот блоков условных микросервисов присутствует некая такая штучка называется палантир Агент я тут перехожу на английский язык потому Ну название классов и название докер контейнеров кириллицей так сказать как-то не принято делать Вот поэтому здесь уже Мы в таком именно на таком слое работаем так вот палантир агенты они делают примерно следующее они собирают собственно говоря информацию с тех микросервисов в которых они живут Ну например с сигнале там с бизнес логики с медийки тротт это дело батчат чтобы там никого не заддосить и отправляют вот этот палантир вй Нужно отметить что этих палантир агентов много то есть условно говоря вот в каждом инстанс микросервиса сидит вот этот агенти и он значит что-то йте пишет именно поэтому Нам нужен вот этот вот промежуточный йте Потому что если мы будем писать прямо в кассандру есть вероятность что мы её можем заддосить или где-то заблокироваться вот поэтому значит эти агенты они сливает всю информацию во чит А в свою очередь он делает следующее значит он получает данные синхронизирует ивенты жмёт их и уже он записывает в базу данных а с точки зрения инстан сов у нас Эта система не не занимает какого-то очень крупного железа значит Касандра у нас по шесть инстан сов в трёх в каждом из трёх дата-центров есть ещё такая технологический компонент координаторы их всего две штуки в каждом дата-центре и собственно Понти райтеры вот эти условные прокси их по вос штук в каждом из трх дата-центров теперь посмотрим А как это выглядит В прямом смысле выглядит то есть UI Как как выглядит UI значит дизайн исключительно Инженерный это над над палантином работают разработчики бэнда и работает ровно ноль дизайнеров и ровно ноль фронтенд разработчиков То есть это всё бкд Разработчики делают под себя значит но главное что бы фун льно значит вот это значит первый экран - это экран поиска по пользователю второе экран поиска по звонку А если мы нашли какого-то человека какого-то пользователя то Вот его список звонков за последнее время Ну вот на скриншоте представлено 7 дней там можно смотреть больше или меньше Сколько нужно А если мы раскроем какой-либо звонок то мы увидим там сразу людей то есть кто участвовал в этом звонке сраз с ашками если мы раскроем какого-то пользователя мы увидим все события связанные с ним разложенные на таймлайне А если мы наведём мышку на какое-то событие то мы увидим во-первых тип этого события его йм и если мы туда Клик мышкой нажмём то нам подсвечивается снизу в списке событий вот это вот событие которые мы мышкой выбрали значит сейчас следующий экран будет это по сути тоже самое Просто я отск вверх то есть у меня таймлайна уйдёт вверх за экран а снизу будет список ивентов Вот соответственно я отск талай ушёл это список ивентов А мы сделали Ещё кроме всего прочего прикольную такую штуку что мы можем делать Search по командам внутри сигнального протокола то есть на самом деле сигнальный протокол - это по большому счёту Jon И там значит бегут всякие разные Командо и вот по имени команды можно на всё Ну просто на самом деле текстовый поиск это очень удобно например вот здесь на скриншоте представлена команда Media modifiers она предназначена для того чтобы включать и отключать серверное шумоподавление Ну и вот можно порчи А где Клиент просил включить или отключить серверное шумоподавление это просто Как пример так можно найти и другие команды тоже А кроме этого Значит мы можем в человека читаемом виде в удобном посмотреть от сообщения вот то есть например вот этот это так называемый sdp S description прокол Мы про него сейчас ещё поговорим он опять же человека читаем Вот кроме sdp у нас в качестве лода для ивентов бывает ещё J и даже наверно большая часть это именно жены и тоже мы J в человекочитаемом виде вот можем смотреть Всё достаточно удобно поговорим о том какие же данные пишутся а на самом деле на данный момент типов событий не так много это по большому счёту событие юзер вошёл юзер вышел websocket на сообще Ну попсокет соединению сообщения от клиента до сервера от сервера к клиенту и offer Answer sdp два слова про sdp - это штука из телекома её нам Мы её так сказать унаследовали вместе с webrtc webrtc так описывает сессию собственно это есть описательные sdp для согласования медийки То есть sdp офер - это когда кто-то хочет инициировать соединение он соответственно кидает офер значит тот кому он предназначен это офер смотрит Значит парсит его и либо соглашается на него либо нет и соответственно идёт обратно А я очень упрощают в том что это описание на самом деле медийки это договорённость на кодеки на параметры этих кодеков на порты вот и всё в таком духе вот коротко ещё раз что мы пишем по каждому событию значит по каждому событию у нас пишется тип мы список типа посмотрели значит время возникновения Тай Stamp естественно и текстовый P наполнение э Значит мы уже видели значит это бывает sdp это бывает Jon попсокета и это может быть фрагмент логов А И если говорить про объёмы и про скорости то ситуация следующая значит я выписал некоторые цифры это цифры за некий такой средний день то есть это не выходной Это не праздник там не Новый год когда пикта там большой Вот это такой средний день например вот там 28 ноября вот хороший день когда у школьников нет каникул и у нас там много обучающих допустим звонков в общем такой некоторый средний день и в такой средний день у нас бывает примерно 300 млн Вот таких событий значит когда максимальная концентрация звонков и пользователей у нас примерно 5.500 в секунду летит таких ивентов при этом Касандра нагружается на 25% опять же в пикта и примерно полан нагружается на 5% при этом срок хранения вот этих эвенто он 14 дней для всех для всех звонков Итак посмотрим Удалось ли нам выполнить наши требования которые мы собственно сами себе и поставили в начале значит как мы видели на схеме вместе со своей базой стоят как бы сбоку справа вот от основной системы и это не только графически это и как бы физически тоже так и таким образом авария палантир То есть даже если он просто значит всё перестанет отвечать то авария палантир никак не сказывается на самих звонках звонки продолжают работать а значит палантир также не влияет на качество и ёмкость звонков опять же если даже база переполнилась то всё продолжает НКИ продолжают работать значит это то есть технически мы закрыли требования выполнили значит продуктовые значит да все события отображаются удобно на таймлайне это выполнено поиск реализован и более того вот даже четвёртое требование перевыполнен то есть мы даже сделали поиск внутри протокола вот а теперь посмотрим А как же нам палантир помогает то есть какие результаты внедрения а значит для того чтобы посмотреть результаты э показать точнее вам результаты Я разберу сейчас два обращения таких достаточно реальных которые встречаются и разберу их как бы в двух вариантах до внедрения палантир как бы я их разбирал раньше имея только логи и ну и админку значит и как я буду разбирать их с палантином вот сейчас Давайте посмотрим обращение номер один а у пользователя такого-то в звонке не было демонстрацию экрана от пользователя другого есть ссылка на звонок Да небольшой комментарий по поводу имн Дело в том что это тестовые боты я было бы не совсем корректно показывать вам реальные какие-то звонки это могло каких-то людей скомпрометировать поэтому для доклада были сделаны специальные тестовые звонки с тестовыми ботами поэтому такие странные имена Итак значит помно получить айдини всех вот этих вот пользователей которые у меня были в звонке хорошо шаг номер два я их получил теперь мне нужно получить не внутренние дишни звонковый а ВК ID Я пошёл в админку и сконвертируйте О'кей Я дальше буду с ней работать я понял какой дишни значит э Шаг номер четыре Я начинаю смотреть все строчки а в то есть огре пою по аидиш неку и смотрю все строчки которые связаны с этим пользователем и АА Я закапываю в логах с некоторой вероятностью я найду строчку я вам Её когда будет следующий разбор с палантином я покажу её её с какой-то вероятностью можно найти но э на это неизвестно сколько времени уйдёт Итак второй вариант Разбираем с нашей системой Рейсинга с палантином значит по звонку значит находим сразу пользователей тут сразу и имена и айдини Значит мы нашли сразу пользователя нужного открыли и что мы видим значит внимание на нижний нижнюю строчку где повторяются такие красные палочки вот Дело в том что пара Красная и Серая палочка - это тот самый согласование sdp offer an и мы видим что они почему-то повторяются Дело в том что в обычной ситуации они должны были произойти один раз в начале и Ну если вот да включение скрин возможно вызовет вот это вот пересогласовать вот один раз это пересогласовать Но вот такое частое повторение этих палочек говорит о том что у нас по таймауту чего-то просто реконнект вот и дальше мы запоминаем тайм СМП который вот мы наводим мышку смотрим на тайм и дальше мы греем лок но греем Log мы уже более актуально мы уже знаем окрестность по времени Где нам надо смотреть и мы уже не смотрим по юзеру Мы в принципе смотрим Что происходит и мы находим в логах ошибку что tcp соединение установилось но по нему не было трафика и оно отвалилось Поэтому вот такие вот реконнект вот значит на этом я считаю разбор окончен то есть дальше будет починка дальше будет изучение почему такое произошло и починка но это уже делает разработка но инженер поддержки на этом закончил он выписал тикет на разработку и всё и Давайте сравним что получилось значит без панти мы потратили ну сделали вернее Пять шагов и потратили Ну много времени там условно там больше 30 минут с палан мы сделали три шага и потратили 5 минут Окей рассмотрим обращение номер два Значит пользователь Android приложения выкидывает из звонка такое вот обращение Значит есть айдини пользователя Итак что мы делаем консервативно есть пологам орые связа с эм пользователем у на есть и ничего не находим нет решительно ничего и что мы делаем мы включаем для этого пользователя логи у нас так можно не по серверу там вот а именно для пользователя врубить Вот и ждм воспроизведение а оно может не наступить или наступить или у другого пользователя наступить у которого мы не включили Деги а что же мы делаем с нтим мы шник пользователя есть вводим дишни пользователя просматриваем список его ивентов и натыкается на замечательную строчку Service unavailable вот опять запоминаем AMP и греем Лок вернее просто просматриваем Лок без репа по пользователю А по тайм смпу значит и наемся нав что оказывается его sdp было невадм вотще то есть дальше jav разработчик пойдёт выяснять Почему был эп но разбор с точки зрения инженера поддержки на этом закончен а Итак значит сравним без панти мы потратили три вернее сделали три с лишним шага Почему я написал Плюс Плюс потому что мы не знаем вот мы декло включили а что дальше мы просто не знаем Может быть там 10 шагов каких-то сделать значит времени мы затратили на самом деле неизвестно сколько И вообще говоря мы просто вообще ли это то есть мы включили декло и забили как бы на это мы неразбиваемый удаётся разобрать Но вот в среднем в пять раз это вот я считаю очень хороший результат дальше что увеличилось количество успешно разобранных обращений это то что мы видели сейчас то есть мы мы не разобрали предыдущий пример до конца мы соответственно стали разбирать больше третье мы стали вытягивать сложные случаи какие-то боль опять же всё равно остаются конечно гробовые какие-то вещи но в то же время увеличилось количество успешно разобранных и четв такой саэ инженерам поддержки стало легче работать Вот потому что и усилилась их мотивация потому что гораздо приятнее работать вот такой Тулой которая позволяет быстро всё найти чем целыми днями сидеть и грепан про планы развития то есть что мы ещё придумали что нам ещё не хватает Значит нам не хватает специфичной информации по медийке конкретно вот что мы умеем делать мы в процессе звонка умеем ня разрешение картинки Вот это нужно фиксировать сейчас чуть позднее объясню Зачем значит следующее мы умеем менять кодек Мы согласуем обычно три кодека и там динамически можем определить какой будет работать данную минуту Значит нужно отсвечивать когда поменяли кодек это достаточно важно третье значит хочется сетевые условия тоже отсвечивать Каким образом чит мы умеем измерять и понимать Какое состояние сети пользователе сечас хочется подсвечивать на таймлайне что вот здесь Красноя здесь У пользователя плохо здесь Зелёная здесь хорошо и всё Это для того чтобы как раз понимать Работают ли наши вот эти вещи как изменение разрешения как значит измерение замена кодека например Работают ли они адекватно в правильные ли они моменты времени срабатывают или нет Значит тоже относится к индикатору сети это мы показываем пользователю вот тоже хочется понимать мы адекватно показываем или неадекватно следующий момент длительность хранение я упоминал что мы храним трейс в течение 14 дней для некоторых обращений этого недостаточно Хочется больше но мы для всех больше не можем сделать потому что у нас тогда не хватит базы данных Вот Но для некоторых звонков Хочется подкрутить вот чтобы было больше например месяц или ещё больше вот килер фича сохранение файл то есть сдам фай приложить к кету И вообще не привязываться ни к какому ТЛ Было бы очень здорово последнее - это пользовательские оценки Дело в том что мы в конце звонков в конце звонка просим пользователя оценить качество звонка Ну от традиционной звёздочки от одного там до пяти от одной до пяти звёздочек хочется соответственно в трей тоже это включать чтобы можно было отфильтровать допустим найти все плохие звонки Вот примерно так сформулировать Вот и тоже касается так называемых проблем но это связано со звёздочками это когда маленький рейтинг да то есть одна звёздочка например просит А что было плохо да там выбираешь там не было звука например были проблемы со звуком Вот это тоже хочется видеть А ну и значит ещё раз коротко то есть нам не хватает сейчас пока по медийке информации не хватает информации состояния сети хочется увеличить длительность хранения и пользовательские оценки тоже видеть в рейсах и мы приближаемся к завершению доклада что хочется сказать в итоге Значит мы построили систему которая хранит и систематизирует И визуализирует для нас э Вот все наши события в звонках значит а она упрощает м собственно нашу работу по поддержке наших пользователей э и примерно вот я уже эту цифру говорил примерно в пять раз ускорилась наша работа по разбору обращения система в первую очередь ведь эта система позволяет именно рутинные операции сократить то есть понятно что есть сложные вещи надо воспроизводить надо там что-то Там дебажить код Там и так далее Это сохраняется но рутинные операции Эта система фактически берёт на себя во многом И последнее Это интересный такой сайд эффект который был замечен Дело в том что тестировщики нередко пользуются этой системой когда допустим разрабатывается новая фича соответственно тестировщик что-то на одном клиенте делает по другом ожидает какой-то эффект и он не просто БК боксом тестирует а он подсматривает палантир а побежали ли нужные события Были ли нужные команды или их не было и может предъявить разработчику более детально проблему если она есть А на этом У меня всё пожалуйста голосуйте за мой доклад это крайне важно и для программного Комитета и для меня лично ваши вопросы Алексей Благодарю тебя за доклад маленький по подарок от о и от генерального спонсора компании Газпром воспользуюсь пра ведущего Откуда появился потому что он меня слегка пугает это лалин колец Джон Рональд л Толкин это он придумал то есть совпадение система американских служб безопасности это атно номе одном из система и у нас первый вопрос так ну давайте я тогда видимо микрофон вы сказали что видеосвязь должна работать Даже дрессировка упала во-первых Были ли такие случаи А во-вторых в связи с этим есть вопрос А кто следит за палантином упал ли он значит палантир так значит пер первая часть вопроса пока ещё не падало но мыс в лаборатории проверяли что ничего не случится значит А ну на продакшене пока не падало значит а следит мониторинг ровно тот же который за продано просто ну график рядом есть который за паром следит Ну и следят соответственно но инженера у нас второй вопрос Да у меня два вопроса Первый вот сразу был такой дисклеймер что вы не читаете логи клиентов вот мне было интересно нет ли каких-то планов по поводу того чтобы Например если пользователь Поставил оценку один просто включать сразу дены логи и ну как-то понимать эти Ну получать Вот это первый вопрос а предлагаю по очереди Да а то Да можно это стек переполнить вопрос значит А отвечаю Так мы хотели бы смотреть клиентские логи нам просто их не всегда присылают это же клиент должен взять несколько фай Ну либо этот самый из браузера хар выгрузить либо десктопе взять несколько txt файлов и зази пова их это под силу не каждому пользователю и не каждый мотивирован это делать поэтому нас просто часто до нас не долетают логи мы бы хотели их получать А вы не думали этот момент автоматизировать что приложение само сло логи Да идеи есть э но есть этому некоторые нюансы вот сейчас не хочется погружаться Не факт что просто удастся льная тема Или будем ждать закладом нам Hell и следующем и у нас вопрос Можно ещё второй вопрос Да вот ещё был вопрос Ну тоже такой про планы скорее А почему не сделать планти как бы автоматическим Вот и сейчас я понимаю все люди которые пользуются поддержкой они просто ходят точнее решают вопросы поддержки они ходят в палантир тыкают какие-то кнопочки и так далее Почему бы не сделать то же самое только Ну автоматически подгружать данные из планти нет Так а это они данные по всем звонкам уже и так пишутся не нужно запрашивать как бы запись для конкретных юзеров это если об этом вопрос Это уже сделано а для просмотра Ну какп какой-то надо же сделать Ну SQL запрос хотя бы написать а тут UI есть специальный то есть А как ещё автоматизировать лучше можно сделать не как бы не UI а просто буквально сразу сходить в сервис и забрать данные грубо говоря фа вот вот это и делается в несколько кликов раз-раз и всё и данные на это кки это клики которы колеги это отличная тема для обсуждения мо можем обсудить позже а у нас следующий вопрос Да у меня такой небольшой вопрос Вот вы говорили что палантир внедрили у тестировщиков соответственно Есть ли у вас планы по внедрению палантир как часть квалити гейта для оценки того насколько эффективен релиз приложения будет то есть насколько вы эффективный код написали на этот раз Угу Ну скорее всего вся icd не будет включён потому что это всё-таки ручная ручной просмотр вот этих вот самых э вещей Вот но в целом наверное можно автоматизировать именно проверку отсылаю ли нужные ивенты это и Спасибо за идею в целом наверное да это стоит проверить пока он он плох поскольку Это внутренняя Тула она проверяется так по остаточному принципу и у нас следующий вопрос Алексей спасибо большое за доклад вопросов четыре я все сразу не буду задавать один У нас очень мало времени А ещё много желающих Почему не омет смотрели ли в сторону омет и смотрели ли в сторону dist рейсов и смотрели ли в сторону отправки ивентов клиента в тот же самый трейс у значит не смотрели почти не смотрели на готовые вещи Потому что всё-таки есть определённая специфика это вот эти вот наши события и плюс был положительный опыт в другом проекте то есть грубо говоря разработчики уже имели опыт в другом проекте я сам лично имел опыт поэтому сделали Как умели как знаем что точно хорошо Вот честно говоря особо на Open sce не смотрели вот с клиентов пока не собираем потому что нужна тогда точка входа Ну endp который надо конфигурировать согласовывать то есть мысли есть пока думаем Надо ли не надо всё равно на бкн оно доходит по большому счёту итак по сигнали нам то что нужно поэтому может и не надо даже А distributed что что если трейс проходит сквозь несколько сервисов Ну сольётся в итоге всё равно в нашу в базу с рейсами Ну то есть отдельно не трекать Нет нет спасибо И у нас следующий вопрос Алексей спасибо за доклад у меня один вопросик Вот вы показывали примеры разбора с нтим и без меня вот смутил немножко момент показали что мы смотрим по логам вот в обычном варианте без панти и ничего не находим а потом в панти хоп всё есть так может быть вопрос в том что раньше в логе писалось недостаточно информации и просто расширив логи тоже самое быстро ключевой момент быстро логи были связаны с айдим пользователя например то есть на что мы греем а не всегда это не всегда происходит то есть например есть какой-то Ну вот Exception случился и Java его выкидывает без привязки к айдини вот а по ашнико всё греется хорошо но сейчас получается разработчики же писали этот трейсинг так чтобы эта связка была и не совсем Мы в панти видим тайм когда была проблема и смотрим все логи за это ки Exception и у нас следующий вопрос Спасибо Здравствуйте спасибо за доклад А подскажите какой процент от объёма логи палантир занимают от общих логов А смотрите это не логи это они пишут что в кассандру Вот то есть это ну некоторые специальные трейс Я прямо в гигабайтах точно сейчас не скажу но это отдельная база данных стоит и она в общем-то нас не напрягает тем что она там живёт Спасибо И у нас следующий вопрос Спасибо большое Алексей отличный доклад у меня возник такой вопрос из-за того что мы видели некоторые дженки в ки возникло ощущение что сервисы передают эти рейсы сервис который там их ксит до базы в виде формата JS правда ли это или в каком-то более Ну практично в бинарном формате А значит Понти R архивируемых и в базу попадают уже в сжатом виде Угу спасибо Вот и у нас финальный вопрос финального доклада финального дня а Привет Игорь ВК тоже есть здесь Угу я встану а считали по деньгам насколько дороже ваши сервисы с этим волонтира ну как бы эксплуатировать то есть сколько там цпу памяти Ну скрупулёзно не считали но я думаю что там порядка два наверное разница то есть у нас в 100 раз больше серверов наверное вот ну взять палантир там вот посчитай я там приводил цифры сейчас в уме быстро не Сосчитай Ну там условно там 10 Да на всё про всё А на продакшене у нас там 1.000 серверов например ну то есть несоизмеримо Меньше палантир несоизмеримо меньше по ресурсам занимает чем основной сервис То есть просто рядышком стоит ниче страшно Спасибо всем спасибо за вопросы Спасибо что пришли к нам на доклад и последний традиционный вопрос Выбери Два лучших вопроса один подарок от спикера другой Да у меня значит вот первый такой вот да от на От нас от ВК значит мне хочется его отдать молодому человеку который спросил а падал ли палантир на продакшене вот и что вообще вообще Тентен вообще надо бы Страшно конечно да вот но поймал меня немножко на том что я тут вот требование выполнено выполнено проверял в лаборатории проверял А на продакшене Неизвестно что и у нас второй приз беленький пакетик Да вот мне понравился вопрос что хорошо бы трейсинг включать в тестирование может быть в fcd может быть в регрессию надо тестировать это в общем мысль очень правильная да L"
}