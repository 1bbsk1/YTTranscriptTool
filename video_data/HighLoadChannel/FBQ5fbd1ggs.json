{
  "video_id": "FBQ5fbd1ggs",
  "channel": "HighLoadChannel",
  "title": "Зачем разработчику статистика, или как улучшить качество продукта? / Юрий Лилеков (Badoo)",
  "views": 2862,
  "duration": 2916,
  "published": "2019-06-03T09:07:12-07:00",
  "text": "меня за юри лелеков тоже занимаюсь из них четыре с половиной года еду и все это время это продуктовая разработка то есть создание новых продуктов и усовершенствования уже существующих немного ободу это 390 миллионов пользователей примерно на данный момент примерно 12000000 онлайн ежедневно и недавно мы подбили такой психологический барьер как один миллион событий статистики в секунду к слову это в целом вообще для разработчиков для аналитиков и для produce менеджеров этот доклад о том зачем нам такая статистика и амиду статистика для разработчиков как ее собирать на примерах из баду и как мы с ней в дальнейшем работаем и так поехали зачем нам такая статистика для этого немного немного нужно разобраться в процессе разработки году а именно в создании новых продуктов году и to do the driving a development company то есть в начале продакт-менеджер и собирают существующую статистику анализирует различные flow ищут пути улучшения или создание новых фич и смотрят что должно быть востребованы пользователями далее они создают перди product реклам с документ в котором описывают основные требования разработчик их имплементировать после чего мы изучаем полученный результат то есть опять же анализируем статистику и так далее по много-много итерации кто самый главный ответственный с технической точки зрения во всем этом процессе продакт-менеджер и не знают различных технических деталей и они в основном заняты проектирование основного flow разработчику довольно-таки непроста предугадать различные технические нюансы пограничные кейсы все остальное and а также заняты реализацией основного flow фича тестеры и тесты тоже не панацея это лишь инструмент для того чтобы помочь разработчику найти какие-то проблемные места выявить их но они не гарантирует того что после въезда новые фичи на продакшен все будет хорошо и так разработчик он ключевое звено он несет ответственность за реализуемую фичу с технической опять же точки зрения ему нужен какой-то инструмент который позволяет позволит ему держать ситуацию под контролем и так статистика для разработчика у нас под очень много различной статистики для у нас есть целый отдел аналитиков называемый биой там работает несколько десятков человек которые изучают можно сказать все что можно изучить есть отдельная продуктовая статистика но нужно еще почему нужно еще потому что во первых разработчикам нужно краткосрочная статистика то есть то что произошло за последние пять минут диаметр количество событий или за последние 10 минут по большому количеству разрезов для того чтобы видеть различные пограничные случаи и самое главное эта статистика нужно быстро опять же в течение 5-10 минут так как продуктовый имя и статистика на обычно собирается часами и анализируется и на текущий день основная вся статистика для аналитиков доступно там за предыдущий день а как же логе спросите вы да логе содержит детальную информацию они позволяют разобраться в каких-то там уникальных случаях они довольно детальны но их относительно тяжело агрегировать а также тяжело мониторить а как же мониторинг до мониторинг это необходимая составляющая особенно в плане контроля за техническим состоянием серверов еще чего-то но это недостаточно мерам например мониторинге довольно сложен выставлять лимиты по различным разрезом статистики для того чтобы собственно горя контролировать их все и к тому же мониторинг не не имеет хороших инструментов инструментов для анализа всего этого это совершенно отдельная статистика спросите вы да части это совершенно отдельная статистика она может быть реализована как отдельными инструментами специальными для того чтобы быстро доставлять события так и совершенно иметь отдельный интерфейс и но и нет одновременно потому что некоторые события которые разработчики могут начать писать с точки со своей то с точки зрения технические события могут в какой-то момент заинтересовать product менеджеров или аналитиков или там еще кого-то и поэтому эти события могут начинать отправляться в разные хранилище и опять же могут быть построен эта статистика для заводчик может построено уже на каких существующих инструментах которые используют аналитики как собственно говоря это помогает улучшить продукт и разработчики в первую очередь быстро узнают об какой-то проблемной ситуации на продакшене и соответственно есть набор инструментов который позволяет легко находить причины возникновения этих ситуаций по этому разработчику нужна своя отдельная статистика давайте посмотрим как собирать подобную статистику и в каких-то на каких-то примерах из буду немного пройдемся по основам и так у нас есть какое-то событие что-то произошло что нам нужно сделать в первую очередь сохранить его для того чтобы потом где-то отобразить ну допустим это будет счетчик аутентификации пользователей для простоты и в дальнейшем я буду просто говорить логинов пользователей вот у нас есть пользователи он логиниться мы будем просто брать и записывать количество аутентификации в какую-то табличку в одну строчку и просто in crime тилль будем каунтер у нас все идет хорошо каунта растет мы периодически его поглядываем но какой-то момент мы видим что аккаунт у вырос очень резко и у нас нет понимания того в какой момент он вырос и для того чтобы в будущем это понимать нам приходится придется теперь начинать писать и таймс темп этого события а события хранить ни видика утра в виде таблички по одной записи на каждое отдельные события теперь у нас все хорошо мы можем построить график на котором мы отобрали отобразить эту метрику собственно говоря нарисовать но в какой-то опять же момент мы столкнемся с примером подобной картины мы видим некие пики и нам не понятно что это за пике мы лезем блоге начинаем анализировать что произошло тратим на это много времени в конце концов выясняем что на самом деле эти пики были вызваны каким-то одним или какой какой то небольшой группой пользователя остальных пользователей все нормально поэтому нам нужно важно уникальность события u1 потому что одно событие может произойти много раз в одного и того же пользователя теперь с этого момента начнём писать в наш в нашу табличку событиям еще идентификатор пользователя будущем построив график уникальности пользователей мы поймем что на самом деле количество уникальных аутентификации не выросла что-то было с каким-то там иди на одиночные пользователями и это в будущем сэкономит нам много времени вы спросите уникальность относительно чего может быть не только относительно пользователя но и относительно какого-то объекта взаимодействие это зависит от самой фичи как она что что в не сделанный что важно логировать например это может быть какая-то фотография которую просматривает пользователь и вы можете писать идентификатор потока фотографии для того чтобы понимать события возникает какой-то одной или со многими фотографиями время большое количество событиями и так следующее что мы будем писать это место где произошло событие к там это может быть имя сервера приложения страна если у вас мультинациональный сайт а также то с кем с чем произошло событие то есть у нас уже есть пользователь они могут быть какие то свои хвост свойства полна примера или возрастная группа а также объект с которым пользователь взаимодействует например где чат с другим пользователям или опять же просмотр какой-то фотографии и свойства опять же этих объектов вы зададитесь вопросом писать теперь все на самом деле писать нужно только то что реально нужно и поможет вам в дальнейшем расследование каких-либо инцидентов но если ваши ресурсы позволяют вас есть много места то лучше писать больше и потом быстро удалить эту ненужную статистику если вы упретесь по размерам откуда писать события ну в первую очередь с бэг-энда то есть из контекста запроса пользователя браузер обратился на сервер или из бэкграунда когда какие-то скрипты работают по крону или обрабатывается какая-то очередь задание и там происходит также какие-то события но давайте предположим что у нас есть под следующий случай пользователь пытается залить видео на сайт и у себя в статистике увидите что с этим процессом все хорошо вы видите что веб-сервер передал скриптом там собственно говоря сам файл вы его обработали залили ново начнут начинает поступать жалобы о том что некоторые файлы не грузятся вы смотрите свою серверную статистику видите что с загрузкой все хорошо никаких проблем нет но чуть позже выясняется что у многих пользователей процесса плода файла отваливается с ошибкой connection тайм-аут потому что они используют мобильный клиент с очень медленным соединениям пытаются залить большое видео и в итоге просто по таймауту соединение отваливается и максимум в эту ошибку увидите в логах веб-сервера поскольку оно не доходит до скриптов поэтому мы событии будем писать еще из клиентов и например фронтэнда через специальный веб-сервис то есть клиент перед тем как начать оплот файла он отправляет события на сервер говоря о том что я начинаю загрузку файла соответственно по окончании отправляет события о том что загрузка закончена а дальше мы построим из этого из этих двух событий графики и можем сравнивать насколько успешен этот процесс загрузки файлов а еще откуда будем писать события а из ниоткуда собственно говоря что это такое ни от куда и откуда его взять это анти событие анти события это как анти-материя то есть анти события слаб при сложении со слабым образует на у а именно иногда лучше писать события анти события заранее чем потом что-то считать например отсутствие реакции на письмо последний месяц очень актуальна тема jedi pr поднимите руки те у кого в компании приходилось расслабь письмо связанные с этим законом довольно таки много я ожидал меньше собственно говоря что такое jedi pr pr это закон европейский наподобие нашего закона персональных данных но более проработанный суть заключается в том что собственно говоря всем нужны об и деталь не относиться к хранению данных и связи с этим аккуратнее относиться к хранению данных связи с этим многие компании отправляли письма своим пользователям с информации несоответствие представим ситуацию что мы отправили это письмо и нам нужно понимать реакцию пользователей на это письмо а именно их клики по ли по ссылкам в письме через какой то промежуток времени или наоборот отсутствие кликов как же можем посчитать отсутствие кликов но мы можем взять посчитать количество tarp отправленных писем там потом бы построить график по ним потом построить график количества кликов по этим письмам а разница высчитывать визуально но мы должны понимать что по на временной шкале это будет не самая правильная информация потому что письмо мы отправили когда-то давно клик был сейчас и непонятно какому к какому письму тогда относится этот клик сейчас поэтому в процессе отправки письма мы можем в какой-то очередь записать задание говоря которая будет обработан и чуть позже там через час через два через три и которая проанализирует о том была ли совершенно тогда клик или нет если вы не было то это задание отправит нам статистику анти события говорящий о том что например там через час не было клика по письму и в дальнейшем нам лишь просто остается построить график поэтому анти событию вместо того чтобы там утруждать себя считать пытаться выяснить по каким в итоге письмам были в клике по каким по каким не был итак представьте вот к нам на сервер пришел за просьба запрос браузера пользователя произошло какое-то событие и нам нужно его куда-то записать начнем с самого малого представьте что у нас есть некая нормализованная база данных который все красиво это так называемая топология звезда у нас есть в центре одна общая табличка фактов которые 1 события равняется одной строчки до табличка небольшая в ней только находится айдишники а все остальные данные у нас лежат в отдельных табличках справочниках все красиво все замечательно но нагрузка на сервер растет количество событий растет в какой то момент мы понимаем что контексте запроса пользы пользователя нас уходит очень много времени на для того чтобы во все эти таблички вставить запись по одному лишь событию мы начинаем думать как это оптимизировать и решаем где нормализировать базу данных стало не так красиво зато стала чуть чуть быстрее потому что нас только одна операция в 100 тв приставки в таблицу пожертвовали местом на диске потому что место стала занимать больше но она дешевле и так растем дальше табличка растет там 10 миллионов записей сто миллионов записи мы понимаем табличка начинает тормозить что-то надо с этим делать ну начинаем шарди табличку в начале по годам потом по месяцам по дням когда табличек совсем стала многое и количество событий тоже большое мы шарден же по серверам но что же дальше в итоге как как начать писать быстрее б д пишет на самом деле на диск зачем нам писать б.д. мы можем сразу писать файлы на диск стоит отдельно отметить что в каждом вашем допустим случае может быть какое-то свое решение нам нам выгоднее писать на диск в вашем случае допустим начали может быть сейчас нормализованные таблички устраивают а может быть где нормализованы это как бы не идеальные идеальное решение не говорю что нужно так делать все зависит именно от вашей ситуации и так мысе падут пишем на диск файлы а есть ещё какие-то варианты мы можно написать записать в память можно закинуть пакет все эти пою т.п. потому что это опять же стоит дешево но мы пишем в самые обычные простые файлы далее пытаемся оптимизировать еще представьте нас пришел пользователь в контексте запросы пользоваться у нас кидается несколько событий собственно говоря как мы можем еще сэкономить хотя бы даже здесь на спичках в итоге мы все эти события не пытаемся тут же записать мы их отдельно в этом же процессе откладываем в память и только после того как мы собрали все необходимые данные для запросы пользователей отпустили его только после этого мы пишем все эти события на диск и опять же пишем одним пакетом они поштучно и так мы пришли к ситуации когда у нас есть некие там пап сервер или веб кластер и ее статистика пишется файлы на диске как доставлять и причем здесь франц кафка с лсд зачем куда-то доставлять ну потому что у нас все эти файлы лежат на в кластере они там мешаются и мы решили обраб обрабатывать их отдельно и а именно централизовано где-то хранить и потом оттуда их читать чем будем доставлять на самом деле существует огромное количество решений тир syslog кафка блок с ташей много-много-много всего остального мы в ободов силу некоторых исторических причин изначально стали использовать скраб но потом были вынуждены от него отказаться потому что проект оказался заброшен через какое то время и мы сделали собственный инструмент называется он лсд live streaming демон ссылку на него здесь можете посмотреть в конце будет ссылка на доклад если вы вдруг сейчас не успеете запомнить собственно говоря что в нем хорошего во первых клиентов основном ему не нужен во-вторых он очень прост в конфигурирование ну и доступность надежность вот это вот все куда ж без этого собственно говоря на гитхабе там все подробно описано если заинтересованы сходите посмотрите куда будем доставлять доставлять будем на отдельную машину или кластер что же мы будем делать дальше а это зависит от того как мы хотим хранить эту статистику мы можем хранить сырые данные они будут занимать много места их нужно будет читать при отображении там складывать там и группировать еще как то каждый раз при каждом просмотре и но зато легко посчитать каун distinct то есть есть данные допустим где-то там мы сквозь базе данных или chef какой там эккаунт distinct уникальных событий посчитали это бразилия либо мы будем хранить агрегаты нашем случае они занимают заметно меньше места не нужно много вычислять максимум их придется там где-то складывать для того чтобы отобразить графике но аккаунт distinct невозможен потому что если у нас есть два соседних агрегата по пять минут и в первом произошло событие с пользователем и во втором тоже произошло если мы их сложим нас будет два события на самом деле у некоего в плане уникальность это событие было только с одним пользователем какие агрегаты считаем собственно говоря нужно понимать что эта статистика для разработчика и нам важно отображать очень детальную статистику первое время самое первое время вот например на этом графике регистрации видно что график довольно таки точно нарисован по дням но с течением времени когда мы видим что никаких аномалий на графике не было нам эта информация становится нужно не такая подробно и гораздо меньше поэтому через месяц мы уже будем отображать часовые агрегаты а не 5 или 10 минутные а через по прошествии четырех месяцев мы можем вообще просто отображать суточные нам этого будет вполне достаточно поэтому мы считаем 5 или 10 минутные агрегата зависит от событий если нужно прям очень детализирована и событие топите если нет то 10 часовые суточные ну и считаем естественно по нужным разрезом так называемым метрикам то есть допустим одна метрика это там количество событий произошедших там на определенной платформе в определенной стране там с определённым полом определенного типа события ну и так далее как еще мы будем обрабатывать эту статистику ну во-первых считаем минимальным максимальное количество средний сумму а также медиану перцентиле и остальную и заодно еще считаем уникальность по алгоритму гипер лак лак этот алгоритм позволяет с довольно приемлемой точностью посчитать уникальность которую нам вполне достаточно для того чтобы отображать на графиках информации о немного есть в интернете если заинтересованы и можете посмотреть почитать где будем хранить специализированных там серии из баз данных есть очень много опять же различных решений графит up and sdb есть более общее решение наподобие клика усы elastic search а про ними по ним есть много различных выступлений статей всего остального но у нас поскольку все это начиналось больше десяти лет назад изначально мы использовали rrd это round robin дтп с помощью не уже рисовали графики а потом стали использовать кассандру подробности причин и перехода вы можете почитать в отдельной статье про это ссылка на статью будет в конце а теперь поехали дальше чему же мы пришли в итоге временно мы события пишем на диск в контексте запроса пользователя для того чтобы не не отбирать у него много времени на ответ доставляем эти события агрегирует считаем и сохраняем в кассандра что же мы дальше с этой статистикой делаем ну и и естественно отображаем во-первых изображения лучше всего воспринимаются в отличие вот таблиц текста и от всего остального плюс классические графики довольно таки эффективны в плане воспринимаем асти а также нам разработчикам позволяет визуализировать информацию о том что там лежит в базе достаточно посмотрев на график как именно будем отображать ну например примерно вот так слева у нас будет фильтры для выбора нужного разреза сверху там меню для быстрого доступа к нужному интервалу соответственно справа и вниз буду в графике какие значения мы будем отображать абсолютные или относительные естественно абсолютно и мы хотим видеть реальные цифры о том что произошло но иногда лучше показывать и относительные в том числе например представьте себе точнее представьте посмотрите на этот график релиза версии мобильного приложения для айфона мы довольно таки часто релизимся примерно раз в неделю и соответственно новые версии выходят и вытесняют старые версии но на этом графике не совсем понятно собственно говоря что происходит если мы построим относительной графика на котором покажем об относительной участие каждой версии относительно сто процентов здесь более понятно становится видна о том как новой версии выходит и вытесняют старые версии приложения ну и где-то вверху там часть пользователей которые ни в какую не желают апгрейде цени при каких условиях это продолжает пытаться использовать старые версии для чего мы строим графики собственно говоря мы графики строим для того чтобы видеть на них какие-то изменения либо и хоть не видеть первое что мы увидим это суточные изменения на данном графике изображена информация за двое суток отчётливо видно как в начале дня график растет доходит до некого пика вечером и потом ночью обратно опускается недельные изменения где видно что понедельники пир в понедельник в начале недели пике более высокие вечером а к выходным пике сглаживаются но зато активность течение дня гораздо больше ну и соответственно мы нарисуем trendline который покажет нам что собственно говоря в основном с графиком происходит растет он или падает чтобы примерно на глазок не вычислять где больше где меньше ну и следующие интересные изменения с которыми сталкиваемся это потолки на графике еще мы их называем полками подобные графики зачастую говорят о том что есть какая-то проблема с производительностью на сервере на кластере и при достижении какого-то пика начинает происходить что-то не то соответственно после прохода после того как активность пользователей начинает падать мы выходим за этого состоянии дали график выравнивается ну и самое интересное чего мы собственно говоря ждем это резки различные резкие изменения на графиках как легче всего выясни выяснять причины этих изменений то есть что-то пошло так или что-то пошло не так нужно на это реагировать не нужно реагировать нужно узнать причину и собственно говоря разработчик первым делом видя этот график задается вопросом что это такое вот и faq-и это послужил началом к созданию отдельной системы которая хранит в себе информацию различные события в базе данных и отображает их на графиках и мы и решили так и назвать в cfd faq выглядит это примерно вот так не есть некий график на нем есть вертикальные линии показывающие каких-то произошедших событиях и в ней внизу есть более детальное объяснение о том что это произошло за событие какие-то ссылки для чтобы детальнее его посмотреть точно говоря в базу для этого инструмента первую очередь мы раз мы добавили различные внутренние события это релизами мобильных приложений изменения канкан конфигурации downtime и прочие различные события на этом графике например был релиз мобильного приложения году на котором видно что изначально фича была раскатана включена лишь для десяти процентов пользователей а потом ее после релиза включили на оставшиеся части графики по фичи я резко пошли вверх здесь видно техобслуживание и downtime соответствие это некий интервала в течение которых могло что-то происходить не так с каким-то инструментом естественно пытаемся предугадать и все сделать правильно но иногда бывает что это не так или вот здесь интерес довольно интересный график и собственно говоря что произошло вот д факт на графике видно что количество аутентификации через facebook начало резко падать и даже начал раз немного расти количество то дефекации через google многие из вас наверное в курсе о том что фейсбук испытывает некоторые проблемы и поэтому они довольно резво меняют свой и пей даже порой не предупреждая тех людей тех разработчиков которые с ними работает и примерно такое случилось начале апреля они резко изменили не только потом поставили всех остальных пост-фактум о том что у них что-то изменилось а что именно они поменяли и пьянь и были некие проблемы с аутентификации или еще один интересный график это это график онлайн of для пуэрто-рико и мы видим что здесь что-то пошло не так опять же к сожалению это событие было почти два года назад и более детального графика не особо не сохранилось только суточные агрегаты но даже на них отчетливо видно большое проседание что произошло на самом деле пуэрто-рико это остров и у них есть только одна единственная электростанция которая обеспечивает этот остров электричеством случился пожар на этой электростанции и собственно говоря многие пользователи остались без электричества и не могли посещать нас наш сайт и включать мобильные приложения собственно горя внешней забывает внешние события технические различные внешние сервисы от которых будет зависеть ваш продукт и от которых в том числе зависит году и различные техногенные аварии бывают еще внешние события социальные футбольные матчи например различные религиозные праздники на них вы зачастую также от отражаются различные изменения они также влияют на работу вашего сайта приложения в том числе нашего будут и также их видно на многих графика здесь например график онлайн и в германии и если вы посмотрите на синие график на нем видно что после 18 часов есть две небольших ям и этих 2 небольших ям и на говорят о футбольном матче клуба баварии с каким-то еще кубан не помню к сожалению и 1 мая это первый тайм горб между ними это перерыв и 2 мая то второй тайм поэтому очень много событий происходит которые мы не можем заранее предугадать их нет в базе данных естественно добавили интерфейс добавления событий через который разработчик разобравшись с проблемой проанализировав в логе и выяснив причину или какие-то новости он может сразу до бытия события это добавить в интерфейсе для того чтобы остальные не тратили время на поиск проблем и так же у нас есть инструмент сравнения естественно графиков на которые мы можем отобразить графики за предыдущие временные периоды например за прошлый день или за прошлую неделю для того чтобы понять изменение это регулярное или нерегулярные на не надо как-то реагировать либо можем сравнить график события с другими событиями но несмотря на все это есть сложности в отслеживание изменений почему это собственно говоря сложно вот представьте у нас есть только одно один какой-то тип события допустим аутентификация также у нас есть четыре платформы например мобайл веб мобайл веб ios и android 250 стран хотя это на самом деле больше 10 приложений и того у нас уже 10 тысяч разрезов то есть метрик который нужно считать отдельно где-то отображать соответственно есть проблема в том для того чтобы мониторить все эти метрики все эти разрезы разработчик должен заниматься написанием кода а не сидеть и постоянно смотреть эти графики и даже если эти изменения даже записать чистую не видно на основном графики они где-то где-то кроется в детальных раз разрезах но даже если видно и на основном то очень тяжело меняю фильтр разрезов понять какой же именно разрез дал такое аномальное поведение и поэтому мы решили воспользоваться таким инструментом как anomaly detection мы перепробовали несколько различных существующих уже на рынке инструментов но к сожалению многие из них не устраивали по различным параметрам и поэтому мы взяли готовую библиотеку которое позволяет отслеживать аномалии с учетом различных колебаний натравили и на большое количество своих собственных метрик написали для нее интерфейс и примерно это выглядит так то есть разработчик заранее задавая какие-то свои фильтры по разрезам может видеть эти аномалии причем самый сильный anomaly он видит наверху менее значимые видят ниже при этом anna malle этот экшен учитывает обычные суточные недельные колебания понимая что как бы нет смысла по ним alert потому что это ожидаемое поведение ну и соответственно нам пришлось долго поработать с порогом срабатывания особенно на графиках по которым очень мало событий для того чтобы зря не беспокоить разработчика и тока аномалии detection это далось нам не просто мы больше года затратили на раза на разработку но это довольно эффективно как же мы работаем в итоге со статистикой на следующем слайде было много текста но в самый последний момент я решила заменить на реальные скриншот из корпоративного чата из корпоративного мессенджера утром приходит разработчик видит аномалию в мексике не понимает что произошло задает вопрос может быть кто-то знает соответственно первое подозрение особенно на два часа что это футбол но выясняется что на самом деле проблема была в мексике с провайдером течение двух часов и 3 разработчик берет не добавляет информацию об этом вот так вот примерно так мы работаем то есть на выяснение мы увидели аномалию и на выяснение причины затратил за тратилась на там порядка восьми минутами что же получилось у нас в итоге мы пишем отдельную свою статистику для разработчиков быстрое и доставляем быстро анализируем быстро реагируем на возникающие проблемы качества продукта от этого растет компания получает прибыль техническом плане у нас получилось то что мы пишем больше 400 тысяч различных разрезов в секунду это только для статистика для разработчика больше 30 серверов надо намин 23 терабайта данных это только кассандра не считая аналитиков не считая продуктовой статистике всего остального дополнительные материалы ссылка на статью евгений губочки на о том почему мы ушли с rrd и в итоге стали использовать кассандру ссылка на доклад валерия старыгина по поводу stats коллектора это доклад 2014 года там много очень интересных моментов совету его тоже посмотреть и доклад по поводу не рыл time аналитики высоконагруженных проекте александр крашенинникова александр сегодня здесь с нами поэтому если у вас будут вопросы какие-то вот прям с губа по вычислениям довольно таки глубокие платформенные то он тоже с радостью ответит на ваши вопросы спасибо а сейчас вопрос и самая ценная на конференции напоминаю по одному вопросу на участника если есть дополнении и уточнении в кулуарах теперь нужно будет выбрать лучший вопрос сможешь да замечательно здравствуйте просто интересно у есть вас детектирование аномалий по отдельному пользователю в целях там может быть безопасно по отдельным уникальному пользователю нет более того я вам скажу что мы не храним айдишники пользователей в статистике мы в процессе передачи пользователя в статистику мы заменяем идентификатор на неких ешь для того чтобы по статистике нельзя было познать кто именно это был например поэтому кто именно получается нельзя но похожу все-таки можно по кабану агрегировать получается метрики относящиеся к одному пользователю так ну если вы говорите про какие-то инциденты то в основном мы используем для этого логе для того чтобы понять что произошло а если как бы в целом про качество продукта что если есть где-то проблемой пользователя с ней сталкиваются то и это видно ни в контексте одного пользователя это видно по группам пользователей сразу по графикам прошу вас такой вопрос у нас пока она вам помогает вот в анализе внутри проблем то есть большинство примером которые привели это были матчи какие-то события пожарин и электростанции а какой процент вот вот этих аномалий приходится на ну то есть на то что вы можете исправить какой процент я так не могу на это ответить потому что бывает очень много аномалий на всякие внешний по всяким внешним причину особенно внешним сервисом с которыми мы работаем но в целом скажем так и аномалий мы видим даже если какие-то внутренние причины мы видим их очень быстро вот иногда счет идет то есть и особенно если это релиз серверного кода новый то разработчики обычно сидят и смотрят на графики параллельны в том числе чтобы держать руку на пульсе и изменение они видят там в течение пяти или десяти минут вот больше времени тратится на поиск реальной причины все же потому что иногда по сну событий известны build новый уехал уехал новый код и тут нужны видно допустим днем искать проблемой нужно смотреть в код выяснять что идет не так и в том числе используются другие различные метрики чтобы понимать допустим если есть у нас какой-то flow и пользователи где-то спотыкается на каком-то шаге то соседние события позволяет понять где именно проблемы после больше простите оля здравствуйте спасибо за доклад вопрос такое футов а катя не данные о событиях из кассандры и накладывает на график событий которые в нее занесены верно ну вот фак грубо говоря отдельная база своя там для событий не нужна не нужна кассандра можно и мускуле держать неважно где просто есть одна база в которой централизовано складываются все внутренние события релизы клиентов все остальное про и оттуда мы подтягиваем и рисуем на графиках параллельно это не highload задача события то мне не тысячи в час поэтому вода пока хранят событий типа мы зарелизили футбол германии там пожарной электростанция да да да и потом при когда вы рисуете график вы берете эти события оттуда там события вот по пользователям из кассандры все это накладывайте рисуйте как спасибо коллеги прошу вас так спасибо за доклад вы говорили что на разработкой системы потратили около года или что-то около того как вы это аргументировали для начальства ну потому что обычно все хотят чтобы все решали задачи они занимались тем что облегчить жизнь разработчиков ну во-первых мы выдели отдельно команду назовем так который занималась именно этим вопросом потому что начальство понимало что потом это окупится потому что начали мы опробовали некоторые уже существующие системы они нам помогали но в них были свои минусы и поэтому решили потратить на это время спасибо юрий раз спасибо за доклад я хотел бы спросить вас очень красивой графики вот но как вы сами говорили то что разработчик сам за это все ответственны да и такой вопрос кто решает что логировать но не что лакировать а какие винты кидайте новые фичи то есть иногда же разработчик он не обладает достаточно экспертизы ли достаточного опыта чтобы знать то что вот тут вот получу вот это покидать и также кто тут опять тоже кто решает какие данные ввн кидать для того чтобы после этого строить графики чтобы не получилась такой ситуации когда что-то не работаю дотану статистика собиралась год а по ней ничего не видно то есть кто как вы это все решаете ну во первых в самом начале покатал диаграмму цикл разработки продукта и продакт-менеджер он определяет те события для себя которые ему важны и зачастую разработчик помимо этих событий добавляет свои собственные технические который он видит которые реально ему нужны для контролирования все всего этого процесса всего нового flow совместно накидывает новые события вода бывают такие случаи когда он пишет меньше чем в итоге требуется и он потом дополнительно добавляет новые события чтобы на будущее подстелить себе соломку то есть но все-таки решает сам разработчика по поводу технических именно событий я спасибо здравствуйте подскажите пожалуйста у вас возникает много всяких событий и ну будучи вот разработчика мне легче было бы списать это на наводнение пожара на любую новость которую я я там найду вот насколько часто бывают ситуации когда вам приходится переосмысливать то есть как бы записали на какое-то внешнее событие на самом деле было что-то не так как часто вот появляется такие ситуации это вопрос номер 1 и вопрос номер 2 сколько времени вы даете на разбор с этим событиям то есть бывает ли события которые остались без ответа то есть аномалии которые непонятно в чем причина что с ним делаете по поводу второго вопроса сразу отвечу что в основном это не какие-то единичные аномалии в основном это тренды мы видим что то есть есть какой-то тренд на уменьшение чего-то или на увеличение и тут соответственно пиков тонкое команда аналитиков занимается пытаясь понять что произошло и разработчик своей страны как технический специалист тоже подключается чтобы дать свое какое-то мнение а первый вопрос напомнить еще раз ну еще ко второму насколько долго вы сколько вы даете времени разработчику на разбор с этим с этой аномалии чтобы он ну это можно до бесконечности разбираться потом сделать вывод что представляющий точно и но случаев это когда что-то изменилось именно в коде и увидели аномалию и тут разгораться особо не надо понятно что причина где-то в коде и раз проблемы в коде разработчик должен ее по из устранить соответственно и него за кратчайшие сроки группы говоря вот а если это событие связано не связано как-то с выкладкой кода какое-то сторонние события или там просто где-то что-то копилось и не была аномалия потом она выстрелила вот та ну бывает что и день разбирается бывает что едва разбирается если это реально какая-то важная фича на эффекте большое количество пользователей если это какая-то мелочь то и мы видим что она не затрагивает большого количества пользователей то и мы там в течение там полудня не смогли выяснить причину там и это откладываем на потом ну и вопрос номер один это ошибки ну то есть когда вы ну то есть принимаете решение что вот эта аномалия это там наводнение самом деле это был все-таки сбой но это выясняется попозже но зачастую если это эффект большое количество пользователей зачастую мы это обсуждаем публично в мессенджере в групповых чатах и с устраиваем своего рода небольшой консилиум и если несколько других разработчиков согласны что да это реальная причина и все на это указывает то значит мы нашли действительно причину если же есть сомнения то все высказывают свои сомнения и мы продолжаем искать дальше ну я не припомню своей памяти случаев когда там списывали это на внешнее событие оказалось что то внутренние ошибки ну просто вот ошибались в диагноз коллеги я думаю детали можно уже будет обсудить в кулуарах потому что мы начинаем закапываться есть еще вопросы о количестве 1 раз спасибо за доклад скажите вот у вас такая куча метрики где вы не меньше вижу вы китами то данные по не увидете ну условно там какая там колонка в кассандре у вас отвечает за главную метрику ну как учитывая записывайте как там и графики как мы храним кассандре как выбираем это для графиков но вообще китами то данные по метрика может быть просто там общей практики но папе по метаданным сейчас не скажу чтобы детально все это узнать посмотрите ссылку на статью евгения кукушкина там все красиво описано вот но в целом это храним как ассоциативные массивы при этом там есть ограничение на самом деле можно хранить вроде как насколько я помню там до двух миллиардов ключей в ассоциативном массиве но мы храним по-моему не больше ста тысяч но опять же лучше почитать статью чтобы понять ну тут немного не такой вопрос именно вот у вас допустим есть набор точек которые показывают я не знаю логин пользователя вот он как-то называется у него есть описание он там рисуется на 10 графиках вот вы в каждый график вот он заново руками добавляете ссылку там на кассандру или у вас там из кита метаданных для этого там один раз писали можете везде о добавлять ну мы кассандр используем как the times roll старридж то есть хранилище временных рядов и соответственно мы ключи к сандре формируем именно в виде вот элементов там допустим в течение дня по какой-то метрики и таким образом мы их выбираем то есть мы не храним информацию по каким-то пользователем отдельно мы храним уже агрегаты в кассандре спасибо спасибо за доклад немножко с другой стороны наверное предыдущий вопрос вы как так вы же делаете разрезы по типам событий до в вы как-то бьете их по каким-то глобальным типом или они эти типы бесконтрольно растут ивы комбинаторного взрываетесь ну или какие-то все-таки глобальные типы есть глобальные типа вы имеете ту типа по и количество пользователей онлайн про это тип события скорее нет глобальных типов нет все применимо в данном случае конкретной фичи например у нас есть какой-то по overlay который при каких-то условиях появляется для пользователя и там дальше какой-то из этого варла идет флуда и соответственно там на сервер приняли решение показать варла и от носа первый тип события для этой фиче дома отправили запрос клиенту показать второй тип событий событий третий тип события клиент показал overlay четвертый тип события пользователь кликнул на кнопку в этом образа и ну и так далее соответственно вот вот чудно щиты еще четыре события четыре типа события появилась и начали считаться разрезы по по странным папа платформу то есть еще плюс там 40 тысяч срезов это совершенно верно таня спасибо здравствуйте и спасибо за доклад а скрыть пожалуйста вас разработчики как-то all our minds вы говорили днем а чего происходит ночью когда нет консилиума на самом деле если происходит ночью какое-то критическое событие то мы мы некоторые метрики мониторим у нас в качестве мониторинга используется запись есть специалист мониторинга которые дежурят круглосуточно и не некоторые критичные метрики мы мониторим через zabbix и если они начинают allure тить то всегда есть ответственный по этим метрикам ему специалист из мониторинга знает с кем нужно связаться ночью кого оповестить в случае возникновении продал за рабочий как в этом участвует специалист мониторинга звонит разработчику и разработчик просыпается ночью и устраняет проблем понял спасибо все так и есть жизнь боль коллеги еще вопросы давайте последний вопрос и отпустим спикера попить кофе мне уже жалко его спасибо напомнить еще раз как вас клиента заставляют эти события это через веб-интерфейс то есть у нас есть некий веб-сервис неважно как именно он сформирован то есть суть в том что есть специальный веб-сервис в которой клиенты отправляет эти события мы на сервере просто принимаем интерфейс другого ряда будете пока ттп у вас не думали это более может эффективные очереди использовать для для этого очереди на стороне клиента вы имеете не порождает лет избыточный честно говоря это больше вопрос к нашему frontend у о том как он пишет эти события к нам но насколько я помню вроде при возникновении каждого события отдельно дергается в api сервис почему front-end и back-end понимаешь а выбора стало просторно бэг-энда же там она стране бэг-энда делаем ну тут зависит от нагрузки собстна говоря количество событий если событие мало то мы можем сразу их кидать если их много то мы складываем их в очередь и где-то отдельно обрабатываем уже отправляем the service очередей используется какой-то извините не раз сервис очередей используются для получения события от клиентов до если нагрузка высокая то да лучше использовать этот это зависит смотрите в некоторых ситуациях он у нас нет такого что прям один общий веб-сервис для абсолютно всех клиентов все это зависит от многих нюансов от как сейчас функционирует и собственного каких-то вещах есть свои отдельные небольшие веб-сервисы куда клиента кидают эти события и потом в протоколе взаимодействия с мобильными клиентами нас общий протокол и соответственно клиенты какие-то стандартные сообщения отправляют через протокол о том что такие события произошли инстр олеге самые то ли я предлагаю уже обсудить в кулуарах давайте еще раз поблагодарим спикера"
}