{
  "video_id": "8k2dPiUZXtI",
  "channel": "HighLoadChannel",
  "title": "Как SRE следит за стабильностью и скоростью HeadHunter / Антон Иванов (HeadHunter)",
  "views": 3838,
  "duration": 2505,
  "published": "2017-04-22T14:48:06-07:00",
  "text": "Всем привет Я работаю в хантере Хантер - это сайт где соискатели находят работу Где работодатели находят себе сотрудников у нас такой средне нагруженный сайт к нам на фронты без статики приходит примерно 3000 запросов в секунду это превращается в 25-26 запросов в секунду к эндам и там больше 50 запросов в секунду базам данных ием Сандру Ну вот как-то так выглядит наша стабильность за последние 2 года можно увидеть что там в четырнадцатом году мы падали ниже 99% доступности Да сайт практически каждый день лежал Вот Но с тех пор нам удалось выровнить нашу стабильность Э мы уверенно выходим за три девятки часто бывают месяцы Когда у нас стопроцентная доступность и я собственно хочу рассказать как у нас это получается что мы Для этого делаем план такой ну я быстро прогусь про то что у нас делает команда S расшифровывается как се вот что у нас делает эксплуатация что там делают другие команды коротко про мониторинг про реакцию на инциденты про нагрузочные тесты и вот больше времени хочется уделить граблям на которые мы натолкнулись мых решали цию которые занимаются железом сетью операционной системой мы используем унту и некоторыми инфраструктурными приложениями балансировки Проси и логом постфикса и так далее отдельно ребята из косан у нас отвечают за соно SQL и есть у нас команда больше разработчиков сре У нас четыре человека включая тестировщика вот именя тимлида мы отвечаем уже за то чтобы те приложения которые крутятся на этом железе работали стабильно чтобы их настройки были правильные Мы в основном в качестве бэнда используем дву поэтому выставляем настройки Garbage Колек ихи и так далее Мы также последнее время часто залезаем настройки иси и в общем Ну влияем на общую архитектуру на самом деле мы делаем одно и тоже просто на разных уровнях в основном основная Наша задача заключается в том чтобы правильно заморить сайт и правильно интерпретировать этот мониторинг Ну вот я там показывал график нашей доступности того чтобы показывать график доступности нужно вначале определить что такое сайт лежит Что такое он доступен вот нам Конечно хочется чтобы сайт считался там лежащим если клиенты перестали платить но у нас это не получается потому что многие клиенты платят редко Но много поэтому мы не придумали ничего лучше как мониторить просто количество пяти соток в секунду ну мы так прикинули что 25 соток в секунду если больше то сайт лежит Если меньше Он вроде как не лежит на самом деле мы реагируем на гораздо более мелкие инциденты и также реагируем когда просто процентили ответов больше там какого-то времени но для команды S это вот для эксплуатации в основном показа мы для себя решили зажать все эти цифры вот реагировать на более мелкие инциденты с точки зрения фронтов наш сайт состоит из собственно тех приложений которые обслуживает сайт из AP и мобильной версии сайта А ну AP обслуживает э запрос работодателя если они хотят интегрироваться там своей системы с нашим сайтом или вообще запросы всех мобилок Ну и видно что нагрузка вообще-то на все эти три компонента не одинаковая и там 5п соток на основном сайте это не тоже самое что 5п на мобильном сайте на мобильном сайте Мы считаем что он лежит да Когда у нас 55 соток поэтому мы с точки зрения с смотрим не на количество на процент пяти соток и раздельно для сайта мобильного сайта Кроме того У нас есть контролируемая деградация если какой-то из бэндо лежит то мы Вполне себе пользователю можем отдать ДТ просто нарисовать какой-то бло нанино сам деле нет пользователь какую-то информацию которая ему нужна была не получил поэтому мы также смотрим за пятками нав Ну у нас пока цифра в п титок в секунду на любом энде но мы там подстраивает вот такие графики Вот как раз наверху есть два графика которые левый отображает процент к а правый понимаем что происходит с сайтом что пятисот какая гистограмма ответов в качестве мониторинга мы используем амер всё очень круто хорошо мы поняли что у нас сайт лежит нам Пришла эсэмэска там или оповещение автоматические оповещения в слаг приходит мы Разбираем там всё вместе инцидент в этом чатике обычно сидит не только программист команды S но и много других программистов поэтому проблему находим довольно быстро и автоматически создаётся Задача В жиры Ну там мы подробно Разбираем описываем прикрепляем всё как мне кажется по-другому и нельзя основной инструмент разбора инцидента это конечно графики Я просто ради интереса сюда запихнул пример даже выдержку из одной дашборды нашей может показаться Здесь много графиков для одного серно сверху вниз обычно мы видим все аномалии и быстро понимаем либо здесь проблема если либо проблема где-то ниже и нам нужно просто посмотреть другой другую дашборд мониторить стараемся всё Ну как в разумных пределах естественно Вот но практика показывает что во время инцидентов никогда не понимаешь Какой график тебе потребуется более того инциденты очень часто бывают разными и предыдущий инцидент совсем не похож на текущий Поэтому вот тут действует правило для меня что лучше перемотать чем не домонтович был предыдущий доклад но Ну да у нас есть request ID м фронтовые инкс его присваивают мы это сделали ещё тогда когда в инсе не было request ID в последних версиях он умеет присваивать request ID запросом и писать это в логи Но тогда мы написали свой модуль этот request ID в хадерах запроса проваливается на бэнды и даже в базе данных таким образом наши дба Вполне себе могут нам сказать А вот ребята ваш запрос кладёт нам базу с таким request ID посмотрите что это такое Вот и мы использовали Лок и он у нас не полетел у нас достаточно много логов Примерно там больше терабайта в день получается И это всё выражалось в том что на машинах с логом У нас под стопроцентная загрузка CPU на самом деле не очень много машин было но больше мы покупать не хотели и там использовать для для такой задачи Вот и соответственно всё что не мог Лок обработать логи терялись и мы потом берём вбиваем туда пощи по этому реквест ID он ничего не находит поэтому мы изобрели такой небольшой собственный велосипед мы сказали Давайте присваивать а таким образом чтобы в начале у него был ну мы точно знаем восколько к нам пришёл этот запрос и мы точно знаем что этот запрос у нас обычно все запросы за 2 секунды точно выполняются редко когда больше вот поэтому мы просто можем взять логи вопрос Где Вот 959 Ну вот можем тыкнуть в какое-то место файла потре там 83 потре что где-то дальше КНУ в другое место и так далее достаточно быстро найти нужную область поиска Ну и таким образом мы получаем вот я перечислил тут несколько сервисов в которых Нашлись логи по request ID достаточно быстро получаем всю выкладку Ну где-то вот этих там в терабайте логов за 10-20 секунд мы Вполне себе все логи прик находим и вроде как нам этого хватает это не требует никакого лишнего CP ничего просто файлики лежат в одном месте и по ним по ним мы бегаем и ищем Мы периодически Тестируем сайт дополнительной нагрузкой делаем это раз в несколько месяцев стараемся это делать когда естественная нагрузка максимальна Потому что потому что нагрузочные тесты - это всегда искусственная нагрузка и всегда есть вероятность что мы проверим что-то не то поэтому мы стараемся как можно меньше искусственные нагрузки давать тогда когда есть максимально естественно стараемся соблюдать баланс между честностью и сложностью профиля нагрузки но тут ничего нового Мы просто берём наиболее частотные запросы правда отдельно для соискателей работодателей анонимов если бы мы брали просто самые частотные запросы из логов и прогоняли их оказалось бы что это все запросы соискателей анонимов работодатели делают меньше запросов поэтому для них в том числе отдельный профиль Ну и мы отдельный профиль снимаем для сайта мобильного сайта получаем несколько профилей и там ну и грузим этим профилем сайт у нас что-то такое получается вот это мы летом нагрузили сайт Когда у нас нагрузка маленькая была мы готовились к осене вот увидели что у нас п один изв правый график количество пяти соток там история оказалась очень простая Просто этот энд он открывает много он на самом деле создан Для того чтобы ходить по другим эндам его даже назвали ли себ какую-то бизнес логику вот и он на каждый запрос открывал соединение новое Вот и оказалось что в момент открытия соединения пакеты Шей теряются вот ну и мы просто заюзал п соединение обычная стандартная фишка ТТП 1 и потом у нас соответственно Такой проблемы не стало ну а дальше Работаем как с инцидентом и вот тут дальше самая интересная часть доклада про то на какие мы грабли напоролись за последнее время как мы их решали первые грабли - это вот про Туха запросов если посмотреть на путь запроса в одном сервисе берём Не микросервис наю архитектуру а просто в одном сервисе то там по крайней мере будет Accept Back в операционной системе куда попадают запросы на соединения которые потом выгреба приложением и попадают например вст Ну в очередь перед тред пулом Ну по крайней мере так работает джетти э так работает Гризли и так работают многие другие серверы потом уже запрос попадает непосредственно в тред Pool но там он тоже может застопорить из-за того что не может получить соединение из базы для работы с базой данных и Представьте себе что в этот момент наступает таймаут этого запроса и клиенту он уже не нужен а он там дальше будет по всем этим очередям лететь обрабатываться получается что мы что пока он лежит в очередях он проетцу тратим ресурсы страшнее то что сервис не можем не может сам восстановиться после каких-то проблем какой-то спа очере начал обрабатывать уже протухшие запросы и продолжает обрабатывать протухшие запросы просто потому что у него вот эти очереди забиты нам уже пора давно выкидывать эти запросы потому что не справились Мы с ними а мы до сих пор он их до сих пор обрабатывает и там двух соток уже не отдаёт Мы конечно могли проставить везде иф на каждом этом этапе и выбрасывать запросы Да если там наступил таймаут Мы решили Другой путь избрать есть подозрение что если образовалась какая-то за гдето проблема значит поздно накапливать в памяти данные необходимо уже падать вот мы отказались от всяких ненужных очередей Ну например мо можем заметить что сам трел является не то что очередью Но некоторым там ресурсом да Если этот ресурс кончился то в общем довольно бесполезно накапливать перед ним ещё очередь запросов скорее всего Эх очередь нужна Например если у вас какие-то CPU intensive вычисления у вас естественно мало трев в тред пуле по количеству ядер и вас абсолютно нормальная ситуация когда есть очередь перед этим пулом потому что вам там хочется загрузить максимально CPU а не отбрасывать запросы просто потому что звёзды сложились Так что одновременно все ядра загружены и там очередь должна быть это нормально просто е надо заморить и зажать размер Или например зажать размер АК ещё лучше не подключаться каждый раз а просто использовать K Life Но если у вас нет размера очереди Например если взять пул соединения к базам данных там обычно очередей не бывает но там почти все пулы позволяют задать тайм-аут на взятие соединения опять же мы очень резко зажали эти таймаута э если мы не можем долго получить соединение к базе данных значит с базе данных плохо нечего копить такой запрос необходимо его откидывать бывают всякие и у нас тоже используется асинхронная архитектура когда нет ну Ред пулов в классическом понимании есть ивен луп который обрабатывают запросы вот там мы пришли к тому что просто зажали одновременное количество запросов но мы сделали это не на балансировщика потому что у нас балансировщик сами по себе сбалансированы Вот грубо говоря у нас несколько инстан сов балансировщика и каждый не знает про про то сколько на этом конкретном бэнде одновременно запросов поэтому мы зажимаем количество запросов непосредственно конфигом бэнда Ну и есть ещё правило как можно ближе зажимать надо Как можно близко к узкому ресурсу потому что ограничение на балансировщик вот я только что рассказал вот так себе его очень часто сложно подобрать вот в асинхронной архитектуре очень сложно подобрать А какое количество максимально может обслужить этот кнд одновременно запросов сегодня это одна цифра завтра другая вот грабли 2 - Это лавина трав мы ВС время завалили себя Рами это происходило примерно следующим образом запрос приходил на фронт который на балансировщик который отправлял его на конкретный фронт которому требуются данные из бэнда и поэтому он шл на балансировщик бэнда чтобы Достучаться до конкретного бэнда Носта эн Давайте представим что сайту плохо Ну или плоховато и он тоже лежит тогда мы отправляем фронту ответ не смог там с точки зрения джинса там 504 если это Тай 502 и этот фронт отправляет фронтовому балансировщик ответ не смог если фронтовый балансировщик плохо настроен то он пойдёт на другой фронт который опять пойдёт на энд балансировщик который опять пойдёт без тогой пщ бкд и на другой пщ Кэн Да в общем мы вместо того чтобы облегчить чтобы они там поднялись мы их ещ сильнее заливаем ра А вы Представьте Это я ещё простую картинку нарисовал Здесь всего два фронта и два энда а если фронтов больше и у вас нет ограничения на количество Рав А если у вас там трёхуровневая архитектура и у вас ретра Может там на каждом уровне по несколько раз с нами такое было собственно и мы кчему пришли подумали принци вот принцип один что травить нужно только непосредственно перед проблемой Ну то есть ни в коем случае нельзя травить на фронтах если у вас проблема в бэнда если проблема дошла до фронта то всё уже Там балансировщик на ним уровне уже 100 раз по Трали поздно поздно ещё раз трать необходимо фаз себе устраивать для этого нужно чётко понимать упал сам сервис Или кто-то под ним Ну мы часто у нас большая часть запросов входит хттп и мы для себя придумали такое правило что пятисотка или 503 означает что упал сам сервис а 502 это тот кто под ним это очень удобно не только в настройке ТВ это очень удобно в момент разбора инцидентов сразу просто по количеству 500 так понимаешь проблема в этом сервисе или в каком-то другом сервисе мы ставим сте ограничение на количество Рав обычно максимум рано За ско мы ожидаем что у нас выпадет эндо и мы ставим ограничение на время в течение которого можно трать потому что бывает проблема тяжёлых запросов для которых например специально поднимается тай на балансировщик ретра тяжёлые запросы это не очень хорошая идея потому что тяжёлый запрос и так может завалить энд а так мы его там ещё раз завалим другой эн вот если совсем непонятно как настраивать тут я приго ло все вот этии про то что у нас вдруг сервис затупил и по непонятным причинам тупит давайте это поем это дешёвое решение в качестве быстрого фикса оно классно годится Но необходимо понимать что потом вы этим трам себя можете завалить и вс-таки с этой проблемой нужно разбираться что мы считаем что обязательно нужно рать Ну это Например Con вне возникает коже Сира просто этом порту никто не слушает если мы выключили сервер для обслуживания например и для и запросов можно пост нехорошо Да потому что потому что ете вдруг он на самом деле был обработан на том на другом Мы его ещ раз обработаем это прит к заднию данных кстати в послед но когда мы это ВС настраивали это е версии ещ не было поэтому мы там изобретали всякие некрасивые Ленки для того чтобы для там для постов нет и да об этих проблемах приходится думать при разработке всё время потому что бывают не только п походы но и там поход в по спрашиваем Ну хорошо А что будет если в этот момент пропадёт соединение ты об этом подумал Нет не подумал давай думать грабли номер три про который хочется рассказать - это лишние промежуточные извени если подумать то вообще наличие балансировщика на которых там выделенных железных машин на которых мы что-то настраиваем это определённая боль Ну во-первых это лишний на переко там пакетов пакетов и так далее это точка отказа и если у нас выходит из строя один из наших балансировщика то там на короткое время на несколько секунд на сайт всё уже недоступен возникает интересный вопрос кто должен балансировать балансировщик если мы хотим горизонтально отмашка На этой конференции доклад что мы с этим придумали вот возникает интересный вопрос а если мы хотим подключиться к Кэн через балансировщик то кто будет троить конект Ну потерю вот этих как раз из пакетов хендшейка логика должна быть по идее заложена в самом приложении если мы хотим рассчитывать на ретрай tcp пакетов на уровне операционной системы нам Придётся подождать потому что там это всё произойдёт не мгновенно насколько я помню там через секунду а это уже поздно у нас таймаут может какой-то сработать вот поэтому эта логику приходится закладывать Ну либо закладывать в приложени которые подключаются к балансировке либо использовать ла Ну и всё Мы постепенно приходим к идее что балансировать нужно всё-таки не отдельными железками потому что между приложением и железкой всё равно есть сеть а необходимо приложил балансировать в самом в самом приложении хотя мы Ну ещё конкретно не реализовали это у нас был яркий пример вот лишнего промежуточного звена когда тупил ПГ баунсер для тех кто не знает Бау это такая штука через которую наши энды подключаются к постгрес это пул соединений Несмотря на то что есть пул соединений на стране непосредственно кэндо есть ещё пул соединений непосредственно перед прогрессом я ещё расскажу почему но мы столкнулись с проблемой что при 10я запросов в секунду у нас время ответа ПГ баун сеера было гораздо выше чем время отд они со своей стороны с этим разбирались А мы с точки зрения с начали чесать голову и думать А зачем нам вообще бар изначально посыл был такой Давайте настроим полу соединения таким образом чтобы каждый энд например ел от п до 15 соединений А баунсер ограничивал их аппетит если вдруг все начнут есть 15 соединений то там по не выдержат 15 это условная м какое-то оние поэтому прямо на той же машине стоит п баунсер который в общем если один энд попросит 15 соединений он вполне ему может предоставить Но если все одновременно попросят он их ограничит и они будут ждать такая схема довольно долго хорошо работала и мы не заботились о том что там внезапно какие-то бэнды иногда сдали весь свой пул соединений но мы натолкнулись ещё на другую проблему представим что тупит база че происходит тогда все бдам требуется больше де соединений не Дат одновременно там всем эндам весь полу соединени они друг друга начинают ждать возникает вопрос А зачем вообще давали эндам много соединений если это в общем бесполезно если они всё равно друг друга ждут и мы решили что давайте не будем для высоконагруженных КНВ вообще использовать баур ограничимся кста там на Кэн может приходить десятки тысяч запросов в секунду а ему достаточно всего там десяти соединений но нет смотрим на график и действительно хватает если понадобилось больше смотри предыдущие всякие грабли Давайте падать а не пытаться увеличить пул или там нарастить очередь и мы ещё сделали для того чтобы экономить соединение для реплик мы сделали походы на реплики без транзакций потому что приложение как правило у нас пошло в базу данных что-то по делало потом ещё раз пошло в базу данных а пока она что-то делает в транзакции вроде как это соединение нельзя использовать для других запросов если это происходит всё вне транзакции пожалуйста соединения могут гораздо лучше переиспользовать Ну и вообще основное правило которое там я для себя вывел что то чего нет сломаться не может и стараюсь всё что особенно не нужно убирать из архитектуры ещё хочется рассказать не столько про грабли сколько про там это балансировка между репликами паса опять же без промежуточных звенив каких-то У нас есть энды в них крутится есть несколько реплик для основной базы у нас там три реплики и мы прописали в энх определённую строчку подключения я сейчас объясню что она означает лишних промежуточных пулов и так далее мы Вполне себе имеем равномерную загрузку на реплике достаточно отказ устойчивую Ну в этом Уле написано что когда драйвер открывает соединение он может открыть на любою из там реплик перечисленных конфиге что если в этот момент сработал или Connection опять же настроен то необходимо тут же пробовать другой сервер что если Ур Ну драйвер умеет обрабатывать ситуации когда умер ql и вам прямо в tcp соединение прилетает СТ сигнал то он сумеет приоткрыть соединение на другой сервер Правда Конечно вот это транзакции вот этот запрос поели но тем не менее падение реплики это в общем довольно исключительная для нас ситуации и если мы потеряли соединение то срабатывает сот Time он опять же задан в конфиге тут можно коне использовать дефолтов ограничивает время выполнения самого долгого запроса это означает что у вас на реплике должны быть очень быстрые запросы мы на самом деле этого и хотим у нас для долгих запросов Если уж совсем никак не получается по-другому выполнить есть отдельная реплика мы её так называем сло реплика вот туда долгие запросы ходят не критичные для сайта и да возникает вопрос хорошо реплика упала мы перевели все соединения которые были на эту реплику на другой инс потом мы её починили поставили обратно работать как на неё соединение вернуться то вот и ну мы не нашли ничего лучше как просто ограничить время жизни соединения одной минутой кажется что это довольно мало но на самом деле для за одну минуту соединение успевает через себя прокачать столько запросов что лишь ну там накладные расходы на переустановку этого соединения они в общем ничтожные и просто у нас раз в минуту рауд Робином переустанавливается соединение на э другую реплику у нас много кэндо у нас у каждого там несколько соединений в пуле Поэтому в среднем получается достаточно равномерно Я немножко совсем хочу рассказать про наш опыт микросервисов чтобы оставаться в тренде очень много докладов про микросервисы Мне кажется любопытно рассказать про наш опыт я уже рассказал что у нас с точки зрения фронтов есть три сервиса это сайт мобильный сайт IP они все ходят в такой бывший Ну как бывший он сейчас остаётся монолитом тяжёлым развесистым приложением вокруг которых постепенно образовалась куча микросервисов Я не все перечислил их на самом деле 10000 и наизусть я их всех не вспомню и каждый вроде отвечает за там узкую функциональность и чего-то там делает эти имеем как плюшки так и головную боль Если говорить о плюшках то ну микросервис - это хорошие декомпозиция Монолита Да если вам хочется вашего монстра превратить в что-то более Ну понима бее то да микросервисы позволяют Если вы их правильно распилили сде сделать это с другой стороны возникает тут же вопрос А точно ли вы хотите декомпозировать ваш большой Монолит выделяя отдельный депт став его на отдельный сервер ведь в современных языках программирования в общем-то Ну там в джаву возьмём да есть много средств Как как инкапсулировать какой-то участок кода есть пакеты пакетная видимость есть maven модули в девятке появятся модули которые прям имеют строгую инкапсуляции вашего кода точно ли нужно начинать с отдельного пло Юнита непонятно часто бывает проще Просто взять их ваш Монолит попытаться нарга модуле внутри вашей кодовой базы Нам нравится что микросервисы обеспечивают контролируемую деградацию если у нас лежит сервис вакансий поиск вакансий то у нас не лежит поиск резюме и наоборот И это хорошо вот нам нравится что микросервисы если они требуют специфичного оборудования то мы можем купить специфичное оборудование непосредственно для этого микросервиса и это здорово есть определённые проблемы с со всеми этими микросервисной архитектурой Ну есть чисто организационные проблемы влат бизнес команда кроссом который потребовался для какой-то бизнес фичи знания устойчивости о том как вообще нужно готовить архитектуру они в с это не столько проблема сколько об этом нужно знать что постоянно коммуницировать с разработчиками это тоже нужно закладываться это тоже требует времени микросервисы у нас востребованные не забрасывают а там пло что-то с этим делать по-моему у него утекает память Да нет не охота есть более важные бизнес задачи Ну это с одной стороны хорошо с точки зрения бизнеса если есть более важные задачи А вот это никого не парит отлично но с другой стороны а Тогда может его вообще выпили Зачем он нужен Если он там такой весь валяется и и создаёт только проблемы микросервис - это всегда арх на стерилизацию стерилизацию чтобы Вы придумывали неб собственные какие-то стерилизаторы у вас всегда поход Просто внутри вашего сервиса внутри процесса внутри потока в другую функцию будет всегда дешевле чем лизация Поход по сети стерилизация микросервис - это определённых при программирование раньше опять же вы вызывали просто функцию которая лежит в соседнем пакете Теперь вы на этом всём Нава rpc зазывает rpc в другом сервисе Вы должны выпускать грамотны релизы совместимые вначале один сервис потом второй потом выпиливаем старые там несовместимые вещи из первого и так далее это всё не ускоряет разработку ещё микросервисы там на мой взгляд это инфраструктурная копипаста Ну то есть у вас 10000 сервисов на каждом например вот у нас стоит джетти вот на каждом льются логи надо настроить куда они льются каждый нужно как-то отстроить по там памяти и так далее и тому подобное и у этого решения на самом деле есть выход можно использовать там образы виртуалок докеры оркестрация Но каждый раз когда в это всё начинаешь залезать думаешь А собственно какую проблему Ты изначально решал я точно Хотел хотел избавиться от микросервисов и теперь думать о Докера оркестрация и так далее или я хотел чего-то другого вот поэтому это не означает что микросервисы выделять не нужно опять же них есть ПС это на помнить взвешенно подходить к проблеме выделения сервиса чем просто бездумно распиливать свою архитектуру монолит - это на самом деле такой же проложение которое тоже можно распилить просто не на отдельные деплой юниты Ну вот у меня всё спасибо Спасибо за доклад у меня у меня такие несколько вопросов можете ещё раз повторить или рассказать каким образом вы вы формируете requ ID и и Бывают ли коллизии в названии это один вопрос второй вопрос У вас вы вы получается используете нагрузочное для того чтобы в продакшене определить при примерную пропускную способность а используете ли вы нагрузочное для билдов Чтобы понимать не не появляется ли в билде деградация в производительности Ну ещё и последний а такой я попробую запомнить да И последнее - это вот вы написали что у вас на канал СК куда приходят уведомления подписано много людей и все могут решить задачу а не бывает ли у вас из-за этого проблем что все отвлекаются и бросаются решать одну и ту же проблему это всё я отвечаю на вопросы в порядке фифо первый вопрос был про request ID мы генерируем его на Фронтовых ин джинсах раньше генерировать просто как случайно какую-то Абракадабра теперь в названии в начале этой Абракадабра есть префикс и он означает тамм коллизии обычно с этим не случается потому что в общем в тайм СМП у нас точностью до миллисекунды и там ещё достаточно много всяких случайности потом поэтому теоретически они могут быть практически я не находил такого чтобы у меня был один запрос и на него было логии совершенно разны Ну один реквест о у него были логии совершенно разных запросов второй вопрос касался нагрузочного тестирования Тестируем ли мы билды Нет мы решили что это неэффективно потому что повторить продакшн с его архитектурой с его железками мы не можем в момент билда А значит в общем-то тестирование билда нам ни о чём не скажет вот поэтому мы приняли такое решение Давайте тестировать прямо днём прям сам прод потому что это достаточно контролируемая штука если какие-то проблемы мы начинаем замечать мы тут же нагрузку устанавливаем Разбираем и Трей вопро нача Да нет каждый В общем умеет строить себе что приоритетнее что нет сре приоритетнее заниматься инцидентами другим командам не очень приоритетным мы можем их пнуть прямо в слаке сказать ну-ка Помоги что что у тебя там происходит вот а можно не в микрофон задавать Я просто не знаю как это на трансляции скажется Окей тогда да спасибо за доклад очень интересно А вы разделили Я так понимаю вот команду на эксплуатацию отдельно и сре отдельно можете чуть поподробнее рассказать какую цель вы преследовали и добились ли того что хотели Спасибо сразу чтобы было понятно я ничего не разделял я на самом деле уже наверное там четвёртый тимлид команды сре это всё было сделано Достаточно давно Да по-моему насколько я понимаю команда сре была выделена в рамках департамента разработки тогда уже команда эксплуатации была отдельно от команды разработки И вот оно так получилось и сейчас действительно часто Есть мысль о том чтобы объединить сре эксплуатацию потому что на самом деле это очень часто одно и то же так А спасибо Антон за доклад вопрос в тему предыдущего вопроса собственно про команды э вот у вас команда эксплуатации она использует те же самые средства мониторинга и алер либо какие-то свои с блэкджеком Ну и абсолютно тот же АК метр спасибо а повторю вопрос для трансляции а логи собираете вы в единое место чем отказались от Лога а очень просто у нас на каждой машине стоит си слог он заливает всё это на другую машину на другой машине все логи есть там разработчики могут их погреть А Могут просто поискать с помощью вот этого сервиса по request ID Да абсолютно Есть ещё вопросы Спасибо за доклад Вопрос такой принимает ли ваша команда участие в подготовке релиза Или например ревю изменения от разработчиков чтобы потом понять что может выстрелить на продакшене у в в принципе есть обязательный код ревю не обязательно присылать комит на ревю в сре обычно это делается добровольно Если есть подозрение что функциональность Критична или она может что-то уронить или это какая-то инфраструктурная штука вот здесь особенных правил нету всё на честном слове Но обычно обычно присылают к нам на ревю какие-то коммиты что касается релизов уже по прили то чтов в начале дня собираются задачки в жири которые стоят в статусе Ready to Release из них собираются билды там сервисов через них автоматически гоняются автотесты вот и это всё если автотесты проходят потом попадает в эксплуатацию и на их в общем полуавтоматический раскатывают на продакшн и мы в этом процессе принимаем участие только тогда когда мы видим что после релиза на сайте пошли пяти сотки Вот так А какой размер команды sre И относительно команды основной бизнес разработки у нас насколько я помню в департаменте разработки примерно 60 человек включая тестировщиков и ну менеджеров а именно разработчиков а именно разработчиков я вот к сожалению не помню но наверное там / че вот э и Какой ещё вопрос был то есть сре а сре на самом деле внутри Да внутри этого департамента всего четыре человека тилит тестировщик и вот ещё два бакан разработчика Всё спасибо Антон подскажите пожалуйста у вас мониторинг круглосуточный то есть кто ночью мониторит как это происходит да логи собираются метрики собираются круглосуточно А алерты ну триггеры настроены и эсэмэски приходят и там оповещение сла приходит на это обычно реагирует эксплуатация Либо мы но честно говоря лю за последнее время ночью у нас уже давно ничего не падало Ну а если вы спите ночью как реакция будет я не знаю потому что ночью ничего не падает А если упадёт Есть ещё вопросы там ещё а вот вы сказали се слогом логи сливай А каким если не секрет р се слогом наш человек а такой вопрос упомянули мельком Кто балансирует балансировщика как у вас до балансера собственно балансировка происходит Ух э там я именно про фронты В данный случае там по-моему стоит вот Вот тут я уже плаваю потому что я с точки зрения там эксплуатации не очень знаю как они это настроили на сколько я понимаю там стоит железная циска или джунипер которая собственно разбрасывает пакеты по непосредственно по машинам А ну дальше в принципе идея понятна ещё был у кого-то вопрос кажется нет спасибо"
}