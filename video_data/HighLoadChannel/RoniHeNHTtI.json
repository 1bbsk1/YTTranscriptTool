{
  "video_id": "RoniHeNHTtI",
  "channel": "HighLoadChannel",
  "title": "TokuDB internals / Владислав Лесин (Percona)",
  "views": 358,
  "duration": 2541,
  "published": "2017-04-09T12:54:56-07:00",
  "text": "добрый день всем меня зовут владислав лисин я работаю в компании перка на программистом весной этого года перк анонсировала покупку компании току так которая занималась разработкой движка для мая scoin и для mongo db худышка основанная на одной идее на 1 библиотеки фрактальной грею что это такое расскажу немножко позже ты-то что я буду рассказывать для москаль движка она во многом правда и для могу тебе движка только тебе вообще почему нам нужен движок почему бы не использовать старый добрый и нагибин зарекомендовавший себя до этого мы рассмотрим диск xs машина долл в этой модели у нас есть два уровня памяти быстрый и и и маленький соответственно медленный и большой и блоки памяти одинаковой длины передаваемые из этого уровня на другой в случае если у нас большинство наших данных влезает в память и или же характер запросов такое что они локализованы там на каком-то определенном участке данных тут такую такой тип нагрузки можно назвать и степью bounded потому что он тоже производились ограничено ресурс миссию в том случае когда у нас данных достаточно много они не входят в память и запросы иметь такой характер что они распределены по данным более-менее равномерно такую нагрузку можно назвать secu будет а я бандит и в этой на выбор в этом случае правильность ограничено пропускной способностью канала между одним уровнем памяти другим соответственно мы будем рассматривать его bounded нагрузку и если мы хотим оптимизировать каким-то образом работы на на наши базы данных под этой нагрузкой наши за за за до задача уменьшить количество блоков памяти передаваемых из до уровня памяти на другой рассмотрим петри почему by 3 ну достаточно раз раненая структур данных для хранения данных на дисках опорной точки объединены в ноты одинакового размера этот размер можно подобрать по размеру бог обычно устройству с которого мамы мы работаем и работы с опорными точками как с блоками мы можем экономить а и если мы рассмотрим процедуру поисков в 3 то количество его в ней будет равно количеству not от рута к листу то есть соответственно будет равно в высоте дерева ну что можно сделать здесь чтобы уменьшить количество заказа кашира и если мы здесь применяем кэширование то они не листовые ноды да да да достаточно хорошо кэшируется но в случае если у нас данных много чуть чем больше нам зло у нас данных тем меньше вероятность того что наш сечь запрос пойдет в топ-лист которую у нас уже запиши rowan соответственно в случае каширования мы можем рассчитывать что у нас на на операцию поиска будет тратиться 1 для чтения листа если мы рассмотрим операцию вставки то здесь возможны два варианта последовательная ставка и рандомная ставка ну тут следует пояснив что такое последовательный рандомная вставка на начнем с простого еще в жизни все не так но на на нашем начнем с простого допустим у нас есть табличка с первичным ключом с и вампиру ющем ключом и мы вставляем данное у нас от первичный ключ с каждой вставкой допустим растет в этом случае на на нагрузку можно назвать последовательный и by three да да да он хорошо обрабатывать такой тип вставок почему потому что у нас вставки идут в правый лист теста используется часто он за кашира вантуз может считаешь нас весь путь от рута ко христу за к шерон кроме того мы можем объединять несколько вставок то есть мы можем не и сбрасывать лист на на диск при каждой вставки можем винить не не несколько ставок и сбросить за заодно и он сразу несколько изменений на диск что экономит а я вот рандомной вставки не так хорошо кэшируются почему потому что чем больше наших данных тем больше листьев тем меньше вероятность того что нам удастся объединить несколько вставок в одном листе и тем меньше вероятность того что этот лист уже за кашированные его не надо читать из диска как можно в этом случае побороться за за производительность как можно уменьшить количество ну например мы можем использовать либо ферри то есть мы можем иметь некий буфер в которой мы будем мы будем складывать операции вставки и затем по когда буфер либо заполняется либо кому-либо другому условию мы можем сгруппировать операции вставки из этого буфера по листам чуть чуть чуть читать эти листы применять к нему операции всем скопом и скидывать данные на диске и тем самым экономя aio pro данный подход может заметить чтение почему потому что если мы будем читать данные из листа нам надо будет собрать все изменения для данного листа из если буфер и применить их к листу перед тем как мы возьмем данные оттуда и в любом случае даже если мы использует используем несут баферы нам надо сначала прочитать значение листа прежде чем применить к нему собраны изменения это ведет к лишнему а если суммирует все что вы сказали про by three to be three хороша для последовательных вставок плоха для рандомных ставок и с ростом с ростом дерево скорость рандомно вставок деградирует фрактальные деревья в чем в чем идеи фрактальных деревьев это по сути своей тот же самое by three но у каждой ноты фрактального дерево имеется буфер буфер содержит сообщение сообщение описывают какие-либо изменения над данными ну допустим вставить вставить какую либо какие-либо данные вот с таким-то первичным ключом когда буферу определенные ноды заполняется сообщения сбрасываются на уровень ниже тут иллюстрация фрактальной деревне фрактального дереву мы здесь видим бы дерево с буферами сообщение вы в этих буферах и я бы хотел проиллюстрировать процесса сброса сообщений на уровень ниже чтобы он немножко понятно о чем идет речь здесь мы видим фрактальное дерево с пустыми буферами вот нам приходит какой-нибудь сообщение она записываются в готовы рутовые ноды на самом деле все все все не так как как здесь показано здесь показана в упрощенном виде если бы у нас было все как здесь у нас был очень большой контент shine наруто вы и ноги у нас бы все сообщения писались в буфер рутовые ноду в только тебе есть оптимизация который позволяет вставлять сообщения на на уровень на на на 2 уровне ниже чтобы уменьшить как контент но тем не менее мы рассмотрим упрощенный вариант чтобы было понятно как как все работает вот приходит еще одно сообщение еще одна еще одно еще это сообщение у нас культовый мужиком и когда случается с сообщение опускается на на уровень ниже по дереву если мы проанализируем производительность операции вставки то мы увидим что ну во-первых наиболее часто используемый буфер кэшируется 2 во вторых нам не нужно каждый раз читать лист при при операции вставки мы просто записываем сообщение во-во-во по определенной буфер и для b3 у нас глаза за задача скомпоновать изменения по определенному листу здесь такой за задачи не стоит мы просто информацию об изменениях пишем в определенный буфер за счет этого больше информации пишется об изменениях пишется на 1 диск на на каждая а тут следует еще сказать одну такую вещь ноды в фрактальной дереве имеет дефолта и размер 4 мегабайта для сравнения в и на тебе у нас можно менять размер ноду увы-увы дерево но дефолта размера этот 16 килобайт то есть в любом случае у нас работе сразу ница с мегабайтами если как попроще то их и на тебе у нас на диск пишет почаще но маленькими порциями только тебе пишет большими порциями но пореже операция поиска очень похожи на операций поиска выделю затем исключением что во время поиска мы собираем по те тем узлам которые мы проходим по пути от рута к листу все сообщения касающиеся этого листа и применяем к этому листу это добавляет больше работы семью но так как мы рассматриваем а у bounded нагрузки у нас узким местом в таких видах нагрузок является а то это общем-то вполне приемлемая цена если я суммирую все все что у сказано про фактор деревьев то количество для для поиска такой же как для бы дерево количество для последовательных вставок такой же как для для b3 дерево но мы видим значительный выигрыш на на рандома вставка такой красивый график хотелось бы сказать пару слов про этот бич марк робинсон был разработан компанией тук уток чего состоит этот табличка есть возможность выбрать количество вторичных индусов для таблички первичный ключ у него у нее автон cry ментальной и тут хотелось бы немножко вернуться там к вопросу о последовательных рандор и рандомных ставках я как когда объяснял чтобы последствий и рандомной ставки я сказал что это упрощенный вариант объяснений на самом деле все не так радужно как как когда мы в майскую делаем унесет по первичному ключу происходит проверка уникальности тут первичного ключа у нас не получается сделать так что вот мы прям просто положили со сообщения об и сирте в буфер сообщений в любом случае insert влечет за собой point клэри a point горит убийц производительности для току тебе так как ведет к родам нам чтению в чем что-то выигрыш пота но раз мы все равно как как как как не можем сделать и несет рандомный insert папа папа при ручном ключу и получить выигрыш в производительности выигрыш заключается в использовании вторичных индексов то есть вот на данные bbh маркин использует 333 вторичных индекса и когда мы делаем последовательную ставку по первичному ключу во вторичные индексы идет ставка как раз уже рандомная и быть порт на написано джаве несколько в несколько клиентов идут запросы к этой таблички и есть возможность конкурировать часть читающих за запросов по отношению к части пишущих за за опросов вот на данном быть марки у нас преобладает пишущие запросы и мы видим что с ростом с ростом размера таблицы скорость вставок на и добить деградирует гораздо сильнее чем на току тебе следующий банишь mark ii the link benchmark разработанной facebook вам для тестирования социальных графов социальный граф а бывают разные разные нагрузки на таблицу обслуживающая тигров и и лилин быть имеет возможно также сконфигурировать количество читающих за за за запросов по отношению к количеству пишущих запросов на этом боссе марки как раз преобладают пишущий запросы и мы видим что только тебе puppey по производительности бьет энди by на медленных дисках то есть за счет чего топ тебе выигрывает на медленных дисках именно за счет того что пишутся блоки больше длины идет по последовательной запись и они пишутся реже по сравнению с энди by тот же самый тест на ssd мы видим что по производительности только тебе проигрывает и нагибина этом тесте но при этом есть другие преимущества за счет того что у нас размер блока на только тебе гораздо больше чем на и на тебе только тебе очень хорошо жмется соответственно если она хорошо жгут авто за занимает не меньше памяти занимать меньше места на диске что позволяет нам экономить место на дорогом носители с одной стороны с другой стороны так как у нас записи происходит реже это хорошо влияет на на здоровье ssd то есть ресурсы и типа повышается хорошо мы рассмотрели фрактальные деревья поняли за счет чего у них в на и на каких типах нагрузки происходит повышение производительности по сравнению с и нагибин теперь рассмотрим те параметры которые влияют на производительность и здесь основные параметры это параметр фрактального дерево fun out этой идеи 300 есть размер ноги размер бы и смог моды и compression чтобы смутно да я объясню чуть ниже на начнем с финал это на самом деле так картинка которую я показал ранее где у нас у каждого у каждой ноты в фрактального дерева был свой буфер она немножко упрощенная на на самом деле у нас есть но до определенного размера и мой буфер для сообщений сгруппировано по пил там папа по опорным точкам чем больше пилотов темы у нас меньше места для сообщений и в конечном итоге при большом количестве пепел то фрактального дерево бук вырождается в by дерево соответственно чем чем меньше у нас этих пилотов тем больше в ноги место для сообщений и тем больше и тем больше так такой вид какой конфигурации подходит для пишущих нагрузок и соответственно хуже для читающих на нагрузок размер но до конфигурируется чем больше размер ноды тему нас лучше топ тебе показывать себя на медленных дисках для ssd лучше выбирать размер блока по поменьше или лист лист нас очень сильно отличается от обычной но до его во первых у него отсутствует буфер сообщений во-вторых он разделен на части части одинаковой длины который называется боясь быть но до излечивают все сделано это сделано для оптимизации точных запросов то есть в случае если у нас идет точечный за за за вопрос нам не нужно учитывать всю воду целиком а как он помним размер но ты у нас 4 мегабайт это может привести к большому количеству а в этом случае мы учитываем только тупость год ноду в которой содержится там нужное значение ключа отдав а твой значение 64 килобайта но мы можем это конфигурировать чуть чуть чуть меньше размер банкноты тем это лучше для точных запросов и но это приводит к большему количеству рандомных и о компрессии вообще но но да очень хорошо сжимается так к небольшого размера и к присед всегда некий некит рейдов между спит и сайт соответственно топ тебе поддерживает несколько видов как компрессии несколько алгоритмов компрессии они отличаются по по по требованию к ресурсов процессора и по как как компрессор фактор как как тут можно что можно сделать с тем чтобы как-то улучшить производительность при при компрессии во первых у нас в каша хранятся только несжатые даты данной и соответственно если мы и мы можем использовать кэш для для хранения сжатых сжатых блоков для этого нам надо выключить дорик того да да ректору auf току тебе и сконфигурировать секунд для того чтобы ограничить размер памяти для маску льда процесса таки мурзы у нас будет 2 уровня кишат для сжатых процессов для сжатых блоков которые обеспечиваются операционной системой и внутренний код какая чтоб тебе что общем то может дать прирост производительности вот здесь мы можем видеть как как выигрывает только тебе в compression factory под по сравнению с и на тебе именно за счет того что ну во-первых применяются разные алгоритмы сжатие во вторых утоп тебе до достаточно большой размер ну да следующий путь систему которая довольно сильно влияет на производительность the top тебе это как ешьте его к что его это внутренне кыш только тебе примерно то же самое что баффер пух в и на тебе цель какая что его хоронить горячий объект в памяти в качестве объектов выступают нодов фрактальных деревьев или без but not и ука-ука что его есть верхний предел по памяти и сервисные 3 тула и виктор виктор это труд пул который отвечает за вытеснение холодных блоков из сша чекпоинт р-ну с адресом для для дать чекпоинта и хуашен задачах ваша задача коши входит сброс сообщений с 1 уровня на другую в бэкграунде собственность принципе может получиться такая ситуация что допустим мы у нас на одном уровне будут бубух и полоном и скидываем сообщение на уровень ниже там тоже будет бу-бу-бу феромоны а не скидываются на уровень и жил такой снежный ком чтобы не не допустить такого снежного кома флеш игра уде делает потихонечку сброс состав сообщение на он на уровне ниже наибольшее влияние на производительность здесь оказывает чипа enter чекпоинтов только тебе работает совсем не так как вы надели если вы ингибин у нас recovery логе можно рассматривать как циклические буферы чтобы иметь возможность перезаписывать данные в этих циклических буферов у нас с такую стартует процесс чекпоинт чуть-чуть чик-чик пойнтинга учу чипа интера есть два его сын стартовал цены эндресен в процессе работы че по чекпоинтам клиенты могут изменять страничке информации об этом записывается в рекавери если мы хотим получить состоянии данных на конец работать чик-чик пойнтера мы берем dazu берём данные прикладываем к ним записей из рекавери лоб вот в этом промежутке между стартовал цены in the sun что это нам дает в и на дебила первых процесс чекпоинт тенге стартуют тогда когда река брелок на определенный процент зал заполнен во вторых чаплин процесс чичек пойти нга распределенного времени что что позволяет размазана на нагрузку во времени в третьих во время чуть чуть чуть файтинга клиенты могут спокойно проводить свои транзакции при этом не не блокируют кто кубик к сожалению все и все все не так радужно там чаще pointing происходит раз в определенный период состоит он из двух фаз первая фаза это пометить все блоки для чипа энтин га если блок папа помечен как pending в этом случае у нас если клиент собирается блок изменить что бог планируется и q клонированная версии передается счетчик по интеру а клиента работает с оригинальной версией соответственно вот на это в нового вот на эту операцию клонирования уходит достаточно много ресурсов во время первого этапа все транзакции блокируются ну в общем то первый этап проходит достаточно быстро поэтому это не не так страшно строй этап это как когда че поттер проходиться по всем помеченным нодом и скидывают их на на на диск в том случае если они грязные тут можем видеть график как процесс чик пачанга влияет на количество транзакций в секунду мы можем видеть вот такие пики вниз связано это с во-первых с нагрузкой на систему ввода-вывода во вторых с нагрузкой на процессор тут то есть у нас процесс клонирования достаточно ресурсоемкий и выедает очень много процессорного времени соответственно что здесь можно сделать такие параметры можно использовать ну во первых есть параметр при помощи которого мы можем настроить период этого чипа и тинга какой здесь тот трейдов тут у нас чем больше период тем сильнее вот эта пика но тем дольше горизонтальный участок работы 2 пара параметр это количество нитей в в чип он тире вот тут мы можем видеть что чем больше количество нитей тем сильнее проседает производительность но при этом чекпоинт завершается быстрее и того хотела бы обобщить когда стоит использовать только тебе когда не стоит использовать только тебе стоит использовать на больших таблицах которые не помещаются в памяти с большим количеством индексов приняты вселенной пишущий нагрузки топ тебе хорошо подходит для немедленно хранилищ отток тебе помогает сохранить свободное место на быстро дорогие хранилищах топ тебе позволяет пра пра пра пра пра длить время эксплуатации для для систем и хорошо подходит для облачных хранилищ когда не стоит использовать топ тебе тогда когда у нас чтение больше чем записей щас прям реки у них юки эту убийц производительности для top baby потому что происходит много рандомных запросов ну вот собственно говоря и все немножко времени осталось есть несколько интересных фич топ тюбик которых нет в энтеббе но апперкота ход яндексе то есть как а когда мы добавляем какой-то новый индекс нам не гадят не ждать когда процесс добавления закончится мы можем параллельно использовать таблицу и в бэкграунде у нас будет создаваться новый индекс маус палка старт яндексе ну здесь понятно можем преимущество индексов перед sse3 перед не класса рад индексами фаски мучений тут тоже интересная штука вот когда вы на тебе мы не меняем схему происходит процесс перестраивании таблица в топ тебе этого нет просто кладется бородка сообщение в рутовые ноду и она потихонечку распространяется по дереву и нам не будет ли ждать когда схема изменится мы можем дальше использовать тот топ-топ тебе и транзакций of all operations что это такое у нас как когда допустим происходит удаление таблицы реально у нас файл с таблицей не удаляется если у нас произошел какой-то сбой во время удаления таблице мы можем спокойно восстановить нашу таблицу из анд блога еще есть пять минут для для вопросов спасибо за the club у меня такой вопрос я рассматриваю использовать код раз движок току д.б. я events are single но для хранения в and stream of events are seen когда мы храним и там есть всегда уникальный индекс ади агрегатором и sequence иван то он там должен быть уникальным вот я не совсем понял вот это ограничение только db по просадке производительности прибор в случае уникального индекса насколько эта проблема то есть насколько это как бы шел стокер вообще использовать только когда ум есть вот такой уникальный яндексе он там должен быть ног сигарет проблема это проблема ну все зависит от этикет от ваших данных то есть вы можете получить выигрыш по по по размеру такой что он перевесит скажем так просит попросишь связанные с использованием не уникального индекса ну то есть получается строитель ность будет сравнима с mdb или будет чуть лучше или она будет чуть хуже чем и но тогда держи ротан по объему то она будет огромным потому что это джейсон объекта которые будут сохранять каждый раз по 4 мегабайта огромное будет выигрыш по объему так вот навскидку сказать сложно надо смотреть как как как конкретный диск конкретные даты как конкретные данные то есть я не могу сказать будет ли это уж и на гибели нет то есть все вот тех бенчмарки что мы видели это исключительно по вторичным к вещам да да спасибо за доклад вопрос качества и был и так понял этот тип a buffer до анала понял и еще вопрос по поводу фас схема чин-чин то есть это типа можно делать и alter темпл при этом таблица не будет золоченом или что имеется ввиду на последнем слайде фичи которые были показаны то есть фаст схема чин-чин да да был пункт то есть изменение схемы без блокировки и таблицы и до операции не не блокируется толпа таблицы просто как кладешь в брод брук бродкаст твои сообщения и все то есть это происходит моментально там без б без буг буг буг буг и рук вы не ждёте перестройки таблицу может дальше использовать это касается российские то ограничения но потому что такие вещи были в 56 качество майские или введены но там с рядом ограничений не все операции возможны но для двух сущностей можно еще раз если какие-то ограничения на тип операции ну то есть можно добавить там только in the вую колонка нельзя текста у или что нибудь такое рагнит ограничение спасибо добрый день еще один вопросик здесь а что с бэкапом и ресторан есть утилитах уход бэкапы 10 или туристу странствия спасибо за доклад и я хотел спросить если какие-то инструменты для отслеживания возможных контент tion of на нотах в данный момент путешественница до вопрос вот ты сказал что праймари ключи убивают тока нужно правильно праймари индексы нет я сказал что не праймеры яндексе убивает току я сказал что непоследовательная вставка папа праймари индексом и point каире пупок по праймером и индексом онегу они удвоить ток понял ее второй вопрос смотри вот если у меня холивар флот workload апдейтов но это много идет апдейтов у меня в процессе этих апдейта будут поиска и select и или они только валок будут писаться будут происходить select и вообще есть такая операции интерес называется абсурд да из к сожалению она у нас пока не реализовано ну вот мы думаем о том что вы верили реализовать но но то есть я я просто про то говорю что если этого не делать то на крутящихся дисках это все убивает на почту ждал стики постоянные нужно каждого газете о ну да это так есть еще я вот что хотел ну еще один вопрос а вот все-таки чем только лучше чем rox baby cham только уж чем рука тебе честно говоря я не могу на это вопрос ответить все не не сравнивал току и рука тебе просто они но очень похоже то есть прямо не проделаю тот же паттерн до что heavy аборт плотно запись и как бы эти мои руки чем и но тебе фактически потому что на чтение они так понимаю пример это же как и на тебе работают и плюс-минус ну не на рандом от чтение химии ведущему чтение да да да да да даже может быть не не нам немножко похуже потому что ну размер блоков на на чтение больше чем чему и ну да то есть короче вот эти оба движка не решают проблем записи и хочется понять какое излишков лучше толку или rocks но надо провести сравнительный восьмерки посмотреть редких случаях лучше пути хуже план спасибо а если в току или будет ли портирована работа с джейсоном что еще раз работа с джейсоном по моему нет пищи 1 от 1 а можно еще один вопрос я тут вопрос про соотношение оперативной памяти и диск вот какое примерное соотношение требуется для тока бибер вот сколько как бы хранению на диске должно соответствовать объем памяти оперативной для того чтобы проявить вот этот для того чтобы появилась то есть вы имеете ввиду как как как какой-то должно быть соотношение хранимых данных с памятью какой-то нормальной работы да ведь лишь ну чтобы увидеть что у нас на русского его bounded там да да да примеру ну допустим если у нас там объем памяти 100 гигабайт тут уже там 3 5 это терабайт вполне достаточно чтобы увидеть разницу то есть примерно 120 и да то есть много участок спасибо владислав спасибо вам за доклад"
}