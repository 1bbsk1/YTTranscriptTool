{
  "video_id": "GW07RZVpH4M",
  "channel": "HighLoadChannel",
  "title": "Необычные случаи оптимизации производительности на примере ClickHouse / Алексей Миловидов (Яндекс)",
  "views": 5832,
  "duration": 2522,
  "published": "2021-10-04T02:32:49-07:00",
  "text": "что мертв 3 хранит данные на диске memory таблица хранят данные в против key а еще мы знаем что памяти быстрее чем диски но обычно конечно можно поставить сервер например 10 нём и ssd и 1 канальную память и тогда этот ssd будут быстрее чем память но правда они не будут работать быстрее потому что все будет ограничиваться памятью но обычно память быстрее чем диски значит ли это что memory- таблицы быстрее чем мертв 3 попробуем проверить тут небольшой скринкаст я выполняю запрос из таблицы тест . hits и таблица типа мертв 357 миллисекунд теперь я сделаю следующее создам таблица с душком memory и вставлю туда данные выставляю memory limit чтобы данные хватило оперативки на вставку данные вставляются довольно быстро миллион строк в секунду даже больше данные вставились всего лишь за 7 секунд теперь я проверяю с какой скоростью выполняется запрос из таблицы хит подчеркивать мэмри 50 миллисекунд 54 а из таблицы хит 57 ну что на несколько миллисекунд memory таблицы все-таки быстрее а вроде вы должны быть больше ну здесь стоит отметить довольно очевидную причину то что мертв 3 таблицы они хранят данные на диске на самом деле файловой системе когда данные читаются они попадают в печках который реализует ядро операционной системы и читаются уже с плеч каша то есть из оперативки получается что имя мари таблицы в оперативки и мертв 3 тоже в оперативке то есть никакой разницы нет но почему тогда memory таблицы все-таки работали быстрее давайте рассмотрим ну во первых есть и очевидные случае это то что мер 4 таблицы поддерживают первичный ключ поддерживают индексы позволяют читать маленькие диапазон и конечно это будет быстрее a memory таблица только full скана но это неинтересно мы будем рассматривать почему full скана в мертв 3 таблицы не так уж и сильно медленнее и в том запросе у нас был именно full scale все данные с агрегировать посмотрим дальше тоже я тут видео сделал правда почему-то весь мой экран за хватился и так выполняю запрос из таблиц этот тест хит 171 миллисекунды hits подчеркивали 215 миллисекунд то есть memory таблица почему-то быть наоборот медленнее чем мертв 3 как такое может быть я выполняю запрос снова с помощью утилиты cliff house benchmark и так memory таблица 213 миллисекунд мертв 3 таблица 150 с чем-то миллисекунд запрос на какую-то агрегацию там был ёрл там было поисковая фраза и парадоксально но когда данные целиком в оперативке работает медленнее как такое может быть ну что давайте разбираться есть еще некоторые случаи почему мертв 3 таблицы могут работать быстрее чем memory во первых из-за сортировки данных norge 3 таблицы данные сортируют по первичному ключу и некоторые алгоритмы могут полагаться на сортировку причем они могут полагаться на сортировку как явно так и не явно например если у нас данный уже отсортировано и мы снова делаем сортировку то повторная сортировка не будет использоваться будет только некий мерч или там грубое по первичному ключу тоже будет использовать сортированных данных но сортированный может использоваться неявно например у нас таблица отсортировано по айпи адресу мы делаем запрос грубой по региону и у нас одинаковые api адреса ведут подряд и систему про это знает но еще у нас одинаковые регионы тоже идут подряд но систему про это не знает но у нас есть прикольная оптимизация если мы видим что какое-то значение повторяется мы при грубой просто не ищем его второй раз в хэш-таблице то есть сортированных данных локальность данных тоже используется но это еще такой пример но ясны данные в одинаковом порядке в мир 4 и в memory таблицы может ли мер 4 быть быстрее сейчас посмотрим во первых нужно я напомню как в как хауса хранятся и обрабатываются данные клиф хаус стал подсовывая база данных данные хранятся по столбцам и данные обрабатываются в памяти тоже по столбцам что это значит вот классический пример сравнение представление данных в оперативке массив структур или структуру массивов в этом пример у нас точка в трехмерном пространстве три координаты слева мы их положили в структуру и сделали массив этих структур а справа мы сделали структуру где три массива разные варианты лучше для разных случаев ясно нам нужно всегда доставать все 3 координаты и как это обычно бывает там я не знаю в каких нибудь в трехмерной графике это лучший вариант слева но если вдруг нам надо взять только одну координату понять пройтись там я не знаю просуммировать x лучший вариант справа на самом деле все чуть-чуть сложнее данные хранятся в оперативке обрабатываются не целыми столбцами а кусочками столбцов например если у нас есть таблица и там миллиард строк мы же не будем весь такой массив миллиард значения одного столбца делать это очень длинно и когда нам надо выполнить операцию плюс мы будем идти по этому миллиарда значений нет мы разобьем данные на такие некоторые блоки и личинки или кусочки я вот не могу придумать еще синонимы слова кусок хотя нам для разработки коли хауса очень нужно больше синоним слова кусок кусок чанг какой спецборт что еще бывает блок кто еще знает синонимы слова кусок что отрезок да винчи у нас тоже есть гранула есть короче читаем эти данные и получается кусок где такие мотивчики для каждого столбца например по несколько десятков тысяч строк и вот эти вот уже кусочки столбцов обрабатываем так делаем все наши операции я даже один раз наткнулся на научную статью научно это значит сверстан аптеки в которой эта технология называлась марс all.biz processing меня даже пришлось пойти и воспользоваться переводчиком чтобы узнать что такое марса оказывается это английское слово которое значит маленькие кусочки еды вот а я прочитал эту статью и обиделся потому что эти авторы они должны были бы вставай статья написать клик house bass processing они изобрели термин отдельный и вот такой способ он лучше потому что он более кэш локальный сейчас объяснять не буду сейчас покажу дальше давайте разберемся как читаются данные из таблицы вот все что происходит если у нас таблица типа мертв 3 там и во-первых читаем файл и из файловой системы файлы содержат сжатые данные данные сжимаются тоже по блокам но другим блокам не тем блоком который мы будем обрабатывать а специальным блоком для сжатия это другой блок например взяли 64 килобайта зале записали файл взяли следующего часа 4 килобайта данных жаль и записали файл когда читаем надо их разжать когда мы их выжимаем мы еще и обязательном в обязательном порядке вычисляем человек суммы и сверяем чак суммы это очень важно потому что данные на диске на ssd могут начать про ту хоть там биты могут слипаться все такое если вас это интересует у меня в позапрошлом году был доклад под названием отъявленные баги рекомендую посмотреть итак проверили checksum и дальше выжимаем сжатые блоке у нас получились не киеси реализованные данные эти сервированные данные надо превратить в те самые кусочки столбцов в оперативке это здесь названа шагом диси реализация и когда в оперативке кусочки столбцов есть мы уже их обрабатываем вроде бы все просто теперь тоже самое для memory таблицы ничего делать не надо в оперативке готовые кусочки столбцов вот они лежат просто бери и обрабатывай то есть все шаги которые здесь были они не нужны memory таблица должна быть более эффективно теоретически но сейчас посмотрим дальше что же на самом деле происходит при чтении данных из мер 3 таблицы шаг 1 читаем сжатые данные из файловой системы читать данные из файловой системы из файлов можно по-разному можно читать с помощью синхронно у воды вывода или с помощью асинхронного если используется синхронный вот вывод можно использовать обычный системные вызовы рид или перед а можно сделать omap файла тогда он будет фактически читаться в афгане 5 фунтов это не системный вызов но тоже пейдж фонд использует ядро операционной системы если у нас асинхронный ввод-вывод мы можем использовать linux а и о системные вызовы айро сабмит и ооо get events и другие или новый интерфейс you ринг который доступен только в самых свежих и ядах linux так что если вы хотите максимально всех поразить написав свой код вы можете использовать интерфейс your young но нам это не так полезно потому что у нас в основном последовательное чтение операции ввода-вывода немного так что асинхронный ввод-вывод особо не поможет можно использовать синхронной если используем асинхронный ввод-вывод можно использовать . или не использовать . не используется если вы поставили флаг a direct а если вы читаете например с помощью эмма по то у вас прям поищешь напиться в адресное пространство процесса если используется мы авто мы избегаем лишнего копирования данных и space каша юзер space тем не менее можно отметить что мы читаем из файлов сжатые данные если у нас коэффициент сжатия например в 10 раз то этих златых данных в 10 раз меньше чем тех данных которым нужно обработать то есть то что мы читаем эти данные вычисляем checksum и личное копирования это все не так важно в 10 раз меньше чем всего остального ну давайте смотреть дальше нажимаем сжатые блоки по умолчанию cliff house использовать алгоритм rc4 данные за ты всегда можно использовать более сильное сжатие zeos т.д. можно наоборот сжатия вообще выключить это у нас названа кодекс затем на на ну вот что интересно проводим эксперимент берем выключаем сжатие и внезапно все работает медленно поэтому возникает ещё вопрос какими блоками лучше сжимать данные влияет на эту на скорость и как кстати если интересует про сжатия данных и рекомендую посмотреть доклад три года назад как у скорость разжатия rc4 но это если вас интересует такой arcor смотрим дальше диси реализация кусочков столбцов на самом деле в клика вы все здесь и реализации нету почти нету это значит что когда данные ража ты допустим хранятся в базе просто числа и int32 то не файле просто подряд уложены в родном формате и чтобы перенести их столбец просто надо их скопировать какой-то кусочек этих данных столбец просто переложить данные переложить данные и все спрашивается а можно ли как-нибудь обойтись без этого копирования без перекладывания данных ну на самом деле иногда можно иногда нет здесь отличие в том что как раз кусочки данных в оперативки и кусочки данных для сжатия данных которые при разжатия образуются они имеют разный размер и они должны иметь разный размер если в таблице у нас какой-то столбец очень маленький например число идентификатор легиона там москва единица санкт-петербург два и так далее допустим uint 32 4 байта и у нас даже если взять один миллион таких чисел это будет 4 мегабайта а другой стал для ценно например содержимое html-страницы 100 килобайт с возьмем миллион сколько получится 100 гигабайт то вообще один блок в оперативку не поместится поэтому если мы читаем толстый сталкиваться нас должен быть маленький кусочек в оперативке если мы читаем маленький стал гадство лучше большой так что приходится иногда перекладывать данные итак случае memory таблиц у нас в оперативке готовые кусочки данных в случае мертв 3 кусочки столбцов формируется при чтении то есть мертв 3 делает больше работы но может ли быть такое что делать больше работы на самом деле быстрее ну конечно может быть если мы на каком-то шаге делаем больше работы а потом на следующем шаге делаем меньше работы ничего сложного я как какие-то такие странные вещи говорю все на самом деле очевидно и так случае мертв 3 кусочки столбцов формируются динамически при чтении и поэтому их размер можно выбирать адаптивно так как будет лучше для кэш локальности наверное уже не черепа это из моего доклада но сейчас я объясню и так какой небольшой столбец типа этого текста html или какие сообщения статьи на сайте довольно крупная в этом случае вот как я говорил лучше формировать маленькие блоки например по 10 строк а когда у нас memory таблица там и размера всех столбцов в этих танках одинаковые но примерно тысячу строк один столбец подругой тоже тысячу строк и мы будем обрабатывать мелкий столбец будет лучше для каш локальности будем обрабатывать большой столбец у нас временные данные будут вымывать процессор на кэш и соответственно будет использоваться больше оперативки и все будет работать медленнее и тут возникает вопрос куча вопросов с какой скоростью работает оперативка это нельзя на этот вопрос просто так ответить скажем вот какой это человек сидит с ноутбуком а какая на вашем ноутбуке скорость оперативки с какой скоростью работает оперативка на вашем ноутбуке что-то никто не знает а как вы можете на ноутбуке я не знаю серфить в браузере что-то и не знать какой скоростью работать оперативка ваше железо вы должны знать с какой скоростью работает ваше железо вот я например всегда знаю как быстро работает оперативка как быстро работает кэш как быстро работает кэш 1 2 и 3 уровня если использовать его из одного процессорного ядра из сразу многих процессах я тёр какая пропускная способность какая latency все это можно взять такой набор чисел стоит сложить перемножить и свериться с ответом ну теперь давайте посмотрим следующий вопрос про сжатия данных вот я провел эксперимент создал мер 4 таблицу с данными которые сжимаются по умолчанию с помощью алгоритма льда 4 я начал это профилировать выполняю запрос смотрю в профайлер в прав игры в топе функция эльза 4d compressive разжатия данных я думаю сейчас я удалю этот пусть у меня данные будут не сжатая этой функции не будет все будет работать быстрее то есть надо просто убрать сжатия данных и вот один я сейчас расскажу историю которую я уже один раз рассказывал но с удовольствием расскажу еще раз несколько лет назад один человек обратился ко мне в чате и говорит что у меня вопрос упирается выражать и данных давайте я можно ли включался как-то отключить сжатия данных я говорю нет нельзя crack house а сделан правильно данной впрягался всегда сжимаются но если вы хотите вы можете отправить pull request человек спрашивает а какие строчки кода менять я говорю ну вот в этом файле памяти и уже на следующий день человек отправил pull request я посмотрел сделал code review по меру сил все нормально работает и спрашиваю его скажите пожалуйста а насколько ускорились вопросы а человек говорит извините не могу сказать насколько ускорили запроса я попробовал от ментов и теперь данные не помещаются на ssd стало слишком много данных а вообще если данные не сжимать то обычно ничего хорошего не выходит то есть вариант 1 не сжимаем данные они не помещаются на диск вариант 2 не сжатые данные помещаются на диск но по их чтение читают гораздо больше используется пропускной способности диска и теперь числе не из диска тормозит хотя раньше не тормозило или например убрали сжатия данных и меньше данных помещаются в печь кэш в оперативке потому что как раз в печь каши были те данные которые файлах то есть сжатые и чем лучше да нажимаются тем больше данных помещается в печь кэш ну давайте представим что у нас куча оперативки на сервере я не знаю один терабайт оперативки 2 терабайта оперативки а скажите а у кого из вас на сервер и еще больше оперативки кричите да сколько у вас оперативки на сервер 6 терабайта ну и вот вы туда все свои эти данные положили и думайте наверное их лучше не сжимать потому что сжатия расходовать циpкa имеет ли это смысл не сжимать данные когда 6 терабайт оперативки давайте проверим возникает вопрос вот самый вот я стал горит нажать о который более сильные сильнее сжимает данные но при этом вязание работают есть более легкие вот или за 4 это более такой легкий алгоритм zeos т.д. несколько более тяжелый зато лучше сжимает данные а если брать еще более еще более легкие алгоритм можно свести всё к тому который вообще ничего не сжимает его можно использовать в качестве bass line и этом ям копи ничего не сжимать и разжимать просто скопировать данные вместо их сжатия к их центр сжать сжатия единица и вопрос что работает быстрее просто скопировать данные переложить их из одного места в другое или взять сжатые данные и разжать их и ответ вроде бы очевиден если я правильно все цифры помню на я навскидку так говорю на своей машине мем копи работает где-то 12 гигабайт в секунду а рожать эльза 4 если мерить по разным данным получается где-то от 2 до 4 гигабайт рогатых данных в секунду то есть просто скопировать данные быстрее чем рожать их вроде все так но есть какой-то подвох может быть кто-нибудь уже знает в чем подвох как я вас обманываю ну я не слышу орите так в оперативке что нас загрузить в опередит у нас уже все данные в оперативку в оперативке я не слышал о рите чего сжатых данных меньше это почти правильно ответ но не совсем все-таки сжатых данных меньше но когда мы их разума и мы же трать тратим на это время и развиваются они медленнее в чем подвох и ответ на самом деле очевидный я хочу чтобы кто-нибудь сказал чего не развивать maximus ты знаешь как отказ локальность я не надо говорить в общем не надо позориться сейчас я все объясню рассмотрим такой сценарий чтобы все понять и так данные хранятся в оперативке данные обрабатываются по блокам каждый блок небольшой и сам помещается в кажется пул но естественно все эти блоки в оперативке не помещается в кажется пу их там терабайт и и данные обрабатываются в несколько потоков то есть данные читаются из оперативки в несколько потоков и каждый блок потом уже обрабатывается внутри каша процессор нова из оперативки читаются только исходные данные и у нас получается да допустим возьмем машину desktop на raise не 16 озер и если в каждом из этих 16 ядер делать нам копи и выполнить просто арифметику домножим 16 на 12 гигабайт в секунду якобы получается 192 гигабайта в секунду но на самом деле не получается если в каждом потоки разжимать свой маленький блоки блочек такой эльза 4 из лера сжатые данные в каждом потоки поместиться в кэш соответствие его процессорного ядра тоже домножаем 16 лидер на от 2 до 4 гигабайт в секунду получается от 32 до сорока восьми гигабайт нажатых данных в секунду оперативка на вот этой конкретной машине работает со скоростью 30 гигабайт в секунду то есть смотрите в каждом потоки делаем мем копи чтобы сделать нам копию мы должны по крамер и прочитать эти исходные данные прочитать их из оперативки и быстрее чем 30 гигабайт в секунду мы это делать просто нему а когда разума эмаль за 4 мы читаем меньше данных мы читаем их с меньшей даже скоростью из памяти потому что они сжаты их просто меньше но в результате генерируем такой же объем 1 сжатых данных но разжатой данные уже в процессор нам кэш и они уже там быстрее обрабатываются и оперативки пропускной способности оперативки используются совсем мало то есть в случае миом копия упираемся скорость памяти в случае 4 не упираемся и скорость получается примерно такая же писать в память не омыв память не пишем вообще мы нажимаем данные как бы в память но они попадают в процедурный кэш каждого процессора во ядра то есть вообще не пишем в память только читаем из этого можно сделать такой вывод что память можно рассматривать как диск и неужели разжать ее за 4 будет быстрее чем нам копи ну это зависит зависит от железа вот например 200 китай серу один из самых мощных по нашим 5 парком на эпики 2 processor ных два сокета в каждом суставе четырехъядерный процессор всего сто двадцать восемь ядер память может быть до 8 канальный максимальная грустная способность аж в 190 гигабайт в секунду и что будет быстрее просто перекладывать данные или разжимать их ну и вот домножаем 128 на 2 например гигабайта в секунду скорость разжатия пор сжатым данным получается 256 гигабайт в секунду что тоже больше чем русская способность памяти и на этом серве тоже рожать и и будет быстрее на самом деле не все так однозначно я проверил еще несколько серверов там серверы на intel и там поменьше было процессор хизер api отливка такая же быстрая и там получилось что не быстрее то есть все это зависит еще можно сказать что здесь рожать а все-таки упирается в процессор например данные сжаты в 10 раз у нас 190 гигабайт в секунду раз сжатых данных и 19 гигабайт в секунду сжатых данных из оперативки читаются только сжатые данные то есть это медленнее чем то что дает оперативка сжатие можно все-таки ускорить ну что давайте посмотрим какие мы сделали оптимизации в криком все просто полагаясь на этот вот опыт для memory таблиц для лучшей каш локальности уменьшили размер блока чтобы при обработке данных не использовать оперативку обрабатывать чисто в каше я добавил сжатия для memory таблиц и вы знаете она выглядит хорошо на бенчмарках это прекрасно в продакшене memory таблице не обязательно нужны используйте мертв 3 ну а то что выглядит на пять марках хорошо это всегда радует оптимизации для мертв 3 таблиц вот кодекс сжатия но он то есть ничего не отжимать и не разжимать спрашивается а зачем тогда вообще данная копировать зачем это личное копирование я убрал это лишнее копирование ненавижу лишние копирования я вообще любой хороший разработчика он больше всего ненавидят в личное копирование если это разработчик на си плюс плюс аист на пахоту ладно дальше у нас есть вычисление checksum и я люди спрашивали вот в профайлер и видного частями checksum можно ли его убрать я говорю нет так правильно данные всегда нужен чек сформировать у нас надёжная система не пудри цена мозги ну потом подола дать проверим что будет если выключить шаг формирования ну выключил и запросы не ускорились не насколько и производительность вообще не изменилось там получается что чтобы учиться чак сумму над пройтись по как он кусочку данных этот кусочек данных будет читаться из оперативки загрузится в кэш а дальше следующее уже будет использовать кэш то есть мы просто раньше загоняем данные в кэш а сама вычисляется как сумма она быстро и дальше сделал возможность чтение с помощью map чтобы еще одно лишнее копирование убрать мало тоже не помогло потому что она поджатым данным и давайте посмотрим как все эти оптимизации все ускорили димка захожу в crack house клиент выполняем сначала из таблица мер 3 запрос 180 миллисекунд а теперь из таблицы хит подчеркивает abs 226 миллисекунд то есть медленнее но как было теперь я попробую применить свою супер оптимизацию сжатие данных оперативки вот я написал engine равно memory компресс равно единице создал таблицу теперь надо вставить в нее данные оставляю данные это происходит медленнее а потому что данные сжимаются но все равно скорость приличная и так очень люблю этот зеленый прогрессбар всегда когда на него смотрю данные вставились выполняем запрос из таблицы his подчеркиваю abs 300 миллисекунд а ведь было 200 с чем-то от этого было 180 что-то не так действительно вот было 200 миллисекунд из таблицы мертв 3 а я все ускорил я всё ускорил и она замедлилось в чем прикол я ведь это павел когда доклад готовил вчера почему она замедлилось я только что объяснял что все должна ускориться она замедлилась ладно я понял все таки почему она завязывалась и сейчас вам расскажу всё дело в размере блока который в мире таблицы создаем ямори таблицу со сжатыми данными и теперь выставим размер блока 8192 поменьше чем по умолчанию по умолчанию 65 тысяч пятьсот 36 сейчас данные записываются в оперативку в виде таких сжатых и блоков каждый из которых 8192 строки каждого столбца и теперь делаю запрос выполняю из таблицы просто хит 107 688 миллисекунд а теперь из таблицы хит спать черные memory оптимизированный о 123 100 16 миллисекунд 198 миллисекунд круто вот на этом я остановлюсь то есть видите изменили размер блока было 300 миллисекунд стала 98 эрик секунд и в чем причина самая главная причина это кто скажет cash cash локальность совершенно верно вроде бы все просто выводы чтобы оптимизировать производительность надо знать что делает ваш код профилирует вашу систему знать возможности железо ну на самом деле достаточно просто знать что процессор имеет много ядер что у процессора есть кэш ну и не путать в этом сети трупу всего спасибо оптимизируйте ваши программы алексей спасибо большое друзья давайте зададим вопрос и теперь же в микрофон они без без вора поднимите ручки пожалуйста вот одна рука вижу вот смотрите к вам бегут две девушки выбирайся микрофон да пожалуйста представьтесь и задайте надо был девушка обнять сначала поэтому микрофон и работы да не достаточно крепкая прием прием здравствуй пасибо большое за доклад вот вопрос на самом деле самого начала крутился в голове про размер этого блока тоже сразу было как-то понятно что есть какая-то зависимость между коэффициентом сжатия и производительностью вот вот если какие-то вот рекомендации по подбору размер этого блока потому что кажется как будто бы это еще зависит от природных данных всем спасибо да действительно вопрос как выбрать размер блока для сжатия данных и это зависит от того какой алгоритм сжатия используется место используется довольно легкий алгоритм сжатия типа семейства за 77 в том числе 54 он работает так есть какое-то движущиеся окно с данными в которой мог быть ссылки назад то есть алгоритм сжатия просто копирует повторение этих данных которые были мне давно и размеров движущуюся окна вылезать 4 максимальный 64 килобайта то есть получается эти бэк reference ссылки назад максимум на 64 килобайта назад я самую выбираем размер блок 64 килобайта получиться неплохо я 128 несколько лучше потому что вот во второй половинки можно будет ссылаться в первую но дальше уже увеличиваем и увеличиваем и никакой разницы нет но если сжать ее более сильная скажем библиотеки которые реализуют эльзе и эм-эй у них размер в котором можно искать данные это многие мегабайт и иногда даже можно выставить что были гигабайты и там уже лучше большие большие золотые блоки но они будут сжиматься и разжиматься так медленно что на кашу локальность вам уже будет наплевать так что смело выбирать а большие блоки если алгоритм сильный спасибо ответил вот человек в третьем ряду и ребята в онлайне вам снова привет если есть вопросы нажимайте супер кнопки пожалуйста сизо перед средств на доклад интересует тема такая вот вы все рассказывали но не упомянули тюнинг параметров операционной системы типа пейдж пичкаешь says и так далее вот эти вот параметры как-то крутили смотрели вообще ну performance мерили с измененными параметрами или на дефолтных каких-то значениях остановились есть такой классический случай когда есть пользователи клик хаоса и у них супер там кластер и он делает какую-то очень важную работу например баннерная крутилка ну вот и стала вот эти люди там куча таких обменов серьезных эти люди думают что сейчас мы прочитаем здесь конфигурационный файл и вот каждую настройку поменяем на какую-то более оптимально сосиска тела 8 везде там часть поменяем они-то меня отнять вроде она работает быстрее на тестовой среде она продакшен внезапно все замедляется иногда люди об этом даже не знаю потом просто сбрасываемся в дефолт и она работает лучше так вот если нет возможности именно хорошая сравнительно сделать тестирование желательно на продакшене просто ничего не меняете и вся вы хорошо на прошу прощения понял ответ может быть какой то оптимальный профиль от яндекса есть уже готовый для продакшен серверов именно там сиско tl профиль и так далее ну то есть или просто вы используете какие-то дефолты и на этом остановились вообще с этим идеальным профилем довольно сложно у каждого клиента чуть-чуть отличается нагрузка у одних например посмотришь запросы и все эти запросы выбираются выполнения рига ксп of ну просто просто наскольно повергать хотя рига кто у нас хорошо оптимизирована и но и остальных вопросах мы ловко все равно все будет опираться в реках спа а у других например очень длинные строки и надо уменьшить размер блока а у некоторых наоборот короткий и надо его увеличить хотя при чтении и смерчи 3 он выбирается сам и вот этих особенности очень много то есть такой идеальный профиль я даже боюсь раздавать тем не менее у нас выложены тестовые данные яндекс метрики of us и рваные и у нас есть benchmark железо и результаты разного железа поэтому мяч марку по запросам тоже из яндекс метрики опубликованы на сайте и там можно сравнивать самое разное железа там даже сравниваться там x86 и arm и и можно посмотреть что быстрее и должно приблизительно оценить стоимость спасибо спасибо и финальный на сегодня вопросы остальное в кулуарах пожалуйста взрослых спасибо за интерес на такие очки оптимизации к тому сошел нужно здесь мысль промелькнула что да можно ускорять чтение это здорово и полезно и нужно но это имеет эффект и на запись энда надо писать и очень быстро очень много и не терять данные соответственно планируется ли какое там защиты более подробно и разворачивание темы как данной оптимизация повлияют на ворота на запись и не завалено мб ram таким образом на самом деле скорость записи имеет другой порядок по сравнению со скоростью чтения то есть мы видели запись это порядка 1 1 миллиона строк в секунду на одном сервере для достаточно широкой таблицы ну там может быть 10 миллионов для мелкой таблиц или там сто тысяч если она очень толстая а чтение это могут миллиарда строк в секунду когда читаем мелкие станции все такое и для записи уже влияет не время на сжатие данных то есть сжатия если хотите можно и посильнее выбрать и разницу скорости не заметить для мертв 3 таблиц влияют во-первых сортировка данных при записи которого он так или иначе нужно для индексов а во-вторых влияет то что данные раскладываются файлы на файловой системе и если писать мелкими блоками то этих файлов будет много для этого кстати недавно сделали оптимизацию компактные компактный формат кусков он включен по умолчанию так что здесь тоже не парьтесь по умолчанию будет работать нормально если медленно просто записывать в большее число потоков ну извините это я говорю как будто вы это уже не делаете но вы выглядеть как профессионал поэтому я уверен что"
}