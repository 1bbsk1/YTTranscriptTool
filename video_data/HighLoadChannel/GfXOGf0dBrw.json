{
  "video_id": "GfXOGf0dBrw",
  "channel": "HighLoadChannel",
  "title": "Использование Hadoop в Badoo / Валерий Старынин (Badoo)",
  "views": 89,
  "duration": 3111,
  "published": "2017-04-22T11:00:42-07:00",
  "text": "те кто интересуется использованием хадуп а своей практике Те кто уже использует те кто хочет его использовать но пока не знает как или просто может быть боится так же как и мы боялись год назад но в своём докладе я расскажу как фактически перестать бояться его использовать и начать его использовать как сегодня пошутил Один мой бывший коллега это говорит доклад про тот кластер который у вас год простоял И вы на м ничего не делали Да это доклад про тот кластер который сначала мы никак не могли использовать но сейчас он работает на полную катушку и а со временем мы планируем Ново всё новое и новое использование а этого нашего кластера для наших задач вычисления статистики в своём докладе я расскажу Какую мы собираем статистику Зачем как а зачем нам потребовалось вообще хадуп почему так много всего стало объясню Какие простые шаги мы сделали для того чтобы перестать бояться дупа и расскажу что мы уже сделали и что мы планируем делать в ближайшее время ну вкратце о баду баду - это социальная сеть новых знакомств на данный момент это мл активных пользователей это сеть знакомств работает по всему миру работает на любых устройствах То есть это мобильные телефоны это компьютеры в общем Практически везде у нас д с половино дата-центра в Европе в Америке и в Азии в Азии у нас хостинг фотографий поэтому там нет никакого выполняемого кода поэтому половинка и всего это более 3000 серверов и все эти сервера производят какие-то события которые мы потом считаем что же такое событие событие - это действие пользователей в первую очередь основной поток событий - это действие пользователей пользователи кликают в интерфейсе пользователи отправляют сообщения пользователи читают сообщения в общем любое действие пользователи это событие действи модераторов это событие скрипты работают пода какие-то события или серии событий ошибки происходят это тоже события отчёты о выполнении каких-либо задач это тоже события все эти события мы собираем с помощью инфраструктуры построенной на Skype на каждом сервере У нас есть Skype сервер который принимает события от выполняемого кода на этом сервере очень быстро в течение там 500 микросекунд по-моему и дальше занимается его доставкой Он передаёт его на главный сервер на в этом дата центре и оттуда события уже попадают туда куда необходимо skp умеет доставлять файлы только файл он записывает файл и всё дальше с этим надо что-то делать У нас есть разные варианты что с этим делать в том числе и поме вду это использовать дуп мы использовали систему стац коллектора которую я рассказывал на де конфе на хабре можно найти моё выступление ссылки на слайды А в конечном итоге события агрегировать и по каждому пользователю у нас получалась Вот такая вот статистика значит здесь агрегация идёт по дате вот первое число второе число и по идентификатору пользователя То есть получается Например вот это один пользователь за одну дату это этот же пользователь за другую дату и по каждому пользователю мы считаем различные показатели А здесь я представил показатели голосов и время проведённое на сайте то есть Ну понятное дело время проведённое на сайте а это просто сумма а сумма всех отрезков через которые пользователь давал какие-то запросы вот оно суммируется за день и получается такой вот отчёт но у этого были проблемы Проблемы были Ну во-первых достаточно большой объём данных база данных только по допустим активности из мобильных приложений занимало в месяц 350 ГБ соответственно чтобы добавить новую метрику добавить нову коло прихо кой врай де ещё и не пишется таблица заблокирована э ну были разные хитрые трюки как это обойти но это очень неприятно долго муторно а не хватает места на серверах а Понятное дело что просто так там никакой раздельщик не добавишь mysql так не поймёт надо там переносить на другой сервер с большим количеством дисков и так далее вот ну и самое главное что нет детальной информации информация за день вся сегрегированный значения А нашим аналитикам хотелось это знать не каждый день но такая информация им нужна была и в конечном итоге мы решили воспользоваться Ну в общем мы решили что надо как-то что-то придумать и ситуацию исправлять Значит чего нам захотелось чтобы наша новая система могла хранить всё в не агрегированного событие в отдельности всё хранить и хранить Как можно дольше нам выдвигали сроки 2 года Ну мы хотим хранить ещё дольше Мы хотим расширяться без проблем то есть купить новый сервер не проблема Главное чтобы его как-то можно было включить в общую структуру использовать его диски и вперёд решить этот вопрос с колонками но очень он нас напрягал как-то надо было что-то с этим делать и данные должны быть доступны для анализа то есть вариант скинуть всё на ленточку убрать куда-нибудь на полку потом достать развернуть П В общем через неделю аналитику предоставить данные потому что админы тоже занимаются какими-то своими другими делами это не вариант Ну и хочется также использовать что-то SQL подобное или SQL в самом хорошем варианте а потому что привыкли к нему удобно а значит И тут один из наших коллег предложил давайте мы хадуп используем Я говорит на предыдущем месте его использовал нормально работает ну Давайте попробуем продукт известный используется большими компаниями вроде удачно используется вот на конференциях также про него рассказывают взяли поставили работает вот ну наверное подойдёт Ну мы тоже взяли поставили А что с ним дальше делать боимся не знаем как туда данные помещать как их оттуда извлекать почитали книжки там всё как-то сложно непонятно там генерация па ключ значение потом ВМ как-то непонятно Ну в общем Начали его дальше смотреть ковырять и что Оказалось хадуп это отнюдь не чёрный ящик в который там как-то что-то помещается где-то что-то куда-то там можно найти знакомые вещи например файлы хранятся в виде файлив на диске Да имена немножко изменены но можно докопаться и понять что вот это вот этот файл А это приятно хотя бы что-то знакомое дальше данные сами реплицируемый в принципе этим фактом Мы тоже используем этот фактор репликации получается что мы можем потерять два сервера и при этом у нас данные останутся живыми дальше посмотрели есть очень похож по синтаксису на mysql пой даже ски на какие-то функции отсылают на dev.com то есть там строковые функции к примеру ещ какие-то они брались прямо оттуда синтаксис такой же здорово можно что-то попытаться и оказывается ха понимает T файлы и J файлы в результате если взять и создать вот такую табличку Залить туда файлики профа та значит здесь поля пять полей вот перечислены файлики делятся по каталогам в каталоге содержится поле ДТ дата то есть мы всё делим по датам и вот эту дату мы прямо в имени каталога храним а иха это удобно когда мы запрашиваем за одну дату он берёт просто файл из одного каталога не лезет вообще в другие дальше говорим что ряды у нас значит поля разделяются табам а ряды разделяются переносом строки всё данные лежат вот здесь ну это переменная она у нас заменяется на реальный путь и он раз в хайве уже есть табличка потом из неё делаешь Селект он берёт сам читает файл выводит уже как будто прям Селект сделал из точно также как в то есть Казалось бы вроде положили Файлик написали запрос таблицы поверх этого файла и Хаф уже умеет её читать уже умеет обрабатывать то есть здесь же можно и группировки применять и всё всё он уже готов к работе Здорово уже уже не так стало страшно уже стало понятно что не надо ковыряться в глубине не надо разбираться там с пресом оно само как-то работает то есть да дуп - это набор Коле подпорок но он такой удачный что его можно разбирать настав можно не разбирать можно просто взять и использовать А ну и дальше мы начали применять и с помощью дуб мы сейчас сделали четыре вещи во-первых это вот активность про которую я уже говорил дальше мы используем его для длительного хранения данных то есть мы данные из mysql перегружая в дуп в myq долго не храним сделали проект под названием и пишем полною СТМ со всего сайта тоже храним его в дупе на случай всяких подробных анализов может быть которые нам пригодятся значит активность мы начали собирать вот в таком виде действия действия пользователей у нас сайт посвящён взаимодействию пользователей поэтому у нас есть Ну понятно дело время в которое произошло событие пользователь который его сделал и есть второй пользователь по отношению которому это было сделано например голосование за фотографию кто-то нажимает на кнопку но при этом он видит фотографию другого человека Вот Passive User ID - это вот Чья фотография дальше пользователь зашёл к кому-то в профиль это пользователь один совершил действие а зашёл в профиль к другому это соответственно другой это пассивный пользователь по отношению к которому совершено действие дальше пишется действие пишется ещё поле а как бы для просмотров для голосов понятное дело оно будет единички А вот например для времени проведённого на сайте оно уже будет не единички поэтому поле акаунт нужно А значит как мы а в дуп кладём события вроде кажется дуп - это система для работы с большими объёмами данных а событие у нас Одно маленькое Ну там не знаю 50 байт а в дупе говорят там надо данные там мегабайта заливать чтобы файлики мегабайт были А мы его с помощью того же самого скраба собираем собираем А с умеет сам нарезать фрагментами с установленным размером мы берём стам лимит 300 МБ получаем фа по 300е проро с этими событиями дальше мы разделяем таким образом чтобы в одном файле была только одна дата то есть на границе дней возможно попадание в один файл событий с разными датами мы это делим для удобства для того чтобы в разные каталоги положить дальше файлики зипу и заливаются в хадуп всё Мы из маленьких единичных событий создали большой файл удобный для анализа естественно За день таких файлов получается много Но для хадуп Это не проблема дальше мы строим агрегаты сначала таблицу Просто схлопывается всю Ту же самую активность сырые данные у нас уже есть Это хорошо Мы можем с помощью Хава там делать запросы но надо построить то что мы уже имели до этого значит строится в два этапа первый этап суммируется за день одинаковые одинаковые события Для одинаковых пользователей То есть например вот первая строка и последняя это действие голосования Нет ну вот оно у нас так называется А значит пользователь один тот же действия суммируется единичка единичка получаем Вот эту вот двоечку сумма а вторая колонка - Это количество зная сумму и количество мы можем почитать среднее значение да вторая строка И предпоследняя время проведённое пользователем на сайте тоже суммируется получается така такое значение и количество строк просуммировать в этот Log а один к одному и здесь самый главный факт если мы собираем новое событие то нам не надо На этом этапе знать какие значения может принимать вот эта колонка мы просто группируя по ней и всё группируя по дате пользователю и этой колонке неважно какие там значения добавили новое отлично оно сгруппируй и попадет во вторую табличку и всё всё будет хорошо то есть на этом этапе добавление нового счётчика не требует Никаких действий вообще А на следующем этапе мы данные помещаем в нашу базу данных exos exu это такая быстрая колоночная база с которой работают уже наши аналитики Вот и вот на этом этапе это единственное место где требуется указать Новую колонку мы просто группируя по пользователю и по дате А дальше каждая строка в этом запросе это и есть Ну эта строка предназначена для создания новой колонки Всё мы получили возможность собирать ту же нашу активность которая у нас в том же самом виде Она работает мы уже перешли на использование новой системы полностью отказались от Старой это что касается активности второй шаг у нас были другие отчёты которые тоже собирались стац коллектором тоже хранились в масле Да они меньше Но всё равно их много их периодически очищали старые данные А нам хотелось бы это всё хранить хранить долго и иногда ещё кое-какое удобство в обработке получить Дело в том что ц колектор при добавлении новых колонок он старый это таблица не трогает начали передавать больше данных Он новую табличку создал с большим количеством колонок а а старый не изменил что мы сделали просто выгружаем всё в виде текстового файла с заголовком Какие колонки у нас есть вызывается обычный mysql с передачей запроса Select он то пишет файл Ну переправлял зипу кладём входу а при НУ второй скрипк написали который получает на вход список колонок которые нужны и в нужном порядке уже при вычитки файла возвращает значение если колонки нет подставляет значение по умолчанию Там кроме имён колонок передаются ещ типы Ну по типу можно понять если это число то но если это дата то там 4 Ну тире д тире 2 Ну если строка то пустая строка удобно а добавили это всё в конфиг то есть система дальше сама берёт просто конфиг смотрит что нам надо выгружать смотрит есть ли у нас эти данные если нету то просто выгружает если есть ничего не делает ждёт нового дня данные опять появились опять выгружаем всё оно само работает само крутится само выгружает опять же получаются достаточно большие файлы Потому что если мы выгружаем за день там как раз Получается уже файлы мегабайт размера опять же удобно для дупа третья вещь что мы сделали это проект под названием он предполагал как замена Google anals То есть для сайтов Понятно берём Google Anal ставим работаем для мобильных приложени не так глад но оно тоже не совсем хорошо работало iOS VIN Mobile никак подумали подумали а Давайте попробуем сделать начали начали собирать сначала собирать просто события которые происходят в интерфейсе которые не не посылаются на сервер они не приводят к запросу серверному то есть мы бы их так до этого не могли собирать теперь что сделали собираем их на клиенте набралось там сколько-то отправляем на события решили отправлять в формате потому что можно его расширять потом будет и уже проводились какие-то изменения то есть разные форматы для разных приложений а оказалось что что можно это всё дело прям в Жене положить в дуп и потом Ду иха прекрасно работают с этим ном можно всяких разных там вариантов А я вот здесь по-моему Да здесь операционная система можно выбирать здесь а события которое происходит здесь версия мобильного приложения Ну в версию входит также там вот тут тут Android тут где-то был вот iOS плохо наверное видно но в общем статистики море можно из этого выжать и всё это делается запросами в запросами написанными на hql То есть он читает ему всё равно делает это тоже достаточно быстро я затрудняюсь сейчас привести время за которое строится вот эта статистика но агрегирование активности производится 15 минут нашим кластером То есть за день берётся и агрегирующие ID пишем все события стац коллектора которые производятся в процессе этого запроса и в общем это позволяет нам при необходимости подробно Взглянуть на всё всё всё что происходило с точностью до секунды до вызова и проанализировать что-то позволяет иногда статистику которую мы не собирали уже начать собирать если мы знаем адрес по которому был вызов знаем идентификатор пользователя мы можем понять что там пользова зам сделал Ну в общем это всё что мы сделали именно для аналитиков Ну для того чтобы всё наш кластер работал надо ещё немножечко усилий приложить мониторинг Значит мы тут свой велосипед построили На прошлом лоде мы послушали про лаудеру но там бесплатный вариант помоему до серверов хорошему надо лицензировать надо платить там за каждую ноду туда-сюда В общем мы поставили чистый хадуп который взяли на пачев ском сайте мониторинг сделали своими силами мониторим Ну общее состояние серверов там пингуется не пингуется мониторим количество дата нодов и таск трекеров Ну это количество серверов хранилище серверов обработки Бывает такое что сервер выпадает бывает наоборот что админы там-то запустили взяли новый сервер в кластере которого не ждали тут на него репликация полилась вот количество блоков это излишних И наоборот если нода отвалилась то часть данных недостаточно реплицировать Ну естественно данные бэкапить уже сложно их много то есть мы их не пим Они и так Потри копии имеют а вот единую точку отказа наду мы вынуждены бэкапить во-первых исходные файлы хранятся 2 дня на серверах с которых мы их загружаем То есть даже если всё пропадёт мы наду из старого какого-нибудь кПа развернётся только лишь описание которое описывает имена и блоки составляющие эти файлики и делается такой ещё п который позволяет вообще вручную даже всё восстановить я уже говорил что Всё лежит в файлика так вот если дать команду ходу поск с таким набором параметров то выданной информации достаточно что из ках блоков сле обычным катом то есть в один файл это ВС сливаем и всё вот можно даже вручную восстановить Вот так мы бекам может быть несколько кривовато но это имеет под собой определённую основу сейчас Вот потому что проблемы сам решает все внутренние проблемы как хотелось бы то есть он может не очень очевидно о них предупреждать может быть мы конечно не умеем его готовить ещё так сильно но факт остаётся фактом Например если появляются сбой нае блоки то при чтении файла периодически выдаётся ошибка типа мы Ну тут попытались прочитать Но у него не сошлась контрольная сумма ча там с третьего раза он вс-таки выбирает с другого сервера фай читается приходится чуть ли не вручную просто удалять файл заливать его заново то есть вычитывать его к себе в конечном итоге Удачно и потом заливать обратно один раз у нас был была история мы долго искали битый диск появлялись нереплицируемый от версии к версии меняется AP меняется название параметров в конфигах Ну в общем меняется практически всё то есть обновить вот просто взять обновить нельзя надо поставить рядышком посмотреть как настроить то же что мы настраивали посмотреть дефолтные настройки которые могли вполне поменяться сравнить всё это дело только потом уже можем обновляться вот Ну в общем вот такой вот он забавный любим применяем вот значит что мы хотим в будущем сделать Хотим мы обновиться с ходу на которого Мы начинали мы его не трогали вот по этой причине что сложно обновляться Мы хотим обновиться до вот свеженькое версии 2.5 а хотим попробовать вообще использовать Спарк потому что обещают очень серьёзный прирост обещают что если вы будете все данные необходимые хранить 100 раз быстрее это интересно это уже ближе ближе ближе к тому что мы хотим и хотим ещё найти какую-нибудь замену skp потому что проект практически не поддерживается Да он сейчас работает в той конфигурации в которой У нас есть но хотим попробовать что-нибудь поискать ему на замену какую-нибудь другую систему которая будет доставлять нам сообщени Ну со со все со всего дата-центра на центральный сервер там уже обрабатывать вот ну и напоследок немного ГИГПОРНО Итак Встречайте его силён быстр вынослив наш дуп кластер Итак наш дуп кластер состоит из 16 серверов один из них - это Неда она несколько похуже по конфигурации четырёхъядерный процессор с гипертрейдинг То есть получается во 64 гиб оперативной памяти один жёсткий диск 1,1 траб Ну видимо у админов только такие были А потому что он не используется там он используется процентов на 10 от силы значит и 15 dat Note они помощнее потому что на них же не только данные хранятся но ещё и обработка производится это шестнадцати ядерный процессор с перрен и 32 192 ГБ оперативной памяти и дисковый мас из Дис по 1Б диски не объединены никак они просто смонтированы в 10 разных каталогов и ходу пузано Вот у тебя 10 каталогов куда класть файлики Окей хорошо Буду буду размазывать их сам Вот и теперь к объёмам данных которые мы собираем значит активности у нас 100 Гб в день собирается глик стрима 1,2 ВС это дело сжимается получаем 27 гигабайт в день в сжатом виде газипаши дисков мы а ежедневно забираем вот ну и объёмы по по количеству событий примерно одинаковая у активности и у Клик стрима по миллиону то есть где-то 2 млн в день у нас набегает А вот так мы и живём Спасибо за внимание ваши вопросы А здравствуйте Спасибо за доклад у меня вопросы и комментарии одновременно А я не очень понял почему вы выбрали хранение данных в ходу в виде текста зипо воно а при том что как бы есть нативные структуры типа ц файлов и оптимайз РЦ файлов которые вам сразу на порядок увеличат скорость выборки через хайв вот Ну мне интересно почему именно это и ну и комментарий как бы если мы при этом ещё возьмём МПУ мы получим ещё на порядок выигрыш вот ну меня больше ответ на вопрос интересует Спасибо А значит если я ничего не путаю то RC - это не текстовый формат А да это не текстовый формат но тем не менее Он поддерживает блочное сжатие оптимизирован для колоночные структур и всегда можно селекто интом получить текст обратно да Значит мы думали об этом формате но он жёстко привязан к хадуп когда Мы начинали всё это делать мы не были уверены в том что мы останемся на хаду Почему у нас есть и всевозможные варианты вот пропадает Java с хопом У нас есть всё чтобы восстановить все наши данные Мы же боялись его использовать и мы не были уверены мы рассматривали этот вариант но он требует дополнительно дополнительного преобразования здесь все преобразования выполняются очень-очень простыми средствами Ну и вот этот вот миллиард событий в день он обсчитывают я уже сказал за 15 минут даже меньше меньше по-моему сейчас минут за 10 уже кстати ускориться нам удалось после того как мы исключили старые медленные ноды Удивительно но факт об за это время Новые заканчивали свою часть работы делали е и часть за старые В общем лишняя перегонка данных по сети она была просто лишнем когда мы избавились от этого мы ускорились вот ну в общем Формат Просто потому что он не текстовый мы не можем его прочитать глазами плюс тексто очень удобен для отладки сечас Сначала отстроили это а вот как раз сечас мы подходим к тому моменту когда мы будем пробовать что-нибудь новенькое ещ Добрый день лоскутов Максим у меня такой вопрос Вы сказали что у вас есть некий буфер компонента которая собирает мелкие логи по 300 после этого с Мадо нае коно копированием Почему скажем не взять кассандру которая специально предназначена для быстрой записи мелких сообщений логов при этом интегрируется с хадум фактически по интерфейсу фса не имеет мастерноды поскольку является децентрализованным хранилищем тоже реплицируемый имел опыт работы с хопом нет вы не поняли Касандра она заменяет В дупе фс то есть является хранилищем причём специально нацеленным под мелкий Ну запись большого количества небольшой Информации а дуп непосредственно библиотеке мадса они также по тем же интерфейсам что и к дфсу умеют подключаться к Касан соответственно мы Решаем проблему с мано е копированию Потому что Касандра децентрализованное хранилище это раз а во-вторых Решаем проблему с вот этой буферным звеном которое собирает данные мелкие в большие файлы Ну данные это собрать нам всё равно надо будет ну их надо можно просто напрямую лить в кассандру А если мы начинаем напрямую лить в кассандру то мы упирать каждый скрипт должен подключиться к кассандре и отправить туда сообщение это долго Ну Касандра децентрализованная мо н нет у нас Skype запущен на каждом сервере локальный Skype запущен на каждом сервере приложение отдавая сообщение подключается локально и отдаёт его очень-очень быстро а дальше локальный Skype уже занимается доставкой в центральный Skype то есть вот этот вот как раз та Ути который вы говорили SCP Значит доставка производится отправка для для приложения производится практически мгновенно если мы включаем туда работу по сети то мы сразу увеличиваем ну на порядок Я думаю из-за сетевой задержки Понятно спасибо Добрый день У меня такой вопрос А вы не подскажете насколько изменилось количество нот после того как вы перешли там с решения на mysql с mysql находу количество НОД Ну как сказать а статистику по Ну статистику по активности Мы собирали на двух на двух серверах mysql но у нас не было детальных данных поэтому Ну как сказать Да оно увеличилось увеличилось в восем раз но мы собираем намного больше и подробнее данные Поэтому я считаю что это оправдано они оценивали если бы остались при той же технологии мы бы просто не смогли собирать эти вообще у нас агрегированные данные занимают 350 Гб в месяц А теперь Представьте Какой объём занимали бы сырые данные там примерно в восемь раз они уменьшаются после агрегации спасибо понятно здравствуйте Скажите а Судя по тому что я видел слово Таре вы всё ещё используете mce первая версия Да мы планируем переход на вторую версию на ярно Да как да О извините я вас не могу найти да Вот он я а как у вас так вышло что когда вы запускали доставщик данных вы взяли именно Skype он ну довольно давно уже не поддерживается Почему сразу нет Skype у нас используется по-моему с 2011 может быть даже с 2010 года То есть у нас есть сеть Skype которую мы он у вас использовался раньше для чего-то Да да у нас стац колектора поверх него плюс там разнообразные логи собираются Ну просто данные передаются ещё тоже другими командами он у нас есть а на что вы больше смотрите на люм или на кафку Вы знаете я пока просто смотрю В общем Потому что я не не проводил ещё тестов и у нас есть план по которому мы будем тестировать А у нас то есть есть критерии по которым мы будем выбирать возможно какой-нибудь следующей конференции если мы сделаем этот выбор я подготовлю доклад о том как мы выбирали что мы выбрали Ладно спасибо Добрый день Меня зовут Владимир Спасибо за доклад скажите пожалуйста вот вы сказали что дуб страшный постоянные апдейты меняют всё но тем не менее Вы его любите А сколько ну времени занимают апдейты у вас вот с учётом всех этих невнятный непонятных изменений и насколько вы отстаёт от последней версии из-за невозможности нормального апдейта то есть насколько вообще реально его использовать в большом продакшене и Сколько времени занимает Ну после того как всё настроено А ните вы уже не надо то есть если Прошу прощения если Ну нет никаких поломок то он просто работает ну а переход на новые версии апдейты м вот мы будем делать переход тогда после этого я смогу вам сказать Наверное в начале следующего года То есть вы живёте на той же версии на которой начали сво Прошу прощения Да понял спасибо да именно так Валера привет Спасибо за доклад вопрос про активити сами события по идее Они же разнородны по структуре да то есть нет они однородны структура строго однородна Ну сейчас у вас да а по идее например там Клик по фотке Да там или лайк фотки он помимо там дишни фотки Да этот Passive object Он же по идее может ещё держать там например там ID альбома этого польз наме и так далее То есть какой-то контекст е дополнительный Я прошу прощения Одну секундочку значит по поводу уже дальше анализа весь дальнейший анализ производится Ну в нашей аналитической базе данных Где есть данные о пользователя полностью там страна по возраст мы не храним это в каждом сообщении те же самые данные про фотоальбомы Ну фактически Да мы не анализируем на данный момент по какой именно фотографии щёлкнул пользователь на какой он поставил лайк Вот Но во-первых это можно выдернуть из Клик стрима но просто наши аналитики пока не просили этого делать Вот длях в другом формате Но это бывает реже это бывает реже поэтому Ну в общем этом потоке активности мы не собираем такую информацию она вот сугубо однородна понял спасибо А вопрос такой А я правильно вот понимаю что вы Пите свои данные так несколько по-своему Да вфс и обычный бэкап просто Ну я к тому что была ли у вас прецедент того что вы восстанавливали файлы из этого бэкапа прецедентов на боевых серверах не было но мы проводили тестирование А что будет если мы сломаем вот так то есть мы взяли отдельно кластер налили туда данных Начали его ломать и всё удалось А по времени то есть ну по времени Естественно что это будет очень долго надо будет найти все эти файлики надо будет это всё сделать Но это просто возможно А ещё я правильно понял что вы не используете нли для собственно сбора с вообще данных с вашего кластера то есть мы используем scpe нет а данных именно по вашему кластеру то есть с hup Note с dat noe например то есть Ганг именно для мониторинга то есть очень такая полезная штука именно для хо нет нет О'кей спасибо мы пользуемся стандартными средствами дупа он выдаёт отчёты о статусе НОД мы запускаем ЦК на нох периодически и дальше Просто парсим текстовый вывод Ну все наверное знают Я просто ну такой может быть совет то есть поте в сторону нли Очень полезная штука именно для сбора статистики по самому кластеру и для визуализации там агрегации всех данных именно по вашему кластеру е раз Как называется Ганг Очень полезная штука Спасибо Спасибо Спасибо вам добрый день спасибо за доклад есть вопрос я здесь есть вопрос по поводу опять же отказа устойчивости Да вот лаудера рекомендует использовать не больше 30% занятости дисков на дата нода Как вы с этим боретесь Что делаете И вот когда бы у вас вот такой Крэш тест сколько как бы НОД вы убивали Ну естественно две при Факторе ции 3 30% То есть получается что ставим диск Там на терабайт используем 300 гиб я не слышу К сожалению а не могли бы вернуть микрофон Да клаудер рекомендует вот использовать не больше 30% да то есть ну занимаем в случае вот если делаем три копии Да ну как бы блока если две умирают остаётся как раз именно видимо одна вот как вы с этим боритесь Нет я я не могу понять суть вопроса Ну мы используем допустим нет 30% жёсткого диска не вижу я не понимаю почему была Дана эта рекомендация потому что ну какие-то внутренние перераспределения что ли внутри жёсткого диска но нет я не понимаю почему надо использовать 30 я сожалению тоже нет нет мы по крайней мере я такой рекомендации не в курсе и у нас нет такой цели использовать не более 30% можно добавить поводу 30 дис процентов тут видимо речь идёт о том что на самом деле в фесе нужно оставлять какое-то место но там не 30% А желательно там 10 или 15 но про 30 Вот ну как бы 20 это вобще хорошо но 15 в принципе по практике вполне хватает вот а что 30 диск такого как бы нет Это очень накладно будет А ну то есть на случай если сервер выходит из строя чтобы было место для репликации ну для чтобы он перебан сирова могу продолжить Да там ворнинг при 20% Critical при 10% места на hdfs Для нормального распределения и возможности дополнительной репликации при выпадении дата ноды А у меня такой да Вопрос Это в принципе ну разумно вполне требование А вопрос мой у вас достаточно такая сложная кастомная штука сохранением текстового вывода есть у кры из Яр они взяли решение Ну когда две и наверно версия 2 Да это версия 2 но они это сделали дай до по-моему вот не помню 1 или есть до первой версии без они тоже сделали они выложили это назад в Open Source можно это взять использовать Это значительно более проще чем было уже достаточно хорошо а 192 гига Откуда такая на одну ноду вышло решение пото что достаточно Ну много вроде бы и никакого H и прочего им не используете зачем столько оперативки как было решено Кто решал опять же я не в курсе Ну не на некоторые вопросы к сожалению не могу ответить Я не принимал участие в А какой там Ну то есть насколько они все утилизируются вы не знаете не готов ответить Ладно спасибо Ну мы планируем переход на более современной версии как я уже говорил причём буквально вот в ближайшее время и там я думаю что будет память использована на пол и ещё такое тоже дополнение в принципе Shark считается уже устаревшим сейчас Спарк SQ от создателей же спарка продвигается так хорошо вообще на самом деле Да Я когда посмотрел на сайт спарка Я не нашёл упоминание о шарки Ну возможно человек который мне это говорил о наших планах он несколько его информация несколько устарела о том что мы будем использовать Ну будем использовать самое современная по возможности Добрый день У меня два вопроса Первый уже вскользь упомянули это если у нас скажем вопрос начинается Если у нас нейм ноды выходят из строя Вот то есть Мета информация вся погибает как вот нам СБО звено Ду есть если кандра у на восстанавливаем А если у нас там 3000 серверов скажем Ну очень много То есть как это всё решать вот эти вот они тоже как бы ну ну скажем они обе погибли или как там как вот с этим быть это первый вопрос второй вопрос такой больше как бы программистский почему выбрали имен в качестве люча дату сегодняшний зали этот ключ как-то по большему количеству серверов то есть по дате Они же локализовали данные на каком-то сервере и мы все запросы за сегодня у нас они скорее ну там на один или на реплики пойдут Ну всё-таки не по кластеру размажу как бы нагрузка Я понял Я понял просто мы уже Время заканчивается а значит за один день получается гораздо больше файлов чем у нас то есть один файл минут за соответственно количество файлов Можете посчитать и на одной ноде будет обработано больше одного файла на каждой ноде то есть данные не пойдут на один сервер за оди день Ну если мы возьмём сколько там получается несколько гигабайт и у нас файлики там по 70 мегабат втом виде Сами понимаете будут об по поводу отказа устойчивости Ну Дело в том что п кластер на п машин п кластер на 50 на 100 на 600 там на 1000 и на 3000 это разные подходы это всё по-разному Поэтому о 3000 мы пока не мечтаем у нас пока нет столько денежкой день Скажите пожалуйста вы говорите что выкачивает данных для анализа вы не рассматривали вариант готический запрос непосредственно по Клару и допустим ЕС поставите будет работать 100 раз быстрее гда я понял Значит у нас для отображения данных применяется такая система как mic она позволяет вильно Ду в том виде в котором есть сейчас он Дат ответ на сложный вопрос но медленно он может дать ответ на простой вопрос но в принципе тоже не быстро поэтому использовать его в связке с M на данный момент не получится со спарко Возможно да возможно мы перейдём к использованию дупа напрямую но пока нагом ко Возможно мы конечно же перейм потому что дополнительный шаг использование места в этой базе которая лицензируется по месту и так далее да мы откажемся от такого перекладывания лишнего Ещё вопросы есть ещё пару минут есть вопрос в приложении в нашем от возможно о немного невнимательный Вопрос такой сколько серверов у вас в кластере и какова их примерная конфигурация и вторая часть вопроса как часто случаются таймы у вас п кластер ещё ни разу не было в тайме Ну а вопроса конфигурация вот он ответ на вопрос ещё есть вопросы Спасибо за доклад Спасибо за вопрос вопрос Дайте микрофон Добрый день спасибо за доклад вот по моим подсчётам у вас место закончится где-то через 60 дней как вы Мы удалим Стрим Мы удалим старый кстм удаляете Стрим да То есть данно активити вы храните долго данные активити мы храним пожизненно То есть у нас спросили 2 года но мы будем их хранить пожизненно Я думаю что нам запрут увеличение места в кластере мы будем удалять кстм А здравствуйте Скажите пожалуйста вы используете ходу потому что из ваших коллег имел опыт работы с ним правильно а другие колоночные базы вообще рассматривались как-то верти хадуп не колоночная база ходу сейчас я я поясню я понял у нас используется exos Solutions распределённая колоночная база А с ветико у нас Дружба не сложилась А по каким причинам А давайте я отвечу на вопрос рох я Я не готов просто я не знаю официальную политику партии по этому поводу на данный момент мы только маленькую часть данных предоставляем Ну нета но около того где-то задержка в час но мы планируем сейчас изменить структуру загрузки данных таким образом чтобы предоставлять все данные с Ну по возможности там небольшой задержкой то есть мы Ирано просто дорабатываем нашу систему и вот приходим тому что мы хотим прийти к этому"
}