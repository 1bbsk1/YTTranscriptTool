{
  "video_id": "cHo1z4Fmu0k",
  "channel": "HighLoadChannel",
  "title": "Метаданные для кластера: гонка key-value-героев / Руслан Рагимов, Светлана Лазарева (RAIDIX)",
  "views": 687,
  "duration": 2880,
  "published": "2018-08-16T03:53:35-07:00",
  "text": "здравствуйте меня зовут светлана лазарева я вместе с русланом рагимова представляя первый доклад нахалу hail audi который называется метаданные в класс террикон какие вылью героев все забудет извините за задержку уже включено отключен мы работаем в компании редис который является ведущим российским разработчиком высокопроизводительных систем хранения данных мы являемся программно определяемым исходы и и если раньше лет там десять назад аппаратный рейд софтверный rate спорили между друг другом теперь пор спорят традиционной системы хранения данных и программно-определяемые сходи и они уже начинают побеждать на рынке и о том как какие большие проекты есть нашей компании в шесть часов вечера рассказы сергей платонов в пекине всех приглашаю на этот доклад я хочу моя часть доклада будет посвящена тому что такое метаданные в кластере какие к ним предъявляются требования а конкретно уже руслан расскажет о тестировании киева и бы баз данных с учетом тех требования которые возникают для метаданных когда любая коммерческая продуктовая компания начинает разрабатывать новый продукт она смотрит что будет в будущем так вот будущем считается что у нас будут побеждать программно-определяемой исходя потому что часть переместиться в облака где системы хранения данных будут использоваться какой слуга те кто не хотят хранить данные в облаке будут покупать произвольное железо и соответственно будут хранить это программно определяемых хранилище где уже на любом железе будет строиться софт который будет обеспечивать доступность надежность и отказоустойчивость рынок растет растет большими темпами очень много стартапов здесь и в общем-то считается что за этим будущее о каком рынке мы вообще будем говорить но первый мы сегодня будем говорить о распределенных системы хранения данных потому что мы понимаем что каждый щелчок фотоаппарата соответственно это все прилитит нам систему хранения данных мы говорим о блочным старриджа то есть это самый низкий уровень который есть мы говорим о дешевых из kd которые используют комнат этих ардва то есть для нас и для наших заказчиков главная стоимость и соответственно сейчас появляется очень много бесплатного софта не программно определяемых сходи потому что продает поддержку и все конечно хотят чтобы она была гибкой в настройке обслуживание быстро развертывалась легко управлялась вот поднимите пожалуйста кто знает что такое цепь дело в том что цех это в систему хранения данных и то сейчас такой очень большой тренд когда говорят об распределенным программно-определяемой исходы и в общем-то считаете что может быть это даже будет вот это базан мы который будет все устроить программно распределяем и исходы что же это такой вот не так было много рук более десяти лет назад как студенческий проект появился проект cf который разрабатывался в университете а сейчас это активно развивающейся open source и на каждом докладе сейчас по системам хранения данных на любых конференциях к все приводит в форте о том какой цех медленный их что они сделали для того чтобы его выставить надо понимать что цех изначально не создавался как производительная система хранения данных потому что не для всех нужно производительная она создавалась для того что когда у нас распределенную систему у нас много дисков то практически всегда система работает тигра ведь это режиме что-нибудь где-то вылетает какой-то диск и мы должны его быстро восстанавливать теперь когда у живут две недели надо наш глисты анонсировал что они по тебе дели гектору ему мамарр и говорят что у 23 года пройдет у нас будет 40 терабайт ные жесткие диски а еще ведутся вообще там исследования как статей в россии так и в сша о том что будут какие-то пятимерные на накопителе которые будут там размером 25 центовые моменту который там 360 терабайт и хранить данные и не портятся как сколько у нас возраст вселенной но это будущее она настоящая цех плохо работает большими дисками и на обочину уровне у него отказоустойчивость с помощью репликации гарантируется соответственно я не могла не предъявить все парки о том как мы протестировали цех мы взяли классе 1 12 нот 2n время диска в каждом и после этого отключили отказоустойчивость тестированием максимальную производительность без реплики взяли cf последний конфигурации blue star где метаданные на рок сгибе напомним что метаданные на rock baby сравнили их с нулевым md рай дом по технологии эфир из 5 детей и еще когда мы говорим о система хранения данных просто всегда все вспоминают за tfs кто нибудь знает что такое за tfs поднимите руки он медленный о том как это ведь мы из этого из ничего как сделали сетевой могу рассказать после доклада это конкретно как тестировали когда тестируя системы хранения данных не надо говорить на цифры смотреть надо смотреть на их относительные но я предъявила не относительные цифра настоящего чтобы вы поняли что я вас не обманываю так вот цех медленной мы 24 января диска 1 н в н ы м е диск на рэндом рид водоем где-то 770 к я ем в которые мы тестировали на арендам раз где-то 260 300 мы видим что мы получили производительность его closer а меньше чем один диск зад и вас еще медленнее md рейд на используя технологии в выдает нам максимум бэг-энда вот к чему мы хотим стремиться и соответственно и ниже чего мы падать не ходи в тон нужно рынку именно сейчас данный конкретный момент рынку нужен быстрый время рейд потому что на самом деле никто еще не может работать такое производительность утра страдает до топаз быстро сетевой инженера и но на самом деле надо понимать что не каждому приложению нужны эти миллионы ой упс потому что не в нужно производительность ну может ли ваше ваше приложение там 10 миллионов aiop обработать секунду или она захлебнется из-за этого я сейчас хочу рассказать о рынках где действительно важна производительность производительность нужно там где есть потоковые последовательное чтение или запись рынок aspesi и это и чередование последовательный записи чтения в сотни тысячи потоков это у нас enterprise базы данных где у нас идет рандомная нагрузкой периодически запускается рабочие предложения с последовательно это же чтение в сотне потоков медиа нагрузка раньше она считалась медиарынок это чисто потоковый теперь это уже переходит тоже в рантом но рандом там интересные торрентом ride and bright большими булками по 512 мегабайт а мы обычно привыкли что рандомная нагрузка над маленькими блоками идет соответственно требования которое предъявляется к распределенной системе данных конкретный сейчас из-за блендер эффекта мы считаем что все случайно и потому что если у нас будет для того чтобы разобрать последовательную нагрузку в тысячи потоков у нас должен быть очень хороший анализатор это опять зубы и тормозит до топаз размеры блоков соотношение берем 50 на 50 лет инси один две миллисекунды для flash потому что современный флеш диски уже выдает две миллисекунды максимума и производительность от 300 до 500 к aux на узел это уже то что есть на рынке у дорогих систем и соответственно вот мы решили что рынок нуждается в распределенной системе хранения данных вообще вроде ты уже есть своя распределенная система когда ставится родиться на него ставить распределенная файловая система например люстра но она на самом деле у таких систем меньше доступность получается если чисто математически по формулам посчитать хоть и доступность 5 9 то есть простой пять минут в год когда уходит на какое-то техническое обслуживаем хотим распределенное кодирование место репликации сейчас на рынке этого нет а у нас самый быстрый имеет лог структурированная запись большой вопрос нужно на или нет дедупликации обязательно потому что мы идем гиперконвергентное системы где будет виртуализация а степень и дупликация 60 процентов если мы говорим о недорогом стороны значит облигация должна быть гибридное хранение snapshot а теперь вот поговорим вообще что такое метаданные в данном случае какие вообще запросы приходят к сходи но первое это время поступления запроса от клиента от которой мы читаем собственной пенсии играть должны гарантировать коз потому что критические бездны и бизнес-предложения особенно в меде очень к этому чувствительные потом тип запроса чтение или запись логически адрес первого блока который приходит от предложения файловой системы и размер запроса собственно что давно сделать система хранения данной блочная система хранения данных определить откуда читать и писать и вы да как это можно быстрее минимален в пенси вопрос во всех блочных система хранения самое медленное и торрентом райт потому что на 1 у нас приходится 3 соответственно все знают что если делать это обычно это будет медленно потому что происходит ритм эти файлы и есть смог структурированная запись который там этапе например это когда мы пишем все подряд это замечательно быстро потому что мы мы случайно вот запись превратили последовательное но нас получается много метаданных теперь у нас нету прямой адресации то есть мы не лба переводим слабо а мы должны где-то эту информацию хранить тогда на 500 терабайт closure а нам нужен один терабайт метаданных идем дальше что такое блочная где публикация на блочном уровне как я говорю что это маст хэв уже для виртуализации это когда мы запилим ни одного мистера смита немного мистера все готово всего 1 то есть означает в тур блочный уровень мы берем наши запросы на боте одинаковые длины или перемены смотрим совпадение ноликов единички если в совпадает то мы не записываем оставим только ссылку когда на 800 терабайт уникальных данных на надо 2 терабайта метаданных тоже очень много и мы понимаем что что у нас такое тогда получается метаданные в классе это plb когда мы сохраним где физически находятся паба плюс хэши для дедупликации плюс статистика для пилинга и получается довольно весомые метаданные их много петабайты информации которых возникла терабайт и метаданных где хранить конечно приходит первым что нам в голову это взять какой-то кей вылью базу данных но для кейлин база данных мы предъявляем два требования и такос то есть вот это не меньше чем две миллисекунды потому что есть у нас будет больше то у нас будет lantra пенсии пока это дойдёт до диска и например для медики у нас дроби цифра им это будет очень плохо и самого второе соответственно это производительность и вот о том как мы тестировали именно различные кей вылью базы для такой конкретной задачи у нас раз конвертер флаг всем привет ещё раз меня зовут руслан напомню всем слышны кто на задних рядах все меня слышат все хорошо на отлично так значит я вам расскажу про вот сами метаданные про техническую часть такой доход доклада поднимите руку те кто вообще я понял что такое метаданные примерно кто знает да ну супер с большинством поняли тогда давайте посмотрим как же выглядят наши метаданные я вам вкратце расскажу вот у нас все пространство хранения разбита на некоторое количество страниц 4 килобайтах страница это минимальная единица чтение записи у нас в кластере и для каждой такой страницы у нас естественно есть адрес 8 байт не довел бы логический адрес блока и есть метаданные вот для каждой страницы мы хотим хранить некую пачку метаданных это 16 байтов принципе неважно что там внутри важно что 16 байтов давайте посмотрим насколько у нас вообще таких страниц в кластере будет давайте рассмотрим один узел в кластере вот если у нас в одном узле хранится 1 миллиард таких страниц 4 килобайтах то мы имеем всего 38 терабайта данных на один узел в кластере это очень мало естественно для кластера хранения но мы уже получаем 22 и 3 гигабайта метаданных 22 и 3 гигабайта это немного совсем мы можем это положить в оперативную память у нас будет быстрый доступ все в принципе хорошо ну давайте чуть более реальные цифры посмотрим вот 60 60 4 терабайта шестьдесят четыре терабайта на узел уже дают нам 17 миллиардов страниц 4 килобайтах для каждой страницы мы храним метаданные в итоге у нас получается уже триста восемьдесят четыре гигабайта метаданных что довольно таки много и положить эту оперативную память будет дорого стоить просто и идеал которому мы стремимся это пол петабайт а данных на один узел в кластере и это 137 миллиардов страниц и 3 терабайта метаданных сами понимаете довольно-таки прилично и приличное количество метаданных и давайте посмотрим вообще как как можно хранить это все дело первый вариант который приходит голову светлана уже упомянула это key и value база данных все просто лба то есть адрес страницы это ключ и метаданные то значения то есть ключ 8 байтов значение 16 байтов все хорошо второй вариант это прямая адресация сейчас я чуть более подробненько расскажу про прямую адресацию чтобы вы поняли что я имею ввиду вот возьмем просто некий накопитель на котором мы хранить нашими то данные возьмем из него первый сектор сектор у нас 512 байт of доу блочного устройства в этот сектор у нас влезет 32 вот этих экземпляра метаданных ну то есть у нас метаданные то 16 байтов 16 умножить на 32 512 да вот так мы возьмем положен для первых 32 страниц в нашем кластере положим метаданные в первый сектор для следующих 32 страниц во второй сектор все по порядку торгуем сохранять тогда нам не нужно хранить сами лба до сами адреса страниц мы храним только метаданные это удобно то есть мы получаем полтора раза меньше метаданных но у прямой адресации есть свои минусы я расскажу об этом в конце доклада если успеем сейчас давайте посмотрим все таки на key value базы данных до попробуем все-таки их использовать для нашей цели значит первое с чем мы столкнулись когда начали выбирать такие value база данных ну вообще они говоря вообще говоря они делятся на 2 типа первый тип встраиваемые так называемые движки да и танец виду какая-то библиотечка небольшая которую вы можете у себя в коде подключить за included и вызывать методы да и пользоваться в общем услугами этой библиотеки второй вариант это выделенные базы данных я так назвал выделенные на самом деле их можно еще назвать серверы б д ну и сквер базы название много я назвал выделены и выделенные базы данных это уже некий это некий отдельный процесс которые крутятся на машине да и мы к нему можем обращаться там с помощью сокетов и так далее у них обычно есть дополнительная функциональность типа реплицирования это далее из них можно классов например сделать вот мы посмотрим принципе на оба типа сегодня давайте начнем вот со встроенных чем можно все это дело тестировать первое что приходит в голову и в поиске это у нас в айсе изгиба нч марк популярный довольно таки он является неким отраслевым стандартам ему доверяют все у него очень удобно настраиваются work воды можно в конфиг файл и прописать все что вы хотите да какой workload все супер есть такой один нюанс у него можно назвать минусом данном случае можно ли он сам просто это то что написано на джаве что это нам дает ну довольно таки много ресурсов относительная кушать java и естественно немножко может влиять на результаты тестов то есть какие-то искажения до вносить во первых во вторых многие движки они все-таки написаны на си си плюс плюс и из java использовать си плюс плюс движки сложнее чем из самого си си плюс плюс правильно поэтому довольно сложно писать драйверы для движков для в айсе избе то есть для рисков не очень хорошо подходит второй вариант iii arena я думаю не слышали скорее всего вы такой benchmark но тем не менее он есть он как раз для движков изначально делался он написан на си проблема у него в том что мало work лодов пришлось самому в код лезть добавлять ничего страшного какие же у нас war клода основной workload как вот говорила светлана это 50 процентов чтения писать процентов записи но мы решили посмотреть на еще на 3 вар клода это 7030 3070 и чистое чтение что понять как вообще база себя ведут вот кто-то на чтение хорош кто-то на запись да и вот это все посмотреть методология тестирования ну тут все довольно таки просто первым делом мы заполняем базу до нужного количества ключей то есть у нас там один миллиард помните 1737 вот заполняем до нужное количество ключей сбрасываем кэш это важно потому что иначе результаты тестов потом будут нечестными второе тестируем в 32 потока это все дело прогоняем те work лады которые которых я говорил и между в окладами опять же сбрасываем конечно это важно то же самое делаем на двести пять шесть потоков вот что будем измерять как обычно количество операций в секунду до труп пропускная способность это можно еще назвать будем измерять я называю это aiop сами но да никто не называет рпс то есть request of для в секунду и т.п. с транзакций секунду в общем а yoxa я буду говорить опции чтобы меня понимали просто значит и в этом си будем измерять минимальную максимальную нет не очень интересно на самом деле вот более интересно среднеквадратичное значение да не отклонения значения и перцентиль 9999 конфигурация у нас была следующая тут кто хочет посмотрит я единственное что скажу это то что храм был взят такой маленький специально потому что нас интересует именно тот момент именно так конфигурация когда у нас данные не влезают в полностью наша мета-данные не влезают полностью оперативную память до часть влезать часть не влезает поэтому взял специально такой маленький объем на что ей важно то что до н в н е диска используется использовали один диск в итоге в тестах потому что ну и было два в целом но даже из одного что-то не выжили вот взяли протестировать вот четыре таких претендентами рука тебе все слышали фэйсбуке и база до варят tiger это движок mongo db интересно было посмотреть да что он там может и софия софия такая думаю наверно вы не слышали скорее всего такую базу ну тем не менее отчета предпочитал посмотрел стало интересно да что она может индекс он здесь немножко отличается от этих ребят у него используется b плюс дерево в отличие от того же rox baby где lsm деревья вот эти себя популярные сейчас у него бы плюс дерево dbx это является формам л н д б только таким улучшенным там поработал в общем человек на надежностью и так далее вот стало интересно тоже посмотреть что будет значит тут важный вариант но важный момент при тестировании вас очень большое влияние оказывает надежность записи на скорость записи здесь принципиально есть три варианта вариант надежности первый вариант это абсолютная надежность скажем так missing максимальная надежность что значит она дает когда нам приходит запрос базу данных мы сначала пишем все это честно на диск и потом говорим клиенту окей мы записали значит второй вариант это отложенная запись это когда у нас приходят запросы сколько-то приходит приходит мы эти все запросы кладем в буфер какой-то оперативной памяти и отвечаем сразу же клиентам что все мы записали будто бы да ну реально на диском еще не записали и только через некоторое время этот буфер он ложится до сбрасывается на диск и тогда мы все уже записали то есть есть некоторые как некоторое количество данных которые мы можем потерять есть нож ну да ну sing режим это когда мы сбиваем на запись данных на диске записан просто когда-то может быть от операционная система сама сделает в общем вот такой вариант не для продакшена да поэтому я выбрала такой сбалансированный вариант это отложенная запись ну какие у нас общие результаты тут получились давайте посмотрим вот у нас есть четыре базы до непонятно где какая вот хочу от вас какие-то предположения услышать давайте срок с биби начнем как думаете rock baby это у нас какого цвета желтое думаете а еще еще варианты ч черный вариант нет ну смотрите rock baby на самом деле вот он красный тут у него интересный момент есть один видите после 800 миллионов чет начала его немного мотать вот то есть сначала шел вроде стабильно все хорошо было но потом что-то с ним случилось хорошо давайте a wild tiger синий черный слышу кто-то сказал желтый желтый правда в aire и тагир здесь показал себя лучше но такая кардиограмма у него какая-то получилась немножко нестабильно как-то да но в целом в целом по среднему до хорошего значит ну софия синяя не буду уже тут тянуть значит imdb x черный смотрите с индексом интересная вещь видите в какой-то момент он взял резко упал это у нас произошло вот ровно в этот момент когда данных стало больше чем оперативной памяти из этого мы делаем вывод что dbx он вот когда данных больше чем памяти он все как бы до сдувается к сожалению будут он рассчитан под все-таки под тот вариант когда у нас в ram помещается это количество данных хорошо здесь у нас графики максимальной в пенси да то есть вот у нас по шло заполнение базы данных от 0 до миллиона ключей и мы видим какую максимальную задержку база показывали давно том или ином моменте заполнения января тагир он показал самую большую производительность и самую большую самое большое количество ключей в секунду он вставлял ну и задержку у меня получилась самая большая в остальном что можно сказать ну вот тут тоже урок сгибе появилась тоже штука до что после 800 миллионов стала подскакивать все дело вот это средняя квадратичная задержка тут ну тоже самое можно отметить пророк сгибе опять же и он dbx а видно что как только данные перестали влезать from сразу же поднялось поднялась задержка а это у нас тест на чтение чтение в 32 потока и в 206 потоков здесь рокс baby уже вышел вперед софия видеть из них тут случилось оно можем сделать вывод что или чтение не любит или много потоков не любит вот чуть позже уже не поймем что конкретно она не любит значит ну вот пока что здесь срок забега лидирует добавим немножко да значит важный момент все wild tiger сначала показал очень здесь показывал просто отвратительно производительность порядка там 20 aiop секунду то есть ну что-то умер он и я стал разбираться чем дело оказалось важные параметры у него есть касайся так что да если друг у будете вот когда-то ставить его обращайте внимание касаясь важен иначе он не работает практически так значит далее у нас немножко добавим записей и видим дай мне бы их сразу упал поскольку записи он вот запись не любит когда он из данные не влезают в ram ну и рук себе уже спустился с новых высот вот софия все также внизу добавили еще записи теперь 50 на 50 до это наш основной work вот на который мы смотрим но видим что на цифры не в небольшие небольшие довольно таки и теперь когда мы сделали уже записи больше чем чтения его red tiger видите на 32 потока он вышел вперед то есть рокс baby он обошел потому что записи больше видимо он любит больше запись и любит ее когда немного поток давайте посмотрим тут на задержки на черные столбики это у нас минимальная максимальную лет инси оранжевая полосочка это средняя квадратичная задержка и красная полосочка это у нас перцентиль 90 99 в принципе на этом графике все что можно интересно вы увидите это то что зеленая полоса это то чем мы хотим то есть мы хотим чтобы задержка была не выше ну перцентиль был не выше чем зеленую эта линия ну к сожалению все довольно таки далеко оказались вот этого результата а это у нас на 5 50 на 50 workload то же самое видим что никто в принципе не достиг этой линии к сожалению теперь пробуем на 17 миллиардов ключей все это дело тестировать то есть то был 1 миллиард ключей здесь 17 уже более интересно смотрите да еще что хочу сказать ну здесь мы будем тестировать уже две базы в aire и таггерры rock baby потому что остальные ну вы как видели еще на одном миллиарде ключей да уже довольно в общем них не подошли нам не подошли нам поэтому мы решили 17 миллиардов ключей уже тестировать два таких претендента которые хотя бы ближе этого red tiger rock сдп видим что wild tiger он остался в принципе ну примерно на том же уровне да только у него появились такие сильные выпады вниз а вот rox baby оказалось что на одном миллиарде мы не видели все картины да на одном миллиарде мы видели более-менее прямую какую-то линию там в конце начались выпады но в целом она держалась на уровне одном а вот дальше после там 1 с чем-то миллиарда оказалось что идет вот так вот вниз и уже до 100 миллионов кайдо 100 тысяч ой упс падает примерно производительность то есть вот можем посмотреть еще раз на картинку с одним миллиардом ключей и здесь мы видим то что варят tiger более-менее держится рук сгибе более-менее держится и возвращаемся и здесь видим что rox baby он оказывается пошел на снижение далее это у нас максимальная задержка сверху до график максимально задержки и график среднеквадратичной задержки все что интересно тут можно увидеть это то что вот rock baby по максимальной задержки он увидите получила ряд игра будет да то есть он по меньшую одежку показывает а вот пост среднеквадратичное уже наоборот он выше в aire и тайгера получается то есть целом по задержке здесь варят ager ну как бы лучше да потому что среднеквадратичное значение но более показательно чем максимально все-таки и смотрите а вот тест на чтение wild tiger совсем провалил данном случае я подумал что с ним такая же штука происходит как и на одном миллиарды что надо ему касаясь побольше сделать я сделал 96 гигабайтов не помогло к сожалению то есть вот это результат с 96 мегабайт и не касаясь ну видимо не то ли его надо как-то еще там до настраивать допиливать ну вот к сожалению да такой такой результат показал он добавили немножко записи видите чуть-чуть майри-та я подрос то есть он на запись он нормально до записи видели что 400000 кексов показывает все хорошо а вот чтение совсем не особо добавили еще записи 50 на 50 его и rox baby получается сравнялся 32 и 36 потоков это у нас 30 на 70 ничего не изменилось до после от 50 от 50 на 50 никак не отличается далее это у нас опять же задержки до задержки ну здесь также видим естественно что не удовлетворяют нашим требованиям потому что на одном миллиарды ключи тоже не удовлетворяли и здесь та же самая и workload 50 на 50 также какие выводы можно сделать да ну вот из этих всех графиков я думаю уже более-менее для себя там кто-то сделал вывод что если на записи мало потоков то в принципе wild tiger нормально да справляется более-менее если же у нас записи много потоков то скорее рук сгибе выходит вперед то есть мы видели что на 256 потоков рокс dp обгонял vr и tiger даже на тех пор коды где больше было записей чем чтение потом если нас чтение и количество данных и больше чем оперативная память the rocks db в принципе он оказался лучшим здесь но смотрите я специально решил протестировать м dbx на небольшом количестве данных когда у нас была данных меньше ну точнее я прибавил рама чтобы все данный влезли в ram решил посмотреть что будет и вот тогда он показал производительность раз примерно восемь девять больше чем rock baby то есть в этом была почти 8 миллионов ah-ips поэтому я бы сказал что чтение и плюс когда данные влезают в оперативную память что mtb x все таки хорошо себя показывает но чтение да мы видели что по записи конечно он отстаёт ну из этого можно сделать вывод что когда 50 на 50 workload много потоков данные не влезают тогда в принципе рокс baby наверное ну как получше до остальных справляется не мы решили все таки потестировать выделенные баз данных потому что rock baby хоть и показал себя там лучше других но он не достиг тех результатов которые нам требуются до из выделенных баз данных можно сразу сказать что-то моя распайка сандро да такие там популярные к сожалению кассандру не успели почистить вот rock этот aerospike сейчас про него расскажу по быстрому смотрите его какие-то особенности интересное это то что яндекс всегда в ram лежит вот по-любому всегда в ран нельзя никак иначе сделать то есть никуда вытеснить тому нельзя и значит второе это использование сырых дисков то есть движки к про которые мы говорили они все пользуются файловой системы они все работают по верх файловой системы aerospike в свою очередь он использует просто сырой блочное устройство интересно особенный да и 3 то что яндекс его не деревянный то есть он не дай как бы не на дереве построен как у большинства а на хэш-таблицы ну смотрите про яндекс первое это целых шестьдесят четыре байта на один ключ то есть мы в яндексе храним на каждый ключ и 64 байта и вы понимаете да у нас там миллиард ключей 17 миллиардов 137 как бы не влезет совсем не куда нам надо ну как-то уменьшать количество ключей да и к счастью наши данные позволяют это сделать и мы придумали простой чит берем значит вот смотрите есть 1 л б один есть метаданные 1 до для него соответственно и так для всех остальных вот мы берем первый ключ и к нему кладем значение от его значения и значение 3 следующих да ребят вот так вот и мы получаем что у нас один ключ хранится сразу четыре значения ближайших да и мы все равно в принципе всегда можем для любого алба достать его значение датчик через его соседа и таким образом мы просто вот эти лишние ключи уже исключаем и получаем там в 4 раза меньше ключей для например назовем это упаковкой смотрите вот мы упаковали до в 4 раза меньше количество ключей в 4 раза меньше у нас стало значение естественно в четыре раза больше то логично вот и мы можем вот упаковать в любой в принципе количество раз и но которые захотим ну давайте сразу потестим это дело на 17 миллиардов на одном не очень интересно и упакуем это 64 раза вот чтобы у нас vram влезала там сами потом можете посчитать нужно упаковать все четыре раза хотя бы вот получен всего 265 миллионов ключей и каждое значение у нас теперь будет не 16 байтов а уже целый килобайт что у нас получилось на а и распайки ну смотрите да скучный график вот он оказался таким довольно таки стабильным парнем 300 300000 а вепсов показал нормальный результат здесь мы видим максимальную задержку выну тоже да просто видим что стабильно все в целом задержка повыше получается там чем урок степи максимально теперь смотрите на этом графике важно да нельзя сравнивать там кто лучше aerospike или rox baby это тесты в разных условиях я привел здесь рокс baby лишь для того чтобы можно было как-то сопоставить да то есть ну понимать вообще много мало там aerospike получил так далее и все нельзя сравнивать у нас здесь а распад тестировался в айсе изгибаешь martin запомнить я говорю что он для он для выделенных бас больше подходит aerospike этим является рук забиты стирался с помощью ой уоррена и поэтому нельзя сравнивать и урок сгибе не использовалась упаковка вот это распайка использовать но тем не менее просто да видно мы получили результаты побольше получили на 206 потоков 400000 нормально смотрим дальше если мы добавили немного записей уже на 32 потока сравнялся aerospike у нас на двести пять шесть всё ещё обгоняет добавили еще записей тут еще под присели все уже rock baby немножко стал немножко переезжать aerospike ну еще добавили записи да ничего особо не меняется то есть в конечном итоге aerospike получается много потоков любит у нас на primal маленьком количестве потоков но то же самое шторок себе получается и вот хороший момент да когда наконец то ходит где-то задержка уже опустилась ниже той планки которая задана да то есть здесь aerospike победил этот барьер прошел но это на чтение да вот на запись к сожалению все равно немного не смог ни на записи она 50 на 50 work воде таким образом можно к тем выводам которые были добавить что если у нас много данных до если у нас много потоков и мы можем как-то данный упаковать то тогда aerospike тоже интересный вариант его можно рассмотреть но важно что данные что у вас не должно быть много ключей потому что расход по памяти парам какой-то огромный получается важно еще сказать да есть этом время осталось да прими время еще осталось какие упущения вообще были до скажем так в этом докладе но для тех кто может быть глубоко разбирается в этом всем 1 до настройки файловых систем настройки какие-то там в линуксе это все было она просто по дефолтом и это все влияет на то как работают движки и если вы эксперт до в этом всём деле настраивать умеете вы можете приподнять приподнять все эти показатели с помощью вот этих настроек это первое второе виртуальную память до отдельно выделю виртуальная память важно потому что движки вот aerospike нет а движки они поскольку используют файловые системы работают поверх файловых систем они на виртуальную память используют используют интенсивно до ее тоже можно настраивать ну и наверное еще есть какие-то нюансы можно в принципе даже обсудить будет значит что вообще дальше да как как продолжить это исследование можно ну нужно попробовать я думаю упаковку да вот эту на rock baby и так далее если честно мой год назад это пробовали делать все равно вроде бы ничего не получилось там но той были стали тесты я здесь вот здесь не показывать будет нечестно потому что версия обновились и так далее надо наконец таки протестировать тоже с большим количеством ключей то есть уже не 17 миллиардов а 137 это то почему мы стремимся ну опять же в рамках одного доклада все не показать ну и попробовать то еще какие то там вот кассандра то же самое интересное вроде да многие говорят там кассандра kassandra кто-то метаданные в ней хранит тоже наверное стоит на нее посмотреть вот опять же да это уже может быть другом докладе и про прямую адресацию обещал сказать да несколько минусов почему же мы все таки не стали и сразу так делать она же там прикольно почему все-таки взялись сначала закиева или у базы данных ну первое workload получается неудобный workload неудобный для твердотельных накопителей когда мы пишем маленькие маленькие такие частички данных да у нас 16 байтов от один экземпляр метаданных 16 байтов и мы случайным образом где-то на твердотельном накопителе начинаем писать вот эти 16 байтов твердотельный накопитель любят во первых когда пишут блоками побольше потому что у них свои там до блоке есть внутри там они порядка там могут быть пол мегабайта даже во первых во вторых запись все-таки и твердотельные накопители любят скорее последовательного чем случайно да то есть случайное чтение отлично случайная запись и не очень хорошо потому что блоки вот эти блоки они фрагментируется и в итоге потом получается что очень много блоков используется только частично и когда вы довольно много данных пишите уже на твердотельный накопитель и он начинает там дефрагментации некоторые проводите все это делаю замедляет работу в итоге ну и трудоемкость трудоемкость конечно программирование всего этого дела до нужно там параллельный доступ все дела все это обрабатывать в киви люба сдав базах данных это уже решено как тогда сделано за нас и третье это то что для того чтобы писать в прямой адресации метаданные нам необходимо ну сразу весь накопитель выделить под это дело потому что вдруг мы сразу за хотим записать там в последнюю страницу нашего кластера что-то да и соответственно мы в конец накопителя то пишем в конец вот а если же мы захотели записать там в середину дамы и соответственно и середину накопителя с метаданными запишем что-то то есть на нас сразу выделяется весь накопитель нельзя так что у нас 100 100 мегабайтов метаданных записанное значит эту мегабайтов накопителе используется остальное мы можем под свои нужды использовать да нет сразу же все там все там 2 терабайта будут уже чисто под это дело ну на этом хочу вот пригласить светлану она рассказывала первую часть доклада светлана и мы с удовольствием ответим на ваши вопросы спасибо за внимание вопрос пожалуйста сейчас обязательно спасибо за доклад очень интересно я являюсь я вот являюсь адептом рук сгибе хотел спросить вы как-то чего-то tune лили тоже взяли все по дефолту мы взяли все по дефолту потому что во первых противника не успели рассказать доведите и так довольно много получилось во вторых тюнинг является задачей ну специфической до нужно жарить конкретно вот в этом конкретно в этой там базе данных или бы разбираться это довольно таки трудоемко если говорить про трудоемкие задачи то мы можем тогда и прямую адресацию использовать правильно вот мы решили посмотреть что вообще изначально мы имеем но если там покупать то ее можно очень сильно верю да я вот с этой с упаковкой то есть там можно до заката рвалась о'хара если вы кстати если разбирайтесь с удовольствием обсужу как все это дело покупать проведена спасибо без микрофона можно да потому что вы использовали база данных ключ-значение для хранения методом да мне вот интересно а сами данные до другой самые данные будет лежать на хранилище то есть как бы это только метаданные потому что дано кто будет петабайты ни одна киева или уже это не поддержит это сердечко это проприетарное ваша собственность собственную как бы мы площади блочное хранение до получается то есть уже распределенный распределенная система хранения точно еще потестим никогда не спасибо вам что видите дании что ролики ну скорее всего придется прямую адресацию делать а сколько времени у вас за дела-то месте равана а руслан являюсь спросили сколько вы потратили времени на тестирование знаете до времени получилось пару месяцев на самом деле пришлось потратить потому что казалось бы да что там запустить тест и но постоянно возникали какие-то проблемы поэтому проблем проблемы из разряда там rox baby заполнялась заполнялась какой-то момент говорит ой простите слишком много файлов открыто и приходится да там tune что-то немножко ну в операционной системе менять до количества там разрешенных файлов открытых в один момент заполнять заново и подобные всякие вещи возникали постоянно итоге пару на пару месяцев ушло да и год назад мы еще пару месяцев тоже это все делать или но только рокс дпр а вот и зубов и выбрали прямую адресацию разработка пошла делать прямую адресацию потом там оказалось не все так хорошо решили потратить еще базы данных 0 что-то улучшилось да потому что это в прямой адрес отеля много проблем здрасьте спасибо за доклад а вот это вот упаковка индекса она вообще как-то влияет на посмотрите у и распайка до некоторого момента она особо не влияет то есть мы берем вот там же как у нас значение сама она увеличивается до естественно и если мы увеличиваем и увеличиваем его да там нескольких килобайт of может 4 ничего особо не изменяется ну так в пределах то может процентов 10 дальше он тоже начинает скатываться то есть упаковка до некоторого момента работает на самом деле а потом все ниже а вот и урок с биби оказалось по крайней мере по нашим тестом год назад оказалось что он сильно колят размеры значения от размера значения сильно зависит производительность довольно таки ум резко падает вниз вот получилось так спасибо еще вопросы спасибо руслан спасибо светлана"
}