{
  "video_id": "rCOKmZ8VqCU",
  "channel": "HighLoadChannel",
  "title": "Реактивные микросервисы с Apache Kafka / Денис Иванов (2ГИС)",
  "views": 29682,
  "duration": 3376,
  "published": "2018-08-16T03:54:35-07:00",
  "text": "так заранее прошу прощения за то что вот слайда не на весь экран здесь у меня если что-то не будет видно обязательно спросите некоторые какие-то нюансы с аппаратурой начнем в общем о чем сегодня поговорим про говорим поговорим про микро сервисы да еще такие которые могут быть реактивными и еще с использованием а пальчиков к ну для начала давайте поймем кто что вообще из этого какой опыт у людей есть кто использует микро сервис то делает микро сервис вот вода это хороший вопрос так где то ты две трети зала а кто использует а пачиков к production не опускайте руки хорошо вот а кто знает что такой реактивный подход реактивное программирование га тоже в общем где-то треть зал замечательно давайте коротко кратко представлюсь меня зовут denis слонов яко работаю в компании 2гис в новосибирске вот кто знает компании 2гис лично новосибирске да и там занимаюсь всем тем что касается рекламных возможностей компании то есть мы делаем я со своей командой делаю системы продаж системы размещения рекламы и прочее прочее вот кроме того там свободное время я вот выступаю на конференциях делюсь опытом сообществом получаю свои какие-то знания вот и являюсь microsoft mvp в категории visual studio 2 технолоджис кому интересна тема про mvp можете подойти ко мне после доклада поговорим это очень такая хорошая штука замечательное сообщество вот ну и всю свою скажем так в общем довольно длительное время до больше десяти лет уже я занимаюсь давно этом все что связано с dota этом сегодня все примеры будут надобно этим жарко вот но на самом деле ничего страшного потому что всё о чём я буду говорить сегодня это все кроссплатформенное собственно кафка понятное дело вот rx и рек extension это тоже кроссплатформенные штуки поэтому на технологии пока мы можем особого внимания обращать кроме того все что о чем я буду говорить сегодня уже прямо сейчас лежит на гитхабе туда я был уже презентацию после доклада после выступления и общем приходите туда задавайте вопросы запускайте дымке смотрите и вообще давайте будем общаться например там в телеграме или через год как угодно я готов ответить на все вопросы может быть что то будет интересно итак о чем сегодня поговорим поговорим что же такое microserver здесь был замечательный вопрос что такое микро сервис определимся с тем что это такое по крайней мере на ближайшие час вот после этого немножко поговорим про пачиков q потому что много людей в зале умеют и использовать поэтому я вообщем кратко расскажу о том что это такое в контексте именно тех задач которые мы собираемся на ней решать после этого поговорим про реактив extensa вообще про реактивные приложения и закончим аким это реальными проблемами которые можно решать с использованием всего вот этого богатства и так что с такой микро сервисом а есть довольно такой термин который многие люди понимают по-разному хотелось бы на чем-то сконцентрироваться мне больше нравится вот такая формулировка мне кажется что микро сервиса это некое развитие объектно-ориентированного подхода это просто кита квадратики не обращать внимания на то что там написано и специально закрасил вот по сути дела у нас в объектно-ориентированном программировании да вот во всем этом объектно-ориентированном проектировании есть что есть классы у классов есть контракты у классов есть вполне определенная ответственность они между собой взаимодействуют все приложения мы примерно похожим образом делаем если посмотреть на микро сервис и вот с этой точки зрения на самом деле получим похожую штуку нас есть micro сервиса они сделаны зачем-то то есть у них есть вполне кита определенной ответственности и они выполняют какие-то вполне определенные операции по четким контрактом то есть вот аналогия в этом есть довольно существенно на мой взгляд но если посмотреть также вот еще с этой стороны да мы можем воспринимать некую платформу регистрации там например купер notice do которая запускает например докер-контейнер хотя все это абсолютно необязательно вы можете там реализовывать не красилась на всем чем угодно можете просто процесса операционной с теми так просто удобнее вот все это дело можно воспринимать как некую распределенную операционную систему на которой мы запускаем наши процессы или какие-то вот наши те самые микро сервисы которые опять же общаются между собой по вполне определенным контрактом да сейчас на текущий момент популярен там рост подход в тесте pisa взаимодействие вот но есть и другие вот поэтому давайте микро сервиса будем понимать вот в этом в этой в этом в этой терминологии и продолжим вот откуда они вообще берутся но на это наверное вряд ли кто-то какая-то команда разработки садится и начинает гореть о том что типа вот два этим и в этот раз нашу новую систему такую супер замечательно сделаем to keep a micro сервисного подход и в общем все делают и давайте нам парада обычно у микро сервисов и вообще вы этого всего подхода есть какая-то причину то есть почему люди выбирают именно этот путь вот я расскажу про наш путь кратко да может быть у вас он тоже найдет отклик мы делали систему управления рекламой в 2гис начали мы и делать год назад как раз в ноябре вот и нам нужно было сделать релиз этой системы до конца лета вот это довольно глобальная система у нас было на тот момент уже в общем тут моим существовала система которая занималась управление рекламой ну для чтобы понимали что такое управление рекламой у нас есть всякие разные продукты в них размещаются всевозможные там тексты рекламные картинки и прочее прочее у нас есть куча рекламодателей и вот и всем этим нужно управлять то есть нужно загружать эту рекламу нужно там понимать каких размерах эти картинки должны быть нужно их там раздавать и так далее тому подобным там довольно много процессов вот но проблема в том что мы хотели сделать именно глобальную систему там компания 2гис не текучего нем представлен только в россии но и там еще в 7 дополнительных странных вы хотели хотели сделать именно глобальную систему поддерживающие мультиязычность и многие другие аспекты вот мы сели с людьми которые как раз больше всего в этом вопросе знают и спроектировать примерно какую-то вот такую систему сделали слоистую такой вот систем в общем довольно стандартный подход единственно весь нестандартного того что мы придумали что у нас будет два типа хранилищ 1 из 3 совместимое хранилища для того чтоб как раз те самые файлы хранить бинарные данные по факту то есть некая файловая система надеемся шили сделать некоторый по слойку в виде и 5 хранение для того чтобы файла система превратить уже в систему ну то есть сделать теперь уже нашей предметной области то есть мы будем хранить там рекламные материалы вот но по факту там внизу лежит все равно с 3 вот нам потребовалось и скверные базы данных для того чтобы хранить всевозможными то информацию всякую стоит строить по ней потом поисковые запросы проще ну понятно нормализация вот понятно у нас есть некая hai la villa 5 то есть по факту наш backend есть frontend вот но когда мы поняли как каким образом мы хотим эту систему сделать выяснилось что вот на то чтобы все это сделать все строки в которой нам необходимо у нас команды такой большой ну и просто не существует поэтому мы как-то вот пошли вот по такому пути мы выбрали разные технологии нашли разных людей там по два по три человека которые в общем как раз и направили всех людей для того чтобы сделать эти комп эти все компоненты на разных технологиях в общем вот это единственный был способ реализации такого приложения все строки в которые у нас до на самом деле под этим проблемы из-за этого проблем никаких не возникало но мы их на самом деле и не видели просто потому что мы можем использовать как я уже сказал там докер кубер найти с это сильно упрощает и на самом деле неважно на какой технологии будет написан ваш сервис важно лишь то что он выполняет таким образом реализованы контракты взаимодействия между этими сервисами вот в виде стрелу нас используется цех мы соответственно там пост пост базы данных пост граждан вот это та причина откуда от микро сервисы взялись у нас вот в этой самой системе мы просто решили делать разными группами людей разные кусочки скажем так система на самом деле есть ещё одна причина а прошу прощения за бежал вперед вот на самом деле вот когда мы эту архитектуру скажем тогда для себя приняли у нас не возникли некоторые проблемы некоторые сложности которые всегда возникает некроз сервисных приложений какие-то сложности ну первое это то что компоненты между собой взаимодействовать либо синхронно либо синхронно каким-то образом нужно это дело до синхронны от когда пользователь ждет асинхронно когда он четко выполняют фоне соответственно нам нужно между всеми этими компонентами данные доставлять гарантирован да еще и с минимальными задержками ну так чтобы у нас система работала быстро и не возникало в ней никаких проблем ну и третья проблема на самом деле да я показывал что он есть два типа хранилищ и вот есть проблема распределенных измерений согласованности на нее хотелось бы обратить особое внимание и поговорить в принципе такие проблемы можно решать если у кого-нибудь такие системы кто где вот используется там несколько типов хранилищ где необходимо согласовать данные вот отлично я как раз об этом хотел сегодня более детально поговорить вот такие бывают распределенные изменения определенные изменения блокирующий не блокирующий да то есть блокирующий там где нам нужно чтобы пользователь подождал пока мы запишем в каждый тип в каждый набор наших сохранились не блокирующие это когда мы записали в одно из центральное скажем так хранилище и потом какие-то запустили фоновые процессы для того чтобы отложен доставить по всем остальным вот и какие-то из принципе возникают проблемы да например в распределенных изменениях в блокирующим виде вот у нас есть наш backend пришел запрос мы сохранили данные быстрее замечательно банду ответили да все у нас круто на самом деле здесь тоже могут быть проблемы можем сохранить то не ответить ну да бог с ними представим себе что все хорошо потом начали пошли в базу данных чтобы эти же самые изменение записать у нас пользователь все это время еще пока ждёт у него там при лодку это круто вот а база данных вот момент может быть у нас недоступна может там взять пропасть может свет выключается что угодно может произойти ну и соответственно пользователь недоволен в этот момент потому что он не сохранил данные но мы не довольно еще больше потому что у нас данные в тот момент 1 или 1 синхронизовать езда у нас часть данных системе есть в одной части системы в другой части с тем и этих данных нет если таких запросов на изменения много не знаю 10 20 30 stories of the мы получим что весь этот процесс мы на самом деле перестанем контролировать у нас в с3 может могут собраться всякие разные данные которых мы понять и не будем иметь что с ними дальше делать нужно ли их каким-то образом процессе дальше не нужно потом когда будем разбирать наши проблемы вот ну известность объем данных большой то принципе получим house вот именно об этой проблеме поговорим как и можно решать с помощью всех тех штук о которых я говорил вначале давайте как раз на вот эти все штуки и посмотрим есть еще одна забавная штука да с точки зрения микро сервисов такие как я уже говорил вот у нас есть а фишки но обычно у нас есть всевозможные процессы которые мы запускаем фоне я много раз об этом об этом сейчас говорил что некоторые процессы нужно делать асинхронно вот и на самом деле с точки зрения микро сервисной архитектуры вот эти фоновые процессы реализуется очень просто в общем довольно логично естественно потому что мы также можем использовать любые технологии для того чтобы их реализовать и в общем обращаться с ними очень проста в плане того что если процесс нам нужен мы его сделали если он не нужен его выкинули до сделали следующий ну вот все вот эти вот преимущества микро сервис и так как вот эти вот микро сервиса между собой друзьях дружить это вообще отдельный вопрос да каким образом нам передать задачу вот в эти фоновые процессы наши сделать бы это так чтобы вся эта передача данных была гарантирована и в карт самые короткие промежутки времени с минимальной пенсии вот для этого на самом деле в компании мы за использовали кафку и причин здесь несколько первая причина в том что нам необходимо было чтобы эти данные гарантированном доставлялись то есть нигде не потерялись по дороге во вторых чтобы это происходило с минимальной задержкой но вторая причина почему кафка потому что на вас было если кафки у вас нет то конечно стоит подумать до использовать ее или нет просто потому что сама по себе развернуть правильно настроить кластер кафки ну в общем тоже не самая простая задача так вот мы использовали кафку себя для того чтобы построить зима листами красе между микро сервисами давайте посмотрим что это такое очень кратко напомню для тех кто знает и может быть кратко расскажу для тех кто не знает что кафка это на самом деле штука которая реализована на концепции распределенного logo что такое распределенный лоб по факту это файл в которой мы записываем в конец всегда распределенный он потому что лежит на нескольких новых соответственно там где файл лежит это нота называется лидером там где он туда натянуты на которую реплицирует соответственно все остальные ноты в кластере вот набор таких файлов моему который называется на уровне кафки пар тишины мира мы объясняем логические топики по факту получаем скажем так именно такие очереди парте цианирование дав которые мы можем данные записывать выбирая таким образом мы какой какой из этих файлов мы хотим записать какой какой пар тишина этих файлов мы хотим записать либо задавая ключи и там правильно настроив парте цианирование уровне самой club кафки для того чтобы как то само выбиралась на спарте шин это с точки зрения хранения и размещения данных с точки зрения получения данных из кафки там есть понятие консьюмер группы концу мир группа это на самом деле логическое тоже понятие которое объединяет под собой несколько процессов которые получают данные из топика вот концу мир группа хороша тем что мы можем параллельно данное читать из разных партий шумов в рамках этой кажется мир консьюмер группы и кафка будет за нас ну или на самом деле можно настроить чтобы мы сами но по сути дела кафка будет у нас трогать то место скажем так который мы уже прочитали это называется на уровне кафки офсет вот мы этот кафка будет тратиться на сосед где мы сейчас находимся в этом самом портишь и не для того чтобы следующий раз когда мы с этой консилер группы придем он отдал нам данные из того же самое место вот консьюмер группа обеспечивает кроме того что параллельно по возможность параллельно чтения из разных партий tion of но еще и по обеспечивает возможность балансировки нагрузки из одного пар тишина может читать только один процесс составе консьюмер группы если их там несколько и один из них который на текущий момент активной падает дату поднимается 2 который начинают эти данные дочитывая до обрабатывает за ну это вот такой очень поверхностный обзор до того как работа того как это как работает кафка я увидел в программе конференции highload будут выступать gland шапира она как раз из тех кто написал довольно хорошую книжку про кафку и от все все вопросы может быть это же можно будет задать попова того как обком внутри устроена как как с ней правильно общаться но давайте посмотрим как как работать кафку с кафкой с точки зрения тот это или на самом деле слово тут нет вы можете заменить на любой другой язык программирования или платформа которую мы вы используете на самом деле с точки зрения клиентской части сказки есть всего для тебя эти два типа библиотек это тут нет есть прошу прощения есть java и в гости к и есть библиотека написано no se если вы джавис три лета ска лист вы используете соответственно джим совместимыми блеать эку если вы использовать какой-то другой язык то вам остается использовать библиотеку под названием либо рта кафка esata для многих языков есть обертка над этой библиотекой вот эта штука open source на обычного белках реализовано не все эпопей но если вам необходимо как ведь именно специфической 5 можете прийти за за пулей request ведь мы так на самом деле сделали нам необходимо было какой некоторые пей которого не было и на самом деле сейчас она уже в релизе то есть и хорошо о чем стоит помнить когда вы используете ли бар тыковку о том что эта штука использует память самостоятельно памяти потоки то есть внутри этой библиотеке реализован код который выделяет память зависимости опять же от настроек до запускает некоторые потоки если вы хотите полностью контролирует свое приложение об этом нужно знать вот эта штука кроссплатформенная можно использовать ее если сдать на этом тут nightcore и красные примеры будут сегодня об этом самом деле проблем тут с какой то вполне определенной системы плода или платформа не давайте посмотрим как реализовать некоторого некую обертку над контейнером то есть над тем товарищем который будет вычитывать данные из кафки здесь когда самая интересная часть продюсером все там довольно просто потому что общем говоришь он пишу да вот с консилером есть много интересных нюансов о которых как раз я хочу рассказать опять же примеры кода на сишарпе но я думаю разберемся мы реализуем соответствие для того чтобы вот такого концу мира концу мир wrapper да то есть некая обертку реализовать мы используем обычного концу мира который есть библиотеки на самом деле зачем вот нам такая обертка для того чтобы как раз попробовать реализовать тот привычный паттерна работа с очередями который мы обычно используем да то есть мы обычно с очередями работает следующим образом приходим в очередь забираем каюта пачку сообщений на своей стране и процессе там не знаю изменяем данные в системе после этого говорим системе очередей commit тем самым сдвигая вот офсет с точки зрения кафки попробуем такой же сценарий реализовать здесь инициализируем консьюмер и создаем просто список до тех сообщений это которые мы хотим вычитать из кафки реализуем две функции они нам нужны будут для call back of 1 первая функция message где по факту просто сообщения добавляем в наш список и второе вторая функция вставляет флаг завершение пар тишина в true вот дальше нужно вот эти функции подписать на событиям то есть по факту сделать обработчики событий библиотек афк афк dot net на библиотека кафка реализовано с помощью событий до знаете вот но по факту это просто лишь те функции которые будут вызваны когда будут когда будут происходить определенные события то есть либо исков кафки прайса произошло событие в том что со быть что что сообщение пришло будет вызвано событиями он мэсседж либо если мы дошли до конца будет вызвана события он партию и а вот после этого самая важная часть мы должны выбрать вы должны вызвать метод субскрайб тем самым подписавшись нашим консилером на какой то вполне определенное количество топиков после этого мы крутим бесконечные по факту цикл до тех пор пока либо добавьте 1 до кан до низа не забрали все сообщения которые нас интересует то есть батч либо пока мы не дошли до конца партии шину либо пока нас не попросили в принципе закончил свою работу вот и мы должны в этот в этом цикле крутить должны крутить его цикл вызывать метод пол так работает принципе кашка да когда мы из клиента постоянно полем том что то что там происходит вот и после того как мы получили этот матч цикл закончили мы должны отписаться от кафки чтобы освободить ресурсы вот здесь у нас на самом деле есть некоторые нюансы который хочет поговорим как как мы будем использовать такого концу мира рапира использовать будем просто создаем ева грин пляж и после этого просто крутим цикл чтобы дойти забрать определенные почитается из наших топиков после этого делаем культа полезную работу ну в моем случае просто выводим и все это дело на консоль и говорим что вот те сообщения которые мы уже прочитали давай-ка казаками тим и все давайте посмотрим на самом деле как это дело работает есть небольшая дымка вот я здесь хотел показать но у меня немножко все слетела с у меня есть dotnet dota 2 версии как вы видите да на маке вот во втором окне у меня запущен докер-контейнер где запущена кафка то есть мне не а кафка по факту локально вот и в третьей вкладке у меня есть 2 2 терминала в первым терминале давайте немножко здесь поменьше сделаем все съехала прошу прощения в первом терминале на самом деле у меня есть приложение которое написал она так это называется dm am я хочу запустить в нем продюсеру то есть того товарища который просто пишут в кафку вызываю свое приложение с параметром продюсер дома и надеюсь сейчас все будет замечательно да у меня пошли сообщение вот здесь написано что такое это сообщение томским taguhi там просто отправлена в топик хайло тысяч 17 только в партию 0 и вот там через собачку показывается его офсет вот с точки зрения кафки мы видим что здесь у нас произошли какие-то магические строчки в консоли то что там вот нам продюсер пришел начал продюсер все хорошо и он часто давайте запустим того самого консилера которой о котором я только что рассказывал до 5 сделаю поменьше вот вы же вызову то же самое приложение это по факту уже другой другой процесс другой микро сервис если хотите сейчас я вспомню как эта штука называется но он и fishing концу мир дима моем случае вот и запущу консилера то есть сверху у меня продюсер тот который пишут снизу концу мир который читает мы видим что концу мир читает продюсер пишет но как-то знаете как то не очень все быстро работает да потому что в общем не сразу же на консоли строчки появляются хотя вот там еще 67 сообщение здесь еще пока 40 там седьмое какое-то мало того если посмотреть внимательно вот на этот лог да мы можем увидеть я вот так вот сделай чтобы это было понятно что этот лог на самом деле постоянно изменяется а изменяется потому что происходит происходит перебалансировки кластера кафки то есть на самом деле мы особо такого ничего плохого не сделали но получили вот на этом коде которую я показывал получили не особо высокую производительность да там говорят что кафку там миллионы сообщений в секунду процессе учёта здесь мы этого не видим вот во вторых много сообщений на уровне logo кафки опере был опере пол соловки перед балансировки концу мир группы на самом деле это происходит просто потому что мы вызываем после каждого матча здесь у меня стоит бочче 3taps край посадкой когда мы вызываем савской мы подписываемся на кафку то есть карта начинает следить за нашим концу миром перри балансируя группу когда мы взываем ансаб скрипт кафка говорит о том что у нас отлично консилер у нас ушел перри балансируем группу выведем его оттуда вот мы каждый раз делаем поэтому получаем вот такие не очень хорошие эффекты мы можем на самом деле этой проблемой избавиться давайте покажу вам как у меня вот здесь есть замечательное аидой эхо под названием райдер это тут нет моей дых который можно писать нашу шахтам я могу сделать немножко иначе я могу вызывать метод не субскрайб а могу будет мир вызывать метод assign вот ну и соответственно у нас обстоят мне нужно позвать этом случае не нужно assign от савской бы отличается тем что мы явным образом говорим нашему клиенту что вот мы хотим данные из кафки вычитывать из вполне определенного места в в определенном портишь или все хорошо но в этом случае когда мы вызываем assign кавказа нами не следит да и вызываем это сайт по факту управления своей концу мир группы то есть несколькими инстансами своего микро сервиса мы отдаем в общем должны эту проблему решать самостоятельно да то есть в этом случае мы можем запустить несколько процессов и все они у нас будут читать одни и те же данные то есть балансировать на балансировать балансировки на уровне у кафки мы не получим в этом случае но зато получим неплохую производительность давайте посмотрим как это будет работать я запишу запущу то же самое приложение но с другим параметрам mail концу мир консьюмер dm1 здесь мы видим довольно быстренько все так происходит вот они он уживались уже синхронизовать и по факту мы видим что продюсер пишет о концу мир тут же читают и задержки минимальные в общем все круто но опять же говорил проблема есть да продюсер и оставим пусть он у нас пишет о конце мира погасян перейдем дальше в общем какие здесь есть проблема если мы используем кафку для того чтобы обмениваться сообщениями внутри нашего мика сервисного приложения легко написать неправильно да то есть вот буквально там вызывая не те методы мы получим получим интересные нюансы если мы это сделали то получим частые перебалансировки консилер группы что влияет на производительность и на самом деле администраторы которой кафка управляет нам тоже спасибо не скажет вот если мы от этой проблемы уходим то получаем другую проблему до что консьюмер ими распределенными нам приходится проект самостоятельно что та же проблема вот опять же да я показывал тебе все циклы это на самом деле есть не сильно хорошо с точки зрения того чтобы постоянно крутим все эти циклы тем самым используем ресурсы процессора у нас возникает вопрос и опять же синхронизации если это многопоточная штука ну и общем то эти вот задержки они тоже возникают просто потому что мы иногда можно нам нужно ждать если вы опять же приложениями многопоточной то есть вот просто использовать кафку так в лоб на самом деле не сильно хорошо получается но как мы можем все эти проблемы решить и сделать взаимодействие нашим микро сервисном приложение на самом деле очень таким эффективным понятным и самое главное простым с точки зрения кода можем применить при активный подход здесь . макроса говорю вот для тех кто не знает кратко скажу что такое вообще в принципе реактивное приложение на самом деле рэкс вот иконку который я показывал это лишь им вполне конкретная реализация самоваре активного подхода реактивный подход это некая скажем так идеология есть вот с реактив манифестом до торг сайтом все дела написано я приведу оттуда выдержки реактивные приложения идите плела это те приложения которые изначально проектируются для того чтобы участь четыре фактора первый это то что приложение которое мы строим они изначально событие на ориентированные то есть события это главный движущий фактор нашего приложения вся логика возникает в ответ на события которые происходят из не второе они изначально масштабируемые да то есть мы должны писать приложения так чтобы можно было ли запускать много-много инстансов с этим проблем не было весит подход нам диктует такую штуку соответственно здесь масштабируемости мы также получаем и отказоустойчивость вот и это тоже очень такой базовый скажем так принцип с помощью который лежит в основе реактивных приложений вот но еще один это прилла это отзывчивость то есть мы используя реактивный подход получаем отзывчивая приложение этой задержки вот я самой про который я говорил ими они минимальны и ну либо вообще отсутствуют в идеальном случае как это все дело реализуется с точки зрения вполне и каретного кода да у нас вот есть всем известная пу модель опять же здесь код над отнеси но на самом деле это просто реализация вполне определенного хорошо известного всем паттерн и итератор когда у нас есть коллекция и мы для того чтобы пробежаться по этой коллекции запускаем цикл до тем самым перебираем нашу коллекцию получаем нумератор после этого бежим по ним в никс там и получаем текущими вот в точки зрения реактивных приложений есть альтернативный подход на самом деле это дуальный подход с математической точки зрения к push модели full модели простите под названием соответсвено push модель да у нас вместо паттерна итератор в этом случае используется паттерн наблюдатель а все вот и отличие в том что мы не самостоятельно должны эту коллекцию пробегаясь а на самом деле коллекция сама позовет тот момент когда либо появится очередной элемент либо появится какая-то новость произойдет ошибка какая-то даунер либо после того как и дойдем до конца вот и чтобы как мы можем использовать в принципе библиотеку в реактив extend шанс для того чтобы подружить и и вот а пешкой для каски вспомним опишу для кафки да там реализовали два метода и потом подписывались на события с точки зрения языка программирования шарф это на самом деле стандартный паттерн у нас есть событие все sharpie изначально да и вот для этого для того чтобы перейти от событийной модели сишарпа к обсирал мод как все равно модели или реактивного приложения для того чтоб получить реактивную коллег реактивную коллекцию а все роба коллекция есть замечательный метод под названием from a wine паттерн вот я уверен что он есть во всех языках во всех языках программирования всех реализациях их rx поэтому здесь проблем быть не должно что мы должны передать первым и должны туда передать на самом деле два метода первый метод будет вызван тогда когда мы просто под первый раз приходим и говорим что мы хотим работать с это я все робу коллекции вот второй метод вызывается самом конце когда мы говорим что все ту подписку которую мы получили на наш обзор был коллекцию мы хотим от нее отписаться да мы хотим человек приходить работу с ней в этот момент как раз мы вызываем метод транс от skype кафки и отписываемся от события вот давайте попробуем написать того же самого то вот ту же самую обертку но уже с помощью рэкс как это будет выглядеть вот мы должны по сути дела вызвать метод концу но в этот в этот момент мы на самом деле все что делаем это мы подписываемся на кафку да и получаем на выход уже не данные об sure able коллекцию то есть ту коллекцию который мы можем выполнять всевозможные операции вот она после этого на самом деле с это я пробыл коллекции мы с точки зрения использования рэкс можем получать довольно забавные и интересные штуки можем использовать все те операторы которые есть в rx для того чтобы работать с ней ну как если кто-то об этом знаком можем использовать множество операторов которое очень похоже на ленка операторы то есть мы можем эту коллекцию с этой коллекцией работать очень хорошо с точки зрения там того что если нам необходимость буфере zero вать как моем случае до в бочке эти сообщения мы можем использовать оператор либо мы можем отфильтровать эти события во все равно коллекции либо мы можем их там кого-то за проецировать и прочее прочее вот ну и последнее что нам нужно это реализовать метод скраб и там реализовать все то что мы хотим делать полезного да вот там мы на самом деле хоть на моем случае хотим просто бегать по этой коллекции вызывать метод writeline консорт line писать на консоль и вызывать камера такая me to sing для того чтобы завершить очередной матч вот одна интересная особенность для тех кто не работал с рэксом внутри себя rx многопоточный но rx нужно использовать правильно с точки зрения как раз работает внутри итак между между этими операторами все эти операторы которые мы должны вызывать у них мы не можем писать асинхронный код потому что в этом случае мы можем нарушить порядок в коллекции и получим интересный эффект поэтому здесь написаны имена написаны на синхронный год давайте посмотрим как все это дело будет работать вот помним да у нас здесь продюсер еще продюсер пойдем к концу мир и вызовем концу мир другой rx консьюмер дима видим что он работает очень быстро да уже мы дошли до конца сообща до конца нашей нашего пар тишина вот и на самом деле в этот момент у нас нет никаких дополнительных событий в логе кафки тем самым на самом деле вот с помощью такого подхода мы решили обе проблемы которые у нас возникали первое это то что у нас кавказа такими кансу не следит за тем самым мы обеспечиваем на самом деле отказоустойчивость и масштабируемость нашего приложения вот а второе то что мы не вызываем постоянные перебалансировки кластера и соответственно это все работает во первых быстро во вторых у админов нам нет никаких вопросов вот все замечательно но давайте вернемся к изначальной проблеме которой я говорил в самом начале да вот нас распределенные изменения как же нам нужно их делать так чтобы все события которые мы пишем нашу систему записывались во все хранилищ вот та проблема да которая говорил вначале на самом деле для начала чтоб решать эту проблему нам ещё необходимо было в нашем случае так просто поделюсь нам нужно было решить изначально другую проблему мы должны были придумать что-то с точки зрения синхронизации записи или там изменения одних и тех же данных просто выстрела ис-3 не транзакционные хранилище просто по сути дела файла из тела и если много пользователей приходят и начинают данные быстрее менять особенно одни и те же данные дату возникают эти вот рейс кондишен поэтому для того чтобы в принципе этот вопрос синхронизовать нам необходимо сделать эксклюзивные блокировки на ресурс до до тех пор пока один пользователь который пришел на определенный ресурс с ним суда сделает мы должны наша система в принципе заблокировать чтобы остальные пользователи в этот момент на мне приходили и ну не скажем так не мешали в первом пользователи работать не перетирали в изменении используя в после реализации вот этих вот распределенных блокировок на таком распределенную опять же приложений тоже стад как-то себе еще задача об этом сейчас не буду говорить но можем об этом пообщаться кулуарах вот мы сделали допустим такую штуку что мы можем сделать еще мы можем на самом деле если вдруг у нас был сдал недоступных мы можем ну в общем сделать несколько ретро до можем попробовать сделать запись в эту базу данных еще раз или там еще два раза или еще раз еще три раза до каким-то промежутком времени на самом деле с точки зрения вот таких вот микро сервисных приложениях где какие-то проблемы могут возникать и сервисы у нас могут памяти вода то есть быть недоступны там в определённый момент времени но уже в следующий момент становятся доступными этот подход на самом деле помогает вот но если у нас баз данных недоступна в принципе или там все эти у нас лежит то этот вопрос таким образом мы не решаем ретро и помогают но не всегда да для того чтобы принципе решить эту проблему фундаментально скажем тогда мы должны на самом деле подумать над а над архитектурой вот этот подход который я предлагаю он помогает нас андрей шить эту проблему мы можем вести свойства неизменяемости в наше приложение для того чтобы в принципе решить эту проблему что такое неизменяемость да то есть но это в общем то что мы давно и когда наше хранилище положили после этого мы их не меня есть три варианта реализации этой штуки первый вариант это марсиане рование данных то есть вместо того чтобы данные перезаписывать мы можем их fierce они ровать все новые изменения это лишь новая версия в наших данных на самом деле в нашем случае вот это именно это и сработала потому что нас было изначально и требование мы хотели иметь аудит всех тех изменений которые происходили в на 6 версия нирване с этим отлично работает второй вариант реализации неизменяемости это на самом деле меняет позволяет меняет наши данные например базе данных до но завести рядом таблицу где мы будем хранить именно все те события которые на данными происходили то есть мы получаем именно неизменяемых событий на данными вот если мы используем транзакционные хранилища то проблем с этим нет потому что мы можем в одной транзакции данные изменить и записать об этом событии вот ну и третье на самом деле подход это воспринимать события как даны мы можем не хранить наши данные охране только события которые с ними происходили и в любой момент построить построить все все данные то есть слева получить слепок данных на определенный момент времени подход называется эванс арсенка он тоже на самом деле подойдет чем неизменяемость в этом случае нам помогает на самом деле тем что вот операцию изменения данных в этот в этом случае мы можем сделать этом патентный на самом деле мы можем несколько раз развиваясь одну и туже со стороны клиента уже до вызывать изменения данных и быть гарантирована уверены в том что мы данные в конечном итоге оставим в том состоянии в котором нам не нам необходимо вызывая одну и ту же операцию несколько раз в случае в этом случае дам мы можем мы получим что если вдруг база данных недоступна мы сделаем еще несколько вызовов на уровне и пей в с3 в этот момент сохраняться некоторые версии тех самых данных то есть данные изначально которые у нас были мы не меняем мы создаем новые версии вот и тем самым имеем полностью возможность повторять наши действия с точки зрения пей да и на самом деле вот это вот это вот этих вот и retrieve ну во многих процентах случаях хватает на самом деле да вот но опять же что дело в том случае если мы на создавали этих версий данных в истре а баз данных у нас все же недоступна вот эта проблема решается но создается другая на самом деле здесь мы должны перейти к вот к этому вопросу не блокирующих изменений то есть тех изменений которые мы должны доставить до остальных хранилищ но уже сказав пользователю что все твои изменения мы получили все хорошо мы их записали и разбираемся дальше вот на самом деле мы мы можем та изначальная проблему дополнительно на самом деле в нашем случае это пришлось сделать в том числе да потому что нам необходимо быть стопроцентной гарантии вот мы можем доставлять эти изменения асинхронно уже вот нам необходимо сделать это гарантированно и с минимальными задержками вот что в этом случае мы можем сделать в этом случае на самом деле перед тем как данные записать в с3 мы можем записать их в очередь вот нашем случае для этого мы использовали кафку просто потому что вам необходимо было что нам необходимо были свойства гарантии сохранения и гарантии порядка вот если мы давно явку записали замечательно они там уже есть мы можем перейти к с3 до и записать туда эти данные если мы записали туда и туда это самый отличный способ самый отличный вариант потому что мы теперь полностью знаем что у нас все данные которые нам необходимы есть мы их никуда не потеряем у нас верси они руется все изменения на уровне хранилища на уровне с 3 и у нас есть все те события которые происходили системы соответственно мы их можем обработать и доставить после этого на самом деле мы можем пользователя отпустить сказать что все круто и запустить фоновый процесс на самом деле запустить какой-то демон да опять же не важно каким технологии он будет реализован вот за используем здесь реактив extension в нашем случае мы именно так и сделали для того чтобы вот те гарантий скажем так или там те плюшки которые реактивный подход дает получить вот и на самом деле что мы в этом случае должны сделать получить просто событие из кафки понять по сходить в истре хранилище для того чтобы узнать те версии которые мы еще не про реплицировали в базу данных их получить что же такое не надо упростить вот и на самом деле их доставить до если база данных у нас не даст не доступна прямо сейчас ничего страшного и тот же самый worker напишет нам блок что не получилось и пойдет на следующую итерацию но в конечном итоге он сделает то что нам нужно он доставит данные до остальной части нашей схемы и в этом случае на самом деле таки хранилищ вторых или третьих может быть сколько угодно здесь мы можем данные распределять по остальным части частям системы ну типичная задача на самом деле дам здесь мы можем доставить все данные до elastic вещь для того чтобы потом построить поисковый яндекс по ним вот еще одна интересная деталь который тоже хотел рассказать она в общем идет из того что мы используем кафку на самом деле в этом случае вот это транзакционные хранилища она уже по сути дела трансакционные меду базы данных она уже не основное хранилище да мы можем в любой момент взять его и убить вот нашем случае данном например если вдруг происходили какие-то проблемы с базы данных data меня с того чтобы восстановить и из бекапа гораздо проще будет ее просто создать с нуля и имея все события в кафки мы можем а все сдвигать как угодно имея все события в в кафки мы можем уйти в самое начало времен имея все версии ps3 мы можем просто пробежаться ещё раз и построить все эти данные в базе данных ну в общем на любое момент времени которые нам необходимо и все будут довольны на самом деле это все о чем я хотел рассказать давайте-ка подведем краткие итоги но первое о чем я говорил что микро сервис и сами все они появляются обычно какая-то причина почему мы хотим это сделать вот поэтому если вдруг вы захотели сделать микро сервисное приложения просто потому что захотели наверно этого делать не стоит потому что есть все те приложения все эти проблемы которых я говорил да то что управление изменениями изменением данных в принципе измене и само приложение значительно упрощая усложняются таких вот приложениях вот если мы используем кафку или на самом деле дать и система очередей которые подходят нам нашим в вашем случае до в нашем случае кафка идеально подошла вот все эти штуки они значительно упрощают асинхронные взаимодействия внутри на шелком многокомпонентного приложений но опять же использование активного подхода позволяет просто убрать границы между компонентами приложения сделав таким сделать так что мы получаем минимальные задержки между сервисами сохранением всех необходимых гарантий и на самом деле вот приложение в этом случае становится простым и понятным помните да я показывал там эти вот операторы их очень легко читать и очень легко тестировать особенно с учетом того что это просто должен быть всегда однопоточный синхронный год еще раз все это чем я рассказывал есть на гитхабе можно запускать это на любой операционной с теми до дна теперь курс по кроссплатформенный поэтому приходите пробуйте вот и вторая ссылка на самом деле это на ссылка на тот компонент который мы делаем внутри 2гис он упал собственный но мы реально его используем продакшене все а то о чем я говорил сегодня на самом деле можно посмотреть как это сделано в реальном в коде реальной системы которые постоянно тоже меняется спасибо ваши вопросы секундочка давайте здравствуйте а вот владислав мегагруп вопрос такой вот вы говорите про такое применение кафки дело в том что и на сколько я понимаю но породит просто огромный log log file в крае и вопрос следующий как эксплуатации на это реагирую реагирует и если какие-то решение может быть не держать ну монолитом дакаре презирающий partition хороший вопрос спасибо я на самом деле об этом не сказал сознательно потому что не так много времени на у кафки есть такое понятие cried and cried and шиндо то есть кафка хранит все данные мы можем сказать сколько до либо по размеру файла либо под по времени вот и соответственно если нам критично скажем тогда вот эти вот вопросы восстановления там данных за год наверно нам придется хранить данных за все данные в кафки загадали звание сбереги просто вы сказали сначала времен восстановить именно это вот немножко резанул да да именно так то есть мы можем на самом деле все эти вещи на общем в зависимости от того какие гарантии и насколько у нас часто там все происходит не очень хорошо да мы можем же сделать сделать это решение из разряда доделаем к это слепок базы данных там на определенного времени в этот момент архивируем лаков кида но и общему таким вот образом действовать если у нас нет никаких проблем с сохранением огромного огромного количества этих копий под ну скажем так предыдущих файлов да с точки зрения партизанов ну пожалуйста будем хранить в нашем случае на самом деле мы решили эту проблему храня данные просто за год потому что нам больше чем за год нам данные просто неинтересно можно здесь микрофон а вот часто просто потом да спасибо за интересный доклад два вопроса ну во первых вот вы говорили что вы используете лог для того чтобы вам базу поднимать за длительный достаточный период как я понимаю вы предполагаете а как вы решаете событий ну как вы решаете проблему которая вот вы when sorting это же возникает когда у вас меняется исходный код относительно событий то есть у вас структура событий в текущей версии в которое у вас сейчас на продакшн и допустим находится изменился event лежат старые версии как вы будет восстанавливать с пастором событием и задаром кодом и старый логика да все верно это вопрос уже скажем так более не технически до больше такой с точки зрения проектирования приложения да и там проектирование следующих велась приложения да вот на самом деле будем решать точно так же как и допустим мы будем решать вопрос взаимодействия между микро сервисными приложениями если меняется контракт взаимодействия до какие-то версии микро сервисов могут меняться и не предоставлять того и пей который уже был на тот момент но на самом деле это вопросов именно в bercy а нирования то есть как раз именно об этом и говорю что мы в на в нашей компании в этой системе решаем вопрос именно гарсиа не rowan то все события у нас предполагает пирсе они рование все опишите versio не раваны уже на текущий момент вот и соответственно обратная совместимость то есть у вас поддержит все время в эксплуатации находиться все версии код вас уйти сначала жизнь систему дорога прочитать вторую я все забыть и там годичной давности поток вирусу полугодичной давности потом сегодняшнюю но именно тогда весь вопрос том что бизнес в котором мы живем меняется не настолько прямо кардинально да и поэтому годичный период на вполне устраивает и второй был вопрос насколько я понимаю вот вы рассказывали про согласованные изменения в меньше в конце снасти или виду то что называется и у вас пользователя готов с ней мириться чтобы делать если пользователь мириться совершил consist осени готов ее требует сразу увидеть результат своих изменений они ждать что мы вон там что-то там делаем посчитали там приходить через час да именно вот те отложенные изменение они приводят к when she vacancies in silver надо соответственно есть два на самом деле варианта решения этой проблемы мы мы оба из них использовали первые это а то мяч о чем я говорил самом начале да то есть если вдруг у нас баз данных от пола то в классических приложениях до монолитных скажем так приложениях в этом случае у пользователя что говорим о типа извини не доступна в принципе в этот момент мы можем сказать тоже самое можем на самом деле сказать что просто система не доступно сейчас поэтому никакие вопросы твои отчете мы не можем вот соответственно если вдруг у нас возникает такая ситуация то мы делаем следующим мы делаем несколько retrieve вот том случае в тех кейсах когда эти ретро и ни к чему хорошему не привели мы говорим пользователю ну в общем все систем сейчас недоступна приходи через какое-то время обращаясь службу поддержки прочь для тех кейсов именно бизнесов кейсов где мы можем себе позволить некоторое промедление да ну например с точки зрения там не критично вот-вот задержка там даже в пять минут есть ну как бы на самом деле у нас есть кейсы когда критична задержка именно даже там в 5 секунд например между этими штуками у для этих кейсов мы говорим нет а для кейсов где вот эта задержка не критично мы позволяем пользователи продолжать дальше самом деле там просто две группы пользователи они друг о друге не знают и задержки вот такой вот она она нам падает подходит все эти кейсы на самом деле решаются точечно я вот об этом прической спасибо за доклад у вас сколько консилеров на 1 топик сколько концу миров на 1 топик лунара происходит как раз когда консьюмер упал забрал в какое-то событие сказки и я говорю уже про консьюмер группу на самом деле у нас есть давайте вспомним короче у нас есть по два товарища в каждом центре все доцента в 3 на самом деле шесть вот для каждого топика для каждого портишь на самом деле вот но работает какой-то момент времени только один из них то есть актив мастер по сути секс онлайн на самом деле всем этим делом руководит кафка да то есть мы поднимаем 6 процессов которые друг о друге вообще ничего не знают они все конектится кафки с отправиться в кафка знает что все они живы и там на самом деле происходит карбид и вот как только ну и кавказ отвесно сама уже на своей стороне выбирает того кому данные будет отдавайте остальные просто 10 куриц ждут своей очереди если вдруг активный товарищ падает то кафка вы выталкивает его из кластера перри балансирует консьюмер группу выбирает другого товарища котором она эти данные были отправлять и отдает ему с того же самого места где закончил предыдущий потому что мы храним сасово такси это на уровне корсет вы берете по 1 классу дело буковка на самом деле хранит офсет на своей стране поэтому следующий подключившийся до имя внизу гипер закипит хранил его предыдущей версии асада делает именно маковка но по одному что-нить то есть по сути уберите по одной по одной записи не плане бачок 5 бачив то вы не можете гора тела что вы его есть обработали на конце мире вот а иначе будет повтор именно так нас на самом деле у нас есть вот такой вот бачин который я показывал именно с точки зрения обертки но сама сама api самая фишка вот liber de casque не позволяет данной бо чем забрать она всегда дает данные по одному спасибо так давайте я сразу скажите используете ли вы бигли кран рассматривали вы конфликт в качестве платформы платформы для кафки и те коннектор которые предлагают вот на самом деле политика компании 2гис в том что мы стараемся все сервисы которые мы используем хостить у себя поэтому conference их платформам как ну типа облака да мы не используем мы развернули кафку себя внутри вот если говорить про коннекторы ну кафка это такая базовая скажем так инфраструктуру на газ на основе которой можно строить очень такие серьезные вещи вот и конкретно в нашем проекте мы не используем никакие коннекторы мы используем просто клиентской части но у нас компании есть проекты к ним работают с джавы со скалы и они используют всевозможные коннекторы и если вам интересно я могу вам это рассказать но уже попозже мне нужно спросить у ребят так что именно они делают вот вопрос поблагодарить эти лоза ваш доклад интересно очень по микро сервиса вопрос а вот смотрите ситуация такая что вот есть вам нужно информацию отфильтровать сразу из нескольких микро сервисов то есть допустим это какой-то grid или отчет то есть допустим один микро сервис вернул там 2000 строгая не другой 2000 строк то есть если бы они лежали и там в одной базе давно война таблицы сделали бы силе вот но с микро сервисами это как бы либо в ходе как это фильтровать либо там синхронизм синхронизировать данные какой-то дополнительно то есть вот так с такой проблемой вы сталкиваетесь и как еда эта проблема обычно возникает именно в тех сервисах которые на самом деле вопрос не только не даже микро сервисах если у вас компании просто есть несколько систем система я не зная учетная бухгалтерская еще к ним бы до вам необходимо делать куют отчетность на данных из всех а из этих систем это проблема более общая ну решается на соответственно таким же образом да то есть мы в компании долги сделаем следующее мы носа специальные ребята специальная команда которая занимается вот такими системами отчетности и у нас есть внутренние ну скажем так правила и инструменты для того чтобы данные до этой системе отчетности доставлять то есть если вдруг мы хотим чтобы эти данные попали в отчеты мы просто их экспортируем и есть там глобальная система отчетности у которой в которой можно там заказчику прийти и запросить определенные отчетом сформулировать требование эти данные будут построены обычно такие отчеты а не скажем так не рилтайм отчеты да то есть это именно какая-то отчетность там за день за неделю за месяц вот если необходимо делать кита рилтайм именно штуки да то опять же воды возникают эти вопросы с эви нашел консистенции да как как данные сохрани заводь между собой да как смешивать вот и на самом деле для для этого тоже в компании мы такие штуки делаем ее об этом я рассказал там пару лет но в других конференциях у нас есть библиотеки и на основе этих биотек мы строим приложение которое строит ritmo del с точки зрения а вот в терминах secures всякие арестом есть разные штуки в том числе и street модель и как раз с помощью вот этого подхода по факту secure снова да или там части его мы имеем возможность данные собирать прямо в реал тайме из нескольких систем складывать их в одну систему где данные будут уже разложены так как они должны быть представлены пользователю я собственно этих вот штуках и паз и строить такие вот псевдо рилтайм отчеты скажем так так осталось 50 до у меня вопроса были вас случай когда вы например своих досках потеряли часть данных и вам нужно прокрутиться назад на определенные таймс tm в кафки и перри зачитайте отсюда до таких случаев слова бы вы ни было потому что кафка обеспечивает гарантию вот а если бы были на самом деле как это то о чем я говорю с точки зрения фунтов кафки есть такое api для того чтобы получить офсет сообщение хранящегося по определенному таймс темпом кафка либо короче именно я это дело до канта бетил в эту библиотеку ли бардаков к это дело поддерживает дат найти этой функциональность небо он теперь она тоже есть можно использовать спасибо здравствуйте вы сказали что у вас конфи мире в разных дата-центрах до апреля понимаю что кафка реплицируется вообще как бы в принципе это скорее всего реализуемо но нашем случае нет мы храним кафку развертываем кафку в новосибирске тогда центре нас на сибирских москве и там европе в голландии вот на самом кафка работает только в новосибирске на текущий момент есть планы при отказе сибирский прядкой это центр в новосибирске но будем честными не работает половина от а то и больше половины продуктов компании поэтому то что консилер и зависает не самая большая проблема спасибо так наверно последнего опрос собственно вопрос по докладу немножко было непонятно как one дыре активизация конце евро решила проблему участках перед абалон балансировать рожаем о чем там была суть суть там в том что мы первый раз то есть проблема перебалансировки концы мир группы в том что мы постоянно вызываем субскрайб ансаб скрипта получая сообщение патчами применение реактивного подхода рекса шанс помогает нам всего один раз на старте подписаться и всего один раз на выходе отписаться от этих вещей да а дальше мы можем делать эти все уже бочонки внутри этого самого а без rx мы можем в этом случае да но проблема здесь в том что нам необходимо эти ресурсы гарантирован в том числе очищает да то есть если у нас вдруг в этот момент что то случилось да то есть не знаю у нас там exception нам нужно его обработать в процессе наших событий мы должны сделать там со skype и в этом случае конечно можно написать эти вещи вот и мы на самом деле это тоже делали но здесь очень сложно в этом случае приложение строить именно точки зрения там девяностик жившим и так далее то есть вот проектировать приложение так чтобы сделать это есть получается такой лапши и код короче по сути дела да и rx помогает вот эти все вопросы решить очень элегантно и там по факту реализовать эту конвейера обработки сообщений ну очень просто с точки зрения рег рег кв к смешно операторов нет там есть много depends rejection контейнеров и вот на этом все наверное ребят спасибо вам большое за внимание"
}