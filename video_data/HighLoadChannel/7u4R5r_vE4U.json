{
  "video_id": "7u4R5r_vE4U",
  "channel": "HighLoadChannel",
  "title": "Yandex Database: распределенные запросы в облаках / Сергей Пучин (Яндекс)",
  "views": 1695,
  "duration": 3086,
  "published": "2019-12-05T12:49:44-08:00",
  "text": "привет меня зовут сергей путин и сегодня я расскажу вам про базу данных индекс do the bass которая уже несколько лет используется внутри яндекса и которая будет предоставляться как новый сервис яндекс облака индекс про яндекс это bass мы рассказываем впервые вне компании и основная задача доклада это во-первых познакомить вас с системой и рассказать с какими задачами она справляется лучше всего доклад будет состоять из трех секций в 1 секции я расскажу про общее устройство яndex это bass я иногда буду называть сокращенно войди бен и для решения каких задач оно разрабатывалось во второй секции мы подробнее поговорим про клиентское взаимодействие системой и про выполнение запросов на данными в частности как основной операцией при работе с базой данных и в финальной секции я расскажу про особенности выполнения запросов в распределенных системах в целом и в vdb в частности и о том как сделать выполнения транзакций эффективным как я уже упомянул индекс это bass изначально разрабатывалась для решения внутренних для решения задач внутренних сервисов яндекса и в первую очередь это работа с в лтп нагрузкой то есть большое количество относительно легковесных рид write транзакций с низким latency другими словами для работы с онлайн данными и мы попытались взять достоинства классических реляционных баз данных такие как схематизация таблиц традиционное выполнение и что еще и конечно же эскель в качестве языка запросов и объединить их с основными достоинствами nautical решение это в первую очередь масштабируемость по нагрузке отказоустойчивость и высокая доступность таким образом появился индекс do the bass это гиа распределенная база данных она может работать не только на нескольких серверах но и одновременно нескольких дата центрах и при этом оно обладает следующими свойствами во первых это надежное хранение данных с автоматической репликацией то есть любые ваши изменения в базу они автоматически надёжно сохраняются именно за счет этого обеспечивается отказоустойчивость далее это механизм распределенных транзакций то есть транзакции в войде by могут быть выполнены на данными которые физически находятся на разных серверах это низкая latency при высокой нагрузке горизонтальное масштабирование до тысяч not теоретически даже больше но на практике у нас пока что такой порядок и автоматическое восстановление при сбоях то есть если допустим во время работы базы какой-то из серверов отказывает все его функции автоматически распределяются между другими живыми на даме базы это обеспечивает высокую доступность системы ну и наконец декларативный язык запросов индекс квари ленгвич про который мы поговорим чуть позже расскажу про несколько сценариев в которых в и деби используется внутри яндекса первый из них это turbo странице там bdp используется для хранения метаданных о картинках на документах и основные операции это собственно получение метаданных картинок для заданного документа добавление новых метаданных и обновления устаревшей информации то есть это рид брать транзакции размер базы составляет несколько терабайт и нагрузка более 50-ти транзакций в секунду при лет он все не более 100 миллисекунд в 99 писатели достаточно высокая нагрузка второй сценарий это индекс коллекции здесь индекс это bass используется для хранения истории о рекомендациях пользователю и основные операции это получение последних записей из истории о рекомендациях и добавление туда новых рекомендаций для пользователя размер базы также порядка нескольких терабайт нагрузка здесь меньше около чуть больше тысячи транзакций в секунду с задержками не более 50 миллисекунд в 99 persantine но здесь есть очень важное свойство а именно что в данном случае нам необходимо уметь переживать отказ целого дата центра то есть если у нас по какой-то причине пропадает дата-центр мы продолжаем работу на чтение и запись и это нам уже приходилось не раз проверять на практике ну и наконец индекс облака здесь войди by является основным хранилищем метаданных как для системных сервисов так и для сервисов управления пользовательскими данными это объект штор и мошки кстати про мисочку завтра два часа на b гонконг будет рассказ должно быть интересно приходить и перейдем к устройству базы данных с точки зрения пользователя схема базы очень напоминает файловую систему то есть она иерархично разрешает произвольную вложенность элементов и в листьях этой иерархии находится как раз пользовательские таблицы с каждым элементом связанными это данные такие как права доступа размер различного рода статистика и такая организация с папочками по нашей практике очень удобно позволяет организовать хранение более удобным образом а также более гибко управлять правами доступа таблицы таблицы основное понятие базы данных в и деби они очень похожи на таблицы в классических реляционных базах данных то есть для таблицы изначально задан наборы и колонок для каждой колонке известен тип хранить хранимым в ней значений кроме того в пойди б/у таблицы всегда задается праймари ключ он состоит из одной или нескольких упорядоченных колонок так называемый составной пока и он всегда уникален и точно идентифицирует строчку таблицы именно по этому ключу происходит формирование таблицы то есть таблица разбивается на набор независимых шар дав шар это такое основополагающее понятие в яндекс дата bass потому что именно за счет шарди рования vdb масштабируют нагрузку shark является таким примитивом параллелизма при выполнении транзакций а каждый шар каждый в каждом шар ду соответствует некоторый диапазон праймари ключа сейчас я попробовала не очень в общем весь диапазон про мире ключа таблицы делится на диапазоны для каждого шарда и шар отвечает за хранение всех строчек в этом диапазоне праймари ключа а также за работу с ними как можно разбить транзакцию какой господи таблицу на шарды тут есть три способа они не взаимоисключающие первый это uniform парте shining достаточно простой все что вам нужно сказать это при создании таблицы сколько шар дав в ней вы хотите видеть при этом первая колонка праймари ключа должна быть числовым значением равномерно распределенным по всему диапазону соответственно все что все что остается bdb это разбить этот диапазон на заданное количество ярдов и соответственно мы получаем такое изначально и позиционирование таблицы я чаще всего этот подход используется когда мы хотим сортировать таблицу похожу от какого-то логического ключа то есть мы берем хэш который равномерно распределен и именно по нему делаем изначально и разбиение второй способ это явное позиционирование здесь кроме количества шар дав нужно также указать явные границы разбиения для каждого из них то есть чуть больше необходимой информации но зато такой подход работает с ренджи вопросами по данным ну и наконец третий способ который дополняет первые два это автоматическое формирование в данном случае pdb сам решает когда нужно разбить шард на 2 либо наоборот склеить 2 шарда вместе сейчас этот механизм работает по размеру шарда настройках таблице вы указываете пороговые значения и при превышении этого значения shard разбивается на два по медиальному ключом перейдем к ленскому взаимодействию индекс дтп с это сервис яндекс облака соответственно все операции control play на такие как создание удаления бас выполняются средствами облака а уже непосредственно работа с базой данных дай the plain происходит через jar писи api пока что это единственный api предоставляемый системой также мы предоставляем наборы клиентских библиотек для популярных языков программирования а именно python гол и java в них реализовано основная логика по транспорту по управлению сессиями по работе с параметрами и результатами и обработки ошибок то есть очень рекомендуется ими пользоваться так как протянул случаев весь тот же самый функционал придется реализовывать с нуля для попал для написания запросов к yandex дтп с используется язык индекс говорил engage про него мы один раз уже рассказывали в контексте нашего моя принес теперь он же используется для выполнения онлайн запросов в виде by это диалекта сквере по сути как бы это с queen с некоторыми особенностями расскажу про некоторые из них во первых это строгая типизация теперь очень аккуратно работает системой типов каждое выражение имеет явно за заранее известный тип есть правила для явных и неявных преобразований соответственно большинство ошибок обнаруживается уже на момент компиляции запроса это нативная поддержка составных типов помимо примитивных типов таких как числа строки daytime а вы келли также умеет работать со списками и словарями с трактами и to'plami очень иногда упрощает запись логике запроса это именованные подвыражения данная особенность позволяет уменьшить вложенность запроса если у вас есть select из результатов select а то вместо того чтобы делать их вложенными вы можете просто внутренней select вынести в именованный подзапрос читается намного легче и это явная параметризация то есть для параметров запроса явно указывается их тип это не просто где-то ? это конструкция языка то есть описанный параметр с заданным типом также в язык добавлено несколько dml конструкции специально для яндекс это bass во-первых это абсурд апдейт плеснул сорт обновляет строчку если она есть добавляет строчку если такой строчки не было это нативная операция для выйди by очень эффективная поэтому для нее есть отдельная инструкция и также апдейт он делит он который соответственно обновляют либо удаляют строчки но не по предикату а по переданным набор ключей и значений посмотрим на небольшой пример здесь как раз некоторые из особенностей продемонстрированы очень простой запросик на байк верь в начале по начали этот не та кнопка вначале мы объявляем параметры запроса тут можно обратить внимание что у каждого из них есть имя и у каждого из них есть конкретный тип данном случае это did do it and 4 далее у нас именованный под запрос из таблички series и потом вот конструкция absurd в табличку dates которая использует результаты предыдущего под запроса в общем если не обращать внимание на некоторые особенности это чистой воды из квн компиляция запроса в войде bee это достаточно сложная операция которая включает себя во первых парсинг запроса аннотацию типов в оптимизацию подготовку плана запроса и наконец генерацию байт-кода то есть это дорогая операция и так как яндекс и the bass рассчитан на работу с очень высоким рейтом запросов компилировать каждый из них было бы очень эффективно поэтому в борьбе используется так называемый механизм подготовленных запросов по сути это просто кэш результатов компиляции то есть если такой запрос мы уже выполняли то результаты в компиляции скорее всего есть в каша и вместо того чтобы проходить все эти этапы заново мы просто берем готовы для выполнения запрос и переходим как сикиш ну для того чтобы этот механизм работал хорошо очень важно параметризовать запросы если у нас есть какое-то значение которое меняется между разными разными вызовами запроса то вместо того чтобы явно в тексте указывать его например один или два его нужно выносить параметр потому что запрос где значение подставлена в сам текст 22 таких запрос это разные запросы соответственно они не смогут переиспользовать результаты компиляции если же это значение вынести в параметр то один раз скомпилировав запрос мы сможем выполнять его с любыми значениями на схеме это выглядит вот так на execution нам всегда приходит две вещи во-первых это сам запрос и значение его параметров значение параметров никак не при добра батэ ваются и попадают всегда напрямую в execution для запросу же как раз есть две ветки быстрая и не очень быстрая ветка это когда мы находим в каше запросов готовый результат компиляции соответственно тогда мы сразу переходим к execution у и вторая ветка это либо запрос новый мы такого запрос еще не выполняли либо по какой-то причине его не оказалось в кэше тогда мы проходим весь вот этот вот этап компиляции получаем подготовленный запрос и если у нас установлен соответствующий флаг сохраняем его в каше и переходим дальше к экзекутором в общем важный момент тут в том что для эффективной работы системы кэш hit rate должен быть высоким в противном случае мы будем тратить очень много ресурсов на компиляцию и это скажется на задержках выполняемых запросов переходим к транзакциям в яндекс это bass все запросы выполняются в рамках транзакций даже вот простое чтение по ключу это все равно транзакция соответственно транзакции в pdb распределенные и уровень изоляции сериала и забав то есть логически все транзакции выполняются последовательно более формально существует такой порядок выполнение в котором будет эквивалентно реальному выполнению и одна из важных особенности транзакции в vdb это так называемый механизм отложенных изменений то есть все изменения транзакции применяются только при ее успешным комитет сюда следует некоторая особенность что внутри транзакции мы не видим собственных изменений если мы в транзакции поменяли какую-то табличку то для следующих запросов в этой транзакции эти изменения не будут видны это немножко отличается от классического поведения поэтому вот об этом стоит помнить ну и при успешном к мите транзакции все изменения надежно сохранены то есть никакие за комичные изменения не теряются в и деби умеет работать с как мы это называем открытыми транзакциями когда мы хотим выполнить несколько отдельных запросов в одной транзакции при этом сами запросы зависит от клиентской логике то есть мы можем явно открыть трансакцию это делается либо вызовом begintransaction либо специальным флагом на первом запросе транзакции далее мы можем получить результаты выполнения первого запроса выполнить какую-то бизнес-логику приложения понять что мы хотим делать в этой транзакции дальше и уже в существующую открытую транзакцию выполнить второй запрос в конце мойка метим транзакцию опять же либо явным вызовом commit либо флагом на последнем запросе и такие за транзакции все так же остаются с силой забыл изоляции на схеме вот показано как это происходит то есть мы начинаем begintransaction потом у нас есть первый запрос и на основе результатов первого запроса мы решаем какой запрос будет отправлен в транзакцию вторым в конце транзакции завершается коми там чтобы такие транзакции все еще были изолированы от других транзакций применяется механизм оптимистичных блокировок каждое чтение в транзакции захватывает блокировку или лак на весь диапазон праймари ключа который она который участвовал в этом чтение то есть если мы читаем одну строчку то блокировка берется на одну строчку если мы читаем какой-то раньше то соответственно блокировка берется на весь женщин при этом блокировка оптимистичная и она на самом деле не мешает другим за по запросам читать и модифицировать данные этого диапазона очень такое важное отличие транзакция в итоге собирает все захваченные в ней блокировки и эти блокировки проверяются при комитет транзакции в момент коми то что происходит мы сначала мы лидируем все взятые блокировки если хотя бы одна из них была инвалиде равана а блокировка инвалиде руется если в диапазон этой блокировки после ее взятия было было произведено какое-то изменение в случае если хотя бы одна из блокировок транзакции инвалид и равана транзакция считается не успешной и она откатывается далее мы ее либо повторяем на клиенте ну либо делаем какую-то другую логику это уже зависит от логики клиента если же валидация всех блокировок была успешной то применяются все отложенные изменения транзакции и после этого разак сочетается успешно закончен и механизма оптимистичных блокировок есть одно явное преимущество здесь не бывает до блоков прогресс всегда есть то есть как минимум одна конкурентная транзак транзакция всегда завершается успешно чаще всего на самом деле больше чем 1 и по сравнению с пессимистичными классическими блокировками где выигрывает 1 транзакция в оптимистичных блокировках на самом деле выигрываю записи то есть если транзакция вообще ничего не читает если это просто слепая запись то такая транзакция никогда не может быть откачано по причине инвалида ции лаков так как она их просто не берет еще раз то же самое на схеме так у нас есть транзакция вне есть какое-то количество лидов и какое-то количество в right of то есть изменений пройти просто сохраняются в контексте транзакции до момента комета они никак не применяются каждый из видов получает эквайер лак на свой диапазон все локи точно также сохраняются в контексте транзакции до момента к метро момент к метро мы сначала проверяем локи и только при успешной их валидации применяем изменения транзакции в случае неудачной валидации транзакция откатывается именно за счет механизма оптимистично тортик оптимистичных блокировок нам удается получить сериал ой забыл изоляцию даже на транзакциях с несколькими независимыми чтениями перейдем к завершающей секции где я постараюсь рассказать об особенностях выполнения транзакций в распределенных системах и в частности в vdb и проблема заключается в чем так как система предоставляет очень такой generic способ для описания запросов а именно sql и на может сложиться впечатление что можно написать абсолютно любой запрос и он будет хорошо выполняться в системе на самом деле это даже правда но до каких-то значений рпс то есть при высокой нагрузке эффективность системы на плохих с ее точки зрения транзакций будет падать и чтобы этого не допустить стоит держать уме некоторые основные моменты связаны с эффективностью транзакций в борьбе 1 наверное самый важный из них это так называемый размер транзакции собирательное понятие из нескольких характеристик первая из них это количество и сложность операций в транзакций и здесь есть простое правило в одну транзакцию индекс это bass стоит объединять только логически атома то есть только те операции которые должны быть логически выполнен а там арно не нужно искусственно увеличивать транзакцию чаще всего это приведет скорее к негативным последствиям то есть попытаться забывать несколько транзакций в одну это на самом деле плохой способ далее это количество данных затрагиваемых транзакций причем как на чтение так и на запись здесь все просто система спроектирована чтобы работать с большим количеством относительно маленьких транзакций то есть транзакции с маленьким food принтом по данным поэтому если у вас какие-то большие сканы таблиц особенно fools сканы то большого рпс данном случае вряд ли удастся добиться поэтому стоит стараться минимизировать количество данных читаемых транзакций в частности задавая предикаты на праймари ключ таблицы либо на другие индексы в общем использовать индексы это хорошо еще одна характеристика как раз таки связанная с распределенность you системы это так называемая ширина транзакции другими словами количество шар дав затрагиваемых этой транзакции наиболее эффективная 1 шар давай транзакции как пример если вы читаете или пишите ровно по одному ключу такая транзакция всегда 1 шар давая так как за один ключ отвечает 1 шард и такие транзакции очень эффективны тем не менее здесь нет задачи гарантировать 1 шар давай свдп спокойно работает и с транзакциями с транзакциями с мага шар демитра за акциями но если есть такая возможность стоит об этом задуматься то есть если вы например читаете по нескольким соседним ключам то с большой вероятностью такая транзакция тоже окажется 1 шар давая так как мы помним шарды разбиваются по праймари ключу который упорядочен соответственно соседние ключи находятся либо в одном либо в соседних шортах даже если транзакцию не получается сделать 1 шар давай стоит как минимум минимизировать количество затрагиваемых шар дав то есть речь идет о том чтобы явно ограничить те ключи по которым мы читаем например с виду легкая транзакция такая как возьми мне топ 10 строчек по какому-то предикату на самом деле может оказаться достаточно тяжелый потому что без ограничений на ключ таблицы нам придется сходить так каждый shard прочитать то на самом деле не много данных десять строчек например если селективность предиката низкая и потом объединить все эти результаты с виду безобидная транзакция может привести к достаточно большой работе внутри системы поэтому всегда стоит явно задавать предикаты на ключи таблицы особенно это касается касается операций join самой тяжелой операции при работе с базой ну и последняя в данной секции про ответ про размер ответа запроса в яндекс это без есть явное ограничение на размер ответа это 1000 строчек или 50 мегабайт в случае если вы превышаете ограничение по количеству строчек результат просто обрезается и об этом сообщается в соответствующем флаги резал сета случае же превышения ограничения на 50 мегабайт такой запрос а вместе с ним и транзакция завершается неудачи следующий важный момент это время жизни транзакции первую очередь это связано как раз-таки с механизмом оптимистичных блокировок а чем больше время жизни транзакции чем больше время жизни транзакции тем больше вероятность что какие-то из ее блокировок будут инвалиде равана и соответственно транзакцию не получится успешно закомитить поэтому хочется максимально минимизировать время жизни транзакции делать больше коротких транзакций и тут есть 2 рекомендации во-первых стоят минимизировать клиентское взаимодействие внутри одной транзакции например за счет того чтобы выражать всю необходимую логику в одном вы киль запросе благо бы гель достаточно мощный язык и большинство клиентской логике на самом деле можно выразить в самом запросе это позволит во-первых сэкономить их опыта кластера во вторых сэкономить вот это вот время которое тратилась на клиенте для вычисления какой-то логики и второй момент это всегда стоит предпочитать использование флагов для начала и конца транзакции вместо явных вызовов опять же мы экономим тут 2-х по набеги не на комете во вторых в яндекс это bass есть специальная оптимизации которые в случае когда заранее известно что запрос является последним в транзакции и после него будет commit может выполнять его более эффективно в частности как раз таки не захватывая блокировки для этого финального запросов а следующая важная штука о которой стоит помнить это конкурентность по ключам один ключ всегда обрабатывается одним шар дам мы не можем разбить один ключ он всегда ата-ата marine соответственно если по какой-то причине у вас возникает очень высокая конкурентность по одному ключу это может ограничить масштабирование системы мы не можем масштабироваться внутри одного шарда соответственно вы получите достаточно ограниченный рпс и кроме того опять же вспоминая про механизм оптимистичных блокировок если у вас большая рид в райт конкурентность на один ключ то только часть из транзакций будет выполняться успешно остальные транзакции будут откатываться из-за инвалид ации лаков что еще больше снизит gps для успешных транзакций соответственно что делать во первых таблицы нужно сортировать чем больше нагрузка тем больше шар дав должно быть у таблица во вторых стоит избегать так называемых ключей монстров которым приходит очень большое количество конкурентных транзакций то есть стараться размазывать нагрузку по разным ключам база если у вас есть какой-то ключ монстр стоит задуматься что чтобы добавить праймари ключ еще какую-то колонку которая позволит разбить этот ключ на несколько ну и до большие чтения и высокая конкурентность также приводят к инвалида ции блокировок поэтому большие чтений здесь тоже стоит избегать следующее важное части которая хотел сказать это вопрос обработки ошибок и ретро им клиентское приложение всегда должно предусматривать логику для обработки ошибок и retrieve особенно это актуально для распределенных систем потому что система состоит из огромного количества нот и системе бывают спой а соответственно ваша транзакция может по какой-то причине например недоступности какой-то временный недоступности какой-то is not завершиться неудачей и клиентское приложение должно быть к этому готова чаще всего это рису решается простым ретро им транзакция была не успешно мы ретро им транзакцию даже без сбоев например при инвалида ции блокировок опять же транзакция может завершиться неудачей и ее необходимо повторить это делается именно на клиентской стороне просто потому что на сервере в общем случае это сделать нельзя если у вас как раз есть какая-то клиентская логика открытой транзакции мы никак не можем повторить и на сервере поэтому задачу по повтору неуспешных и транзакций решаю решается на клиентской стороне в клиентский библиотеках есть хелперы которые умеют обрабатывать наиболее часто возникающие ошибки системы их можно использовать соответственно добавляя туда свою собственную логику зависимости от того что вы хотите получить также важный момент про транзакции лучше всего использовать одном патентные транзакции то есть такие транзакции которые при многократном выполнении приводит к тому к тому же самому результату это сильно упрощает логику retrieve случае нетривиальных ошибок например транспортных ошибок когда вы отправили запрос у вас пропала сеть и на самом деле состояния транзакции в этот момент неизвестно и наверное последние про что хочу рассказать это тайм-аута запросов это не совсем про эффективность отдельно взятого запроса это скорее про общую устойчивой системы так как в яндекс дтп с очень высокий orbeez транзакции при возникновении кого-то спайка нагрузке или при каком-то сбоя возможно накопление достаточно большой очереди транзакций и установка таймаутов или дэдлайнов на каждые запросов позволяет серверу не выполнять те запросы ответы на которые уже заведомо не интересно клиенту чаще всего вот например там случае яндекс коллекции мы знаем что у нас есть 50 миллисекунд и если мы ответим через там 200 миллисекунд то это то же самое что не ответить этот результат уже не будет интересен соответственно оставляя правильные тайм-аута мы позволяем серверу выбрасывать транзакции которые уже не важны клиенту и переходить к выполнению более актуальных транзакций таким образом мы лучше переживаем эти спайки нагрузки либо какие-то сбои системы в качестве заключения небольшое самаре index to the bass это база данных которая интересна в первую очередь когда для вас важные вопросы отказоустойчивости высокой доступности и масштабирования то есть высокой нагрузке на систему она достаточно дружелюбна предоставляет сиквел в качестве языка запросов соответственно порог входа на мой взгляд достаточно низкий и она автоматически решает за вас вопросы масштабирования репликации и надежного хранения данных на этом наверное все есть слайд с ссылками во первых на правят превью где можно записаться если вам интересны индекс do the bass и вы хотите его попробовать а также ссылки на те sdk про который я говорил для python on gault и java на этом у меня все спасибо если есть вопросы задавайте по себе сергей ровно сорок минут молодец если она до вопросы да здравствуйте меня зовут сергей вопрос такой может я прослушал но вы сказали что первичнее за каждый отвечать только одна шарда и соответственно шарды не масштабируются то есть не понятно что с репликацией если оно вообще так так так сейчас я попробую ответить смотри прошли что я имел ввиду что вот у тебя есть набор праймер ключей за один конкретный праймари ключ всегда отвечает 1 шард просто потому что мы не можем разбить ключ соответственно тут вопрос в нагрузке если у тебя очень большая нагрузка на один ключ то соответственно ты упираешься пропускную способность одного шарда репликация тут не поможет репликация она в первую очередь для надежности она никак не позволяет увеличить пропускную способность шар даром если как чтение же мы можем масштабировать по шагам бренд но если бы шар до самого масштабировать по серверам да ну через дублирование просто данных я понял о чем речь то есть у нас есть механизм так называемый стоял rid of когда данные шарда асинхронно реплицируются и в запросе можно читать с реплик соответственно сительно это позволяет распараллелить чтение однако при сирил ой забыл обработки транзакции в шарди выполняются последовательно поэтому там пропускная способность ограниченной пропускной способностью 1 шар да то есть если нужны самые свежие данные и стоял данные не подходят то для одного ключа мы ограниченной производительностью 1 шар да понял спасибо спасибо свернуть привет спасибо большое за доклад расскажи пожалуйста как устроена уникальный индекса например есть таблицы пользователи которых прайма реки будет и и например надо обеспечить уникальность и mail а как будут распределены локи в данном случае если я хочу попробовать зарегистрировать нового пользователя с заданным мэлом и так то есть у нас праймари ключ это идти о ней mail юзера и деда юзер иди но смотри у нас если ты говоришь про уникальные индексы то уникальных индексов в войде by сейчас нет а как это реализовать но соответственно тебе придется сделать select в котором найти есть ли такой пользуете или нет соответственно основе этого запроса принимать дальнейшие решения у нас есть вторичный яндексе ты можешь построить вторичный яндекс по емейлу он не будет гарантировать уникальность но это можно проверить в рамках selecta но здравствуйте спасибо за доклад хотелось бы узнать есть ли какая-то возможность отлаживать либо сделать локальную инсталляцию данные базы данных для кого-то дебага либо отладки когда нету доступа скажем в интернет да это смотря это открытый вопрос вот прямо сейчас нет но конечно мы об этом помним и если можно еще маленький вопросик по поводу транзакции который по поводу запрос которые возвращают больше чем 15 тысяч или сколько там строки . то есть до 1000 строк а возвращается флаг tranque этот а есть ли возможность получить следующую пачку если какая-нибудь пейджинг ли что-то это pp джонг мы рекомендуем делать пейджинг по ключу то есть тебя возвращается последний ключ и ты делаешь запрос с предикатом на то чтобы след следующей записи были больше то есть вот такой вот п п кинг про то что у вас строю консистентной по нодам строго консистентных данных при этом у вас есть апдейтами то данные насколько велика задержка в обновлении данных по нодам и нет ли расхождения метаданных и данных реальных нет нет у нас ну то есть консистентной на уровне и данных и метаданных и возможно не до конца понял вопрос но то что называется метаданными количество строк это вот всего как бы нет а я понял мне все понял про дадут ли количество строк это действительно статистика то есть мы никогда не говорим его точно только если выполнить явный запрос он обновляется по ходу дела задержка ну наверное секунды около того но это это не является данными системой то есть тут к ассистент ность не совсем ну просто мы столкнулись с tbs столкнулись с тем что в одном аду ты вставляешь большой пока данных и на другой ноги у тебя появляется эти данные не сразу с какой-то задержкой лет такого нет то есть у вас все синхронно только транзакция закончилась со всех ног системы видно эти изменения не они атомарные не бывает такого что есть разногласия по поводу того есть строчки или нету и еще один вопрос ты говорил про именованные под запросы вопрос именованный под запрос если я делаю в начале большого запроса эти данные куда-то сохраняются или каждый раз скоблить при обращении к этому именно запросу заново происходит я понял вопрос а это просто конструкция языка на самом деле это эквивалентно как если записать под запрос как это будет выполняться зависит от оптимизатора то есть оптимизатор в любом случае выполняет запрос так как он считает правильно независимо от того как это было записано сиквел это все-таки декларативный язык а посмотреть как посчитал оптимизатор с помощью explay на которые я сейчас у нас до выдает st запроса спасибо за доклад а если планы предоставлять его не только в облаке как дистрибутив чтобы на свои раскатать честно говоря пока что таких планов нет может быть когда нибудь еще правее у меня вопрос не столько по использованию его продаж несколько по профилактике все-таки абсолютно ненужных данных не существует расскажите пожалуйста как вообще работает backup подобный база данных на практике и в резистор случай если что-то возникло но студия могу рассказать как это сейчас работает внутри яндекса у нас поддерживаются полный backup базы мы их бы copping другой наш сторож называется войти это наш мо предисторию соответственно оттуда можно восстановить этот backup на кластер то есть я правильно понимаю каждая нота пока пицца отдельно в свою как бы меня нет нет то есть по капица вся база данных если она гил распределенная по всей планете то как происходит ну не носите если вопрос как физически происходит до с каждой ноты мы отправляем данные по внешнюю систему вы рекомендуете использовать свои usb для размещения кросс дата-центр то есть между центрами да да вот например яндекс коллекции это crosse bc инсталляция в и т.п. понятно тогда вот сама процедура парадигма восстановление дан как происходит то есть вы за какого-то какого-то одного места запускаете и что также становление backup а все остальные находится восстанавливается в этом направлении backup а да как вам устанавливается ровно в те места ровно все шар допами где это должно располагаться против управляет shorted олега логическая штука может быть на любой ноге кластеры это не так важно то есть мы просто заливаем данные из бака по в шарды где бы они не находились это некритично то есть то есть какой то инструмент оркестровки безусловно карьера спасибо спасибо и последний вопрос слева спасибо большое за кучу вопросов но я так попытаюсь те самые важные соответственно вы говорили распределенность я у меня по-другому не бывает говорили про дороги распределенную не раскрыли как она реализуется хотелось бы чуть чуть услышать у меня выключили они выгнали включи на про это будут доклады на на других я послал в продолжении бэкапов если недоступность кластера на момент быка по есть ли pantene таймер каверы когда мы восстанавливаемся на какую-то точку во времени а как реализуется как реализуется этот контент таймер говори поскольку у вас я так про если я правильно понял координаторы транзакции равномерно распределены по ну каждый узел скорее всего является координатором соответственно где тот секвенсор который позволяет вам получить count on time recovery ну и еще чего-нибудь сейчас я вспомню я хотел а следующий вопрос будет платным уже заворачиваю спасибо жду ответ так ну про бэкап и нет они не добавляют down time of то есть как это происходит мы берем снапшоты на все таблицы и соответственно далее уже работаем с этими snapshot ами постепенно заливая их во внешнюю систему это не препятствует онлайн нагрузки это отнимает некоторые ресурсы системы это правда но это все таки бэкграунд процессы и они не должны сильно влиять на онлайн нагрузку про point in time восстановление у нас сейчас довольно часто не уверен насчет наталия отвечаю или нет но backup устанавливается отдельно стоящие таблички и только после восстановления на них подается нагрузка поэтому там наверное не возникает такого вопроса вот я прям вижу ваше будущее сейчас общается когда мы официально войти вот эти за в зоне дискуссий попробуем выяснить истину кому книжку подарим если честно мне прям 1 просто очень понравился больная тема параллельные транзакции на чтение а вы еще здесь покажитесь волонтеру у нас просто некоторые сессии x появится тот видео но не все вот прекрасно замечательно"
}