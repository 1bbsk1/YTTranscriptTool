{
  "video_id": "OOP_4kuzaWI",
  "channel": "HighLoadChannel",
  "title": "PG Saga: зависимые изменения данных в нескольких сервисах / Константин Евтеев (Avito)",
  "views": 19462,
  "duration": 2866,
  "published": "2019-01-14T00:08:24-08:00",
  "text": "всем привет меня зовут константин гордеев йа рабба это и сегодня я хочу с вами поделиться опытом как мы решили один из вызовов микро сервисной архитектуры построения бизнес транзакций в инфраструктуре сервисов построенных с помощью паттерна дата был сервис давайте вот побыстрому введу в контекст но в прибывший кто не слушал доклад у николай например значит какие у нас условия то есть изначально мы жили в условиях монолита где у нас монолитной базы монолитные приложения и далее возникает потребность когда уже не можете дальше вертикально расти и соответственно начинаете строить микро сервисную архитектуру и монолитной инфраструктуре у нас был соответственно все честный и сид когда у нас много различных сервисов и нам нужно выполнить там например покупку какой премиальной подписки где нам надо списать деньги применить какие-то услуги пользователю пакеты басов купите где-то что-то пойдет не так уже не совсем понятно как это все делать соответственно немножко теория вот в том числе мне например нравится ответ на это есть ответ как вы уже поняли мы нашли в сагах мне нравится white paper 87 года где в принципе не гектор гарсия малина кстати он сейчас один из членов совета директоров оракла описывает следующую задачу которую как они решают значит проблема была в чем значит есть долго живущие транзакции и тогда когда ресурсов не так много было нужно как-то реализовывать многозадачность то есть одной стороны длительные задачи надолго эксклюзивный забирает ваши ресурсы короткие задания не проскакивают с другой стороны могут в том числе находиться и длительные блокировки опять же то и соответственно то каскад блокировок выстроится вашей свободы и более того а вдруг что-то пойдет не так и транзакции не завершится и начнется откат и тогда если она была достаточно длинной откат будет идти тоже долго и ретро и потом опять все это время будет происходить то есть это все тяжело и что там предлагается там советую почитать берем и бьем длинную транзакцию на части и более того мне кажется многие из вас уже к этому подходили им его это тоже к там подходили даже не что этот документ неоднократно мы рассказывали от мир про наши div проки когда мы например брали берем блокируем пользователя мы выполняем транзакцию короткую быстрый отвечаем моментально клиента of trance акционную очередь мы ставим задачу потом асинхронно там небольшими пачками по 10 объявлений его объявление блокируем то есть вот это вот все делали с помощью транзакционных очередей но сейчас вот немножко с другой стороны надо взглянуть соответственно у нас микро сервисная архитектура это не одна особа д.и. перед нами стояла следующее требование нам нужно было достаточно быстро разнести наш монолит при этом нам нужно было чтобы это было быстро нам надо бы мы решили перенести старый функционалу как есть логику нами красе рвались на сервис на микро сервисы как есть соответственно мы хотим обеспечить целостность бизнес критичных транзакций и консистентной иметь возможность задавать строгий порядок более того мы хотим гарантировать и уметь проверять и это то есть действительно нашей распределенные транзакции теперь работает в итоге мы реализовали оркестре ru ему юсова виде сервиса пиджи сага на данном слайде вы соответственно видите такую схему значит верху это сервис пиджи сага пиджи потому что как хранилище в этом сервисе мы используем синхронный под груз также в нем есть еще компонента есть api и экзекуторы ряд других компонентов я сейчас позднее буду подробнее рассказывать также на схеме не забыли изображен на верху сервис владелец так и внизу сервисы которые будут выполнять шаги саги и у них соответственно могут быть разные хранилище значит сначала сервисов владелец саги должен у нас зарегистрировать в сервисе сак некую сагу что он будет теперь их создавать после этого он генерирует класс саги то есть уже с пилотом и далее уже в сервисе suck экзекутор by поднимает из хранилища копи щиеся саги и начинает выполнять ее по шагам соответственно первый шаг в нашем случае мы рассматриваем случае значит покупка премиальной подписки происходит сервисе биллинга резервирование денег потом получается в сервисе пользователя применяются некие вас операции к нему и далее уже вас сервисы создаются какие-то пакеты басов ну и может быть дальше еще какие-то шаги есть ну как вы понимаете могут быть различные аварии и прежде всего то есть вот известные приемы которые в распределенной системе нужны это сеть может быть ненадежно надо делать и литра и для того чтобы не было дублирования операции нужно каждую операцию маркировать каким-то ключом едим патентным вот так же есть ссылка на слайде мне очень нравится от материал тоже рекомендую почитать но это известные то есть вещи в распределенной структуре инфраструктуре а вот специфичный для содействия это компенсация транзакцией соответственно для каждой положительной транзакций мы должны писать обратные действия бизнес цена и шага и который в случае если что-то пошло не так в том числе в нашей реализации мы предлагаем следующий сценарий даже если у вас какой-то шаг саги не успешно завершился вы сделали н retrieve все равно есть вероятность что на последнем ретро и повторе этой операции он сработал успешно но просто вы не получили этот ответ поэтому мы потом пробуем в том числе его компенсировать просто этот компенсационный сцена и не является обязательным и соответственно мы выключаем в вас и пакеты отменяем операцию пользователя отменяем резервирования средств размораживаем средством а что будет если все таки и компенсация не работает ну логично предположить что сценарий очень похож что компенсацию транзакций нужно делать точно так же как и положительные транзакции то есть мы точно также применяем и литра едим патентные ключи а далее если уже не получается произвести компенсацию но вот например сервис недоступен которым шаг мы должны компенсировать далее можно делать вызов уже сервиса владельцы саги и говорить о том что это сага неудачная и там уже эскалировать дальнейшем проблему например для ручного разбирательства или какую-то новую автоматику запускать городить более того хочу отметить важный момент представьте себе что у нас какой то шаг саги сервис он стал недоступным а наверняка же еще на стороне тот кто инициирует это действие он потом какие-то ретро и буду делать и соответственно ваш сервис сак начнет до какого-то шага делать первый шаг 2 шаг авария отменяем второй шаг отменяем первый шаг и у нас получается сервисах будет заниматься непонятно чем а еще возможно аномалий в этот момент соответственно в данном сценарии мы делаем еще один момент вот там сейчас есть hell checker еще блок этот hell штекер должен опрашивать шаги сервисов сервисы которые выполняют шаги сак смотреть а работают ли они и в случае если они не какой-то сервис стал недоступен мы те которые уже в работе саги мы их компенсируем а которые новые можно соответственно что делать либо в принципе не давать генерировать экземпляр таких сад либо давать их создавать но не брать в работу их экзекутором чтобы сервис не занимался лишними действиями которые не приведут ни к чему хорошему а давайте посмотрим еще один сценарий представьте себе что мы опять же делаем ту же самую пример подписку покупаем мы резервируем средства применяем в пользователю какие-то услуги создаем вас пакета и все вроде бы хорошо а тут внезапно когда наша транзакция завершилась выясняется что у нас сервисе пользователей было асинхронной репликации используется а еще бывает так что бывает какая-то такая нагрузка на вашу реплику когда по различным причинам она либо и и перегружает его она не успевает накатывать репликацию либо может быть такое что она блокирует проигрывание репликация либо ваш источник перегружен по каким-то причинам ваша реплика отставая отставала и после авария тот шаг который был успешным стал внезапно неуспешным то есть все сломалось для этого реализуем еще один компонент системе мы делаем checker checker занимается тем что через время заведомо больше чем все ваши отставания возможны там мир через 12 часов вот такая цифрам нам нравится мы проходим по всем шагам успешных шаг сад и проверяем а действительно ли они до сих пор успешно выполнены и если соответственно он не выполнит мы производим откат этой саги как вы успели увидеть что достаточно много различные лайки на разных местах вот этой вот распределенной транзакции нашей и когда мы с вами скажем клиентским командам интегрироваться которые должны будут создавать саги которые должны будут делать там сервисы чтобы они были частью этой саги у них станет весьма большой набор задач очень неочевидных нам нужно прежде всего как-то создать сагу так чтобы не получилось двойного создания то есть работать какой-то не пакетной операции созданием написание трека ними а далее нужно что то сделать в сервисов чтобы они умели трекать каждый шаг каждый саги с одной стороны чтобы как бы опять же два раза ваня выполнить с другой стороны еще надо уметь ответить а действительно ли он был выполнен а еще это все висеть и механизму надо как-то обслуживать чтобы наши хранилище наших сервисов не переполнились а еще есть большая масса языков к на которых могут быть написан написано ваши сервисы огромный выбор хранилищ и на каждом этапе это очень во первых то есть нужно разобраться в теории нужно имплементировать всю вот эту вот логику на разных частях и более того можно еще нагородить целую кучу ошибок то есть есть много правильных путей и столько же моментов когда вы можете оставить все конечность соответственно для того чтобы это работало нужно все это завернуть в клиентские библиотеки которые будут прозрачно для ваших клиентов все это реализовывать но вот как пример то есть того что можно вот реализовать клиентской библиотеке можно сделать генерацию саги значит прежде всего то есть мы получаем какой-то request айди который по которому должны создать сагу дальше мы идем в сервисах получаемые уникальный идентификатор у себя эту информацию куда-то локально сохраняем далее сервисах мы должны запушить всю вот эту тягу с приводом и вот я предлагаю следующий подход можно сделать по другому первый шаг саги которую вы делаете в этом сервисе вы в том числе почте и в сервисах первым шагом то есть все свои операции они вы делаете его первым шагом и далее уже возникает уже некой гонка когда сервисах может выполнить этот шаг и вы должны в том числе еще его выполнить кто-то из вас его выполняет это в любом случае у нас один раз вы делаете дим патентную операцию и только после этого вы отвечаете клиенту которого танец и и рвал это действие то есть данном случае мы говорим о том что мы будем работать вот это пример как вы с базой данных вы же можете отправить запрос а далее соединение может быть и оборвется но действие все равно будет выполнено вот примерно точно так же так дальше а как это все проверить нужно написать вот там пирамидка есть на слайде побольше unit тестов дальше уже интеграционных тестов и and the end тестов то есть достаточно много надо написать тестов но все равно микро серво на микро сервисной архитектуру накладывает некую специфику и это специфика вот выражается следующим мы для себя во вид приняли следующий подход к тестированию микро сервисной архитектуре консьюмер на drawing контракт в чем это заключается что когда у вас про какую проблему то решаем эти тесты могут верить и всего никакие проблемы могут вскрыться только на инту эн тестах они очень дорогие и потом очень сложно вернуться назад то есть как понять заранее что у вас все работает значит confirm and driving контракт заключается в следующем подход что у вас есть некий сервис который предоставляет контракт то есть он у него есть api это провайдер а есть другой сервис который вызывает эта питайся пользуются этим контрактам этот консьюмер и соответственно тот сервис который является консью миром пишет тесты на контракт провайдера причем эти тесты которые будут проверять только контракт никакие это не функциональные тесты нам важно гарантировать что в случае если тот меняет свою афишу нас не сломаются наши шаги в данном контексте и далее после того как вы написали эти тесты у вас появляется еще один элемент service broker где вы регистрируете что у вас теперь есть тесты и далее при каждом изменении сервиса провайдера он будет поднимать в изолированном окружении тесты которые написал для вас консьюмер таким образом в сервисе сак мы регистрируем команда которая генерирует сайгу саги пищат тесты на все шаги слабее регистрируют и на слайде есть ссылка с нашего доклада на реке тоже рекомендую ознакомиться теперь давайте рассмотрим какие могут быть виды сак значит всади у нас могут быть по разделяться шаги сак по порядку вызова функции то есть может быть неупорядоченная когда мы можем все сразу вызвать или упорядоченная когда последовательно вызываем давайте рассмотрим какой-то сценарий конкретный пример первым шагом тот же самый сценарий премиальной подписки покупки мы должны зарезервировать средства постов когда мы их зарезервировали изменение к пользователю и создания каких-то премиальных пакетов мы можем выполнить уже параллельно а пользователю мы должны отправить уведомление только когда закончатся эти два шага и второе отделение может быть сак синхронные и асинхронные как мы вызываем шаги suck данном случае хочу вас предостеречь от никакой ошибки лучше не делать синхронные шаги сак особенно при таком подходе потому что в дан если вы будете делать синхронные шаги suck the service так будет ждать пока выполнится этот шаг то есть это лишняя нагрузка и лишние проблемы в сервисе сакон 1а участников так много шагов масштабировать как это все можно масштабировать можно следующим образом все зависит от того какого размера вы планируете свою систему ну может быть это одна база и обрабатывать просто большими одним обработчиком шаги и так далее вы можете н обработчиков выстроить и сделать некую как расческу то есть по остатку отделения выгребать то есть каждый экзекутору вычет вытаскивать свои шаги или можно реализовать уже с тем что вот у нас на подвесе skip локи то есть еще быстрее будет а далее уже если вы заранее знаете что вы упретесь производительность одного сервера суде в данном случае нужно делать шарден когда мы будем говорить что у нас будет an instance of base и они будут работать с каким-то своим набором данных sharding соответственно то есть вы должны вопи реализовать сортирование а что если нужно еще больше гибкости даже в этом паттерне можно организовать такую ситуацию о которой говорил николай что чисто теоретически можно допустить что клиентский сервис будет обращаться к сервису sakai вписываться туда и в том числе может быть и опциональное участие в саге а еще может быть такой сценарий когда компенсировать невозможно действие если вы уже отправили письмо назад того отправить как бы нельзя ну можно например другое письмо отправить что это было неправильно вот и могут быть сценарии соответственно в том числе когда у вас будет проигрываться сага только вперед никаких компенсаций а в случае если на вперед не проигрывается значит это как раз вот тот случай когда надо со обращать сервису владельцу саги что все ничего не работает а еще вот такая вот история я когда пришел в команду биллинга рассказывать им про сайдинг а вот нам нужен log ну давайте ещё назад тогда шаг сделаем целом если вы можете сделать свою логику без саги не надо делать сагу то есть не надо делать это сложное а сроком примерно то же самое лучше делать без блока то есть и им я конкретно объяснил своим лак не нужен но это стоит предусмотреть что лог возможно потребуется мы до сервис исак примерно такие действия когда я вот рассказывал что мы синхронно чет делаем и потом асинхронно доделываем и такие блокировки реализовывали как и можно сделать если вы рамках одной свободы вы можете сделать некую таблицу в которую будете сохранять записи о блокировке и далее в триггере над объектом этой блокировки ходить в эту таблицу и случай если кто-то пытается его поменять во время блокировки то есть генерировать исключения примерно то же самое можно сделать и в сервисе сак тут главное соблюсти что прежде всего порядок то есть я предлагаю следующий подход что сначала мы делаем блокировку в сервисе сак если мы через сагу хотим блокировать а потом уже и и спускаем до клиентского сервиса вот выше риск описанным подходом можно и по другому но главное что был правильный порядок и вот тут вот уже возникает совсем сложные моменты если у вас появились блокировки значит у вас появится еда блоки а если у вас появится до блоки а значит нужно делать детектор дат локов в общем все сложно а еще блокировки вероятнее всего могут быть эксклюзивные и разделяемые в общем это все можно реализовать для себя я это держу в голове вероятнее всего многоуровневую блокировку делать тоже не планирую то есть это еще сложнее будет это достаточно сложная история сервис должен быть простом потому что он единой . отказа все его всех ваших транзакций получается вот может быть на одном уровне вам примерно того же советую так а теперь еще один такой вот момент сложной у нас получается есть от омар ность за счет того что все шаги либо выполнится либо компенсируется у нас есть какая-то консистентной сочнее на не какая-то она есть за счет сервиса сак и локальных хранилища в сервисе сак мы обеспечим и герой ability за счет локальных хранилищ а вот изоляции у нас нету и в отсутствие изоляции у нас будут возникать различные аномалии аномалии будет возникать когда мы будем можем потерять обновление когда вы прочитаете какие-то данные потом кто-то другой что-то запишет а ваша исходная транзакция возьмет и перепишет эти изменения могут происходить грязные чтения когда вы в процессе выполняете какую-то сагу сделали одно там что-то записали кто-то эти изменения уже прочитала ваш от 1 агата еще не закончится и вы еще раз запишите что-то поменяете ли кто-то прочитает неправильное состояние а еще может быть неповторяющиеся чтение когда вы в течение одной и той же саги будьте получать разные состояния вот этого вашего объекта какого-либо и для того чтобы этого всего избежать как с этим бороться вам нужно прежде всего например работать с версии объекта то есть держать некую версию в меру пользователя и и инкрементировать при каждом изменении и проверяющего вы все еще работаете с ней или же смотреть то состояние с которой вы хотите поменять то есть часть чего-то там статус и смотреть что вы проверяете применяете его к тому самому статус у которого до этого хотели сменить как я уже говорил можно выстроить блокировки и соответственно выстраивать реализовывать все изменения вокруг главного объекта sagen а еще такой вот важный момент что в пайлот саги передавайте только события не работайте состоянием потому все это вся эта история и венчали консистенции и если вы передадите там состоянии объявления сервису пользователей может быть она уже поменяется к тому моменту нужно только говорить что там произошла на мир блокировка пользователей ли мы применили пользователю премиум услугу все больше ничего не нужно так мониторинг как всю эту историю мониторить соответственно нам нужно мониторить выполнение сак соответственно нам нужно мониторить саги с разбивкой по всем шагам и по всем статусом мы должны собирать телеметрии то есть мы должны собирать том числе как долго выполняется каждый шаг саги и сами саги все то же самое мы должны смотреть и для компенсирующих транзакций плюс дополнительно еще у нас есть шейкер а еще хорошо бы обложить ваш сервис от метриками на каждом шаге вот но тут вот примера графиков некоторые которые мы собираем я заключение чего хочется на что хочется обратить ваше внимание что если мы проектируем сервисах нужно избегать паразитной нагрузки об этом я говорил что нужно строить некий checker если какой-то узел вышел из строя нужно прекращать выполнять эти шаги потому что сервис acadian клиентов много и вы просто перегрузите лишний нагрузкой ваш сервис сак заранее подумать о том как вы будете масштабировать этот сервис ок старайтесь избегать сложную логику и избыточного функционала в сервисе сак потому что как только вы ввязываетесь в эту историю сервисах становится самой критичной точкой вашей инфраструктуре и в случае его отказа впоследствии могут быть ровно такими сколько какой вы функционал на него на вяжите то есть мы хотим его завязать самый критичный функционалом и поэтому в том числе про тот patterns а когда мы говорим про хореографии про то что рассказывал николай почему он выгоднее смотрится потому что там сервисах участвует только тогда когда что-то пошло не так то есть в общем виде даже если ваш сервис ок хореографию при графе поттер не сломается у вас все будет продолжать работать он там нужен только когда нужно выполнять откат в случае если мы делаем регистрируем ую сагу с выходом из строя сервиса сак выйдет все соответственно чем меньше логике вы туда вкрутите тем проще вам будет работать чем быстрее он будет работать тем надежнее будет вся ваша система в целом следующий шаг интеграция с клиентами то есть обучить все ваши команды всем этим подходом то есть вот этот вот пласт теорий надо прочитать как работать с хранилищами очень сложно подумайте как сделать удобно то есть работу с локальном хранилище работу с одной с одним языком с другим языком то есть все это нужно в библиотеке клиентские положение мониторинга allure think соответственно нужно смотреть все перцентиле потому что только по ним можно понять когда у вас по ним раньше поймете что что-то уже пошло не так по различным шагом мониторить надо сервис ваш failover то есть том числе у сервиса sacd нужно прикручивать хранилище у к локальному то есть все это обкладывать и тестировать тестировать данном случае мы говорим про сервисах соответственно нужно покрыть весь сервис ок тестами для того чтобы в случае внесения раз там не должно быть сильно больших большого и сложного функционалом и вы его вероятнее всего будете менять чтобы все это внезапно не сломать потому что вероятнее всего у вас все будет работать положительно и когда вы вы хотите когда у вас случится авария это будет очень неожиданно что вас что-то пошло не так поэтому все нужно покрывать тестами следующий момент прасаде что хотелось сказать нужно проектировать компенсационной транзакции причем в этом вам больше помогут сторона бизнеса то есть вам нужно прорабатывать тот сценарий то есть что делать если вас что то не получилось как быть случае различных аварий то есть когда невозможно выполнить сагу тоже опять же нужно внимательно это с бизнесом изучить этот сценарий то есть что мы будем делать если вот больше невозможно выполнять это действие а что если будет таких операций очень много то есть мы уже руками это не обработаем то есть все вот эти сценарии нужно заранее описать отсутствие изоляции это вообще очень сложная и соответственно лучше прям вот рисовать различные сценарии кто работает с тем или иным объектом вашей саги которые или частью саги то есть конкретного шага и что может пойти не так если он прочитает это изменение в середине и соответственно защищаться от этого блокировки может быть стоит сделать но если вы будете делать вы должны понимать что это еще сложнее все и авария будет еще более плачевней сложнее будет все это де бо жить и отладить мониторинга лифтинг соответственно это метрики нужно со всех сак собирать и соответственно тестировать непосредственно уже шаги вашей саги так на этом у меня все на последнем слайде вот такая вот картинка вот этот слоника иллюстрирует наш сервис 50 и он сверху присматривает и смотрит вызывает шаги со всем спасибо ваши вопросы что шакал о вопросе есть ну вот давайте вот при последнем ряду мужчина здравствуйте меня зовут игорь подскажите пожалуйста а как в случае поломки саги как вы определяете место где она сломалась соответственно как я уже сказал мы шлём метрики о том сколько с одной стороны мы можем со стороны сервиса сок получается мы шлём все состояния то есть что сейчас взяли в работу шаг допустим резервирование средства саги там номер три и далее на все эти шаги сак мы должны повесить некие alert и то есть если не работает долго какой-то шаг саги значит что-то уже пошло не так но это может быть еще сага совсем не сломалась то есть просто может быть там какая то нагрузка на этом сервисе а вот как определить что совсем не работает какой-то шаг саги например в данном случае получается hell checker проверяет все in point и клиентских сервисов на то что они все еще в принципе работают а с третьей стороны еще может быть аварии страны бизнес цена я и вот ответственность бизнес сценарий что ваша транзакция бизнес выполняется корректно это уже полная ответственность клиентской команды и владелец конкретно взятой саги должен покрытие тестами в том числе and one тестами то есть когда он ее проектирует и далее получается уже различные в том числе дополнительный бизнес метрики та команда которая стимулировала эту сову она их у себя как-то трека и ты соответственно зона уже и и ответственность простишься сценарий если у вас три sing там пассажирка лайки а вы имеете ввиду tracing по 40 лойди да это прозрачно все состояния в хранится то есть как бы но это уже в общем есть некая пик куда вы в сервис саги прокидывайте этот вот идентификаторы конкретного экземпляра саги и он вам возвращает его состоянии и текущее то есть это задач оркестров понятно спасибо дальше по вопросу спасибо за доклад я правильно понимаю что оркестровую сагу вы используете как возможность рефакторинга legacy кода если бы была возможность написанием всего с нуля вы бы использовали хореографическую сам да все правильно тут очень интересный и об этом докладе не сказал что тут появляется узким горлышком сервисах то есть получается вам нужно сообщить если вы хотите как-то поменять сагу вам надо пойти команде которая владелец этой саги договориться о том что вы чтобы там собираетесь менять потому что у нее там в том все тесты над мир могут быть но в любом случае то есть вам как минимум надо с ними договориться или закрыт кантри beauty в их сервис тот ход который теперь будет генерировать сагу с дополнительно вашим шагом и таким образом получается что это достаточно узкое горлышко это очень плохо масштабируется если у вас очень много команд и различные бизнес-логики это минус плюс почему вот именно текущей функционал так удобно переносить потому что мы можем заранее более жестко это и тестировать и соответственно гарантировать и порядок выполнения и проверяемость еще у кого войти сюда силой зато клад первом докладе был представлен только идеальный мир значит есть мана лист своими проблемами от с другой стороны ночника сервисы такие все независимые у каждого своя база и есть такая легковесная шина и все отлично работает а во второй части вот я сушу значит вот эта шина это какой-то самописный от получается да я лежу себе вот сколько если smarties над это тут в данном случае как бы можно сказать как жена это пузырь с грубо говоря в данном случае выступает синхронный по сгрыз ну и еще одним а помимо плоскость за там же и же пару строчек кода по иногда там 8 человека месяцах сколько это примерно я думаю мало какая компания вот это потянет эту шины можно забыть это все дело и обжарено монолите можно не вы просто проблема монолита то есть целая тема доклада просто когда вы смасштабировать и до определенного размера вы у вас просто релиз уже будет такое время занимать что вот этим всем командам который различный функционал свою ник дедлайна вы спроса не сможете релизиться поэтому инвестиция в написании соответственно такого сервиса она оправдана более того вероятнее всего вам может я же примерно описывал как мы сделали и любую из этих частей может быть какую-то часть из этого есть реализуете она вероятнее всего удовлетворит вашим потребностям тут главное на берегу заранее понять то есть что именно из этого всего вак нужны как много ресурсов у вас есть тогда другой вопрос архитектурных сколько там патронов этот паттерн шаги он как бы такое но общий там я думаю рублей можно собрать целую кучу там по мониторингу еще почему-то по вот этому фол как это саги там откатываются и все ли он там развесистые там на полу томов этот паттерн я сейчас уже не очень понимаю что именно томами мерить сервис от должен быть максимально простым он то есть если мы говорим например вот про конкретную реализацию у вас есть шаги вам их надо вызывать то есть либо в обратную сторону может вам компенсация не нужна то есть просто в каком или ином виде если вы будете делать микро сервисов набор вы должны либо в каждом сервисе каждой команды у вас будет реализовывать что-то если у вас нет вообще потер насок что будет взаимодействовать с другим потом это должно еще с чем то еще и таким образом то есть эти взаимодействия очень много вероятней всего повторяющихся частей в этих взаимодействиях тоже очень много и просто каждая команда которая делать тот или иной микро сервис будет делать похожие вещи собирать похожие баги и тратить много времени на это то есть это в будущем должно в любом случае окупится с точки зрения ресурсов спасибо еще давайте вот сюда здравствуйте меня зовут роман я хотел спросить действительно не каждая компания осилит сделать все это с нуля вы не планируете это выложить вклад в open source то есть как у вас тоже есть название по косово может быть название да есть пока конкретно не могу точно сказать то есть есть даже желание насколько на текущем этапе это не готово для того чтобы вы выложить i'm open source в том числе если у нас есть желание соответственно вероятнее всего есть появится завод возможность мы это выложим какие-то имплементации то есть если говорить не про наш внук меру то что николай рассказывал крис ричардс сон и микро сервисе с его сайт который там в том числе на его гитхабе есть его реализации сервисов сак еще вопросы of a здравствуй а можно чуть подробнее вот шина этапа сгрыз как понять то есть каким образом о чирикает события что нужно узнать какой то шаг я это очень такое как стать абстрактное сравнение сказал то есть я про сказал что нас тут нет шины получается то что вот я до этого рассказывал то есть каким образом приходит событие у нас получается сервис как владелец шаги сохранил экземпляр вызова саги сервисах то есть это набор in point of в нашем случае это in point биллинга пользователя какой-то и вас сервиса и туда внес некий пилот и далее получается что делает сервисах он делает вызовы вот этих вот in point of с тем по его одном который ему пришел от сервиса вагнера то есть по факту вызов api просто вот таким образом это работает то есть если в шине данных у вас есть некий event вы бросаете далее вы подписывайтесь на какую-то очередь то есть найти ивенты и вам приходят эти event это в данном случае получается сервиса вниро бросает создает экземпляр саги и далее сервисах вызывает конкретная api различных сервисов определенном порядке ещё у кого-нибудь россия спасибо за доклад вопрос про тестирование как вы тестируете вообще в принципе вот этот сервис сак и тестируете ли вы именно последовательность сак в рамках одной транзакции допустим хороший вопрос спасибо значит тут есть разные блоки тестов если мы говорим про сервис от то есть этот инструмент это по факту что он умеет выполнять положительный транзакции умеет их компенсировать в случае не работы посетить там положительно негативных сценариев то есть будет делать сервиса авнер осакой и тут получается мы пишем тесты в общем виде что какую-то абстрактную сагу может выполнить какие то есть цена и соответственно юнит-тесты с другой стороны соответственно непосредственно сами положительные транзакции компенсационной транзакции на сервисах которые выполняют шаги сак это уже теста не это же простой api соответственно команда владелец этого сервиса это уже на зоне ответственности ответственности написание тестов на эти вещи в сервисе далее следующий шаг идет далее есть консью мин driving контракт соответственно тот сервис который создал сагу он либо напишет тесты проверки этих контрактов либо они уже есть он просто зарегистрирует сервис брокере то что теперь при изменении любого сервиса участника саги будет подниматься изолированное окружение и будет про гоняться тесты вот сидиси а далее уже команда которая владелец сагой пишет nt and test где она проверяет что вся бизнес логика работает в данном случае когда выполняется это сага intent это значит уже когда появляется какое-то дев окружении поднимаются все экземпляры сервисов и в том числе сервисах и там уже проходит проверку непосредственно бизнес сценарий константин спасибо меня зовут дмитрий у меня пара вопросов 1 я правильно понимаю что вот он пиджи сага есть некое мета описание всех этих сценариев куда то есть это есть класса сохо писан то есть сценарий описаны в сервис из окна чем это пицца это просто реляционная структура таблицы в которых есть саги отдельно есть шаги этих sacd есть некие связки соответственно там же есть конкретные как называется api описано контракты и все такое то есть если мета-описание рядом с в сервисе сак есть одной стороны мета-описание а с другой стороны есть уже непосредственно вызовы и состоянии конкретных шагов шаги история кто регистрирует вот эти шаги шаги в едином реестре то есть даже еще вопрос чуть глубже есть какой-то сервис в широком смысле да которые представляют набор api есть какие-то внутренние например api и часть api которая является сагре это правильное утверждение то есть часть а пиво является каким-то внутренним может быть а часть может являть внутренней api может быть являться частью саги в том числе у сервиса это понятно но наружи как бы торчит определенный api которая условно говоря успешная и компенсирующие дак которая является именно api для саги да вот этот сервис он сам регистрируется там или это как бы никаких контракт а снаружи грубо говоря вот вот то что часть саги это как я уже сказал тут могут быть два сценарий нормальный сценарий если вот чтобы ваш сервис стал частью саги нужно какую не клиентскую библиотеку который сделает как раз вот эту всю работу в общем виде для различных сервисов одинаково что она построить какую-то структуру хранилище вашем клиентском сервисе нд мир там втором туре сделать какую-то структуру чтобы трек ать этот шаг шаг и соответственно имплементировать себя вызовы внутри него и и работу сервисом сак то есть это все вместе соберет это понятно общее как бы это понимаю регистрация идёт регистрация если я говорила снаружи и как у меня больше интересует как бы кто за и кто ответственен кто занимается кто ответственен за правильный сценарий кто его тестирует и кто отвечает за финально за то что вот полностью вот эта сага работает корректно за это отвечает сервис владелец саги причем сервис владеет владелец саги он в каких-то случаях в том числе может быть на других in point of участникам других сак и в данном случае то есть на прессу и там говорить там пользовательского опыта у вас есть команда это получается в данном случае сценарии описывает команда которая занимается пользователям то есть она создает сагу которой она зарегистрирует в сервисе sako на договаривается со всеми командами или смотрит туда то есть непосредственно мая кантри beauty твоих репозитории что теперь вот такие какие-то шаги будут выполняться различными сервисами и покрывает тестами ну то есть это уже могут еще какие-то команды сами все сделать но вот непосредственно бизнес test and the end это уже на ответственности команды который владеет и которые непосредственно регистрировал эту сагу в сервисе сад спасибо вот молодой человек и сюда спасибо за доклад было очень интересно у меня вопрос такое у вас есть checker который через 12 часов понимает что операции нужно отменять правильно можно отменять я сказал только отменять но может быть такие ситуации в том числе то есть это возможные варианты как вы напишете может быть просто надо сообщить серверу то есть через на часов может быть так что то менять уже и ничего особенно ну все уже куда-то движется все и соответственно может быть такой сценарий что вместо отмена у вас просто должен быть и сигнализация сервиса владельцу саги о том что эта операция не выполнилось ну вот у меня собственно такой похоже был вопрос что что вы делаете если операция отмены невозможно ну то есть например там пользователю за что-то накинули денег потом нужно сделать отмена у него уже баланс там 0 и списать с него нельзя эти деньги такие догнали или ужин решать бизнес соответственно и в данном случае вот именно в конкретных примерах обычно игра идет в пользу пользователя получается у него такой бонус то есть он заработал да хорошо спасибо вот мужчине потом дальше вам спасибо за доклад моими вниз алиев хотел спросить вот когда вы это выбирали я вот смотрю это похоже очень на берем движки чем-то смотрели вы ли их в качестве альтернативы вот этого накал оркестра таро если смотрели то какие плюсы-минусы были я незнаком вот они термина не услышал какой движок ну например флорбол то есть bpm движки которой оркестрик бизнес-процессы то есть такой язык bpmn времени в данном случае несмотря не рассматриваем спасибо спасибо за доклад вопрос вот у вас есть пиджи сага сервис есть бизнес сервисы которые соответствуют его идеологии у вас есть api а что с version ностью если проблемы и как вы с ними боретесь в конкретно данной реализации version ностью следующая история в случае если мы говорим что отцы именно в этом сервисе в этой имплементации мы хотим чего-то поменять мы создаем новую сагу старый сага само собой отомрет то есть и соответственно version ность то есть и снова версии какого-то api сервис то есть вы получается заново создаете новые классы начинаете генерировать новые шаги при этом иногда нужно переписывать бизнес-сервис правильно ну тут уже без вариантов то есть случае если смотреть хотя какой version на steam и говоря я имею ввиду version ность механизмы version as терапии то есть если бизнес сервис в этой идеологии он требует поддержку ретро и поддержку от кота если вы что-то поменяете там добавить и там вот есть обязательность флаг у каждого шага добавить еще какой-то флаг обязательная обратно считая сказал что может быть гибкость и какие-то необязательные шаги можно вписывать можно реализовать чисто теоретически в данном случае мы не реализовывали то есть тут все шаги обязательно то есть это делалось задачей конкретно по конкретной задачи распила быстрого распила текущего монолита внесения логики и до ответ на ваши вопросы то есть зависимости от того что затронуть изменения могут они за трон в том числе надо будет переписывать бизнес-логику может быть не надо будет то есть грубо говоря если у вас поменялось сценарий на биллинг сервисе то вероятнее всего надо поменять просто новый api выкатить то есть там что-то поменяется и он так и продолжит выполняться если это в целом чего-то еще аффекте то есть например транзакции отката же она может быть не локально внутри сервис этой за ней что-то стоит то есть может быть придется переписывать еще какие-то узлы то есть для только потому что мы поменяли один шаг если мы говорим о том что если мы меняем сервисах там тоже если грубо говоря изменения будут обратно не совместим и естественно все будет нужно будет менять то есть серебряной пули нет то есть все зависит от того насколько велик характер изменений которые вы собираетесь внести были у вас таких случая что было такое уже пока нет спасибо что ж на этом давайте вопрос в зале закончим если у кого-то они еще остались константина ответит на них позднее на дискуссионной площадки сейчас мы благодарим константина за интересный доклад"
}