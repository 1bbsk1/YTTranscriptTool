{
  "video_id": "nzrgneDVcTQ",
  "channel": "HighLoadChannel",
  "title": "Эффективная работа с PostgreSQL в нагруженном PHP-проекте / Ильяс Салихов (RetailCRM)",
  "views": 219,
  "duration": 2462,
  "published": "2023-10-06T07:20:45-07:00",
  "text": "супер пару слов обо мне его проекте я сидел в проекте retel CRM На зарубежке мы известны под брендом simple.com мы Облачный B2B проект автоматизируем компании которые продают товары онлайн или оффлайн сейчас у нас более 3000 клиентов Это бизнес и разного размера проект работает на 250 физических серверах на данный момент из них более 50 это сервера дневная нагрузка к ним не менее 100 тысяч транзакций в секунду О чем я буду говорить вначале поговорю о об особенностях подключения далее про управление схемой данных после этого Про некоторые кейсы миграций и в конце про управление индексами буквально пару терминов чтобы правильно друг друга понимать моделью данных я буду называть описание структуры баз данных на уровне приложения в а конкретном уровне доктрины и схемы данных уже физическую структуру в виде таблицы полей Ну что ж начнем первая часть такая базовая Ну не менее важная начну с Connection Puller в типовом PHP приложение в его простом виде как правило есть только две части phpm и passql PHP приходит http запросы он свою очередь создает соединение выполняет запросы отдает ответ на уровне кодов простейшем виде на примере добала это выглядит так и в рамках него выполняется сказать запрос проблема этой схемы в том что создание Connection дорогая операция так как на каждый Connection создается новый процесс поэтому существует класс таких утилит как Connection Puller или мультиплексоры коннекторов самый распространенный из них это погабаунтер мы у себя используем его и суть его в том что он с одной стороны создает постоянное соединение с плоскореем а с другой стороны эффективно многопоточном режиме принимают соединение приложения на уровне кода в чем плюс что вам достаточно поменять холст и порт на холстый порт балансера в остальном код менять не требуется и ваше приложение уже работает через него а чтобы продемонстрировать в чем важность и преимущество использования балансеров я наказал простой пример в примере цикле мы создаем соединение выполняем запрос закрываем соединение Вот и этот пример я попробовал прогнать при работе напрямую спасскрелем и через packbounder Лично у меня на тестовой машине получились следующие цифры если мы делаем запросы через то запрос среднего уклоняться за две с половиной секунды Если через погаузеры то за пол миллисекунды то есть пять раз быстрее если также выполнить запрос в консоли с включенными таймерами то у меня показывал 0,4 секунды то есть о чем это говорит о том что в случае мы убираем практически все Касты На создание соединений в случае особенно легких запросов это дает очень заметный Где лучше всего размещать по дополнитель один вариант Когда вы ставите по любому на каждый Application сервер рядом с приложением другой вариант Когда вы его ставите рядом с подгарской Элем на каждый серверов баз данных Ну еще третий вариант комбинированный Когда у вас есть сервере и на сервере базы данных Ну я его не буду рассматривать в первом варианте получается точка коннекта ближе к приложению и в теории Вы можете даже делать индивидуальные настройки балансера Под каждый экземпляр приложения но если честно я не встречал возникновение Такой необходимости вот и это как правило приводит только к сложности конфигурирования обычно требуется тепловая конфигурация и также минусом в этой схеме является то что на уровне фбд вам сложнее контролировать Сколько в совокупности коннектов от этих нескольких программкеров вам придет база данных Лично у тебя Мы всегда используем второй вариант то есть ставим рядом с каждой из базы данных существует аналоги есть аналог от Яндекса Одиссей как я понимаю они используют его внутри себя в том числе Яндекс облаке и есть еще аргентинский проект Если честно у нас не было практического применения этих проектов поэтому не могу сказать ничего плохого не хорошего по поводу них так Ну если резюмировать получается по-любалансиру выполнять свою прямую задачу при использую пере использовать Connect и постгрылю это позволяет ускорять исковые запросы это экономит ресурса базы данных и как бонус он является таким барьером который защищают базы данных при возрастании нагрузки допустим когда к вашим приложению приходит много запросов будет их или отметать или ставить в очередь ну так или иначе он не даст перегрузить вашу баз данных большим количеством коннектов также очень важно при создании коннекта сквелем настраивать тайм-аут Давайте посмотрим следующий пример у нас есть наше приложение поэтому я опускаем приложение есть стандартная настройка по максимальным времени выполнению скрипта 60 секунд представим что к нам прилетают http-запрос внутри приложения чтобы обработать этот запрос нам нужно сделать SQL запрос Вот и так выходит что этот искать запрос выполняется долго и не успевает выполнить за 60 секунд в итоге Engine 504 убивается со стороны но в самом деле сказать запрос продолжает выполняться и если так случается что пользователи массовые идут в этот inpoint то у вас в подписи Копится всё больше и больше таких Долгих запросов и не могут банально перегрузить Ваш возраст чтобы такое происходило достаточно настроить чуть больше времени выполнения страницы а если рассматривать пример с дебалом то в нем есть возможность прокинуть дополнительные опции вы например можете задать переменную прокинуть её в опцию и дальше чуть переопределив драйвер на основе этой опции задать настройку возгласа в рамках текущего соединения приложение как правило помимо обработки и запросов нужно выполнять всякие фоновые задачи команды и там операции бывает более сложные запросы более тяжелые Вот и тайм-аут нужны соответственно больше ну как раз переменную вам позволит задать там свои индивидуальные настройки что здесь важно важно эту настройку Не устанавливать на уровне самого pazgrosql это написано и в самой документации возгласа потому что это за эффекте это абсолютно все сессии а фосгорса много и служебных операций допустим это может быть операция создания бэкапа или репликация это все начнет эффектиться поэтому только на уровне коннектов Также важно выставлять тайм-аут и налоги и их тоже стоит выставлять на уровне Connection of или на уровне вообще отдельных транзакций если это требуется кстати вот в предыдущем примере SQL запрос смог долго выполняться не только потому что он тяжелый а потому что он напоролся на Лог взятой другими запросам и ждет когда этот Лог снимется вот чтобы таких ситуациях не возникало важны вот эти таймаута дальше поговорим про управление схемой данных а Казалось бы в чем здесь особенности если опять же рассматривать доктрину то цикл у нас как правило следующий мы вносим какие-то изменения в модель или создаем новые модельки дальше доктрины же генерируем миграцию на основе этих изменений и у себя и в продакшене применяем эти миграции Казалось бы все но есть нюансы в целом ряде случаев требуется миграция нарабатывать самый популярный пример когда допустим нужно переносить данные Ну либо нужно носить изменения в схему в каком-то другом порядке не в том котором генерировала доктрина Если вы носите изменения Вы можете носить и ошибки вот если вносит ошибки то у вас Может это все привести к тому что модель написано приложение расходится с физической схемой базе данных как мы проверяем эту у себя в доктрине есть замечательная команда так три схема апдейт она сама берет вашу модельку анализирует также схему данных и если они расходятся она генерирует на боль SQL команд для того чтобы их синхронизировать вот мы возьмем просто за основу сделаем мои файле небольшой хелпер который будет возвращать статус 0 если ничего синхронизировать не требуется или статус один если есть изменения и дальше лично себя мы делаем прогоняем следующий сценарий мы создаем чистую базу на котором мне все миграции вот после этого проверяем наши утилиты что расхождение нет После этого мы проигрываем все миграции в обратную сторону до нуля и с еще раз прогоняем до конца и снова проверяем Таким образом мы проверяем Down секции наших миграций обычно на практике что по крайней мере я вижу когда он секциям намного меньше внимания и там как правило намного больше ошибок оно и понятно их обычно редко приходится применять но бывают случаи когда начинаешь применять и они не работают Вот этот механизм он помогает их с некой долей уверенности проверить Ну и в конце еще можно проверить встроенный механизмом доктрины провалидировать схему Лично у тебя у нас данный алгоритм прогоняется все в каждом мэрии и дает больше уверенности что расхождение нет про миграции бывает случаи когда миграции накатываются не просто особенно таблицы большие Я хотел бы рассмотреть пару кейсов первый кейс на заполнение колонки представим что у нас есть таблица товаров дней 4 поля один название цена и валюта в которой заданы наша цена нашей таблице продакшене уже порядка 100 миллионов товаров так исторически сложилось что для валюты были разрешены Ну а на уровне кода была логика что если там ну то значит цена задана в долларах Мы хотим это исправить хотим чтобы и цены в долларах тоже указывались явно в поле валюты вносим модель изменения миграцию подобную миграцию в целом Я думаю все понятно Если попробовать в лоб накатить на продакшене то мы конечно же получим ошибку потому что у нас там есть данные с новыми полях самое очевидно добавить апдейт чтобы перед тем как изменить схему данных заполнить нулы значение доллара но вспомним наши вводные у нас много записей также вспомним что доктрина каждую миграцию выполняет внутри транзакции То есть у нас внутри транзакции выполняется огромный апдейт после этого еще изменения схемы это гарантированно приведет к тому чтобы иммиграция возьмет Лог как минимум на записи как максимум на всю таблицу Ну это в свою очередь за affected запрос от пользователей нам хотелось бы чтобы этого не происходило как делаем обычно мы у себя на практике во-первых мы делим операции которые меняют данные операции которые меняют схему на разные миграции вот разделим их собственно где миграции Далее в первой миграции отключим транзакционность потому что нам не требуется чтобы нас атомарно обновились все записи в таблице и в-третьих мы первую транзакцию переработаем чтобы данный у нас обновлялись порциями в три шага на Первом шаге мы определяем максимальный ID записи где у нас ну валюте на втором шаге мы начинаем порциями заполнять поле валюты и идем по диапазонам айтишников и на последнем шаге мы до заполняем те записи которые у нас появились например пока происходили две предыдущие операции что здесь важно как я говорил мы идем именно по интервалам айдишников это нам гарантирует то что выборка записей будет гарантированно по индексу по сути по первичному ключу и это будет всегда происходить быстро независимо от размера диапазона его дальности по первости разработчики бывают используют обходы итерациями через лимитов сет вот случай постгальца Чем дальше Вы заходите в глубь в этом те медленнее будет выполняться запросы потому что фактически пост будет поднимать с диска все записи которые идут и до вашего офсета как результат мы не мешаем нашим пользователям пока мы внедряем миграцию и можно внедрять миграции По отдельности поэтапно Возможно у вас возник вопрос как вести себя приложению в то время когда у нас накатывается миграция этот вопрос Я хотел бы рассмотреть на следующем кейсе Чуть более сложным следующим У нас есть все та же таблица товаров и от бизнеса к нам приходят требования что надо дать возможность пользователям теперь указывать несколько цен для товаров вот самое очевидно здесь создать новую таблицу связь один ко многим Ну помимо изменения схемы нужно еще и перенести существующие данные с точки зрения логики в целом как бы мы разбили на этапы Мы создали сначала новую таблицу после этого перенесли данные и в конце удалили старые Поля если посмотреть Если внести эти изменения в модель и сгенерить миграцию доктриной то она будет примерно следующий состоять из тех же трех этапов создается новая таблица дальше вставляются переносится данные из первой таблицы и удаляются старые поля Но если посмотреть на водный в таблице много записей на таблицу постоянно нагрузка от runtime идет нам важно чтобы миграция не брала большие Локи и чтобы это не ответило наших пользователей которые работают в это время с приложением Если же накатить ту миграцию в лоб то Мы соберем все эти грабли гарантированно здесь опять же напрашивается то решение которое было в первом кейсе делим иммиграции и накатываем переносим данные порции Да здесь верно стоит так делать но когда мы переносим данные порциями то это требует довольно много времени особенно на таком матче таблицы а если параллельно еще есть нагрузка то Ну это легко может занимать и целый час прогон таких миграций и надо понять что же делать приложениям когда часть данных еще старой структуре а часть данных уже много Мы у себя выработали следующий сценарий внедрения подобных изменений на Первом шаге мы создаем миграции новую таблицу при этом внутри нашей логики мы пишем и читаем из старых полей но важный момент что в сеторах старых полей мы дублируем данные уже в Новую таблицу для пользователя при этом работа приложения она еще старая То есть он работает с одной ценой товара после внедрения проверяем что в новой таблице появляются записи Вот и после этого шага мы уже знаем что все изменения и новые товары они уже попадают во вторую таблицу можно двигаться дальше на втором этапе нам нужно перенести эти данные которые пользователями не затрагивались Вот и мы собственно этом шаги миграцию где порциями небольшими чтобы не лочь наших пользователей переносим старые данные новую таблицу для пользователей Все работает по-прежнему еще по-старому проверяем что в новой таблице есть все соответствующие старой записи если все окей двигаемся к следующим шагом на третьем шаге у нас миграции нет мы просто переключаемся на работу уже с новой таблицей пишем в Новые поля но важный момент что при этом внутри сеторов мы дублируем данные в старую таблицу и для пользователя мы все еще показываем старый интерфейс работы с одной ценой Почему важно дублировать данные в старую таблицу это важно на случай Если вы где-нибудь накосячили вот вплоть до третьего шага Вы знаете что старой таблице у вас все данные они актуальны и вы можете на любой шаг вплоть до нулевого откатиться назад Если же Все окей Все работает как надо то можно двигаться почти финальному шагу где Мы открываем фичу работать с множественными ценами Вот и старую таблицу уже данные не дублируем остается последний пятый шаг чтобы удалить старые неиспользуемые поля и такого самого внедрения довольно таки такое сложное получается многоэтапно и длительное по времени но при этом мы не эффектим пользователей и на большинстве шагов мы можем откатиться на любой шаг назад если что-то пошло не так а это бывает очень важно Окей и теперь а именно управление индексами рассмотрим такой пример в Retail CRM как и в любой CRM есть профиль клиента где собрана информация о нем а также все события которые происходили с этим клиентом Какие заказы он делал какие письма написал или мы ему писали там переписки в чатах и так далее вот если проваливаться на уровень баз данных то у нас есть отдельный таблица Под каждый тип данных там письма SMS заказы звонки и есть таблица единственная задача которая это выстроить все эти данные события в хронологическом порядке по своей сути таблица данных не содержит Вот но содержит много полей связи с другими таблицами если описывает такую модельку доктриной и генерировать миграцию то доктрина автоматически создает индексы Под каждый из полей связи Вот ну и в целом это оправдано они полезны Ну если посмотреть в одну из наших реальных таблиц на 3,5 миллиона записей например то видно что данные занимает 300 Мегабайт а индексы в таком случае будут занимать 1,4 Гб как-то не очень прикольно Если же посмотреть на сами данные то видно что большинство полей Оно пустое Вот и в данном случае очень полезно оказывается Такой тип индексов позже как parshall индексы или частичные индексы особенность их в том что они индексируют только те записи которые подпадают под указанное вами условия и в данном случае мы добавляем условие чтобы не индексировать нулевые записи попробуем поменять доктриновский индексы на наши Паршивые индексы вот и это покажет следующий результат наш индексы вместо 1 4 гигабайтов станут занимать 400 мегабайт все еще больше чем сами данные но в три раза меньше Мне кажется неплохая экономия в данном примере я поменял эти индексы руками Ну хотелось как-то бы неправильно постоянно эти миграции которые генерит доктрина сделать так чтобы она генерировала их сразу оптимальными и дает такой способ у нее есть вы можете на него подписаться внутри него получить в том числе индексы которые она собирается сгенерировать и доработать их нужном образом мы у себя как раз поступаем так и у нас все поля связи они по умолчанию помимо полей связей прошлой индексы могут быть полезны и для обычных полей конкретно у нас самый распространенный кейс когда на таблице на модельке висит доктрин extension расширение доктрины саудовлеты был вот и это расширение добавляет поле делиться Ted а также добавляют во все запросы условия чтобы отсекать удаленные записи и в таком случае полезно также во все ваши индексы добавлять это условия во-первых не будут индексироваться ненужные поля во-вторых сам индекс будет меньше В третьих план запроса будет банально лучше Ну если хочется большего есть много других индексов приведу только некоторые примеры например Есть индексное выражение Возможно вы знаете мы у себя очень часто используем вот самые распространенный кейс когда вам нужно сделать фильтр по названию дать пользователю такой фильтр и как правило пользователи ждать что фильтр регистры независимой в таком случае вам нужно искать Без учета регистра допустим с применением к нижнему регистру И когда вы делаете такой поиск индекс будет работать и поиск будет быстрый еще чаще такой вид поиска такой вид фильтров требуется на вхождение то есть пользователь вводит часть названия и ожидает увидеть все товары которые содержат такую часть названия и для таких кейсов тоже есть индексы например есть триграммный Джин индекс в данном случае на выражение и он работает даже если вы делаете лайк с процентами с двух сторон И как видно план запроса чисто по индексу Ну это очень клёво но не клёво то что на уровне доктрины нет выразительных средств чтобы описать такие индексы а на уровне миграции вручную добавлять такие индексы не вариант потому что потом вы запутаетесь и не будете понимать в целом картины какие у вас индекс сейчас есть в таблицах будут появляться дубли индексов которые плохие не только из лишнего занимаемого места но из-за того что вас они могут ломать план других запросов Ну короче хотелось бы такие индексы тоже описывать в модели мы для себя сделали бандул который нам позволяет это делать он по данному названию на гитхабе и покажете Вы можете его использовать также у него две основные функции первое Он позволяет через аннотации описать более специфичные индексы и второе в нем есть команд который автоматически отслеживает какие изменения в аннотации вы внесли и какие индексы в результате убрали он удаляются из базы а какие добавили он соответственно также добавляет базу данных как итог Мы у себя лично все эти практики используем и за счет этого эффективно подключаемся к возгласу контролируем время выполнения запросов время налоги управляем структурой базы данных полностью через модель доктрине следим за синхронностью этой модели со схемой внедрям тяжелой печи так чтобы это не влияло на работу пользователей и строим оптимальный индексы под наши запросы на этом У меня все Спасибо буду рад вашим вопросам Ильяс Смотри ты в курсе уже Да что надо будет выбрать автора самого интересного вопроса поэтому ты старайся запоминать те вопросы которые тебе задают это самое сложное желающие получить призы самые интересный вопрос поднимайте руки и мы вот там уже есть вопрос Спасибо за доклад у меня несколько вопросов первый вопрос здесь было написано проблема связана с тем что когда engines завершает приложение по Макс экшен тайм то база данных продолжает выполнять тяжелые запрос Ну стандартной схеме это не так ведь при обрыве соединения когда приложение завершается обрывает соединение с базой данных и базе данных обрывается все процессы которые связаны с этим подключением То есть это проблема возможно только лишь том случае если вы используете стратегию разделяемых подключений То есть это стратегия и создает эту проблему вторая проблема это то что в Стратегии разделяемых подключений есть другая проблема ведь соединением связано и состояние этого соединения допустим приложение начало транзакцию и отвалилось другое предложение которое будет другой процесс который будет использовать подключение уже войдет в работу соединения значит приложение это еще одна проблема также Здесь был показан очень яркий антипатерм Как делать нельзя Это таблица Event событий Event в ней были указаны несколько ID на дочерние объекты там чата ID там еще что-то много айдишников это создает проблему логическую Когда в этой таблице может быть несколько идей заполнена то есть риски Такое возможно другая проблема Это в том что экстренного кейс обычно ссылается с дочерних объектов на родительских а не наоборот в этом случае Как делается правильно делается таблица Event и в ней ставится Type и ID так вот завести с нужной таблицы не потребуется делать индекс потом на полтора гига который гораздо больше данных То есть это Явный который применять лучше не надо так не советует хорошо А в чем вопрос У меня еще много разных вопросов было по докладу Ну я ограничусь пока этими да Давайте попробуем прокомментировать Насколько помню разделяемые соединение Мы у себя не используем Скорее всего в нашем случае это как раз следствие использования Вот Но в нем Мы также используем стандартные настройки же как бы совсем плохо Ну а его использование приводит к таким последствиям Ну так или иначе Мне кажется с таймаута в любом случае важно выставлять какими-то лимитами Окей по поводу связи и антипатарно для таблицы Event сейчас пытаюсь представить как это описывается на уровне модели данных если это тип идишник такой динамический я чуть не уверен что это на уровне доктрина можно написать Вот а мы очень не любим влазить и придумывать велосипеды с точки зрения RM вот стараемся использовать стандартные библиотеки Да в том числе Там наверное конструиты тоже проблемы поставить Ну короче свои минусы этого решения нам Спасибо лучше с микрофоном Наверное потому что могут смотреть трансляцию и не услышат Спасибо А скажите Почему рекомендуется Лог тайм-аут меньше чем статумом тайм-аут Ведь статы мы как раз и берет Лог на время своего выполнения если сделать Лог тайм-аут меньше то это создаст какой-то непонятная ситуация не всегда у вас жилок и берутся не на все время выполняя запросов насколько я помню то есть база данных более Умно с этим работают условно если вам нужно там обновить N записи она же не возьмет на все время выполнения запроса блоки сейчас нам подумать делать Локи в одну минуту точно плохая идея нет покопать поглубже но практика показывает что Локи они не долгие вот приводит плохим если берутся на очень долгое время Спасибо за доклад такой вопрос а вот как насчет не оптимальных запросов доктрины может ну и доктрину и его проблемы которые генерирует один классический один плюс запроса Когда у нас по лениво подгружается сущности вот Или например при включении стандартной системы не удаляется сортировки и всё всё вот это вот всё то есть может э стоит Иногда без доктрины говорит Билдер и просто собирать запросы самостоятельно проблема им + 1 я думаю это же следствие того как разработчик напишет сам по себе запрос N + 1 он же вполне оптимален То есть вы делаете исходный запрос остальные запросы а потом по уровню обращения к подгруженной сущности даже м штук они довольно-таки оптимальные если даже посмотреть Кстати кто особенно когда есть бронзер на самом деле Познер очень быстро прожёвывает вот Ну конечно у вас получается намного более тяжелый запрос Когда вы пытаетесь выбрать основную таблицу и сразу к ней за джоинить связаны Вот Но тут как правило например мы делаем что мы выбираем Из основной таблицы и потом через vr-ин сразу пачку записей и связаны подгружаем вот Анджелины часто усугубляют ситуацию Ну короче я не хочу сказать что проблема нет плюс один Да ну сам вижу что хотелось бы больше контроля затем где они у нас вот такие вещи протекают я могу здесь немножечко подсказать на одну таблицу можно смотреть разные эти и в одной может быть коллекция другой нет Все зависит от того Где вы используете как модель или как Raid модель Может на эту сторону посмотреть Ну достаточно может быть интересно А вопрос такой какой вид пуринга вы используете фгбаум себе от этого сильно многие вещи зависит мы используем стандартные Блин я не помню как он называется Да да мы здесь не Не экспериментируем ну просто для конкретно там например PHP приложение вообще приложение рекомендация там от тех же дата игрет использовать транзакшн-пулинг на самом деле и он накладывает уже некоторые интересные ограничения Спасибо так все вопрос закончились в нашем случае я могу сказать что мы не используем транзакцию потому что а у нас меньше профита от него у нас основной сервис который довольно таки крупный он мультитансный и он у нас под каждый аккаунт заводится отдельно база если быть точнее отдельная схема которая распределены по разным базам ну короче так или иначе а пгм аутсор он держит коннекты постоянно для каждой базы своей Вот и между базами их не использовать в микрофон пожалуйста Да закшен есть преимущество что если вы составит собираете много транзакций у вас на самом деле большой входящий поток то они успевают вдруг между другом проскочить даже в течение одной сессии у вас сессии друг друга отпускают много сессий успевают проскочить с этим транзакциями друг другу Да уступают место очередь и поэтому именно для приложения Ну как бы есть одна из таких рекомендаций так все супер Я тебе надо выбрать автор самой интересного вопроса пожалуй выберу первого это кого а вот пожалуйста включите ему у него был прям мир большой конспект замечаний Так мы тебе от организаторов вручим тоже небольшой подарок спасибо тебе за твой контент Спасибо уже не первый выступаешь Да я уже слышал Даже твой доклад раньше Спасибо тебе огромное подавайте еще будем рады У нас заканчивается первый день конференции в рамках конференции хайлоут с вами сегодня здесь был Антон Морев Я был в вашем ведущим Спасибо большое и до встречи завтра в этом же зале только буду уже ведущим я всем спасибо"
}