{
  "video_id": "J8ZvWzzoVVo",
  "channel": "HighLoadChannel",
  "title": "Создание BigData-платформы для ФГУП Почта России / Андрей Бащенко (Luxoft)",
  "views": 2640,
  "duration": 3222,
  "published": "2018-08-16T04:06:15-07:00",
  "text": "меня зовут андрей башенка я сейчас руковожу бегает и направлением почта россии и сегодня я вам расскажу про наш кейс построение big data платформы для всех задач big data всех задач связанных с machine learning зато сайнс в почте россии параллельно прямо сейчас мой коллега алексей вовченко наш архитектор делает доклад по инфраструктурным и архитектурной составляющей я рекомендую всем кому будет интересно позже ознакомиться с материалом его доклада он называется big почта и там подробно рассказывается о том как мы выбирали компоненты технологического стыка как мы их сравнивали как мы собственно принимали решения по построению наша архитектура вот ну а мой доклад сфокусирован на управление big data платформой на управление разработкой и я расскажу подробно как мы решали возникающие трудности у нас процесс получился 3 по мощности в россии кластер физический после яндекса и mail.ru в принципе никаких тут официальных рейтингов там не проводилось и не публиковалось но мы общаемся с коллегами мы знаем у кого собственно что есть вот я собственно для того чтобы этот доклад имел для вас больший смысл я сначала пройдусь по тем задачам которые возникают ольги проходите вот налево здесь много свободных мест я сначала расскажу про задачи из них будут вытекать требования к решению ну и собственно дальше мы уже пройдем хронологическом порядке по тому как как мы организовывали разработку ну вот смотрите что приходит в голову когда мы говорим типичная простая такая bigdata история вот самая простая самая простая история это когда мы в принципе собираемся данные они избыточных можно терять и даже если что-то ну кластер недоступен у пострадают дата-сайентистов компании нормально работает вот и в принципе достаточно большой обработки мы строим пост аналитику на ней как бы такая вот нормально простая история так вот сейчас извините так вот ни один из этих пунктов для нас не является правдой нам нельзя терять данные нам нужна высокая доступность а почему давайте пойдем дальше для ответ на вопрос почему я расскажу что же такое вообще почта россии ну все новерна знают но почта россии это крупнейшее в стране ритейл сеть а и крупнейший в стране логистическая инфраструктура при этом и такой особенный retail в котором каждый а этом уникален и должен уникально отслеживаться потому что вот эту там грубо говоря пакет чипсов если в обычном ритейле можно просто вот человеку нужен пакет чипсов lays с таким-то вкусом вот как бы любой бери отдавай все задача выполнена то здесь каждый right i'm ждет конкретный там петя там это той там едет от конкретного там не знают дедушки или там из китая это накладывает свои ограничения ну и собственно а также почта россии это важная социальная функция потому что если бы мы были коммерческой структуры мы могли бы просто закрыть половину убыточных отделений сразу же как бы запустить выручку снизить затраты и в принципе а жить припеваючи но во многих отдаленных местах нашей страны отделение почты это единственная связь с внешним миром и это надо учитывать то есть мы должны сохранять доступность услуги еще важный момент для понимания big data ландшафта на почты данные разделить по географии мне возможно то есть данные которые где-нибудь поступают из не знаю сортировки сортировочного центра где-то в середине страны они влияют на картину по тем отправлениям которые едут с камчатки или из китая там данные которые например денег на чукотке их тоже нельзя не учитывать потому что они повлияют на что-то что будет вручена потом в калининграде ну сказав это давайте перейдем к примерам задачи есть такая типичная задача для логистики разворачивание вложений иногда говорится разворачивание матрешки на о чем речь вот ваше конкретное письмо бандероль пакет он вложен в какой-то ящик в какой-то мешок это в свою очередь вложены в контейнер этот контейнер едет по логистической сети где-то он проходит через сканер штрих-кодов и мы видим что да вот контейнер с таким штрих-кодом проехал здесь поехал туда с ним сделали то-то но при этом мы не видим а что происходит собственно с теми конкретными управлением которые там лежат они могут лежать на довольно глубоко и в итоге если вы тут 2015 года когда мы запустили свою платформу вот эту задачу мы взяли первую если выйдут 2015 года пользовались рейтингом на на сайте почту рута вы могли видеть вот какую такую картину вот как справа с дырами в общем-то между ну вернее как меня серыми зонами между операциями по вашему отправлению там но в несколько дней не понять что там происходило вообще где а ну то есть вот оно принято в отделении связи там это письмо было физически вот она проходила через сканер дальше она покидала место приема тоже она там была физически проходил через сканер дальше она погрузилась какие-то там емкости и нигде не всплывала потом на сортировке его достали пири-пири сортировали впихнули в другую емкость и дальше опять все razon ничего не видно но эту задачу решили и собственно этот поток данных ну во-первых мы его показываем здесь то есть 2015 года вы видите гораздо более полный список операций потому что вы видите транзиты вы видите собственно их благодаря тому что мы разворачиваемся вложения ну это помогает достигнуть хэппи-энда когда вы получаете свою долгожданную пакет iphone бандероль еще что там собственно для этого мы multiply церу им эти операции то есть мы их повторяем для всех вложений для всех вложений более низкого уровня в среднем у нас получается где-то 400 миллионов логистических операций в сутки достаточно тяжелой операции ну по сути каждой операции тайники джейсон с параметрами так вот это дело довольно тяжелая этот поток данных модель мне только трекингу мы отдаем его сортировочном машинам то есть все вся сортировка завязано на наши данные она без наших данных конечно не встанет но насильно за длится мы отдаем эти данные фронт системам например и другим производством систему почты пойдемте дальше контроль сроков доставки что это такое вот когда вы собственно когда вы выбираете каким тарифам отправить не знаю там письмо или бандероли еще что-то каждому тарифу привязаны конкретные контрольные сроки и в принципе вся логистика разбита на плечи все маршруты разбита на плечи плечо это вот минимальный отрезок логистического пути для каждого плеча есть эти контрольные сроки для каждого вида отправления для каждого тарифам мы же отслеживаем фактически и сроки сравнимых с контрольными мы видим где пошло отставания и мы высчитываем процент выполнения контрольных сроков из этого складывается теперь каждый раз когда ваше какое-то отправление где-то не ложилась контрольные сроки какие-то конкретные сотрудники которые отвечают за это направление соответственно не до получают свою премию можете представить как тщательно они выбирают наши данные вот ну и собственно а еще в этой задаче интересно что иногда возникают в steam массовые замедления то есть где то проблема на маршруте там не знаю в сибири где-то снегопад у в общем то там где железнодорожный например ветка там просто пути засыпал например и мы видим это в онлайне мы видим что там пошли замедление массовые прямо вот массовые мы сразу же эту информацию должны обработать для того чтобы например включить другой маршрутом не знаю подключить либо пойти по другому маршруту пойти по другому виду транспорта это уже задача следующая это ситуацию на реагированием дело в том что история когда мы посчитали данные актуальны на вчера мы сделали отчет и собственно смотрим на него видим проблему пытаемся их исправлять она но это вчерашний день для некоторых проблем это не работают вообще поезд ушел как бы уже давно поздно все сгорело можно не тушить а вот для тех проблем для которых собственно нужно реагировать прямо в режиме real time существует наше решение которое суд по сути это по которой автоматизм отработаю ситуационного центра такой ситуационный центр сидят люди в большой комнате смотрят на экраны на мониторы по данным всплывают какие-то ticket и для них которые они разрешают один из примеров типичных это зацикливание на посылке штрих-код поврежден как-то сбит и она начинает ездить между двумя просто сорт узлами она так будет ездить в принципе достаточно долго раньше это решалось просто вручную она нам а заливала глаза какой-нибудь бабушке договорилась счет а вот это вот едет тут уже 100 раз она просто снимала но я так и думала вот а сейчас это решается лучше потому что например для этого кейса а где сорт линия автоматизирован и вообще шлём то есть заразиться ticket да но он автоматически разрешается то есть мы шьем автоматическую команду на сорт машину сбросить эту емкость или отправления в специальную кстати отбраковку где ее просто уже обработают то есть переклеить на нее штрих-код и она счастлива пойдет дальше так следующий класс задач это процесс майнинг о чём тут речь ну вот это решается с помощью всевозможных методов кластеризации с помощью алгоритмов машин learn инга но суть простая да то есть у нас есть массив данных по всем бизнес-процессам и мы можем отслеживать какие то систематические ошибки либо злоупотребления ну просто за счет того что вот есть выборка там типовых не знаю прохождение там этих процессов и есть выборка про которому точно знаем что а вот это плохие а вот это вот вектор плохих и мы учим модель определять плохие по неким паттерном который даже мы не можем формализовать наверно я пересказываю суть машин лёрн инга одни из примеров это вот серая почта это открытые данные тут ничего страшно что я привожу эти цифры что потери от серой почты вот 5 8 миллиардов были в 2015 году например что такое syrup о что это некий недобросовестный там человек где-то на маршруте получает денежку от какой-то коммерческая структура которая отправляет массовый какие-то вот объём корреспонденции как правило это не регистре мы корреспонденцию то есть это всякие письма раз ссылки там не знаю может быть реклама и так бы она заплатила почты например там не знаю там сто тысяч за этот мешок а так она ему отдает там не знаю 30000 например он это сбрасывает просто-напросто в машину и дальше она едет по сети почты их и его сложно вот в сети сложно отличить от легитимны какой-то корреспонденту за который хочет получила деньги вот собственно вот такие кейсы мы решаем сейчас мы подбираемся это в процессе кстати вот предыдущей задаче они вроде уже в продакшене вот эта задача up call in progress потому что мы решаем мы все еще учимся с помощью бизнеса с помощью безопасников выявлять эти вещи с помощью изменений по массе и с помощью определенных паттернов поведения вот отправлений на маршруте она еще задачи собственно управление по китаем не только логистика и сейчас это тоже в продукте we то есть мы полностью всей почтой управляем по китаем и выстраивать китая на наших данных это не только логистика это на понятный вам на рынке пиаре то есть это контрольные сроки доставки доставка в срок это сохранность вложений тоже важная вещь сохранность отправление извините то есть грубо говоря когда кто-то недополучил свою посылку которая от куда то ехала соответствующие люди которые за это отвечают недополучили свои деньги и это справедливо следующий тебя и там тоже понятные это среднее время очереди в очереди в отделении средняя длина очереди жалобы и претензии ну и собственно более коммерческий такие как средний чек средние временно обслуживание одного человека такса в одном окне и так далее вот это все работает ну и другие примеры задач прогноз нагрузки и составление графика сотрудников автоматизированные опять таки на основе алгоритмов машин learning а здесь мы первую часть сделали то есть прогноз нагрузки у нас уже есть мы этот прогноз составляется по сути из двух частей с одной стороны у нас системе ворочаются данные мы точно закон можем понять какие отправления уже едут вот в эту точку и прибудут в это отделение например там в интересующий день плюс мы можем наложить на это еще некий прогноз на основе статистических данных о том что еще в сеть не поступило она еще у нас не зарегистрировано данных о нём нет но мы же знаем тренд мы знаем данные прошлых периодов мы накладываем сезонное какие-то колебания и вуаля мы знаем нагрузку мы знаем так называемых клиента поток вот а из него уже элементарно составить расписание смен и прямо спустить его начальнику отделения вот чтобы он это вручную не дел следующий шаг будет разослать вообще людям на почту на телефон эсэмэски что ваше смену тогда-то вы ходите вот таким образом мы снимаем нагрузку с людей с тех кто на местах управляет почтой ogio маркетинг понятно класс задач есть массив данных по социально-экономическому составу населения привязаны к гиа координатам и у нас есть розничная сеть и наша задача ту розничную сеть оптимизировать сохраняя доступность услуги то есть мы говорим вот это отделение надо подвинуть вот сюда вот это увеличить добавить еще два окна а вот это можно вообще убрать но вот здесь тогда надо сделать при этом мы оптимизируем такие параметры как выручка затраты но при этом я говорю мы должны не ухудшить доступность услуги ну и понятное дело аналитика понятное дело вся компания получает аналитику в виде потока в данных виде витрин данных видя кубов виде даже бордов интерактивных статичных отчетов все это тоже наша ну и естественно все эти данные нами предоставляются в систему потребители это была короткая view задачу а теперь собственно те важнейшее требование которые из этого вытекают ну вот это наше текущее сальдо то есть мы обеспечиваем 5 9 сохранности данных для нас любая потеря данных это реально дефект это реально прям проблему потому что ну потеря данных это означает что какие то люди там нет получили свою премию сотрудники почты вы можете представить насколько тщательно они проводят ее от тестирования наших собственных инструментов до наших витрин наших отчётов там система китаев и потому что это их деньги в конце концов доступность пока три девятки это тоже важный параметр потому что вот тут если у нас недоступен кластер это прям беда это прям реально беда это не то что там дата-сайентистов счет не могут там модельки обучать но обучит завтра это означает что поток данных останавливаться например в сортировке сортировки замедляются то есть да они продолжают жить но они сортируют не оптимально без вот этих данных дополнительных которые являются ну по сути кровь и бизнеса например останавливаться поток данных в отделения в отделение должны вам печатать такие формочки которые вкладываются в почтовый ящик о том что ваша там мелкий пакет из китая вот он лежит в отделении ждет вас вот данные для этих вещей а шлем мы соответственно если мы вдруг их не шлем это беда это значит что сотрудники выхода сверхурочно там по выходным по ночам вбивают эти данные руками это означает что в рабочее время там очередь в отделениях и в общем-то нас конкретно это аффект это не скажем так вот ну и понятное дело что нам не обойтись одной batch обработкой у нас салям до архитектура то есть мы основной массив данных мы рассчитаем каждую ночь при этом нам приходится пересчитывать весь массив как я говорил что любое там любая операция где то есть сортировки там в середине страны она меняет картину например по тем отправлениям которые ехали там с чукотки куда-нить в калининград плюс есть streaming обработки streaming в основном обслуживает собственно все потоки вод фабрики данных то есть мы данный интегрируем обогащаем раздаём ну и плюс добавляем это собственно дельта онлайновую к рассчитанным бать чем данным для того чтобы предоставить были оперативной данный там где-то нужно я здесь не буду приводить каких-то архитектурных диаграмм вот это такая укропа укрупненная схема платформы как она есть то есть как она есть вот на данный момент значит сейчас по сути у нас в основе некий do the lake дальше мы посмотрим своим технологический стык когда перейдем к разработке деталей к понятное дело на hadoop стеки и можно выделить логичным таких логических два компонента основной компонент конечно эта фабрика данных и и задача вот эти все данные из всех систем обрабатывать процессить то есть интегрировать между собой обогащать формировать где-то так сказать как сказать и вот не знаю для всех понятным термин золотые записи это из master data management то есть грубо говоря это некий поддерживаемые в актуальном состоянии запись которая характеризует какую-то важную сущность отправления емкость документ и любая там операция которая где-то подскочила которое добавляет какую-то достоверную детальку какой-то атрибутика которому мы верим так стать к этой записи должно быть обработаны мы должны оправдать эту запись и и фабрика данных собственно это streaming плюс баччана раздает потоки данных как я уже говорил всем производственным системам практически все эти системы сервисы почты являются нашими либо поставщиками либо потребителями данных либо и то и другое ну и все триста тысяч сотрудников почты являются нашими пользователями плюс косвенным пользователями являетесь все вы то есть все физические и юридические лица страны а отдельный компонент это лаборатория монетизации данных я позже расскажу про это подробно как это устроено почему мы это выделили но суть в том что это некий внутренний инкубатор где прогоняются по некому такому вот через некую воронку идеи новых да это driving продуктов ну и собственно основное взаимодействие идет конечно же через шину данных с системами потребителями сейчас немножко фактов то есть у нас обрабатывается до миллиарда событий в сутки ворочаем мы вот активно пересчитываем порядка петабайт а чуть больше данных физический кластеров 7200 ядер физических ну и понятное дело что все это создавалось для того чтобы можно было линейно масштабировать горизонтально при увеличении нагрузки и это нам удалось давайте теперь посмотрим как это все хозяйство разрабатывается как этим управлять ну собственно технологический стык вот он слева да то есть данные мы принимаем в основном через кафку есть и раз ты приема данных флюма мв линком мы их разгребаем здесь они оба потому что прямо сейчас у нас происходит переход мы переползаешь флюма на fling поскольку fling для наших задач меньше терять данные естественно ходу естественно hive кассандра быстро key value хранилище которое решает для нас задачу типичная задача следующая вот есть конкретное отправление у него есть иди и вот нам надо вытащить быстро все операции поэтому отправляем вот кому-то понадобилось с ним разобраться что-то происходит там что случилось конкретно с этим отправлением вот кассандра с этим справляется лучше всех spark streaming на котором работают streaming часть фабрики данных узи понятное дело как workflow артист rush in a spark crack house мы используем как хранилище в которой мы даём доступ аналитиком для работы с данными через кель интерфейс vertica вот здесь все open source кроме винтики vertica настолько хороша что она попала к нам вот в этот вот open source компания так стоп source стек поскольку на наших кейсах мы не нашли ничего лучше что могло бы нас три кейса было основных для этой нагрузочное тестирование первый кейс это очень быстрая заливка готовых рассчитанных структур данных рассчитанных витрин наделать рим очень быстро чтобы мы успели батч провернуть так сказано что есть пересчитать залить верте q и там к 9 утра выдать готовый аналитику следующие два кейса это сложный olap запросы и массовые несложные но очень массовые когда вся сеть там эти сотни тысяч людей ломятся за своими отчетами это все пойдет тоже в вирте q вот но и пинтах а как некий да и сьют на данный момент у нас 36 человек хамит разработки это все senior plus то есть у нас вообще нет ни джунов не рейверов а вот эти шесть человек это собственно архитекторы product owner и аналитики senior developer и и к и командам ну и основная единица разработки у нас это с парковые телешова на скала ну потому что все остальное кроме скала для нас не вариант поддерживать пойдемте в хронологическом порядке вот начинали мы в тринадцатом году ну собственно вот про начала тут особо нечего сказать потому что там нет особых болей нет особых тыкать челленджи и каких-то хитрых решений до то есть начало проекта на такое вот мы решали конкретную задачу для логистов команда меньше десяти человек такая вот знаете атмосфера творчества нет киселев пользователям важно чтобы мы им задачу решили им они еще не требуют качество они не требуют там не знаю ослабление силы f не терять данные там доступность кластер да вообще неважно кластер может неделю лежать главный потом водоему решение задачи не говорит ничего так круто а вот дальше дальше мы разрослись а команда выросла за десять человек стало понятно что надо как-то делиться надо что то делать и здесь очевидны такое классическое решение а давайте сделаем кросс функционально кому анды там джоэл коуч всякие рекомендуют казалось бы кровь национальной команды пилят фичи из общего бак logo здесь сразу что хорошо для того кто управляет этой историей очень хорошо что у вас есть бенчмаркинг вот есть команда 1 команда двоек то не делают примерно одинаковые задачи можно их сравнить можно сказать о осматриваться сделал вот интересную качестве не там лучше быстрее вот прими у него опыт вот ну и собственно когда есть бы кулак там на 2 года до когда становится две команды кажется ну так они же сейчас быстрее его сделает раза в два в общем прогноз становится более оптимистичному ну и плюс как здоровой конкуренции между командами за интересные задачки из общего бак logo тоже хороший фактор но вот на нашем длинном технологическому стеки реально эта вся история не очень работает почему ну вот так условно давайте разделим стек на backend понятно что все что ближе к приему там данных к собственно кластеру куда-то лейку это все на такой backend вообще надо и фронт-энд все что ближе к конечным витринам к конечной аналитики собственным бизнесом конкретным пользователям и вот понятно что основной минус на самом деле это то что в одной команде этом управляемого размера собрать компетенции по всему этому вот стыку от приема данных томат собственно от работы с кафкой там да да разгребание этих всех отказ от потоков там в фильме френки и доверху до frontend но крайне сложный когда у вас уникальный какой то человек который только один умеет работать с кафкой вот он заболел или там ушел отпуску от вас прилетела задачка как бы нам сидим курим второй основной минус это то что научим кластере но тут написано начался хаос а как именно это выглядело то есть ну представьте на общем кластере собственно есть некое общее workflow всем надо успеть за ночь перед считаться когда грубо говоря одна из команд тепло и не очень оптимизированную какую-то кстати обработку которая например ну довольно долго считается кто должен собственно решите сказать что ну нет это вот что то долго вот ли тот и командует нет это недолго это максим что мы можем сделать мы пробовали здесь вводить кросс командные review ну честно говоря ребята она не взлетают потому что приоритет и как бы у команды понятно у команды есть свои задачи а потом на review стоит очередь задачи к другой команды но понятное дело что они делаются по остаточному принципу то есть когда вот наших срочных задач нет ну мы возьмемся за review в общем кросс команды review здесь вообще не взлетела и второй большой минус это второй большой пример хаоса на общем кластере это собственно стабильность то есть когда джо попадают это реально проблема то есть наступает утро у нас ночной расчет упал и начинается разбирательства начинается поиск виновных а почему так случилось в общем то с этим решили побороться следующим образом и вот это сработало в эту картинку перевернули вот так то есть мы поделились горизонтально и в нашем случае это очень здорово сработала потому что но очевидно мы разрезали этот очень длинный технологический стык мы разрезали примерно пополам мы сказали давайте у нас будет backend который возьмет на себя все вот стабильность кластера возьмет на себя управление вот собственно кластером из dsm возьмет на себя все по приему данных по их валидации потому что бы их не терять при этом смотрите какая интересная штука для того чтобы это сработало деление продукта на горизонтальные компоненты обязательного условия вот они здесь отображены это целый для компонентов и понятный и 5 как у компоненты такого команды давайте подробнее что это такое вот в нашем случае ну сначала из общего к частному то есть что означает из целей для компонент это простая штука ответ на простой вопрос как вы поймете компонент работать нормально или плохо уже команда вот это отработал нормально или плохо вот с или для бэг-энда у нас это три основные вещи команды бэг-энда отвечает за доступность в девятках мы считаем время аварии и понимаем когда собственно эта доступность падает за производительность кластер а то есть они изучают за то чтобы кластер успевал рассчитать все к 9 утра чтобы streaming успевал разгрести весь объем и важный показатель их если это одна неделя на релиз того что им дает команда фронтенда для тепло и на кластеров то тоже важный показатель и вот они не успевают за неделю зарились эту фичу которая соответствует их требованиям которая прошла по регламентированным процессу там прошла тест you at сделано релизная ветка сделаны все артефакты если они успевают это сделать за неделю значит нас проблема если успевает значится хорошо и собственно и мы карты в руки а они имеют инструмент для того чтобы выполнять этот слой потому что они ревнуют когда им дается для диплома некая обработка они review это и могут сказать что нет это недостаточно оптимальна это можно сделать лучше да то есть они проводят кадры view собственной они заинтересованы кровный потому что это их если это своих команды и вот в этом случае куда review работает они либо сами подскажут как оптимизировать дали бы заворачивают собственно объясняю аргументировал почему можно сделать лучше и второй момент этой вот в данном случае это им команды бэг-энда вернее и и пиарим бэг-энда как компоненты являются рассчитываемые по расписанию готовые витрины промежуточные витрины с данными которые предоставляются фронтенда для того чтобы строить на них итоговые какие-то расчеты витриной визуализации все что происходит до этого прием потоков данных их валидации сохранения шуточные структуры расчет каких-то промежуточных агрегатов потому что здесь довольно сложная история здесь мы пришли к тому что полезно считать некий промежуточный средний слой агрегатов а не строить собственно конечно это не знаю витрины которые отвечают на конкретные бизнес задачи прямо из там текст структур которые пришли вот формате сообщений так вот вот этот вот теперь это набор вот этих витрин все что да все что под ним это подробности имплементации который скрыт за черный ящик его bkn может менять по своему усмотрению как хотят главное чтобы они и 5 поддерживали и в принципе вот эта история в нашем случае сработала очень классно мы наконец получили стабильный кластер потому что теперь понятны и люди за него понятным образом отвечают имеют инструменты для того чтобы собственно обеспечивать доступность и производительность как я уже говорил review и мы честно говоря увеличили скорость разработки в каждом компоненте за счет того что мы порезали тех стек ну грубо говоря когда команда front а теперь не должна знать про кафку fling в принципе кассандру и streaming это прямо круто да им гораздо проще вот сфокусироваться на спарку не верте кинопремьеры пинтах а прямо у нас здорово повысилась производить в каждом компоненте но конечно же для тех фич которые and the end производительность просела но это осознанный трейдов потому что мы растем повышается заревел с продуктом и для бизнеса начинает быть важным если на предыдущем там на стартап стадия не говорили да вы нам даете результат никого не парил там что кластер может там лежать пару дней а теперь для них начинает быть важна доступность теперь для них важного качества теперь они хотят потерять данные теперь они хотят правильные данные теперь они следят за количеством дефектов за количеством провод дефектов поэтому вот этот thread'ов он ну довольно естественный для этапа скажем так повышением очередь повышение зрелость продуктом дальше из этого следует нашу следующую трансформация мы понял что в принципе в такой постановке когда мы четко прописали пиа и бэг-энда когда мы четко определились целой команды бэг-энда в такой постановке не важно сколько у нас фронтовых командах можно масштабировать и мы их немедленно сделали 2 это стало хорошо можете ли что это полезно что мы можем вообще грубо говоря вводить какие-то команды выделены под определенный вид бизнеса мы говорим ребята у вас есть бюджет у вас много задач вы прям хотите приоритета все мы резервируем вот эту команду по 2 ст набираемый под вас она решает ваши задачи эта история классная пользователь действительно дико рады что дальше как правило вот тут минус такой до тех долг накапливается в бэг-энде что это значит ну тех долг он такой он заводится как плесень там где не видно вот как правило фокус внимания всей эскалации внимание заказчика внимание руководства но всегда направлена больше на фронте на то что видно да то есть то что там backend может быть уже живет на каких-то старых костылях которые там уже рассыпаются тону незаметно пока она не обрушится полностью в принципе не кого-то не будет волновать и нас подвел к тому что нужны изменения кейс когда мы посмотрели на рост и рост и приема данных мы их разворачиваем на докере можно масштабировать в общем они выдерживают всю нагрузку там да они принимают эти данным и поняли что мы их не писали в самом начале 2015 сих пор не трогали мы полезли ну расследуют дефект с потерей данных мы полезли туда поняли что вообще все плохо то есть надо было давно их переписать но до этого не доходили руки потому что все внимание притянута к фронту куда идут эскалации и мы решили бороться с этим следующим окей чем мы распилим на backend опять таки на горизонтальной команды мы выделим вот здесь решали конкретную больше приемом данных да мы выделим компоненту инфраструктура управления кластером здесь понятна эта команда devops of на этом у них понятный для всех и 5 понятные целые да это вот как раз та самая производительность кластер а его доступность и недельный релиз команды приема данных мы решили что мы и выделим в сферу ответственности тоже понятным образом попадает задачи вот есть некая такая система в ней есть данные они большие их надо к нам как-то завести как-то принимать разгребать во лидировать не терять сохранять все отдавать эти hive структуры сохраненным право лидера ванными данными не потерянными отдавать наверх это и по этой команды наружу собственное если я проговорил то есть данные нельзя терять данные надо бы лидировать и путем регулирования размер этой команды вот мы и создали из трех разработчиков ну и 1 киви туда присоединили вообще-то работает то есть мы регулируем размер у них есть вот этот свой компонента не фокусируется только на нем у них есть свой boklok вот они конкретно справляются с тем чтобы оптимизировать рефакторинг свой компонент прием данных и приводите в божеское состояние которое там отвечает потребностям развития всего продукта случае если у вас где-то заводится и так сказать вот такой вот систематически то тех долг вы понимаете что проблема в том что то систематически не доходят руки но это прям вот решение и оно понятно и она регулируемая это все мы уже проговорили и плюс еще дополнительный бонус в том что мы не сильно разрезали еще больше тех стек по компонентам стала еще лучше у нас еще повысилась специализация а теперь собственно так что теперь ну да понятное дело что and fitch просили еще сильнее но это опять таки плата осознанная за еще большее повышение зрелости всего продукта за то чтобы он был более стабилен давайте теперь вот пришло время рассказать про то что такое лаборатория монетизация данных зачем мы выделили то есть принципе где-то в этот момент стало понятно что предъявляются бизнесом совершенно разная скажем так требование о силе и к фабрике данных понятно что важно фабрики данных важно соблюдение салов важно качество важно данные не терять важна доступность то есть если фабрика данных лежит я говорил это катастрофа и вот есть некий поток задач которые звучат так ну вот интересно что-то вот здесь сделать вот есть какая-то боль тома тоже серая почта вот хорошо бы какой-то продукт iq сделать который бы эту боль решал и в общем то здесь это такое поле экспериментов где ну качество общение применимые силы неприменим кого волнует качество и просто сделать прототип сделай идею дальше пусть она заживет мы поняли что нам надо сделать вот такой компонент внутренней инкубатор понятное дело что четко инкубатор от некая воронка сужающуюся к верху то есть сначала некая стадия концепта по сути не знаю там презенташку основанная на том что покопались пару в игру загаданных сделали примерно собрали по ним статистику сделают концепт если мы будем делать так это заживет дальше прототип тут уже больше ресурсов команды разработки нужно тут уже нужно что то сделать какой-нибудь прототип чик пилот это но уже практически такое вот работающее решение но на ограниченном объеме то есть инвестиции возрастают снизу вверх на каждом этапе наша задача зарубить то что не выстреливает ну то есть заставить либо совсем зарубить ли поставить на паузу то есть не вкладываться вкладываться только в то что реально как бы имеет наибольшие шансы у нас эта история зажила вот здесь выделен они не выглядят здесь зеленая галочка стоит у как раз оперативного мониторинга логистики то вот тут а вот тот самый ситуационный центр это тот продукт который прошел всю эту цепочку инкубатора зажил сейчас то отдельный продукт это отдельный бюджет это отдельные люди отдельная команда она живет на нашей общей инфраструктуре ну и вот здесь собственно такое поле остальных продуктов которые сейчас в инкубаторе крутятся и живут на той или иной стадии они все in progress вот этого нее желтые лампочки так давайте дальше интересная вещь на витим миньонов становится много они атакуют окружают нас и от этого нарастают некая паника вот точно также мы себя чувствуем когда когда вы начинаете что-то деле вы ведь делать какой-то давать результат делать полезные штуки как он начинает приходить множество людей это собственно мы вращаем продуктов нашими куба 3 до они становятся нашими же заказчиками тоже ситуационный центр да у них есть некие задачки для нас которые должны крутиться на стриминге какие-то streaming триггер streaming джо бы какие-то большого у нас должны крутиться другие этой системы к нам приходят своими запросами отдайте нам новый поток данных а предоставьте нам новую витрину вот у нас есть такая задачка бизнес блоки подразделения приходится своими задачами в общем то что с этим делать вот вариант а вот если вы продакт-менеджер и у вас вот вы центральный некий компонент в по идее обслуживает всю компанию и у вас вариант вы можете конечно наращивать команду до чтобы справляться с этим потоком запросов но есть некий предел управляемости наверно есть некий предел возможностях ваших масштабироваться можно брать backlog называть сроки в годах но это мягко послать да это тоже не очень айс можно жестко послать можно отказывать но какой продукт менеджер вот здесь готов обрезайте грубо говоря обрубать развитие возможности развития своему продукту мне кажется что вот это все плохие варианты спихивать задачи на другие продукты говорит но вот может быть вот эти ребята там вот этот к ним задачки не к нам но этого все плохие варианты хороший вариант которому мы пришли это не замыкать задачи на себя а позволить другим людям работать вместе с нами то есть вот с того момента как мы определили четко веселее и и pr нашего бэг-энда стало понятно что вообще-то нам неважно работают с этим брендом фронт команды наше собственное и не должно быть никаких различий в работе с брендом для наших команд и не наших грубо говоря вот насколько они не нашего ситуационный центр это наши жеребятам и их вырастили вот они прошли по инкубатору вот они превратили самостоятельно команду самостоятельный продукт а плюс какие-то external тем да это какие-то вот бизнес блоки приходится каким-то своим задачками здесь я расскажу про случай месяц назад нам пришел бизнес блог горит у нас классные дата сайнс крутые задачи дайте нам данные откройте нам кластер мы будем мы значит построим свой кластер у себя мудрым за зачем ребята работаете с нами вот по понятному процессу таксовать у нас вот все стандартизована работать с нами о моем откроем наш тестовый кластер заходите на нем прям вот тестируйте искренен это мне нужно с вами что-то долго это на такие тут с архитекторы согласования надо на что то вдруг мама положим мы свой свой ходу кластер построим уже взяли целого архитектором и скоро возьмите сионистов ну в общем то сказать ребят вам никто не согласует там архитектура не пропустит досадовать внутреннего конкурента там разбивать вот единое the mighty ландшафт почты на какие-то вот под столом у вас тут кластер будет какой-то работать с чем-то надо попробуйте поработать с тестом ладно давайте доступ ну сгенерить ssh ключи что это такое как генерит это linux надо ставить звучим ugreen так вы говорили про какой-то дата сайнс у вас linux нет ну хорошо поставьте пути сгенерить и под виндой в итоге низко не знаете вот это сантис ты выйдут пусть они тени ряд мы не будем этим заниматься в общем да это довольно детей иногда бывают люди которые приходят от бизнеса вот они поэтому здесь как сине миньон обозначены но все равно с ними надо работать и по сути здесь мы переходим от того чтобы разрабатывать к тому чтобы проповедовать к тому чтобы делать ники евангелизм мы учим мы говорим о том вот наш open source ный ходу павский стек какие задачи он решает для чего он подходит для чего не подходит а мы проповедуем и мы собственно рассказываем про тот процесс который у нас есть универсальный danone простой да он упрощенный что ребята приходите к нам вот вам открыты наши девелоперская тестовая среда пожалуйста играетесь создавайте свои какие-то обработки свои какие-то с вы круто аналитику дальше в нашей инфраструктуры в нашем детей создавать артефакт нашим детей создавать в абсурд создавайте запрос на кадре view мы про review и мы подскажем мы протестируем мы оптимизируем дальше это пройдет you at помогите приведите своих пользователей который знает как надо как как и должно работать как-то проверять пройдет you at пройдет наш припрут пойдет в провод ну тут снизу еще схема как работаем с кодом я думаю что не суть важно она не столь оригинально а и в принципе поэтому же процесс универсального мы работаем и со своими командами и не со своими вот здесь такой немножко культурный аспект когда вы это делаете когда вы начинаете строить открытую к систему это тяжело может быть психологически потому что вы по сути делитесь с другими командами ну результатами своего труда то есть кто-то может рассказать какой он крутой как он классно там делает bigdata вот такие-то задачи да и пусть вам же в конце концов если для вас важен конечный результат то вот вопрос а кто получит за этот результат какие-то там репутационные бонусы вот он не должен тогда вставать на пути действительно дело на пути задачи но я предупреждаю что этот путь сложный то есть вот эти миньоны там они диски на такие дикие там добегают они сильно не понимают разницы там между реляционными данными и собственно big 3 они там зовут на вопросы а почему собственно там это так сложно все и долго сколько теперь запросов доставит данные там в этот куб в эту витрину бурим чувак это вообще неприменимость 10 ну как же но я знаю уже за 2 а там все сколько у вас источников данных но это наверно единственный путь до потому что вот все остальные опции вот здесь они плохие если вы будете отказывать если вы будете называть сроки длиною в год там до исходя из своих мощностей ну просто вы будете выращивать все внутренних конкурентов они пойдут не знаю к какому то другому вентру кому другому подрядчику по сайт каких-то людей хорошо если нормальные люди будут да а могут прийти какие-нибудь товарищи которые все в итоге обладают разгребать все равно потом вам поэтому лучше сразу взять на себя труд учить заниматься евангелизмом по компании до рассказывать всем о том что у вас есть некая открыто инфраструктура открытая платформа о том что любые задачи да это сайнс машин learning связанные с большими данными приходите к нам мы научим вот наш процесс мы вас по нему проведем и собственно все будет работать вот как то так собственно это совместный проект luxoft и почты россии спасибо что пришли еще раз если интересно и на архитектурную инфраструктурная часть посмотрите доклад big почта от алексей вовченко нашего архитектора ну и в принципе вот таким образом мы меняем почту к лучшему спасибо вопросы 5 вот пожалуйста арфа и 7 нас поджимает поэтому вопрос буквально добрый день спасибо за доклад у меня вопрос такой вы сейчас рассказывали что все посылки требуются по посредством штрих-кода и тому подобное вот все у которых есть раки набор ответе просто такой вопрос как случилась такая ситуация вы наверное слышали сколько скандальных релизов последних тоже люди находили коробки от посылок в лесах в полях и тому подобное то есть tracking у вас идет но при этом сам штрих-код не добрался до получателя я такую ситуацию честно говоря не помню конкретно смотрите все просто дают пока не идеален мы пока скажем так меняем его к лучшему но вообще если это трека и мы отправление то наверное вас успокоит что кто-то ответственный за конкретно вот этот вот это отправление этот участок поплатился своими денежками еще раз неимением под он поплатился сразу как только собственно во-первых она исчезла где-то до во вторых как бы она не прошло контрольный срок то есть дважды сразу не тогда когда его что ты где-то нашей в общем мне сложно ответить на такую историю давайте дальше андрей спасибо ещё раз за доклад мне вопрос такой при насколько я понял достаточно хаотичном пополнение big logo существует ли вообще трудно проекта как он должен был развиваться и развивает частных модель да это действительно челленж спасибо вот за интересный вопрос это челлендж том плане что действительно backlog пополняется и такое ощущение что он наполняется какой-то россыпи мелких разрозненных задачек и задача собрать из них более высокие смысл и собственно она на команде проекта на на продакт-менеджер и она на продукт оунера то есть у меня вот это все поделено на конкретной компоненты у каждого компонента из вас свой продукт оунер и в принципе эта задача решается тем что проводятся регулярные такие вот это нельзя назвать классическим и пиаром потому что оно бесполезно пытаться рифа и нить вот эту раз сюда скорее это попытка особо какие-то привнести какой-то смысл то есть мы знаем что нам важно ну вот например мы знали что нам важно выделить streaming кластер да потом мы знали что нам важно не знаю подключить таки это мощные потоки данных которые мы пока не подключили а из этого подключил эти потоки данных мы собственно можем решать следующий какие-то мелкие задачи бизнеса то есть вот другого какого-то здесь универсального рецепта честно говоря нет то есть вот где-то 1 месяц мы действительно делаем вот эту попытку связать там стратегический смысл которые мы видим с то россыпью задачек которые собственно к нам прилетают через деньгами нормально все ну то есть как бы bi business вкладывает до бизнес когда упал получает вылью его то есть бизнесу бизнесу понятно вылью смотрите бизнес-цели да вот именно для этого нам нужно вот это увязывать потому что для бизнеса бизнес цель выглядит так мне нужно вот такой аналитика к марту вот такой отчет мне нужен к апрелю вот такой отчет мне нужен тогда-то к сожалению к сожалению да к сожалению очень часто бизнес фокусируется именно вот на оперативных тактических задачах бизнес-цели здесь а вот они скорее они скорее были вначале когда я рассказывал про типы задач которая собственно у нас есть да вот например сделать вот эту систему управления по кипиа и мкас кодируем для всей компании вот это было понятно и бизнес цель вот то есть но здесь на самом деле мы как носители вот команда разработки мы как носители знания мы общаемся с бизнесом для того чтобы уловить какие-то стратегические вещи которые бизнес волнуют и понять что из этого может быть целью в контексте вот конкретно big да это задача в контексте развития вот нашей платформы давайте без микрофона нет нет смотрите естественно совместно ну конечно же это делал я это делал наш архитектор это делали лиды команд то есть если коротко то вот лидой команд до плюс руководствовалась всего продукта то есть вот мы собираемся и определяем как это должно жить как нам рассесться по удобней да то есть какие-то боли в текущей ситуации как бы нам оптимизирована рассесться чтобы эти боли как-то за адресовать и в принципе вот эти силы они для всех но более менее понятно здесь шел только некоторый торг до между собственно backend командой и между frontend команды о том а как это конкретно будет мириться как это будет считаться какие мы считаем satisfaction удовлетворительными целый до вот к сожалению в данный момент эта задача либо архитектора либо моя это понятно что это ручное управление какое-то но что делать да то есть у меня на самом деле получается так что окей в бэг-энде это отдельные задачки задачка для команды приема привести данные задачка для команды drops of там не знаю за перед там новый компонент какой-то поставить задачка такси для фронтона фронтовые команды сделать на этом готовы аналитику к сожалению но это одна и та же задача да там понятно что они связаны и пиком но скоординировать их по срокам это к сожалению только моя работа backlog разбит по компонентам да к сожалению это приводит к дублированию да то есть если у вас and the end фича вы получите пять этих задачек объединенных с одним и пика много к сожаленью так я боюсь это был последний вопрос потому что я готов нервах лично если что спасибо всем"
}