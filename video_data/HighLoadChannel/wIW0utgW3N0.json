{
  "video_id": "wIW0utgW3N0",
  "channel": "HighLoadChannel",
  "title": "Эксплуатация ML в Почте Mail.ru / Эдуард Тянтов (Mail.ru Group)",
  "views": 619,
  "duration": 2961,
  "published": "2020-04-14T11:05:03-07:00",
  "text": "всем привет спасибо что пришли меня зовут эдвард центов и отвечаю за антиспам и машина лёнинг в почте облаке mail.ru я сразу извиняюсь за свой голос немного приболел и буду сегодня начнешь рассказывать вот теперь буду вещать вам про эксплуатацию машин ленин га и давайте начнем с того что такое вообще почта современной что если она представляет и какие задачи мы там решаем несмотря на то что многие предсказывали уже сто лет назад умер от лени и почты всякими соц сетями и мессенджерами но это все еще не так и почта живее всех живых и мы ведем в ней бизнес переписку с вами храним важные письма такие как заказы авиабилеты и так далее книг а эстонцы стала неким индии в интернете и полтора года назад мы сформировали и презентовали стратегию развитие нашего современной почты которые заключается в том что почта должна быть умной а то есть она должна помогать пользователю ориентироваться во все нарастающего объемах информации которые сыпятся вещь к выделять из нее наиболее важные письма второе это то что он должен быть полезной то есть она должна давать возможность решать пользовательские задачи прямо в почте например вам пришло уведомление штрафе и вы тут же вы оплачиваете к сожалению я постоянно пользуюсь этой функции вот надеюсь когда-нибудь закончит и 3 естественно так как мы храним данные пользоваться ли это многое разные важна информация естественно почту должна защищать пользователя от взломов от спама от фродо от фишинга и всю эту по примеру фичи которые уже в продакшене и 1 от умный smart реплей нейросеть на письма от людей предлагает три варианта ответа пользователю чтобы он сократил свое время на набору текста ну как правило действительно так быстрее отличается еще иногда это бывает забавную то есть сеть иногда подсказывать такие выражения которые я никогда не использую 2 второй пример это группировка писем из интернет-магазинов все мы с вами делаем заказы в интернет-магазинах и часто несколько писем приходит о у об одном заказе в ящик и неплохо бы их было сгруппировать и вот если вы заказывали на aliexpress то вы знаете что алекс пришлет огромное количество писем по вашему заказу и в терминальном случае это число писем достигает 30 примерно вот все это не был мы группируем с помощью nine and intense recognise мы выделяем номер заказа и прочие сущности и показываем все это в едином интерфейсе с со всеми статусов 3 про безопасность это анти fishing fishing от такой особо опасный вид спама мошеннические когда злодея пытаются выудить и у пользователя информацию про его кредит шел к почте или другим ресурсам вот и для этого они мимикрирует под реальное письмо и мы используем компьютер vision для того чтобы анализировать не только текст url или все что есть стальной письме но и визуальное оформление таким образом мы распознаем оформлением mail.ru различных банков но самые топовые компании которые подделывают у нас есть визуальное распознавание что помогает нам бороться с пишем естественно в основе всех этих вещей лежит машин leaning и письмо проходит достаточно длинный путь в почте прежде чем дойти до пользователь в начале мы отсекаем спам оставляем хорошие письма далее мы хорошие письма делим на письма от людей которые мы считаем очень важный показываем пользователем такие фичи как smart реплей и на письма от робота который в свою очередь мы делим на информационные такие рассылки скидки уведомления от соц сетей которые мы в нашем новом интерфейсе группируем два отдельных 3d рассылки и соцсети соответственно таким образом визуально очищая почтовый ящик и оставляя на виду только самые важные письма это уже упомянутый письма от людей и в основном это транзакционные письма упомянутые заказы штрафа в покупке путешествие и так далее вот но здесь масштаб на самом деле не такой как на самом деле спама который мы не доставляем до пользуется кого ящика даже до путь до папки спам огромное количество и это работает система пользователь фактически не наблюдает а задача достаточно сложная потому что в игра он не идет серьезная борьба между людьми на одной стороне который пилит имели моей команде и спамерами на другой которая адаптирует возможно тоже свой какой-то эмаль вот я достаточно чем живой задач и пару цифр и соответственно сутки нас примерно проходит полтора миллиарда писем на 30 миллионов пользователей дала и у нас все это обслуживает добро 30 примерно 30 машин для них систем нет достаточно большое количество эмали и когда у тебя куча систем машину обучение это означает что ее на поддерживать и это достаточно большое количество поддержки поэтому для нас задача эксплуатации она особенно актуально вот и почему надо вообще поддерживаете мель потому что модели со временем деградирует по нескольким причинам например потому что имели такой же софт как и весь остальной там случается баги плохие выкатки ломаются признаки с вашей модели может случиться что угодно естественно это естественно всегда происходит второе то что данные в принципе не стоят на месте пользователи меняют свое поведение продукт запускает новые фичи и все время все данные меняются и модель может на самом деле очень быстро выйти из строя ну и третье есть конечно плохие люди которые пытаются обмануть ваш муж на время к алгоритму и это наиболее актуальна берем там с вами в рекламе в поиске то есть там где можно ли они приносят какие-то деньги и таких бизнесов становится все больше и больше естественно там возникают люди которые пытаться пытаются эксплуатировать так или иначе вот я особенность машин линга на самом деле в том что оно поддержка машины ольга но очень дорогая операция потому что иногда даже самые простые изменения как добавление нескольких признаков могут вызвать достаточно много работы вот и особенно это так когда нет отлажены инфраструктуры и по моим наблюдениям на самом деле среда окружающая то есть данные которые окружают модели уже все происходящее она все больше и больше меняется и как правило это означает что надо еще больше и больше поддерживать модели и у нас принципе даже была такая ситуация когда мы напилили радостно много систему а в итоге там в течение нескольких месяцев практически full-time их поддерживали потому что возникали различные проблемы и мы не могли пилить нечего нового вот это означает что у нас есть высокие касты неплохо бы их автоматизировать что можем автоматизировать это на самом деле практически все это сбор данных до обучения и диплом и соответственно тестирование мониторинг как сопровождении это собственно и будет моим планам на сегодня и первые 3 элемента сбору данных до обучения deployed по сути фидбэк клуб то есть постоянный цикл до обучения модели на фидбэки от пользователей и там где среда хоть каким-то образом меняется мое заявление в том что инфраструктуру и часто гораздо более важнее чем сложность моделей то есть такой простой линейной классификатор может с хорошими данными с постоянным притоком фидбэка с новыми признаками может работать гораздо лучше чем стоит у зоро то любая модель и вообще в принципе поддержка свойственно любому проекту там не только таком масштабном у как у нас такие перейдем в бак лупу его первый пример почему это важно насчет и график вот зелененький регистрации почте mail.ru то есть какое количество в минуту аккаунтов регистрируются на почте и мы запускали вот слева красная полоса у нас мы запустили этом очередную версию анти бота естественно у нас были какие-то боты какие-то пользователи средстве на ботов убили и остались только пользовать мы радуемся но радовались на примерно 4:00 запустили мы в 14 1800 все примерно вернулось на круги своя что это означает что на самом деле в этом случае разработчик потратил месяц своей жизни вот за четыре часа спамер все это прекрасно обошел то есть достаточно хрупкое изменение было и поэтому если не думать о том как ваша система будет в будущем эксплуатироваться какие возможны изменения и как вы будете добычей свою систему очень велика вероятность о том что вы убьете кучу времени в стол и будь переделывать в итоге свою систему перейдем к сбору данных все мы знаем что естественной рассеется там для них даны это топливо и люди наши пользователи поставляет эти данные вот но тут самое важно понимать что тот фидбэк которым да им пользуется ли то есть как бы финальный критерии оценки того как работает наша модель потому что очень частая ошибка машин лидеров это считать что если написать этих у тебя модель хорошо работает значит всё замечательно но это совершенно не так в очень важно как именно пользователя оценивают работу вашей системы потому что для них мы и работаем поэтому всегда важно давать пользователю голосовать каким-то образом давать фидбэк в данном случае письмо которому распознали как финансы в правом верхнем углу пользователь может нажать на финансы и там дать фидбэк какое-то письмо или какой другой категории вот здесь важно понимать что у всех у пользователей у нас с вами абсолютно разное понимание фичи то есть для нас финансы и тото письма от банков а для пользователей какого-то конкретного этого письма за ее бабушки про пенсию да и он может давать фидбэк от этого письма профинанс и таким образом получается что у каждого свое понимание фичи и надо каким-то образом это учитывать второе то что некоторым пользователям вообще в принципе нравится лупить по кнопкам и они выдают делают какие-то неадекватные действия и там сколько ни наблюдаешь за ними непонятную почему они нажали такие такой или иной куриную фидбэк кнопку вот и как пример пример нигерийского письма насчет такое очень забавный вид спама когда пользователи пишут из какой не веря человек который говорит вот я адвокат вашего покойного там родственника якобы и вот получите 5 миллионов долларов ну и потом начинают естественно разводить и вот когда мы запустили первый раз классификатор нигерийского спама начали складывать эти письма в папку спам пользователей начали жать не спам и мы проанализировали и увидели что 80 процентов того что жмут пользователь не спам оказалось то есть сеть на человек видит что ему светит 5 миллионов долларов радуется и жмет что это не спам начинает переписываться вот то есть пользователи очень часто вообще в заблуждение того что происходит и поэтому на прям такие письма вообще нельзя доставлять в ящик в принципе вот ну и третье чего становится все больше то что боты и всевозможные там спамеры они тоже кликают по всем кнопкам сейчас с помощью сеем и chrome и можно воссоздать фактически полное поведение пользователя на сайте и соответственно это тоже с этим тоже надо жить как-то из этого мы делаем вывод что просто фидбэк сам по себе он как бы не очень полезен то что ем очень много мусора вот как я уже говорил до 80 процентов эта цифра может достигать и с этим надо что-то делать и вот что делает мне больше всего нравится концепция когда один имели другой имел лишь как один из примеров соответственно у вас могут может работать несколько систем машинного обучения который решает одну и ту же задачу например в том же анти боте который я уже показывал график у нас есть система быстро есть которая принимает свое решение в тенистом 100 миллисекунд прямо на регистрации есть медленно и которая постфактум изучает поведение класть и рисует пользователь раз отвесно имеет гораздо более серьезный при сижу на реку естественно всю разницу между этими двумя моделями можем направлять в быструю модель как фидбэк естественно быстрая модель пытается постоянно приблизиться к более точные медленной модели вот это здорово работает и поставляет постоянный поток данных второе то что можно каждый клик на самом деле пользователя классифицировать и определять подходит ли он к нам для обучения то с чисто это клик или нет мы в инте спамят такое запилили то есть мы письме анализируем пользователя смотрим и его признаки какая у него история на что он там до этого кликал что он получает на признаки отправить или его статистику смотрим насколько адекватный контент и это в целом насколько это письмо мощным спамом или нет потому что ну понятно будут тоже кликают вот это кукла секатор нас работает и что здесь важно что мы очень сильно выкручиваем при хижину в угоду recall а потому что машина обучение очень важно подставлять чистый данные и пусть будет меньше зато они будут гарантированно давать хорошие фидбэк в модели потому что модель все ошибки прекрасно выучат которые будут в этом фидбэки вот пока мы на самом деле анализируем пользу такие клики и там добыча я нашей модели пользователи в это время могут страдать то есть мы должны помнить что когда мы смотрим на графике и видим там тысячи и миллионы это там статистика для нас для пользователя каждой бак и проблемы эта трагедия и он как-то должен с этим всегда жить то есть всегда может должен мочь исправить и продолжать счастлива дальше пользоваться продуктом и также обычно пользуются предполагает что если он потратил свои драгоценные 5 секунд и что-то из правил то в будущем это уже никогда не повторится поэтому нужно всегда думать о том как на и на этих кликах пользователя можно навесить какую-нить эвристику которая будет исправлять проблему для конкретного пользователя в ее ящики это может быть какие самые простые вещи типа письма от этого отправителя больше не доставляется в такую-то папку вот и есть проблема более серьезно естественно там уже разработчики в полуавтоматическом режиме уже как-то костыли свою модель вот и вот у нас есть такие получаются два вида костылей которые у пользователей и у нас со стороны модели и все вот эти костыли они вообще любые эвристики они имеют свойство разрастаться их достаточно тяжело поддерживает это как брать а со второй стороны того фидбэка которую нам дает пользуется ли его иногда может быть недостаточно если мы сфолдили на нескольких там пользователях там там несколько писем выборки и вообще никак не гарантирующему исправим эту проблему вот казалось бы для разной проблему можно объединить и как бы друг другу помочь что мы делаем то есть вот у нас есть модель которая работает в продакшн и мы начинаем положить на чем-то после этого мы делаем к это временный костыль в надежде что он временно и конечно вот и с этого костыля мы отправляем данные напрямую в обучении модель здесь естественно важно чтобы это юристе к было достаточно точно чтобы она подходила для обучения и дальше мы вешаем мониторинг то есть анализируем насколько этот костыль срабатывать часто очевидно когда мы сделали этот фикс то у нас срабатывание часто потом мы предположить на добыче и модель и он обращается в ноль вот в этот момент когда обращается в ноль мы можем костыль спилить таким образом мы решаем две проблемы с одной стороной мы учим нашу модель исправляем ее ошибки со второй стороны мы снижаем нашу вверх от на поддержку в эвристику вот и получается что эвристики очень полезно для моделей и естественно здесь важно чтобы срок слух чтобы их чтобы их службы было срочные они постоянны ok переходим к обучению на чем мы собрали данные у нас достаточно чистый фидбек теперь вопрос как до обучать модель что такое вообще до обучения это вот у нас есть текущий выбор коммуна этой выборке обучили модель и нам пришел чистый фидбек пользователем и на этой основе хотим обучить новую версию модели локации в продакшн какие у нас бывает вообще проблемы с обучением ну во-первых модель может принципе не поддерживать до обучения то есть только учится заново с нуля второе это то что нигде в книге природы не написано что добавление новых данных улучшит качество моделей на продакшне все может пойти на самом деле наоборот 3 достаточно тонкий момент который мы наблюдали это то что даже если мы запускаем вторую модель и анапа метрикам работает практически точно также как первое но в чем-то они отличаются то на самом деле то есть профита в терминах метрики мы не приносим но мы вносим какие-то новые ошибки с которыми мы ещё не умеем жить то есть со старой моделью же пользователя мы учили жить мы научились жить а новая модель вносят расы и кучу ошибок новых да и второй этаж на самом деле уже пофикшены проблема может снова возвращать вот это такая важная вещь и поэтому здесь важно гарантировать чтоб наша новая модель улучшало и и или хотя бы не у не ухудшало нашу ситуацию и первое что приходит в голову для дам учения так называемый activelink когда вот у нас есть модель классификации например финансов у нас есть где та граница принятия решения на 85 процентах и мы вокруг этой границе с эмблемы эти письма либо нам пользователь дает фидбэк либо мы-то размечаем как-то через асессоров соответственно мы на этой границе пополняй нашу выборку и модель все время уточняется на этой границе все лучше и лучше становится принимает решения в спорных случаях но это имеет очень важный недостаток состоящее в том что у нас в итоге очень сильно меняется распределение выборки относительно production то есть у нас получается основная выборка соответствует вот этой зоне вокруг границ принятие решения а то что на углах где модели как бы больше всего уверена у нас это выборки нет это означает что мы по выборке по метрика мы абсолютно не можем ничего сказать что у нас будет на продакш или вот и концепцию в том что нужно гарантировать улучшение можно переформулировать в то что нам важно чтобы новая модель сохранилась старая паттерна которая ловила предыдущая модель детективом и приобрела приобрела какие-то новые и здесь получается вас такая концепция преемственности когда мы используем предыдущую модель которую мы каким-то образом уже вывели в продакшен ее работы достаточно приемлемым это мне на первую версию там с кровью и потом запустили вот все отладили все на основе этого теперь мы можем работать дальше вот это вот такая ключевая вещь что то что у нас уже в продакшене мы можем использовать для того чтобы безопасно улучшать нашу модель и у нас почти нет несколько типов моделей это линейное деревья и нейросети и для каждого свой алгоритм до обучения начнем с линейных допустим мы обучаем лог регрессию у нас появился новый сет и мы нашлось составляем из нескольких компонентов значит первое мы обучаем до обучаем текущую модель на новом с этим и параллельно естественным и не забудь не забываем про регуляризация и регулируем признаки но только новые те которые пришли с этим светом то есть старые мы пока никак не трогаем второе мы не забываем про старые сайты тоже учимся и прогоняем какие-то сэмплы со старого сайта потому что очень важно не забывать то что мы когда-то знали и не бегать за своим хвостом как бы постоянно добыча я и фикция проблема которую же ранее были пофикшены и третье самое важное это так называемая гармоническая регуляризация то есть мы на навешиваем специальную регуляризация на старые веса чтобы vesa новой модели не сильно по норме отличались от старой таким образом будет гарантированно что у нас изменения текущей модели новый будет небольшой относительно старый это как раз позволяет нам быть более или менее уверены в том что новая модель не натворит каких-то очень серьезных делов то есть оно не сильно изменится коэффициенты при всех этих лодках нам дают небольшую гибку из которой она позволяет настроить адаптивность наши нашей модели новые насколько на этом сильнее будет реагировать на новые данные ok перейдем к деревьям мы используем busting и вот у нас допустим есть лес деревьев на старом с этим мы стандартного до обучения как такового в деревьях нет мы придумали такую штуку мы отрезаем в конце 5 деревьев и добавляем 10 новых вот и обучаем их там с большим весом на новым на новых данных у нас получается лес из там примерно 100 300 деревьев и отрезаем кусочек добавляем в два раза больше и таким образом у нас такой инкрементальные улучшение модели получается но мы здесь можем видеть что как бы при таком подходе у нас число деревьев постоянно будет расти или бы неплохо бы их периодически отрезать чтобы не вылезет за тайминги и 2 но да и здесь нам на помощь спешит очень популярна нынче концепция научитесь слышен когда одна сеть пытается более простая выучить работу новый как это выглядит мы берем тренинг сайт прогоняем ую через нашу старую модель получаем она predicted у нас вероятности и мы новой моделью более простой пытаемся повторить эти вероятности на выходе и таким образом обучить практически такую же модель здесь очень важно что здесь нет вообще нигде таргет of то есть нам вообще не обязательно использует trennings и поэтому мы можем использовать сэмпл потока это очень важно потому что напомню что тренинг сет как правило имеет распределение совершенно отличающийся продакшн и а таким образом мы можем как бы выровнять эту ситуацию добавить production данных без всякой разметки ему на самом деле с помощью научности лишь на деревьях делаем не только там сокращение количества деревьев но и другие операции такие как удаление признаков и устойчивость пропуском мисс элис здесь написал это означает то что у нас например есть признаки которые статистически и статистика считается в каких-то базах данных базы данных мозгу могут отказывать а выборки соответственно таких совершенно нет примеров где база данных отказывала и в момент сложностей модель может сходить с ума раму соответственно мы например когда хотим сделать более устойчиво нашу модель к таким событиям вот применяем но здесь и лишь следствие мы берем тренинг сытый сэмпл потока прогоняем через модель опять же получаем получаем те же самые распределения вероятности на выходе и далее мы производим аугментацию данных то есть мы либо удаляем признаки либо заменяем их на не определенные значения и копируем просто выходы для соответствующих данных и у нас новая модель пытается выучить все вот это добро таким образом некая помесь аугментации с но уж distillation of вот и опять же мы используем все без таргетом что очень здорово и мы применяли этот метод заметили то что чем более сложную операцию мы выполняем с моделью тем больше процент нам требуется production данных то есть например когда мы просто удаляем признак это достаточно простая операция модели училась на тренинг сети и в общем не очень сильное изменение нам достаточно небольшого кусочка с production как только мы производим более сложную операцию типа тримминг деревьев над пытаемся сотни деревьев приблизить модель 300 кто мы уже там примерно 50 на 50 j для в наших задачах когда на статистика является очень важным признаком соответственно мы используем еще больше samples потока таким образом чтобы наш production performance было максимально приближать макей приходим к подтекст у вас текст им будет false текста состоит из инбридинга слова и и maiden во всех в него входящих ingram обычно это 3 грамма и триграммы эти обычно мопед в максим массив фиксированного размера это называется bucket caching и таким образом мы в итоге учим матрицу размером длинные внутреннего слоя на количество слов плюс количество пакетов если мы возьмем новые данные и попытаемся до обучить вас текста во первых происходит и вещи помимо новых данных у нас появляются новые признаки это новые слова и новые инграммы и второе если мы берем фейсбук узкую реализацию и пытаемся что-либо доучить с помощью нее то там алгоритм достаточно простой вопрос она нового данных без добавления новых признаков добыча и нашу модель с помощью круз энтропии естественно табак естественно обладает все с теми же недостатками же о чем я и говорил раньше то есть модель может измениться непредсказуемую как минимум и также мы не добавляем новые данные то есть две такие вещи их мы решили пофиксить то есть мы добавляем новые признаки дальше учимся с курсом трапе и и аналогично как мы делали с линейной моделью новейшим гармоническую реализацию на старой веса таким образом опять же мы гарантируем что наши новые бединге они не сильно изменятся относительно предыдущей модели кей для cnn ок все немножко сложнее то есть если мы здесь надо учим последний классе ционный слой то все предыдущие методы применяются но если нам нужно всю сетку переобучить или у большую часть соответственно это нам не подходит если у нас такая счастливая ситуация что мы сами контролируем полностью данные когда у нас есть свой генератор например для распознавания текста . то есть мы у себя написали генераторы полностью контролируем и можем в принципе хорошо повторяется распределение данных на продакшен и других случаях можно гарантировать не сильное изменение тимбилдингов и это возможно сделать с помощью триплет лосса дремлят лосс на примере анти фишинга вот у нас мы хотим распознавать разные типы логотипов вот например нас есть логотип mail.ru и мы используем элемент этого класса как позитивные примеры другие классы как негативные и минимизируем расстояние между первыми и максимизируем расстояние между вторыми и делаем это с неким зазором таким образом чтобы наши классы были более компактные и более разделимы в метрическом пространстве значит это замечательный метод который работает на любых выборках для любого объема но соответственно если мы добавим новые данные у нас и мы ding ye метрическое пространство как следствие изменится непредсказуемым образом чего нам очень не хотелось в этом есть вариация как можно достичь вот это вот это совместимость имбилдингом значит мы просто добавляем новых данных в данном случае этот amazon у нас появился вот такой логотип у которого раньше не было и мы просто учимся с нуля и дальше мы начинаем процедуру фан тюнинга мы говорим пусть у нас часть данных вычисляется текущая модель это беден ква 2 имеется ввиду что мы новой моделью в 2 предыдущие в1 в2 который мы обучаем мы вычисляем бединге для только части данных а для остальной части мы вычисляем бы не где с помощью старой модели которые работают на продакшне и таким образом в момент обучения у нас смешиваются им бединге двух разных версий и нативно получается что mb денги в т 2 версии начинает быть совместимыми с 1 и таким образом можно опять же достичь вот это не сильного изменения естественно это будет в угоду качества как правило но можно сделать там 10 последовательных итераций и это будет легче для диплома чем сделать одну большой масштабный как правило если рассмотреть как у нас устроено в итоге весь pipeline avanti спаме у нас на нижнем уровне признаки таких как картинки тексты и вот все прочее которые нас есть там статистика и все что мы извлекаем из письма далее мы из текста и картинок извлекаем бейнлинги с помощью цены на пафос текста над ними мы строим различные классификаторы классификаторы пишем и двигалась в которых каких-то классов спама классов писем и и их уже вместе с другим признакам мы подаем в наш результирующий busting деревьев с 10 разумный вопрос который вас может возникнуть зачем здесь вообще классификаторы почему не подать сразу сырые данные делаем этом для того чтобы чтобы лучше понимать что у нас происходит когда мы сырым бединге запихнем в модель деревьев мужа не поймем в каком месте мы ну точнее будет тяжелее понять где мы именно там косящим что нам нужно исправить когда у нас есть конкретные классы которые на хорошо интерпретируем и мы можем понять что мы именно в них у нас проблемы и гораздо легче эту маленькую ячейку переобучить чем переобучить верхний уровень и получается мы каждую из этих вещей этот seen in a fast текст мы используем гармоническую регуляризации для до обучения для классификаторов опять же гармонической регуляризация и клик калибровка которая позволяет сделать выходы вероятности такими же как предыдущей модели и верхний слой в виде деревьев у нас инкрементальный мы добавляем по чуть-чуть то есть все мы компоненты здесь можем менять независима друг от друга по как бы не сильными изменениями и все остальное не разваливается это достаточно на самом деле крутая штука потому что каскад из моделей достаточно сложно поддерживать если не пользоваться таким способом то как правило надо все вместе переобучить этого очень не хотелось здесь каждый компонент получается достаточно независимо отсюда вывод что прям с модели очень сильно решает и вот советую вам всегда ее применять переходим к диплому лишь мы собрали данных научились докучать модель до обучение нам представляет к постоянно какие-то новые модели и нам надо каким-то образом деплоить разумеется нам надо делать это через оба тесты потому что некие метрики на тренинг сетах нам не скажут что у нас будет происходить на продакшн несмотря на то что мы пытаемся гарантировать чтоб новая модель по было похоже на старые все равно надо всегда бы то есть и мы всегда выкатываем естественно пытаясь постепенно сначала там на 5 процентов на 30 до 50 и уже потом на стол и делаем мы это в полуавтоматическом режиме то есть до 50 процентов у нас автоматика смотрит на метрики каждой модели то есть к к к к к к меня статистика принятия решения какой фидбэк от пользователей если все хорошо на пропускает на следующий уровень и уже дальше на 50 процентов человек уже смотрят все ли хорошо точно и жмет раз катить на сто процент в целом шаг тоже можно полностью автоматизировать проблем с этим большим нет а проблемы есть тем что бы с латов на самом деле не очень много и вообще экспериментировать на пользователях и катить на них постоянно в большом количестве возможны не самой лучшей модели не хотелось бы это раз второе любая bts там где фидбэк достаточно долго получается почте это так то есть мы распознали миллиона письма пользователей потом в течение кота времени на них реагирует соответственно птс может идти там доступ к примеру иногда это может быть шесть часов иногда это может быть 12 зависимости от статистическая значимость но это говорит нам о том что вообще эта процедура достаточно трудоемкое неплохо бы ее было бы тоже оп сорян и неплохо бы тоже было как-то авто мы оптимизировать успешность оба тестов собственно чтобы ускорил наши вообще deploy весь и мы делаем с помощью классификатора как ни странно и вот допустим мы обучаем деревья у нас много кандидатов постоянно идет до обучение на новых данных какое-то количество кандидатов мы смотрим какие у них метрики на тройник сайте престижен recall статистика принятие решения и вот уж потом придумаем далее мы смотрим метрики на отложенном сети вообще абсолютно на котором мы не научились смотрим на стенд на из потока что там происходит и сравниваем это все текущую моделью естественно там еще в разного рода признаки типа насколько модель стала более сложной и так далее вот и далее мы это все скорик классификатора которые уже на истории пройденных тестов может понять какой какая из моделей с большей вероятностью пройдет до конца и когда мы это внедрили у нас в несколько раз ускорился диплом что достаточно круто и хотя это на самом деле очень просто иди ok переходим к тестированию мониторингу окей мы наши модели разложили важно с ними теперь как-то жить и и не ломать их тестирование мониторинг краже над крайне важны это всем понятно вот почему это еще раз заострю внимание почему все-таки надо же дальше все сломается когда-либо потому что вот это график который показывает количество ошибок 1 систему в зависимости от времени то есть вначале когда мы много разрабатываем у нас много ошибок потом мы баги фиксе мы выходим над низкий уровень ошибок но потом со временем энтропии берет свое что-то вокруг меняется система ломаются и в ошибке петь снова растут если нет должного уровня поддержки и это означает что всегда надо же отдать что что все компоненты вашей системы когда-либо разнесет естественные мониторится тестирует все что вы делаете и вот здесь такой вот пример это классификатор это количество дефектов классификатора определенного мошеннического спама и мы можем видеть что там очень мало писем детектив это нормально потому что мошеннических писем на самом деле не так уж многое но они все очень опасны и в этот момент признак один из самых важных у моделей сходит с ума и она начинает похожие на пишу письма тоже считать фишку и вот мы уже увидеть во сколько график то в сотни раз возрос и соответственно по неудачному стечению обстоятельств краса не было мониторинга принятия решений средстве на какое-то время он так проработал и а потом мы естественно мотивировали последствия но уже думаешь как бы нанесем и здесь важно понимать что у каждой системы есть кот lifetime вэлью сколько она агрегированном принесет профита и понятно что после такого факап а как бы эта модель уже никогда себя не сможет окупить она слишком много накосячила и нам изначально как бы уже можно было считаю не запускать потому что она уже нависла больше вреда чем пользы вот и поэтому очень важно иметь либо автоматически мониторинге которые создаются при запуске системы либо очень четко проверять на задача проекта все все все что нужно за монитором и вот что мы интересному мониторим помимо стандартных метрик это различные распределение то есть мы смотрим на сколько наших классификаторы какие распределения меток он выдает сколько там ноликов и единичек какой распределение с коров этого классификатора и какое распределение признаков которых участвует принятие решения и таким образом мы это делаем там для всего потока для разных для разных инстанциях нашего сервиса и мы можем либо сравнивать по истории ты смотри что сейчас что-то произошло распределение напрокат признак резко изменилась алярм надо что-то сделать либо же когда мы катим нашу модель на процент мы можем тоже смотреть и видеть что распределение с коров как-то подозрительно сильно изменилась до например модель стала резко сильно более уверена в своих решениях что-то странное основе этого можно либо даже откатить модель либо хотя посмотреть вот и второе мы чувство запускаем нашу модель из с помощью каких-то минимальных эвристик и мы часто эти эвристики потом когда заменяем на машины обучения используем как мониторинг в данном случае это могут быть там какие-то регулярке и мы наблюдаем какой процент этой регулярке нашу модель перекрывает если она перестает перекрывать например скажем 50 процентов эвристики там и аль армии мы смотрим в чем проблема и как правило если было обновление модели от абсолютно очевидно что мы потеряли часть приколы и надо откатывать и разбираться вот еще мы вообще в целом делай вывод что эксплуатации на думать заранее потому что очень многие из этих моментов достаточно тривиальных которых я рассказал их можно достаточно легко продумать в самом начале чтоб потом не собирать плоды как бы куча ошибок и переделок перейдем к рекам и значит фидбэк еще раз очень важно пользователю давать всегда голосовать от не только метрики качества но и важный источник данных для нашего обучения и всегда важно фильтровать эти данные так чтобы они имели профит для нашей модели второе до обучение здесь основное это то что у вас должно быть преемственность модели мы вместе каждое следующее улучшение модели она не сильно отличается образом мы можем перестраивать целые крупные системы без серьезных изменений и 3 очень сильно помогает off to deploy по метрикам потому что избавляет от кучи рутинных операций просмотра графиков и реакции человека окей и собственно у меня на этом все и я надеюсь что рассказанные трюки инсайты помогут вам делать вашу систему лучше делать их более надежными и как следствие лучше спать по ночам и отдыхать на выходных массива у меня все спасибо огромное сейчас будет серия вопросов-ответов сейчас нам принесут подарок для тебя а для тебя будет задача из всех вопросов выбрать самое интересное на тебя и для него будет подарок от компании wargaming а вот этот подарок для тебя базиликаты удобная сумочка сошли с разве до последнего опроса было обычно до ваши вопросы дорогие тут спасибо большое за клад некоторые моменты вы достаточно быстро проговорили пустим трибьют лосс где-то можно считать меня там в презентации ссылка в след от гугла и спасения для физ ре как низшего десна их идея чтоб себя нужно загуглить пред спасибо за доклад сказал что сказал что вы берете различные распределения и потом смотрите что вот там не знаю новой модели эти распределения никаким образом не ломает а как вы определяете что вот-вот распределение как бы была нормальная теперь она стала плохим где вот этот вот пришел что типа вот вот это изменение достаточно большое что это уже как бы признак какого-то пока по или файла и не нужно откатываться назад но это мы используем коли дивергенцию для сравнение распределения ну и собственно для каждого случая ты смотришь на историю и смотришь какое такое нормальное изменение бывает этого распределения вы как-то выставляешь порог и сегодняшнего со временем как как только он фолдит но стандартные мне кажется штука с мониторингом спасибо за доклад здесь здесь здесь здесь привет ещё раз вопрос такое вот на этапе на обучение для вас было слайд поэтому по линейному классификатору у вас добавлялось новая модель там где вот формула там цель 2 регуляризации плюс еще добавлялись результаты от старой модели она просто новую модель в чем-то же на старых данных размена новых данных у нас есть лосс отвечающие за новые данные за старые все диски некоторым коэффициент просто думаю что там как бы не будут ни давление что там суммируется и все еще знака loss суммируется модель у нас старые мы обучаем на новых данных на старых и еще регулируем новые признаки старые а когда вы результаты по старой модели отсекать и потом понял вас там еще есть регуляция по разнице весов между датами моделью новой модели эта часть вал старая модель всегда пользуется как это мы просто фиксируем мы знаем веса старой модели и мы просто оптимизирован наше текущее веса ориентируясь на веса старой модели мы просто волости задаем что норма ну а если потом вас еще новые модели еще новее вышло но новее вышла она от следующей версии плюс один всегда то есть стоянка ментально изменить не может на вас новая модель + новая модель + 0 это мнение всех друг за другом они как пойдут позвали на как раз небольшие изменения диплом добрый день склад жить говорили что у вас количество слотов ограниченные вы не можете много экспериментов одновременно запускать не ну я имел ввиду что их ты вот у нас там может сутки этом не за 30 моделей до обучать но ты не будешь на 5 процентов 30 раз катить это раз во вторых если модель какая-то плохая ну не достаточно хорошее то есть у нас получается знак значимый процент пользователей постоянно под какими-то экспериментами от не очень хорошо нам нужно на приводится спаме достаточно быстро обновлять наши модели и для этого нам надо указывать на достаточно значимый процент пользователей чтобы быстро получить фидбэк туши смывок этим на ноль один процент мы можем там три недели ждать пока у нас на течет необходимы этого статистическая значимость поэтому вот у нас в данном случае она как бы количество этих флотов не очень большое и ну не и а не хочется экспериментировать на огромном количестве пользователей а также не есть какие-то цифры может быть личный опыт а какой процент аудитории допустим тестами держать порядка 20-30 в пике может быть еще один вопросик до пасибо за доклад спасибо еще один вопросик забыл про обед с там у вас собирается статистика и как аналитика по тем пользователям которые давид фидбэки какие такие пользователи которые отдают фидбэки тут какой-то которой чаще живут кнопки то есть более активно разрез активно у детально давно на это вот это бы тестирование распространять более активны в италии у вас случайно the corner у нас случайно но именно в продукте почты там естественно есть там бы то пользователи вот ну да на принадлежать и спама такого нет и там для большинства классификаторов мы просто делаем рандом не считаю что какая то часть пользователей пожизненно должна больше страдать чем остальные от них быстрей бы feedback получали нет не пострадают немножко они уже привыкли что я же попытался объяснить им постоянно добыча им а не будь всегда страдать в этом их проблем спасибо за доклад такой можно пару слов как еще вас модель в продакшн вижу то есть от некими к сервисы как ним почта там обращается вот как-то в этому заберу и весь этот зоопарк и как там несколько инстансов одной модели существует что нагрузку выдерживать у нас по-разному есть там тот случай когда это микро сервис чистый например там не знаю microserver спас текста микро service to name the entity recognition но они не живут в кубер найтись и и томские лиц и соответственно горизонтально тут все достаточно просто какие-то вещи у нас там работают прямо внутри там большого достаточно монолитного сервисы где важен там оптимизации некая не тратить там лишняя миллисекунда на сетевой запрос этом одну-две даже если там три секунды секунды работает какое-то вычисление это из них две миллисекунды и хочешь куда-то это не имеет очень большой смысл спасибо спасибо за доклад вы упоминали про классификацию неадекватность активности пользователей как вы измеряли мы получали тренировочную выборку вы где-то брали неадекватных не ну здесь очень просто так как фидбэк пользователи это по сути задан личное сообщение дальше мы их можем просто проверить и увидеть спам там или не вспомни ссср и какой процент у вас получился адекватных пользователей но у нас получается в данном случае это классификатор клика и там пользователи участвует как но его фичи участвует не то есть мы не знаем адекватные ли или нет напрямую когда у нас есть отдельные штуки produce ватных пользователь их там процентов 10 но они не так активно используются ну это спасибо верно посреди набор же rogue больше не про адекватность она тонн сколько их представлениям о конкретной работе классификатора совпадает с нашим скорее так адекватное от большинство пользователей на добрый день терехин александра скажи пожалуйста как вы боретесь или наоборот выступаете за конфидециальности этих данных которые вы обрабатываете я так понимаю это личные сообщения в том числе там всех ваших пользователей как вы их храните как вы храните выборки когда those in these работаю с орками и как вот вы там дабы не допускать чтобы их не выносили например из вашего офиса покуда я понял но для этого есть специальный отдел безопасности которые все время это нас дрочат не дает нам нечего делать вот как бы мы не хотели там посмотреть куда либо но те жалобы пользователей клики как они там прописаны в игре мы то что да нет то есть мы эти сообщения можем смотреть и мы на них смотрим но только на те которые пользователь прямой скала я даю фидбэк но все остальное естественно не как мы смотреть не можем это что рассказывал про сэмпла потока вследствие то в production in warm анти крутится в котором у разработчиков нету доступа там все это хранится в базах по высокие securities вся кишит этими шифрации так далее ну все как обычно добрый день на пред вот вы рассказали про такой паттерн мониторинга качества модели в кроме как сравнение историческими данными фактически пусть вы исторические данные принимаете как норму отклоняет них как аномалию а есть какие-то еще работающие паттерны которые вы используете этом мини там показу и там да ну например мы ориентируемся на то ну например мы смотрим если между пользователями переписка и мы считаем количество писем на которых мы сработали на которых был в терминах спама к примеру на письмах которые между которыми людьми которые была переписка предположительно это как бы не спам и это как бы очень хороший метрика если она очень сильно там практически 100 процентов коррелируют pool spa затем и вот это одна из таких метрик которые позволяют нам еще на старте до того как мы пустили в птс проверить по всем там отложим выборкам и понять как бы насколько на файзова это очень сильный признака достаточно спасибо огромное спасибо соответственно от тебя решение по поводу в красные вот это да а подарки от компании wargaming соответственно если у вас еще остались какие-то вопросы вы можете их задать в кулуарах спасибо большое спасибо"
}