{
  "video_id": "R304Xy5eTso",
  "channel": "HighLoadChannel",
  "title": "Увлекательное в повседневном / Артем Просветов, Анастасия Семенова (CleverDATA)",
  "views": 671,
  "duration": 2985,
  "published": "2020-04-14T11:29:04-07:00",
  "text": "добрый день меня зовут артем просветов и мы с моей коллегой анастасия семёновой представляем компанию клевер да это основной продукт нашей компании связан с монетизацией данных мы предоставляем платформу которая позволяет получать выгоду из данных и связать данные с сайта серым и других источников для того чтобы затем с этими данными эффективно работать это может быть эффективна и в маркетинге и в других областях в частности в рамках нашей деятельности на нашей платформе есть биржа данных через которую проходит больше ну или порядка 100 миллионов людей ежедневно масштабы уже впечатляющее и для того чтобы с ними работать нам не сильно приходится использовать множество современных техник и подходов для того чтобы эффективно выбрать сегмент людей например для маркетинговых кампаний необходимо знать о их интересах о том что их может зацепить и на бирже данных существует информация о том что человек интересовался например мототехникой или у него где-то был проявлен интерес к определенному виду спорта и для того чтобы эту информацию корректным образом хранить и определять на нашей платформе нам пришлось решить ни одну задачу и один из наших последних кейсов нам расскажет анастасия прошел спесивой артем да я расскажу про очень интересный ну и лично для меня я надеюсь на все это аудиторе кейс который мы назвали курс уроков волшебства для обычного когда я сначала расскажу в чем была задача в целом у нас есть какой-то потолка онлайн покупок и мы хотим чтобы с каждой онлайн-покупки с помощью какого-то черного ящика какого-то мида или там неважно какого то инструмента у нас получился заполненный профиль в принципе поток онлайн чеков что это такое пример чикаго мы сейчас видим на экранах вот у нас есть подобная покупка и каким образом мы можем представить в принципе покупателям мы решили его представить в виде вектора фактов интереса владения или увлечения то есть например представляем его в виде вектора где она каком-то конкретном месте соответствующим атрибуту таксономии типа наличие велосипеда или наличие велосипедного насоса или конкретной марки велосипедного насоса у нас-то это единичка на всех остальных местах 0 и естественно возникает вопрос если нам хочется носить такую задачу почему бы не попробовать методы он supra вас лёнинг или например не привести задачи лкм нога классовой классификации если есть какая-либо разметка и для это сантис то появляется желание применить хорошую большую сложную нейронную сеть например с трансформером или бертом для того чтобы максимально хорошо решить эту этот кейс на а сейчас я расскажу почему все эти первоначальные прекрасные превосходные интересные идеи к нашей задаче не очень-то и применим и потому что например да методов он супер во есть у нас не известно количество кластеров ну в наши таксономии 30000 атрибутов и если мы просто вслепую поставим на 30000 кластеров там какую-то кластеризацию там и скорее всего даже не сможем это смотреть обратно в наш таксономии ведь получившиеся кластеры вовсе не будут отвечать конкретно математика наших атрибутов вот но и тем не менее мы пробовали какие-то такие подходы в экспериментах и они не дали очень высокого качества ну в общем то даже это теоретически было несколько ожидаемо по поводу много- глаз с этой классификации мы уже на примере того насоса даже велосипедного видели что один человек может свидетельствовать о нескольких атрибутах ну и то есть вот в данном случае мы видим что у тебя мало того что есть телефон samsung galaxy s6 так еще у него есть и чехол для него еще конкретной марки или вот следующий случай когда в принципе то что что-то купленно для автомобиля марки чери это свидетельствует во-первых о том что у тебя есть автомобиль во вторых о том что он марки chery в третьих о том что этого человека автомобиль китайской марки ведь под разные гейси нам нужно использовать разную сегментацию вот по поводу еще раз идеи с одной большой и классный красивой моделью че архитектуры потому можно хвастаться на разных крупных конференциях вот почему нам это не очень подходит предположим у нас появился один новый атрибут и нам нужно всю эту гигантскую огромную машину обучать за нам это не это ну просто нереально на самом деле потому что атрибут может новый атрибут может появиться несколько раз в день может там нам понадобится как-то подтюнить какому-то атрибуту модель ну неадекватный подход поэтому я решила строить на каждый атрибут свою модель бинарной классификации вот то есть какой план план совершенно очевиден мы берем множество текстов соответствующие тематике и не соответствующие тематике какого-то конкретного атрибута и строй модель данной классификации и на этом этапе возникает планомерный вопрос а где же взять разметку если разметки у нас нету это конечно замечательно пресс вот есть разные подходы как нанять разведчиков или вас пользуются какими-то сервисами вот но мы очень любим изобретать свое и соответственно мы решили просто обратиться к поисковой системе искра улиц поисковую выдачу по какому-то конкретному запросу теперь такой вопрос и что же нам отправлять в таксономии но его в поисковик если у нас есть рука таксономия этого просто будет несколько мало и мы приняли решение о комментировать наши тексты тексты нашей таксономии и затем их отправить уже в поисковик и скроллить войсковую выдачу по а комментированием атрибутом как будем аргументировать ну мы воспользовались перед обычными деньгами mb денги это отображение из пространства софт расстройства векторов некоторой фиксированной длины в котором близкие по смыслу сама находятся близко друг с другом по метрике данного пространства но далекие по смыслу соответственно находятся далеко как конкретно работает на шоу комментатор вот предположим рассмотрим такой атрибут как интерес к мистическому жанру кино и мы видим какую как у нас получилось аргументировать его конкретно эта этот механизм работает следующим образом мы берем имя атрибута нашей таксономии превращаем его понятное дело список слов и убираем ненужные не информативной слова ну таких мало они достаточно легко находятся по просто фильтрации почувствовать там наши таксономии потом мы берем случайное подмножество слов ну там проходимся просто simply ruim как какой-то какие-то выборки из этих слов и склеиваем синонимы в пространстве им беден гав с тем словом которые не попала в эту под выборку и вот например если мы взяли жанр и кино и для него a simpler овале синонимы и склеились со словом мистический то мы получим такой вот выборку по результату этой все процедуры к интересу к мистическому же андрогенов мы получили вот такие у комментирование тексты которые мы потом будем отправлять поисковик как мы подбираем негативную выборку ну то есть отрицательные какие-то примеры просто посчитали какое количество строк у нас получилось после у коммендации и поэтому количеству из таксономии выбрали все не относящиеся к тематике к выделенные тематике атрибуты то есть ну вот нормальный в общем-то запросы не относящиеся ни к к теме мистического кино как мы будем обучать и что мы будем отметить обучать ну начинаем с какого-то breeze line а это dff la грек отфильтровали спустили гроттерши и что же мы получаем метрики близки к единице и а то очень сильно напоминает переобучение выглядит подозрительно не так ли да выглядит весьма подозрительно рукава к единице это просто что-то нереальное как будто мы где-то ошиблись на самом деле при обучении нет потому что действительно вот на примере модели которая определяет владельцев техники а игр мы видим что все сработало хорошо действительно у нас вестей есть слово и бы ввести это техника и все прекрасно но конечно не все случаи такие замечательные да есть один из моих любимых примеров это автомобили газ горьковского автомобильного завода нас в выдаче нашей модели попалась вот такая под строчкой ну что же нам с этим всем делать теперь вы собственно то что дало нам название данного кейси случился как-то у меня такой момент я решил построить интерес модель интереса к дополнительному образованию а именно курсом профессиональной переподготовки и случился вот такой вот вот конкретный в жук просто когда я увидела строчку про курсора к волшебства для обычного когда лично я как бы понимаю модель потому что по набору слов это очень и очень похожа на курсы профессиональной переподготовки но это похоже по набору слов но вовсе не похожи по смыслу и даже по тому какие то сказала уже понятно что мы можем опять обратиться к embedding мы решили замерить ввести еще такое такой дополнительный как параметр хочу это расстояние до центра положительного класс который мы с кроули ли в пространстве им митингов и заметили что действительно очень хорошо отделяют ложные срабатывания то есть которые близки по словам но далеки по смыслу именно порогом расстояние до центра во положительной выборки также это вот хорошо заметно на примере владельцев автомобилей audi футболка и цитрат никак не свидетельствует о том что у человека есть audi масляный фильтр говорит о том что наверное этого человека можно и предлагать закрылки audi вот дальше встает такой хороший вопрос у нас 30 тысяч атрибутов просто вот посадить там меня моих коллег заставить строить 30 тысяч моделей это не не очень адекватно значит нам нужно каким-то образом автоматизировать наши процессы на данный момент что мы делаем мы я напомню берем просто короткий текст атрибута из нашей таксономии а у коментируем отправляем это в поисковик раулем выдачу обучаем на этом логистическую регрессию с метриками близкими к единице и фильтруем выдачу по расстоянию до центра положительного класса в пространстве maiden гав слабые места pipeline а то что но это на самом деле не автоматическая ситуация мы видели ну мы не знаем что именно мы на самом деле scrawl'а ли мы это все не читаем своими глазами и не знаем что туда попадется значит нам нужно выбрать какую-то метрику которая говорит нам этом хорошая модель или плохая у нас модель будем придумывать что-то свое собственно как нам оценивать качество нашей модели со стандартные метрики не информативны мы видели рока лук единица f1 единицы ну это конечно связано с тем что мы смотрим качество на 1 выборки для бизнеса важно качество на друга на другой выборки на который мы не знаем правильных ответов и значит нам нужно как-то померить распределение и понять их разницу и когда возникает такой вопрос естественно обратиться к дивергенции кальбуко лейбле ра ну да то есть вот мы возьмем зафиксируем произвольный порог логистической регрессии и рассмотрим расстояние до центра положить иного класса 18 в деньгах для тех строк которые перешли порог логистической регрессии и для тех которые не перешли этот порог конечно конечно просится дивергенция коль поколеблено давайте я 1000 раз наверное всем покажу этот замечательный функционал который на самом деле не является метрикой поскольку там не выполняется 2 аксиома метрики поэтому потенциально мы должны быть готовы к тому что эта вещь может не сработать то есть это не критерий ну и действительно дивергенцию как бокале блэра всюду показала 0 то есть разницу этих распределений она не уловила ну вернемся к распределением посмотрим на них внимательно и померяем и расстояние между и в средними в cig мах общего распределения расстояние до центра этой выборке вот мы назвали это z метрикой и выглядит это таким образом собственная идея какая давайте мы посмотрим на то как вид у тебя метрики для хороших и для плохих моделей и научимся в каким-нибудь простым решающим правилам определять какая модель хорошая какая плохая то есть автоматизируем этот процесс полностью ну вопрос видно ли где и здесь хорошие модели или плохие я не пронаблюдал они как будто есть простой решающие правила не не получилось найти и вот такой теперь ужасный сценарий это попробовать определить например вот эта модель хорошая или плохая мы видим за от метрику равную 10 то есть в 10 средне квадратичных отклонениях находится средний квадратичных отклонениях исходной выборки расстояние до центра положительного класса находятся наши распределения но казалось бы чем больше тем лучше они отлично разделяют с чего еще нужно но на самом деле эта модель плохая и и помню прекрасно и она мне добавила несколько вот удивительных моментов просто моей жизни это модель должна была определить наличие у человека интересы к путешествию в таиланд то что мы делаем мы берем там текст без таксономии там комментируем отправляем поисковик но и мы радостно совершенно с краули или просто объявление всех spa-салонов и путешествие в таиланд и модель действительно научилась очень хорошо отделять класс посещения спа-салонов от всех остальных людей но на самом деле это никак не отвечая тому что человек действительно хочется вообще собирать ездил в тайланд или еще ну в общем это модель плохая простого решающего правила у нас не получилось но здесь уже сыграл роль то что мы хорошо лагера вали нас и эксперименты же время всех этих экспериментов пока я надеялась на простой решающие правила мне придет замечательная идея о том что там ли папой рок подавлять либо еще что то мы набрали достаточное количество разметки для того чтобы обучить мета модель мы выбрали guy in градиентный busting и он показал себя очень хорошо то есть мы на основе на основе рядов поведения z метрики которую мы ввели обучили модель которая умеет определять хорошая модель к была построена автоматически или плохая какие профит и мы от этого получили мы у нас всего лишь была одна таксономия то есть какой-то набор так стиков в единственном экземпляре и мы умеем строить любое наперед заданное число модели бинарной классификации по интересов по интересам людей и при этом мы экономим собственное время моральные силы нас разработчиков и полностью смогли автоматизировать этот процесс какие выводы я советую не отказывается от супер вались даже если у вас нет разметки то есть разметка необязательными делать руками можно придумать какие-то лайфхаки для этого всего дела будет и не нужно стыдиться мистических регрессии ничего в них не всегда это плохо эта модель из статистические они устойчивы и в общем если они показывают хорошие метрики то почему бы их не использовать и ну и советую вам хорошо записывать результаты ваших экспериментов потому что вы возможно вы формируете новые обучающую выборку в теперь я передаю слово артему благодарю я хотел бы рассказать вам про еще один наш кейс который был связан также с поиском альтернатив для обучающей выборке в этом кейсе к нам обратился наш партнер с задачей у этого партнера было множество от текстовых описаний изделий изделий технические там например могли были быть болты и гайки шпильки с их параметрами это размеры это вид резьбы это госты и так тому подобное потребность была в том чтобы идти все текстовые описания и сырого вида перевести в табличный вид чтобы были выделены ключевые параметры для этих изделий и для этих параметров извлечены их значения из этих текстовых описаний поэтому задачу мы разбили на две подзадачи во первых нам нужно было понять какие параметры ключевые а во вторых нужно было найти как извлекать эти параметры из сырых текстов таким образом выглядит текстовые описания этих изделий то есть мы видим в них могут быть ошибки в них могут быть лишние пробелы или отсутствуют где-то пробелы разделители не всегда есть и часто они могут быть непредсказуемого формата ну в общем это вроде как случай хотим и что использовать просто регулярке именно так если использовать гипотезу о том что ключевыми параметрами являются те тексты которыми одно изделие отличается от другого изделия и в то же время эти же самые параметры должны встречаться в множестве других изделий там и прямым образом приходим к регулярным выражением и этих регулярных выражений в принципе может быть достаточно для того чтобы скомпоновать параметры даже 2 двух уровней верхнего уровня это например комплектация расширенная у изделие и параметр более низкого уровня чем именно конкретно расширена эта комплектация в данном случае в комплекте с гайкой изделие и сколько еще получилось у нас регулярных выражений для этой задачи для наших целей нам предоставили 6 классов изделий и для них мы нашли примерно 200000 регулярных выражений 200000 параметров всего строк которые мы анализировали было порядка полумиллиона но это была небольшая под выборка из того что потребуется потом заказчику классов если мы использовали 6 в данном случае то в продакшене планировалось использовать их несколько сотен соответственно на каждый текстовый фрагмент нужно про потратить огромное количество операций слишком много патронов слишком много текстов с этим надо как-то справляться и для того чтобы с этим справиться мы решили обратиться снова к машинному обучению мы сделаем рекомендательную систему для текстов для того чтобы каждому тексту рекомендовать соответствующий этому тексту паттерн соответствующий этому тексту регулярное выражение здесь мы обратились к уже практически классическому подходу deep semantics емеля реки моду в котором тренируются 2 нейронные сети одна из которых относится к тексту 2 из относится к шаблону на конечном этапе они имеют общий слой в котором происходит измерение дистанцией между тендера мест обоих этих неровных сетей это может быть косинус на расстоянии и таким образом мы определяем это хороший паттерн или плохой паттерн для этого текста этот подход в рекомендательных системах используется широко и мы неоднократно его сами использовали в других наших проектах но у нас есть проблема если мы хотим строить рекомендательную систему нам нужно разметка а переход от текст во описания к конкретному шаблону с конкретными параметрами весьма затруднен даже если мы регулярными выражениями нашли некоторые шаблоны которые срабатывают на всей совокупности текстов это не значит что в конкретном кейсе этот шаблон сработает что же сделать если прямой путь затруднен мы можем пойти в обратном направлении мы можем взять те шаблоны которые мы нашли мы легко можем посчитать частотность их взаимо встречаемости и мы на нашем дата сайте видим допустимые значения параметров для этих шаблонов а значит мы можем сгенерировать сами эти тексты которые будут максимально близки к элис реальным текстом и даже внести какой-то свой шум который нам захочется после тренировки такой рекомендательные системы мы как минимум на два порядка снизили количество операций на каждый текст в некоторых случаях возможно и больше это сделать но важнее лишний раз проверить подожди подозрительный паттерн чем его пропустить и вот что у нас получается если у нас есть пример со шпилькой сейчас вот пример со шпилькой с гостами и такими параметрами наша система распознает что срабатывают следующий набор паттернов они относятся вот сработали из-за того что есть слов комплекте с гайкой среагировали на сложные произносимый параметр и не среагировали на ост теперь следующий этап нужно извлечь из текста описания параметры но если мы знаем уже конкретную форму что мы должны извлекать нам легко это сделать из текстов мы точно знаем какой формат нас ожидает в этом текстовом описании нам нужно только извлечь цифры а это делается достаточно просто тоже регулярными выражениями все на одном хорошем примере теперь конечно срабатывает не идеально но срабатывает в большинстве случаев если мы возьмем набор шпилек для этих шпилек есть общие параметры какие-то из них с гайками мы проводим этот набор шпилек через наш алгоритм и получаем плоскую таблицу в которой мы по наличию гайки можем выделить ряд изделий ряд шпилек то есть именно этого и требовалось достичь для реализации проекта что хочется отметить пусть после того как мы эти проекты завершили что конечно нельзя отказываться от хорошего качества и уходить от супры васюник как он супер вас лёнинг но требуется контролировать качество с экзотической выборки это если качество если синтетическая выборка из поисковика его нужно контролировать например модели на основе митингов если это выборка сгенерировано нами мы должны тщательно контролировать как она генерируется и шумами заниматься тоже тщательно и помнить старый принцип горбачев горбач out и смело экспериментировать можно даже классические простые подходы применить в сочетании с новыми подходами и получить вполне хорошие результаты на этом спасибо у меня сосед давайте ваши благодарности благодаря и давайте перейдем к вопросам просто спасибо за доклад у меня такой вопрос вот вы говорили что для того чтобы разместиться до насколько вы брали результаты каролингов google так не обязательно гугла google google в принципе может препятствовать и crawling он во первых он препятствует crawling а во-вторых мне вот интересно было если вы с гугла или яндекса как вы учитывали еще гео-локацию геотаргетинг потому что они берут это ну как бы отслеживают и третий момент что выбрали из и скролинга это органично выборку результат до или все-таки рекламный результат мы проверяли присутствие рекламы выборки и в частности сравнивали выдачу с поисковиком дуг дуг в котором как раз нет коммерческой выборки хорошо тогда сразу в догонку как вы учитывали то что google во первых тут как раз вы является то что при геотаргетинга он учитывает и и пи адрес ваш и перестает выдавать рекламу с учетом того как бы региона где вы бы хотели ее получить и второй момент что через запросов он перестает он выдавать рекламу если вы не ведете себя как человек да поэтому нам пришлось во первых не подавать на поисковик сразу всю нашу таксономия делать это постепенно во вторых делать это тщательнее и контролировать то что мы подаем поверит эта система случайных задержек то есть для для того что на самом деле очень интересно получить рекламную выдачу потому что нам как раз нужно иметь в виду о те продукты которые люди покупают в рамках какого-то интереса который описан абстрактно нам нужно в первую очередь чтобы данные были очень вариативные и за счет того что у нас нету конкретного конкретной привязки геолокации у нас получается еще более вариативная выдача то есть это работает нам на руку скорее чем против нас чем больше уникальных слов чем больше уникальных терминов в этих данных тем лучше если мы получим одинаковую выдачу ну как например было со спа салонами да и связанными с гео-локации например в москве спа салоны в москве то у нас будут выдача будет почти 1 брат практически однообразная но это это важная тема и мы действительно перед тем как это делать мы исследовали этот вопрос и проверяли можно ли так поступать 3 а наша задача стоит нельзя всем этим а так как вы представляете себя нам не обязательно отразить этот вопрос вообще перейти потом в дискуссионный зал и предлагаю уже в следующем задать вопрос спасибо большое за доклад вот вы в первой части в конце его сказали что их же буста сработал хорошо а по каким метрикам вы это оценивать не могли бы поделиться она да конечно поскольку задач классификации очень нравится и я думаю не только мне метрика рука лук обозначения интерес метрики или нет именно сама метрика потому что до этого вы говорили что это довольно сложно оценить качество хороший плохой мы изобретали было интересно мы вручную можно сказать набрали 3 метку в результате экспериментов то есть условно некий абстрактный dat ass on this сидел и смотрел хорошая выдачу модель или плохая то есть и именно в человеческой интерпретации хорошо работает моделью или плохо это документировала на основе у значение z метрики то есть у нас есть просто вот показатель который представляет собой там разность между двумя распределениями записаны по шагу 5 сотых в пороге логистической регрессии то есть мы это сняли для каждой модели вручную отметили хороший класс или плохой я бы чилик же boost который отличает хороший класс модели от плохих с метрикой рока лука то есть мы оптимизировали в данном случае рука лук можно я попробую ответить то за прокомментирую у нас до сильно была проблема в том что понять хорошее качество или плохое на сырых данных потому что на них нет разметки а обучение мета модели мы провели не на этих сырых данных она результатов наших тестов то есть мы знали уже те модели которые сработали те модели которые не сработали и могли уже сравнивать метрики на этом дата сайте то есть все таки это основано на экспертной оценки тест выборка на который вы строили на который строя также пусть дано экспертные оценки но это лестно называть нас работа экспертной потому что она основана на наших тестах на том как мы считаем сработала модель или не сработало но в принципе так тоже можно назвать да именно таким как вы примерно объем покрытия то есть приблизительно сколько у нас была строка для обучения как же просто порядка 160 спасибо большое спасибо здравствуйте у меня вопрос о первой части доклада вот вы когда обучали логистическую регрессию какой у вас был баланс классов баланс класса положительного классе приблизительно 40 процентов ну да есть это не неровный но от 40 до 50 процентов то есть в целом выборка считалось сбалансированный и за счет этого не приходилось каким-то образом потягивать параметры баланса вот спасибо ну это вопрос собственно был к тому что было подозрительная качество единиц я думал может быть большой перевес и я поняла констант надо то есть нет ни константный просто рука у он чувствителен к балансу классов поэтому у меня возникло подозрение же не может быть мне не выдал дело дело как раз в том что мы сравнивали сильно разные тексты то есть это нормально что они очень хорошо разделялись просто мы-то модель когда будем отправлять в продакшен там не сильно будет отличаться тексты по тематике и поэтому нужно проверять адекватность модели спасибо за вас заклад следующий вопрос правильно ли я понял что у вас не было размеченных данных и вы разметили их сначала сами потом построили модель ну на которые получили рутуб единиц как бы отчасти да у нас не было размеченных данных но данные мы старались не размечать самим и данные мы сформировали тренировочную выборку и разметку на основе какого-то подхода машин на основе машинного обучения ну то есть вы построили нету свою модель на основе который вы разметили и потом сделали новые модели получили русалка единицу возникало ли у вас мысли что ваша модель просто обучилась тому же принципу на основе коту вы размещали ваш выбор давайте немножко еще раз тогда проясним workflow стоп потому что в нем очень легко заплутать смотрите тренировочной выборки не было часа сейчас мы до пеппой над листаем вот тренировочной выборки у нас нету для набора текстов покупок мы строим мы хотели бы например это сделать с помощью какой-то языковой модели но языковые модели не срабатывают в этом кейсе они оказываются недостаточного качества поэтому мы строим alt какую-то альтернативу мы караулим собираем каким-либо образом такой да по сайт который позволяет разделить модели 1 класс а вдруг от всего остального отделить то есть мы не вручную делаем разметку почему модель не учится тому что научилась другая модель потому что вторая модель работает на другом принципе то есть в первом случае это ловко регрессия во втором случае также пусть вторая модель работает на других признаках потому что в первом случае она работает на словах во втором случае она работает на основе статистических метрик типа z метрики или каких-либо еще параметров и кроме того она сравнивает не результат раб она получается выдает результат качество выдачи 2 первой модели она оценивает качество выдачи они пытаются решить ту же самую задачу то есть целевая функция у неё у второй модели тоже отличается от первой модели нет когда вы получали русалка единицы a rock rock оука единицу мы получили когда мы взяли простой тв и df да и агрессию применили на определенных текстов которые мы сами с караулили вот там получился получилось метрика равна единице по которому вы не это не второй модели это как раз в первой модели rocca ук единица на отложенной части тренировочной выборки на валидации онной тренировочной выборки у которой мы знаем ответы и этот это качество когда мы про исследовали этот вопрос у нас естественно сразу возникли подозрение что здесь что-то не так это качество легко объясняется тем что модель тренируется на определенных словах она находит быстро определенные ключевые слова которые присутствуют в текстах и за счет вот этих вот ключевых слов она легко отделяет тексты определенной тематике от произвольных текстов одну и ту же модель да у нас не была моделью для разметки у нас алгоритм для генерации выборки ну то есть там простой достаточно pipeline когда мы находим для слова синонимы и отправляем это в поисковик и собираем выдачу вот таким вот образом мы сформировали обучающие выборку для этой модели просто за счет того что текста в очень разных тематик это абсолютно нормально что у нас метрики получились близкими к единице в связи с тем что классе различаются очень сильно то есть например максимальный расходятся последний месяц это одна строчка которая была отправлена в поисковик и другая строчка это купить билет в кино вот и поэтому текст и очень сильно различаются и модель очень легко отличает эти два класса поэтому это абсолютно нормально и что у модели метрика раковка единица и и стеснять никакого переобучения спасибо но человек за тасс последний вопрос и здравствуйте спасибо за доклад меня 2 вопроса по первому так просто интересно сколько вы потратили времени чтоб собрать данные стучать стучась в поисковик и не проще ли было купить какие нить уже готовые поисковые лаги там тот же similarweb и второй вопрос про второй пример вот вы собрали точнее разделили там большое наименование вот на часть его на маленькие части но выглядит так что вы не по нему но смысле не понятно что вы получили что эти части означает неужели заказчик и ты хотел так еще раз второй вопрос что заказчик хотел именно такую таблицу плоского что здесь получилось заказчик хотел инструмент который позволит быстро находить изделие с определенными параметрами в частности бизнес потребность была такая заказать например шпильки с гайками с расширенной комплектации в комплектации с гайкой определенной резьбы после того как сформировано подобная таблица плоская можно выделить только те изделия у которых есть комплектация гайки с гайкой про гайку понятно вот например что из этого размер на и тоже непонятно размер на так по столбцам изделие по строкам параметры и на что вот можно обратить внимание есть сложные параметры например где есть а.м. численная величина x другая численная величина есть более простой параметр который казалось бы входит в подмножество вот этого сложного параметра то есть такие вещи возникают для этого шаблона у нас извлекаются следующие случаи для от изделия 1 1 численная величина 42 2 численная величина 415 то есть именно благодаря такой плоской структуры удается быстро находить те изделия которые нужно заказать например так и первый был вопрос да если внедрили повторите по жести первый вопрос она crawling сколько времени потратили на crawling чтобы скрывать все данные которые были нужны наших экспериментов понадобилось ну где то наверное нон-стопом неделю три четыре вот так вот в это время шли эксперименты и ничего мы не ждали crawling ну краудер и это был параллельный процесс а почему мы не могли купить данные у нас достаточно четкая таксономия и она иногда включает в себя экзотические параметры например профессия сельский староста казалось бы редкая вещь но возможно кому-то она важна и логии пск века по запросу сельский староста конечно не будут продаваться давайте теперь выберем вашему мнению самый лучший выпуск про девушки хорошо . поздравляем спасибо"
}