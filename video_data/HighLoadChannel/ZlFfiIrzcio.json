{
  "video_id": "ZlFfiIrzcio",
  "channel": "HighLoadChannel",
  "title": "One-cloud — система управления дата-центром в Одноклассниках / Олег Анастасьев (Одноклассники)",
  "views": 1456,
  "duration": 3335,
  "published": "2018-08-16T04:06:40-07:00",
  "text": "всем добрый день меня зовут олег анастасьев и я работаю в компании одноклассники в команде платформы кроме меня в одноклассниках есть очень много железом у нас 4 дата центра в этих дата-центрах с размещены 500 стоит где-то и в эти стойки понапихано около 8 тысяч серверов почти все эти серверы работают под управлением операционной системы linux и кроме меня с этим железом работают еще следующие люди инженеры работают непосредственно в дата-центрах и меняют допустим диски и другую работу с оборудования производят сетевики настраивают сеть администратора занимается автоматизацией инфраструктуры ну и собственно разработчики у них они на самом деле не одна такая большая серая масса они поделены на функциональной команды разработчики делают и выкатывают на продакшен софт который работает как то так запросы пользователей поступают на фронты или на фронт основного портала или на другие фронты например здесь фронта api музыкального сервиса для обработки бизнес-логики они делают запросы на applications and applications сервер уже распределяя запросы по каким-то сервисам которые могут владеть данными и которые собственно формируют ответы который нужен для обработки каждый из бизнес запросам и у каждого такого сервиса есть кто-то ответственный разработчик который отвечает за его функционирование и развитие и эти сервисы запускались на жилете и да не бы долину до недавнего времени это выглядело как то так на один сервер был специализирован под выполнение ровно 1 задач почему так ну во первых это просто в массовом управление допустим задачи требуют каких-то определённых библиотек каких-то определенных часть этого настроек и тогда можно приписать это сервер к определенной группе сформировать для нее политику всех инженер и в массовом порядке раскатать эту конфигурацию это просто так же в диагностики мониторинге тогда глядя на то как потребляются ресурсы конкретным сервером дав как элиза пикси вы точно знаете что в 90 процентов циpкa сажала 1 вот эта конкретная задача в они тоненькие тоже полезно потому что можно настроить тогда единообразно мониторы на какие-то сколы и чтобы они срабатывали как и тогда сервису который состоит из многих реплик просто выделяется какое-то количество серверов и с этой точки зрения ресурсы распределяются вычислительный ресурс из поделиться очень просто сколько у сервиса и железо столько он и может потребить а здесь просто не с точки зрения что это легко администрируется с точки значит достаточно тупо ну а это позволяло нам сделать какие-то специализированные hour вольны и конфигурации ну допустим если у вас есть задача которая в первую очередь работает как большое хранилище например вот как-то рассказывал саша христофоров то поднимают собирается железка на 4 он обитает там 38 дисков не стоит если же задача в первую очередь вычислительная какая-то дата используется более дешевый один вариант и и это эффективно с точки зрения распределения вычислительных ресурсов в то это позволило нам допустим по сравнению с одной дружественной нам социальные сети иметь в 4 раза меньше машин при сопоставимой нагрузки мы также считали что поскольку это эффективно по вычислительным ресурсам то это и экономически эффективно исходя из посылки что самое дорогое это сервера и долгое время самым дорогим в нашу и starting люди была цена собственно железо и мы только вы работали над тем чтобы снизить стоимость закупаемого железо как реализации определенных алгоритмов и отказоустойчивости в совке так и и это позволило нам покупать машины с пониженным уровнем надежности сейчас мы дошли до стоить стадии когда цена сервера уже не является определяющей и сейчас на первый план у нас выходит цена место в стойке самое дорогое это место которое сервер занимает стойки дата центра если не брать какой-то распоследний экзотики нам практически все равно что в эту стойку засунуть ну естественно поскольку сама и мы поняли что самое дорогое для нас сейчас это стойка место то мы решили давайте посчитаем утилизацию этого места то есть если бы мы допустим в этом место поставили более мощные сервера в эти стойки и продолжали бы использовать по одной задаче ночами вот эту самую модель на тос да сколько бы мы эти стойки могли утилизировать нагрузить посчитали прослезились утилизация оказывается на уровне 11 процентов то есть практически девять десятых нашей мощности или наших стоек просто греют воздух вывод очевиден нам нужно повышать утилизацию стоит давайте попробуем повысить это по-простому на одном члены запустим теперь много задач и тут все становится очень сложным потому что конфигурация резко усложняется теперь невозможно один сервер приписать какой-то одной группе какой группе приписать если там разные сервисы запущенный разных функциональных команд вообще строк говоря не понятно кроме того эта конфигурация может быть конфликтующие одному нужно одни сошки другому трубы и сошки все то все уже очень сложно усложняется диагностика тебе глядя на загрузку циpкa и дисков допустим невозможно понять отделить одну задачу от другой если что-то идет не так раз летом я такого инцидента усложняется ну и главное что между задачами запущенными по простому на одной машине нет изоляции что это такое допустим у нас есть какая-то задача с короткой задержкой и она работает на машине и мы рядом запустили какую-то другую задачу который что-то там считает вот здесь вот на графике как раз видно вот эффект который оказывает на задержку такой задачи с короткой задержкой запущенная рядом просто вычислительная задача понятно что задача с короткой задержки и и задержки они деградируют очень сильный ответ очевиден нужно запускать задачи либо в контейнерах либо в виртуальных машинах ну на самом деле выбор у нас довольно был между виртуальными машинами и контейнерами но поскольку все почти все восемь тысяч шаров работают под управлением linux и все задачи которые на них запускается уже адаптированы под linux то расходовать ресурсы на поддержку виртуальных машин понятно неэффективно поэтому мы вы выбрали контейнеризации как технологии в качестве машины нужно но в качестве engine машина на которой мы делаем то новеллизацию докер оказался неплохим из кандидатов проблемой конфликтующих конфигураций хорошо решаются в докере имиджа me у него есть образы файловой системы для этого и они разбиты на разные слои свои улучшают кэширование общих частей имидже предложения тогда мы можем выделить какую-то общую часть имиджа в отдельный слой и тем самым улучшить каширу и масть этого слоя на многих многих миньон атаки и registry можно использовать как примитивы доставки и versio нирования кода на продакшен на самом деле мотать и мультиплеерные или многослойные файловой системы это довольно критичная для нас часть и во многом она склонила наш выбора в сторону докер но киль также как и любая технология контейнеризации обещает нам изоляцию контейнеров ну во-первых изоляцию папа нити каждому можно определить ту память которую может разрешенный лимит памяти выше которого контейнер мне может потребить это хорошо работает можно также изолировать и по использованию цифру тут правда не так все хорошо как находится в рекламном как написано в рекламных буклетах докер да и об этом я расскажу немножко подробнее позже часть проблем с непосредственно на машинах мы решили но из другая часть проблем это непосредственно размещение контейнеров на сервера то есть мы должны распределить все все имеющиеся у нас варианты контейнеров на сервера так чтобы эти сервера были с одной стороны плотно упакованы по ресурсам то есть использована как можно больше ресурсов конечных машин но при этом это бы не производить не приводило к деградации их производительности кроме того это размещение может быть достаточно сложным нам нужно учитывать стойки в которой стоят эти машины или зал и да с точки зрения обеспечения отказоустойчивости то есть если падает допустим стойка мы не хотим потерять все реплики какого-либо сервиса или зал кроме того естественно что если у вас есть с одной стороны 8000 машина с другой там 8 или 16 тысяч контейнеров то вручную их как-то распределить это достаточно муторная задача и понятно что для нас это был в общем-то не вариант с другой стороны мы хотели сделать так чтобы выделение ресурсов на проект на для чтобы разработчики могли сами размещать свои контейнеры на продакшене с этой стороны мы хотели дать им больше самостоятельности чтобы не нужно было каждый конкретный контейнер чтобы подключался администратор и распределялась по каким-то машинам но женой стороны мы хотели сохранить какой-то контроль чтобы какой-нибудь второстепенный допустим сервис не потребил все ресурсы production ну тут очевидно что нам нужен какой-то управляющий слой который автоматически все эти требования выполняет и тут мы приходим к простой схеме с тремя квадратиками так обожаемые архитекторами разработчик отправляет мастеру манифест в котором информация нужная для запуска сервиса он отправляет его в отказоустойчивый кластер на мастеров фанк low to master на основании этой информации дает команду выбранным миньонам то есть машинам использующимся для запуска контейнер команда поступает в наш агент ван клауд миньон д который на основании команда коммуницируют стокеру которую свою очередь конфигурирует кернел для запуска контейнер с миньонами пока все понятно что может быть проще вот этих трех квадратиков ну на самом деле нет все оказалось значительно сложнее да но давайте разбираться показа задачей более сложный это распределение ресурсов множество миньон ну для начала давайте поймем что же такое для нас ресурс несколько это количество вычислить не мощностей центрального процессора который контейнер может потребить и то есть у всех памяти понятно тоже очевидно кроме того для нас это еще и трафик это редко используется это часто опускается в готовых уже системах управления дата центрами но трафик это тоже конечный ресурс и потому что на коней на конкретной машине есть конкретный пропускной канал там 1 гигабит или 10 гигабит и он тоже кончается нельзя просто так размещать контейнер вторая часть для нас это диски опять же кроме собственно места на дисках мы еще выделяем такие ресурсы как тип этого диска они разные есть хдд есть ssd они ведут себя совершенно по-разному нельзя просто распределят место и и abs и то есть сколько эта задача потребляет собственно и а псов на диске и тогда мы можем для какого-то сервиса записать вот мы не в манифесте вот такой приблизительно требования ресурсов хотим полторы тысячи кора хотим полтора терабайта памяти хотим 32 гигабита туда-сюда и под сервис мы выделяем 20 хдд по 15 понятно что ресурсы конечно а это значит в нас тоже конечные ресурсы это значит их нужно ограничивать как-то то есть на что-то нам нужно навесить какой-то лимиты но на что давайте еще раз посмотрим на вот эту принципиальную структуру она какая-то такая да но она слишком упрощенная давайте перерисуем эту схему на более понятную вот какую то такую тут уже первое что бросается в глаза что на самом деле веб и музыка используют разные кластера одного и того же приложения applications сервером второе что бросается в те самые глаза и то что мы можем выделить на самом деле логические слои к которым эти кластера относится например вот фронты вот кэш а вот и база данных нужно ли еще что то выделять видно что фронт неоднороден у него там разные функциональные системы вот это веб то есть основной портал одноклассники ru а вот этот фронт относится к относится к музыке это он используется только для музыки каши тоже можно поделить по под системе данные которые они каши вы давайте перерисуем эту картинку уберем из нее квадратики и мы получим вот что-то типа такого на вот у нас веб вот музыка вот музыка вот api вот крыши на самом деле мы разделяем веб на несколько групп потому что это довольно большая группировка серверов и для удобства управления мы разделяем на несколько групп ничего не напоминает что такое картинка это ираке и тогда мы для того чтобы ограничить для того чтобы специфицировать какую-то можем назначить на какой-то узел от иерархии ответ снова программиста да и ограничить использование на уровне этой рахи ресурсов навесив на этот узел к вот давайте уберем все эти линии да и тогда мы можем записать все эти имена более плоско group 1 vip фронт api music фронт и cash cash таким образом мы приходим к понятию иерархической очереди у нее есть имя вот она мне и навешиваются квоты на ресурсы например такие на неё также навешиваются права пользователя допустим для какого-то пользователю который больше разработчик дается право на отправку сервисов в эту очередь к какому-то другому человеку который operations и админ даются административные права на это на эту очередь то есть он может добавлять и удалять оттуда пользователя и в эту очередь собственно отправляются сервисом и эти сервисы они выполняются в пределах квоты то есть если разработчик нас отметил кучу сервисов и квоты ему не хватает то они будут выполнены в этой очереди по очереди от один за другим отсюда собственно понятия очередь и понятно откуда эротической давайте посмотрим на сервис у сервиса тоже есть имя и она вот какое-то такое она включает себя имя очереди у сервиса также есть манифест в котором описываются ресурсы которая потребляется этим сервисом какой-то конфигурация которую нужно чтобы этот сервис чтобы экземпляры два сервиса запустить на миньонах и там же описывается какие тарификации ну и какие-то атрибуты связанные с отказоустойчивость это все кроме того у сервиса есть еще экземпляр то есть это они появляются тогда когда сервис непосредственно необходимо непосредственно разместить уже на машинах и этих экземпляров тоже есть те которые получаются очень просто или за pr и дальше имя сервис теперь давайте более подробно посмотрим что же эти за экземпляра какие задачи собственно эти экземпляры выполняют в одноклассниках как наверное везде есть следующие три класса задач первый класс это задача с малой задержкой мы называем их прод это задача для которых очень важна скорость за которую каждый индивидуальный запрос был обработан то есть задержка примером таких задач могут служить все виды кэш и все что угодно критичности роста раджан высоко нарушены это все прут другой класс задач это расчетный batch здесь уже скорость обработки каждого конкретного запроса не так важно здесь важно именно то сколько вычислений за привезенный большой промежуток времени это задача сделать это различные мапри deus и машин learning и к эта статистика и так далее третий класс задач это фоновой задачи они очень похожи на расчетные с той позиции что неважно как быстро отрабатывают каждой конкретные запросы да но с другой стороны это такие задачи где нам в общем неважно и за сколько времени мы обработали эти задачи в итоге то есть это какие-то тесты это какие-то конвертации пересчет и и так далее теперь давайте посмотрим как эти задачи потребляют ресурсы машины начнем спрут задачи это задача с малой задержкой и потребление паттерн употребления циpкa у них какой то такой то есть задача получила запрос взяла рис ресурсы циpкa быстро отработала вернула ответ потом ждем следующего запроса когда он поступит поступил следующий запрос быстро отработали вернулись снова ждем пока сын поступят следующий запрос таким образом чтобы гарантировать скорость отработки запросов мы нам нужно гарантировать что задача в любое время получит свои вот эти четыре коры в данном случае то есть мы должны зарезервировать эти четыре коры на машинах миньонах тогда формула резервации будет выглядеть как-то так мы хотим циpкa 4 кормит по максимуму и тогда если у нас есть к этого допустим миньон вот у него 16 core и мы тогда очень просто размещаем машины на сервер а вот одна задача разместила взяла 4-core другая еще четыре коры зарезервировали ну 3 4 все бы хорошо но у проф задач есть одна проблема они на самом деле очень низко утилизируются пу в среднем потому что большую часть времени и не больше а значительную часть времени такая задача ждет запрос теперь давайте посмотрим на другую другой класс задач на расчетные у него уже потом потребление будет несколько совершенно другим да вот мы там посчитали что то получили какой-то данные еще чуть больше посчитали и продолжили считать у расчетные задачи со средним уровнем потребления все в порядке да он достаточно высокий но для неё мы часто хотим гарантировать минимум тех ресурсов которые она получит чтобы весь расчет который весь чтобы весь расчет занимал не больше определенного количества времени и тогда формула резервирования будет выглядеть как то так то есть мы хотим разместить такую задачу на машину у которой есть минимум один свободной циpкa а дальше нам неважно сколько есть столько есть но значительно больше выигрыш можно получить тогда когда мы на одном миньо не совмещаем оба типа задач то есть когда и причем приоритизирует процессор раздачу процессора таким способом чтобы как только процессор требуется для прот задачи немедленно она бы его получала отрабатывала быстренько а дальше пока процессор не востребован ни одной использовать он бы регулировался на расчетные задачи но как это сделать давайте начнем с того как мы бы зарезервировались собственно 4-core и для рот задач мы можем это сделать двумя способами мы можем использоваться pool set за резервирует 4 ядра или мы можем назначить квоту то есть указать что каждый из 100 миллисекунд задачи позволено потребить 400 миллисекунд процессор на во времени эффективно это вот как раз те самые четыре core но какой из них выбрать на самом деле мы пока не знаем если мы не посмотрим как мы будем распределять расчетные задачи на те же самой машины и тут выясняется что собственно циpкa со хотя он и выглядит более привлекательно да потому что у нас там и каши с локальности все хорошо и можно там numa что-то включить это макаровна и тут получается что вот этот цифру сету собственно для нас не работает потому что за полсотни позволяет на тех же самых корок запускать 2 зараженные формируют короб под один контейнер ок вот а наоборот она для нас очень подходит потому что она не ограничивать на каких собственных порах будет выполняться это задача теперь давайте посмотрим как мы то есть мы выбрали супруг вот у собственно для того чтобы проб резюмировать а как мы тебе будем резюмировать процессах для batch тут кого-то нам общем то срок говоря не подходит потому что для борща наоборот мы не хотим ограничивать верхнюю планку сопло а подходят хорошо здесь как раз супер шерсть и мы договорились что для матч задачу которой требуется минимум один цикл мы используем вот такой сидишь с а если нам требуется согласие пью тумбы используем вот такой соверши раз напомню что сиквел шанс работает только ситуации когда есть себе у старого ищем то есть когда вам не хватает процессора и тогда этот процессор будет распределяться пропорционально указанному количество шар то есть в данном случае первый матч получит два раза меньше чем 2 но даже при использовании вот такой код и шаг нам бы сделать так чтобы задача с короткой задержкой получала приоритет через бадью задачей в реал тайме а как это сделать в докере строго говоря возможности приоритизации контейнеров нет кто знает а тут нам помогут различные политики планировщика центрального процессора давайте вспомним какие они есть шат а за это собственно дефолтный духовная политика которая в линуксе повышает практически все программы другая политика это shad батч она предназначена для ресурсоемких задач и она подразумевает что если задача получила фланцы по времени то она будет долго над ним работать соответственно у такой вот активации есть штраф за активацию и эффективно это приводит к тому что за счет other задача всегда получает приоритет перед счет батч когда они конкурируют за процесса 3 политика это shad idol это политика позволяет запускать фоновые задачи с приоритетом даже ниже чем на из 19 то есть задача с таким с такой политикой будет отдан процессор когда больше не башни other этот процессор не нужен и тогда мы в меню не можем использовать мы используем меню написано начала он использует вот такой курс собственной библиотеку ванне и изнутри миньона мы изнутри миньоны но снаружи контейнера мы можем выставить политику планировщика вот таким вызовом но в принципе это не обязательно делать с помощью во мне в этом можно сделать и командой вот какой то такой и тогда чтобы реализовать наши классы изоляции задач делаем следующее мы запускаем прот с квотой пишет other матч запускается сыпем шерсть и политикой планировщика schippach и idol запускается сиквел шерсть и политикой планировщика shad idol поможет понадобится вот этот capacities из нас внутри контейнера page по дефолту до кирова отнимает если вы хотите изнутри контейнера менять политики планировщиком центрального но задача потребляют ведь не только циpкa да они еще потребляют трафик который еще сильнее влияет на лето msi и мы хотим приоритизировать трафик точно таким же способом то есть когда прот потребляет трафик мы хотим ограничить планка его потребления квартировать но строй страны мы хотим чтобы когда прот что-то посылает или принимает и сети он был бы приоритетнее чем бачили idol задач и мы хотим вот такой чтобы такая политика принимаем применялась как на исходящий трафик так и понятно но входящие тоже потому что снаружи какой-нибудь какая-нибудь расчетная задача hadoop на я например может запросто забить весь трафик входящими данными для mapreduce как мы это можем сделать docker узнать никак не сделать и здесь нам на помощь приходит собственно минут скалить в сервис подсистема от минус знают что есть такая утилитка traffic control тисе которая управляет приоритизировать и им пакетов дамы поэкспериментировать немножко с этой утилитой с и выяснили после многих довольно экспериментов долгих что вот эту вот политику которую мы хотим примите очень хорошо реализуется с помощью дисциплины теракте cool fire service кофту и fsc и с помощью неё мы выделяем два класса 2 2 класса которые управляются этой дисциплины прот более приоритетно но с ограниченным трафиком и batch file при этом все мы знаем что traffic control может управлять приоритизации только исходящего трафика а нам нужно еще и входящий но для этого мы используем вот такой вот модуль и vb которые единственное назначение которого это завернуть исходящий трафик внутри kernal а вы звоните завернуть входящий трафик внутри кельвинов отдыху через который проходит исходящий трафик и тогда его можно тоже использовать для в трафик контроля но к сожалению не вот так вот стандартными сервисами linux не получилось сделать потому что нам нужно регулируемая полоса для пропускания бочки idol она меняется со временем и она зависит от среднего потребления трафика пратт контейнерами это пришлось докрутить сверху точнее снаружи вот и миньон кроме того что именно меня не специальный процесс который отслеживает среднем потребление и перри конфигурирует собственно этот банк бочанова разное потрясение потребление и так у нас есть теперь три класса про даче idol и поскольку этот класс сильно влияет на задачу и хочется сразу в принципе понимать чем то имеешь дело мы решили поместить этот признак на самый верх наш иерархии и тогда наши фронты становятся вот так под прот да ну кроме того мы еще в качестве примера batch задачи давайте мы рассмотрим задачу мезек каталог которая составляет кота каталоге музыкальных треков собирает их в альбомы и там приписывают количеством такая при расчетной а задача запускающийся раз в иксу времени ну и пример майкл задачей может служить некие мейджик транс транс форме кто используется допустим для людей на музыке там то есть то что все загружается он каким-то образом этим по кличке преобразования тогда их имена собственно становится какими-то уже такими мы дописываем в конец класс этой задачи все прекрасно все замечательно но есть горькая правда полная изоляция задача работающие на машине мы не добились на самом деле мы добились следующего если у нас есть провод задача и рядом работает интенсивный цикл интенсивный batch который потребляет много циpкa то в этом случае влияние на задачу на прок задачу практически никакого нет но если это базе задачи еще и хорошо работает с памятью то есть большими кусками что-то оттуда читает переписывает то здесь наблюдается такой side effect что у прот задачи при этом вымываются крыши циpкa каши память и это приводит где-то на наших задачах приблизительно к 10-процентной 10 процентному увеличению задержки трафик еще сложнее изолировать потому что есть такого понятия к внутренняя сетевая очередь карты если уже пакет попал в железную сетевую посети в очередь в card data уже оттуда его никакой возможности вынуть нет и если батч пакет пока у попал первым то значит он первым и поедет в провод это приводит и второе это то что таким способом можно приоритизировать только тисе пи трафик то есть мы юдифи трафик таким способом вообще никак невозможно изолировать ну и соответственно сетевой задача та которая много пакетов туда судя посылает на это приводит еще к дополнительным плюс 10 процентов на про нашу задачу задержки про изоляцию поговорили теперь давайте поговорим о нашей любимой теме в отказывай устойчивостью что может пойти не так ну во-первых может отказать контейнер самих сценариев отказа может быть несколько это может быть например какой то баг в коде например эксперимент или ошибка в манифесте из-за которой допустим прот контейнер то есть задача с короткой задержкой начинает потреблять больше ресурсов чем положено был у нас такой случай когда один из разработчиков делал какой-то очень сложный алгоритм и он там сам себя перемудрил а и запутался и в итоге получилось так что это задача с короткой задержки просто зацикли валось внутри себя да и просто выжрала весь циpкa который ей был дадим но здесь очень хорошо работает именно изоляция поскольку каждый прот контейнер имеет квоту и он при этом высоко приоритетный но у него есть квота то никакого в дом этот задача просто уперлась свою квоту и никакого влияния на работающие рядом на том же меню не задач не оказал мой второй сценарий отказа это просто крыши здесь все понятно есть политики ресторан у докера не встроены always это вопрос задачи практически всегда имеют эту политику на он sailor это хорошо подходит для патча для этот врач но не знаю для кого нужно ну а теперь посмотрим давайте следовать давайте нарастим масштаб и посмотрим что мы можем сделать при недоступностью миньона целиком что он что нужно делать был миньон были там контейнер и упал что дальше делаем миньон эта машина до переносим задачу в принципе на крутом другое меню или все задачи на разными не понятно здесь мы можем перины в принципе здесь есть две модели да мы можем либо переносить контейнеры так чтобы они принимали адрес миньона то есть физической машины либо мы можем сделать так чтобы у каждого контейнера был свой собственный адрес и он бы ехал ездил за контейнером везде здесь есть одна проблема вариант с той pepper миньон да и pepper машина он требует сервис discovery без него вообще никак не получится потому что у контейнера все меняется и 5s где его найти не понятно иногда сервис discovery также требуется и для варианта а кипиа в контейнер тоже но это зависит от того насколько динамически эти адреса выписываются системы управления ну в принципе сервис discovery это удобно при посмотрел понятно где работает много на рынке решений разной степени отказоустойчивости есть до чаще часто там какой-то балансировщик еще внутри давайте посмотрим нужен ли еще раз discovery нам ну балансира лак вот балансировщика всяких разных у нас уже понаписано наверное штук 30 их много всяких разных они отлично работают в принципе балансировщик нам не нужно кроме того в нос еще одной системой как сервис discovery добавляет нам одну критическую под систему от которой зависит весь продакшн и нам нужно тогда очень внимательно тестировать очень внимательно выбирать эти системы service desk овале чтобы внезапно не оказаться с неработающим продакшн и главная проблема это в том что для того чтобы ввести в инфраструктуру сервис discovery нам придется очень сильно все переделывать нас еще много всяких разных микро сервисов каждой из которых нужно переписать таким образом чтобы он поддерживал теперь систему сервис discovery это очень много работы местами это даже невозможно просто потому что используются решение которые не находятся под нашим контролем то какие-то железки это какой-то код в терминале какие-то балансировщик и уже достаточно низкого уровня мы и туда сервис discovery уже вообще никак нельзя засунуть поэтому мы решили что мы не будем требовать всем с discovery и решили и тогда как можно это сделать вот так айпи адреса закрепляются за контейнером статическим то есть как только пользователь первый раз согните сервис в облака ему каждому из экземпляров этого сервиса выписываются сразу моментально ip-адреса эти адреса выписываются пресса первом саммите и в общем-то всегда остаются закрепленными за этими за этими экземплярами при этом количество айпи адресов будет столько закреплена сколько было максимальное количество реплик за всю историю жизни этого сервиса да если мы сначала за совместили 10 сначала 10 потом увеличили до 2020 уменьшили до 10 все но 20 и такие питаться они следуют за контейнером посетит когда он переезжает на других миньон и естественно мы хотим сделать так чтобы имея вот имя сервиса мы помогли не сразу получить информацию о том на каких и петлицах в общем-то экземпляру этого сервиса расположена давайте посмотрим на вот это вот имя она что-то похоже на что dns правильно да это да и на 7 мы решили что dns будет хорошей альтернативой при этом этот dns сервис он авторе то тела его обслуживает непосредственно мастер облака он возвращает одновременно он разрешает все резервирование обидится то есть он возвращает адреса и живых экземпляров и мертвых да то есть нашем примере с десятью репликами и потом 20 чудо потом опять 10 он вернет 25 адресов все которые там зарезервируем и при этом клиенты которые хотят с этими сервисом разговаривать они уже сами на уровне клиентские библиотеки отлично умеют отфильтровывать мертвые адреса они сами отфильтрует кто из них живой кто из них мертв это также открывает нам возможность использовать вообще не использовать критических сервисов dns и забивать просто в конфигурацию непосредственно айпи адреса нужных нам экземпляров с таким вот переносом айпи могут быть некоторые проблемы на сети давайте рассмотрим сетевую часть более подробно допустим мастер дает миньону команду запустить вот а к экземпляру с таким айпи адресом на меня не при этом работает бёрд который поп по протоколу пдп этот анонсирует этот адрес в специальный сервер который называется рота рефлектор у робота рефлектора есть сессия с железкой bgp сосед железкой он транслирует этот анонс в железку таким образом железка сетевая она уже знает на какой миньон направлять пакеты с таким адресом внутри миньона уже средствами linux этот адрес прикидывается внутри контейнера вы заметили что робота рефлекторов здесь три на мы любим все утраивать 3 а не из-за отказоустойчивости потому что это очень критично я часть мы распределяем их в разных залах по возможности дата-центров потому что если не один из рук рефлекторов не будет работать то в общем то все облака не будет работать потому что железка не будет знать куда крутить пакет теперь давайте предположим что у нас произошел партии shining то есть мастер потерял связь от миньонов мастер при этом подразумевает что меня он вышел из строя потому что он не отвечает на пакеты и тогда мастер выбирает какой-нибудь другой миньон и отправляет ему команду запустить перенести то и запустить тот же самый экземпляр да то же самое контейнер сам же сам адресом тот точно также birds анонсирует в рот дефлектор фотоэффектов точно также анонсирует андрис железку и уже лески теперь проблема потому что у нее есть 21 одинаковая 5 и разные пути куда этот адрес нужно учить что же делать этот нам помогает такая штука bgp как мультик дискриминатор на самом деле в протоколе bgp вместе в анонсе в багаж ломанулся вместе с и 5 сам можно указать некоторый вес этого анонса да и тогда железка получив два маршрута разрешает конфликт очень просто у кого этот вес меньше тот и прав а у кого больше атака это лишнее фигня и это имеет поддержку на стране мастера мастер когда на самом деле выписывает 1 1 отель он назначает ему мультик мультик за дискриминатор раввины миллион да а в ситуации когда он не уверен в меню не то есть может произойти парке shining antique ремонтирует этот мы всех дискриминатор и для 2 для второго контейнера указывает вот более меньшей метод мед и таким образом все пакеты будут учиться уже по новому адресу ну а тот миньон который завис и он остался без связей в принципе все равно что он там делает да не будет иметь никакого влияния на задач теперь давайте поговорим о товаре до этого мы рассматривали мелкие отказы а мелкие отказы все системы управления отрабатываю приемлемо давайте рассмотрим как мы отрабатываем на аварию то есть отказ множество серверов сразу например при отказе питания в одном или более залов дата-центра что значит авария авария это единовременный отказ множество машин при этом естественно что внезапно возникает куча задач для системы управления облаком она должна перемещать очень много большое количество контейнеров туда-сюда кроме того авария означает то что слишком много машин вывалилась нам просто может не хватить ресурсов для того чтобы запустить все эти машины часто аварии сопровождаются также отказом управляющего слой и за как выхода и оборудование на котором работают мастера такая чаще всего из-за того что аварии не тестируются практически никогда и мастера складываются просто от перегрузки или просто начинают тормозить так что дальше уже нет смысла продолжать обычно в таких случаях планов ликвидации аварий какой-то вот такой он не очень эффективный давайте посмотрим что мы можем сделать каждый из этой проблемы массовой миграции означает что в этой структуре возникает большое количество действий миграции размещений которые должны произойти и каждая из миграции может занимать какое-то время то есть допустим на доставку образов и меджидов поэтому хочется чтобы более важные задачи запускали вы быстрее чем менее важны давайте посмотрим на нашу иерархию какие задачи мы в первую очередь хотели бы запустить конечно быстрее мы хотим запустить те процессы которые участвуют непосредственно в обработке запросов пользователей то есть пруд для того чтобы это выразить мы используем приоритет размещения это число которое может быть назначено очереди чем выше приоритет тем первей отрабатывается размещение и иммиграция сервисов это очень это решается просто вот так назначаем приоритеты на порог повыше чтобы он шёл первым чуть пониже набок и его миграция сайт пойдет после правда ну еще ниже найду как видно эти приоритеты применяются иерархически у всех задач ниже по ираке будет соответствующий приоритет внутри же провода мы хотим чтобы каши запускались перед фронтами и это мы можем сделать назначив вот такие приоритеты на кэш и фронт по дочь или сегежи фронтов на конечно хотим сначала запустить основной портов поэтому для фронтов музыки ставим совсем низкий приоритет следующая проблема это нехватка ресурсов у нас оказала большое количество оборудования зала и целые дата-центры мы на запускали сервисов столько что теперь на всех них не хватает ресурсов то есть мы должны решить какими задачами можно пожертвовать для того чтобы работали основные критичные сервис давайте посмотрим под этим углом на нашей рахили решим что должно работать что чем можно пожертвовать в отличие от приоритета размещения мы не можем пожертвовать всеми batch задачами потому что некоторые из них часто важны для функционируем порталом поэтому мы выделили отдельно приоритет вытеснение задач при размещении задача с более высоким приоритетом может вытеснить то есть остановить задачу с более низким приоритетом если для нее более нет свободного меня при этом задача с низким приоритетом с большой долей вероятности так и останется не размещенными не запущены для нашей раки очень просто указать приоритет вытеснения такой чтобы провод задачи вытесняли а то есть останавливали idol задачи но не друг дружку вот таким образом так же мы можем просто указать что функцией музыке мы можем пожертвовать остановить ее если не хватает ресурсов даже для основного портал как мы видим при ликвидации аварии эротические очереди тоже оказываются довольно полезно сама ними разобрались теперь давайте поговорим перейдем на самый большой масштаб авария в дата-центре целиком почему это может случиться ну во-первых стихия конечно же вот здесь есть классный пост от компании dateline который как раз описывают такой случай кроме того стихии может он могут допустим считаться бомжи который спалили проводов коллектора до или пьяный экскаваторщик который кроме того аварии в дата-центре этот человеческий фактор есть какой-то оператор который дает какой-то команда все порушено ой баги конечно же есть баги смерти которые убивают все да и здесь важно понимать то что валит это центра это не какой-то редкий случай у нас эти аварии случаются периодически раз в несколько месяцев и что же мы делаем чтобы никто в твиттере hawk живи не портил не постил давайте посмотрим что можно делать в этом случае конечно же изолировать изолировать облака таким способом чтобы авария на одном дата-центре никаким образом не повлияло на инстанцию облаков которые работают с другом дата-центр таким образом 11 instance клапан клауда управляет машинами строго находящимся внутри одного дата-центра таки можем даже если что-то пойдет не так с облаком то мы потеряем один дата центрах при этом надо понимать что наше приложение все уже сейчас готовы к под теле дата центра и с точки зрения политики и резюме не задач из мы используем отказоустойчивые базы данных которые нам это позволяют делать также мы проводим часто тестирования отказов или учения по тому просто вырубаем дата-центр и смотрим что получилось соответственно у нас сейчас 4 дата центра значит нас 4 ван клауд и они полностью изолированы друг от друга соединений между ними нет ничего общего это позволяет изолировать отказ как из-за физических причин так и из-за некоторых ошибок оператора но давайте посмотрим ошибки оператора интересные темы что можем с ними сделать еще допустим есть у нас какой-нибудь админ он дает какую-нибудь команду и облака спрашивают спрашивайте вот такой вопрос давайте поиграем в арифметику а ты действительно достаточно адекватен для того чтобы сильно хочешь эту команду выполнить до соответственно админ и админ и у нас прокаченные в арифметике довольно быстро решаю такие задачки но на самом деле не всегда такой вопрос возникает он возникает при потенциально опасных командах то есть ну например это команда останова массового останова всех реплик сервисов будет такой вопрос также такой вопрос будет задан при каких-нибудь странных командах ну например уменьшение реплик обычно люди увеличивают количество реплик если будет уменьшение значит быть такой вопрос смена имени образа сервиса в манифесте обычно люди меняют только так если вы поменяли образ что-то вас должна не так то есть появление такой такого вопроса сразу вызывает желание остановиться и подумать перед тем как показывать скиллы в арифметике правильно правильно ли то что я делаю esbe мы дошли до конца я хотел бы просто сумма визировать все что я сейчас рассказывал отличительно особенностью нашего облака является иерархия сервисов что позволяет нам очень просто понимать глядя просто на имя задачи что это откуда как должно работать что с этим делать про ты батч совмещение проти батч классов утилизации задач позволяет плотнее утилизируя технику мы достигаем это с помощью к вот шар и политик циклу scheduler мы не используем cyprus от изоляция полностью не возможно только с помощью синей изоленты аварии нужно адресовать приоритеты и в ираке это очень хорошо ну и да если неадекватный администратор страшные стихи это все спасибо она снова просите осталось буквально 5 минут так что несколько вопросов коротеньких если что я не бегу я буду стоять прямо там зажимайте меню в углу и пытать здравствуйте короткий вопрос я правильно понимаю что си миньоны скорее всего еще скафандры как-то общаются чтобы нет спасибо спасибо за доклад вопрос если у вас в каждом дата-центре свой он клауд каким образом сервиса заворачивается в нескольких дата-центров каждом он кладу сообщает свою честь значит у нас у нас да сейчас одна из основных задач а то придумать как новых будем фидере ровать так чтобы не повалить одной команды все нафиг вот поэтому в данный момент пока первый сабмит манифеста происходит вручную во все три облака и у нас есть соглашение что одинаковые сервисы должны именоваться одинаково в разных уроках а с другой стороны не и самая частая задача это апдейт то есть изменение не собьют первый раз да а у изменения каких-то параметров и для этого у нас есть специальный ю ай да который позволяет составлять сценарий апдейта то можно написать что куда на какое облака перекладывать и в этот сценарий могут входить как облачные как облака так и железные простые там ну там сложный сценарий можно составлять там выложить туда подождать посмотреть что все нормально потом продолжить ну такой tool он как бы был просто развиты он у нас есть для железных распахнув и записали необходимые куски для облачных спасибо за доклад недавно вопроса первое что вы делаете бадами ну как они контейнер fastreport отдельные машинки как они мигрируют и второй вопрос организационной какая команда программа то в какой количест человека внедряли такие вещи я неожиданно начну низ последний у вас первого вопроса отвечать значит базы базы это точно такие же контейнер и как и остальные но облака умеет управлять дисками домами на дисках и она умеет есть такое понять как манифест тораджи это отдельная сущность в облаке и можно сказать что у меня и сторож там такой-то иммунную у него есть какие то там а вот это там ssd это том хдд столько-то столько-то размеров до этот это 100 раза пузыри вается и облака делать делает эти тома на и потом отметиться когда манифест задачи то она указывает mount он то что мне с этого стороже вот сюда на и облака уже сама там по шагам распределяет эти задачи и собственно сам там это непосредственно lvm ный вол им который отрезан там автоматически скриптом да и он туда просто монтируется то есть это бен mount делается да и это просто как он существует внутри контейнера как просто mount point и туда собственно базой пишет есть куча я менеджмент всяких команд которые позволяют с этими волнами дальше работать то есть их там увеличивать уменьшать переносить одного миллиона другое отслеживать там еще есть мониторинг дисков через творца талантом умеет сама отслеживать что девайс и сами рабочие там что-то делать с лимитом а второй вопрос про команду значит мы все разрабатываем короткими шагами значит 1 короткий шаг был сделан в прошлом году да и в принципе мы разрабатывали силами двумя 2 разработчиков в течение трех месяцев и что-то мы там запустили это был на самом деле облака стекла с без без так уж для без песен со стороны а в этом году вот мы еще потратили там месяце 4 и допилили туда собственно работу с ими же и сейчас команда три человека а вот на готовое решение у меня есть отдельный слайд вот я ожидал этот вопрос почему мы не взяли ну во первых есть понятия класс изоляции задачи они на самом деле по-разному размещаются на миньоны до если про задачу можно размещать на миньоны просто математические резервируя ресурсы отнимая чисел key data батч уже так не получается для размещения базе задачи нужно отслеживать фактическую статистику загрузки процессоров на меню и на основании ее уже принимать решение во вторых у нас есть эротические очереди который как-то нужно учитывать и этого нигде нет кроме того у нас статический pepper контейнер которого тоже нигде нет да ну и в третьих простота да потому что нам не нужны вот эти вот многоэтажные под и составлять вот такие вот которые нами те кто работал в купер надписи знают что они достаточно большое количество занимают байтов и из строк да у нас манифесты значительно проще а на чем разрабатывали иван клауд java java интересно то что вот допустим давайте посмотрим на еще одну мою мой рояль в кустах когда часто говорят что java очень много памяти жрет его нельзя никогда использовать да вот потребление памяти на машине реальные в дата-центре топ по памяти в топе да и мы видим кто живет больше памяти при том что его задача просто запустить контейнер и дальше ничего не делать да кто ж чуть поменьше ну и там сравнимо в принципе съев engine тоже потребляет conti в принципе это все одного уровня потребления нет никакого никакой разницы на чему пишите если вы натерли напишите то будет где-то в два раза больше появится то не придется стрелять потому что у нас время спасибо вам огромное за тебя"
}