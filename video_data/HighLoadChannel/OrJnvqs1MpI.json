{
  "video_id": "OrJnvqs1MpI",
  "channel": "HighLoadChannel",
  "title": "Версионирование дата-сетов и моделей машинного обучения / Дмитрий Петров (Iterative.ai)",
  "views": 1438,
  "duration": 2636,
  "published": "2020-02-26T11:59:51-08:00",
  "text": "всем привет сегодня будем говорить про versio нирования машин learning моделей вместе они рования data set of пропан source инструменты которые помогут вам быть более эффективными ваших e-mail проектах я и проектах я являюсь одним из создателем проекта девисе то есть да это vision control если вы видели предыдущий презентацию привет привет предыдущую там были ссылки и примера как бы использование 9 в разных там сценариях в частности вся сидит для машин леоненко сегодня будем говорить о нем но не только о нем вообще-то я изначально с далекой провинции я выросла в тюменской области на самом севере после чего 10 лет более десяти лет прожил в петербурге и переехал сиетл приходился microsoft где был достаньте 100 ма в bengi ну и большой компании я веду как вообще да это санса и машин living организован вот в крупной компании как работает множество достаньте став над одним проектом какие хорошие лучше практике они используют и каким образом компания делает собственных работ эффективно и каким образом они строят фреймворке для machine learning и каким образом в workflow организуется это собственно и легло в основу проекта отчасти легла в основу проекта девисе этот проект изначально был моим таким хобби проектом и как получается часто в кремниевой долине в различные начинания так иначе превращается в стартап и сейчас мы работаем над проектом 9-ку в рамках уже стартапа и территория там у нас целый распределенная команда работает над проектом и сейчас вот проекта очень активно развивается говорить мы будем не только удивись и мы в целом поговорим о окон сложных инструментах в частности это и масло от это брикс это git lfs для больших отверстия герани больших файлах и собственно 9 ну мое мнение как создать родились и может быть немножко ну предвзятым д ну я думаю я я попытаюсь по крайней мере со всех сторон эту проблему рассмотреть мы начнем вообще срывал с вопроса о том а что же особенного в проектах машин для ринга зачем нам нужно думать о каких-то новых практиках новых инструментах а почему нам нельзя взять вот и софтверные подходы годами отточено использовать есть популярное мнение что вот в машины оринги проекта машин линга не очень эффективное что мы тратим огромное количество времени на различные проблемы на решение проблем снова и снова мы не знаем как организовать workflow какие по методологии даже использовать у нас нет инструмента fierce а нирования не модели не данных и собственно отсюда все проблемы и растут ждут понять точку зрения глубже давайте посмотрим вообще различные аспекты м л проектов чем они отличаются от инженерных там есть понятно код данные модели и так далее вот эти собственно особенности мы и будем рассматривать ну и первая особенность которую все знакомы это же конечно же тюнинг гипер параметров мы знаем что в имел проекторах большую часть проекта занимает вот тюнинг подбор гипер параметров станьте 100 тратит много времени для того чтоб найти правильно там комбинации лучше из позиции workflow почему это важно потому что во время подбора гипер параметров кардинально меняется динамика вашего проекта то есть если вы изначально сначала берете код его пишите там тестируете смотрите модифицируйте и у вас как бы качественных изменений происходит там одна две три пять в день максимум то с перебором gibt параметров вы можете легко проверить попробовать там десяток сотню гипотез экспериментов там за один час например да соответственно вы не можете использовать стандартные инжиниринговые инструменты для того чтобы мониторить все эти изменения вы не можете взять ее там 50 коммитов сделать да за один час вряд ли это понравится вашим коллегам да и вам самим не очень захочется это иметь для того же под историю тем не менее хранить и как-то коммуницировать с коллегами люди часто использую такую технологий которая называется стал spreadsheets то есть они туда помещаю тут информацию про ваш про свои эксперименты про гипер параметры которые не попробовали данном случае их парочку их может быть там десяток и эта информация это коммуницируете там с коллегами ну и самим собой да потому что завтра вы должны помнить попробовали вы вот такие-то параметры или нет икса спрашивает это достаточно продвинутая технология часто это все делается просто через email через файлики через флаг это и так далее и тому подобное следующая разница между млн джинни рингом это метрики да с одной стороны вот мы научились до передавать через снег нашей гипер барометры и записывать их табличку но неплохо выписать туда и метрики потому что это собственно то как мы будем выбирать наши лучше эксперименты и они часто идут в те же самые каналы коммуникации которые вот вы используете вашей команде до метра к обычно назначено много в данном случае всего три но это все нужно тем не менее вот поддерживать и с экспериментами вместе где-то хранить дальше модели если вы натренировали там десяток моделей и потом ривер решили вернуться к моделям там не зная номер семь то вам вряд ли захочется заново его перед тренировкой до тратит дополнительный час и в этом плане неплохо бы результат ваших тренировках где-то а нить положите сказать вот она моя модель в результате у вас образуется такое хранилище некоторые с моделями какой-то директория какая-то люди придумают кита креативные именно этим файлом типы виз 7 там подчеркивание l25 они из имеет смысл очень маловероятно что через неделю вы будете помнить это смысл но тем не менее как бы это способ разграничить не разграничить а сохранить все эти данные какая таки коммуницировать самим собой и со своей командой немножко сложнее обстоит дело с дата сетами очень хорошо если вот это сет не меняется он его статический но когда вы работаете с динамическим дата сетами когда у вас лейбл и снова и снова приходят там каждую неделю вам приносят новые новый лейбл и достаньте 100 сами ребята тент в данных пока подсачек модифицировать какие-нибудь данную выбросить какие-то добавить и это такой естественный процесс и datasette это же нужно как-то versio не ровать опять таки можно просто создавать там копии директорий до или файлов и эти копии как-то распространять вот в команде в команде и соответственно эта информация тоже нужно где-то хранить то есть очень часто бывает что у вас может быть там директория там с тридцатью версиями разного datasette а и нужно помнить какая модель с кем с чем была натренирована собственно туда же в те же каналы коммуникации в те же таблице вы помещаете эти эти данные ну и последняя разница который на самом деле не разница больше похоже с между машин лингам и инжиниринга это кот то есть on this ты по-прежнему пишут код достаточно много времени на это тратят гипер параметры тюнинг гипер параметр это всего лишь одна из стадий самого процесса машин или одна нога и нужно хранить соответственно коллекцию каким-то образом от года до вашего и вот всего того что вот мы только что обсудили это данные модели гипер параметры и так далее ну можно просто кэш checksum и там теги вот в эту же табличку в эти жесты канала каким-то образом вот коллегам показывать то есть вот мы рассмотрели пять таких различий тире похожести до между процессом и когда обычные об этих вещах us on this to me разговариваешь они как бы говорят да понятное дело хорошее практике мы это обычно делаем все нормально когда живут разговариваешь с инженерами и так понимаю что большинство инженеры у них обычно вот так волосы дыбом становятся говорят ну как бы как то так жить это можно в инженерии мы давно уже придумали что все что пишется руками да ну как бы не совсем правильно и поддерживать какие-то по таблице руками это ненормально процесс становится совершенно такой слабо управляемой слабо контролируемой и нужно от этого избавляться сложно людей заставить поддержать это таблица сложных очень легко сделать ошибки но и понятно что нужно от этого избавляться собственно для этого нам нужны и 100 или инструмента новые для машин learning которые позволят нам автоматизировать этот процесс поддержки вот этой вот информации этой информации про ваши e-mail эксперименты ну давайте пройдемся по трем выше озвученным инструментом первый из них это масло продукта дтп это брикс он одна из основных его функция это собственно помочь вам в тюнинге гипер параметров в этом он очень хороший и очень довольно эффективен он позволяет вам во время тренировки взять и сохранить все ги про параметры которые были использованы ваш экспериментах взять всем метрики и даже модели зачастую и положить их некоторые хранилище это может быть на вокальном машине храниться может быть на каком-то удаленном там централизованным сервере куда все команда результаты пишет выглядит это довольно просто это библиотечка либо для питона либо для скалы что в нашем мире означает обычно spark вы импортируете и говорить вот у нас есть такие параметры такое это значение но обычно там переменные они циферки конечно после того как ваш код запускается все эти данные куда-то стаи собираются вот в то самое в та самая сторож до который вас локально или кто централизовано и через некоторые ей вы можете посмотреть что в результате получилось вот получать спринт такая табличка она в общем то похоже на то что мы видели до этого да но эта таблица понятно что она автоматически сгенерированы тут довольно сложно сделать какую-то ошибку и собственно то автоматизация который мы говорили она тут каком-то виде представлена и ваш процесс улучшает тем самым вы можете избежать ошибок когда там один достаньте из приходит другому и говорит о знаешь я вот вчера целый день потратил попробовал там вот новую модель и вот представляешь на не сработало а другой горит ну да конечно я на прошлой неделе такую же провал тоже целый день потратил с таким результатом да то есть если у вас есть утка таблица центрально какая-то со своими экспериментами то это вам позволяет вот таких вот избежать траты времени таким образом малфой лампа на помогает сохранять ваши эксперименты виде гипер параметров метрик и зачастую модели потому что ему модели можно точно так же в эту базу вот помещать и копировать если же говорить о данных тем более больших данных гигабайт данных и там сотни гигабайт них то это наверное пожалуй лучший инструмент и вряд ли вы захотите после того как тренировка закончена 100 гигабайт копировать там какой-то центральные сторож или там даже в локально не вряд ли захотите также здесь отсутствует явная коннектится вот между кодом да и данными вот мы привыкли обычно вот мы в детками тем там все четко цепляется вы знаете что какой код был использован там для построения кого-то там какого-то круто версии программы здесь это этой коллекции четкой нету к сожалению и для того чтобы тут коллекции обеспечить можно использовать другие инструменты и один из них это git lfs large file storage то есть шаги для больших файлов это на самом деле не часть гита оригинального это отдельная программа вы должны это отдельно скачать настроить его поддерживает гид hop beat лап в стандартный вид сервер не всегда поддерживает тем не менее вы можете специфицировать что для вас является большим файлам и таким образом можете уже сохранять свои картинки там и другие dtc ты больше чем обычные чем обычные текстовые файлы об обычной совершенно стандартный workle о появляется да то есть вы как пользовались где там так ему пользуйтесь только только большие файлы вы можете дополнительно класть очень простой инструмент я тут не имею туда что вот гид простой инструмент я вот имею ввиду что если вы знаете как пользоваться битум дата вы разберетесь наверное и с эфесом и все с ним отлично до тех момент до того момента как вы начинаете как вы переходите за скейл там гигабайта двух гигабайт и и и более например гид хоп он не поддерживает файлы больше двух гигабайт и для и то есть как бы причинно изначально git lfs не был разработан для проектов данных он был сделан там для game developer of для front-end developer of и под большим файлом там поманить понимается файл там десятки мегабайт сотни мегабайт а ну не до гигабайт но вряд ли больше ну и также он как бы не поддерживать те сторожок которыми мы привыкли да люблю люди любят использовать там ис-3 и подобный там клауд решение это конечно не про не про это в таким образом git lfs вам позволяет четко связать ваши данные он позволяет вам вести а не рвать ваши модели который обычно не очень большие это десятки сотни гигабайт но он вряд ли подходит для data set of для гигабайтный бы the set of и также он не специфичны для машины ринга там нет ни метрик не гипер параметров и понятно дело что здесь вот не стоит рассчитывать что нам принесёт какую-то пользу когда я работал большой компания microsoft и там были целые я и платформы которые позволяли нам создавать эти эксперименты икон и контролировать все что с ними связано то есть у меня не было вопросов там а что я сделал вчера я шел смотрю что сделал вчера у меня были там все эксперименты у меня не было вопроса какой датасет использовался то я видел четко что там использовался evil какие-то мерзок метрики использовались я не думал где-то мне ресурсы взять жду бы там какой-нибудь тренировку запустить или еще что-нибудь все это платформа я и платформы покрывали их сейчас в любой большой конторе эти и я и платформы они существуют и да и то с antis там помогают когда же перешел в стартап я вот и был немножко удивлен как бы а как же так у нас ничего этого нет мы вынуждены тратить время на то чтобы самим выделять ресурсы дату создавать cummins нас в облаке например копировать туда данные убедиться что данная правильной версии запускать там тренировку копировать модель куда-то там к себе на машину или куда-то обратно в сторож потом естественно оказывается штамм данные не те корни тут делать это снова порой еще раз и так далее я спрашивала как же так чем почему тратим время то на это и все как бы коллегии все люди в общем-то вокруг из среды как бы старта посредник компании они говорили ну ты знаешь этот вообще говоря вот то как машин лирник сегодня организован если ты как бы умеешь тренировать модели то ну извини но ты разберешься когда на это версия не ровать как данные перемещать но со своей машины там на инстанции потом от модель обратно и в целом в общем то они правы да это не рокет сайенс проблема здесь в том что как бы не хочется тратить на это время не хочется делать те же самые ошибки снова и снова хочется жду под некоторые фреймворк некоторые назовем это я и платформа эти проблемы на себя брала и соответственно скрывала от меня от команды это и было основной мотивацией создания проекта девисе мы хотели взять вот все эти тяжёлые операции и не только тяжелый и переместить на какой-то фреймворк которая будет по верху концов снова стыка да вот тут это очень важный компонент не хотела создавать там какую-то я и платформу которая вам большая красивая но живет в отдельном каком-то прекрасном мире хотелось создавать что-то в чем если сантис работает то он уже в стайках то он уже в 200 инженерном стеки он уже он уже использует гид он уже используют наши клауд старриджа и тем не менее он может эффективно управлять своими ресурсами и не тратить время на вот этот вот весь heavy lifting связанные с менеджментом данных моделей артефактов также хотелось иметь возможность работы с большими данными что значит большие данные в контексте машинного обучения это означает любые данные которые помещаются на одну машину которая может обработать одна машина мы сейчас не говорим как бы америка stir of мы говорим как бы о том шаги когда у вас данные уже есть для процесс машину обучения для тренировки да это сотни это мегабайт гигабайт и сотни гигабайт в редких случаях терабайта но уже там не петабайтов мне кластерное решение естественно хочется иметь и мал специфичные штуки метрики мал pipeline и и тому подобные вещи к которым сантис ты привыкли таким образом мы создали проект девисе это отдельная программа она не специфичная для вашего языка программирования для фреймворка вы можете его использовать там с питоном саром счас парком со всем этим вместе взятым в одном проекте это просто командой на инструмент что интересно что мы добавляем этот инструмент у нас есть стандартные гид сервера которую мы привыкли мы не пытаемся их рашель там как например git lfs делает мы совместимы со всеми при этом мы добавляем концепт клаб дейта ремонт то есть вы можете как плюс к вашему кадре маска сказать вот у нас есть да это ремонт это наш с 3 bucket или там директория в баке теле и жор блок пожалуйста все данные хранит там все данные пульту да да то есть когда вы делаете пол буш данные должны уходить в этот самый сторож в результате что это нам позволяет сделать здесь должно быть удивительно эдема которую не получилось они показать я буду на слайдах показывать это нам позволяет добавить данные в нашей базе торе запушить переместить наши данные в наши наш cloud storage и соответственно когда ваш коллега будет вашей базе торе и получает да то есть клонировать пулить то он те самые данные получат т.е. если у вас был там не знаю 3 гигабайта данных положенного репозиторию то это собственно способ переместить эти 3 гигабайта и дать всей команде доступ к ним до важно что эти данные будут привязаны к вашему комменту в этом плане тут четкой аналогия с git lfs а если вы положили положили данные делайте commit то соответственно вы код с данными четко связали при этом 9 поскольку он не нарушают протокол стандартных готовых он это все дополнительную работу делать нами то файлах во-первых мы модифицируем гид игнор но потому что вы мы хотим исключить да наши данные из где-то мы не хотим наши данных гид помещать моих в git игнор соответственно добавляем и мы создаем некоторые метаданные a9 файлы мы называем который является по сути пантерами пантерами к самим данных в кровать и клад абстрагируется клауд тоже нужно задать их да это ремонт то есть вы говорите дэвисе и там ремонт от и дальше ваш там bucket да там быстрее или там путь в дтп хранилища то есть вы как бы абстрагируйтесь от этого это прекрасно работает и с директориями то есть например если восьмистам 50 гигабайт там картинок сотни тысяч картинок вы точно также говорится 9 и ты как бы все после push его вас уходит в клауд и ваши коллеги это все используют когда у вас добавилось там еще там пять тысяч картинок вы добавляете просто точно так же делать еще один комент еще один push эти картинки дополнена уходят следующей версии в сторож и все видят что данные изменились все как бы просто я довольно аналогично сбитом собственно так вот работает опыт ваших коллег и которые получают репозитории спланировали перешли 9 сделали полк получили данные при этом не всегда важно иметь все данные иногда у вас есть там 100 гигабайт входных данных 100 гигабайт от процесс иных данных потом еще какие-нибудь фичино 50 гигабайт а потом уже модель 100 мегабайт в некоторых сценариях вам нужны только фичи например или там только процессные данные соответственно можно сказать за полем не только вот тут этот курс вот эти вот этот кусок и получить соответственно только этот кусок это особенно интересно в сценариях deployment am когда вам нужно только модель до вам нужно последний 100 мегабайт которые получились в результате от вашего проекта соответственно здесь можно без клонирования репозитория просто сказать девисе там дай мне модель вот из того репозитория с таким-то полным названием да и получить эту модель а для deployment а такая же кстати библиотеку нас из питона работы то есть из питона можете взять там из своего сервера модель из тораджи модель и за тепло и сразу же на сервер кроме этого есть более такие файлы в сборе ваз корни абстракции как понял pipeline и метрики сегодня не буду их подробно касаться но тут идея понятна до pipeline и это собственно способ связать ваши там входные данные до сырые данные с моделью вы можете специфицировать команду к которой это преобразование получается dependency до минус d и выходы до минус у и соответственно комета файл будет создан и который показывает как это все происходит преобразование данных таким образом вы можете создавать сложные pipeline и не обязательно лин линейные и весь свой e-mail процесс описывать кроме этого можно метрики назначать специфицировать и таким образом вас появится возможность навигации в git репозитория через метр и то есть вы можете ответить на вопрос где самая лучшая метрика в каком раньше самая лучшая метрика в каком к мите самое лучшее метрика покажи мне метрики в последних кометах то есть некоторые машин летных специфические команды метрика 2 win команды в этом фреймворке ну и собственно что произошло с помощью девисе мы заменили вот ту самую таблицу до о которой мы говорили в самом начале точнее от большую часть этой таблице мы ее заменили на историю гита это вот одна из тех лучших практик которые вот инженеры пришли в течение последних вот 30 наверное лет да нет ну вообще система контроля версий история системы контроля версий это пожалуй единственный документация в которую верят любой инженер в любом проекте и мы как бы к этой практике пришли что тут важно понимать что с одной стран да мы связали код данные там модели метрики все отлично но мы по прежнему находимся в концепции гид комментов это означает что для гипер параметров такой подход вряд ли подход подойдет для гипер параметров вы не захотите использовать там 9 чтобы там 30 коммитов одинаковых делать до с одним изменением конфиг-файл а тут эта область контент который нам еще предстоит поработать ну и в частности в виде заключения давайте сравним вообще все из перечисленных подходов здесь можно сделать разделение по тому насколько важен для вас процесс подбора гипер параметров насколько важен для вас процесс versio не рование до сета процесса как бы и воля эволюции datasette а если у вас данные достаточно большие то есть гигабайт плюс скажем так если у вас данный меняется часто то 9 в этом плане может вам дать достаточно много пользы если же вы работы с гипер параметрами то удивить и вам вряд ли поможет вам нужно использовать более специфичные фреймворке типа mlc тут важно понимать что вот эти два фреймворка 9 мл фл оао никак бы не являются взаимоисключающими и сегодня многие команды используют девисе имел слов совместно то есть 9 9 для данных кода и versio нирования м флот для подборки при параметров они органично вполне живут в одном проекте вы можете найти там ну как минимум 5-7 блок постов на эту тему как вообще вот их подружить и как с ними совместно жить git lfs тут тоже не стоит списывать счетов поскольку все таки это простой фреймворк он может вам дать такой вот компромисс между простотой да и тем той пользы которые гарсиа нирования может привести вашу команду то есть и ряд команд тоже используют git lfs вот для версии а нирования например модели ну то есть что что происходит сейчас сейчас мы видим такой переход от software инжиниринга к новому прекрасному миру машину обучения я как хотите назовите наверняка название изменится не раз и вот последнее такое изменение происходило вот лет началось лет 30 назад когда вот matt hardy дизайна до переходили к software инжинирингу у нас и все методологии поменялись разработки у нас инструментарий поменялся без практики поменялись единственный нюанс что до 30 лет она заняла и здесь возникает вопрос хорошо значит ли это что эффективно e-mail проекта мы будем делать только через 30 лет и тут я думаю я верю что мы это можем сделать сильно быстрее по разным причинам нас больше людей в индустрии у нас интернет сегодня есть 30 лет не очень-то и был но тут нужно делать еще никто дополнительные шаги чтоб ускорить этот процесс во первых нужно понимать вообще что такое машин ли рынок как процесс организован где мы тратим наше время в этом процессе какие ошибки мы допускаем в этом процессе ну и собственно как избежать до этих ошибок и перестать тратить наше время следующее нам нужны инструменты автоматизации то есть поэтому мы их разрабатываем а не говорим и тут важно эти инструменты под этими инструментами пользоваться не исключено что это инструменты которые нужны вам они еще не существует их может быть и стоит создавать сегодня пока еще хорошее время для этого ну и пожалуй самое главное это нужно этими знаниями делиться то есть нужно понимать в каких случаях мы тратим наше время как это избежать какие инструменты нам помогают в каких случаях помогает каких случаях не помогает вот сегодня был отличный доклад отпросись иди в машину rng как им помогло это для определенных задач и вот этим знанием обязательно нужно делиться но и окон сорт инструмент это собственно это лучший способ делиться этими знаниями это ток если кто-то поделился знаниями использовал послушны инструменты значит что весь остальной мир может взять и сразу же использовать это знание всем спасибо не потеряйтесь своих версиях моделей data set of готов к опросам примите благодарность и перейдём в дмитрий спасибо за доклад спасибо за систему такой вопрос локальное хранилище можно использовать кончик ходу ли house или только из 3 подобные да сейчас реализация такая что поддерживается только в такие скажем так о брикс top можно использовать и ссср то есть вы может сказать вот у меня сервер есть там директория пожалуйста вот храни все там gdfs у нас было поддержкой в принципе можно было это делать сейчас мы ее убрали я могу отдельно искать почему там есть нюансы и данные дублироваться каждый раз при лекси они но не целиком то есть если у нас идут оси по 30 гигабайт при изменении он будет также дублироваться и второй вопрос если поддержка купить их оба хорошо давайте с дублирования начнем дублироваться это зависит от данных если вы versio нир уйти целый файл а потом его изменили то есть часть система сделано таким образом что мы храним как бы две версии и это довольно стандартный подход например git lfs делает также и многие другие системы почему так происходит просто чтобы нормально дело дупликацию нужно очень-очень много знать про формат и сегодня мы вот решили пока что не делать этого и просто хранить как бы было бы и все ситуация меняется с директориями если у вас есть директория как вот я приводил пример да там 100 не знаю тысяч файлов например вы добавили еще семь тысяч 2000 вы убрали и полтыщи вы модифицировали и делайте commit вот в этом случае публикации не происходит все что нужно записалась файл директории изменился как бы небольшой файл д а вот 100 гигабайт который она занимала но не будет не будет дополнительный столь занимать то есть на уровне файлы публикации нет нужен территория дупликация есть простой ответ такой юпитер хоп тут зависит как бы что а зависит от вашего workflow если вы говорите просто g петр ноутбуках а джек это хобби тогда ну как бы так в целом то проблем нету да можно есть варя есть примеры использования девисе в с джокером тогда например джо петр работает в облаке даже петр хобби и людям нужно данные подтаскивать туда соответственно не используйте вести специального для этого простой цели синхронизировали данные поработали в питере сделали коммиты езжу питера либо там его нету уже не так важно данные синхронизировали обратно и если нужно там есть у петра вышли то есть в этом плане как бы тесная интеграция нет но в целом это хорошее space и люди так делать день добрый несколько слов скажите про branch имидж потому что это как то вот я не услышал это можно или нельзя это поддерживается не поддерживается и вообще какие тут практике бывают да вот это хороший вопрос изначально идея была такая что нам это все очень нужно вот мы хотим вот этот весь битв лода взять и его вот в машину лёрн ит так принести в этом плане мы эту задачу решили мы его принесли это можно делать мер джебран чей все все вот это при этом появляется некоторые нюансы поскольку мы создаем это файлы то ваши мер джиани ну чуть-чуть от усложняется вам нужно еще не the file & magic дополнению к коду но вот но в целом это возможно конечно же привет вопрос одесский суд скорее всего будет вот был продемонстрирован там слайд с 9 рам командой то есть у нас создается pipeline где-то жестко фиксируется метро файлах и там кэш и хранится потом на удаленном нам наша страна примерная strida можно ли как то декларативно это описать за imported там библиотеку например в притоне да и весь pipeline задать кодом и потом конечно не часто меняется в принципе совместно кратно россияне да да да я не дакар собой на вопрос у многих антисов существует как бы сказать такое желание использовать это все именно из кода это наверно естественное желание и многие сантис ты так и делают они используют 9 дней как командный инструмент а как библиотеку то есть они просто поскольку написано бетоне да вы cможете про сказать там 9 install там потом дивись импорт и как бы все это пользовать но это делают многие компании то есть это возможно в принципе но в целом у нас фокус все-таки отполировать сделать идеальным именно командой на экспириенс именно для того чтоб объединить от мирный то сайнса с инжиниринга mindmap сам потому что вот кому использование pipeline of the miz питон кода она как бы devops инженером не так близко как к сантис там где-то возможно скажем так но это не главный юз кейс для 9 дмитрий спасибо у меня такой вопрос вот смотрите получается и стружка вы рассказываете эксперимент это некий тоже артефакт до который имеет там чуть более сложную структуру версия нирования чем например код детей или артефакты в арте factory то есть по сути он является коллекцией версия которые версия не руются и она является набором ссылок на версии других объектов то есть тех коллекций если вас правильно понимаю то у вас это некая обертка которая позволяет эксперимента есть в рамках эксперимента версия не ровать все входящие в него объект вот их 5 ну там технических можно сколько угодно много сделать вопрос такой то есть если вы решили вопрос там по 4 до аспектом из пяти то в чем проблема например версия не ровать не то параметры если это просто ну там условно строка значение для развития с разделителем и которых можно версия не ровать в отдельном репозитории и также ссылаться в чем проблема можете пояснить да ну как был верно говорите что вообще проблем такой нету да что пожалуйста параметры это просто параметры это либо 9 ранда в нем и соответственно в мета файл этого хоть эти параметры либо у вас есть файл конфигурации в нем гепард параметры эксперименты и там вы что-то меняете комитете все отлично да то есть технически то нет проблем проблем возникает вот когда когда вы занимаетесь тюнингом гипер параметров у вас экспериментов становится очень много у вас может вот как я приводил пример да за час может быть там 50 экспериментов и вряд ли вы захотите все-все хранить в истории где то вряд ли вы захотите иметь 50 коммитов с изменению в одну строку каждый вот в этом проблем вот вот этого люди не хотят делать и это соответственно является барьером для использования 9 вот в тюнинге гипер параметров в некоторых случаях вам эта информация не нужно вам не нужно сохранять скажем так да вы 50 экспериментов сделали вы ничего не заметили а потом сказали ok но вот 43 эксперимент был вполне ничего вот его я и закончу делать там один комет либо там два коммента в этом плане вполне можно использовать девисе даже на этой стадии но вот как способ коммуникации 50 экспериментов но через пятьдесят комментов наверное не лучший способ спасибо за доклад и как я понимаю у вас есть научный background и поэтому вы скорее всего знаете проблему воспроизводимости экспериментов и статьях часто встречаются такие эксперименты которые хочется сделать их не удается сделать и готов ли продукт дивизии стать таким стандартным для международного научного сообщества через который можно будет свой опыт расшаривать с другими исследователями да конечно же я очень надеюсь что мы как бы в этом направлении движемся и в частности мы разговариваем с никаким людьми в частности с организаторами там ни пса поскольку они они хотят прийти к такому миру когда на нем нельзя будет заметить статью без кода без reprap reduce блокада я думал что-то произойдет ли через по 50 но тем не менее то что они уйдут туда это очень хорошо но здесь мне кажется ориентироваться на науку и на научное сообщество несмотря на мой бэкграунд не очень правильно почему потому что проблема rip ради соберите проблема вот воспроизводимости экспериментов она намного острее стоит в индустрии нежели в научном сообществе потому что там у вас ездят машины там у вас крутится реклама и и связаны с деньгами и так далее и тому подобное в научном сообществе это как бы ну это классно но не так же все готовы туда бежать сразу а вот в индустрии проблема намного острее поэтому мы конечно же в первую очередь на индустрию ориентируемся давайте последний вопрос спасибо за доклад вопрос такой вот файлы с расширением 9 они создаются автоматически при там где висит и висит уж добавлять их в jade игнор надо ручку ручную автоматически не являются добавляются в git игнор не дивись и файлы и файлы с данными на то есть если у вас там в директория была и mogers да тот она уйдет в детектор файл а девисе он не уйдёт при этом файла необычная мол вы можете даже руками их создавать это нормально вполне практика понятненько и вот второе просьбу гипер параметрам предыдущий вопрос насколько я понимаю гипер параметра не вижу редко вручную подбираются они либо автоматически на сетке либо там генетическим алгоритме либо другими алгоритмами оптимизации то есть тоже не видно проблемы они все ног пишутся куда-то то есть результаты от подбора диктор параметров они куда-то пишутся вместе с этим и гипер параметрами ну в простейших учи это файл то есть этот файл уже с этим с последним каменному идет как джип и он там будет жить до тех пор пока в домике прочитают или не изменит или не добавит а она до 50 экспериментов отдельно комитета есть один коммент будет на 50 экспериментом это это так в некоторых случаях то есть вот идея то что давайте пройдем по гряду до или используем генетические алгоритмы подберем параметры она как бы хорошая и красивая но все-таки по моему опыту это не первый шаг это уже такой но я бы назвал тоже брутфорс когда идей больше не осталось давай сделаем так все таки изначально когда вы смотрите гипер параметры вы исходите из каких-то качественных типа гипотез то есть например вы предполагаете что вот у нас там не зная learning рейд нужно уменьшить потому что вот я представляю что функциями тут примерно такую вот структура давайте это сделаем а давайте изменим так они затар потому что вот я нашел из примеров с эти который по говорят что наш организатор он неправильной измене то есть чаще ручная работа первоначально чаще до часа гипер параметры все-таки перебирается вручную вручную вручную до а и зачитывали чтобы найти границы между которыми именно и минус ветку да да да и потом если у вас на это есть силы время ресурсы тогда вы говорите ноги и давайте сделаем брутфорс и более четко подберем как бы более точные параметры но ручная работа то мне крайне диване сожаления да да согласен но все равно как бы это не очень большая проблема даже в ручном режиме как бы вот этот файл генерить то есть гипермаркет ры и результат но нет особенно в вашем примере которые вы сказали там вот сетка этот вообще не так ну так как это многие бы сделали передём к самые сложные части это всего понравился ох это сложно вот первый вопрос про гипер параметр я не помню кто его задам да вот первый вопрос погиб и право параметра супер спасибо спасибо большое дмитрий петров"
}