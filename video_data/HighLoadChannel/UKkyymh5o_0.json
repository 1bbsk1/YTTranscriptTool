{
  "video_id": "UKkyymh5o_0",
  "channel": "HighLoadChannel",
  "title": "Как мы считали трафик на Вертике / Николай Голов (Avito)",
  "views": 997,
  "duration": 2816,
  "published": "2017-04-22T14:47:43-07:00",
  "text": "всем привет меня зовут голов николай ii архитектор хранилище данных компании авито и я вам хочу рассказать про то как мы работаем с большими данными эти два дня я слушал другие доклады и понял что возможно планирую я сделал свой доклад немножко слишком детальным и поэтому сейчас я сделаю следующим образом я поделю его на 2 части первую часть я расскажу вам про нашу инсталляцию потому что я думаю вам это понравится и потом вы сможете задать вопросы именно про инсталляцию про то как можно взять верте q и не очень напрягаясь получить отличный аналитический инструмент но совершенно космических космических данных а во второй половине я вам расскажу как из этого аналитического инструмента можно взять и напрягшись чуть побольше выжать просто фантастические результаты но для этого на оружие нужно думать в парадигме мапри deus соответственно давайте начнем значит компания авито все знают что такое вид а я думаю не надо рассказывать вот тут немного целью то есть самый большой сайт объявлений миллиард раз в месяц миллиона посетителей и так далее то есть тут нет относительно то что она сама свежие общем все далее не россии кроме ариес лексей собрать это то это будет в 16 раз больше чем стороне то есть очень большие у нас много да да вот так и в постоянно становится больше и наши руководство постоянно с этим данным хочет что-то делалось у нас нет того что говорят у нас есть задача построить их кластеры построить и инструмент который будет решать эту задачу мы вместо этого нам говорят должны быть все данные и мы придумаем вам задачу вы должны быть готовы ответить на наш вопрос соответственно вот активные объявление так далее год назад эта задача была вот так сформулирована пример тогда я пришел волита и пример тогда мы решили строить кластер на веточке а и соответствии с сентября c 11 сентября коз абсолютно чаем совпадения а началась туда лица история вести пользователей на нашем сайт и давно в результате получился получилась вот такая инсталляция давайте я вам покажу это вот как раз дадим этому будет посвящено это собственно что такое хранилища видно во первых какие данные основные данные это данные по корпусам это система которая держит нашла я высоко нам нужен и высоконагруженных сайт классических там все объявления все пользоваться огнем на туда данные по каждой 20 минут при этом все данные льются с полной изменчивость то есть у нас сейчас примерно там через 500 миллионов объявлений я точно не помню в базе каждое объявление поставляется на название описание картинки куча полей и они постоянно меняются мы храним полную историю то есть в любой момент про любой момент объявления мы можем сказать какая была цена как у нее тогда было название и какое было описание мы можем знать когда он поменял цель как как у него изменилось популярность объявления когда например что-то меня это очень актуально соответствуешь самое есть для пуль для пользователей вся атрибутика для платежных операций тогда соответственно данный а3 что-то в 300 не таблица самая большая содержит в районе двух миллиардов записей этот контекст историчности вы можете спросить почему так много потому что хранилище построена по 6 нормальной форме ну я не думаю что много много людей знают что такое шасси нормальная форма ну некоторые знают большинство уже 3 neo ходили в общем 6 нормально максимально узкий таблицы да очень узкие таблицы я не говорю что в верх текке нужно обязательно делать так есть люди которые говорят что нужно делать по другому но для нашего блока задач от работает достаточно удача отвернется довольно мало то есть самый большой пакет который 8 ну ладно может залиться это сотни тысяч то нам 500 тысяч строк максимум куда может прийти вот а вот куда более интересная часть экстрим то есть это все действия посетителей нашего сайта причем и зарегистрированных и не зарегистрирован и вот тут такая красная цифра 500 миллионов событий в день данные с хранилища каждые 15 то есть хранилище в реальности она отстаёт от боевого состоянии сайта на примерно где-то там 15-20 минут на цикл загрузки ну там до 30 минут и все данные которые залиты они готовы для оперативного анализа важный момент а это я вот рассказываю в контексте тех бормотов который вы скорее всего предварительно слуш слуша и войдут делают и других которых во первых а это не просто помещение данных вот нам пришел 3 extreme с фиксированным количеством поляки мы положили в такую же таблицу все данные они проходят через три уровня стретчинга все данные очищаются где нормализуется и провязываются по внутренним ключ от хранилища то есть нам приходит клик по объявлению это значит что книг про поступает хранилищем связывается с объявление прядь при этом нам не важно что раньше придет в создании объявлений бэк-офиса или клик по нему абсолютно не важно в любом случае он будет заблокирована просто в начале будет клик ссылка на объявления а а потом уже вокруг объявления вырастут название цена категории так далее либо наоборот вначале категории а потом вокруг нему в насчет вырастать книги то есть это достигается за счет 6 нормальной формы также такой подход позволяет во первых оперативно закрывать дыры то есть если мы видим что наши данные за какой-то временной период в прошлом они загрузились не полностью мы можем затребовать от исходной системы перекачать данные то есть и за счет того что он все данные заливаются они заливаются не просто потоку news они сравниваются и заливаются только те которые изменились за счет этого к нам попадут только те данные которые мы пропустили за счет этого когда у нас появляется дырка такое бывает ну какой-нибудь промежуточное звено от пола и мы потеряли данные мы можем без копания в миллионных строк мы можем просто автоматически буквально параметр перекачать вот что вы представляли каждые 15 минут что нам приходит когда ведь умел это делать я вот рассказывал что так здорово нам каждые 15 минут приходит от трех до пяти миллионов событий сейчас нам приходит 10 иногда 15 миллионов событий каждые 15 минут причем события клик стрима это вот если помните рассказывал коллега из байду это в аду батут про спросить это урал refer a user agent cookies соответственно коллег из базуки не хранится а и дальше произвольной атрибутика то есть если это событие поисках например в поиске есть хочет ли ну например человек там был приходит джейсон с параметрами поиска ну например чаще бмв там приходит слово которым он еще например кафе к слову по этим данным и год назад поняли что iphone на авито еще больше чем на яндексе уже тогда это было сейчас намного больше вот соответственно если это просто клип по объявлению то у него конечно нет поискового слова но при клике приходят номер объявления вот такое очень интересно да событие например когда пользователь отправляет сообщение другому пользователю тогда приходит пользователь не зарегистрирован приходит его e-mail пользователя приходит например там у нее галочка он может поставить не ставить галочку хочет ли он получать маркетинговые материалы это тоже очень интересно то есть каждое событие всего событие сейчас насколько помню 76 там что-то в этом роде у каждого своя атрибутика причем они постоянно добавляются вот и вот это разрешенный поток из 15 где то 10 15 миллионов вот таких разряженных строк он приходит через триста слой стайлинга раскладывается провязывается по ключам и загружаются в базу только то что изменилось в результате хранилище формируется так называемый слой dts слой детальных данных где сотни высоко нормализованных таблицы фразу и такую граф где вот там есть объявление uriel refer a и между ними огромное количество связей все дела и отослал 26 терабайт сейчас скорее 30 40 дойдем до у нас место на 50 но если чем мы найдем где почистить вот и вот весь этот блок он доступен для анализа то есть нет того что эта информация которую мы просто как-то складываем наша задача сохранить а потом может быть она как-то будет анализироваться у нас существует команда аналитиков каждому из которых каждый из которых на диске и каждый из которых когда он приходит я провожу с ним короткий курс я рассказываю как писать запросы qwerty key к 26 терабайт а где вам рассказываю пару фокус тоже если таблицы маленькие на верти key ну условно говоря до миллиарда строк ну там дартом доставили он что вы понимали до 100 миллионов это обычная база не нужно писать обычные джоны ну и как-то вот через некоторое время начать расстраивается почему а вот того сделка сотни миллионов написал там joy там 10 таблиц проджезил оон результат не вернул там две минуты ждал а я ждал минут хотел минут а если работать с данными трактире мам то есть данный текст рим чтобы представляю это мужские таблицы ну вот такие основные например cookies или этим события а там сейчас вот когда я смотрел три дня назад там по моему 130 миллиардов было то есть таблицы где по 130 миллиардов строк и чтобы получить эту информацию их нужно вот и просто людям которые это делают рассказывать fox скажите много ли из вас в последнее время пользовались райт join вот один нашелся ну в общем если вы будете работать смерти как бы вы можете обратиться вам расскажу в чем фокус а потому что пара особенностей позволяет ну то есть vertica в любом случае вам позволит из 26 терабайт получить анализ то есть кусок говоря у вас данный за год вы хотите получить информацию ну например динамику как меняется посещу а количество уникальных пользователей покупающих автомобили с айфона причем пользователи которые покупающий закона который допускает недвижимость это принципе абсолютно нормально запрос которые вас могут захотеть и аналитики могут его начать если разорили а просто глоб обычным успели чтобы представлена мне что-то почитаются ну что в принципе нормальная скорость работы для ходу инсталляцию кто поведет результатов для нас она не приедем мог точно знают этой фокусы с джоном и там ну еще пара моментов ответ на этот вопрос может быть получен в реальности 10 15 минут вот чтобы представляет все 26 терабайт запрос который в сырую берет их всех но потом за счет фильтрации и грамотного деление и агрегации он выдает вам ответ минут очень короче отличная штука очень рекомендую соответственно будут у нас и наш кластер он из чего состоит свое место 10 серверов это уже не совсем правда потому что у нас не так давно у одного сервера железяку мужу строя я надеюсь то есть сейчас уже новый под ключом но его пока держим в резерве он в принципе на 9 работать нормально 10 директоров каждый из этих 32 ограда из 56 гигабайт оперативной памяти соответственно эти данные и вот по ним равномерно размазаны с безопасностью как сайт проводить то есть каждый каждый кусок данных бун дублировать 2 сервера поэтому соответственно вот это выпадение одном сервера она она заменяет производительность нового класса работоспособность не теряет то есть если это происходит дается команда на рекомендацию или там такая бой и все продолжает принципе дан тайны сыграем сделать это там он составит не больше суток причем это не означает что сумки клатчи будет работать вообще это означает что сутки кластер он будет поддерживать расставание от боевых систем не 15 минут а он отстанет на несколько часов там возможно десятки а потом когда рекомендации закончится он начнет заново догонять и снова достигнет 15 минутного окна вот ну и напоследок чтобы представляет инфраструктуру заливки в обращении в хранилище для заливки данных клик стрима мы используем fleur de которые пишут в мозгу мозгу мы используем просто как кэш то есть помощи 112 серверов поправят а это и она держит 3 трое суток данных и man и соответственно просто из манки вычитывает новые временные окна если отстаёт она просто читает глубже в прошлое вот наличие такого как шар на манги она позволяет нам не боятся стать то есть если мы оставим не более чем на три дня то мы можем догнать если больше по которому представила собственного в общем я довольно много всяких слов сказал сейчас вы можете пород инсталляцию позадавать вопросы такой интересный вопрос для меня пускать просто сказали то что все вы проходит 26 терабайт так вопрос никаких индексов ничего чтобы ускорял этот проход нет вопрос 26 проходит офицер ничего не то чтобы позволял бы ускорить прохождение в смысле прохождения ну то есть я понял ну например утроить какую-то статистику аналитику то есть все в нашей второй давайте немножко расскажу про view а тут форматы данных просто вверх к лицензируется понижать да ну а в реальности в базе они сжимаются поэтому они уменьшаются но потом они раздваиваются потому что у нас касаев 1 то есть они в двух местах хранятся и то есть что да и самое главное что вот то что вы говорите там существуют индексы танцует проекции вещи которые оптимизированы под can которые можно создать для оптимизации работы с конкретными запрос а мы со своей стороны пошли последующей то есть там можно создавать проекции то есть это вот условно варикоз таблицы может быть отсортированы по одному поле а вы можете хранить на сортировку другому никак не отражает христиан пространственно больше мест это фактически всегда требуется сдать вот эти проекции под каждую вашу задачу но мы пошли по пути высокой нормализации 6 нормальная форма она именно vitro чтобы мы не применяем справиться под запрос добрый день как насчет богатов бэкапы значит во первых но основной backup наш это касаев 1 то есть дублирование данных на этом кафе номер не пока что это филарет не пока да по поводу да это так я понимаю ваш вопрос вот до такого быка по глобального который позволит вот сейчас все это восстановить у нас пока нет ну нет ты про другой да нет там не пишется туда ничего сейчас да ну мы смелые ребята я говорю эта штука работает up at times этой штуки уже больше года то есть все ноды вылетали все целиком она держится при этом сейчас мы запустили систему почему я говорю что все это не за не база бы копировать мы сейчас старые данные вот пока экстриму мы их отгружаем потому что ну мы понимаем что они нам не нужны они занимают лицензионное пространство и мы старые партиции мы сбрасываем в сжатой c свои файлы и выкладываем на специальную серию ну может быть мы потом hadoop на нем будем считать или мы их будем поднимать обратно это очень быстро делается то есть вот такая сброс в церкви архивация у нас применяется просто она сейчас весь блок не прошел потому что сервер для сохранить в csv файлов он приехал только недавно мы запустили этот промышленный вариант только недавно а тогда мы просто смелые да а вот можно включить потому что плохо слышно и вот какие именно нулю по громче говорить вот а вот честно говоря когда я вот честно говоря про эту базу услышал в первый раз про коллеги с буду они к нам обращались по поводу консультации поверки но там с ним dessin смешная история то есть там просто коле английский офис вертите с ним не вышел на связь просто они именно договор не заключили то есть там вот так я могу озвучить причины вот с чем мы вас но мы сравнивали это ну это не я сравнивал то есть я так че просто знаю информацию про это green план на теза ну и там немножко там думали там про кассандры прочь основные достоинства верте копиров она работает на комоде серверах то есть это просто вот на рынке покупаются linux новая машина на неё ставится но соответственно ubuntu там не ставятся дистрибутив where текке она втыкается в сеть 1 и кластер на нее начинает раз сегментировать то есть просто обычный сервер там green плану green plant же может это сделать нити за или там например teradata им нужен им нужно сказать свои шкафы за большие деньги а второй это скорость записи ouverte ки совершенно фантастическая скорость вот именно из там csv или из бинарного файла загрузки внутри у него собственно команд команду load использование которой дает вам ну и он так расскажу сейчас самая большая инсталляция в мире ветки это у фейсбука ну чтобы вы понимали facebook он сейчас перешел на vertica они проводили нагрузочный тест то есть просто у ребят из вертикальных самих нет такого кластера который есть у фейсбука они вот вместе с ними экспериментировали они смогли добиться скорости 26 терабайт загрузки в кластер в час там правда кластеру не по моему 100 станок и там специализированные но ты под детей были сделаны у нас таких нет нам такое не надо же вы понимали 26 терабайт в час это вот предел вот именно сырой заливки ну и мы понимаем что как бы с нашими данными мы мы проживем даже если мы вырастим в несколько раз вот и третье это скорость ну вот в реально скорость аналитики она если вот знать вот эти маленькие нюансы она просто фантастическая работал с тирада той ну работал с другими аналитическими инструментами они могут читать быстро vertica может делать в разы быстрее вот эти вот вот аналитические запросы по десяткам терабайт который работает за минуты это в первыми первое время это просто шокирует а потом про привыкаешь вот еще вопрос вот сколько стоит соответственно там по объемам несжатых и все-таки если можно по подробнее по поводу 6 нормы потому что вы как бы получаете дублируйте функционал колоночный базу данных а часть потому что каждая колонка является соответственно но как бы поэтому проще почему по поводу цен сразу я не продажник вертите хотя возможно также про не рассказываемую не продаю а я не знаю цен но я могу скажи не знаете за что вы покупали ну как бы там был тендер я к моему все равно там есть какая-то политика естественно того что больше там опять заработать скажу я могу сказать краткие принципе то есть первый бесплатный потом вот до 10 там очень плохие цены поэтому выгоднее сразу злодейство есть 10 она выгоднее чем пять или шесть терабайт и там дальше то есть мы брали условно говоря в начале 10 потом мы по-моему добрали 15 и следующая планочка хорошая это вот 50 то есть там вот такие падения цены за терабайт происходит по поводу почему мы используем 6 нормальную форму хотя там она колоночный во-первых из-за лицензионного пространство представьте да вы можете взять загрузить таблицу с к экстримом где например реферер и и урал и и cookies они будут повторяться верте к их сожмёт на диске сэкономит вам кучу места но в лицензионном пространство нибудь точно так же в нашем же случае так как мы грузим нормализацию мы грузим каждый уриал длиннющий каждый refer каждую куклу один раз а дальше мы сохраняем просто ссылки на них вот это позволяет во первых невероятно упростить аналитические запросы например там действия с определенным уралом это очень просто потому что это просто ссылки с него вот и позволяет очень здорово оптимизировать место и второе хотя формально колонна и хранение должно делать то же самое что 6 нормальная форма в реальности когда размеры таблиц достигают десятков миллиардов там начинаются нюансы в частности у на у меня был секс эксперимент таблица 50 столбцов а лились данные к экстриму в неё и они лились в 50 узких таблиц первый месяц до того как мы набрали пару миллиардов заливка была одинаковая а потом заливка в широкую таблицу она начала деградировать она начала замедляться потому что там зависимости сжатия и прочее и вот месяц нормально потом она через два месяца на в 2 раза медленнее а потом мы просто поняли шнюк лари ность 15 минут то есть узкие таблице они вам гарантируют скорость всегда сколько бы там нибыло широким возможно нюансы и второе что многие операции верте кеа они основу то есть таблицы гигантский когда вы хотите с ней что-то сделать например реп арте цианирование рей сегментировать такое часто бывает невозможно сначала сделать дизайн когда у вас узкая таблица вы можете запустить процесс на ней подождать пока он несколько часов поработает потом запустить на следующий это вам не убивает систему если же у вас таблица в которой пятьдесят столбцов и 100 миллиардов строк вы запускаете на ней репозиционирование она требует выделения временно у память равно размера таблицы у вас на серверов кого нет все до свидания ничего не можете сделать абсолютно реальная история с одной из инсталляция вертит в россии поэтому узкая таблица она развязывает вам руки вы сможете с ними когда у вас много маленьких можете с ними играться широкие там вот вот эти два три нюанса а' соответственно при join проекция они как-то вы используете их данном случае при join a нет мы не используем при джоне проекции потому что у них тяжело с outer join me то есть фулл joins смысле когда inner join супер но у нас часто бывают outer ног же простейший пример вот те же cookies у нас все действия с обе в свое время были без скуки а проекции вы используете семьи редко иногда используем но в большинстве случаев когда у нас узкие таблицу это не очень нужно иногда используя но они брали я понимаю что они используются как бы для при калькуляции то есть когда вы льете у вас получается нет проекция это другое проекция это индекс то есть все данные лежат а есть в верте кинет бинарных индексов нет деревьев она хранит все ваши яндексе просто отсортированы ну документация сказано что это все-таки данные которые хранятся то есть это получается что колонка вы как бы храните данные они индекс там как бы вы пересчитывайте то есть если вы делаете агрегацию в проекции да там select каунт то у вас уже будут лежать вот этим как бы агрегированные данные вы нет вы говорите про приклейте the great который в 71 появились но он намерен вот эти вот эти но это новая штука она такая экспериментальная тоже не для всего работы это да я я понял вопрос именно что это просто про проекция то что все так каждая таблица это проекция плюс может быть создано другая проекция на тех же данных которых просто продублируют от сортирует в другой по другому но только тоже будет отсортированные данные все равно то есть смотрите выберите колонку и и соответственно потом делать и не из неё про акцию то у вас будет колонка отсортированный по другому с удвоенными данными то есть у вас и будет исходная колонка и соответственно уже как бы отсортируем другом то есть два раза данные был туда а если вы сделать речь это вот три раза причем это важно еще раз это таблиц она работает то есть эта база она кластерная то есть все вся каждая таблица большая и и приходит нужно сегментировать и кондиционирует но нет ее нужно и парте цианирование сегментировать томат разные вещи то есть вертите сегментации называется вот именно sharding на сервера а позиционирование это внутри сервера их еще можно понять на чем по времени до чтобы например сбрасывать старой портится потому что у этой штуки она почти не держит например или ты апдейта очень не любят ну это хранилище да ну да если правильно сделать если вам не нужны апдейты делита это действительно супер но например если вам очистить старые данные вот не дай бог вы будете отдел дали там ну просто все вот так сразу ляжет только друг портишь а то сразу же вопрос а как вы дельта накатывать и вот вы говорили что вы заливаете только изменения вот прям вот ну может быть на мужскую реальных запросов да у нас все все и все эти работает naskel внутри то есть - лон говоря мы заливаем некоторый блок данных большой то есть миллионы строк а потом вот этот блок сравниваем с тем что в daisy просто что отличается то и загрузили сравнили вот у вас допустим одной строки не хватает одна строка отличается значением что дальше в вертите происходит если если строки не хватает анапа записывается если строка отличается значение и на таблице включена историчности отключена не везде ну например поля с артемом юзерам а не исторична то вот эти узкие таблице они построены по sc2 с очень домашний тир 2 и просто формируется следующая запись что с такой-то даты у этого объявления например цена стала вот такой то есть классическая очень dimension то есть актуализация запись то есть это using ох как кажется там using этапах по моему них есть такая штука да нет ладно потом нет я понял и плохо но это не это не эпоха это там есть такая штука эпохи это про другое но это просто набор на уровень функционал и скейлер просто insert но апдейт очень dimension с одним и сторичный полем не буду рассказывать но если то можете почитать или спросить да можно питать то что потребители данных it аналитики там нельзя допустим зайти в личный кабинет нам построить график поверьте ки напрямую нет потому что она аналитическое у нее достаточно большие транснациональные издержки то есть там открытие connection и прочее не миллисекунды это занимает время просто кидать запрос а сколько бы она держит правильных вопросов параллельных ну сейчас мы вот сейчас ограничения стоит на условно говоря 407 ну то есть смотрите вот там работает аналитики там работает doblo там работает постоянно ялте запросы и там работают модели дата майнинга и там работает ну например у нас есть специальный интерфейс для полиции полиция хочет узнать там вот это объявление кто его смотрел ских айпишник of хорошо но в общем у нас есть способ который позволяет большое количество запросов туда через очередь вот ладно ну в общем давайте я думал про инсталляцию все дайте попробую последний вопрос я попытаюсь рассказать собственно про задача трафика еще один вопрос скрутки и используются ли vertica для тестирования используя вот там действий аналитиков у каждого из них свой блог задача он приходит говорит мне нужны вот эти вот эти данные добавить добавляется иногда стресса новые новые таблицы они добавляются витель параллельно он расширяется она льется и он берет эти данные иногда на месяц в глубь и анализирует стране а бы тестирование на когда разные версии сайты показывается разными пользователями льется меточка вот у каждого действия лимитами ты там меточка эксперимента не то что а и b там их больше на я понимаю да и на каждое на каждый строит свои стать и спасибо вот это как раз вот эти метки и добавляется как расширение да ладно давайте теперь попробую рассказать собственно как мы трафик хорошо так вот задача то есть еще раз vertica очень мощная позволяет очень здорово все считать но у неё тоже есть задачи где она утыкается условно говоря предел каковы задачи расчет трафик то есть нам нужно почитать количество наших уникальных посетителей а соответственно у нас есть допустим времена месяц неделю день у нас есть географическая российские города у нас есть категория автомобили там бывает мы поддерживаем и нам нужно вот для этих иерархии посчитать вот для каждой элементарной разбивки нужно посчитать количество не коли посетить а соответственно вот сочетание которых я перечислил перемножении при чем тут разные типу действий ну например поиск объявления просмотр объявления там еще что-нибудь есть платформы то есть например на обычных компьютерах там или мобильная версия просмотр через api просмотр через iphone просмотр через android разных платформ и вот этих всех сочетаний это примерно там три миллиона там в реальности измерений с 3 миллиона новых сочетаний именно за счет того что носит декартово произведение ногу и главный фокус ну то есть принципе если в лоб смотреть мне очень страшно в день у на 350 миллионов событий а если помните там было 500 почему 1050 потому что а нам интересен тратить только плохо human traffic у то есть только люди то есть это уже после того как он прошёл сложную фильтрацию и от всей на роботы нужно загримировать три миллиона миль в принципе не очень сложная задача казалась но отчет по трафику он не аддитивным то есть если у вас человек зашел в городе сочи поискал новый автомат из-за такого хищников такой момент а это уникальный посетитель на уровне российской федерации на уровне краснодарского края на уровне сочи авто на уровне сочи новый авто и так далее все на уровне все авто то есть везде это уникальный посетитель и более того мы не можем получить цифру на уровне российской федерации складывая цифры на уровне иерархии ниш то есть каждый из трех миллионов агрегатах нужно считать независимо а чтобы это считать нужно каждый вот этот объект его соответственно размножить каждую бригад ну югру а бригадный брус среднем получается но там примерно 20 то есть пример перечислил то есть 10 миллионов событий они размножаются в 5 миллиардов сочетанию то есть в 5 миллиардов вхождение в уникальный двигатель и вот эти пять миллиардов нужно зафиксировать в три миллиона групп в принципе даже не очень сложно казалось бы в принципе vertica это держит без так сказать без строгих мер но если мы считаем это за месяц уникальные посетители которые в течение месяца в сачек подержанных автомобилях с айфона что-то искали искали а то сочетание уже буду полтора триллиона как я уже говорил самых больших таблиц и которые нас есть там порядка 130 миллиардов и это предел тут полтора триллиона события это полтора триллиона записи это очень много то есть чтобы где-то считать нам взять нужно свою версию кластер мир тики и вот просто купи в 10 раз дороже на неё заплатить соответственно если у нас такая проблема ее нужно сортировать нужно как-то медь поделить на кусочки как же ее можно поделить главная проблема тут заключается в том что мы не можем за счет не аддитивности мы не можем в h9 данные по входящим то есть мы не можем взять входящий трафик уделить его слову говоря на 10 кусочков и агрегировать их независимо потому что данные из каждого из 10 кусочков этот пример привел а не за счет размножения могут в итоге попасть в один целевой агрегат ну например российской федерации единственный способ формирования целевых на и соответственно грамотная конструкция работали мы делаем начали строить полный список всех не пустые колеус тысяч читаем дальше мы устроим устроил такие уникальные пустые сочетаются и мы строим адресу который говорит что например упадут все знают все таки мира краснодар сочи для каждой группы мы закроем все падает а после этого мы проводим можем провести шунтирование уже целевым группам то есть берем выделение уберется характеристик они обещают решили берется старых и деление отбирается на горе группа который не падают размножаются в точке как это пока анализируется но вот базовым вселенных к мамке стинг группа падает в целевую облёкся уже то есть каким образом считаются целевая ребята волос причем для удобства это размножаются чуть по регионам независимо делалось в то есть вся эта конструкция арки струится на новую за счет у питона потому что версии нет просто процедурный логике нам нельзя сделать нормальный процедуры всяких процедур налоги как только вы можете соответственно то есть реализация алгоритма каждый шаг за каждый день независимо размножается формируемых середины уха который содержит десятки миллиардов агрегируется ему заполняя и так повторяется говорят о каждой ячейки а размеры че то есть его собственно готового результата это сумки ведь вселенных народов где семь шагов а соответственно начинается обычно меньше недели месяц 7 миллиардов на ход на двадцать один фрагмент а соответственно 16 17 часов когда это делать лучше выходные потому что верность и что что то пора ли дело но часов у нас полностью пересчитаны месяц и самое главное что если нам приходит руководство говорит а почему вы вот эти записи с таким уралом считают не считаете как некая и изменить алгоритм мы можем сказать о кей стерео трафик за какой-то месяц и перечитать его по новому алгоритму чтобы лучше бился с данными олив интернета на лица передали собственная я практически успел давайте успели увидеть ava rose можешь сказать каким образом происходит сбор активности на сайте вот этих вот quick stream ну соответственно в общем ну с веб-приложения лакируют через плюньте это пишется флис люди флинте пишет логе в манго с манги они пишутся верху там на каждый какой-то ульяновске срабатывать записывает вот эту вот штуку ну не в мою штуку а в его штука мне рано или поздно она попадает своих мою штуку спасибо америке замечательные документации по делу но кратко вот а какие дополнительные ресурсы есть кроме их форма форум но вот вот мои vertical он очень хорош потому что там сразу связываются человек то можно общаться и самое главное что если начать с чеком общаться из него можно выловить всякие внутренние handed очень полезно есть там живы они они правда все индусы но они живы они по делу отвечают и слова что вы представляли в августе туда ездил в бостон вот там вот все все все топы разработчики это наша то есть такие вот советские евреи то есть там вот все как надо все сделано правильно и с ними можно от них многому можно полезного узнать то есть если выйти на них на контакт а можно слайд назад вот эта трубочка которая соответственно это что это смотрите вот вот запись например что седьмого числа человек в сочи искал подержанный автомобиль и вот эта . для агрегации она размножается что подержанные автомобили скал краснодарском крае искал в мороси искал автомобиль в россии то есть это размножение cookies не того чтобы она отразилась на каждом эта таблица то есть это как бы получается вы создаете в арктике соответственно таблицу и в нее соответственно выбираете из хранилищ то есть это временное но она не временная но это это как бы такая буферная таблица которая а вот после того как бы цикл прошел она защищается то есть ну она очень большая там реальности миллиарда строк но вот она так живет очищается заполняется агрегируется и по новый как один короткий вопрос я здесь по поводу дней не вы читаете по часовому поясу по москве появитесь и или каждый для каждого региона свой в общем поить еще пройтись и то есть не услышу это по-разному делается просто чтобы как-то чтобы был не один insert a чтобы условно говоря там месяц чтобы был там тут 37 ну руководству же интересно наверное дням кому по правильным дням по дням по региону смотреть аналитик ну скажем так пока они такого не говорили но если они захотят мы с радостью им это все от коллекция их их устраивает или сил хватает у нас москва-питер основной пока трафик вопрос такой для загрузки дементьев и что-нибудь использовали для загрузки человека для диментий то есть и метаданных и как вы там называете офисные офисный или то коснулся лишь на покоится ну это нельзя скажет измерение нет просто из нашего наши базы быть рядом сидят которые сделали просто инкремент он побольше таблицам инкремент по маленьким все погружается в церкви и прокачивается верху каждый на 20 минут или час то есть руками через верх улучшить слова с моста через моим лучшим то что откажут . еще вопрос скажите а вот аналитики они прямо несколькими забросами или есть какой-то того которая умеет генерировать арийских запросы но мы его не пускаем дальше зома то есть это зон или 3а плюс детальные условия они прозрачны я думаю в общем последних что мир проблеме уже говорят растит скажите пожалуйста удаляете ли вы из источников данных . экстремист бэк-офиса и сколько хранить и персики из источников ну как бы мы в источниках их не специальный механизм первых офис он не хранит вторичное почти а смотреть данный по корпусу то есть объявление а юзеры прочее с историчность у хранятся до конца времен не стирается вообще ну просто вам их мало по экстриму мы сбрасываем старые месте вот сейчас она сдана и вот строго сначала 14 года вот мы возможно через некоторое рф пара месяцов порежу потому что закону мы должны дело хранить там все вместе мы храним соответственно больше на место хватает перестанет хватать в этом чуть-чуть подрезать собственному счет"
}