{
  "video_id": "ZjyjawX_VAs",
  "channel": "HighLoadChannel",
  "title": "NoSQL внутри SQL: приземленные вопросы практического применения /  Дмитрий Долгов (Mindojo)",
  "views": 879,
  "duration": 2588,
  "published": "2017-04-22T14:48:16-07:00",
  "text": "продолжаем общаться про слабо структурированные данные про но всегда так называемый тренд очень популярный возможно кто-то из вас застал потрясающий доклад брюсом он же на внизу в зале сингапур сегодня с утра был пронос сиквел внутри postgres а сейчас нас не менее предстоящей докладчик по имени дмитрий долгов который расскажет о том как нынче вообще работать с документа retiro ванны и данными в современных классических реляционных базах данных придет такой обзорный экскурс и расскажет что называется что где и как и почему давайте друзья поприветствуем да всем привет собственно сегодня мы до как уже сказали обсудим тему на самом деле материальную тему это но искать фичу в стандартных реляционных баз данных и для начала вопрос аудитории кто пользуется джейсон 2 типом данных после силе бинарным джейсона мосту или ты на самом деле хорошо это очень радует самом деле да тема популярна и последнее время и собственно от мои контакты если кому интересно работы сейчас компании минджи но последние пару лет я связался с ребятами использовать professional и стараюсь как-то по мере своих сил и возможности внести вклад в развитие в себе в подпись и и прелесть в том что да при том что мы должны мы работаем с манго тебе в под колеса на скамейке у нас сейчас на видео по отгрыз и я как-то получается на на краем на грани двух этих миров нахожусь в принципе имеют опыт экспириенс с собой из областей получается в интересно собственно что мы будем изучать первичный посылаются в том что у нас данные которые находятся на 6 м с которыми работаем они всегда очень разные и один из способов самый достаточно простой их разделить это сказать что у нас есть данные которые очень хорошо кладутся на реляционную модель и документы ориентированные данные то есть принципе такая противоположной для вещи и естественно решение для обоих уже давно существует хорошо проработанный но начинаются проблемы если у вас необходимость возникает обрабатывать одновременно эти два типа данных в одной системе в принципе логично что у вас есть для того чтобы это все приблизительно делать у вас есть два решения либо разносить эти два вида данных в отдельных хранилище и соответственно там у нас просто возник инфраструктура какие-то все такие вещи либо хранить их в одном хранилище если она предоставляет такие возможности и естественно у них у каждого из этих вариантов есть свои плюсы и минусы понятно дело что если мы берем отдельных хранилище мы совершенно ничего нового не придумываем у нас наилучшая производились для конкретного типа данных все хорошо но вопрос в том что у нас возникают проблемы инфраструктуру и нам необходим поставить крупную такую серьезную инфраструктуру для того чтобы взаимодействие эти хранилища разные и и более того на там в конце концов вам скорее всего всё равно понадобится какая-то аналитика у вас возникнет дублирование этих данных все такое прочее в общем нетривиально на самом деле ну и свои плюсы и минусы есть у единого хранилища самый главный плюс это естественно она не требует какой-то интерграции инфраструктуры особенно это важно для тех случаев когда у вас данные разных форматов несовместимые он не сравнимы по объемам то есть в этом случае вы просто совершенно никогда не отобьете затраты потраченную инфраструктуру для вот этого маленького кусочка нестандартных данных которые у вас есть но опять же вопросы связаны с тем что мы серьезно получается очень зависим от конкретной база данных которые мы используем и ограничены в тех вещах которые она предоставляет ну и собственно вот этот вариантный как раз сейчас больше всего я обсудим в принципе мы будем осуждать на примере на примере мы искали я подрос а сам-то я поскольку по сетке больше отношение к подросли невозможно будет небольшой такой забег в эту сторону но я стараюсь сделать его более равномерным и так вот сейчас небольшое время занимательных историй какие примеры какие данные я имею 2 3 за реальной жизни как я сказал работая в компании main тут же у нас есть такая интересная вещь все наши данные они строго разделены чисто логически строгой разделен на 2 части 1 и части она очень хорошо ложится именно на объектно-ориентированный модель документа ориентированная модель это данные связанные с обучением то есть у нас профессора пишут какие-то данные курсы там уроки все такое прочее и поскольку это контент и сейчас наносим сильно меняется он очень и структурированный там они постоянно придумывают что-то новое новый тип вопросов так далее и более того это вся вот эта вещь она очень хорошо так вот связано блокирована в рамках курса в рамках какого-то урока поэтому это все очень хорошо ложится в эту тему но естественно у нас есть и нормальные данные там пользователи какие-то биллинговые информации и соответственно для них было бы неплохо иметь хороший резоны данные там транзакции как минимум все прочие вот здесь уже совершенно у нас большие проблемы с мангой и скорее всего мы будем их потом разделять ближайшем будущем просто два сервиса потому что других опций нет ну и другой пример с противоположной стороны очень часто на конференциях спрашивают приводит такие примеры и в моем опыте тоже был такой один проект когда у нас данные в проекте абсолютно реляционные все хорошо но в какой-то момент возникает необходимость иметь например в модели пользователя какие-то хитрые вещи которые там эта информация может какая-то в нашем случае это был набор настроек для виджетов которые использовались в пользователи нашей системе и соответственно они постоянно меняются создаются что такое но не хочется естественно ничего для такого маленького случай информации дело дополнительно и вот например нашем проекте мы используем этот момент штор и ждали миграции на 3 сундэ когда она вышла в пол 1 94 ну вот примерно такие реальные примеры использования такие примеры реальные примеры данных которые нас возникают и в принципе эта тенденция предоставление но эскель фитну в данном случае скорее мы все-таки говорим документы ориентированных фич в реляционных базах она на самом деле последнее время больше и больше заметно и наиболее у двери частных базой в этом плане это по сбросу и москве как минимум в них есть бинарное представление документов но и от для перечислены остальные в тоже от есть более каком-то или менее добавим формате но они-то медленне чуть меньше возможности вы они текстовые но тем не менее тенденция прослеживается ну и основное мой посыл в данной презентации с будет качества в том что на самом деле когда ты это может быть было немножко страшно сейчас тоже очень просто взять и начать работать такими видами данных в обычный реляционной базе данных на самом деле сильно ничего проблемного то нет и вы можете завтра прийти на работу с конвертировать через данных в адрес он и радоваться жизни ну и вообще какие шаги чтобы начать это делать понятное дело что у вас есть только два источника данных либо вы хотите конвертировать в документы какие-то данные внутри вашей реляционные базы предположим так получилось вы хотите поиграться либо внешние какие-то источники но если мы хотим работать внутри конвертировать данные внутри нашей базы у нас есть простота набор функций для того чтобы их вручную построить но это естественно не очень удобно гораздо удобнее делать вот так это джейсон для кредит в пост грехи и вот к сожалению только недавно появилась майские леса смерти тоже также функция называется же сон облик агрегат который я привез который учится в том чтобы просто указываете выборку которую необходимо какой-то набор данных и за вас она автоматически делает документы у которых каждый стал каждым статус соответствует один ключ в документе крайне удобно и абсолютно декларативное просто замечательно работает естественно если у вас есть внешние источники данных это тоже достаточно легко мы просто копируем внутри базы но а тут есть некоторые тонкости источники тоже будет разные например если вы просто делаете манга дамп из манки то это одно это в принципе свежие и актуальные данные все хорошо просто загружаете учитывая специфику monkey там разные специфические виды более прочее бывает другие ситуации когда у вас есть просто какие-то исторические данные которые по какой то ли иной причине были сохранены в формате джейсон и тут уже возникает вопрос а что они могут просто элементарно битные поломаны и если они совершенно поломанные в том плане что там нарушена логика единственное что вы можете сделать это просто руками пройтись от сожаление абсолютно в мануальным способом цилиндром посмотреть что мне так и загрузить но если структурах данных не нарушена вы можете воспользоваться библиотекой на 30 женщин five очень удобная штука это что то вроде такого более мягкого стандарта для джейсона там разные скобочки а не знаю какие то кавычки и запятые опущенные она все то проглотит и выдаст он хороший валидный джейсон который выпал без проблем потом загрузите в подросли бы в москве ну и следующую часть относительно производительности и даже скорее относительно грабли который можно словить в плане производительности то есть раньше ну буквально еще несколько лет назад и еще до сих пор бытовал миф о том что использование документов реляционных базах достаточно медленно и есть смысл это делать если у вас какие-то данные не требующие производительности сейчас я уже на самом деле не совсем так и дальше я постараюсь показать что к чему в этом плане чего можно избегать чего чем нас она наоборот можно пользоваться там достаточно интересно ну и тема конечно скользкой на самом деле потому что бенчмарки всё такое прочее можно сделать что угодно на самом деле показать что угодно но в принципе все равно я надеюсь что какие-то знания вы из этой бенчмарков вынесете и сначала обсудим факторы которую яд на производительность в случае документов реляционной базе данных во первых эту структуру данных в которых они хранятся на диске по большому счету все они об одном и том же что в виссон в манге что джейсон дэй это просто обычная же сон в котором добавлено какая-то дополнительная меты но не мета дополнить информацию например о типах и размерах данных которым ты хранятся просто для того чтобы можно было потом быстро бегать внутри по этому документу почему это важно во-первых это влияет непосредственно на объем данных которые вас сохранится а во вторых есть операции который происходит быстрее если мы их выполняем непосредственно в диском представления нежели поднимаем в память то есть вот там такой баланс необходимо находить и в принципе есть разные вариации на эту тему другой пример другой фактор который влияет реализацией 10 реализации данных когда мы поднимаем диска и представления в память в принципе по большому счету во всех решениях которым и дальше рассматриваем она более-менее идентична сити стараетесь а в том что там немножко разный порядок вот как они внутри внутри структурированы ну и собственно очень важный момент это то каким образом поддерживает индексирование по нашим документам ну и как я уже сказал им рассмотрим три решения это манга деби как такое ну может быть не самый хороший пример но я склеил база данных но как минимум самый популярный из ним зачастую мы сравниваем ся потому что это просто интересно ну вот примерно так выглядит у нас тип данных bison в диском представлении это на самом деле по факту такой интерфейс найти потому что он использованных везде не только внутри они просто показывают наружу и выкатим следующим образом у нас есть какой-то документ says от всего этого всего документа и затем внутри вот есть такие повторяющиеся кадры где у нас указан тип значения собственно ключ который к нему относится его размеры и само значение сделано для того чтобы можно было легко прыгать с одного значение другое просто пропуская какие то количество какое-то количество просто данных на диске ну и котел скалат интерфейс вы можете взять любую библиотеку которой это поддерживать и посмотреть что оно представляет из себя внутри вот ездил питонов sky bison и вот в виде в начале вот там 1700 это у нас размер документа дальше вот этот ключ и и потом его значение троечка чуть дальше у нас ключик б опять же с типом который находится двоечка эта строка дальше длина четверочка и собственно x y z строка в самом конце у нас находится собственно то о чем не говорит тристан рифма версий немножко сложнее в том плане что нарушен не показывается он абсолютно внутренней но структуру не очень похоже исключением того что у нас ключи они сгруппированы вместе с то есть начала подключим потом значение они не перемешаны между собой и в итоге в принципе структуру то же самое но немножко разные распределение в данных и если захочется тоже можно посмотреть тоже видно здесь два ключа и обе они находятся рядом абсолютно там дальше мета информации туры в конце два значения троечка x y z это тот самый документ которая показана начали то есть вот вот этот вот ну и в моей сплели турне свой особенность по факту там что-то похожее тоже тип значения тоже длина и все такое прочее но а там есть в начале к же документах и др в котором указано так называемые поинты rhino необходимые данные не только назначения но еще и на ключи и пойнтер естественно поскольку танкистами представлении это не по этой в память это просто смещение и длинные которые необходимы для того чтобы быстро что-то найти в этом так менти относительно второго фактора относительности реализации данных собственно как я уже сказал они более менее похоже во всех трех случаях в манге у нас все сериале зайца в память в структуру древовидную дерево элемент в мой скейт принципе тоже пост 200 что-то похожее там тоже древовидно структуру но там ключи и значение они выложены просто в список 1 последовательно и поэтому да по нему продвигается в коде во всех функциях просто проходятся побега нее по списку ну и индексы тоже интересный момент на самом деле в принципе в манге все очевидно там есть простые обычные индексы там их на самом деле не очень много типов на самой часть используем обычно просто bo3 по какому-то пути внутри документа в подписи все интереснее там есть два основных типа данных типа индексов первый это джин индекс который просто индексируют и вот например с опцией тенге по fox который индексирует все пути внутри документа то есть это такое продолжение идея о том что если мы используем джейсон нам как бы не было бы неплохо иметь гибкость и поэтому вы устроите этот милость и дальше больше не заботьтесь он работает достаточно и производительное в принципе он очень популярен но при необходимости вы можете построить яндекс по конкретному путину 3q мента и это будет просто занимать меньше пространства дискового вашей системе ну и в москве или к сожалению нету прямого способа индексировать документы там вам предлагается создавать просто виртуальные генерируемые поля и индексировать их как обычные мы теперь непосредственно к миску к бенчмарком как я уже сказал тема такая вот спецэффект специфичная немножко скользкая подозревающего там пещерный человек производил бенчмарки там высоты костра в зависимости от степени не там сухость и дерево которое он использовал и собственно сначала небольшой такое background во-первых известная не первые кто то делаю наверное даже не последнее естественно были до меня разные исследования в том числе я в прошлом году делал бенчмарки на основе инструмент осознав из интро произвели и по большому счету они говорят об одном если вы использует документы внутри рельса на базу данных это как минимум будет достаточно хорошо то есть в большинстве случаев вы получите производительность как минимум такую же как и например той же манги либо лучше есть конечно разные вариации какие-то кейсы но тем не менее общий смысл примерно такой ну и стенд на котором мы гоняли собственно основу за основу был взят мной инструмент называется яху клауд сервер benchmark это очень удобно и на самом деле утилита мука конструк инструмент такой полноценный развернутая система для тестирования разных мой стиль решений написано на жаль из обертки мина поэта нее там очень много разных драйверов для разных разных баз данных mysql там не знаю там манга коучи и gps там что угодно вот эту с великолепия и в том числе есть драйвер для джитибиси он очень простой на самом деле и поэтому там пришлось в итоге сделать форк чтобы сделать его более интересным но прелесть этого в том что там внутри уже много заложено в нете различий и если вы используете я халат был бы скорее всего лужу пак получаете на выходе полноценные результаты которые можно хорошо потом просто проанализировать ну и версию нас было 08 мы проверяли это на небольшом таком на самом деле наборе документов то есть там в среднем было около 1 миллиона там в разных случаев по-разному это не очень много нас другой стороны этого достаточно чтобы увидеть разные эффекты ну и вот следующие были выбраны версии трех баз данных это все гонялась на амазоне на инстансе м4 слэш вот со следующими характеристиками в принципе достаточно памяти более-менее достаточно процессора и там были внутри ssd находились ну и естественно ключевой момент данном случае это не то что сами тесты мы гоняем а в том что мы постарались сделать их воспроизводимыми дело в том что все эти модели которые были раньше они просто будут картинка графиках вот хоть что хочешь то и делай с ним для того чтобы выяснить что он был внутри нужно было писать автору как-то разбираться и так далее в данном случае у нас есть форму я кукла второй матч марк можно там посмотреть и есть скрипты которые настраивать все необходимое окружении на ems apple они на самом деле ножках сыроватый пока еще там есть разные вещи такие но основная база в этом месте она уже работает я очень надеюсь найдите ru если кто-то из вас захочет потыкаться посмотреть и попробуй тоже вас провести какие-нибудь из этих результатов это будет очень полезно в том числе и для нас вы конфигурация понятное дело что речь на самом деле очень разные манга под брус майский и как бы влезать в настройки разные не очень хотелось бы потому что то огромное количество общее исследования дальнейших нужно все делать поэтапно но есть вещи без которых обойтись нельзя во первых эта память манга она выживает всю память поэтому необходимо тоже хорошо по памяти настройки под груз и майский ну и естественно необходимо настроить все что связано с райт консервы с durability потому что по умолчанию вас в манге редкий черный лак на улице он просто кидает и забывает фанфред естественно там огромной производительность но durability не очень соответственно в данном случае я использовал два подхода red концерн журнал-то которые в документации описывается как наиболее ну как наиболее надежный способ работы с данными для одной машины то есть не учитывай кластера просто одна машина но фишка в том что есть там еще другая вещь в vr таргет в арт объект если вы посмотрите в документ в код там есть опция называется траншеи транзак сенсинг метод и его можно указать в sing это на самом деле более такой но по моим представлениям более честный sing то что происходит в других базах данных но разработчики манга это очень не любят они бьют всех попасть in кто это использует но тем не менее я вот в расчетах старался использовать и то и другое расчетах что я говорю в в бенчмарках естественно ну и собственно что мы выбирали самый просто способ это сделать выборку просто из документов из нашей базы данных здесь использовался то что я сейчас называю в презентации маленький документ на самом деле вопрос относительно это 10 полей в каждом из них просто рандомно сгенерированной строка из 100 символов ibiza вложенности поскольку это сам простой вид нагрузки которые у нас есть в данном случае мы используем яндекс и вот получили такую интересную картинку она на самом деле была неожиданной потому что я ожидал что джейн будет чуть более производителен но как мы видим здесь выпуск 1 и началось очень так то наверное там 10 20 потоков насыщение дальше он вышел на прямой уровень то время как манга прыгнул чуть выше но потом немножко упала на в данном случае москве на самом деле как то очень плохо себя показал я такой до конца не понял чем это связано потому что индексом определенно используется там памяти достаточно то есть это либо какая-то ручка которую я там потерял может быть не докрутил либо прямо от проблемы с реализацией ну естественно если мы используем джин джин яндекс и он как-то так интересно себя ведет посмотрим тогда другой надо slide in sin другой интересный момент как менее 10 манга лучше в среднем работает на sin берем 99 пирсинг или latency мы видим что после внезапной все равно более стабилен получается манго вначале этом на пути потоках она хватит более выдает большую прогнуть способность но один процент запросов он очень долго висит ну это если я не сказал об этом если вы не поняли внизу там количество клиентов которые дал газ в базу ну а по вертикали по оси y у нас соответственно метрика ты в данном случае это она на секунду там до этого были секунду операция секундам но это мы посмотрели один из индексов другой сразу интересно посмотреть обычно нормальный b3 яндекс по одному из полей и и тут уже другая ситуация другая то есть как минимум у нас начали до 20 потоков puzzles и манга растут практически один в один а дальше нас происходит такое стекло рода насыщения адреса ну а манга падает гораздо серьезнее то есть принципе получается что по выборкам вы уже получаете в принципе лучше в данной конкретной ситуации ну и латинских принципе здесь тоже ожидаемая например такой же как раньше было следующий вариант ну так я сказал структура документа была очень простая и в принципе сердечек markant подразумевается что он заточен а именно такую структуру и если вам нужно что-то более сложное вы делаете то слой драйверы в нем пишите и в данном случае оду этому проверяли просто произнеси индекса но еще документ как сериализация и поэтому мы сделали более сложные структуры документа это там три уровня вложенности у каждого но каждого значения у кота куча по 4 потомка там два значения 2 еще глубину то тогда общем полноценное дерево которые необходимы эти реализовать при работе и сделали в принципе примерно ту же самую выборку результаты получились ну естественно количественно чуть пониже но смысл тот же самый то есть начиная до какого-то количества клиентов которые долбятся в базу маски под газ и манга они примерно одинаковы и дальше то опять же происходит спадания но в данном случае у манги она чуть меньше но опять же как факт мы получаем что мы как минимум такую же признательности имеем по чтению даже на сложных документах и в принципе сериализация но это очевидно то есть реализация штука такая которую трудно плохо реализовать поэтому во всех трех решениях оно более менее производительные ну или там все тут на самом деле интересный график тоже немножко не очевидно для меня дело в том что вот после 60 клиентов резко повышается ли пенсию по адресу я и у манги out майский как то начинать себя все еще вести равномерно и это в принципе на самом деле интересный паттерн который проследую сквозь все графики которые дальше показываю ума и спели почему the light on se более равномерно и хотя в среднем он работает похоже это очень интересно самом деле вещь которая возникла но тем не менее но естественно это вот мы посмотрели индексы им смотрите реализацию но нам очень редко бывает необходимо поднимать весь целый документ часто мы хотим выбрать из него какую-то часть например взять средств или одно поле и тут же подключается дополнительный уровень машинерии собственно выборки всех этих вещей этих веществ уже посмотрим здесь я уже взял штуку которая зал большой документ здесь у нас 100 полей в нем и удвоенная величина каир значения над и повезли символов то есть мы получается увеличили в 20 раз примерно документ опять же что по ли это на самом деле очень такой вопрос тханки потому что вот например списки рассылки прогресса вы как-то раз писал один человек у которого была там 500 морей например то есть все зависит от конкретной системы от вашей конфигурации в такое прочее здесь на самом деле картинка момент следующая напоминаете тоже индекс b3 и как мы видим это по трусы немножко правильность получается поменьше процесс способность есть опять же пик связанные с 20 примерно клиентами о манге но дальше он падает и есть получается в данном случае мы подключаем эту машинерию по выбору одного ключа и чуть уже получается похуже есть такая тонкость вот здесь на самом деле это заключается то о чем я говорил раньше выборка первого элемента в манге она происходит обычно чуть быстрее чем остальные потому что просто на уровне реализации там прямая ссылка она на самом деле данном случае погонял варианты с первым выборкой 1 полюс уборка последнего в принципе разница была но они очень заметная показать так друзья у нас уже три часа регламент требует начало нашего положения нашего мероприятия нас такая небольшая секция по базам данных и архивах осталось вечерком 3 доклада интересных продолжаем общаться про слабо структурированные данные про но вы всегда так называемый тренд очень популярный возможно кто-то из вас застал потрясающий доклад брюсом он же на внизу в зале сингапур сегодня с утра был пранав сиквел внутри postgres а сейчас нас не менее представить что-то клочкова и медведь и долгов который расскажет о том как нынче вообще работать с документа retiro ванными данными в современных классических реляционных базах данных придет такой обзорный экскурс и расскажет что называется что где как и почему давайте друзья поприветствуем да всем привет собственно сегодня мы до как уже сказали в обсудим тему и самом деле интере альным тему это но если фичи в стандартных реляционных базах данных и для начала вопрос аудитории кто пользуется джейсен 2 типом данных после силе бинарным джейсона месту или ты на самом деле хорошо это очень радует самом деле да тема популярна и последнее время и собственно вот мои контакты если кому интересно работы сейчас компания мандат же но последние пару лет я связался с ребятами способов professional и стараюсь как-то по мере своих сил и возможности внести вклад в развитие трясины в подписи и прелесть в том что да при том что мы не должны мы работаем с манга тебе в повысят с на скамейке у нас сейчас на видео под груз и я как то получатся над на край на грани двух этих миров нахожусь в принципе имеют опыт экспириенс собой из областей получается очень интересно собственно что мы будем изучать первичный посылаются в том что у нас данные которые находится в нашей семьи который мы работаем они всегда очень разные и один из способов самый достаточно простой их разделить это сказать что у нас есть данные которые очень хорошо кладутся на реляционную модель и документы ориентированные данные то есть принципе такая противоположные для вещи и естественно решение для обоих уже давно существует хорошо проработанный но он начинается проблема если у вас необходимость возникает обрабатывать одновременно эти два типа данных в одной системе в принципе логично что у вас есть для того чтобы это все пользователь не делать у вас есть два решения либо разносить эти два вида данных в отдельные хранилища и соответственно там у нас просто возник инфраструктура какие-то все такие вещи либо хранить их в одном хранилище если она предоставляет такие возможности и естественно у них у каждого из этих вариантов и свои плюсы и минусы понятное дело что если мы берем отдельным хранилищем и совершенно ничего нового не придумываем у нас наилучшие производились для конкретного типа данных все хорошо но вопрос в том что у нас возникает проблем и инфраструктуры нам необходимо поставить крупную такой достаточно серьезно инфраструктуру для того чтобы взаимодействие эти хранилища разные и и более того ну там в конце концов вам скорее всего все равно понадобится какая-то аналитика у вас возникнет дублирование этих данных все такое прочее в общем нетривиально на самом деле ну и свои плюсы и минусы есть у единого хранилища самый главный плюс это естественно она не требует какой-то интерграции инфраструктуры особенно это важно для тех случаев когда у вас данные разных форматов несовместимые он не сравнимы по объемам то есть в этом случае вы просто совершенно никогда не отобьете затраты потраченную инфраструктуру для вот этого маленького кусочка нестандартных данных которые у вас есть но опять же вопросы связаны с тем что мы серьезно получается очень зависим от конкретной база данных которые мы используем и ограничены в тех вещах которые она предоставляет ну и собственно вот этот вариантный как раз сейчас больше всего и обсудим в принципе мы будем осуждать на примере на примере мы искали подброса санта поскольку по сетке больше отношениях под русскими возможно будет небольшой такой сдвиг в эту сторону но я стараюсь сделать его более равномерным и так вот сейчас небольшое время занимательных историй какие примеры какие данные я имею тут реальные как рассказал работая в компании минджи у нас есть такая интересная вещь все наши данные они строго разделены чисто логически строгой разделены на две части в первой части она очень хорошо ложится именно на объектно-ориентированный модель документа ориентированная модель это данные связанные с обучением то есть у нас профессора пишет какие-то данные курсы там уроки все такое прочее и поскольку это контент сейчас носим постоянно меняется он еще не структурированный там они постоянно придумывают что-то новое новый тип вопросов так далее и более того это вся вот эта вещь она очень хорошо а так вот связано блокирована в рамках курса в рамках какого-то урока поэтому это все очень хорошо ложится в эту тему но естественно у нас есть и нормальные данные там пользователи какие-то биллинговой информации и соответственно для них было бы неплохо иметь хорошие реляционные данные там транзакции как минимум все прочие вот здесь уже совершенно у нас большие проблемы с мангой и скорее всего мы будем их потом разделять ближайшем будущем просто на два сервиса потому что других опций нет ну и другой пример с противоположной стороны очень часто на конференциях спрашивают приводят такие примеры и в моем опыте тоже был такой один проект когда у нас данные в проекте абсолютно реализованы все хорошо но в какой-то момент возникает необходимость иметь например в модели пользователя какие-то хитрые вещи которые там эта информация может какая-то в нашем случае это был набор настроек для виджетов которые использовались в пользователей нашей системе и соответственно они постоянно меняются создаются что такое но не хочется естественно ничего для такого маленького случай информации дело дополнительно и вот например нашем проекте мы использовали тот момент штор и ждали миграции на 3 сундэ когда она вышла в под 1 94 ну вот примерно такие реальные примеры использования такие примеры реальные примеры данных которые нас возникают и в принципе эта тенденция предоставление нойз killfish в данном случае скорее мы все-таки говорим документа ориентированных фич в реляционных базах она на самом деле последнее время больше и больше заметно и наиболее у двери частных базой в этом плане это пост бросай москве эль как минимум в них есть бинарное представление документов но и от для перечислены остальные в тоже от есть более каком-то или менее добавим формате но они-то медленнее чуть меньше возможности вы они текстовые но тем не менее тенденция прослеживается ну и основное мой посыл в данной презентации с будет учиться в том что на самом деле когда ты это может быть было немножко страшно сейчас тоже очень просто взять и начать работать такими видами данных в обычные реляционной базе данных на самом деле сильно ничего проблемного там нет вы можете завтра прийти на работу с конвертирую часть данных в адрес он и радуется жизни ну и вообще какие шаги чтобы начать это делать понятное дело что у вас есть только два источника данных либо вы хотите конвертировать в документы какие-то данные внутри вашей реляционные базы предположим так получилось вы хотите поиграться либо внешние какие-то источники но если мы хотим работать внутри конвертировать данные внутри нашей базы у нас есть просто там набор функций для того чтобы их вручную построить но это естественно не очень удобно гораздо удобнее делать вот так это джейсен где кредит в воздухе и вот к сожалению только недавно появилась моя скилле со смертью тоже также функция называет же субъект агрегате который при есть который чего-то в том что вы просто указываете выборку которую необходимо какой-то набор данных и за вас она автоматически делает документы у которых каждый стал каждом толпу соответствует один ключ в документе это крайне удобно и абсолютно декларативно просто замечательно работает естественно если у вас есть внешние источники данных это тоже достаточно легко мы просто копируем внутри базы но а тут есть некоторые тонкости источники тоже будет разные например если вы просто делаете man годам из манги то это одно это в принципе свежие и актуальные данные все хорошо вопросы загружаете учитывая специфику monkey там разные специфические виды более прочее бывает других ситуаций когда вы здесь просто какие-то исторические данные которые пока путают или иной причине были сохранены формате джейсон и тут уже возникает вопрос а провал они симметричны идут пусть и для манги или по адресу а мы запускаем одновременно мангу и под найду и тундру же сторону то они не совсем одновременно на в один момент времени тома немножко разнесены чтобы они не мешали друг другу на генераторе но при этом чтобы не было такого что например один момент времени там не знаю а в один день сеть была хорошая другой внезапно стало хуже то есть такого нету конечно спасибо очень подозрительно тяжелым спасибо за доклад очень интересно подскажите пожалуйста а вот вы был слайд в котором показывалось сколько занимает место это имелось ввиду место только после того как мы залили данные туда доделать без индексов просто сами данные просто на таблицу скажите пожалуйста вынес равную что происходит после того как мы данные по колбасили там 50 процентов наделим vision нет этого не сравнивал потому что основной план был в том что посмотреть вот просто чистой статические данные здесь образ до в итоге вывод какой то есть для каких практических задач стоит использовать мангу ну смотрите вот основное то что я говорил на текущий момент у нас есть некоторые вопросы в реляционных базах связаны с тем что у нас здесь есть огромный огромный документ и мы обновляем только одно поле обновлением реляционных получается менее производительность например если вот у вас такая ситуация огромных огромные документы в из них часто обновляйте что-то одно тогда лучше дома нгу а на самом деле в большое количество других случаев плюс-минус в принципе они либо эквивалентны либо например вот на чтение выпуск достаточно хорошо на самом деле шло давай наконец автор первых атаки witch mark of я в первый раз сделать показал что адрес оказывается не сильно хуже иногда бывает лучше манги последнего просто хочу дать так адрес надо использовать тогда когда вы хотите чтобы у вас данные были целые это в первую очередь думать я вам сейчас скажу что я не то что я не люблю манга там мы мы конечно смотрели в нее в ковыряясь в исходниках и конечно же после того как мы сделали доклад дублине по моему в 13-м году что ли и показали что мы быстрее чем он gianni конечно же быстро купили команду в орто герда и сделали движок действительно на хорошем уровне то есть вот этого are the gear идеи заложены в него это на самом деле ngc этом конкурентность все взяли у тебя в подписи и даже я хочу как я недавно сам гонял мяч марки размеры индексов если раньше размер индекса были гораздо большему после сотри теперь размер linux сравнялись после сам и размер таблицы сохранялся с половицам то есть действительно врт gear действительно хороший движок другое дело что вот имплементация для меня немного не понятно почему она такая не очень хорошая у них это был вопрос надо имплементацию но в первую очередь конечно это все все сначала безопасности данных гибкость из использования джейсон дэй в подписи вполне нормальная то есть там достаточно много функций вот эти дмитрий не сказал он является автором некоторых функций для работы с джейсон бей и вот в версии 10 уже будет скорее всего примут патч его патч это нормальный synthetic для подойти но все дальше пудрой сейчас там не очень удобно и сян сян взгляды это джейсона то теперь можно будет писать апдейт как как положено апдейт чего-то такое равно тому-то исключен очень неровно забота то есть этого это очень большой шаг но ценность вот работали дмитрия того что одна из первых работ которая поставила целью создать benchmark на котором можно будет систематически проверять производительность разных бас вы все знаете что benchmark это такая очень сложная штука очень много условий там метеорит пролетел да уже там что-то поменялось в атмосфере вы уже можете получить у дэвида там плохо подумали настроение плохое все меняется поэтому то что дмитрий сейчас сделала это одна из как бы первая итерация мы планируем в марте будет конце марта будет конференция в нью-йорке планируем там уже показать более плотные такие данные действительно надо будет повторять много раз и показывать наверное уже пороге ошибок но пределы ошибки они на самом деле там будут достаточно крупным потом собственные колебания ней в конце особенно очень портит картину всегда когда вы делаете исследуем всегда уже понимать откуда эти колебания взялись из нужно уметь объяснять это да сейчас конечно этого не сделано потому что времени хватило просто как вы вот такой что действительно реляционные базы данных они вполне себе достойно это сравнению с носку или нами и я вот уже год как показывал силой что на самом деле никакого пренебрежение у нас нет мускульной базу просто все вся эволюция на ускоренный бас идет к тому что она усложняется ведь помните там в восемь лет назад были первые вот базы данных даже не 8 15 лет назад berkeley db первое это может это был окей well you базы данных обычные потом появились отдых базы базу данных когда нужно было уже как-то упорядочивать то есть она стала сложнее вот потом появились уже вот как вот кассандре там family товсь объединять колоночки друг другом это уже вообще почти таблицы вот потом появились palace текстовые базу данных там появились графом новые базы данных и они становятся все сложнее и сложнее почему потому что жизнь жизнь становится сложнее люди понимают что просто кей вел никому не нужно нужно всякий какие так ему фича но все усложняется усложняется и вот мы вот web адресе пошли другим путем и от нашей реляционной модели немного повернулись в сторону новый сквер и сделали вот это джейсон б просто не для того чтобы кого-то там ущемить дамон гудатама просто потому что многим пользователям нужна гибкость на ус quelle и надежность реляционных баз данных и после сета предоставил если конечно вам нужно у вас хипстерский проект вы можете потерять там процент данных и вам нужно это все до 100 машинах то долго здесь нормально работает никаких проблем вот но для серьезных проектов да конечно манга еще просто не доросла то есть сильно серьезная база данных она должна ну 10 лет наверно 10 лет для неё такой хороший юниорский возраст когда она когда уже вычищены такие баги страшные силы до когда уже не будет там всяких териане данных и так далее это да так что вот так я считаю это вот такой практический совет поаплодируем олегу но я не знаю может быть это вот еще вопрос есть после такого развернутого ответа видимо нет а нет есть скажите а вы пробовали из каких-то нормализованных таблиц но которых достаточно много строить материала сьюз в которых уже джейсон и по нему искать вообще нет на самом деле интересно идею ну и мы не пробовали ну например вот обычный пример это характеристики продуктов как минимум три таблицы обычных там с десяток будет по которым ну достаточно тяжело искать что-то и фильтровать ну вот все наверно яндекс маркет заходили видели вот фильтр по товарам его на реляционной модели не очень удобно делать но если баба материала сью которая все вот это джейсон превращала получался бы практически плоский какие-то такие иски на самом деле в данном айзе мы пока еще в котле какали курском мы начали и такой случай мы пока еще не пробовали но этих из кейсов огромное количество этом участке мы по ним приходиться возможно в будущем уже мы что такое посмотрим в общем следите за обновлениями в 2003 году потому что вот как раз наше самое такое популярное расширение и что вы написали 2003 году как раз специально для этого у нас было там 50 разных таблиц и по ним надо было искать и надо было очень тяжело было сказать по 50 облиться поэтому мы взяли все эти 50 таблицы или в одну таблицу и получили таблицы скую s500 полями большинство значений которых было просто новый мы на это посмотрел смотрели написали вот типа и часов в котором и краса лежал лежали вот эти ключ-значение плюс значение для разных там это было и мы получили все все очень хорошо работает в космосе да конечно у места с места меньше еще я хочу забыл сказать о том что что ожидается в пудре все с джейсоном то есть мы не то что мы сделали джейсон и забыли про него вот дмитрий сделал хорошее почти с abs крик шины с abs тришин синтаксис это просто удобно писать об детей удобно для джейсона а мы еще сделали во первых у нас есть тип взять сон это можно прямо на гитхабе скачать и использовать эта компрессия джейсона как мы все знаем джейсон у джейсона ключи могут быть произвольной длины и они могут занимать много места это его на 4 давая при трампе поэтому самые которые в голову приходит способ уменьшить размер это просто сделать словари отдельный ключей да и используют внутри какие-нибудь такие коротенькие не индикаторы то есть вот такая штука она вот и уже сейчас работает в законе можно скачать и как-то пользовать но это такая как бы наша тренировочная вещь а мы разрабатываем уже полноценный dictionary компресс которая позволяет его там несколько раз ужать это джейсон хорошо это мы надеемся протащить в этот самый в адрес дальше там идея джисона очень много и даже не волнуйтесь мы не забыли про него мы его каждый раз будем его допиливать лучше без патч и пока еще не обходилась 943 сон и если очень много были бы только силы на вот еще вопрос спасибо за так вот интересно хотя бы не сравнивали с побочными что называется движками там скажем так удобен для mais quel и вот на одной из конференций погодя и представлены было альваресом да вот он хотел чтобы протокол вон к тебе поверх да он хотел чтобы мы тоже поверили и сейчас мы как раз вот думаем что надо добрать те тамарин дебитом как же тебе это как раз вот в планах у нас потому что в том числе по его benchmark который представлял это выглядело очень красиво и лучше я пока еще я только тоже смотрел на этот сад и птичьего полета конкретно внутри за бенчмарками я не залезал но это у нас планах спасибо ну видимо видимо все на этот момент лиги давайте поблагодарим нашего уважаемого докладчика"
}