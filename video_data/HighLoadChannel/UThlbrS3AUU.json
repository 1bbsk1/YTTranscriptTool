{
  "video_id": "UThlbrS3AUU",
  "channel": "HighLoadChannel",
  "title": "Машинное обучение (lightGBM) и теория вероятностей для предсказания продаж / Александр Алексейцев",
  "views": 2184,
  "duration": 3478,
  "published": "2020-04-14T11:17:06-07:00",
  "text": "всем привет да я действительно в прошлом году рассказывал о том как мы покатили в про такую нулевую версию скажем так системы для автоматизации пополнения складов за год мы повзрослели и много чему научились много чего сделали нового этот доклад это продолжение хайло до прошлого года и usda это конов этого года давайте очень короткий интерактив для того чтобы познакомиться самом начале скажите кто нибудь в прошлом году на холоде присутствовал на моем докладе есть такие люди не так много не так много это с одной стороны хорошо с другой стороны нет скорее хорошо а по поводу usda это которые было в этом году пару месяцев назад кто-нибудь присутствовал отлично тогда для вас будет много нового и это это хорошо значит мы начали в прошлом в прошлом году строить такую систему мы хотели прогнозировать продажи как можно точнее для того чтобы как можно точнее класть нужные товары на склад а не нужна и не класть потому что склады не резиновые и нужно как-то свои амбиции соизмерять с мощностями нашими складскими в этот раз я коротко пробегусь аврал по всей системе для тех кто с ней не знаком я так понимаю что таких большинство и дальше подробно расскажу о том чему мы научились в этом году мы сильно продвинулись в том чтобы поработать с парком чтобы он начал делать наш нам нужно мы придумали новой клёвые фичи и глубоко погрузились в бизнес ориентацию этого проекта мы много мучил многому научились и в общении с бизнеса в том числе общая постановка задачи которые я с команда решаю мы хотим разработать инту эн систему пополнения складов то есть что такое intent это значит что в ней в целом не должно быть в каком-то светлом будущем не должно быть людей в ней должны быть столько алгоритма машинного обучения и скрип текке которые результат этого машину обучение записывать нужные таблички для этого мы пишем надежный код на спарки с питоном для этого мы делаем крутой товарный прогноз продаж для этого мы все это оборачиваем в некий scheduler запуска всех наших алгоритмов чтобы в нужный момент времени у нужного менеджера на столе появилась нужная цифра и просто обрабатывала интерпретировать результаты потому что бизнес очень хочет чтобы они были интерпретированы эти результаты и не очень хочет верить просто в цифру 5 без того чтобы был написан опять и почему там 5 доклад сегодняшний будет условно состоять из трех частей первая часть будет про прогноз и про то как как мы его разрабатываем про то как мы в этом вопросе продвинулись вторая часть будет чуточку про бизнес применения этого прогноза в реалиях реалиях пополнения складов и последняя часть будет о том как мы работаем с парком о том чего мы научились и к чему это привело в сравнении с цифрами которые были на прошлом докладе мной показаны давайте начнем с первой части первая часть про прогноз продаж про то как мы разрабатываем и сам просто первый вопрос который нужно на которые нужно ответить зачем он вообще нужен интернет магазина этот прогноз он нужен для понятных вещей для планирования мощностей в но что склад не резиновый меня все не влезет что даже будь ты владельцем огромных территорий все но все твои амбиции выйти склада не влезут нам нужно своевременно пополнять запасы нам нужно не допускать завалов на складах потому что такое тоже иногда бывает например после нового года мы хотим использовать наши модели для того чтобы оценивать эластичности спроса по абсолютно любому признаку который мы хотим который бизнесу сейчас нужен это может быть погода за окном и это самом деле наши люди я думаю все люди покупают незамерзайку с первыми холодами они заранее и это нормально и вот это как пример того как где эта задача где-то сдача может применяться в реальной жизни вообще знать будущее это хорошая идея которая даёт преимущество тем кто его знает сравнение с теми кто и этого будущего не знает и так как мы двигались к тому решению которые у нас есть сейчас для прогнозирования продаж мы перепробовали огромное количество всяких алгоритмов и методов и не влезло бы это сюда не на один экран каким был большим бы ни был то что мы попробовали как все нормальные люди мы начали с каких-то простых вещей скользящих средних линейных регрессии в таком духе как все нормальные люди мы перепробовали огромное количество всего на свете потом опять же как все нормальные люди попробовали busting и как все нормально люди на нем же остановились у нас сейчас вроде работает light бэ бэ бэ бэ бэ бэ нам понравился больше чем например популярных живут вас первую очередь из-за того что он работает значительно быстрее в первую очередь из-за этого но и конечно и и результатом дает лучший и работать при этом значительно быстрее то есть если что такое значительно но это в 2 раза например вот на наших данных мы получили такой преимуществах gm и что ты за метрика моя понятно что она особо ни о чем не говорит это скорее для демонстрации того как мы поэтапно двигались от простого к сложному мы не использовали ни какие алгоритмы которые предсказывают временные ряды на основании только этих временных рядов такие как например там prophet и арима просто потому что мы заранее знаем что хороший прогноз на основании только самого графика продаж сделать невозможно пушин зависит от огромного количества огромного количества внешних факторов и тут человек который мой доклад в прошлом году слышал справедливо заметить что в прошлом году моей был ниже и это правда может показаться что мы сделали за целый год только хуже но это не так и почему это не так потому что рынок e-commerce растет примерно сто на сто процентов в год озон растет еще сильнее чем на сто процентов в год и естественным образом амплитуды тех значений которые мы предсказуем увеличивается а значит за ними вслед и увеличивается наша абсолютной ошибка это нормально и здесь важно то что любой в любом проекте где бы где бы ты чего не делал где-то собираешь исторические данные они будут устаревать они будут устаревать и нужно готовиться к тому что придется придумывать какие-то решения для того чтобы каким то образом дисконтировать вклад более старых данных в обучении модели которые будут работать прямо сейчас озон очень быстро развивается изменяется эти механики взаимодействие с пользователями и соответственно то как люди покупали год назад это несоизмеримо по своей с тем как они покупают в этом году подробнее о том как мы в целом от начала до конца обучаем модель мы строим обучающую выборку выглядит сделаем это следующим образом мы для каждого товара на его в его истории находим 30 случайных моментов времени вся история которая левее от этого случайно выбранного момент времени это пространство в котором мы можем найти с которым можем выделить фичи следующие 7 дней это тот таргет который мы хотим предсказать в случае если мы делаем прогноз на неделю я не сказал все эти цифры которых я говорю я говорю для примера когда мы делаем прогноз на неделю но естественно мы делаем не только на неделю это просто для для конкретики у нас примерно 210 fitch сейчас почему игру примерно потому что примерно в 1 2 месяца у нас выходит новая версия в которой это количество фичей там может быть то больше то меньше сейчас их примерно 210 выборка состоит из полутора миллионов почему полтора миллиона потому что полтора миллиона действующих товаров есть на озон тех которых изо дня в день мы закупаем и продаем пользователям и для каждого мы пытаемся найти 30 сэмплов естественно не для всех это возможно сделать какие-то товары совсем супер новинки и естественно это выборка то что здесь написано полтора миллиона умножить на 30 это в случае если у всех товаров есть достаточно истории в реальной жизни эта цифра не намного меньше чем полтора миллиона нужно 30 какие фичи фичи естественно хорошим предиктором будущих продаж являются прошлые продаже естественно хорошим предиктором является цена которая была до если вы вдруг знаем какая цена будет в будущем то и цена которой будет будущем качество описания влияет на то как человек будет с каким рвением он захочет купить товар у которого есть одна строчка в описании у которого из целое подробная со всеми всеми деталями этого товара есть например это описание изменится а это часто происходит постоянно контент отдела которые занимаются контентом улучшают и улучшает описание товаров если это описание улучшается естественно спрос на товар увеличится доступность что здесь имеется ввиду имеется ввиду как в недавнем прошлом товар был доступен для пользу может быть недоступен по разным причинам например потому что он закончился это самая распространенная причина почему не доступен для пользователя и естественно если вы в прошлом не купили ни разу это не значащим плохое то зачать что невозможно просто не было ему модели таким образом объясняем почему почему его не купили или почему вы купили меньше чем обычно по сравнению с прошлым годом то что мы добавили принципиально новому мы добавили в модель такое рафинированное знание о наличии сезонности в продажах товаров кажется что это не бог весть какая новость что товары продаются какие-то больше зимой какие больше какие-то больше летом мы сделали некий да это driving подход к тому чтобы привить какие же конкретно летом какие конкретно зимой и сделай построен этом отдельный такой машины вернет pipeline и вот это уже знание о том что товар зимми товар лет не отдаем в модель предсказание спроса и просто варны фичи тоже об этом чуть расскажу это фичи который позволяет объяснить как продажи как цена одного товара влияет на продажи цену на продаже другого какого-то похожего на него или заменители этого товара сейчас подробно расскажу о том как мы провели research и какой запилили алгоритму для определения сезонности товаров кажется что это не так сложно но на самом деле проблема в том что для того чтобы быть хоть насколько-то уверенным что это как это повторяющийся паттерн тебе нужно два года истории продаж этого товара а двух лет история продаж товаров далеко не у всех есть боль того каждый день на озоне появляются тысячи новых товаров и на данный момент pipeline того чтобы разместить их на зимние летние и осенние он абсолютно ручной менеджер берет тысячу товаров просматривать их глазами и определяет какому сезона он относится для того чтобы как то потом руководить закупкой этого товара какой мы придумали pipeline для того чтобы эту проблему решить pipeline следующий мы взяли товары у которых есть два года истории такие тоже есть их небольшое количество их 1050 максимум 100 мы взяли все эти товары построили графики продаж этих товаров и он супер войска вас три завали эти графики не вкладывая в этой абсолютно никакого так скажем экспертного знания о том что какие вообще сезоны бывают летние зимние какие угодно мы кластере завали у нас получилось 9 по моему 9 или 10 абсолютно интерпретируемых очень классных кластеров я щас я вам покажу на которых отчетливо видно к какому сезону относится товар но что дальше это ведь всего 50 или 100 тысяч а у нас товаров полтора миллиона что делать с остальными дальше мы на этой размеченные выборки полученной этапе кластеризации обучаем классификатор на фичах которые не обязаны знать о истории товара ведь правда что для того чтобы сказать что санки джимми the worm он не нужно знать какой у него был график продаж мы все и так понимаем что санки зимний товар и мы вдохновившись этим пониманием что не нужно на самом деле история для того чтобы говорить что товар зимний обучили классификатор на выборке размеченной кластеризацией и теперь мы применяем этот классификатор к товарам у которых нет может быть может не быть никакой истории и таким образом размечаем все товары независим от новой истории у них есть или нет в двух словах подробнее о том как мы провели кластеризацию мы предобработки наши временные ряды мы заполнили пропуски естественно они там были пропуски опять же товар не было какое-то время нужно чем-то заменять чем-то заменять историю мы абсолютно простое решение в этом месте используем мы затыкаем последние назначением на период пока когда товар был доступен средние средние продажи за последний месяц пока он был доступен мэра протягиваем на период когда он был недоступен мы блага риф мир им эти временные ряды почему потому что логарифм позволяет избавиться от резких выбросов которые могут мешать для дальнейших просто лизации из коллируем extends андерс келлером что можно было сравнивать товары которую сильно продаются товарами которые слабо продаются это не мешает быть очень классным самкам у нас которые продаются там по 100 штук где не каким-то не очень хорошим самкам который продаются по три штуки в день и но это это это и другой это самки этой другой это земли товар мы попробовали кластере заводь временные ряды в том виде в котором они есть в пространстве временных рядов у нас то получалось не очень хорошо мы испытали мы применяли всякие разные метрики близости мы ну естественно начали с евклидовой метрики просто прикладывать 11 коллировать наряд к другому это сработало не очень хорошо мы пробовали всякие разные другие не такие близости например мы использовали дтп и это тоже не очень нам помогло а что получилось хорошо это просто выделить по моему 20 или что то типа того ну там не больше чем 50 свечей из каждого временного ряда что это за фичи это угловые коэффициенты прошу прощения за прошлый слайд это угловые коэффициенты этого временного ряда за все 2 года это коэффициент автокорреляции одного года к другому году это коэффициенты выявляет преобразований этого временного ряда на самом деле мы вдохновлялись такая библиотека с fresh всем доступна она позволяет выделить там по моему несколько сот печей мы все их не брали мы выбрали те которые нам понравились мы добавим чуть от себя по моему вот с фреша не реализован выявлять преобразование мы добавили хоть себя мы добавили топ-3 абсолютно значение коэффициентов разложения в ряд фурье чтобы привить какие есть самые топовые частоты в.в. движение этого графика и получили вот такие симпатичные результаты вот например один из таких кластеров это новогодние товары вот эта зеленая линия это новый год вот график заканчивается тоже новым годом мы видим что все товары которые попали в эту в этот кластер все они довольно спокойно ведут себя в течение года и к новому году имеют резкий рост продаж вот например это школьные товары вот эта вертикальная линия это 1 сентября это всякие школьные тетрадки и ручки учебники рюкзаки и все в таком духе и потихоньку этот спрос на эти товары потихоньку спадает с течением с течением времени люди кто-то раньше кто то позже закупился для детей к первому сентября и потихоньку спрос на эти товары пропадают и уменьшается и уменьшается что же дальше дальше мы взяли размечена таким образом выборку и обучили на ней классификатор мы выделили достаточно простые фичи из товаров это те pdf на описаниях карточек товаров у них если вы зайдёте на сайт ozon увидите что большинство товаров имеет достаточно подробное описание мы взяли тот кусок истории продаж которую товара есть но мы абсолютно не требуем чтобы он был хоть каким-то то есть если этих товар продается всего несколько недель все фичи которые отвечают за его историю более поздний все заполняется минус единицами и мы не требуем чтобы товар был хотя бы одно значение в печах который отвечает за историю продаж это mb денги товаров команда соседняя тоже в зоне сделал очень прикольный research вот есть название статьи не цель на хабре статью о том как они сделали они обучили по сути некий аналог во рту века для сессии пользователей на сайте ozon то есть пользователь заходит что-то посмотрел что до было в корзину что-то купил один товар оттуда удаляется и пытаемся предсказать его по всей оставшейся сессий таким образом были получены векторные представления товаров они тоже используют в качестве печей ну и категорийные деле вы это скорее о том как человек отправил какому типу товара этот конкретный товар то есть с этого razon каким-то образом разбиты на такие категории и подкатегории под подкатегории так далее мы используем знание о том как человек разметил товар на категорию подкатегории так далее обучаем на этой выборке полученной от кластеризации мы обучаем классификатор мы никуда дальше не пошли дальше ранам forest и и за скалярно просто потому что нет в этом никакой необходимости все получилось достаточно прилично мы пробовали что-то более серьезное опять же тот же самый life gbm но в этом месте мы не получили какой-то принципиального просто качества и остановились на более простой реализации и теперь мы применяем применяем классификатор к новым товаром старым товаром каким угодно и мы имеем разметку все-все всех товаров озон на зимние летние школьные в подарки к 8 марта и в таком духе что это дало формальная процент ошибки уменьшится он здесь процентных пунктов это очень прилично а на деле мы полностью избавили менеджеров от этого ручного труда которые они делали до этого они размещали это руками мы автоматизировали процесс закупок товаров заранее почему это важно потому что поставщиков и заканчивается товар в преддверии сезона все набегают перед новым годом уже в ноябре начинает покупать елкин член покупать санки заказывать у поставщиков чтобы во время положить их на склад и у поставщика если прийти к нему в декабре за санками они у него уже закончится поэтому таким образом автоматизируем закупки заранее и решаем проблему того что товары который очень хорошо продавались до нового года но абсолютно никак не продаются после нового года например это те же елки искусственные который название продаются любая модель имеет некую инертность и она будет предсказать все равно достаточно достаточно ощутимый прогноз после такого большого роста продаж с помощью этой фиче мы избавились от этой проблемой теперь мы дали точно знает что если этого елку то после нового года с приходом прям вот 31 декабря спрос на них абсолютно обнуляется не больше никому не нужны в течение всего следующего года давайте вот я сейчас таким образом рассказал о новый фича которую мы добавили она дала 10 процентных пунктов теперь давайте к тому как все эти фичи которые были на предыдущем слайде плюс эта фича как мы их отдаем ее дбм и как мы заставляем его хорошо учиться оптимизируем мы метрику моя как я уже говорил нам она нравится исходя из этого распределения которые есть на нашей выборке мы используем 6 файловую консолидацию то есть мы разбиваем весь последний год на 6 участков по два месяца обучаем модель на первом годе предсказываем на первые два месяца следующего года потом предсказываем потом обучаем на 14 месяцев и проверяем на следующих двух усредняем мои полученные на всех этих консультационных выборках и выбираем ту модель которая запер форма лучше в среднем на всех этих фондах тут в этом месте будет логично задать вопрос а почему именно средний почему не последняя почему-то мне какое-то еще чем какая другая комбинация и вот это действительно то место в котором мы сейчас работаем мы проводим research на тему того что нам на самом деле нужно требовать от модели чтобы она была в среднем хороша на все в течение всего года или чтобы она была хороша на последнем фалды потому что как я говорил мы обновляем модели 1 2 месяца примерно и может быть то что модель хорошо работает в январе абсолютно неважно а в среднем который мы вычисляем она участвует и если ты модель прекрасно работать в январе она понизит средние мая на всех волнах мы ее выберем а может выясниться что на самом деле она была нужна не она поэтому да сейчас мы над этим думаем сейчас мы этим работаем используем и гипер об очень хорошо нам мы с мы с ним подружились более того последняя версия умеет то чтобы распределена работать на кластере и на нотах обучать отдельная модель параллели ца и мы еще пока не воткнули и в прод мы не знаем как это будет но мы уже знаем то что она это умеет и уже читали статьи о том как люди это используют боль того лет бмв последний последней версии microsoft сказал что лет gbm теперь тоже сможет обучаться обучаться отдавать ему спарта фрейм он будет распределена народов обучаться чего раньше не было поэтому мы в большом в предвкушении находимся этой истории подбираем гипер параметры мы с вот тут нарисован график того как работает гипер опт он пытается заполнить все пространство гипер параметров но когда находит какой-та удачную комбинацию начинает обстреливать ее более подробно мы выбираем наилучшую комбинацию кипра параметров и начинаем анализировать эту модель вручную что что я имею в виду например мы строим вот такие графики зависимости таргета от prediction а вот если посмотреть на левый график то мы видим что все prediction и приличное то по вертикальной оси находятся все prediction и меньше чем 2000 и казалось бы моей модели которая справа отличается на какую-то капельку который может быть можно и не заметить но на деле мы получаем что что первая модель в целом не способна предсказать цифру больше чем 2000 а это что такое это значит что самые продающийся товары будем очень сильно ошибаться до общий вклад этих самых продающихся товаров очень небольшой в моей когда у тебя там огромная выборка это правда очень небольшой но какое значение для бизнеса эти товары имеют самое высокое это та который категорийный менеджер и вешают в рамочку эти товары и за них только и душа у них и болит поэтому мы анализируем каждую модель вручную мы струя не только такие графики мы считаем огромное количество метрик мы считаем мои по разным диапазоном значение таргета как эта модель работает с товарами который плохо продаются как с товарами которые хорошо продаются а как она работает летом и как она работает зимой мы строим огромное количество вот этих дополнительных метрик и только когда модель удовлетворяет нашим такому после такой ручной обработки только тогда мы катим и евфрат и вот здесь мы достаточно сильно назовем это повзрослели с прошлого года и это взросление заключается в том что мы детальным образом изучили как работает наша модель на самых разных комбинациях печей на самых разных в разные периоды времени с разными типами товаров почему это важно это важно потому что какие-то механики появляются новые какие-то появляются название новинки например еще год назад она не продавал товары аптека сейчас он уже продает активированный уголь или какие-то достаточно простые но в тоже время это медикаменты как на них устроена как как на них реагируют клиенты абсолютно по-новому не так как они реагировали на товары которые мы продаем до этого появляется например ювелирные изделия человек который выбирает ювелирные изделия в интернет магазине ozon это определенная группа людей это люди которые готовы потратить большую сумму отдать у интернет-магазина удивлена изделий как правило стоит дорого это не те люди которые покупают на зоне к примеру подгузники товары повседневного спроса и они уже привыкли к тому что они хорошо продаются и покупают их заказывают делают это смело появляются новые механики взаимодействия с пользователем появляется твой реклама как performed товары когда их показывают по телику и говорят покупайте у нас там какой-то конкретный конкретный шампунь и что здесь очень важно что нужно когда ты катишь такую большую штуку в рот нужно внимательно оценить и знать качество работы системы на в самых маленьких разрезах потому что может быть именно этот маленький разрез кому-то какому-то конкретному менеджеру очень сильно болит он очень хочет чтобы конкретно в этом разрезе все было у него окей это может абсолютно никакого влияния не иметь на общую метрику которую вы оптимизируете но может выясниться что именно за это вам прилетит потому что потому что это очень важно как оказалось столь каких-то конкретных товаров которые показывали по телевизору конечно очень важно чтобы они заранее были привязаны на склад потому что зачем мы когда показываем мы тратим деньги на то чтобы купить время эфирное и даже в каких-то местах мы обучили простенькие модельки которые работают с конкретными группами товаров то есть мы выделили вот примеру товары это является таким примерно будь мы взяли совсем простенькое решение в от пули вы туда и она работает лучше чем вот эта большая модель который очень хорошо работает на большой выборке товаров но конкретно с этими товарами она работает не очень поэтому в этом месте мы затыкаем такими достаточно простыми но супер таргетированным и алгоритмами ok прогноз продаж готов теперь нужно сколько-то на склад заказать и тут появляется огромное количество случайных процессов на пути товар на склад что это случайный процесс и повелось во-первых как-то случайно ошибается во вторых поставщики как каким-то случайным образом могут опоздать или при или приехать чуть заранее и более того поставщики могут привести не совсем то количество товаров которые мы у них заказали потому что везде есть люди везде есть какие-то случайные ошибки что-то в били никто не в то ячейку и в таком духе и хорошую новость в том что распределение этих случайных величин на ней их можно оценить их можно оценить использовать распределение этих случайных величин для того чтобы обезопасить себя от трех видов вот таких косяков от ошибки прогноза и какие каких-то неидеальности в работе поставщик что для этого мы сделали мы оценили распределение ошибки прогноза для таких товаров для всяких товаров из и прогноз говорит 10 что это означало на историю товар заказывали могли за 5 и 11 9 но с какой вероятностью 11 какой вероятностью 9 мы оценили опоздание поставщиков то есть распределение времени когда мы договорились с ним там на пятницу когда они на самом деле приехали вкус сколько сколько они от этой пятницы отклонились вправо или влево и тот процент который они нам недовольств или приводит больше такой тоже часто бывает и мы подумали что в этом месте пользователи а именно коммерческий отдел ему абсолютно неважно кто накосячил ему хочется с какой-то уверенностью говорить о том что я хочу чтобы товар был 95 процентов времени на складе мне отсюда не важно кто из вас косячит давайте сделаем так чтобы эти косяки никаким образом не влияли на мои 95 процентов за которые я уже пообещал там кому-то еще более высокому начальнику и мы разработали такой подход который позволяет от всех этих распределений от распределения ошибки прогноза от распределения опоздание от распределений не дало за взять ту площадь под под кривой тот процент площади под кривой уверенность такой процент и площади уверенность который хочет человек из коммерции с какой уверенность он хочет видеть этот товар то есть например на первом графике мы видим распределение распределение ошибок прогноза и если менеджер хочет чтобы этот товар у него был да ему на него не очень это и важно 30 процентов времени и мы будем даже заказывать меньше чем прогноз прогнозировал потому что мы знаем что с вероятностью 30 процентов если мы говорим 10 то привезут его меньше том если прогноз говорит что вы привезут 10 то его могут купить и 9 и 8 раз и как раз где мы наберем эти 30 процентов вот там мы остановимся вы столько прогнозы мы будем заказывать меньше если мы знаем что поставщик постоянно опаздывает коммерческий коммерческий сотрудник хочет чтобы этот товар был постоянно там 90 процентов окей мы за мыс заметаем 90 процентов площади распределения опозданий поставщиков и говорим смотри мы спрогнозировали 10 тебе на неделю потому что он возит нам условно раз в неделю но поскольку ты хочешь 95 процентов поэтому мы закажем не действие 20 потому что прогнулся живется с известным вероятностью мы закажем не на 7 дней она 10 дней потому что мы знаем что поставщик может опоздать и и на это регулярно делает и мы еще домножим эту цифру на тот процент который поставщик на мне привезет если он в этот раз на косячный мы знаем распыление этого косяка и мы сформулировали вот такую формулу сейчас я поясню что в ней что в ней где то есть мы прибавляем к тому периоду на который мы делаем прогноз дельта t мы прибавляем его опоздание мы делаем мы прибавляем к нашему прогнозу дельта которую мы заложили в котором мы рассчитали вот в этом месте и делим это все на тот процент который поставщик нам не довезет в этот конкретный раз с некой степени уверенности и вот вот эта цифра уже говорит о том что вот с такой уверенностью вы получите этот товар на складе если все эти распределения останутся останутся правдой и что там происходит это происходит две вещи 1 мы экстренно полечили проблему 2 мы подсветили эту проблему мы увидели что конкретный поставщик имеет супер широкое распределение косяков а значит ему надо быстро звонить с него взыскать и начать с ним какую-то работу и когда он пообещает что все я больше не буду косячить окей мы его распределение забываем говоришь перевозит нам все честно во время как он как мы с ними договоримся и заказу мы получаем меньше потому что мы уже можем не закладывать на его опоздание это история сейчас обкатывается мы рассчитали для некой группы поставщиков отдали этой коммерческому отделу они с большим с большим энтузиазмом восприняли нашу идею и сейчас мы потихоньку потихоньку эта идея обкатываем и нее есть проблемы понятно что такие хорошие распределения ты не построишь для некоторых поставщиков потому что история нашего с ними взаимодействие может быть не такая большая чтобы строить какие-то распродали да здесь нужно придумывать какие-то какие-то затычки какие-то заменять это распределение каким-то среднем наступление по всем поставщикам если ты не знаешь историю конкретного но для какие-то самых топовых это это уже работает окей это такая была позже отдельно стоящая история как мы применяем наш прогноз для непосредственно целей бизнеса и теперь немножко отойдем в сторону отдельная я анонсировал в превью к докладу то что мы поговорим о как мы используем прогноз для оптимизации цен это отдельно такой отдельно такой research отдельно стоящей в чем как бы фокус фокус в том что если у тебя есть прогноз продаж который зависит от некоторых факторов ты дальше эти факторы может факты крутить изменять при замороженных всех остальных и смотреть как от этого будет меняться прогноз и таким образом ты можешь оценить какая эластичность спроса по некому какому-то фактору например этот фактор может быть ценой и понятно что всем интересны именно это как будет меняться в данную конкретную секунду спрос на данный конкретный товар если мы цену увеличена 10 рублей следующая мысль которая приходит затем когда у тебя есть такой инструмент это а давайте теперь маржу сохранил ту же который у нас было и при этом максимизируем оборота на какие-то товары и цены повысим на какие-то понизим и оборот этого хотим и чтобы он увеличился но при этом бизнес требует чтобы маржа была ровно такая какая она была до этого чтобы ничего не испортить мы сформулировали такую оптимизационных задач у мы пытаемся максимизировать произведение цены товара на prediction его продаж при этой цене то есть это и есть тот оборот который мы будем получать от продажи товаров при новых ценах при этом мы имеем ограничение первое ограничение это просто ограничение на адекватность и цена не может быть ниже нуля и не может быть больше там чем миллион долларов второе ограничение это как раз про маржу это то что маржа не будет меньше чем альфа за данное нам спущенное нам сверху не меньше чем альфа должна быть маржан и мы решаем такую оптимизационная задача как выглядит функция которую мы оптимизируем выглядит она примерно так это такие кривые которые мы получили сделав приди продаж товара при разных значениях цены понятно что это кривая не нисколько не бьется с некими представлениями экономистов теоретиков которые говорят о том что это должна быть экспонента именно поэтому мы говорим о том что здесь должен быть какой-то доверительный интервал где мы можем модели доверять где мы не можем потому что например таких низких цен для этого товара на никогда не видела таких высоких ценах никогда до этого товар не видела мы выделяем неким достаточно простыми эвристическим и способами определяем этот доверительный интервал в котором мы можем модель доверять ну то есть чтобы этот график продолжал соответствовать представлениям неких экономистов теоретиков и что происходит в результате в результате модель говорит что для товара который нарисован слева целом нужно повысить потому что при повышении цены продажи на него упадут не так сильно а это что означает что в этом месте мы можем заработать для компании маржу для товара справа цену можно понизить потому что небольшое снижение цены ведет к резкому скачку продаж а значит здесь мы заработаем оборот и вот на такой достаточно разнообразной выборки по женив одни товары с другими мы получаем что одни генерят оборот другие генерят маржу все звучит очень классно и на тесте который мы взяли для такой небольшой выборки нам дали поиграться мы получили плюс 3 ст полный процента к обороту при сохранении тоже сам маржи но есть вопрос на который мы не знаем ответ и этот вопрос а где мы их взяли эти пистоны проценты не отъели ли мы их у соседних товаров которые просто наш эксперимент не ваш ли мы реально от отъели кусок рынка таким образом или мы отвели у самих же себя из других каких-то категорий товаров по чуть-чуть так чтобы на этой маленькой выборки ну да получили palustris полный проценту насколько мы потеряли на остальное выборки товаров кто-то пришел увидел этот товар который подорожал не стал покупать его и вместе с ним не купил что-то еще и сколько мы от этого потеряли и это тема которую который мы занимаемся прямо сейчас мы добавили в модели кросс товарные фичи что это такое это значит что feci которые говорят о том какой был перфоманс у товаров похожих на тебя что такое похожих на одном из предыдущих слайдах я сказал prime бединге это ближайшие 10 соседей в пространстве им бейнлингов которые для нас подготовили ребята из соседней команды мы берём 10 лежащий соседей и описываем их историю продаж тоже в печах для того чтобы предсказать продажи этого конкретного товара я на конференции южный так он говорил о том что мы над этим работаем и это правда мы работаем прошел месяц мы по-прежнему работаем у нас уже есть хорошие фичи мы их воткнули в модель они имеют высокий фич impotence это все пока находится в ноутбуках и мы не можем об этом говорить как о чем то что реально получается хотя это реально получается наберите в этом нельзя ну потому что и пруфов никаких нет окей это была вторая часть моего доклада 3 будет техническая часть нужно заранее подготовиться потому что что то что то может быть что-то может быть сложно и часть это касается того как мы научились работать с аспаркам для того чтобы он решал наша задача так как нам нужно чтобы он их решал а какие в основном задачи мы с помощью спарка выполняем мы берем какие-то таблички джон нем одном другую фильтруем каким-то правилам и таким образом рассчитываем фичи по плану что выглядит таким образом у нас есть всегда маленькая табличка в которой мы отдаем задание для нашего генератора фичей а с генри нами фичи для того чтобы сделать prediction и для вот такого айтемы на период с дает старт падает and мы отдаем ему задания а дальше у нас есть огромные таблицы с историей которые могут в тысячу раз или в десять тысяч сто тысяч раз быть больше чем это первая табличка и что происходит дальше мы хотим друг другом joy нить но прежде чем и друг другом джо нить мы должны в память положить и что происходит если не особо вдаваться в детали настроек spark контекста что произойдет он маленькую табличку запишет на один executor потому что оно маленькое ненужное и разбрасывать по всем остальным а большой табличку распределить по экзекутором потому что она очень большая и стандартные настройки spark контекста таковы что он горит давать динамически будем аллоцировать твою таблицу по разным родам и что произойдет если мы начнем их joy нить произойдет следующий эта большая табличка вся потечет через экзекутор на котором лежит маленькая табличка и так будет происходить со всеми большими табличками и это приводит во-первых потому что все работает медленно ты на самом деле не используешь свою вычислить не мощности и второе ты рискуешь провалиться по памяти потому что ты свою все свои огромные таблички вынужден класть на денег , с какого там которому ты выделил какое-то ограниченное количество оперативника и абсолютно не предполагал что через него потекут сотовые данные и какое мы нашли в этом месте решения мы начали равномерно раскидывать таблицы по экзекутором делаем мы это с помощью настроек спарка сразу скажу что это может у кого то не сработать я много консультировал много консультировались нашими даты инженерами которые верили что аккуратнее говорить о том что это сейчас всем полечится их проблемы потому что здесь есть много о том какой у вас кластер какие у вас данный какие у вас на самом деле размеры таблиц что нам очень хорошо помогло нам помогло отключить динамическую локацию это первая настройка нам помогло сказать что минимальное количество экзекуторов равно максимального количества экзекуторов и не нужно нам для каких-то задач и уделять больше для каких-то меньше дай нам только те которые мы у тебя попросили мы сказали что это четвертый настройка авто брака joint школ что нет никакого порога выше которого таблицу уже не нужно разбрасывать по маркерам разбрасываю любого размера таблицу по маркерам последняя настройка это некий назовем и секретный настроек души и нет в документации спарка есть тикет который о том что добавить эту настройку в документацию это тикки тысячи шестнадцатого года ну сама у sparkasse он висит и а не вынешь нечестен можно найти он легко гуглиться они собираются добавлять его в документацию не знаю каким причинам но нам очень хорошо взлетела эта история мы что это за что эта настройка отвечает отвечать за то что если в ты сначала разбросался свою таблицу по варке рам потом ты по фильтровал и каким-то образом эти результаты фильтрации уже не равномерно разбросаны по маркерам и эта настройка говорит о том что окей мы сейчас будем джонни титу таблицы на что-то а давайте будем точнее неправильно сказал мне джо нить а будем делать какие-то радиус операции над этой таблице иногда читать какие-то средние по каким-то самцом и давайте делать их только на тех пор тирах на которых уже большинства table залижет и мы запрещаем делать это таким образом и составляемого разбрасывать ее по-прежнему равномерно по всем и компьютером и да мы проигрываем в том что нужно потратить сетевые ресурсы на то чтобы перекинуть данные с одного с какого-то с одной сущности на другую да это правда ну очень сильно в нашем случае выигрываем от того что работать будут все они только те на которых остались результаты фильтрации какой-то предварительной фильтрация этих данных с помощью вот этих настроек нам удалось ощутимым образом увеличить с одной стороны время выпал уменьшить время выполнения вы страны увеличить надежность выполнения то есть теперь настраивая объем памяти на каждом экзекьютора ты это делаешь исходя не из того что тебе нужно все данные засунуть в один а теперь ты считаешь общий объем своих данных и делишь его равномерно таким образом ты защищаешь себя на то что в каком-то конкретном компьютере сейчас произойдет переполнение и все и все рухнет мы на этом не остановились в изучении того какие как можно про контекст настраивать мы за был очень важную вещь сказать что нужно руками для sparco принудительно ему говорит сделала не порти шин моей таблички по какому-то конкретному столбцу это очень важная штука о чем она говорит потому что если вы постоянно joy нити одну таблицу на другой по какому-то одному и тому же пользу разбросайте их равномерно так что вы именно по этой колоночки по которой вы сейчас собираетесь joy не тяни раз бросались равномерно и дальше из следующей таблицы разбросается по тем же самым значением этой колоночки и таким образом достигается наивысшая степень параллелизма ваших join of потому что нужные куски данных уже лежат на нужном экзекутор них не нужно никуда переносить еще немного про настройки мы прочитали и подтвердили на своем примере что память между настройки какое суммарное количество памяти ты выдаешь компьютеру или на драйвере какое суммарное количество памяти тем отдаешь и какой память какое количество памяти ему даешь на то чтобы еще не по мать не падать в море оверхед но уже писать какой-нибудь notification об этом это соотношение девять к одному ему немного где-то об этом читали говоришь это хороший тон она действительно очень хорошо работает мы увеличились стабильность за счет того что поигрались с настройками ну условно поддержание жизнедеятельности кластера то есть мы его просим каждые 10 секунд хоббит интервал говорить о том что каждый worker жив я не помню какая там стандартный настройка у нас хорошо получилось это настройки мы увеличили количество последовательных попыток выполнить одну и ту же jopu увеличили до 10 и еще важная штука про то что сервер с мы поставили 64 это о чем говорит это очень сильно зависит от того какие конкретные железяки у вас находятся в вашем кластере какие там жесткие диски ее нужно настраивать индивидуально под каждый это ведь о том сколько потоков ты будешь читать со своих жестких дисков и здесь очень важно не перегреть потому что можно очень быстро их испортить но это довольно будет довольно сильно увеличивает скорость обработки ну это же важная история о том что не нужно давать экзекутором памяти больше точнее не то что не нужно как только ты даешь память им экзо культурам больше чем 32 гигабайта тут же java начинает хранить служебную информацию которая хранится на экзекьютора начинает хранить intel 64 битном виде и как и если поставить тридцать один гигабайт и 9999 а потом поставить 32000 один ты вроде бы увеличил количество памяти но на самом деле ты его уменьшил потому что служат информация начинать занять больше и больше места поэтому в этом в этом момент увеличиваешь память и переходе через два гигабайта нужно понимать что ты на самом деле только что у и уменьшил тебе нужно значительно увеличивать через три задать гигабайта чтобы получить какой то какой то эффект от этого почему это все важно на прошлом колоде я рассказывал о том какие у нас большие объемы данных и как долго это все считается так вот на тех же самых объемах данных теперь это считается два часа вместо 5 и теперь мы используем меньшей ядер и количество оперативы который мы знаем а меч у нас в 10 раз в десять раз мы блокируем меньше оперативу у нашего вычислительного кластера по сравнению с прошлым годом только за счет того что мы внимательно силе разобрались настройках и под нашу конкретную задачу сделали конкретные настройки они одни общие настройки для всех любых задач это очень важно для тех у кого ресурс ограничен и они у всех ограничен и ok с этим я тоже заканчиваю последняя о чем я скажу это о том как мы это все зашагали как это все запускается изо дня в день в нужное время чтобы нужный момент времени закончить мы используем р flow мы создаем вот такие элегантные симпатичные последовательности выполнения наших задач выстраиваем зависимость от от выполнения какой задачи зависит следующая задача хочу отдельно обратить тут внимание на вот этот темное синенький кружок это тёмносиним кружок эта зависимость этого дага от придут от совсем другого дага то есть можно привязать один одну вычисленную цепочку к результатам работы совсем другой вышлите цепочки не гнись не не складывать их все в один большой в одну большую кучу а разбить на много маленьких и сделать зависимости одного другого делается это с помощью с помощью вот такого такого класса который из flow можно за им портить на этом практически все планы у нас дорабатывать в тех местах которых я сказал на ними работаем мы хотим естественно добавлять фичи добить и то есть рост товарную историю и хотим перейти от бустинга каким-то алгоритм которые работают с временными рядами как с временными рядами вот чтобы эту природу наших данных не терять в тот момент когда мы делимся чип мы верим в чистку к продаж был за последние 7 дней а как они внутри этих семи дней менялись мы теряем таким образом мы хотим сохранить эту природу наших данных и поэтому активно сейчас читаем статьи на тему того как люди используют властям в комбинации с какими-то другими алгоритмами пока просто читаем это наши планы у меня все спасибо за внимание спасибо огромное она соответственно спасибо тебе за доклад и мы хотим тебе сказать спасибо вот такими вот подарками супер пасибо большое спасибо и у нас сейчас будет еще одна задача который нужно быть решить сейчас будет сессию вопросов-ответов наверняка очень много вопросов и тебе нужно будет выбрать тот вопрос который тебе больше всего понравится спасибо большое за доклад супер интересно у меня будет два вопроса один коротенький другой может чуть по длиннее коротенький бро метрику мапей а вы сказали что вы ее используете насколько я помню у него знаменатель стоит фактические значения какой стратегии придерживайтесь когда фактические значения там продажи были нулевые то есть исключали из выборки или там на соты одна тысячная лукой просто какой путь выбрали и второй вопрос будет когда вы делали систему вот именно прогнозы товара на складе вы рассказали про несколько технических метрик а на каком языке общались бизнесом переводили ли вы это в бизнес метрики деньги в заказы во что-то еще как вообще договаривались обосновывали улучшений ok по поводу первого вопроса оптимизируем мы на самом деле не мое указываем в качестве улус функции для всех наших методов машин обучением указываем моя и он как раз этой проблемы лишь он мопед скорее показывал для того чтобы на понятном языке объяснить потому что моя на в центр же абсолютной ошибки она ни о чем может не говорить никому из вас что такое 2 или 3 а уже такой про 30 процентов это всем понятно поэтому mapper было скорее для визуализации этого результата а не для того чтобы использовать его где то для обучения вот а что касается разговоров с бизнесом да у нас действительно было очень много общение на тему как показать им что что то что это нужно что это приносит деньги был достаточно простой было достаточно простая операция бизнес нам сказал что есть некий очень простой подход как прогнозирует продажи брать средние продажи за последние 30 дней доступности то но наличии товар на складе вот есть такой очень простой подход и если почитать какие-нибудь источники о том как в целом большинство людей работают вот они примерно так и работают они примерно так и предсказывать свои продажи ли используя скользящие средние и нам четко сказали что нам нужно обыграть эту историю оба гарантию и показать что это дает я не привел в этом докладе график и но мы строили для ней графики например какой процент товаров концу недели кончится если заказать по нашему прогнозу и по вот такому простят кого про какой процент товаров кончится к этому концу недели и используя наш прогноз ты получаешь значительно меньший процент товаров которые кончился вот вот на таком языке это это же понятная история смотрели все закончится товар с нашим не закончится или наоборот а сколько у тебя останется после того как например прошел один цикл закупки сколько у тебя останется товаров которые ты же сам считаешь до 100 кгц стоки такие товары которые просто лежат большими кучами и очень-очень мал продать их например закупили слишком много и они теперь лежат как у сколько у тебя в кубометрах останется товаров который ты сам считаешь ждут стоковым если будешь закупаться по нашему прогнозу если будет закупаться повод такой простой формуле то есть да мы оценивали бизнес метрики и сравнивали их с неким очень простым подходом но этот очень простой подход был очень всем знакомы понятен ну что вот же конечно правильно последние 30 дней взяли средние посчитали так и нужно делать и вот этот очень понятный и простой подход мы горим вот это понятно это понятно смотрите мы можем лучше и на вашем языке этот товар кончится этот не кончится и и завалов будет меньше если мы будем пользоваться нашим прогнозам вот как то так спасибо за доклад и вот в дополнение к предыдущему вопросу вопрос следующие а был ли у вас и бить тестирования оба тестирования вот как раз вот этих моментов то есть когда вы бизнесу говорить что будет так на самом деле все может быть совершенно по другому если вашим прогнозам пользоваться то есть вот если там поделить грубо говоря ассортиментом выделить какую-то часть вот старую мы пользуемся старым прогнозам до новый год применяем новые технологии сравниваем было ли что-нибудь потом такого не было был только оффлайн тесты то есть мы показывали на прошлом вот это простая формула вот наша формула но показывали только на прошлом и этого оказалось достаточно того чтобы нам поверили это привлекательная идея сделать такой bts разбить товары на две группы одним отдать просто прогноз другим наш эта привлекательная идея но на самом деле есть так много всяких которых я тоже говорил о всяких случайностей которые происходят что на каком-то промежутке времени даже две недели мы можем увидеть любую ситуацию как в лучшую так и в худшую сторону просто потому что какие-то поставщики чет не привезли чего-то там они опоздали и достаточно большой промежуток времени пришлось бы этот тест чтобы он действительно прорисовались какие-нибудь зеленые и красные сигналы поэтому нет мы этого не делали ну и не только потому что конечно сейчас сейчас и объясняет что это было бы долго но там даже вопрос такого не буду то есть нет не делают спасибо за доклад у меня вопрос такого характера вы вначале упомянули что код должен быть надежной ну это понятно и логично ну а вот как быть с тем что dat ass in this to any в принципе очень любят работать с юпитер ноутбуком на юпитер ноутбук это такая среда где нельзя сделать нормально дебаггинга где код получается то есть это не код который пойдет в продакшн вот такой исследовательский а тем более у вас насколько я понимаю код падет в spark нормой есть своей особе конечно то как вы заполняете вот этот пробел между исследовательской работой дата-сайентистов то есть может быть какая-то там еда и у вас используется или еще как то есть как код даты seen this то уходит в парк вопрос эта проблема решается на этапе найма людей в do it is on this ты она решается тем что мы сразу говорим что вы не только должны быть это сантис там еще вы должны писать продакшен код хотя бы знать как это делать вот может быть вы никогда этого не делали но хотя бы вы должны понимать как это как это как чем он отличается вот том примере который ты горишь над ноутбук и как это потом переходит продакшна это первая мысль боль того многие ты it is on this ты вообще отказались от ноутбуков вот в нашем отделе многие отказались целом от ноутбуков и пользуется пай chapman да там есть проблемы с тем что график нарисовать конечно сложнее потому что там отдельном окошке появляется им так удобно но есть и такие люди которые даже вообще ушли от ноутбуков то есть мы стараемся набирать людей которые готовы к тому что нужно писать продакшен код и возможно даже стоит это делать с самого начала вот и даже не не пользуется ноутбуками вот как то так ну а те кто пользуется ноутбуками они понимают что у них будет отдельный task этот код теперь из ноутбука превратить в приличные сдох стрингами со всеми чем положено и вы будете свой же код из ноутбука переносить в продакшен не кто-то другой это будет это будет по этому делу его сразу хорошо вот и все как бы сопи мыслью сразу приходит к нам работать и поэтому не приходится потом решать какие-то конфликты как то так здравствуйте очень интересный доклад вот вы упоминали что для разных объемов продаж разные веса то есть для дорогих товаров для дорогих для товаров с большим объемом продаж м с и е будет похожим но для если ошибка допущена на товарах с большим объемом продаж это модель очевидно хуже как вы подбираете веса при оценке вот этой метрики не то вот первый вопрос а второй вопрос вы пробовали r-квадрат ну при оценке моделей и сколько он получился примерно так первый вопрос был о том как мы взвешиваем наши товары когда даем их модели ответ не как мы понимаем что те товары но когда ты обучаешь с метрикой мая тот товар который продается меньшими объемами на нем и абсолютно ошибка будет меньше она тех товаров которые продают но это как бы линейная линейной зависимости там есть эти товары которые продают сильнее на них и ошибка будет больше соответственно вклад она будет носить больше в общую сумму поэтому ответ напрямую не как мы не взвешиваем товары которые слабо продаются товары к той сильном продаются может быть это стоит делать я не могу сказать что это плохо и деле хорошие мы этого не делали потому что метрика качество всей этой истории с машины о лингам она моей а вот метрика качество всей этой движухе в продакшене она уже деньги и про деньги там была целая отдельная история как теперь сделать что товар все время был на складе используя какой-то прогноз чем будет лучше твой прогноз тем будет уже распределение в ошибке тем меньше тебе нужно закладывать стратегических запасов на то чтобы эту ошибку компенсировать и быть от неё застрахованным поэтому и с очень простой без нее чем точнее будет наш прогноз тем меньше нужно иметь страховых запасов и в этом месте поэтому когда мы обучаем модель машинного обучения мы никаким образом мы не говорим про тушь это товаром более важное затмение важной так что ответ на пера просто не как мы этого не делаем второй вопрос r-квадрат из надо назвать назвать цифру я не помню боль того на должен понимать что когда мы говорим про какую-то модель которая предсказывает на 7 дней у нее будет какой-то один r-квадрат модель кота выпуска значит у нас они его нужно будет больше потому что и объема больше зачитаны змеи сложнее при прогнозировать начатым за не поэтому в какую-то одну цифру сказать не могу я не помню ни души только это военный тайным просто я не хочу какой-то глупости сказать это был последний вопрос а соответственно нужно выбрать кто из них был мне очень понравится вопрос про продакшен код давайте мы этого просто наградим кто его задавал подарки от merlin единиц спасибо тебе огромная сила вам просто пасе большой после большое"
}