{
  "video_id": "tAut3abz5QM",
  "channel": "HighLoadChannel",
  "title": "Hadoop в Облаке: история миграции сотен петабайт / Михаил Марюфич (VK, Одноклассники)",
  "views": 432,
  "duration": 2697,
  "published": "2024-10-29T02:37:38-07:00",
  "text": "И следующий доклад у нас будет от Михаила о том как Михаил из Одноклассников как переезжали ходу пом в облако Миш прошу Всем привет Рад всех видеть меня зву зовут Миша как сказали Я из Одноклассников в Одноклассниках я руковожу платформой данных платформа данных - это такая штука которая отвечает за инфраструктуру больших данных за некоторые подсистемы расчёта которыми пользуются конечные пользователи Дато инженеры иль инженеры аналитики там разные за некоторые конкретные подсистемы типа дата трансфера из каки в хоп из хадуп в хау из разных других систем в другие системы в общем за всё это большая зона ответственности у нас к сожалению к счастью Вот и схематически это выглядит так есть огромный продакшн Одноклассников и видео ВКонтакте который пишет логи достаточно интенсивно в кафку оттуда мы это перекладываем в хадуп собственно люди пользуются потом хопом наши бизнес пользователи дата аналитики инженеры дата и ML и делают из этого крутые штуки ML модели отчёты витрин немаловажно что в Одноклассниках мы пользуемся все дружно собственным контейнерным оркестратор One Cloud Вот про это есть крутая статья и доклад на лоде на который я даю ссылку вот немножко внизу можно посмотреть а ближайший его аналог из Open Source мира - это как бы кубернетес вот почему мы используем его можно как раз учить в докладе но могу сказать что это решение сейчас вышло на уровень холдинга не только одноклассников сейчас да заезжает допустим дн ВКонтакте и другие бизнес-юрист мы конкретно платформы разворачиваем все наши приложения Каха многие другие системы и вот в частности теперь в этом в клауде и пойдёт речь сегодня про миграцию дупа туда то есть сегодня мы будем говорить Следовательно конкретно О хопе как вы видите на слайдах это довольно большая инсталляция ключевые цифры у нас 250 Сейчас размер кластера в дих и 200б ну на Яр которые растянуты по семи дата центрам запускается довольно много задач вот ну в общем довольно крупная система Вот и сегодня мы не будем говорить о том как дуп использоваться в Одноклассниках и других ю потому что Про это есть много других докладов некоторые ключевые я выделил можете потом посмотреть сегодня мы будем говорить конкретно про технику Как зачем почему мы решили сделать то что мы сделали для того чтобы ну понять для начала окунёк выглядел хадуп до этой миграции зачем мы на это решились немножко напомню Что такое дуп для тех кто может быть не в курсе или подзабыл вот Нас интересуют сегодня две его ключевые подсистемы Яр это подсистема расчётов она интенсивно использует пу и рам на машине на которой Она развёрнуто состоит из ресурсного менеджера который выделяет ресурсы и ноды менеджеров на которых запускаются всякие Спарки мопред усы и другие звери которые утилизируют ресурсы вот и hdfs это более сложная система в миграции Да это подсистема расчётов состоит из нейд Где хранится информация о блоках с ней взаимодействуют клиенты и дата ноды Где хранится собственно вся битка вот в железном виде Это обычно выглядит Так есть две или три группы серверов мастер Хосты Где развёрнуты нано ресурс менеджеры исты где развернут менеджер и Дада так сделано чтобы они вместе утилизировали всю тачку Ну хотя бы пытались потому что дано только диски в основном использу как раз их практически не использует сказать про хадуп мы стараемся обеспечивать для него работу без тайма и у нас это в принципе получается касательно вывода намного из строя у нас классическая схема которая сейчас везде используется начиная с дуп двоечки через кворум журналы когда есть у нас один активный мастер который пишет информацию в журналы с кворум то есть и есть стендбай в любой момент стендбай могут стать активными потому что они зачитывают логи изменений из журналов и синхронизируют свои изменения в памяти то есть более интересны момент тут мы немножко может быть отличаемся от кого-то наш хадуп он растянут по нескольким дата-центра так сделано Потому что есть жёсткая требования быть Абсолютно устойчивыми к выпадению одного дата центра в том числе навсегда есть некоторые традиции и обоснования Почему так сделано но мы этому правилу следуем это решение дискуссионное потому что оно генерирует некоторый трафик рос ДЦ но альтернативное решение которое сопоставимо по надёжности оно как бы требует чтобы мы целиком отре все данные в другой центр что ну для нас немножко дороговато это такой некий трешхолд сейчас нам выгодно делать так и так сложилось да то есть за счёт чего гарантируется отказоустойчивость что у каждого блока реплики находятся в трёх разных дата-центра соответственно один из них можно выкидывать условно навсегда будем немножко страдать Но выживем вот какие есть проблемы я бы не сказал что это супер проблема Это скорее наша история эволюционная про улучшение то есть но То есть можно выделить эксплуатационные проблемы Замена добавления особенно мастеров это такой полуй процесс выход из строя дисков тоже иногда требует какого-то вмешательства обновление конфигурации на кластере происходит Ну типа с учётом автоматизации конечно по кнопке но не гладкие детали есть и развёртывание новых кластеров довольно тяжело То есть первый момент второй момент такой тоже минорный мутабельность состояние компонентов то есть что я имею в виду Несмотря на то что практики работы с железом у нас развиты то есть мы стараемся не допускать на практике возникают ситуация когда по какой-то причине наряде not оказались не консистентной с остальным кластером конфиги или там установлена Ну допустим какая-то другая версия Java По непонятным причинам это очень редкая ситуация которая не входит в норму но она может возникнуть и система сама себя восстановить в данной ситуации может не суметь то есть и критической недостаток Ну точнее улучшение которое мы хотели внести это разделение код у нас из-за того что этого нет есть ситуация неэффективно утилизации ресурсов Почему Обратите внимание на график то есть утилизация цпу ночью как бы всё более-менее нормально Мы целиком запрашиваем все ядра всё хорошо потому что большая часть расчётов запускается ночью и у нас есть SL чтобы мы дочитали к утру то есть Следовательно нам ночью как бы нужно как можно больше ресурсов а потом днём там в основном считаются всякие хоки то есть эксперименты разработка оно не требует столько ресурсов то есть мы бы эти ресурсы могли бы освободить и кому-то отдать Ну или соответственно можно воспринять эту ситуацию как хочу ночью у кого-то забрать ресурсы которые мне не принадлежат а потом отдать чтобы считаться быстрее вот эти улучшения хотелось бы внести в систему то есть независимое горизонтальное масштабирование повысить удобство эксплуатации и мутабельность состояние То есть как к этой проблеме подходят люди вообще первый путь - это пойти в менедж инфраструктуры Очень популярный путь на западе то есть мы соответственно by Design получаем разделённый коп Stage и избавляемся эксплуатационных проблем просто потому что кто-то там на стороне вендора берёт эти проблемы на себя то есть для нас этот путь не подходит потому что во-первых если бы даже мы могли там это хранить это было бы крайне дорого для нас ну и в России это ну как бы у многих компаниях по этим соображениям принципе не принято Ну сами все всё понимают второй путь для нас означает смену стека он популярен в других компаниях то есть мы в качестве Режа можем взять что-то S3 comp например CF apone есть такой набира популярность инструмент можно написать своё решение которое у нас кстати написано про это есть доклад ссылку на которую я забыл здесь вставить но потом вставлю но у нас есть уже hdfs который Нас устраивает целиком он мы умеем его готовить всё хорошо проблем с самим hdf нет в качестве компьют популярно использовать допустим Spark Over cuber Over cuber и какие-то другие штучки но во-первых у нас не только Spark есть некоторые можно назвать leg можно назвать Наследие русские и в виде сам мадса которого почти не осталось но тем не менее и нет Ку Бернеса вот поэтому мы рассматриваем Ну и смена стека ради получения этих преимуществ это как бы слишком дорого эти преимущество не столь значимо чтобы мы всё взяли и переписывали то есть поэтому есть третий путь сделать всё на внутренней инфраструктуре Для нас это значит взять и развернуть One Cloud с разделённым компью редм отдельно hdfs отдельно yarn То есть как примеры того что так большие компании реально делают можно привести uber который совершил Аналогично нашему проект по миграции ходу по собственное облако контейнера и вот Яндекс известный факт что V заус разворачивается во внутреннем контейнерном облаке в контейнерах А так этот путь для нас предпочтителен поскольку он эволюционный и как бы согласуется со стратегией развития в принципе всей нашей компании то есть Давайте посмотрим что Он решает эту проблему и как это выглядит то есть ходу по клауде как это будет выглядеть схематически То есть если начинать рисовать То есть у нас есть One Cloud такой большой контейнерный оркестратор который менет вообще распределение всех ресурсов компании есть набор облачных хостов очень большой то есть там условно весь продакшн хости и на и этот контейнерный регистратор будет решать где разместиться тот или иной инстанс нашего приложения например на Первом Хосте у нас может разместиться и какие-то другие наме кака на втором Хосте у нас Дада поместилась на третьем стено менеджера то есть обычно Ну облако распределяет всё это делать так чтобы целиком утилизировать как память так и диск то есть облако оно получается берёт за нас эту проблему менеджмента ресурсов Кто где хочет Кто где будет размещаться и соответственно можно слить компоненты вверх и вниз если нам это нужно нам это нужно вот как это выглядит с точки зрения использования для того чтобы развернуть кластер пишем небольшой манифест где ключевые понятия - это там докер образ количество ресурсов которые Нам требуются для работы приложения количество диска который требуется для работы приложения и вот такие простые штучки вот для работы дупа то есть нужно решить несколько проблем в Облаке первая проблема - это конфигурация то есть во внешнем мире это часто решается через там через лаудера менеджер как он называется немножко забыл вот у нас это решается всегда решалась в том числе на желез на железе через собственную систему называется Portal Management System Эта система отлично проинтегрировать со всем продакшене её функциональная возможность то что я там могу писать конфигурации к отдельному приложению и потом подписываться на изменение этих конфигураций могу доставлять их как файлики в том числе в контейнере как мы делаем в хопе то есть Итак для менеджмента конфигурации мы используем эту систему А и любим её вторая проблема Челлендж такой - это kbos как Многие знают а кто-то может быть нет - это сетевой протокол анфи Он широко используется в ходу по сути это единственный способ настроить секюрити в дупе он там используется для того чтобы адентии клиентов кластера и для того чтобы адентии узлы кластера между собой да то есть если кто медл кто-то мог видеть такие вот учётки Даба ваша доменная область Вот это суть учётка рбе которая нужна для того чтобы узлы связывались между собой вот на железе мы это дело медли на самом деле немножко получ впоследствии появились некоторые автоматизации Вот Но в Облаке это дело точно Нужно было крепко автоматизировать универсально чтобы не заниматься выписывание ки табов вручную ни в каком виде вот мы написали компонент KB registration Manager так называемый он сканирует топологию кластера свеже созданного смотрит Для каких узлов ещё не созданы учётки создаёт их в кирсе мы используем фри ипу для реализации нами kerberos Вот и создаёт китабы и заливает их в Volt про Volt как он надёжно устойчиво работает можно вот доклади посмотреть будучи созданными китабы могут доставится в контейнеры собственно когда Китаб уже в контейнеры ээ приложение успешно стартует так же как оно это делало на железе Итого целиком pipeline создание вот ин допустим dat Note до менеджеров это мы сотим манифест в облако затем облако в зависимости от запрошенных ресурсов выбирает машины которые подходят для запуска и стартуют там контейнер в контейнер при старте доставляются конфигурации из Portal Management System сертификат роски Tab про путь создани о котором мы поговорили и затем соответственно стартует приложение hup соответствующий узел hup входит в кластер Итак вот таким вот способом мы можем себе натыкаться кластер в котором будет разделённый кою storage отдельно hdfs отдельно yn соответственно менеджеров мы можем делать больше если нам надо и меньше совершенно лёгкая Операция С дата нодами тоже можно но понятно это с компонент нельзя просто так сделать их сильно меньше иначе ну типа данные потеряются но нам это и не надо так но у нас кластер есть Мы научились создавать но пользоваться мы им не можем потому что все данные сейчас в большом объёме находятся на железных кластерах то есть для того чтобы эта система стала продакшены нам нужно их как-то перенести давайте рассмотрим Как можно это сделать первый путь который может прийти в голову простой но у нас уже есть свеже созданный кластер в Облаке давайте мы начнём потихоньку заливать туда данные переносить приложение в идеале мы можем сделать его такого же размера как предыдущий Но для нас это непозволительная роскошь Поэтому если бы мы так делали то мы бы переводили туда приложение постепенно расширяя Облачный кластер и сжимая Железный Вот Но это надёжный буть Но чем он по моему мнению плох тем что это долгая миграция ручная копирование этих данных Может затянуться на неопределённое время в зависимости от того насколько пользователи будут заинтересованы в этой миграции и они определённо будут страдать из-за того что какой-то период времени год-полтора будут вынуждены работать с несколькими кластерами в тех местах где они привыкли работать с одним и должны будут модифицировать соответственно свои приложения чтобы они там часть данных с одного места читали описали в другое В общем это какая-то бизнес логика которая требует проработки Я знаю что некоторые ком аналогичны мав в Росси поступили так но там я считаю что это было оправдано эту схему можно применить Когда у нас либо нет контроля над узлами То есть когда мы допустим в какой-то ду в Облаке уезжаем либо когда мы хотим там съехать с какого-то устаревшего или на более современную версию Нила ходу Ну может быть риск одновременной миграции будет ещё больше у на степенное добавление облачных узлов то есть В чём состоит этот алгоритм У нас есть старый кластер и есть облачные ресурсы определённая квота выделенная на проект которая постепенно будет расширяться мы стартуем в Облаке новую дата ноду которая изначально пустая но Уже вошла в кластер и кластер начинает писать туда данные то есть затем мы запускаем вывод одно из старых нот через проду Демис это процедура которая делает так чтобы бло умы мве отливали безопасным образом на все остальные узлы то есть мы запускаем миссию постепенно нода котору мы деком становится пустая Вот и соответственно её можно вывести из кластера вывели и таким вот нехитрым образом мы постепенно перемещаем все наши данные в облако пользователь всё это время ничего не замечает и потом последним быстрым гм шам пере тоже в облако это и вс Ду в Облаке Это здорово никто ничего не заметил Профит то есть Давайте повторим Я добавляю НОД потом запускаю комиссию по окончанию комиссии мы отключаем старые дады по возможности переставляем это железо в облако расширяя квоту соответствующим образом проекта И через некоторое Ну время у нас все данные оказываются в Облаке бего ру понять из картинки когда мы попробовали что-то здесь пошло не так вот можно догадаться что Ну конечно речь тут пойдёт про скорость смотрите запустили мы эту процедуру но скорость репликации блоков какая-то неприемлемо Малая 2.000 блоков в минуту то есть ну это в пределе там если размер блока 128 МБ 250 Гб в минуту и вот в одном из наших кластеров не самом большом С такой скоростью миграция кончится за полтора месяца приемлемо скажете вы Я тоже да но не ну всё-таки хотелось бы иметь ограничение не на уровне физического кластера там ну вы понимаете не сеть не утилизирована ничего То есть можно гораздо быстрее то есть мы начали это дело расследовать по профилировать наду вот зашли она там стоит такая пустая у неё там ядра не загружены Всё круто но в фоне крутится вот такой вот НН монитор метод comp это класс который отвечает собственно за назначение задания на реплика ра работает думает вот этот блок надо куда-то передвинуть к ней дано стучатся время от времени она им отправляет задание ты сюда отправляешь Ты туда вот такой класс очень медленно и постепенно отправлял эти задания на репликацию В чём там оказалось дело после продолжительного расследования Там какой алгоритм внутри Мы выбираем Случайный дады в счасть то мы как реки размечаем дата-центры То есть у нас к равно Датан То есть это популярный трюк когда люди реализуют Вот эту вот стратегию что каждый блок в свом дата-центре находится в принципе как бы нормальная тема можно и получше сделать но это работает это ок вот потом проверяем на соответствие политики размещения блоков то есть выбрали ли мы три дата ноды в трёх разных дата центрах если выбрали то собственно всё нормально Если нет то повторяем случай провала и вот на самом деле время рало на ВМ пункте на третьем Как можно было бы подумать А именно на Первом то есть 90% времени мы проводим на выборе случайных случайных там реков очень странно вроде бы как быстрая операция вот ну если углубляться там в реализацию я привёл здесь псевдокод потом приведу ссылку на кусочек кода где можно покопаться то там сделано так общем мы проходим по списку добавляем в их список потом среди этого списка выбираем рандомную Даду 90% времени собственно тратится на этом цикле Но люди просто не предполагали что кто-то добавит в этот список там не 10 элементов А там 100-150 не знаю 2 то есть немножко тратится время на это мы собственно этот кусочек переписали на более простую схему Тем более что у нас только один тип диска HD в нашей конкретной инсталляции если будет в дисках мы переди зайни этот кусочек Ну в общем просто выбираем рандомно Если подходит то подходит если не подходит то не подходит Всегда подходит соответственно вот здесь ссылка на класс в который вносились изменения его можно менять в ран тайме То есть это подразумевается конструкцией без пересборка дупа вот после того как мы внесли такое изменение скорость репликации выросла там во много раз Теперь мы можем реплицировать 2 ТБ в минуту в пределе Это совершенно не предел но этого нам уже оказалось достаточно например миграция этого кластера заняла бы 7 дней Что гораздо быстрее чем мы физически можем это делать учитывая что ресурсов не было всех моменте были некоторые промежуточные стадии типа переставить железки с одного места в другое но скорость устроила вот там есть тонкости в этой истории в дискуссионной зоне можем обсудить просто слишком сложно всё там сталих пряме рассказать вот сейчас Итак мы находимся здесь есть мы передвинули все данные и нам нужно очень быстро там последний чек сделать двинуть наду то есть кто работал с хопом может предположить что здесь тоже возникнут некоторые сложности вот обсудим миграцию мастеров для начала схем То есть как вообще осуществляется миграция мастеров вот у нас есть допустим кластер из двух Note одна из них активная вторая standby есть три журнала в которые они пишут с кворум Ну активная мы добавляем в облаки новую ноду вот и пару журналов Мы же их тоже перемещаем ы их было нечетное количество ВС время иначе Тим нельзя будет собирать вот проверяем что ВС работает хорошо делаем её активной после того как убедились что всё работает хорошо можно вывести одну из старых из строя вывели передвигаемся На этом этапе миграция целиком завершена то есть какие здесь есть вообще нюансы то есть во-первых ну дуп не позволяет динамически добавлять новые ноды и журналы там в самой последней версии Там че которая ещё не вышло несли некоторые патчи чтобы можно было добавлять динамически но в нашей 314 пока это недоступно вот uber в своей статье как разносили пат чтобы можно было динамически ре конфигурировать потому что них раз кластеров и Ну не хотелось проводить процедуру рестарта для добавления новых мастеров для каждого из этих кластеров поэтому они вложились для нас в принципе на нескольких кластерах вручную поработать ноды разово было приемлемо Вот Но это первый такой Челлендж просто неудобство при проведении этого манёвра не всё так прота шагах когда мы перемещали данные собственно для клиентов которые пользуются хопом ничего совершенно не менялось с нейм нодами же идёт активная работа со стороны многих десятков клиентов и если в какой-то момент связь между ними нарушится то Ну какой-то продакшн процесс Ну во многом это бач процесс то есть там это не так страшно Но тем не менее не хотелось бы будет нарушен То есть почему эта связь может быть нарушена то есть потому что в дупе так сложилось что Discovery кластера то есть извлечение топология кластера хранится прямо на клиенте то есть кто администрировать hup видел Файлик hdf Сай xml где перечислен список name noe э среди которых нужно поискать по одному из методов которые конфигурируется активную ноду то есть соответственно когда я добавляю новую облачную найду если я в этот момент не добавил их на все клиенты то там где Яни добавил и не собственно переконлива у меня это будет выглядеть как дата кластера то есть Итак для того чтобы всё прошло корректно нам конфигурацию топологии кластера необходимо доставить на каждого клиента и обновлять при её изменении то есть Благо у нас с этим было всё хорошо как раз-таки потому что процессы построены Так что все конфигурации должны применяться динамически в большинстве приложений и храниться Вот в этой единой системе Portal Management System для конкретных аду была предварительно при ранних манёврах по добавлению например новых в новые дата-центры работа по централизации всех конфигов Итого на момент конкретно этой миграции была возможность просто добавлять в одном месте новую ноду которую я добавляю в Облаке и она автоматически подтягивается во всех клиентах то есть Клиенты умеют перечитывать конфигурацию кластера и того всё хорошо если я добавляю в определённом месте строчку конечно всё пошло не совсем по плану Нашлись приложения которые почему-то либо не перечитываю конфигурацию в онлайне либо почему-то берут конфиги другого источника всё же но для большинства мест для Особенно для критичных мест всё прошло Хорошо если вовремя обновляться на современные наши там наработки то всё точно будет круто вот а вот в убере в статье там я привожу у них всё было нехорошо и как раз-таки на момент этого шага они обнаружили что у них конфигурация захард кожена просто в гите где-то и чтобы провести такую миграцию перед этим нужно весь продакшн простить и везде унифицировать конфиги То есть хорошо что у нас это уже было сделано по что иначе это просто такая тяжелая работа в общем если вы хотите делать такие манёвры в будущем делайте так как мы и у вас будет удобно это эксплуатировать Итак мы мигрировали дуб весь целиком Всё круто было пару локальных проблем В общем и целом никто ничего не заметил но перфоманс Упал Упал на 10-15 про мой вывод наш то есть что мы наверное потеряли в локально данных Дело в том что в железных дух есть оптимизация когда ноды менеджер умеет у дата ноды прямо через сот читать информацию локально вот этой оптимизации У нас сейчас нет соответственно потому что компью Stage разделён то есть больше вызовов по сети идёт в любом случае даже если в рамках одного Дато центра или стойки Вот Но для нас это приемлемо Ну помните преимуществ куча ещё Эта система намного дешевле я об этом не говорил но можно покупать только диски например а сервера шарить с приложением это экономит прямо много миллионов поэтому норм 10-15 про Ну переживём там нарасти подкупишь было нормально и вот для нас после этой миграции Нор стало дова ликом там может быть утра к 12 плохо но вот к 11 Нормально вот на новогодних каникулах ВС было хорошо вот сразу после началась резкая деградация То есть можно на скрине увидеть что сразу оно там к часу начало завершаться потом к 4 потом Ну короче вот в итоге к 6 к 7 к 8 вечера то есть мы прям в панике были мы уже ну активно расследовали что это может быть Вотс занимают всю доступную память день в день то есть ВС супер плохо Вот мы это расследовали и в какой-то момент поняли что дело здесь застревает всё на ИО то есть с некоторых дано наши менеджеры считывают там в 10 20 30 40 100 раз медленнее то есть в этот момент немножко осенило В чём может быть дело вот Ну вот собственно с некоторых считывается очень медленнее оза положить что вы как и я плохо знакомы с этой технологией или не слышали о ней вообще Это технология которая применяется в больших дата центрах ИО cost Она позволяет изолировать приложения между собой гарантировать им какие-то по диску гарантировать им какие-то гарантии чтения записи то есть позволяет разным приложениям типа Кафки и какой-то другой базе жить на одном диске нормально то есть ну Лучше чем без такой изоляции Вот как я узнал про E Кост то есть про шерсти логи журнала действий там Кто что делал на продакшн и оказалось что есть такая корреляция то есть проводился манёвр по внедрению собственно технологии чтобы гарантировать лучшие гарантии то есть и чем на большее количество Дато центров это раскатывать тем сильнее деградировали расчёты Вот такая вот закономерность Ну мы поговорили с ребятами решили временно это откатить для проверки может действительно связь какая-то есть и в тот момент когда откатились всё прямо залетала всё быстро Круто Ну конечно некоторые приложения ради которых это внедрялись стали работать хуже но дупу стало комфортно то есть Так мы так мы поняли что Дело было двоу Кост Главное чтобы ходу было комфортно но нет то есть мы как бы любим своих соседей поэтому следующий нас шаг - это мы добавили некоторые метрики снятия профайло с ходу по почтению записи и то есть это всё тюни профилировать И в итоге включили его коз чтобы гарантировать там нашим другим пользователям системы какие-то гарантии без эффекта на дупа и на остальной продакшн Вот такая вот мораль красненькая стало считаться к 6:00 утра к 7 Всё круто то есть мы мало того что мигрировали там удешевить миграция была бесшовной ей Можно гордиться все работы были проведены за год-полтора если считать доработки без отрыва - инженеров дата инженеров от своей работы то есть я считаю что это то к чему нужно стремиться при миграциях и учитывать это в планировании нашей дальнейшей архитектуры чтобы не портить этот Вот exp люди должны работать а не заниматься миграция для этого есть специальные люди уроки которые можно из всего этого извлечь во-первых Ну если мы работаем системой глубоко на лоде там на продакшене да то нужно не бояться читать и править Исходный код Ну Особенно учитывая особенность системы в нашем случае у нас вот мы немножко не по дизайну использовали реки и нарвались на проблемы и самостоятельно эту проблему для себя решили например обкладывают и вовремя реагируем на родительный сигналы это понятно Ну вот такой ключевой рок для меня это никогда не забивать То есть если мы не понимаем Почему возникает тот или иной эффект то это проблема И она обязательно выстрелить неудобный момент Это хорошо что она была после Нового года не вовремя иначе было бы совсем как бы неприятно Итак мы обсудили как мы это сделали Зачем возможно и Давайте обсудим к чему Мы пришли коротенько результаты по разделению разделили то есть впоследствии также объединили наши вычислительные лае научились брать у облако больше ресурсов поставили ещ ме в фоне и ускорили расчёты теперь к 5 утра считается 95% иногда и к чем всё завершается некоторые расчёты за счёт нвме в 10 раз ускорилось сэкономили на закупках миллионов рублей не буду говорить сколько Но много за счёт возможности покупать только Диски когда нам нужны только диски И шарить всё остальное с другими продакшн приложениями по эксплуатации целиком автоматизированные рутинные операции сходу расширение кластера замена поло дисков нот и сделали дуп Как сервис так на этом У меня сегодня всё по материалу рад видеть внимательные лица был готов ответить на все вопросы сейчас и в дискуссионной зоне соответственно Спасибо большое за доклад а перед тем как перейдём к вопросам и попрошу вас ещё отсканировать QR код и оставить голос да Для меня это очень важно Так что пожалуйста Да давай начнём и в конце вручим подарок от нашего партнёра лучше вопрос поэтому запоминай и вот здесь у колонны вижу руку Здравствуйте спасибо за доклад очень интересно Егор из Спортмастера тоже даты хопом занимаюсь хотел бы спросить то есть вы мигрировали в кубер Я так понял да в докер правильно в контейнере в клауде аналог кубернетес внутренний Угу и по функционалу типа тоже самое ну высокоуровневые если То есть это контейнеры под управлени Да оркестрация ну собственно это виртуально можно воспринимать как р То есть я декларируют то есть сколько меня должно быть инстан сов и так далее оно размещает их с учётом реальной нагрузки всего флота из там многих тысяч машин Понятно А ещё маленький вопросик по поводу нейм нода у вас на нейм ноде НОД менеджер не работает вообще ну или вы То есть у вас на ноде у вас и дата нода и не Да и так соответственно раньше не работало То есть сейчас то есть условно говоря может так получиться Ну в общем это вопрос изоляции которая даёт облако само стратегия такая что контейнеры не должны замечать эффект друг на друга на практике Да этот эффект может быть то есть Поэтому конкретно для ноды мы нивелиром что забронировали себе Целую ноду То есть все остальные Ну компоненты все тысячи узлов живут на общих основаниях и это работает сейчас нормально спасибо ну потому что когда конкретно нано мигрировало там очень жёсткий процесс рядом поселился и мы увидели что страдает мы как бы будем работать над этим но пока так так Следующий вопрос вот из центра зала Да спасибо большое за доклад Меня зовут Лев Я из райфа такой вопрос не раз слышал мнение что если перемещать ой перемещать ходу в контейнере то может страдать сетевое взаимодействие насколько это было про исследовано Было ли влияние была ли разница Ну я тут про сетевой слой облака детально не отвечу но на практи замене ответ на этот вопрос на практике Ну никакой разницы с в дупе мы не заметили ни в одном из компонентов только позитивные разница из-за того что поехали на лучшее железо более новое так вот вижу Дмитрий руку тянет Спасибо за доклад у меня такой вопрос есть я представитель бизнес Юнита вы получаете сделали и у меня получается два выбора выбрать Cloud либо S3 если я не испо не использую какие-то персональные данные Вот почему я должен выбрать Hop Cloud а не S3 мм я бы сказал что вы то есть не должны то есть есть несколько соображений Ну во-первых то есть в первую очередь я считаю Ну вот hdfs всё-таки вот такое классическое решение ориентировано на тех у кого уже есть какая-то кодовая база есть завязки на именно вот hdfs то есть тем у кого нет как бы завязок кто выбирает СТК с нуля можно в принципе выбрать и другое решения Но эти вот облачные хранилки они отличаются между собой То есть например если выбираем амазонок Стрим или индексов то там операция там она очень сильно тарифицируется В то время как и медленная И cons в то время как вду она атомарная да то есть и некоторые ДБ Там они иу что типа сразу Нафига всё в одновременную папку потом вать соответственно чтобы всё работало эффективно нужно будет немножко там переписать свои бизнес процесса Ну то есть какой-то такой ответ Тут нужно смотреть то есть если с нуля стек то можно использовать плюс есть некоторые интересные облачные хранилки вот мне нравится aure Data Lake V2 что-то там потому что у них как бы она типа бесконечно скели в Облаке но целиком совместимо сфм со всеми гарантиями типа де листингов и вс такое то есть могут быть проблемы при по сравнению с хопом но нет блоке чтобы его использовать там в современном мире как я приводил это один из кейсов Как можно решить эту проблему С3 знаете в чём проблема если в Облаке если вам Ок в Облаке типа Ок поехали в в Яндексе там в меле в Гугле там ребята сделают своё дело красиво но если вы будете это онм делать Не факт что это будет проще и надежнее чем с многие люди испт что он что его сложно эксплуатировать то есть Может быть в этом будет проблема а помимо Цефа вообще нет аналогов нормальных но сейчас которые можно развернуть внутри он прм то есть в этом может быть проблема Угу спасибо А здесь вот на втором ряду Михаил Спасибо большое за доклад А вот у меня по крайней мере не не совсем появилось понимание а как стод вот под дата нодами организован то есть там есть различные политики хранения применяются то есть там быстрые наверно медленные какие-то диски как вот это реализовано у нас Stage под нодами реализован унифицированы это обычные HDD диски то есть без вариабельности то есть собственно с точки зрения дупа и ну реализация - это локальные диски которые монтируются контейнер локальные то есть без сетевых без ничего да то есть там есть какой-то как сказать констрейнт для инстан дано что они поднимаются вот на этих но где есть диски Да в терминах кубера у нас все инстанс это это л сеты у них там забронированы пишни у них одинаковый fdn то есть и соответственно если диск есть то они Ну если будут переезжать то вместе с диском куда-то Ага О'кей я Поня с перемещением айпишник и всего такого хорошо Спасибо друзья Вот в этой части зала есть вопросы ещё ни у кого нет Давайте тогда дальше здесь продолжим Спасибо Спасибо огромное за доклад очень информативно у меня Меня зовут Анастасия у меня было такой несколько вопросов первый вопрос про отказоустойчивость вообще есть какой-то влияние на отказоустойчивость кластера то есть больше падать меньше поднимать не поднимать это вот первый вопрос второй был про взаимодействие то есть условно какого-нибудь нма и коннектора и так далее Есть ли какое-то влияние после переноса в облако и третий вопрос Ну он такой скорее бизнесов больше то есть появилось Если больше возможностей условно то больше ли стало кластеров или меньше или в принципе сколько на железе было столько их и осталось угу Значит отвечу по порядку так блин забыл порядок Какой первый там вопрос был А про насчёт стало ли лучше работать Ну конечно то есть там Все манёвры просто ускорились там в десятки раз то есть там ну если нужно потники Это ресурсы вот допустим крутой пример да то есть мы для ускорения наших расчётов проводили эксперимент по монтированию nvme диска выбили себе бюджет договорились то есть решили проверить насколько расчёты будут быстрее то есть на железе чтобы провести масштабный манёвр Да это вообще невозможно мы бы там себе выбивали тестовый там кластере небольшой с дисками этими гоняли бы расчёты доказывали бы что ты камуто здесь как бы согласование в разы быстрее Ну по крайней мере согласование Может быть там ну надо с кем-то договориться но сам манёвр это мы нажимаем там кнопку меняем манифест вжух там за пару часов весь кластер переконлива диски приехали то есть по надёжности там ну то есть я бы сказал что если не проводить манёвров он сейчас дуп вообще не требует администрирования никакого то есть ну только там в каких-то критических моментов когда арты загораются то есть ну стало лучше оден за с Как раз за счёт того что у нас просто стратегия такая компании то есть развивать именно это решение как я говорил его уже на уровень холдинга вывели и он просто лучше работает там все процессы лучше работают то есть условно Это облако - это как такой единый слой который менедж специальные там администраторы и там просто люди решают все проблемы которые могли бы возникнуть то есть там если мне нужно операционный систем обновлять всё вообще без моего участия происходит Ну как бы то есть намного лучше удобнее конечно с точки зрения эксплуатации Да ну с точки зрения пользования как бы всё тоже самое но как плюшечка пользователя мы им всё ускорили там в пять раз Ну ещё по-моему два вопро так ещё два вопроса да про гнп У нас их нет но взаимодействие с другими системами Не нарушилось то есть тут я говорю никакого влияния контейнеров не замечено в очередной раз у нас уже большой опыт там и часто влияния контейнеров Нет есть влияние других узлов иногда То есть если рядом с вашим контейнером есть ещё какой-то другой контейнер это такая проблема бывает с ней борется стало намного лучше могу сказать за там несколько лет но сами контейнеры они практически не добавляют там на вот этих вот наших бигдата кейсах Так что ещё третий вопрос что там количество кластеров пока не увеличилось Кроме тех кластеров которые мы подняли Аля Как сервис но нам Теперь гораздо легче делать шардирование то есть понятно Такой Ну основной способ масштабирования ходу - это Федерация у нас Собственно уже есть Федерация то есть нам новый узел Федерации завести очень легко Спасибо и вопрос из чата от Романа скажи пожалуйста вы только hdfs мигрировали или был опыт миграции других компонентов например СУБД или так мы Ну мигрировали собственно в рамках этого доклада hdfs и я да А в рамках других работ мы мигрировали много чего там про платформы это миграция кластеров каки То есть все кластеры каки были на железе стали в итоге на Ну в Облаке то есть миграция была также ещё такой у нас есть Store то есть штука из которой быстро забирают фичи доти Ну своего продакшена то есть тоже такая миграция была вообще ну в Одноклассниках мигрировали абсолютно всё с железа в облако там это большие инсталляции Кан там много чего ном нет из в зрительном зале Есть ещё вопросы То есть у нас условно можете считать всё кроме там какого-то древнего legas сейчас работает в этом облаке Кроме этого Legacy и каких-то критических компонент которые принципиально на железе развёрнуто by Design Спасибо А тогда ещё один вопрос из чата Каковы нагрузки на межд каналы и вот если рассматривают три цода там Угу Ну такой да тонкий вопрос но мы ограничиваемся Ну сотни Гигабит там сотнями Гигабит для наших вот рабочих нагрузок супер Спасибо Миш Выбирай пожалуйста Два лучших вопроса начнём с подарка от нашего партнёра от газпромнефти давай у меня немножко сбилось про лучшие вопросы так А где подарки у нас вопросы то есть Ну давайте то есть последние надим потому что ну много там актуальных вопросов Ну последнее где было три вопроса У нас вот девушка задавала Да и ещё дополнительно Какие вопросы были можно быстро повторить там кто запомнил А я сам не помню А ну Поднимите руки кто задавал вопросы какие вопросы были так ну классиче вопрос на самом деле хотел да то есть это это тема которую Ну всегда нужно обсуждать Ну то есть что выбрать Там всё-таки старый добрый хадуп или что-то новое модное Поэтому вот подарок от Одноклассников вам Угу Ну у нас на самом деле есть подарок и для тебя тоже спасибо спасибо тебе большое Миш за то что поделился своим опытом приходи рассказывай ещё и о других миграциях и в целом как дела Y"
}