{
  "video_id": "29MJugEzrtA",
  "channel": "HighLoadChannel",
  "title": "Как мы переживаем сплит-брейн и продолжаем писать данные по S3-протоколу / С. Богатырев (YADRO)",
  "views": 1454,
  "duration": 3100,
  "published": "2024-04-17T01:11:00-07:00",
  "text": "В жизни каждого спикера наступает момент когда надо выйти под музыку прошу друзья Готовьте вопросы через полчаса вернусь к вам Здравствуйте всем Меня зовут Станислав Богатырев Я сейчас работаю в компании Drom это российский производитель систем обработки данных хранение данных микропроцессорных дизайнов умных устройств и так далее с прямо фабрикой России сегодня мы будем говорить о системах хранения данных системах хранения данных давайте начнем то есть что сегодня будет вначале мы кратенько введем тему объектного хранения чтобы все понимали О чем идет речь чтобы было понятно проблематика потом немножко поговорим про математику а потом будут котики графики вот все что мы любим Итак я буду говорить про систему Frost Fast и totalking frost.fs это децентрализованная объектная система хранения данных которую наша команда разрабатывает с 2018 года вот здесь в Петербурге Это все свободное по gpr V3 лицензия очень интересная система много забавной математики внутри и обжиг это коммерческий интернет-класса продукт объектное хранилище на основе Frost FS сделаны что это такое Это сеть хранения данных То есть у нас нету какого-то единого центра это полностью децентрализованная система у нас могут быть в рамках одной большой стихи хранения какие-то группы узлов собранные по региональному признаку или по какому-то домену отказа если мы говорим слово кластер в контексте нашей системы мы имеем в виду именно на это а Ключевая особенность системы в том что она масштабируется на масштаб глобуса до размера глобуса и как следствие система большая должна работать с диком в интернете а в диком интернете всё постоянно ломается у нас может а-а странно вести себя сеть могут странно вести себя сервера железо пользователи вокруг плохая погода всё что угодно система наша с этим всем справляется это накладывает ряд особенностей по требованиям к ней потому как она себя ведёт а теперь система объектная то есть мы работаем с объектами храним данные в объектах объект Это кусочек данных к которому прилеплены какие-то метаданные если мы возьмем от этой структуры Хеш мы получим адрес объекта объекты неизменяемые Мы в один раз записали создали сумму посчитали подписали все он мясо не может это был данные неизменяемые объекты мы можем группировать в контейнеры Это примерно как директория файловой системе на диске соответственно контейнер Это примерно то же самое что баки в Amazon 3 если кто-то знаком а я так понимаю что большинство наверное Вот то есть мы описываем политику хранения как мы хотим чтобы наши объекты хранились добавляем какие-то атрибуты а права доступа опять же таки от этой структуры берем Хеш и вот у нас есть адрес контейнера адрес объекта это полный адрес по которому мы можем доступа к нашим данным то есть мы адресуем данные по хэш вы содержимого это называется контент-тересовал сторож то есть кассы поэтому мы касса система К объектам системам обычно доступ идет по какому-то API у каждой объектной системы обычно плюс-минус свой У нас тоже так как мы должны работать в недоверенной нестабильной среде у нас свой API на базе gpc и протобуфа Ну мы понимаем что это не очень сильно распространён за пределами нашей системы поэтому у нас поддерживается концепция протокольных шлюзов то есть отдельных сервисов которые транслируют запросы из какого-то протокола например HP в наш и ещё раз Ключевое свойство системы чтобы Мы понимали проблематику то что у нас нету какой-то Центральный митоза нет Центральной точки отказа каждый узел в системе максимальная автономный То есть он делает все возможное с его точки зрения для того чтобы данное хранились оптимальным образом соответствие с заданной политикой делает вообще всё что можно максимум старается вот им никто не командует практически а как нам удается этой Центральной метабазой избегать Значит у нас есть политика хранения политика хранения описывается внутри системы в бинарном виде для людей у нас есть несколько представлений подобный язык описания политики визуальный редактор для тех кто любит картинки двигать по экрану в общем Широкая многообразие и компилятор соответственно внутреннее представление То есть например представим что у нас Наша сеть хранения состоит из четырёх узлов Мы хотим хранить объектик один в Петербурге один где попало вот мы Давайте читать снизу вверх мы берём определяем фильтр по какому-то геотрибуту То есть у каждого узла есть атрибуты А мы выбираем что мы считаем Петербургом потом из этого множества выбираем Один узел а умножаем его на два э себе фактор это БК Фактор А для пущей безопасности А И вот стрелочка идёт что мы из этой группы выбрали например ноду S1 а переходим к разбору следующего пункта реп один из звёздочка то есть мы хотим хранить ещё одну лепку где угодно и вот у нас например Москва свободна вот хороним в Москве вот а таким образом если мы знаем политику карту сети мы накладываем одно другое получаем Вектор узлов отсортированный в порядке понижения вероятности нахождения в них узла вот мы при создании объекта вычисляем этот Вектор при нахождении объекта опять же таки вычисляем этот вектор и без Центральной метабазы всегда можем его положить в нужное место и найти его соответственно Вот примерно так это работает Если упростить возникает вопрос Где взять контейнер и тут появляется наш прекрасный блокчейн у нас внутри системы есть настоящий блокчейн Зачем он нам нужен значит во-первых это источник времени так как наша система может работать в масштабе глобуса мы не можем доверять термическому времени оно везде течёт по-разному на каждом узле оно течёт с разной плотностью и постоянно сбивается поэтому у нас э через всю систему проходит дискрет то же время которое мы вычисляем в высоте блоков то есть Сколько блоков блокчейне блокчейн понимает это наше время дискретная по системе блок мы генерируем примерно раз 8 секунд и Это наша точка лицензизация дискретизации для каких-то не очень больших операций и раз 10 минут примерно по высоте блоков нас наступает новая Эпоха это такая большая отсечка в рамках которой мы например можем изменить карту сети то есть какие-то какое-то количество узлов пришло какое-то ушло мы фиксируем это состояние Вот примерно раз в эпоху Для чего нам еще это нужно кликер работай вот блокчейн Для нас это база данных то есть мы используем блокчейн как реплицируемый на каждый узел базу данных в котором храним не очень большое объем доверенной информации если проводить аналогию с традиционными системами то можно представить что у нас есть смарт-контракт блокчейне это как бы такая табличка киевелю которая у нас как-то специализированном виде существует и мы можем к этой табличке писать сторис процедура которая эти данные будут обрабатывать вот фактически в таком варианте мы блокчейн и используем и так как все свойства блокчейнов у нас внутри системы сохраняются Для нас это источник Правды мы можем криптографически гарантировать что то что пришло к нам через цепочку это вот точно правда что там проверено все подписи права доступа обмануть там математические сложно э-э возможно но в рамках длительности нашей жизни это не имеет смысла Итак в нашей области объектного хранения есть примерно два полюса которым тяготеют разные проекты на одном конце это бесконечное масштабируемость до межпланетарного масштаба на другом конце у нас управляемость вплоть до каких-то совсем тонких кишечков как мы данные на диске храним и ряд систем пытается балансировать между этими двумя крайностями с разной степени успешности Мы хотим быть Примерно вот в этом месте квадрата то есть наш Frost FS как Public систем он действительно способен масштабироваться до размеров глобуса на межпланетные взаимодействие пока не замахиваемся там будут другие проблемы Вот поэтому Глобус для нас достаточно э и э в рамках этой мы чуть-чуть снижаем порог масштабирования в пользу управляемости и ну ограничиваем а-а размеры сети сот нями узлов для того чтобы этим можно было проще управлять как-то встраивать в корпоративную инфраструктуру и добиваться выполнения всяких разных требований значит перейдем теперь к ближе к теме доклада К сожалению стандартам де-факто индустрии для объектного доступа стал протокол S3 Это протокол старый у него тяжелые эволюционное развитие и он сделал огромное дело для индустрии и в основном Он позволяет наложить привычную пользователю абстракцию доступа файлового на объектную реальность Поэтому у всего есть имена это с точки зрения системы некоторые проблемы мы можем именовать файлики можем именовать бакики так как мы объекты не можем изменять о файлики можем то быстрее протоколе У нас есть версии объектов Мы что-то записали изменили у нас появилась новая версия удаление в децентрализованной системе это большая отдельная интересная задача а-а поэтому удаление протоколе это тоже создание новой версии маркеры удаления и чтобы сделать жизнь проще людям можно создавать быстрее из объектиков которые поименованы некое дерево директории привычный с дискотопов А у нас Кас у нас и мутабельные объекты и мутабельный контейнеры они все плоские и нам надо как-то из три протокол реализовывать то есть мы видим сверху что ис-3 это нечто очень спроектированное на сильный центр то есть этот хорошо работает централизованной системе на систему полностью децентрализованная но мы это сделать смогли давайте сейчас посмотрим как Для начала сразу пройдемся по наивным решениям наивное решение они не работают в этой области Мы любим практиковать такой научный подход То есть раньше мы сначала публиковали какую-то научную статью потом им примете две в проекте сейчас на все это время не хватает поэтому мы как минимум делаем какие-то эксперименты и уже их сравниваем Давайте быстренько пройдем по наивным решениям то есть первое что приходит в голову у нас же есть блокчейн Давайте хранить блокчейне соответствие версии имени и так далее То есть у нас у объекта есть атрибуты Давайте в атрибуты запишем имя и путь Ну можем записать можем вот а давайте Теперь попробуем сделать э какой-то смарт-контракт в котором мы будем прописывать какой путь э у нас э какой версии соответствует версии и так далее э здорово здорово просто реализовать Ну просто э Однако на практике это не работает потому что блок принимается раз 8 секунд э И несмотря на то что у нас э может быть в блоке множество операций существенно большое а на каждую из этих операций все равно будет 8 секунд как ни крути а это примерно сравнимо с тайм-аутом в клиентских библиотеках и получается что мы сразу делаем систему которая Априори балансирует на грани тайм-аута запроса это не то что хочется видеть и теме интерпрайз-класса поэтому это решение не подходит следующее что можно рассмотреть это наивный мы определились лайк подход То есть у нас есть атрибуты все то же самое и внутри системы у нас есть глагол всё ещё то есть мы в своём апель можем делать не только гет пост гет-под запросы на объекты можем делать ещё то есть мы можем поискать А в сети какие-то объекты по определённой характеристикам и вот например мы можем на каждый год выстреле взять и поискать объекты с таким именем можем Но тут получается что это достаточно долго и какие-то узлы сети могут в этот момент отсутствовать поэтому ответ Мы никогда не получим это значит у нас э решение совершенно без гарантии оно будет работать непредсказуемое Это значит что пользователь будет удивлён А мы стараемся строить систему по принципу наименьшего удивления по крайней мере для этого возможно поэтому такой подход тоже нерабочий кликер работай И что же мы можем сделать это было где-то на границе 20 20 года Мы подумали что мы же можем сделать следующий шаг от прошлого слайда и реализовать как минимум средити и то писать то есть это структуру данных всех детей которые бесконфликтная сливается при изменениях разных точек Например если у нас есть счетчик там с двух сторон мы сделали плюс два здесь два здесь при слиянии мы получили плюс 4 счетчик коррекция здесь примерно тот же принцип но чуть посложнее в литературе эта структура данных еще может называться gside но мы использовали то писает по историческим причинам В чём суть что мы когда создаем объект Мы в него записываем дополнительные информацию а именно версии которые мы знаем что были добавлены э-э это мы смотрим опять же таки поиском записанный список версии которые были удалены мы записываем известную нам маркеры удаления каждый объект в системе имеет синтетический таймстеп если мы в итоге собираем какую-то версию то мы без централизованной метабазы В итоге получаем корректное С математической точки зрения последней версии объекта это действительно работает работает Ну относительно неплохо на малом количестве версий поэтому конечно такое решение быть не может но на практике мы посмотрели что в дикой природе в сети публичный версии объектов потребность там на пальцах одной руки обычно считается если они есть Поэтому мы попробовали такое решение заинплементить Оно даже для каких случаев нормально работало но потом случилось прекрасное Мартин клипман опубликовала свою статью про средити дерево в котором он доказал возможность операции то есть в чём в чем суть идеи У нас есть дерево и мы можем представить дерево как последовательность операций его формирующая то есть мы формируем Лог операции например добавить узел удалить узел передвинуть узел и вылетать обработки этого Лога формируется итоговое дерево Вот раньше не было формального доказательства того что что-то кроме добавления можно в таком варианте делать а статья э-э клепана как раз в нём есть доказательства теоремы которая позволяет э-э реализовать муху операцию то есть он также доказывает для множества этих операций свойства коммутативности и получается что мы можем вставлять операцию изменения не только в конец для разрешения конфликтов а вставляешь фактически в любое место поэтому когда мы пытаемся синхронизировать дерево мы делаем откат вставляем операции перенакартоном остаток получаем согласованные итоговое дерево всё просто а-а и самое главное ещё раз то что можно делать мув они только это потому что это точно такой же муфт только в да то есть если мы хотим удалить кусочек дерева мы передвигаем его а-а потом там к дереву к узлу который не доступен от корня и вот мы фактически реализовали удаление при этом оставшись а-а абсолютно корректными С математической точки зрения это вот прям очень крутая фича Ну потому что без неё удаление в децентрализованной системе без единого центра это правда очень-очень-очень больно Вот то есть у нас есть внутри системы отдельные механизмы на случай зомби-апокалипсиса У нас есть специальное кладбище для объектов вот все эти вещи они существенно упрощаются с доказательством этого свойства и еще раз все это работает полностью децентрализованно То есть у нас нету какой-то Центральной базы данных которая пишет вот этот объект лежит здесь этот объект лежит здесь вот мы всё это делаем максимально децентрализованно значит как это выглядит Давайте посмотрим У нас есть две реплики между ними есть сетевой связи у нас на них одинаковое дерево Теперь попробуем сделать простенькую операцию Мы в реплике Один узел B передвинем э-э дочерним а узел а другой репливия дочери вот мы сформируем два дерева теперь у нас все эти восстановилась и прошла какая-то коммуникация синхронизационная что же у нас будет в конце У нас возможно четыре варианта значит давайте их рассмотрим вариант а мы получили цикл Когда в дереве появляется цикл что он превращается в Граф правильно А это выходит за пределы нашей теоремы поэтому варианта нам совершенно не подходит вариант б мы сделали операцию передвижения с точки зрения как конкретно реплики вообще одну а получили три фантомных узла в дереве мы не делали варианты добавления Это какой-то плохой вариант Поэтому нам тоже не подходит чтобы варианта плохие Остается два варианта C и D какой из них лучше кто за отца Поднимите руки одинаково да нам без разницы нам по большому счету вообще плевать с нашей точки зрения правильный тот вариант который будет одинаковый с двух сторон поэтому цель это будет или D нам вообще без разницы Главное чтобы сошлось вот поэтому правильный ответ без разницы и Вот примерно такой алгоритмику Мы в нашей системе реализовали Значит мы назвали деревянная служба то есть отдельный опек который позволяет множеством ему табельных объектов сформировать иерархию изменяемую иерархию именованных объектов и в процессе реализации оказалось что статья прекрасная доказательство там замечательные но на практике требуется большое количество изменений дополнений чтобы это все заработало в реальном мире первое что Пришлось сделать это сделать API который работает не с абстрактными идентификаторами узлов дерева А с чем-то понятным людям то есть с именами поэтому на шаппе рассчитана на имена мы сделали API опираясь над байпас вызов То есть когда мы добавляем объект мы его идентифицируем по пути то есть там кошечки мой котик точка гг а и дальше висят и строится на основании этого утверждения в дереве мы формируем собственно говоря вот три ноты это структура которая определяет узел в дереве Здесь тоже мы сделали ряд изменений относительно оригинальной статьи То есть во-первых статья доказывает теорему для фиксированного числа узлов в нашей системе узлы постоянно приходят и уходят структура топология сети постоянно меняется поэтому мы э в качестве ID узла используем не глобальные идентификатор а идентификатор локальный для какой-то группы узлов таким образом каждый узел генерирует уникальные идентификаторы в своём собственном пространстве и пересечение здесь исключены А дальше мы привязываем к этой структуре э идентификатор объекта э полный адрес наших шоу им табельного и он же идентифицирует версию выстреле быстрее у версии есть аишник мы привязываем эти трагичник к адресу объекта а Да корректно с точки зрения протокола и позволяет нам делать общие общий субъектов между разными протокольными гитарами то есть одна из вещей система в том что мы сразу работаем по нескольким протоколам можем загрузить объект систему по ис-3 что-то с ним сделать по нативному протоколу и дальше отдать похотп через протокольный гейт и вот это всё прям друже друг с другом Это очень прикольно на самом деле А и дальше чтобы как минимум в S3 у нас э работала корректно сортировка объектов по времени появления мы изменили э семантику более тайм то есть мы маркируем узлы в дереве э по синтетическому таймингу монотонного возрастающему в рамках всей системы и высота э высоту появления узла в системе в оригинальной статье мы э определяем время последние муфту операции злом э это очень интересные изменения Прочитайте статью там прикольные доказательство А вот можно будет понять почему почему мы не ошибаемся А давайте теперь посмотрим кликер работает вот посмотрим как это всё работает значит чтобы когда мы делаем пуд объекта мы делаем запись в структуру специального вида мы называемый пилорама Мы берем дерево рубим на логи вот складываем пилораму то есть мы например делаем мы создаем котикам котик у нас лежит по пути lol Cast gpg Значит мы формируем влог операций запись мы добавляем элементы мы так как мы добавляем по пути Мы путь разбиваем на промежуточные узлы и вот мы видим что нулевой узел на схеме это корень дальше Мы создали что-то типа директории lol CS и дальше последний уровень - это кэшбг это как раз последняя версия объекта Cat jpg вот у нас получилось такое дерево с котиком э Давайте немножко усложнение добавим вторую версию котика мы с точки зрения пилорамы добавляем Точно такую же запись но с другим идентификатором привязанного объекта то есть всё то же самое против другой обрабатываем точно так же вызов пас добавляем узел дерева у него другой идентификатор и мы сразу видим что это последняя версия котика То есть когда мы сделаем запрос Get мы посмотрим на это дерево найдем листик который представляет котика и детерминирована выберем последнюю версию дадим ее пользователю давайте сделаем чуть сложнее ближе к теме доклада как мы будем работать в условиях Брейна то есть потеря сетевые связности то есть networtion мы на одной стороне Добавляем еще одного котика вот у нас 18 узел появился в сети вот мы его с одной стороны добавили у нас случилось беда все эти разделилась с другой стороны никто брать ничего не знает но при этом тоже добавляет котиков мы добавляем новую версию вот у нас появляется узел с идентификатором 20 при этом до 16 узла с обоих сторон все видят котиков просто разногласия Какой котик последний Теперь мы восстановили связность и получили непротиворечивое опять дерево назад что мы видим как мы посмотрели раньше если таймс темпы как мы решаем конфликт То есть фактически У нас есть лок-операций мы берем этот операции и перемалываем таким образом чтобы в итоге у нас получился корректный результат мы имеем некое свойство коммутативности доказанное для этих операций поэтому мы вали там у нас есть некие вольности если у нас темпы различаются здесь очевидно как мы видели с примером с первым двумя котиком мы берём последнюю здесь звезды сложились Так что у нас Темп получился одинаковый то есть мы с точки зрения системы её дискретного времени двух котиков а создали одновременно надо решить Какой из котиков главный а-а Как мы можем это сделать котики меряются у кого же не значит у кого каждый день Вот в этой версии главный котик вот собственно говоря всё это детерминировано всегда работает никаких проблем с этим нет никакого удивления независимо от сложности позиционирования Мы всегда решаем конфликт и немножко о том какие трудности нам пришлось преодолеть на пути к работающей системе во-первых нам пришлось в пилораме минимизировать число ключей чтобы снизить влияние на этой точнее чтобы мы с ним как-то хоть вменяем работали мы нам пришлось максимум слить вэлью как-то делать группирование и так далее задача была поставлена минимизировать число ключей в пилораме чтобы с этим можно было работать приемлемо мы пишем систему нагор поэтому вот мы сделали все структуры так чтобы минимизировать маршалинг вот у многих программистов сейчас должно было отозваться в душе что-то и мы в качестве нижнего уровня хранилки для пилорамы используем базу Бей болт и нам Пришлось написать свой бачинг для того чтобы мы могли группировать ключи не просто в порядке их появления А в порядке принадлежности к определённому дереву а плюс мы определили некую оптимизацию для основного алгоритма мы выделили что есть ряд операций которые Безопасен для добавления группы и не требует перенакладки и разбора То есть например там добавление под дерево в ряде случаев Вот для этого Пришлось написать небольшие небольшие изменения с точки зрения это все в рамках одного узла с точки зрения синхронизации деревьев Мы тоже от наивной модели сделали ряд улучшений то есть во-первых свойства этого дерева позволяет нам синхронизацию делать параллельно а-а то есть мы можем параллельно обходить все узлы э-э которые требуют синхронизации дерева копить изменения группировать безопасное и уже за один присест э делать э слияние это прямо разница между наивным подходом и вот этой оптимизацией это уже практически порядок вот а дальше Если синхронизироваться до конца то есть когда два узла пытаются синхронизировать дерево в ситуации когда идет большой поток запросов на изменение дерева мы можем никогда не сойтись поэтому здесь нужно делать отсечку и синхронизировать для какой-то точки потом вставляете операцию тогда это хотя бы сходили процесс сходящийся и если вдруг у нас входит в сеть новый узел он должен подняться он ничего не знает он начинает ниже синхронизацию деревьев вот здесь есть некий предел когда не стоит принимать новые операции на чистый узел дождаться как синхронизации до какой-то разумной высоты это не влияет на систему в целом потому что другие узлы доступны операции из дерева можно делать через соседей А И когда мы эту ситуацию изучали нас появился Соблазн такой что у нас же операция коммутативная мы можем просто взять которые не Успеваем работать ну и выкинуть из Лога потом по синхронизируем делов-то Ну оказалось нет Э потом приходилось откатываться на э существенную глубину в прошлое делать теперь накат это в итоге всё оказалось дорого поэтому дешевле шевле просто подождать и у нас здесь тоже возникла проблема с мертвецами Они нестабильны то есть к сожалению если в сети какой-то узел начинает умирать он делает это не моментально и не навсегда Часто у него очень такая деструктивная агония Поэтому если мы подозреваем что узел мертвый то мы на какое-то время перестаем с ним общаться пока не не стабилизирует ситуацию если бы он умрёт навсегда либо оживёт в другой интернет нации И как же мы всё это проверяем мы сделали не одну реализацию а несколько А во-первых мы сделали мемориализацию для того чтобы работать с проверкой корректностью то есть мы э постоянно гоняем тесты на деревянную службу мы берём какое-то дерево генерируем случайно очень большую глубину операции много-много-много получаем итоговое дерево потом мы хранилище э произвольным образом их перемешиваем в нескольких этапах потом делаем с рождения и смотрим Что в результате мёрджи мы получили тот же самый результат а-а это конечно неформальные доказательство корректности а но мы готовим модель для того чтобы хоть какой-то доказательство иметь а когда напишем доказательство модель мы наверняка какой-нибудь очередную научную статью как мы любим и Значит так ли хорошо это работает Как я говорю да да вот это пример на обычном комоде тяжелее мы провели эксперимент взяли котика размером в 1 мегабайт и 10 тысяч раз записали его самого себя то есть создали 10 тысяч версий одного и того же котика мы это делали на нашем деревянной на деревянной службе и на реализации который мы дети которые мы обсуждали чуть ранее и вот мы видим что сложность с глубиной версии растёт у всех детей это полиномиальная А наши деревянная служба работает практически линейно здесь можно обратить внимание что где-то в районе 10.000 версий колебания около 5% начинаются но общий паттерн это не меняет то есть Прям вообще красиво и задержки влияют на срубот напрямую и вот мы можем посмотреть что в случае если у нас независимо от количества узлов сруб от фактически остается тем же вот мы за счет накопленных задержек работаем на скорости примерно 23 мб/с это Маловато для интерфейса с деревом мы с каждого узла на достаточно мелких объектах на коммунит эти железы получаем вот 500 мб/с это практически линейно растёт э на э гигаба почти гигабайт секунд То есть это в принципе мы на двух узлах уже выедаем э 10 Гб а Итого что же у нас получилось Мы внедрение cr-dt дерево в Операции можем полноценно работать с объектами сетевой изоляции Э он же Брейн э с небольшими оговорками мы не свалились централизованную какую-то метабазу у нас так и не появилась Центральная метабаза Мы работаем без Центральной точки отказа Мы полностью децентрализованы у нас отсутствует какие-то непредсказуемые конфликты при синхронизации то есть здесь одна из важных задач которую мы решали это не Паради Ситуацию которая потребует вмешательства человека Мы хотим сделать систему максимально независимо от людей Поэтому если возникает какой-то конфликт мы решаем автоматически это хорошо но ничто не происходит бесплатное вот эти мелкие низкие задержки на этапах создания объектов на этапах э-э Вычисли объектов их приходится компенсировать обыграл всех организаций но это не влияет на целевую функцию системы винную пользователя к счастью это всё внутренние проблемы сети хранения они в принципе людям не видны Как начать использовать наш Frost FS который лежит в основе татны обжиг Это настоящий свободный настоящий свободное поло настоящего бансорс gplv3 можно сходить на гитфордская с инфо в этом убедиться почитайте сходнички оставить баги всячески приобщиться У нас есть удобный Ван контейнер для экспериментов делали мы его для того чтобы можно было протестировать какую-то интеграцию с сторонним софтом проверить насколько Мы хорошо поддерживаем stre-протокол проверить интеграцию какой-то другой системой и у нас есть документация которая сейчас не так хороша как нам хотелось бы но мы работаем над этим и если вы хотите посмотреть на наш прекрасный интернет-продукт Вот это тоже можно сделать по ссылочке Всё спасибо Я надеюсь будут хорошие интересные вопросы токсичные и холиварные так курьеры с микрофонами Уже побежали прямо вот да Третий ряд завсегда ты пожалуйста Это первый и последний кажется спикер на это конференции который Давайте токсичные вопросы Максим Озон технологии Будьте нежными пожалуйста Да я постараюсь вот для S3 как мне кажется есть такие достаточно тяжелые вещи связанные с удалением как лайфхакл когда люди хотят удалять там тысячи миллионы объектов ну какие-то такие внушительные вещи и еще когда какой-то сторонний софт который Ну не знает или думает что знает что такое стрит делает муфф из одного грубо говоря так сказать части дерева в другое Не знаю что это kiway хранилище насколько Вот такая распределённая система она вообще в состоянии выдержать Когда у нас там кто-то взял и переместил там миллион объектов из точки А в точку б то есть 10 млнений 10 млн ставок Вот это очень Как хорошо вопрос а именно чтобы в такой ситуации нормально жить Вот это Дерево нашей помогает то есть для нас э 100 млн объектов это одна операция фактически на бэкенте с этим Нет проблем Это будет две операции То есть с-3 ты не знаешь что это одна операция протокол так не устроен это как бы ну мы рады за ис-3 у нас твой протокольный гейт Он в курсе вот то есть увидев мув операцию он э-э будет общаться с деревянной службой нашей и сделать всё ну как бы по оптимуму поэтому э во-первых операция не то чтобы там в Истре было очень очень Как сказать очень в базовой библиотеках давайте так мягко скажем вот через удалить ставить это вот твоя вот у нас в нашем сдэшечке мы сейчас пока это не выносим на уровень Стрим А на уровне родного языка Да конечно же есть вот мы над этим работаем то есть в отличие от прочих унылых и стрессоражей А у нас за счёт вот этой операции Move э делается всё в три в три пресса значит дальше ещё было первая часть вопроса на которой тоже хотел ответить давай так э Здесь ответы с двух частей Значит во-первых у нас есть э-э если мы хотим задать лайфхакл и знаем чего мы хотим на старте мы можем задать experation объекта и он э фактически за бесплатно протухнет по всей сети одновременно Ну плюс-минус вот а если речь идёт о динамических войсках которые вот э практически через ленточки реализуются реквире Вот то пока мы это не поддерживаем именно потому что у нас пока нету лямдочек своих децентрализованных Как только они появятся сразу сделаем вот Спасибо в чатик почему выбрал на битболт исторически сложилось Э мы с как мы по сравнивали би-болд э-э баджер level db и в принципе мы от от смены базы данных не то чтобы очень сильно выигрываем у нас проблемы уровня выше уровнем ниже поэтому bebalt у нас в целом пока устраивает Спасибо будьте добры Да спасибо за доклад такой вопрос Вот вы dvc пробовали использовать вообще сравнивали как он работает я так понимаю это что же у нас про контроль версий Pro версионирование элементов Ну да смотри Давайте вот вопрос он как бы Давайте его кулуарана потому что он немножко как он про сравнение классов систем Вот и я готов поговорить там часик с Олегом была такая тема к нему подходит уже после выступления задают вопрос а у меня уже выключен микрофон чтобы ещё есть вопросы собственно Вопрос такой все хорошо у нас пропала сетевая связность узлы продолжают принимать данные потом между собой синхронизируются Но мы же не знаем сколько продлится пропадание этой сети Вот давайте возьмём вашего котика но он будет Не статичным мы про этого котика решили сделать мультфильм мультфильм после того как его нарисовали нужно трендерить это допустим 24 кадра в секунду стандартно мы запускаем 500 серверов рендера который начинают забирать котика для того чтобы рендерить кадр и получается так что половина серверов забирает Слот одних на которых версия котика шестнадцатая а вторые вторая половина серверов начинает забирать котика с двадцатой версии и в итоге у нас получится что половина мультфильма про одного котика А половина про второго вам получается надо либо кластер переводить в оврайтон или режим какой в этом смысл либо отказываться от этого то есть какую задачу В этом случае решает вот этот вот ну здесь два вопроса в одном У вас во-первых если наш софт находится в третьей точке которая доступна оба изолированного сегмента то здесь софт либо вся система которая построена должна быть достаточно умной Чтобы понимать здесь вопросы к архитектору прикладного уровня почему он при понятных свойствах системы снизу сверху сбоку вот такую ситуацию допустил вот второе давайте сейчас немножко поговорим про физику времени а-а в нашей системе э время дискретное да А и оно высчитывается от цепочки то есть оно течёт примерно с одинаковой скоростью волнами по всей сети вот если в какой-то части системы у нас потерялась сетевая связность то если цепочка потеряла все консенсы с узлы то вот в этой части время остановится Вот и таким образом нас будет часть в которой время Остановилась и в этом нет ничего плохого все объекты операции продолжают работать вот а в другой части системы время идёт вверх Вот таких систем таких частей системы в которых время течет и остановилась разная скорость может быть сколько угодно до числа количество консенсов узлов Поэтому вот сколько мы в таком состоянии пробудим нам неважно потому что в момент соединения системы время э ну время начнёт течь с другой плотностью то есть система которая застыла во времени э на момент сетевого парцианирования э время в нём начнёт внезапно быть очень плотным и она проживёт там условно за день а э недельную изоляцию поэтому все эти операции которые были произведены в частях системы не выпавших из потока времени они в этой системе воспроизведутся и к моменту когда мы решим что она работоспособна у неё видение останется таким же как у других вот примерно так давайте упростим вопрос чтобы было понятно есть четыре ноды потерял связность две между собой связаны и другие тобой связаны система перейдет система никогда не переходит в системе может остановиться время время становится в обоих системах зависит того как мы распределим если четыре узла то давайте рассмотрим практически у нас сузил один в одной части системы время продолжите в другой части остановится Одна часть узлов отвалится А что с ней продолжить писаться время там нельзя будет создавать новые контейнеры читать можно а как должна система внешняя какая-то определить Откуда можно читать Откуда нет она же не знает про ваши внутреннее время для этого если мы говорим про внешнюю систему как пользователи нашей то у нас выставлено достаточно большое количество ручек Метрика и так далее которая позволяет эту ситуацию наблюдать мы изнутри каждый каждого такого кусочка системы достаточно честно репортуем его состояние Если это важно для внешней системы эта информация может быть принята в расчёт стоп Я из внешней системы могу ходить в оба кластер который связан с потерями между собой предположим да хожу в оба кластер и оба кластера мне отвечают разными данными оба кластера отвечают разными данными на объектные запросы То есть вы делаете getca jpg Вот получается Здесь на охотите здесь другого совершенно верно Вот смысл в этом если в вашей системе это критично со своей стороны Вы можете понять э Какой котик э Где какая часть системы например в каком времени находится разве это не для любой системы критично вот у меня сидит дизайнер он заслал котика о до одной системы дошёл котик другой не дошёл дизайнер про это знать не знает это прекрасно смотрите вот если ваш дизайнер сидит в одном офисе и у вас там есть э приёмные узлы вот наша система например то он вот куда положил там у него последняя котика лежит Всё нормально Вот он сам вместе с системой находится в силовой изоляции он а сервера которые рендерит забирает котиков с собой систему Они же не знают куда дизайнер положила они предполагают что дизайнер положил и дальше ты не головная боль дизайнера куда он положил я могу читать с любого узла и получать актуальные данные консистент это головные более системы которая действует связь между слоем хранения слоем рендеринга Короче вы вместо того чтобы упростить добавили головной боли тем кто этим пользуется э-э Ну не совсем так во-первых как я говорил то же самое начало это хотела сказать да что ты ждал 10 минут чтобы сказать эту фразу что вы должны это было понятно чтобы это был Так а вы с пальца э-э Ну Ну не совсем так то есть как я и говорил э проблема людей Для нас вторичная в плане Ну не совсем так это я понял просили лишь токсичный вопрос то есть там там где мы максимально избегаем ситуации которые потребуют именно активного вмешательства человека Вот поэтому человек как существо наделённое интеллектом естественно вот э-э ситуация которая находится за пределами системы вот он их должен обрабатывать мы делаем всё чтобы эти ситуации были неудивительными вот да да и на конференциях для дизайнеров начнут говорить проблемы на стороне архитектора Спасибо Спасибо большое а-а Будьте добры следующий э-э Я надеюсь менее так Добрый день Станислав Спасибо за доклад у меня такой вопрос Чем вас так расстроили базы данных что вы решили от них отказаться Значит тут был доклад от другого Бородача чем база данных так прекрасны Да но он говорил про бас данных которые прекрасно работают в контролируемой сети среде который мы управляем наша система работает диком интернете и там что-то гарантировать ну такое себе поэтому построить на весь интернет децентрализованное или инфицированный кластер какой-то базы данных эта задача примерно невыполнимая на практике поэтому из-за того что сейчас есть в дикой природе работающего кроме блокчейнов в таком масштабе способных хотя бы какой-то кусочек данных Ну вменяемое практически полезный объём на весь интернет э-э обрабатывать Вот кроме блокчейн походов фактически ничего нету а любая база данных э-э она на таком масштабе То есть когда у нас там 10.000 узлов они все друг другом работают никакого управляющего центра у нас нет это всё просто не сложится и в итоге мы придумываем что-то блокчейн подобное получив все те же самые недостатки либо можно просто сразу взять блокчейн Ну но с блокчейном понятно с большими системами типа интернета тоже все ясно но здесь речь идет про файл storage который как правило используется в довольно Замкнутый среде Особенно если это Enterprise решение в замкнутых контурах и оно в принципе довольно контролируемо и предсказуемо зачем было городить такой страшный огород во-первых не файл а Объект это объект Да а во-вторых как оказалось не все контуры интерпраздные такие уже замкнутые и ограничены а очень много заказчиков э-э особенно в нашей стране хотят широкую географию и когда у нас начинает быть больше там двух-трех-четырёх реплик э-э то на Большом объёме это уже тоже начинает работать очень плохо э ну давайте там не знаю вспомним это праздник на букву C Вот и как туда положить 4 петабайта а потом синхронизировать другой дата-центр Ну как бы Ладно хорошо 8 с другим центром Как добавить узел Вот и вот все такие проблемы у систем Которые рассчитаны на работу в замкнутом изолированном контуре одного максимум двух Ну хорошо если повезло 3 Вот это центров Вот они наша система решаются То есть за счёт того что мы сразу рассчитываем на глубокую масштабирование Да если мы будем говорить о выраженном случае там не знаю одного узла или там двух-трех двух узлов э Да действительно здесь сложность для решения которые дальше двух слов не растёт возможно избыточно но если мы планируем рост как минимум Ну хотя бы там на три локации это уже начинает иметь смысл Ясно То есть это там от трёх локаций если хочется тогда имеется смысл ясно и ещё такой вопрос тут была картиночка по поводу сравнения записи объекта 10.000 раз типа на вашей системе именно на другой Так это другая тоже наша а другая тоже ваша мы просто сделали в реабилитации алгоритма один э-э то писатель и второе Вот это деревом Ага всё я понял а но всё ещё возникает вопрос э мне не нужно записывать объект 10.000 раз мне нужно записать 10.000 объектов к примеру Ну это будет работать точно так же точно так же конечно хорошо и последний вопрос время создания Бакета объекта там вы говорили около 8 секунд Это довольно долго это только для Бакета объектов моментально То есть хорошо объектные операции не идут по цепочке по цепочкам фиксируем только создание Бакета изменение extendo tcl и изменение карты сети а если мне нужно создать тысячу пакетов вы создадите 1000 бакетов за 8 секунд полторы тысячи бакетов за 8 секунд можно и больше тысяч байкетов за за 8 секунд хорошо А если мне надо 1.000 бакетов С задержкой в 10 секунд создать Ну типа создался 10 секунд прошло следующая создался Но это э-э Юрский когда много людей создаёт себе файл storeg же мы в границе восьми секунд будем ингредировать запросы и на создание батитов просто и всё то есть это 1.000 бакетов умножить на 8 секунд Я кажется вы хотите создали один багет подождали создали следующий Ну да ну то есть это я не говорю про фиксированное время я беру в среднем в таком случае вот именно для одного потока создания таких бакетов один за другим Да каждый будет создаваться за 8 секунд может быть много я понял спасибо а за сколько 8 человек съедят 8 батонов 8 человек съедят 8 батонов Да если один человек съедает Один батон за один час это за час и съедят мы сейчас скажи пожалуйста у Frost FS есть какая-то реализация Fuse это последний вопрос Вот это самый токсичный вопрос наверное значит человек из интернетов кажется поэтому придется что я по IP просто вот значит Fuse У нас есть прототип значит во-первых идея натягивать файловый доступ на объектную систему она греховно по определению поэтому делать её в полном мире невозможно потому что это натягивание с собой на Глобус э-э Мы у нас есть на Глобус не до конца в виде прототипа гейта для srtp то есть мы можем У нас есть гейт который после всех тебе позволяет это сделать фьюз мы можем сделать у нас даже есть прототип но э как бы он нормально работает только в регионе Не потому что там мы плохие потому что в принципе концепция сама провальная вот если мы посмотрим на амазон то они тоже для ис-3 дают файловый доступ только через NFS только в доме вот поэтому ответ такой что Fuse возможен нормально Это будет работать только в ритори Прототип У нас есть лежит на нашем инфо можно посмотреть и использовать но я не рекомендую потому что у нас есть sd-кашечки практически там подгошечку под питон под C Sharp и проще проще пользоваться нативными компонентами Или на худой конец брать готовую истребить библиотеку это будет эффективнее чем пытаться натянуть Fuse на объектную систему в средствах Спасибо большое кому книжку подарим за лучший вопрос А это Аплодисменты Тебе да а я зрителем за токсичные вопросы э-э Ну как махните рукой кто задавал вопросы Ну давайте вот токсичному молодому человеку вот книжечку про устройство Вселенной да да здесь вот мир физики и доброго атома отлично тебе тоже э-э тебе тоже супер подарок от от конференции Спасибо большое за выступление вот вам всем спасибо отлично Спасибо"
}