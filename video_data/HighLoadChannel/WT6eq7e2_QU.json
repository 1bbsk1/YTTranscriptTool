{
  "video_id": "WT6eq7e2_QU",
  "channel": "HighLoadChannel",
  "title": "Как организовать работу с метаданными для большого бизнеса / Алексей Еремихин (Badoo)",
  "views": 837,
  "duration": 2906,
  "published": "2020-04-14T11:16:00-07:00",
  "text": "доклад называется как организовать работу с метаданными для большого бизнеса и в собственно верны кто я вообще такой чтобы вам рассказывать об этом меня зовут алексей и риме хен и большую часть своей жизни я занимаюсь программированием то есть уже лет 20 и последние десять лет я работаю с данными для меня bigdata сначала было это что то такое что измеряется гигабайтами потом терабайтами вот при достижении 1 петабайт а множество становится несколько скучно потому что куча инструментов есть и про них постоянно рассказывают для меня bigdata это гораздо более интересная область за счет того что это не объемы данных их количества и разнообразия какие они бывают и как они между собой связаны я работу в крупной компании баду это самый большой сервис знакомств в мире ну для понимания что такой самый большой полмиллиарда человек полмиллиарда человек пользоваться сервисом у нас долгое время был только потом сейчас у нас есть больше приложений которые мы делаем и мы стали себя идентифицировать как группу компаний который называется magic club про объемы про то насколько компания крупная у нас три тысячи серверов которые находятся в двух дата-центрах у нас очень быстрые темпы разработки мы релизимся два раза в день мы запускаем 1000 pt100 в год ну примерно так вот когда каждый день запускается по 1 по 3 теста это много и над всеми компонентами над всем этим работает примерно 300 разработчиков вот те продукты которые я показал они работают не сами по себе они работают на мобильных приложений на мобильных устройствах на андроидах на весах работает на вебе и вот на этом слайде 10 галочек 11 наверное 11 галочек и это не просто 11 галочек это 11 различных каких-то истории потому что каждое приложение на каждой платформе имеет какую-то свою специфику потому что это конкретное приложение и конкретной платформы всегда накладывает какую-то специфику потому что платформы разные что такое мета-данные то о чем я буду говорить но если коротко то это данные о данных а полное определение вот такой вот страшные взята из википедии если я сначала прочитал его я не понял о чем она потом я когда другая подготовил доклад я понял 100 обо всем этом рассказываю то есть прочитав определение не понять что такое метаданные насколько они важны и нужны где мы встречаемся с метаданными но те кто работает с файлами знают о том что файл есть методом это время создания время изменения права доступа к этому файлу собственного пользователь которым принадлежит файл или группа в китеже в жире можно увидеть метаданные это кто поставил ticket кто будет работать на пике там кому этот ticket вообще нужен или например что это что блокирует этот тикет это все мета информация про этот ticket это не сути кита не то что надо сделать а просто какая-то справочная информация про этот ticket и я хочу вам рассказать как использование метаданных обеспечивает гибкость при постоянном развитии компании план доклада я хочу вам рассказать про две задача 1 задача гитель вторая задача о потоке событий я поделюсь теми проблемами с которыми мы столкнулись это как мы их решали и при чем тут метаданные первая задача будет задача у отель ну если попытаться описать что такое задача и цель то есть какой-то набор компонентов которые формируют собственно само приложение которое работает и есть люди которые хотят знать какую-то статистику аналитику по этому приложению они вот справа на слайде нарисован это менеджеры аналитики data science инженер машин leaning инструмента обычно как бы компоненты имеют какие-то собственные базы данных обычного лтп база данных от mais quel postgres но для того чтобы делать аналитику обычного лтп решения не подходят нужно какой специализированное решение это называется olap и вот тот слой который собирает данные отовсюду как-то их рекомбинируют загружает в аналитическую базу данных называется детей lim вот задача и цель это вот собрать данные отовсюду загрузить в аналитическую базу данных а дальше имя уже как-то будут пользоваться как выглядит например на процесс в лицах процесс как-то вот жизни это его разработчика вот у нас будут три котика один котик это разработчик компонента 2 котик это грубо говоря я разработчики тель и 3 котик это может быть менеджер это может быть аналитик и возникают у котиков разные вопросы о данных а какие выданные у нас забираете а можно было тут хотим сейчас система переделать и вынести какое-то поле в конфиг и там поменять тип столбца дропнуть столбец добавить столбец соответственно у аналитиков возникает вопрос а вот этот столбец вроде как есть у сущность а что вот 1 что оно означает все эти вопросы они как правило приходят на среднего котика и средний котик начинает грустить вот начинает грустить ну когда компания маленькая там 10 человек двадцать человек работает это все еще может там один котик справляться а когда компания растет и в компании уже 300 разработчиков уже как-то котиком посередине становится грустно и типичный результат если не достаточно оперативно реагировать на вопросы быстро развивающихся компонентов выглядят примерно вот так такая вот ошибочка которая случается в два часа ночи потому что загрузка данных для reporting а она ежедневно я бы данный курс утра должны быть готовой ошибка случилась ночью и соответственно это все надо как-то чинить почему так получается так получается потому что компоненты лежат в разных репозиториях то равно как и системой отель она тоже находится своем отдельном репозитории у компонентов у всех компонентов своих прав есть свой цикл release of кто-то релизиться два раза в день кто-то релизиться два раза в неделю кто то released раз в две недели по разному бывает новые фичи которые появляются компонентов а не как к 1 приводят тому что модель данных постоянно меняется и вот в результате получается вот такая штука что у детей вроде как выполняет задача по факту он непрозрачен люди вот котики слева и справа они друг другу поговорить не могут как-то решать ну конечно можно протестирует все вообще в сборе вот соберем сейчас вот там вот все наши десятки компонентов которые у нас есть все соберем и будем тестировать прежде чем что-то релизе но мы вспоминаем что у каждого компонента свои цикла релиза и торопиться ради других компонентов они и не очень будут любить соответствие протестировать все в сборе невозможно можно попробовать писать документацию как оно должно работать исследователь поднимите пожалуйста руки в зале кто любит писать документацию мне грустно я не люблю писать документации я люблю генерировать документацию об этом я буду рассказывать мы решили о том что мы хотим собрать метаданные что мы вообще хотим знать и оборудовать места где эти данные они будут не просто генерироваться или написано руками это будет коллаборативный работа и где люди могут приходить и уточнять данные сами что мы сделали мы сделали два решения одной назвали дата и 5 2 confluence веке ну конечно мы не придумали конфликтуете мы стали просто его использовать но я вам расскажу как про эти два компонента по очереди сначала начнем с датой 5 до 3 5 штук похоже надписи то есть какой-то интерфейс где можно прийти сказать по имени мне нужны какие-то данные технически будет это какое-то консольное приложение которое можно писать на любом диске и программирования физически она будет лежать на стороне компонента и быть частью компонента чуть больше технических данных данные передаем в csv на входе список столбцов и фильтра к который нужно применить чтобы загрузить только например инкрементальные последние данные на выходе еще дополнительно есть кроме данных есть сообщение об ошибках как я сказал нуб можно писать на любом языке программирования свой транспорт ssh если кому то интересно под после доклада подойдите расскажу ничего сложного нет работает отлично пример использования вот пример использования вот пример простого консольного приложения мы их все назвали дам пирами такой дата дампир ну как то вот очень хорошо сложилось соответственно название дампира определяет какие данные он вернет его указывается что нужно передать 3 что он должен вернуть три поля когда транзакция ну собственно dang dang называется инком блок дампир он может вернуть когда транзакция была создана каким пользователям его цена конечно же полный список атрибут в транзакции намного длиньше но на слабо это не влезло здесь же можно передать фильтр о том что я хочу только свежие данные начиная с какой-то дату по я не хочу забирать все данные за десятилетия и какие-то возможности сэмплирования вот посту дауд эта команда дополнительно это как консольное приложение это дампир может рассказать на каком физическом сервере на в какой физической таблицы на самом деле данные лежат откуда мы данные забрали а также описывать такой вот сущность как компонент это к какому компоненту данной относятся а пример дампира я уверен что видно хорошо но читать здесь особо много ничего здесь видно что дампир он являясь частью компонента использовать конфиге компонента используют константы компонента поэтому всякие переименования и все использования таблиц или все использования все вся работа с базой данных она находится на стороне компонента соответственно дампир также может рассказать какие поля он может вернуть а также в простеньком конце где можно сделать базу какие-то искали преобразования в результате того что мы вместо того чтобы лазить виску елями в чужие базы данных забирать и испытывать проблемы мы получили историю что у нас есть дата и 5 где по имени можно просто забрать данные надежно хорошо точно мета-данные про собственно данные то есть список столбцов они получаются уже автоматизированные а также метаданные про компонент можно начать генерировать документацию пример страницы confluence который у нас есть у нас для каждой таблицы в аналитической базе данных есть страничка страничка где написано как как часто загружается эти данные какими скриптами и посылочка можно получить детали есть описание что это за данные есть отдельно пока лодочное описание каждого столбца что он означает но фокус этой странице состоит в том что эту страницу редактирует или и роботы и люди робот создал эту страницу создал начальное наполнение поддерживает консистентную структуру таблицы все то что может сделать робот делает робот люди только приходят и дописывают описании на самом деле история заключается в том что разработчики не любят писать документацию в вики но они с радостью это сделаю частью какого-то компоненты будут держать в коде а когда придут аналитики аналитиком неудобно лезть в код и править документацию в коде и мб удобнее правитель документацию в вики поэтому так и получается то что разработчики правят в коде из-за них документацию делает робот аналитики редактируют вики и эта информация может быть использована в дальнейшем уже в разработке пример метаданных компонента указывается то что на каком физическом сервере в какой физической таблицы находятся данные но самое главное что зная компонент мы можем еще заодно показать а какие конкретно разработчики делают этот компонент и знают все детали о данных таблицы тут появляется возможность аналитика просто вот из документацию и найти разработчика собственно что получилось грушин котиком посередине грустный кот в середине создал два инструмента и сама удалился с этого слайда для того чтобы это сделать она вроде бы как создал два инструмента но два инструмента которые работают с метаданными в этой задаче метаданные они были довольно разнообразны это была структура таблицы и типы данных а также комментарий к этой таблице структура не то данные это люди разработчики аналитики и компонент которым относятся эти данные метаданные это то что понимает роботы может писать робот ими то данная это коллаборация как людей так и роботов ну на самом деле роботы как аватары разработчиков я закончил с первой задачи вторая задача она будет несколько иной называется поток событий многие наверняка про нее слышали как events стрим или клик stream и многие компании я знаю пытались ее сделайте испытывали множество проблем равно как и мы эти проблемы испытывали и нашли им решение как выглядит типичный цикл разработки продукта придумали новый функционал определили какими теперь этот функционал должен тратятся сделали логирование построили графики итак операция за это раз и придумываем но в новую пищу придумываем теперь сделали логирование построили графики и вот этого сделали логирование построили графики она повторяется из раза в раз как пример рассмотрим просто ключевую ключевой функционал наших продуктов это возможность проголосовать за пользователя собственно есть сердечко внизу есть крестик пользователь может проголосовать за или против кипя и но очевидно число голосов в разбивке но нарын по атрибутам по странам по полу пользователя по еще каким-то по возрасту пользователя ну естественно за какой-то период времени вроде бы данные понятные кажется что и разработчикам и менеджером и всем эти данные нужны но если посмотреть то выяснится что да им всем нужно число голосов но разработчику важно знать например разбивку по серверам на которых эти голоса были обработаны а также разработчику важно иметь инструменты для оперативного мониторинга чтобы понять что вот новый функционал выехал и графики не поехали то есть там через минуту график уже должен быть построен но еще может быть какая-то ретроспективы там на неделю назад или на более долгий срок если мы посмотрим мнение про этот кипя от менеджер продукта то мы обнаружим что менеджер продукта мало знать ну менеджер продукта не интересно знать на каком сервере обработалось это событие но важно знать в каких странах люди больше голосуют или меньше голосуют менеджер продукта интересно узнать а вот пользователь вот на экран то пол чтобы нажать сердечка или крестик или картинку влево-вправо спайк ну чтобы это сделать разработчики не интересно ну а также временной масштаб на котором менеджер продукта смотрят это как правило день неделя месяц год по минутные данные василь редко нужны менеджеру почему так происходит потому что разработчики как мы видели вроде бы данные разные данные схожие детализация разные и требование разные и в итоге получается что разработчики делают какие-то используют какие-то свои инструменты для того чтобы нарисовать графики посчитать соответственно собираю свою статистику а для менеджеров продуктов делаю другую статистику которая будет считаться медленнее там будет больше деталей и как правило есть такой вот дисбаланс когда разработчики не смотрят на бизнес на на те же самые бизнес показатели что и менеджер равно как и менеджер не понимает технический показатель разработчиков их разные области интересов и мы много и часто на порывы личную историю про то что есть какой-то компонент у вас есть какая-то статистика да есть у вас есть история да есть а приходишься смотрит что что ключевых показателей бизнеса по которым разбить в данных нет разработчики до для себя сделали про бизнес не подумали и мы стали решать вот эту задачу здесь дуализм пол здесь получается две проблемы проблемы того что разные данные данные для разработчиков и данные для бизнеса а также то что инструменты разные собрали хотелки мы решили что мы хотим единый лак всех событий со всех компонентов вот прям вот все что можно в него засунуть это сделать мы хотим построить с этого строго с этого logo строить графики как для разработчиков так и для бизнеса тогда получается что данные общие графики каждому нужно блюму интерфейсе хотим ускорить доступ к данным к историческим данным чтобы иметь возможность не просто смотреть уже агрегированные данные о миллионах события иметь возможность посмотреть что у нас две недели назад была в деталях также хотим и оперативный исторический reporting напоминаю функционал пользователь голосует да или нет делает клик или свайп вроде бы блок можно поместить такое событие но назвать его волк profile у него положить кто проголосовал за кого проголосовал информацию о том с какой платформе было сделано это действие этого боялся ли android что сделал пользователь стопу чтобы проголосовать он кликал или свой пол и на каком сервере отобрав это обработалось собственно первое у по она интересна и менеджеру и разработчику вторая группа она интересна только менеджеру а третья группа она интересна только разработчику она все отлично комбинируется второе тоже банально у нас в приложениях есть чат и событие называем send message кто написал сообщение кому написал сообщение с какой платформы может быть длина сообщение на каком сервере это обработалось мы посмотрев на два события и на прочие сопутствующие понимаем о том что у событий между собой есть общая атрибута это кто сделал действие с какой платформы на каком сервере это событие было обработано а также у каждого события есть какие-то специфичные конкретно для этого события атрибуты что это был за голос за кого голос информация или на при для стенд мессаджа эта длина сообщения и кому оно было отправлено попытаемся формализовать это описание собственно мы уже увидели что и событий у них есть какие-то атрибуты составим для начала справочнике в пронумеруем все платформы праны пронумеруем варианта голоса отзовем момента тоже засунув справочник просто для удобства получаем формируем какие-то общие структуры данных которые позволят как-то логически сгруппировать потому что логически сгруппировать атрибута например это будет будет информация про приложение где мы заложим информацию что это за платформа и какая версия приложения также информации пропал про пользователя какой был и какой был идентификатор пользователя и с какой стороны этот был пользователям объявим атрибуты которые будут вообще у всех ивентов вот такой вот пап папа всех ивентов родитель всех элементов то что событие она всегда происходит какое-то время у него будет какой-то идентификатор как он называется у него будет информация пользователя приложения о том сервер на котором оно обработалось потом объявим событие которые по сути являются наследниками ну не совсем наследование как в лоб и но принцип расширение атрибут то что голос голос и есть все атрибуты как у всех ивентов а также есть свои специфичные муссон мессаджа есть атрибуты как у всех ивентов также есть свои специфичные технически если сериале все реализовать от события в джейсоне будет выглядеть примерно так ну видно что это был голос пользователя из россии с android обработанный конкретным сервере пользователей пользователь проголосовал с и это удобно роботом это удобно для мы технической обработки что как отправлять события так как мы изначально формализовали структуру всех событий и знаем структуру событий мы можем сгенерировать sdk под разные языки программирования удобными для использования в компоненте здесь пример отправки события про голосование пользователя и спички для psp собственно чтобы отправить событий нужно написать четыре строчки кода отправлять события для разработчиков в итоге легко да есть такая прячет много магии под капотом но для бизнес разработки правка выглядят легко аналогичным образом для javascript а точно такое . точно такое же событие легко отправляется было много холивар of о том что передавать аргументы в конструкторе или делать саперы для атрибутов ну здесь наверное каждый у каждого в каждом компоненте есть какая-то своя культура разработки и можно генерировать sdk под компоненты в том виде как им это нравится главное чтобы это было просто после того как мы сделали sdk начали отправлять событие что можно делать событий как любые события можно отправить в очередь можно организовать подписку на эти события чтобы делать какие-то дополнительные автоматизации а также можно из общего потока событий выбрать какую-то часть и использовать для специфических задач естественно с потока событий можно посчитать агрегации срезы с этих агрегации срезов построить графики как оперативные так и исторически данные можно залить какую-нибудь базу данных какая вам нравится но как залить кажется что данные не совсем нормализованы но история в том что у вас есть в самом первом шаге мы формализовали структуру всех данных и мы можем сами определить как разложить эти данные в базе данных как это будет удобно аналогичный point про то чтобы залить это в ходу поимейте сколь доступ в хайвей престо но это не совсем база данных но рисковали доступа нефиг есть все зависит от конкретной задачи здесь я передаю общую идею сейчас я расскажу как мотивирует разработчиков правда заключается в том что когда ты приходишь к разработчикам и говоришь друзья вот вам sdk пожалуйте его из пожалуйста используйте его ну конечно же нет конечно же есть уже какие-то наработанные практики мы не хотим мы вот нам тут так удобно и для этого важно обеспечить чтобы новая sdk который вы им предлагаете он был удобнее чем старый чтобы вести статистику в новой системе было гораздо удобнее новая система должна давать новые возможности и решать проблемы старый соответственно система должна быть открыта к нужным разработчикам разработчики всегда будут придумывать какие-то технические менты которые еще не интересны бизнесу они будут интересны там может быть через полгода но в каждый момент времени это просто как правило есть какая-то техническая метрика и разработчики должны иметь возможность объявляйте свои события чтобы их отправлять об и строить графики получается что нужно построить такую под платформу обработки данных и да с точки зрения управления компанией нужно создать отдел который будет делать эту платформу естесно кто-то должен сделать эту работу но правда в том что у каждого компонента есть уже какая-то своя платформа с данными и они будут скорее всего рады поменьше поддерживают свою маленькую платформа пользоваться большое если она удобно и хорошо работает как выглядит пример события отправленного события объявленного разработчикам вот придумал разработчик что у него будет события hard бит написал на языке про табов как будет выглядеть это событие объявил какие-то дополнительные параметры по какие агрегации какие срезу ему хочется видеть после этого он отправил это событие и получил какой-то график ну здесь вот график ведет себя странно и я надеюсь что разработчик знает ну шутка конечно я рассказал разработчик что как-то график себя странно ведет но суть в том что вроде бы вот этот график он же не просто графика тоже данные данные которые есть и можно вернуться в прошлое и посмотреть прямо детали с каких серверов этих эти события были отправлены когда они были отправлены искать есть сырые данные чтобы разработчик мог работать очень интерактивная штука и интерактивность той точки зрения что графики строятся вот буквально там . появляется каждую минуту с другой стороны есть возможность получить полную сковали доступ к этим данным а что еще можно сделать а еще если вы сделаете это не просто событиями реестром событий ну такой бизнес реестр событий которые могут происходить в приложениях вы эти события можете презентовать к техническому заданию или к техническому описанию продукта то есть придумали какой-то новый функционал взяли перерисовали главную страницу сайта вот с иглой с игрой encounters где можно поставить голос за или нет и отправка событий она уже является частью описание функционала продукта то что получается линков к что мы знаем какие события из какого продукта из какого места продукты должны быть отправлены а также далеко в обратную сторону а что это событие означает и в каких случаях она отправляется есть еще интересный кейс когда поток данных общей имеет замечательный бонус про который мы изначально не подумали но получили это когда вы придумываете какой-то новый инструмент когда вы придумываете новый инструмент инструмент например поиск аномалий на временных рядах вот есть какой-то график он себя как-то вел в прошлом сегодня у него и случилось изменение в поведении хочется об этом знать рано правда в том что вы пробуете какие-то инструменты решайте одну конкретную задачу для какого-то конкретного события но после того как вы решили задачу для конкретного события на самом деле вас появилась возможность решить эту же задачу для всех событий в этом потоке вопрос только масштабирование соответственно в одном компоненте придумали что-то попробовали а дальше это легко масштабируется потому что поток событий является общим в этой задаче метаданных тьма это событие их атрибуты и реестр который мы сформировали с описанием событий метаданные эта привязка событий к техническим заданием и обратно метаданные это само описание событий соответственно получается событие для бизнеса которые сейчас используются в актуальном reporting хорошо описаны события разработчиков ну вы видели разработчики не люблю писать документацию мета-данные это то где и как eg и сколько хранятся события в какой базе данных и они хранятся и сколько ну нельзя же хранится быть ее вечно все все равно придется как бы принять решение о том что здесь мы храним две недели здесь мы храним год в зависимости от задачи вот я вам рассказал про две задачи про метаданные где мета-данные управление метаданными позволило нам не только описать данные и поделиться информация что это за данное это не просто данная данных это структура информация эта структура компании метаданные это инструмент когда люди внутри компании мог при помощи которого люди внутри компании могут взаимодействовать друг с другом мета-данные это просто получается ключ высокой гибкость развития продукта но если у вас в команде или в компании 10 человек в на вид наверное вам формальное описание данных не нужно если у вас количество людей в компании измеряется сотнями то метаданные просто основа того чтобы построить коммуникацию метаданные они не просто кому инструмент коммуникации это часть бизнес-процессов от как я показал что метаданные лин куются к техническому заданию или к описанию продукта требования продукта да они формирования метаданных стало просто частью бизнес-процесса когда мы на уровне метаданных заранее договорились о том что событие которых мы соберем будет достаточно чтобы в дальнейшем делать reporting метаданные это единый язык на котором говорят менеджеры разработчики и аналитики вот просто решается огромнейшее количество коммуникационных вопросов когда у вас есть один четкий термин одно четкое событие с описанием и все его однозначно понимают правильно в том языке в котором он привычно разработчику видят одним аналитика выведет другим но есть информация собранная как разработчик видит события в коде он понимает как когда кидается событий в коде аналитик не видит события в коде аналитик видят события в виде там функционала продукта таким образом метаданные это единый язык на котором могут говорить сотрудники вашей компании спасибо алексей спасибо за ваш доклад вы своим выступлением не сливк от проведение конференции и есть ли у зала вопросы 1 2 3 антон ленок jal разработчика сбербанком алексей большое спасибо за интересный доклад по ходу повествования у меня возник один вопрос терминологии можете объяснить что такое этель как это расшифровывается и цель это расшифровывается как экстер простите не рассказал тел это экстракт transform load и вот тот слайдик где я пытался его нарисовать это вот есть данные на стороне компонентов есть данные в аналитической какой-то базе данных вот и цель это то что делает экстракт из компонента делает transform чтобы сделать reporting и сделать лаут в аналитическую базу данных чтобы это сделать чтобы как бы это все заработало спасибо за доклад а вот такого праздника мы журнализм журнале ruim событие да все всем довольны и тут прилетает задача какая такая говорят нам нужна новая статистика да то есть мы же вроде все что можно но вот как-то какой-то параметр забыли да что мы же ради роли ровно то что нам нужно было для бизнес-целей а тут появилась какая то тут там критерии как эта метрика а там медведь узнать новое которая текущими данными не покрывается текущими событиями что как как решается проблема он это событие есть событие да это характеристика есть нам ее почему-то не журналирование вот стоит левитировать вообще все всегда без остановки до тогда наверное можно михель уже ни у кого не хватит даже на жестких дисках либо как-то вот как такие случаи при 2 предостеречь ну стой щас я понимаю вопрос у него на самом деле две такие поставьте 1 поставь это да когда вы вообще ничего не знаете даже не откуда это восстановить ноту по информации нет ну что поделать как бы информация ниоткуда не возьмется как бы тут решение нет но часто получается ситуация когда аналитики tumblr они не подумали что это будет полезно а разработчики для каких-то своих нужд блоге записали в них были эти лаги но так как эти логе они велись в общем в общем потоке данных аналитики имеет доступ к лагам разработчиков это все трансформируется единая система данных единой стрим событий короче пишите все что можно до сигарете логе писать должно быть удобнее чем куда-нибудь еще алексей спасибо за доклад и fila на нем сбербанк я завтра выступаю тоже на юбк очень похоже тему на работу с метаданными и вот мне очень понравился твой доклад и я хотел бы отметить что я рад что мы думаем об одном и том же направлении вплоть до вот формулировок а мой вопрос такой что если количество источников там уже даже не сотня может быть и 1000 и немного интеграции то вот например как решить задачу поиска нужных метаданных когда как вы ее решили когда мне нужно какие-то данными надергать из разных систем там витрин куя для машин линга или счет хочу собрать и вот метаданные хочу подергать с точки зрения хранилищ данных у нас есть дата lake в одном ходу у нас есть одна аналитическая база данных в которой все в которой есть собственно все события из этого logo в полной детализацией за последние 30 дней в агрегатах в зависимости от задач то есть мы не комбинируем несколько разных аналитических аналитических источников мы вот у нас есть до толик виде ходу поесть аналитическая база данных в которых который есть все да они просто открыв рискуя или клиенту увидев список таблиц в нем разобраться в даташите разобраться невозможно но для этого есть документация которую пишут и люди и роботы и позволяют делать связи геннадий сбербанк есть два вопроса если у нас много я ничего не могут затем они так вот два вопроса если не сложно вопрос первый по существу рассматривали ли вы альтернативы потому что вы назвали дата и то есть инструмента для того чтобы как-то изобразить схему данных как она выглядит что там лежит в принципе их есть сколько это вопрос изучали ли вы этот вопрос извиниться тавтология и 2 бонусный а как вы справились с табличками в конференцию они постоянно разбегаются как только ты в них данных немножко больше кладешь тем более если начинаешь много раз ее редактировать честно я не нашел секрет поэтому спрашиваю профессионал спасибо напомните пожалуйста первый вопрос я начал что в голове отвечать на 2 забыл про первый но ведь это про про второй расскажу с табличками в confluence и они не знают силу каких причин у нас никуда не разбегаются нас робот знает что 1 ст облиться на странице это то куда то что может редактировать робот люди знают что вот эти вот первые два столбца это то что редактирует робот ну и новой строки добавляет из старой удаляет тоже робот а все остальные поля вот как бы воля то есть есть как бы робот точно знает то что он может редактировать это первый блок с деталями правитель это первая табличка на странице в которой должна лежать структура а дальше в общем все остальное все остальные объекты на вики страницы можно редактировать как хочется человеку человеку альтернативы data api наверное нет не рассматривали потому что проект сама идея data api оно появилось много много лет назад и основой ее появление было то что мы хотим вытащить и сквозь запрос который лежит на стороне бей на сторону компонента чтобы сделать данные чтобы не было чтобы не детей лазил получается в чужую базу данных и этого использования компонент не видел чтобы кому компоненты был интерфейс которая дает данные а данные бывает не только в базах данных там вплоть до того что надо reflection нам пройтись по классику и собрать константа это тоже делай дампир спасибо большое за доклад и одни сбербанка банк . дмитрий меня такой вопрос вы рассказали очень красивую концепцию экстрактов данного еще говорили про transform лот что у вас в качестве метаданных именно на уровне трансформации происходят но например вот что-то на системах источниках поменялось и это влияет именно на бизнес-логику они на не на структура данных и трансформации которые работали они могут начинать собирать неправильно данные но и вообще в принципе как у вас метаданные на трансформации построены ну это наверное отчасти вопрос про качество данных то что ком компонент изменился изменил бизнес показателя вот в старой системе когда отель входит в базу данных компоненты и сами что то забирают у разработчиков компоненты есть возможность сказать о том что как бы но это что-то там убей щеки ходят вот они неправильно забирали а когда у тебя есть дата дампир у разработчика компонента просто есть возможность увидеть использование таблицей прежде чем менять суть он как бы все равно от гриппа и все использования этой таблице поймет как она используется да бывает так что в таблицу начинают писать какие-то дополнительные строки которые не вписываются в старую бизнес-логику но это же может разработчик компонентов простом консольном приложении дополнительно там вы сказали написать vr и и не забирать строки собственно за качество данных получается у разработчика компоненты появляется возможность отвечать за качество данных ну я понимаю скепсис по поводу того что она ему надо или она ему не надо скажите кто в вашей компании отвечают за качество вот если не разработчик спасибо за доклад очень интересно было послушать ваш доклад потому что я здесь увидел свою мечту it документы ichinose код но вопрос будет немножко не поэтому вас есть этапе который меняет структуры ну вас документация ведется и соответственно у вас и tl происходит таким образом что вытаскивает но структуры непосредственно из баз и трансформирует их как-то и кладет кладет вашу лап у меня такой вопрос а при преобразовании не ничего не ломается то есть у вас есть дата пиа и который с помощью которого можно управлять метаданными и когда разработчики постоянно меняет метаданные возникает какой-то хаос грубо говоря пользователю нужно всегда давать инструменты осторожностью и не получается ли такого что вас возникает в абсолютный хаос в ваших метаданных они меняются каждый день каждый день нужно менять какие-то агрегации или эти агрегации уже не нужны или их нельзя сделать к тому же еще и вопрос применения миграции на olap как бы с этим проблемой сталкивались как-то или как их решили проблему миграции в lab решаются по старинке командуют эль то что если появился новый столбец его просто добавляют в лапе просто когда это иль работает он знает текущую структуру данных вала переспрашивает именно те данные которые он ожидает у дампира разработчик компоненты не может поменять данные в хранилище данных но может предоставить сказать о том что вот у нас появились новые данные пожалуйста вот добавьте их себя в хранилище данных пожалуйста начните из обеды забирать и соответственно обратная ситуация когда разработчик дропнул столбец потому что с чел его ненужным забор данных от этого сломался это ситуация трансформируется по сути варнинг вопрос вот wording если какого-то столбца нет должно ли все останавливаться до ручного вмешательства это очень открытый вопрос как правило дропа еца столбцы который меньше всего использовать поэтому обычно вардинга осмотрен его с утра вполне достаточно у нас еще не было ни одного такого инцидента чтобы разработчик компонента дропнул столбец который активно используется вас не слышно к сожалению спасибо за хороший доклад частично мой вопрос перекрывает пару предыдущих относительно вот на каком этапе формируются те срезы о которых вы говорили что одним нужны там срезы по городам другим нужно по серверам часть мы выделили в общей да но система живет развивается дополняются постоянно вот и как я понимаю нужно постоянно следить за миграции данных вот в лапида то есть как у вас организуется когда бизнес решает что нужно еще какие-то данные добавлять вы добавляете и беком побелить вот этот организуется что не ломается я кажется понял ваш вопрос в моем докладе был две части одна была часть про задача вот классического е т р 2 было про поток событий пурпурно ну и взаимодействие между ними в принципе вот этот поток событий выступает для детей ли как еще один из источников данных как еще один источник данных откуда данные можно забирать ну то есть пула мы опрашиваем вот эти дата дата lauder или как ну а пиво через другую дверь две системы что здесь две системы одна система просто вот сбора данных и потока событий когда ку ку да да да и как правило новая атрибута добавляется добавляется новый ивент и делают снова и логирование эта система живет по своим правилам и таблицы для каждого события или соответственно одна таблица для всех событий она генерируется автоматически исходя из описания потока событий задача и цель эта задача сбора данных из кучи разных источников как внешних так и внутренних там только ручное объявление какие атрибуты будут и какой reporting будет точно не будет ли у вас проблемы с производительностью когда вы приходите в dota pit вот и пытаетесь собрать много данных из сервиса ну как вы боретесь с такими накладными расходами такие проблемы возникали его внедрения data api когда пришли на портале es que el запустили его в mais quel и мой сколь решил что план выполнения будет так таким и в силу каких-то причин начал делать его там например не очень оптимально да как бы в любом случае в базу данных компонента пойдет какой-то и сколь запрос она просто в случае когда мы ходим напрямую в базу у нас есть возможность сходить в реплику там на культа со специально созданы для глаз разработчик компонента может сказать слушать она суд реплика есть слушать avast дампир есть вы меняетесь . применяйте дампир он будет забирать из реплики также дополнительная нагрузка на боевое железо ну то есть на продакшн окружении aresa ну она есть но это управляется разработчики компоненты могут управлять этим это не какая-то внешняя система которая к ним приходит и без их ведома берет мне все эти интерфейсы под рукой хотят сделать реплику и собираюсь ненагруженной машины и отдавать не нагружены машина данные пожалуйста окей ты его тоже не подошло концу спасибо за ваши вопросы теперь я очередь ваше выбрать участника самым интересным по вашему мнению вопросам им подарить по ему подарок мне очень понравилось два вопроса вот откуда-то вот да вот помогут у ребята и сбербанка 1 я помню был второй а второй вопрос не понял хотите сюда тогда да"
}