{
  "video_id": "cQsSALJt80E",
  "channel": "HighLoadChannel",
  "title": "Бэкап в современной инфраструктуре / Антон Турецкий (Badoo)",
  "views": 2603,
  "duration": 3019,
  "published": "2020-04-14T10:47:03-07:00",
  "text": "итак всем привет меня зовут антон турецкий сегодня я расскажу вам про бэкап в современном france структуре и я все еще работаю в компании буду на данный момент не так давно компания буду стала входить в группу компаний magic лап и мы разрабатываем помимо буду еще несколько приложений приложение bumble которые известны в основном за рубежом приложение люмен это социальную сеть для знакомств для тех кому 50 и плюс так как речь сегодня пойдет про бэкап это давайте сначала я покажу вам то как выглядит наш backup цифрах что было понятно о чем вообще говорить итак на данный момент порядка более чем 4000 работ присутствует по баку апа в нашей системе наши стороны насчитывают суммарную на всех там площадках порядка полутора петабайт доступного места и в среднем порядка 40 терабайт час мы прокачиваем эти 100 руджес различных постов которые мы собственно бы каким но тема пор пока по достаточно скучно поэтому я не буду рассказывать в этот раз про себя расскажу выдуманную историю и в этой истории соответственно семена придуманы совпадения случайны и так наш главный герой админ по имени савелий савелий как и все админы наверное самом начале очень любил читать различные книжки по линуксу и рано или поздно он дошел до состояния когда он стал админом и так в докладе я расскажу о том как совелий нашёл работу и пошёл работать потом очень сильно удивился что на работе нужно еще и думать о прекрасные дружбе админы савелия с другом программистом как сами их как ставили все за бы копил и проверок написал и в конце савелий подержит поделится с вами советами и своей рабочей практики итак начнем историю с главного наверное выводок от как которому пришелся ели по итоги своей работы со всеми этими богатыми и так состояние любого быка по остается неизвестным до того как его попробует восстановить сомелье читала в книжках и всегда знал что для того чтобы начать делать бэкап необходимо как минимум три компонента нужны сначала данные которые собственно нужно будет бы копить нужно хранилище куда эти данные классе что монетном лежали что будет называться в конечном итоге бэкапом и нужен некий координатор который будет понимать откуда данные взять куда эти данные положить в какое время это лучше сделать и в общем организовать всю эту схему backup на начальном этапе инфраструктура савелия была классическая очень простенькая у него был один сервер баз данных у него была машинка с нагрузкой под frontend у него был некий backend все это выглядело по классике все было достаточно просто поэтому никаких сложностей звуковым у него в общем-то не возникло он брал просто каждую машину в отдельности все что на ней было сливал в хранилище и получался у него такой backup то есть зале целиком машину запихнули дальше время на месте не стоял а соответственно савелий узнал что существует такая штука как система управления конфигурациями томи всякие по 5 акции булычев и и прочее вот эта штука и тут до меня дошло что собственно штука классная надо использовать и в общем то большую часть жизненного цикла сервера она умеет поддерживать отдельно как мог бы капов поэтому он понял что бы копить дальше целиком всю машину уже смысла большого не имеет и он стал забирать просто какую-то частичку необходимых данных в backup всем остальным занимала систему управления конфигурациями проект развивался стартап или не стартап получился довольно успешно поэтому инфраструктура немножко подросла сервис frontend нами разрослись бы кантами то же самое появились какие-то связи связи каждого компонента с каждым связи внутри каждого из этих компонент самое интересное коснулась например баз данных у вас данных появилось какое-то сортирование у каждого шарда возможно появилась по одному или несколько слоев то есть получилось так что данные у нас расползлись и плюс ко всему помимо того что они расползлись по инфраструктуре получилось некое дублирование то есть данные одного шарда могут располагаться там на 5 600 хода на просто много поэтому совет и задумался и подумал о такой штуке чтобы копаем в принципе больше не нужны как бы данных много машина упала другой своих подниму с мастер его читаю все поедет дальше но работал савелий ни один в компании было достаточно много программистов и один из них программист по имени савелий он наверное был лучшим приятелями по имени аристофан он был лучшим приятелем савелия собственно и в какой то момент времени когда он работал над каким-то своим проектом он сжал ее выполнил некий деструктив с базой данных он взял и сделал просто дроп дроп этот соответственно уехал на мастера но савелий админ был есть хороший когда он устраивал репликацию нас не выйду за отставанием а собственно следил точнее ну не допускал соответственно как только друг приехал в мастера троп разъехалась по всем своего данных больше не осталось поэтому садили подумал о том что что же все таки такой backup для него и решил чтобы копыто неизменяемые данные на определенный четкий момент времени также он решил вывести некоторые свойства которым backup должен собственно отвечать что в его делать первое важное свойство заключается в том чтобы cup должен находиться в стороне и он не должен быть подвержен изменению к этому он пришел собственно после получения дроп от своего приятеля аристофан backup обязательно должен восстанавливатся и нужно всегда знать за какое время ты сможешь восстановить свой backup проблемы есть инфраструктура растет бэкапы делать все же как выясняется надо поэтому савелий решил обстоятельно подумать и над чем же ему пришлось подумать делему заключалась в том что как ему поступить дальше с быками по старинке бэкапить сервер целиком или же рассмотреть вариант отслеживания местоположения сервиса и бы копить делать бэкапы именно сервисные как я уже сказал они пользовались системы управления конфигурациями также у них в проекте присутствовала карта расположение сервисов карта расположения сервисов здесь может выступать что угодно это может быть как день это может быть консул это может быть одессе диета может быть связка всего этого вместе взятого у ребят это было поэтому грех не воспользоваться и собственно по итогам после того как залили попробовал собственно новый вариант он сделал определенные выводы о об этих двух подходах и так с точки зрения формирования бэкапы разницы большой нет мы в любом случае пользуемся точнее савелий в любом случае пользовался картой и определить ему backup то есть для того чтобы определить из карты какой сервер бак обители какой сервис book пить разницы большой нет но на момент когда возникало необходимости устанавливать эти самые данные сложности заключались следующем если происходил backup именно сервера то рядом с нужными ему данными лежали данные какого-то там 2 3 4 сервиса поэтому приходилось фильтровать глазами и доставать только нужны также происходили ситуации когда данные определенного сервиса с одного сервера с мигрировали на другой и приходилось в этом случае копаться с выяснением куда же они делись и какой сервер действительно нужен поэтому попробовал два варианта он пришел к выводу о том что все таки бэкапить с точки зрения с точки зрения имени гораздо удобнее именно сервис следующий момент который ставили собственно разрабатывая пока отметил для себя заключается в том что карта расположения сервисов это неотъемлемая часть системы бэкапов современно инфраструктуре помимо того что он бы копил сервис он догадывался что есть на каждом из сервер из серверов есть какой-то данных которые необходимо бы копить помимо всего прочего он для себя это определил достаточно то он решил что будет с каждой машины бэкапить потолок одессе обязательно все для всех пользователей и на всякий случай 1 сутки сохранять информацию от рулится разделов о том как там устроена м просто на случай если что-то где-то упадет эта информация для конкретного сервера понадобится итак вывод одной которого пришел савелий он звучал приблизительно так что современным бэкапом современную оркестрацию чтобы это не значило все шло хорошо бы к понастроили все прекрасно но тут в какой то момент времени аристофан приходит к савелию с очередной претензии и заявляет о том что backup мешает работе сервиса савелий немножко удивился этому но они решили вместе съесть поговорите с целью что-то и пришли к следующим договоренностям что бы к при своей работе его нужно ограничивать в плане потребления ресурсов про ресурсы если мы говорим то это будет диск сеть процессор память но также стояли решил проявить некую инициативу и использовать не только полный бэкап и а также сохранить возможность использовать инкрементальные бэкапы к такому решению пришел исходя из того что данные скажем так место на стороже в этом случае можно нет немножко сэкономить и ресурсы утилизации сети тоже можно собственно сэкономить гоняя чуть меньше трафика посети чем нужно но также он всегда подозревал что есть некий трейдов между full им incremental а мы за это вот за этим чередованием непосредственно очень внимательно всегда следил договоренностям они пришли некое лимитирование для бэкапов настроили и жили они собственно после этого долго и счастливо но как обычно появляется новая проблема которую необходимо решать заключалась она в том что в их уже большой инфраструктуре необходимо было содержать некую devil площадку которая являлась точной копии продакшен окружении но а крутилась на виртуальных машинах и проблема здесь заключается в том что devil это территория разработчика то есть это вотчина аристофана но при этом завели всегда понимал что watch вот это может и аристофана но рано или поздно за звуковым данных он скорее всего к нему придет поэтому нужно было выработать какое-то решение потому что же делать виртуальной машины и так решение было следующим раз в сутки савелий решил собирать из какой-то карты сервисов информацию о всех виртуальных машинах выкидывать из этого списка все машины с базами данных и дать возможность туристов она имеет некое воздействие над этими бы к маме преимущественно это касалось включение выключение определенных виртуалок из backup а потому как раз делел это его вот чего то соответственно только он может хорошо знать о том что что нужно бы копить а что можно совсем выкинуть и как бы держать за эту ответственность и так сложности с которыми садили столкнулся при бэкапе виртуальных машин заключались в том что нужно всегда следить в процессе когда ты делаешь когда он делал бы копирует выход виртуалке нужно следить за тем чтобы во первых не было какого-то текущего snapshot of в момент backup а во-вторых не оставлять snapshot после быка по на самой машине не трогать snapshot если вдруг аристофан его для каких-то своих нужд сделал ни в коем случае не удалять но сообщать аристофан о том что вдруг там у тебя есть какой-то snapshot может быть он тебе не нужен ты его потрешь и на мы продолжим делать бэкап на этой машине и так как савелий аристофана дал возможность порулить включением-выключением он savely также придумал некой оповещал q которая сообщала аристофан о том что машина в инфраструктуре уже нет запись идет там либо бы кабелей вы ник не бы к ней присутствует поэтому было бы неплохо за собой прибрать и так почему савелий не бык обед виртуалке с базами данных все на самом деле просто потому что савелий теперь всегда по умолчанию бы copied все инстанции с базами данных вообще везде просто по умолчанию потому что он помнит прекрасную историю про друг и так чем же собственно отличается backup базы данных от бэкапы простого сервиса потому что собственно базу данных тоже сервис и backup сервиса тоже backup сервис есть некая сложность была некая сложность у савелия который включал в том что очень часто на сервер базы данных data set настолько большой что сделать локально положить дампа потом его забрать уже в систему резервного копирования не было возможным случае для тех машин на которых сделает дампа локально положить возможность была он принял решение о том что он не будет все равно так делать потому что ему важно бэкапить собственно везде одинаково что мне была разница есть места нет места просто делали люди везде одинаковые так будет наверное потом проще и также он решил что он будет использовать pipe то есть он брал подключался к базе и собственно через там некий pipe некое удаленное хранилище данных сразу нариту сливал также разрабатывая свои решение по бэкапы баз данных савелий опять же решил что необходимо дайте несколько рычагов управления для аристофана потому как многие вещи в инфраструктуре аристофан возможно сдал знал хорошо и даже лучше он знал какая база более нагруженной в какой момент времени какую базу можно бы купить а какой нет поэтому он выделил три пункта которые как бы воздействовать на которого разрешил аристофан ну скажем так первый пункт это включать и выключать бы кампус сам по себе то есть можно было поставить какую-то галочку глаза просто не бы копить он дал ему возможность менять и добавлять и удалять какие-то параметры для утилита бэкапы и собственно меня расписание самого быка по к реализации savely подошел достаточно просто и в общем-то очевидно он раз какое-то время решил формировать список со всеми машинами с базами данных и делать приоритезация приоритезация формата сначала всегда бы капица мелкие базы потом и капица крупные сделано для того чтобы в процессе когда есть окно для backup & bass как можно большую часть сделать сначала длинные какие то работы по быка поставить уже напоследок чтобы они не вышли не мешали не держали в очереди все остальное выкапываем собственно запустил они договорились чтобы копы теперь сервисом не мешают и на этом все можно расходиться все работает но на самом деле не все совсем так дальше они вдвоем начали смотреть на то что же бывает в процессе бэкапов когда даже если имитирование что можно сделать лучше чтоб все было как то что все работал лучше скажем так первая проблема который он увидел посмотрев на графике заключалась в том что есть такие сервисы которые в процессе своей работы из памяти свои данные дампир на локальный диск и собственно периодически в это же время когда данные до конца приходит бы копы начинают эти данные забирать здесь на графике нарисован собственно то что то что у нас уходит в отрицательную сторону это запись дампа то что у нас зелеными линиями наверх это собственно приходит сам backup то есть они по времени пересекаются и помимо того что дисковая система здесь довольно сильно нагружает в этом случае мы еще они еще и получали не всегда консистентные нужный им backup поэтому поиграв с расписанием ребята пришли вот к таким графиком на этом графике уже видно то что собственно дамбу сервиса отдельно бэкап и отдельно никто никому не мешает все хорошо следующий момент который они отметили что необходимо обращать внимание на то как же ведет именно сам сервис по своим метрикам не влияет ли как-то негативно то когда приходит backup на то что сервис начинает отвечать нам сильно медленней следующие к чему пришел савелий некий вывод это то что за системой бэкапов нужно следить в таком близ как рилтайм а то есть бывают ситуации когда о чем-то необходимо узнать прям вот в тот момент когда это случилось что вы не выстраивать большие очереди чтобы не вылезать возможно за окно бэкапов чтобы понимать что достаточное количество места чтобы эти бэкапы прошли по расписанию нормально и все то есть все сделано все бы капица научились они выяснять все вот эти пересечения строить расписанию все отлично но завели спокойно спать не мог до момента пока у него не было уверенности в том что все что он за бы копил анод на самом деле нормальными то есть это можно как-то достать и что то с этим сделать как об этом узнать он для себя придумал достаточно простое решение он разработал такой так называемый чек-лист из четырех шагов каждый из этих шагов выполняется от состояния скажем так от набора действий от простого к сложному в случае если происходит скажем так нельзя поставить зеленую галочку на каком-то из шагов происходит откат на предыдущий и попытка этого устранение и так цепочка довольно простая она заключалась в том что проверяется статус проверяется цепочка проявляю проверяется восстановление происходит запуск непосредственно самого сервиса что имеется ввиду под проверка статуса здесь все просто и под статусом имеется ввиду то что в процессе выполнения боков задача проверяется в общем-то статусы и то есть backup завершился со статусом ok или произошла ошибка и получился error здесь понятно что делать если разбирается почему собственно почему error если эти идем к следующему шагу в нашем чек-листе следующий шаг называется проверка цепочки проверка цепочки достаточно легковесный шаг на самом деле он проверяет состояние на каждый момент времени необходимые для восстановления того или иного века по насколько насколько нужны для восстановления данные присутствуют на сервере хранения то есть просто проверяется что есть у нас какой то на какой то момент времени full потом цепочка incremental of живых и дата восстановления если как бы так то все хорошо если есть картинка с тем что либо нету фула но валяются одни incremental либо там есть фулл нов сидит в каком-то месте в чередовании incremental of произошел обрыв то это тоже проблема после этого происходит возврат на предыдущий шаг и в данном случае backup сервиса считается невалидным следующий третий шаг в чек-листе заключаются восстановление это уже достаточно тяжеловесных шаг потому как в случае восстановления данные непосредственно необходимо взять система хранит вылить их куда-то на нити сервер и на шаги в восстановлении проверяется помимо того что собственно ok не окей что данные в принципе можно скопировать хранилище куда-то положить и второй очень важный момент который выясняется на этапе заключается в том что нужно посмотреть на время то есть скажем так сколько условно терабайт в час прокачивается в случае восстановление из бекапа этот шаг важен для того чтобы всегда быть уверенным в том что те цифры которые ты называешь для восстановления не соответствуют действительности и если на шаге восстановление как бы верификации не укладывается в некий timeline будто нужно либо говорить о том что backup него летит либо сообщать о каком-то вардинге и говорить о том что надо пойти посмотреть что же там связки между сторону мы целевой машиной и последним шагом в цепочке заключается запуск непосредственно самого сервиса то есть получается так что у нас все было хорошо цепочка мы проверили данные мы установили по времени мы соответствуем нашим ожиданиям все прекрасно у нас лежат данные и нам нужно попробовать стартануть наш сервис на этих данных здесь все достаточно тривиально то есть мы сервис пытаемся поднять и тут уже он либо он запускается либо не запускается если случилась проблема на этапе запуска сервиса то это наверное самая большая проблема и копать надо куда-то глубже соответственно вот к следующему выводу приходит у нас савелий и убеждается очередной раз в том что недостаточно просто положить данные в backup а всегда нужно гарантировать их восстановление в своей рабочей практики савелий использовал форк бокалы под названием борис это прям был его выбор нему нравился хардкор поэтому он решил пойти вот по такому пути и из своей практики и поработав повозившись с этой системой он решил поделиться некими девятью практическими советами о которых дальше я вам расскажу итак первый совет заключается в том что имеет смысл использовать virtual чем же это такой скажем так больше наверное группировка утилит не какая-то конкретная здесь указана ссылка на ту который пользовался и пользуется савелий плюс использования ченджера заключается в том что если для разных пулов используется например один сторож что можно всегда описать я для примера говорю о том что есть у нас некий набор сервисов которые мы бы копьем в два пула один пу называется что-то там full второй был называется что-то там инкремента в этом случае можно всегда бы копить данные в оба пула и не переживать о том что пачка заданий ожидающих полный backup встанет на ожидание пока не закончится выкопай инкрементальные это довольно часто бывает нужным ещё один важный момент это когда идет набор backup задание и необходимо сделать restore случае отсутствие ченджера пришлось бы делать следующую пришлось выступать все бокам задания монтировать нужные кассеты для ristora и пытаться рис творится также использовать ченджера позволяет довольно просто делать процедуры там добавлении удалении кассет маркировки очистки транзита и прочего следующий совет заключается в том чтобы использовать блочное устройство как магазин то есть продолжаем рассматривать файловый backup как бы к полноценной ленточные библиотеки в случае использования различных блочных устройств для магазинов из плюсов получается следующий что можно строго ограничивать место под те или иные пулы можно их не зависим друг от друга это удалять добавлять делать ресайза добавлять них кассеты еще чтобы такое и важный момент что можно играться с параметром если это отдельное блочное устройство можно отдельно играться с параметром lady-fit это бывает важно в случае восстановления здесь конечно все зависит от того насколько у вас хватит на машине на которой это будет производиться памяти но в случае для восстановления это периодически достаточно сильно помогало savely еще немаловажный вопрос и собственно здесь на него савелий тоже дает некий совет заключается в том сколько же задание хранить на кассете потому как если представить ситуацию что у нас есть некий сторож у нас есть 5 10 сразу каких-то клиентов которые в один момент времени решили писаться в кассеты одного пола они придут на девайс начнут писать как бы каждый каждый свой кусочек то есть получается ситуация такая что сначала будет кусок 1 job а потом кусок 2 джова потом возможно опять кусок 1 джова потом 3 4 и скажем так вот такой разнобой кассеты в бариос подвержены в том числе фрагментации и на момент записи вот как бы запись вот такая она проблемой на самом деле не является так что это собственно файловый записи поршней но с проблемой столкнуться можно при восстановлении когда сторож демону придется для того чтобы получить нужный кусок данных вычитать помимо вот скажем так блоков которые принадлежат работе для восстановления учитывать еще все промежуточная которой она является откидывать за ненадобностью поэтому исходя из этого есть еще такой вариант как взять и написать уменьшенное количество job of на одну кассету на данном примере я показал о том что можно писать просто по одному учебу на кассету и самый замечательно что здесь получается в конечном итоге что когда backup завершается количество кассет и занятое место в общем-то совершенно одинаковы в случае вот такого подхода и случае вот такого подхода очередной совет отца реле которое говорит о том что в бариос в баку ли собственно параметров и крутилок очень много и крутить можно все что угодно но это вот такой минимум который он вывел для себя с чем имеет смысл поработать если нужна какая-то более тонкая настройка параметры которые относятся к максимуму воли джобс копируем джобс они в общем то как раз таки для настройки советы из предыдущего шага про то какое количество джона должно быть на кассете параметры которые касаются блок сайте файл союз влияют в общем-то и на вас на скорость записи самого быка по если это прям можно откуда-то линейно быстро читать и быстро писать все очень сильно зависит от той задачи которая решается но зачитывает параметр помогает если есть такая необходимость то что касается спал атрибуции spool дейта это в основном применительно не к файловым backup его все-таки клеточному bacopa но как он отметил это тоже собственно имеет смысл покрутить также проблема была в том что когда савелий собственно решил бы копить все базы просто по умолчанию берем и бы к ним возникла такая ситуация что раз мы бы к ним все по умолчанию то соответственно правила и на хранении у нас и у них получились собственно тоже одинаковыми но бывают такие ситуации когда данные хранить нужно либо больше либо меньше на меньше можно не обращать внимание как бы ну лежать больше да и хорошо вот если хранить нужно больше то с этим нужно что-то делать есть вариант завести еще бокам заданий и бы копить базы или там сервисы еще дополнительно в другие пол и но более верным здесь будет использование копи jobo который заберет то что уже лежит системе хранения положат куда то в сторону в другой пул и они будут там жить и столько времени сколько им нужно совет номер шесть от савелий заключался в том что если возникает такая ситуация когда вот необходимо забекапить какой-то кусок файловой системы а на ней там куча каких-то директории со в директории в под директориях там порядка тысячи и тысячи мелких файлов какие то возможны g пеги или что-то такое но привод их много много и он пришел к выводу о том что в этом случае простой вариант бэкапов файлового борисом не подходит потому как случае начала вычисления например того же энгри ментального джова файловый демон будет гораздо больше сидеть в процессе построения дерева того что же там изменилась и нужно за бы копить нежели произойдет с она заливка файлов вариантов здесь может быть масса здесь может быть вариант попробовать бы капец целым snapshot а мы сливаем есть на машине нередко бывает ситуацию что можно попробовать вариант быка по через да да и тот же pipe или в принципе рассмотреть вариант не бы каппель баре усама придумать какую-то другую систему которая будет куда то в сторону сливать вот эти вот необходимые файлики помимо того что савелий работал админом у него ясное дело были коллеги с которыми ему приходилось работать и он говорит о том что необходимо выработать некий внутренние договоренности того где же будут где и как будут располагаться те или иные настройки в самом борюсь и потому как те кто сварю сработал вакулы работал я думаю прекрасно знают о том что настройки там пула створа джека set within шины все остальное можно раскидать настолько в разных местах что собственно если придёт второй человек который мыслит несколько отлично от первого человека то искать он и там привносить путаницы только продолжат поэтому советы рекомендуют использовать некий практике именно договоренности о том где как бы где и в каких местах какие секции конфигов будут отмечаться также необходимо следить за со за самой базой борис следите за ней чтобы в базе не появлялись не существующие записи чтобы там было как можно меньше дублирующихся записей собственно чем там будет меньше всякой разной ерунды тем быстрее наверное будет происходить туда запись и запросы на различные select а также имеет смысл дополнительно используя озу смотреть за состоянием кассет потому как часто возникала ситуация когда до redemption кассет остается там всего лишь час но задача должны прийти сейчас если задачи придут сейчас они не смогут начать backup потому что час до окончания ретенция нужно знать нужно ждать в этом случае иногда не помешает взять и поставить там бурчишь преимущественно кассеты и сделать так чтобы в задании лишний час не висели важен последний совет который хотел бы дать solely и заключается в том что необходимо собирать как можно больше данных системы бэкапов собирать их как текстовый логе в какой-нибудь например ластик search так и остальные метрики можно в influx параметров кому что больше нравится собирать это для того чтобы строить различные метрики которые могут помочь ответить на кучу вопросов если вдруг они возникнут а случае построение пока мы не возникнут точно абсолютно вот наверное приблизительно такие графики можно строить собирая различные метрики данный график показывает о том как в течение какого-то отрезка времени разные пулы происходит запись здесь можно смотреть на пересечении хорошей терпели пересечении площади пересечения возможно появится если смотреть на больший диапазон появятся какие-то окна когда backup совсем не идет а где-то идет много работ поэтому их нужно поменять с собой местами также можно посмотреть на график о том что здесь кто-то пытался что-то историк и возможно как раз таки там где график идёт вверх и скорость увеличивается возможно как раз таки и потрогали параметры дохода или какой-то еще в данном случае да это изменение с помощью изменения со стандартного ледохода для блочного устройства можно посмотреть на график того какое количество данных там в течение поминутно по часам сливается в укаб систему также можно посмотреть в какие пул и в какое время количественно jobo заканчиваются опять же найти окна что ты подвинуть и сделать жизнь и работу бы копать чуточку лучше так доклад подходит концу и выводы к которым пришел со деле заключается в том что современная не современная инфраструктура бэкапы нужны всегда бэкапы безусловно важны одна из главных мыслей заключаются в том что возможность восстановление из бекапа зачастую важнее чем просто навык эти бэкапы делать не надо бояться экспериментировать и для таких консервативных utility потом бокалы боятся привязывают что-то сбоку с перепелку надо экспериментировать не надо бояться все будет хорошо ее рано или поздно все получится и стоит не забывать о том что в общем то необходим также backup база barrios потому как если потерять ее это все остальное большого смысла не имеет спасибо что сша теперь вы можете задавать вопросы свои есть ли кого-то доклада что-то говорилось еще про слово цех и про то что это бывает по разному казнить и пожалуйста этой темы цех я думаю что потянет в общем-то на целый отдельный доклад если про него начать говорить я в докладе упомянул применительно к бэкапом я как-то сказал о блочном устройстве магазине собственно зачастую этим блочные устройства наступает блок девайс со стороны до цифры то используется rbd есть участки где используются на самом деле на базе того же кластер а используется с 3 но это как раз таки это часто хватает больше когда я говорил о мелких файликах о том что это плохо через обычную то она собственно там есть вариант когда что-то льётся через s3 но преимущество да это попил этих больших пулов на rbd имидже монтирования их на там одну две три n-нное количество машин и backup уже через них есть как бы ты бы к пишу локально формально локально но у тебя это внешнее сторож то есть используется он так и собственно вида хитрая ли там достаточно сильным в том числе и блок девайс тоже рояле там достаточно сильно blog sites кассеты когда ты пишешь вот от он здесь по центру спасибо за доклад вопрос попадаете ли вы под регуляцию chedi при а если да то каким образом как вы хоть ситуации мы попадаем под регуляцию же димер почему такой вопрос то есть я не очень понимаю почему но вопрос о том что допустим у вас есть данные польстили выезжай покатали и потом после говорит что я хочу данное удалить вам нужно общение кого-то там интервал эти данные удалить собственного капитала согласно регуляции согласно регуляции да наверное так то есть я думаю что изначально когда такой запрос придет он придет скорее всего дня к нам как отдел эксплуатации он придет скорее всего там как минимум в отдел разработки ли тех кто может сказать где данные этого пользователя жили соответственно если придет сообщение о том что данные вот они лежат там-то и там-то в том-то сервисе они будут удалены сделать некий тренд ведь и не думаю что будет являться проблемой то есть на данный момент от реки например если у вас допустим говорят то же самое гейское сета и вниз данные вам нужно получается собственно какой-то кусок там вот и польстили данный удалить как бы в принципе как бы но технически очень сложно но я подошел подошёл бы к этому наверно так что если у нас на кассете есть помимо нужных данных еще какие-то данные я бы скопировал все остальное эту кассету это кассету шлаков translate скорее всего понятно удаление транзитом из бекапа отвечаю на ваш вопрос просто есть подход можно на самом деле кажется если любит данные у вас есть как бы шифровать ключами просто ключи выкидываете у каждого жителя свой отдельный ключ и просто выкладывать ключ у вас фактически есть короче скромный богат новый потом его не можете восстановить то что выключи выкинули возможно возможно но я думаю что это как раз таки на этот вопрос прощения отвечу же ну то есть возможно данный хранятся именно так я даже ну скажем так я не знаю в каком виде хранятся данные в дампе всех сервисов которые мы собственно бы к ним то есть мы видим некий там блок который мы просто забираем и я не уверен в том что там что-то лежит в общем открыто видео спасибо вопрос попроще про историю савелия строп тёплом до друг поблагодарить вас был кто аристофан аристофан был молодец вот здесь получается у нас две крайности да с одной стороны у нас отставание то есть ну тему бэкапов что насколько они актуальны и с другой стороны на сколько у нас есть запас времени чтобы оперативно это решить то есть вот есть я не слышал о таких решениях когда используют отложенные репликации то есть да там скажем на час не знаю встает и в течение часа можно решить эту проблему но из второй вопрос немного связаны с этим как вы обнаруживаете что у вас прилетели данные надо быстро бэкапы доставать спасибо отвечаю на первый вопрос я на самом деле ожидал подобного вопроса про настоящую репликацию здесь в общем-то идея можно неплохая но никто не дает гарантию о том что во первых ты всегда то есть условно ты знаешь что у тебя вот на этом участке машины есть отставания в час появится другая группа машинки отставания будет фиксированного два часа нет никакой гарантии о том что ты рано или поздно не забудешь о том что собственно у тебя есть всего лишь час этой на обеде в отпуске в самолете не важно где и ли там кто то кто-то где-то как-то но он не может присутствовать и починить второй собственно пункт отвечаю на первый вопрос заключается во втором вопросе который ты задаешь который горит о том когда понимаешь как бы данных уже нет вот случае когда у тебя такой некий bk подстава отстающим своего очень велика вероятность того что ты чуть позже поймешь о том что с данными беда чем дойдешь до момента когда у тебя отстающий своих все-таки догонят мастера вот и решение о том что с данными что-то не так зачастую все-таки спускаются в эксплуатацию больше от группы разработки которые говорят о том что вот чего ты где-то не хватает что-то где-то случилась есть кейсы когда падает например база она падает условно физически оно упало что-то покрасилось на ней не было живой реплики в этом случае придется устанавливать из бекапа на 99 наверное процентах случаях вот такого физического падения решаются просто вот там дублирование и становится мастером и все хорошо то есть утрату данных информации о том что данные утраченный придет откуда-то с внешнего дело будет сказано что это так их начнут устанавливать антон спасибо за доклад вопрос зачем савелий разделил задание дамба и bacopa и стал вынужден поддерживать несколько расписаний пересекающихся как-то управлять этим зачем какой профит еще раз задание дампа и быка по да он на данный момент когда они вместе с аристофан нам садились и начинали из изобретать расписание не перекрывающие друг друга зачем зачем них отдельно идет дам а потом в какой момент времени начинается пока по этого дома имеется ввиду да где я говорил есть некий и статичный там не статична динамичный сервис который работает в основном там своей памяти 1 какое-то время этот сервис на всякий случай свои данные свои данные у соответственно dumped в локальный диск то есть чтобы если что-то произойдет подняться с диска и дальше продолжит работать в памяти вот ситуация когда сервис начал д'ампеццо приходит system backup и говорит я хочу сделать incremental и дай-ка мне вот то что у тебя там новое появилось и сложность здесь заключается в том что во первых она достаточно бесполезна начинает что-то забирать потому что по факту дампа еще нет он просто пишется во вторых на диск на диске появляется дополнительная нагрузка который заключается в том что на диск помимо того что пишут здесь клещей хотят читать и как бы в этом нет большой необходимости поэтому пришли к выводу о том что для приличной части сервисов которые вот так добиться более правильным будет является подход когда сервису дается возможность дойти и завершить свой дам после чего уже нужные данные забрать практически будучи уверенным что вот там вот этого часа будет выкатит скажем так вот этого час то есть это напрямую не взаимосвязанные процессы это двадцать два разных процесса только seo сервисы и system backup а сейчас микрофон дадут антон так изменить секунд спасибо за доклад ами вопрос такой вот аристофан все савелий все зубы копил установил и запустил что данные порядке он как может проверить там знаешь помощи его аристофана того же тут есть некая сложность которая говорит о том что да вот я абстрактный нарисовал картинку что он восстановил там будь то мускул будь то сервис будет что-то еще случай если эта база процедура получается следующий данные выливаются incremental и накладываются после этого запускается test of incense майский ли он подключается своем к текущему мастеру пытается догнать текущего мастера за какой-то период времени в идеальной ситуации он собственно твой мастер разгоняет догоняет потом происходит некий добытчик сам который проверяет этим занимаются ребята из команды я прям в деталях не скажу что в чем заключается этот чек сам которой они гоняют на собственно после на последней операции для мы искали происходит сравнение возможны каких-то хэши и вывод о том что данные там действительно валидный случае сервиса у нас есть достаточно большое количество внутренних сервисов со своей логикой со своими форматами snapshot of дампов и всего остального и мы со своей стороны можем проверить только то что мы данный сервис у дали старт ему сказали он поднялся и выписал я в себя там грузил столько-то столько-то а дальше уже как бы то есть скажем так наша верификация на этом участке она собственно заканчивается дальше можно на городить огород и посмотреть мы точно знаем срез когда мы делали backup у нас есть систем мониторинга который знает условно сколько там в текущий час в этом деле не было там пользователь или кого-то ещё столько уже их там или нет но преимущественно думаю что это опять же такое восстановление она уедет к разработчику сервиса ему скажут о том что посмотри пожалуйста вот мы тебе установили оно поднялось всё ли там в порядке можно можно вот приехали вот вызвали у меня два вопроса на чем больше был на 21 мне просто интересно вы везде говорить что вы сначала снимаете дамп а потом его бока вы забираете летом а вас хоть где-нибудь используется прямая запись по сети не создавая дам то есть берете пишет и и все пошло либо по из казино как угодно то есть посетить секундочку да я про это говорил когда я говорил о том что есть разница в бэкапе базой и в бэкапе файловом собственно случае пока по базам мы очень часто используем pipe и данные прямо напрямую с базы которые есть мы бьем по трубе куда-то еще случаи когда я приводил в пример что плохо бэкапить мелкие файлики когда их очень много в этом варианте тоже можно рассмотреть вариант такого удаленного внешнего сразу копирование будь то там году или иным snapshot как который делается уезжает посети например но случилось выманит случае да да да вот и второй вопрос будет мы просто интересно а как часто вы восстанавливаете если у вас это касается баз данных в том числе там fooling вот-вот каждый инкремента быть останавливать этим всем понял а если у вас идет backup допустим база данных вы делаете там fools каким-то шагам дороге инкремент делать с каждым шагом по после каждого incremental и будете восстанавливать делать проверять там дар чистота вот что-то японию rowe стандартные расписание у нас следующую мы раз в неделю делаем full условно там субботу или воскресенье в самый пик мы делаем full всех баз прям полный backup далее начиная с следующий следующего дня после full и делается всю неделю incremental для каждой база данных когда приходит verify катар у нас есть договоренность о том что в течение окна в неделю мы для каждой базы проверим ее как бы валидности валидность бэкапы для нее на тот момент когда придет verify катар то есть условный рифе катар приходит рассудке делает выборку скажем так 10 каких-то рандомных баз и на момент когда он пришел он проверяет всю их цепочку то есть вот там от воскресного фула да там сегодня если среда значит он проверит с воскресенья по среду все лишнее хорошо случае когда мы уходим в пятницу например ли секатор понимает что у него осталось непроверенных там условно 5 бас он сливает их и восстанавливает их до пятницы ну суть вопроса в чем ну допустим вы сняли раз но 1 недели full нас тоже раз модель поснимать там осудит инкремент он пошел если вы понимаете что с цепочки в середине недели коммент умер вы об этом узнаете когда когда вас пришел этот verify катар или раньше знание то я выдаю знаю на самом деле я об этом узнаю из стой проверки который занимается на втором шаге я говорил когда про проверку цепочки повести как это который достаточно дешевые которой проверяется преимущество через базу если там увижу что произошел либо вообще файл бэкапа инструментального либо какая-то битность то есть я не смогу проверить середине недели целостность данных если я не буду делать восстановление этого я не проверяю то есть как бы в этом случае мы будем считать до что backup возможно будет невалидным то есть таком случае если вопрос был именно про восстановление то нет будете делать если у вас лента по бьется если лента об этом сразу не узнаете вы узнаете когда будете разматывать я об этом нет во первых у нас ленты присутствует но она такая достаточно то есть лента у нас это типа есть горячие данные холодные данные вот случай ленты это там четвёртой итерации куда данные поедут просто чтобы они там были на данный момент с ленты есть попытка восстановления падал нас уезжает достаточно жирные штуки совсем то есть это среза среза кучу дампов и там проверка происходит что-то из серии 1 несколько по моему раз в две недели и эта проверка бежит порядка чуть ли не неделю она идет то есть там данные оттуда точно также достаются на них пытается подняться товаре но и сервисы появляются сообщения о том что плохо или неплохо то есть ситуации с тем что невозможно прочитать кассеты несколько нас там случались в этом случае соответственно появляется сообщение о том что данные там утрачены если их можно с предыдущего шага с файл бэкапа залить туда еще раз то как бы да если я не помню ситуацию что был так что типа данные там утраченное среднем стороны их уже нет не совсем нет константин как у вас организована песочница для проверки даже поднять сервис для того чтобы корректно его проверить это зачастую нетривиальные занятия особенно если он там обладает q там кучу внешних атрибутов как его поднять что он никому не помешал собственно где вы его подымаете как-то автоматизировано вручную и так далее нет но это все не вручную точно абсолютно то есть большая часть сервисов она поднимается и серии данные скопировались следующий шаг но есть некие там условно назовем его скрипт который дождался завершения работы атп отрапортовал проблеме со временем все хорошо значит он приходит на машину и пытается сделать запуск если это касается мой склеили и попытки поднять свои в то маловероятно что что-то сломает здесь ребята степей по моему держит скажем так есть у них типы баз разделенные на условно там три пункта ну что 3 серии там small medium и большой какой-то instance соответственно такие джогу тоже выливаются на машины где такую базу по той же памяти можно поднять его нельзя своих запускаются насколько я знаю в автоматическом режиме если запустился все хорошо если не запустился плохо по поводу сервисов те сервисы дампы которых бы капец они в общем то скажем так сервисы неактивные то есть это сервис который поднял данный прочитал вам себе их содержит он не будет на основании этих данных которые есть в нем сообщать во внешние источники о том что я вот такой новый во мне кучу данных сделай с ними что-нибудь то есть сервис поднимет данный прочитает начнут держать их памяти и будет сдать внешних обращений которые придут и спросят чувак типа как то у тебя вообще есть что-то или нет спасибо всем за вопросы продолжите просто дискуссионные зоне выберите пожалуйста лучше вопрос не против вопрос понравился вот здесь у него могут есть поднимется человек вам приз его вам антон тоже при спасибо за выступление спасибо"
}