{
  "video_id": "0bI4nY9UUyw",
  "channel": "HighLoadChannel",
  "title": "DropFaaS. Представляя функции как сервис / Анатолий Макаров",
  "views": 401,
  "duration": 2877,
  "published": "2020-04-27T12:10:55-07:00",
  "text": "всем привет натали и я увлекаюсь распределенными числе ними и принципе все что с этим связанно и увлечение это не появилось само собой стала ответная реакция на те проекты задачи которые приходилось решать и тем более которые мы испытывали с этим коротко о том чем сегодня поговорим мы погорим изначально давайте познакомимся я более 12 лет занимаюсь архитектурой разработкой у часто в разных секторах разработки это банковский сектор гос сектор консалтинг несколько инфраструктурных проектов немного open source чем мы сегодня поговорим поговорим о нашем пути к бисерные архитектуре о тех задачу которого решали и тех проблем которые возникали мы с этим поговорим о архитектурных решениях которые есть на рынке и причинах почему мы решили в итоге идти своим путём и начали делать свое решение посмотрим например написанием и чувствительные функции и в принципе оценим подход и побочные эффекты которые дает такой подход ну и наша платформа в частности итак поговорим о задаче на вот этом слайде я пытался изобразить основные вехи и концепта до задача с которой вот приходить пришлось столкнуться проект я влился где-то года три назад и первое это работа с данными да то есть у нас есть некие некий как бы стратегии то есть данный имеет потоковую природа у нас есть большая распределенная система регионального уровня причем в каждом регионе есть несколько систем на самом деле и знание о сущностях в одной сущности хранится в детских системах опять же сама задача имеет саги дедлайн и задача по анализу этих данных она имеет жестко определенный срок ну к этому сроку бизнес либо принимает решение либо не принимать решение то есть он ожидает некий выльем если говорить о задачей и его и и количественном писания дата можно описать следующим образом это порядка 200 миллионов объектов сущностей как я и говорил у каждой сущности есть порядка десяти подчиненных сущностей и каждая из этих сущностей имеет достаточно глубокую историчность и общий объем данных именно которые приходится обрабатывать то есть данный всей системы они намного больше мы говорим о количестве попеременно 200 терабайт данных это именно те данные еще раз замечу которые непосредственно участвуют в обработке какова же была изначальная система было некое хранилище объектов это реляционная база данных oracle в нескольких таблицах хранятся знания в объектах на самом деле было ни одна база данных а их было несколько говоря базе данных мы говорим о совершенно двух разных системах принципе то есть они логически содержит один логический это один один и тот же объект данных но система абсолютно разные они у них разные схемы разные таблицы данные по-разному нормализованный хранятся вообще по-разному также часть мета информации об объектах хранится в внешних сервисов которые тоже должны участок в обработке также есть с 3 хранилище в которых хранятся разные бинарные документы это скан копии документов фотографии такого рода информации опять же я изначально сказал что сам подход работает сам бизнес процесс он имеет немного потоковую такую природу то есть у нас со всеми этими объектами каждый день совершают сальники и действия эти действия приводят к изменению текущих от и создаются новые задача классический состоит следующем достать эти объекты и по определенному алгоритму алгоритма это некая цепочка до каких-то действий это вытащить нормализовать с джой нить смешать и вот такого рода и в конечном итоге загрузить их в исходную целевую систем ну то есть кажется задача достаточно простой по сути это некий это и льда процесс выгрузить данные проистекают эту информацию узкая сложную и загружать исходный не забываем что это за сама система она распределена в принципе по низким регионом и задача еще скупляется тем что несколько регионов конфликтуют между собой тоже по одним и тем же объект то есть у них знаниях и приходится решать конфликты на уровне принципе всей системы мы говорим что таких регионов локациях они распределены их достаточно много но по факту это каждый регион нашей страны и в конечном итоге весь этот фрейм нужно тоже определенным образом обрабатывать для этого есть там набор алгоритм что же такое эта обработка когда я говорю об обработке что я под этим подразумеваю ну какие сказал обработка это некие процессы которые производят некую некую работу говорят там допустим про извлечение данных да мы говорим не просто про извлечение то есть на тот момент были написаны куски кода которые помимо извлечения делились делали еще определенный бизнес-логику и также на каждом этапе то есть есть валидация трансформация данных joint в частности есть процесса подписания определенных цепочек объект побочных эффектов и в конечном итоге загрузка их целевую систему и тут мы говорим что это некий pipeline то есть у нас побочные эффекты от них процессов являются входными данными для других процессов и вообще вся эта цепочка однозначно развесистая и ну как мы и говорили что такие цепочки существует как в рамках одной локации так и глобально на в сондо там фейн поговорим об архитектуре для которая на тот момент была то есть это классически была очередь были процесса являющиеся обработчики в этих событий и были входные выхода системы входных выходных очередей но мы говорим что этих обработчиков было много они были на разных языках написаны начинают низкоуровневых сей заканчивая вас ковровым питонам и все они имели ну как бы такое же устройство то есть были входные выходные очереди обработчики подключались также я говорил что есть выделенные части инфраструктуры для общих сервисов как помимо части обработки так и в принципе экосистемы это например следовать подписание выше данных и другие их было достаточно много и часть функций она также обращалась за данными и за обработкой как этим сервисом и вообще там говорил что да у нас определенной системы по сути под каждого локаций у нас были свои системы очередей и опять же включающий себя там массив обработчиков достаточно большой кластер порядка 250 машин и каждый которой есть определенная система и ты конфигурации какие проблемы данных и мы испытывали мы говорим о еще раз напоминаю что мы говорим о неком до 2 ним большом количестве данных и оперативном подходе работе с данными и к потоковой природе получал следующим у нас так как мы заведомо не знали характера прихода данных то есть ночью допустим могли прийти часть кусок большой данных от одного региона да и он нагружал в принципе вот эту систему очередей кластер который выделен был специально нарезан передка фигурировал над каждый регион а другие части очередей обработчиков они могли простаивать или загружать только другие части задачи и по факту эти общая утилизация вообще всей этой системы она была достаточно низкая достаточно низкая на большую почему потому что у нас есть выделенные узлы виде очередей и выделены участки архитектур сервисов соответственно они периодически падали выключая принципе из работы все все эти обработчики дайте сервера которые были подписаны на обработку эти очереди также с выделенными участками ну то есть эти сервисы с баллончиком классический даст балансировщик am and not под него то есть соответственно выпадания балансировщика губит на принципе всю дальнейшую обработку да еще раз поговорим о последствиях это не эффективное использование ресурсов это простое с выпадением выгодных узлов не был авто скиллинга ну то есть хотелось чтобы не при конфигурировать до нас были часть системы было автоматизировано но в любом случае нужно было вмешательство человека для того чтобы перед перри балансировать нагрузку и те брокера до которые подключились на очереди это было неэффективно поэтому говорил что of the screen для нету медленный транспорт еще раз замечу что цепочки достаточного месяце и принципе этих обработчиков очень много и система входящих у тещи во входящих и выходящих очередей она достаточно большая отсюда узкое место здесь сразу явно больше цикл очереди скорость была достаточно низкой ну как я сказал ручное управление принципе общее сложность системы то есть для того чтобы дальнейшем масштабировать сопровождать и вообще какое там делом управлять нужно было дополнительно писать еще один структурный код это был очень сложным и в конечном счете неэффективным и тут мы начали думать вообще как принципе могла решаться такая задача и вообще вот наше видение видение проблемы да и поиски вот этих решений они нас стали приводить тому что нам нужен был свой аналог для bada ну надо нужна своя серверная архитектура давайте поговорим немножко войдем в контекст и как бы определимся с определениями что же такое сервер лес итоге сейчас если смотреть в интернет очень много описаний картинок на самом деле вот лично для меня ясности очень мало ну то есть мы что же это такое и тут не очень понравился так вот тело see how to is the google адвокат девелопер из их облачной платформы он как-то выступал с докладом и вот его обоснование мне очень понравилась идея следующем то есть он задавал этот вопрос людям с такой сервер лес все обычно вспоминают о двух вещах и говорят ну эта функция этого не некие события но по факту это ответ на то как происходит в облаке доработать и рвался то есть есть функция они подписаны на события какие-то триггеры и не обрабатываются событием и по факту функция отвечает на вопрос как нам что-то сделать событие когда нам это что то сделать но основной это вопрос зачем зачем нам менять там текущей подход текущая из титул зачем нам нужно именно этот подход для чего и ответ тут конечно данные в принципе сейчас все создает данным генерит данным и обработка и последующая обработка этих данных она тоже создает данные которые опять же дальше передаются на обработку и то есть мы говорим что данная очень важно показатели и еще один еще одна важная очень мысль это что наши данные наших системах они переходят знания из ценность какую-то только путем их обработки и соответственно для того чтобы бизнеса получать большую ценность извлечения извлекает извлечения данных нужно больше обрабатывать и собственно задачи авто скиллинга масштабирования на кластере уплотнение вычисления не вот как никогда ставит вас в полный рост и какие решения вот когда мы начинали смотреть эти решения на тот момент и было достаточно мало мы сейчас говорим открытых до решениях то есть до было ли это были google functions но так как у нас задача вам премия заказчик со своим ходом мы не могли их использовать были решения на самом деле либо немного они все были достаточно сыром виде и классических можно было разделить на два типа на самом деле это те решения которые использовали кластерные возможности кубер не tissot и решение которые шли своим путём какапо через к примеру но там внизу те же очереди оля кафка то что у нас по сути под ну практически в такой по или там вроде было мы начали смотреть анализировать думать все ну как использовать перед от себя доработать их конечном итоге мы поняли что они нам не подходят любом случае почему я не подходит ну первое то собственно чего мы хотели мы хотели повысить надежность большой системы в принципе поэтому нужно отказываться от водяных узлов нужен частный мастер мастер классе до второй очень важный момент это способ передачи сообщений ну как я и говорил что у нас очень много цепочки достаточно развесистые их очень много и скорость передачи сообщений очень критично причем хотелось управлять транспортным про таком но на уровне платформы то есть там где нам нужна большая скорость но меньшая надежность мы могли бы допустим переключаться следующий очень важный момент специфичный runtime бы у нас было очень много кода написано на разных языках и то есть там порядка 100 обработчиков стек очень разнообразны и мы не могли ну то есть затраты на переписывание в какую-то нотацию ли стиль но они были бы очень большими 2 эта скорость работы требования к ресурсам но и общая сложность то есть мы в принципе проводили сравнение с решением которые у нас были с теми решению его под соснами нато момент которые были как бы скоростью не очень-то впечатлял итак мы говорим что мы начали свое решение нам хорошенько подумали об этом мы поняли что без этого наверно никак во-первых дизайн да мы говорим о том что мы отказываемся от водяных узлов для того чтобы увеличить надежную систему второе транспорт мне вот всегда очень нравился подход unix когда сложные вещи делаются на боевом простых и вообще в принципе и люксовый pipe он как бы берет на себя до зону ответственности транспорта то есть мы пишем простая обработку пишутся они достаточно просто сама эта абстракция решает за нас сам транспорт и мы можем создавать создавать вот этот поток вычислений достаточно просто хотелось такого же естественно нам нужно были от абстракции для того чтобы управлять этими цепочками функций не привязываясь каким-то компонентом системы и вот здесь очень модель акторов очень хорошо ложится на такие задачи то есть есть некие акторы да то есть и у них есть почтовый ящик соответственно сами актеры могут обмениваться сообщениями синхронно и асинхронно это получается своего рода такой распределенный pops up то есть мы можем одним актером подписаться на другой передавать сообщение в таком стиле вот здесь прозрачное вот эта модель она очень хорошо жевать в итоге какое решением естественно нам нужно нудного вне изоляции этих функций докер как бы решал все проблемы в принципе то есть на уровне одного экземпляра этим управляли памяти и циклу то есть все это он очень хорошо решал мы его перес пользовали дальше когда вот мы начали рассуждать о модели актеров прозрачности сети скорости передачи скорости работы с сетью и в принципе базовых пластиковых возможностях прозрачности до и акторов те же то есть тут сразу на ум приходит и ранг то есть тут можно его рассматривать как операционную систему второго уровня до для построения и у него есть абстракции мы мы можем строить достаточно сложные большие системы которые распределены на кластере мы получали с уильямом туда то есть в принципе оценив масштаб действий мы поняли что по сути большая часть кода с очень сложного у нас уже есть и нам нужно только собрать вот эти кубики какие абстракции у нас родились на уровне общей платформы ну то есть мы говорим о функции функция по сути это просто вычислительный процесс в качестве протоколы передачи данных мы решили пойти самым простым путем мы используем просто файловые дескрипторы ввода-вывода и ошибок для лоббирования и здесь вроде как бы все просто то есть любой любой процесс в принципе да не важно на каком языке мы можем завернуть такую конвенцию и работать с ним как вот собственно с процессом далее дальше это некий вычислительный пол что это такое вычислительный пол имеет определенные характеристики это на самом деле группа функций состоящий как минимум за 1 и и есть название которое прозрачно видно давно всем кластере у нее есть разные метрики типа лимитов таймаутов она несет в себе эту информацию о количестве от текущих бургеров функции количество работы которые не выполняет и еще она делает ну то есть мы подписываемся на пол и если функциях допустим падают они не сообщают никаких причин ошибок по от имени этих функций самых создает сообщение и бросает их в принципе возле систему тем самым мы можем ну то есть мы управляем разного рода сообщениям не только бизнеса вы но и системными все эти пу они распределены на класть и на нотах причем хочу заметить что у нас есть системная так называемую функции до которая слушает событие операционной системы слушать события кластера сети есть пути по планировщика который подписан на эти полу распределенного принимают эту информацию в себя и делать какие-то выводы отправляют события в следующий функцию пул которое создает допустим экземпляры и создает новые полы есть где так называемый flow все такое flow это некая декларация функция или некий сценарий то есть декларация все понятно мы david планируем функцию и на кластере она создается с определенными параметрами видом имя есть название до образ образ которым завернуты все dependence и и все зависимости runtime принципе нужно для выполнения этой функции и есть ну некое аргументы запускай ну здесь допустим командная строка этими переменами на самом деле этих параметрах больше то есть там есть лимиты памяти лимиты по циклу все заметить есть лет количество лет количество функций этим управляют собственно сама платформа то есть я разработчик не заботятся до количестве инстансов он просто декларируют некую действительную функцию и говорит что я хочу чтобы меня эта функция была я работала с приходом нагрузки пускай она там как вы доске лица этих флуда они могут быть сложными достаточно сложными как мы говорим что есть на так называемый распределенная подписка вот здесь выделена что в принципе вот функция а вот дубли кейт она подписана на функцию валидатор из подписка степень подписки тоже бывают разные то есть у нас есть подписка локальная подписка распределенная подписка при определенной функции ну то есть зависимости от другой функции и можно еще мочить сообщение то есть если мы мы можем подписаться на события какой-нибудь система ну допустим на только на ошибки на тайм-ауте и как-то это будет ретрит сделать и вообще там он туда бы цепочку можно составлять достаточно просто и сложно вот там у нас очень просят и графический интерфейс если из коробки идет и вот можно примерно посмотреть как это выглядит граф вычислений вот мы задекларировали эти функции и вот он разбился в такой вот граф какие фича да вот у нас какие у нас отличительные черты по сравнению с другими как я и сказал у нас реально нету в один из узлов то есть нам не важно какая надо у нас выпадает все решается достаточно быстро то есть у нас на кластере есть общие компоненты но у нас есть ip адрес да где мы держим на любой из моде и в случае выпадание именно той ноды с которой где сидел vip нам нужно буквально десять секунд чтобы он переехал но делается это все автоматически если выпадает но до обычно как но без липового адресата это происходит моментально следующая фича так называемый правит space это уровень разграничения группы функций fps alloy допустим у нас есть plaster большой есть ресурсы которых есть выделены и так как частоты процесса большая память ssd какой-нибудь и мы можем принципе сделать так называемой группы и обеспечить и целые конкретным функциям в текущей группе мы можем это не делать можем объединить в один кластер 1 in space как я говорил на уровне платформы мы можем управлять транспортом передачи сообщений то есть вообще в контейнерах сети у нас в яндексе в контейнерах сети выключена вообще то есть если вы захотите взаимодействовать с внешним миром вы взаимодействуете через платформу есть определенные системные функции типа урал вечера теперь триггер а.к. вот принимает событию дпс и т.п. это все уже написано то есть это нужно использовать сами функции они по сути только сиквел bound задачи решает следующая фича это встраиваемый планировщик есть низко стратегий есть разные flow до которая требует разных стратегий ну кому то нужен низкие постоянные сала и кому-то нужно держать ресурсы меньше как бы увеличивать солей 0 держатель соусами и вот у нас есть несколько в нашем случае там выродилась миска планировщиков чем планировщик я говорю да что это та же функция и есть символ планировавший к власти клауд и есть сейчас мы думаем на тему машин леоненко сделать модель которая будет полировщик будет по этой модели собственно делать выводы до создание каких-то функций заранее зависимости от долгоиграющего процесса у нас есть компрессия ну как так объекты достаточно могут приходить большие на обработку v-триггер они у нас в принципе высчитываются кусками всегда но изначально когда приходит какой-то большой кусок данных мы его сразу можем определить что он большой сжимаемого в потоке погоняем если допустим функция на какой-то другой ноги запрос крюшона первую ноту сжимаем их данные в потоке по точно передаем их по сети нажимаем на выходе из функции в этом плане разработчик вообще об этом не заботится и опять же мы управляем это на уровне платформы то есть степени сжатие так далее следующая очень интересная штука у нас был опыт на есть такая по 8 архитектура отойдем а она открытая и была возможность попробовать в принципе с компилится под это дело и проверить насколько это все будет эффективно работать так вот мы скомпилить и запустились и вроде работаем и даем хорошие результаты следующая важная тема это поддержка амазона здесь все достаточно просто то есть вы можете создать из этой инстанции там у себя в бама зоне разве бываете в принципе эту платформу и работать так же как с тоже линдой но получаю все те же преимущества которые есть то есть допустим лямда есть лимиты есть ограничение определенного для того чтобы составить цепочку функции вам нужен еще один инструмент степ functions да и ну как можно в принципе воспользоваться альтернативой причем ну можно за использовать часть инфраструктуры на выделенную дать выделенных мощностях также можно сапата инстанции за использовать сократить расходы следующая тема который вот сейчас мы прорабатываем так называемые гибридные решения с федерациями это в моменте вот у вас есть он прим он имеет определенный ресурс наступает там у вас черная пятница и не знаю там у кого что и вам в моменте на неделю и вас него края ткани с гипотеза дал бизнеса и в моменте нужно очень много мощностей в принципе вы можете создать это гибридное решение по факту сейчас это два namespace а которые между собой то есть есть функции которые занимаются общение между этими двумя анализ пейсами но эта тема еще не работает но мы над этим думаем и следующая важная тема которая есть в принципе уже профи в концепт этого платить некое общее решение принести два мира обычной виртуализации к военные если нужна какая-то большая изоляция и сети все эти преимущества принципе которые дает квн квн виртуализация да и контейнерную принести скорость выкатки разработки функции так далее так давайте я сейчас покажу что это из себя представляет так вот это нас наш такой интерфейсе небольшой по сути это тоже на самом деле функция до которой в которой заем это просто спа приложения вот тут кластер из трёх нот тут есть носим есть знания о доходах но до между собой тоже обмениваются событий если надо выпадает он впадает входит в кластер и появляются события а также есть так могут эти наши полу здесь разбивка по 10 системные все системные по по нотам и время в миллисекундах вот эта графа это следующее это по сути ну ошибки тайм-аут и и так называемый но события это когда сообщение приходит в пул но все worker занятым и мы на самом деле продолжаем обрабатывать не кидаем тайм-аут и и ик но от имени под кидается системное событие ума на которую подписано планировщик собственно планировщик понимает что здесь наступает возникновении нагрузки и исходя стали из остальных событий системных общей пластинках он принимает решение создания новых экземпляров у функции есть называемый лог это бизнесовые характеристики ошибки и тайм-аут и запущены мой и так далее в принципе можно посмотреть текущий лоб это по сути вот этот std так и есть а информация текущих ресурсах функции которые они занимают системы в основном эта ци полную память диск они тут не используем практически до потому что функция у нас несут состояния до поэтому мы их легко из келим то есть если вам нужно сохранять состояние вы пишете функцию допустим записи в кассандра или еще куда то подписывайтесь это функция какие-то события и она уже сохраняет их из нефть системы также есть эти flow наши у которого дома видели на картинке допустим есть такой фон так увеличить сейчас это у меня локально запущена не нужно судить строго здесь побыть марком это все запущено ноутбуки бо гарантия да кстати вы это можете тоже принципе попробовать есть в конце будет ссылка с описанием по сути есть несколько можно попробовать через vagrant есть официальный впм репозитории пакетов и также есть образы на истцу инстансах так у нас есть три ноты заходим на ту вообще неважно на какой в принципе даже мы об этом не заботимся мужем на 1 можно 2 есть базовая есть кризис и инструмент для того чтобы управлять принципе кластером вы включаете для разного рода функциональности собирать класть и разбирать к власти вот так нужно авторизоваться так сейчас у нас запущен plaster здесь мы видим что у нас есть веб-адрес плавающие да на кластере собственно через которую мы заходим есть собственный способ список этих функций так есть список этих форм нужно указательным спрей так вот сейчас у нас есть функция давайте я покажу что такое функция допустим на примере питона до функция это по сути докер файл исполняемый код и описание исполняем коде у нас есть айпи ай да он просто здесь он очень простой принципе можно инкапсулировать это в какой-нибудь библиотеке но здесь я хочу показать что в принципе это не обязательно ну и делайте какую-то полезную работу так давайте попробуем поменьше немножко смотреть как происходит скиллинг у нас сейчас есть функция ну орехового она работает на кластер и да давайте посмотрим что она действительно работает какие метрики вы дарят вот время выполнения функций а там порядка пяти миллисекунд 2 дал сократилось до двух так попробуем поставить эту функцию посмотрим как оно у нас растет масштабах используем для этого выродка сейчас функция лично принимать продолжать принимать события сообщения но скорее всего вы сейчас начнет не воспевать это делать успела огни вот не успел и это не ошибки дает здесь это те события которые у нас как бы временно приостановились но да да выполнялись в процессе вот мы видим да что там сейчас она дает такой the performance в этом месте тоже наблюдаем сейчас это один из сан функции там один вот начинает да у нас ps начинает расти и потихоньку планировщик принимает эти события нового он принимает уже решение или на кого стилен сейчас я попробую запулить это сразу много чтобы от делится на несколько нот так вот он растет давайте за полем туда сразу пусть он захлебнется и уже видно да что у нас скелет происходить кстати посмотрим сколько функция в нас был данным вен запущенную да тут порядка трех функций азиата сейчас одной ноги дробное число то там нам нужно было по определенным причинам здесь то есть порядка пяти функций 1 на разные на разных модах дальше когда нагрузка падает на сейчас увидим происходит скилл down функций ну это происходит не моментально это происходит через какой-то момент времени то есть мы оставляем их ненадолго жить когда вы сейчас это порядка 15 секунд мы низкие в данию функция обратную сторону так но это не очень интересно давайте попробуем собственно сделать эту цепочку это намного интересней цепочка немного задача то что на себя представляет я сказал скачал файлик сейчас статьи и би си news за вообще за весь период не в таком вот формате то есть эта дата и текст и название новости да и задача допустим пустить их к свету покажу pipeline задача состоит в следующем то есть такой граф обработки то есть у нас нужно отполировать новость дальше нужно посчитать все слова почитать ну то есть первый обработчик подписаны считает слова зависимости от этого принимают решение на создание допустим генерацию xml второе читает буквы находит темп к определенное количество букв note 3 считает количество слов до 1 считает количество дубликатов слов и в зависимости от этого мы объединяем допустим два потока в еще одну цепочку в жизнь в xml в конечном итоге объединяемся данные которые получилось в подпись подписываем их и отправляем на некий здесь и пьера сейчас нам примеру под огневым в куницын откат сейчас мы поднимем так ну чтобы вы просто нам побочный эффект посмотреть в принципе мы могли бы записать их куда-то файл примеру да причем и за счет за счет того что у нас функция это по сути процессы мы можем функций делать из простых даже большого команд можем тот же на tkat виде стрим франция сделать которая будет читать и там что то делать то есть они пишутся достаточно просто так давайте давайте сначала посмотрим что у нас на самом деле skeleton функции прошел да вот мы видим даже у нас сейчас функция это выписали она осталась на одной воде и на в одном количестве сейчас мы это проверим да вот она одна ну и по сути вот у нас был пик загрузки этой функции дальше со ушел вниз мы освободили ресурсы для тех функций которые требуют сейчас обработки так сейчас мы мы попробуем flow можно поднять сейчас он опущен именно вот этого цепочки да так в ходе сядем писи сейчас я бы поставил до фол в статус активности сейчас планировщик как бы это увидит примет деситин если ты какой-то там небольшая уже так времени он определяет ресурсы где это нужно разместить по некому алгоритму вот там его поднял то есть вот вот поднялась наша цепочка функций вот они все эти описан давали дата вот каунт собой джейсон так и пустим поток на обработку так септик которая просто по сути делает из степи события в низких потоках event используется так вот мы видим до что вот параллельном окне у нас идет эта цепочка документы бегут в конечном итоге подписываются но мы можем это принципе посмотреть что вот здесь у нас есть время до время выполнения именно самих функций насколько они занимают причем мы говорим что вот этот flow да он включает себя вот эту группу функций и сам скиллинг он сначала происходит а вокально вот какой то функция за 1 у нас на ученую другую ноду случае с группой мы идем от признака локальности данных и их обработки и мы стелим принципе всю группу сразу то есть возможность сделать звук говоря часть обработчиков разместить на разных модов да чтоб они не были зависимы друг от друга так давайте продолжим это все интересно да но интересны наверно больше практический опыт применения про production ну как мы говорили мы когда начинали нашу разработку на самом деле вы до конца не успели реализовать все элементы системы успели только на одном примере то есть говоря о той системе до архитектуре мы говорили о выделенном узле обыденных инфраструктурах в части в частности это был сервис подписания готовой он был написан на java использовался tomcat классическая архитектура была джинс антон котов в них все вряд и нагрузка балансируется соответственно там при выпадении этого узла мы там теряли потеряли принципе это функциональность но самое обидное что по сути он не всегда был загружен то есть вот эти ресурсы которые стояли они ни использовались по большую часть ну там ночью приходили подписание днем но если проследить историю the utilization всех этих 9 машин который стоит денег она ну там на уровне 20 процентов не больше но мы не можем уменьшить до кластер потому что с приходом нагрузки в один момент мы не просто не успеем от скелетону то есть админ не успеет это сделать больше или когда он не знает когда здесь как бы есть там три ли должны до ложь откровенная ложь и тесты на производительность здесь больше я хотел показать не сам башмак да вот смотрите там увеличились и уменьшились а сравнительный анализ то есть текущие сервис которую вот реализован но в новой нотации мы ничего с ним не делали абсолютно ничего не оптимизации не какой то есть мы по сути что сделали мы взяли вытащили прям под из веб-сервиса как он есть запаковали все это в контейнер немного обернули естественно нотация которая включается коннотацию наших функций и опубликовали на платформе и что он получили если здесь смотреть с предыдущей картинкой но рпс примерно такой же но уитон все увеличился как бы в чем здесь плюс да он увеличился потому что на самом деле у нас один сын с одной функции стратегия планирования не жесткая и по факту для того чтобы ей скелет в моменте приходит сразу много запросов мы ловим высокие володин себя дальше бен чем 15 секунд и видим результат нас в этом эссе падает функции стелется здесь порядка их там 7 8 шт 8 7 8 что их порядка шести штук здесь и получаем fps там намного больше дачам чем был этот классический подход как то так то есть это реально production ну то есть это реально что это часть инфраструктуры которую мы заменили и по сути вот те ресурсы которые просто его ли мы сейчас и готовы предоставить для обработки другими функциями опять же если у нас мы говорим что какие-то критичных вещах уровни разных функциях есть приоритеты то есть масса железа равно конечно да и функции могут одномоментно потребовать ресурс здесь мы начинаем разваливать это приоритетами то есть если приоритет функция выше функция которая с низким приоритетом не скилл долбятся давая возможность высвободит освобождает ресурсы для исполнения более приятных функций этот системный процесс загрузки и тайфун этой же функции ну то есть мы видим даже к тому моменту у нас и происходит какой-то там цикл bound он уходит и вообще завершая когда рассказ я хочу сказать что наша основная задача сейчас на это вы можете мы выкладываем решение в open source и вообще в принципе мы хотим чтобы проекту двигался дальше и поэтому если у кого есть интерес и желание и то есть тест ибо рифмовать и там ещё что-то и всегда очень рада ответить помочь и балкам ты просто спикер моей мечты смотри 1649 до соответственно друзья все вопросы в кулуарах я вижу ваше будущее в телеграме был вопрос почему нельзя склонах а человека на удаленке давайте быстро в микрофон вопросы стиле грамма и потом лишь как тебя с постели грамм надеемся на всю страну спасет скорее всего да сейчас все кому я рассказал в прошлый раз про сладкое они побежим авеш telegram.bot не может включить микрофон возрасте до скажите в мои все нормально вопрос от повела беды рассматривались возможности использования hadoop для решений описываемых задачи если да то почему не выбрали но я еще раз замечу что ну то есть почему ходу до ходок по сути это оффлайновые давно и то есть мы загрузить туда дальше какой-нибудь мой придет берем и обрабатываем здесь вообще подход изначально был таков что у нас некий гипотеза у бизнеса есть и они ну то есть сама задача была как некий эксперимент они хотели перепроверять вообще весь полностью цикл то есть алгоритмы менялись данных то есть и эти данные постоянно менялись системах исходных то есть нам приходилось перерабатывать это заново и просто вот и тут задача была ну не больше как бы аппарата подход побольше экономия на ресурсах то есть ресурсы кластер ограничены грузы на груз когда приходящие вот эти кусок данных которые было там одном регионе сформировался прибежал на обработку она заведомо не известно да и здесь именно данные они streamlight как бы они не offline то есть мы не могли там вытащить и начать обмолотить их там анализа каким-то и сказать здесь они изначально то есть можно было эту задачу изначально решать так но уже был очень много алгоритм написано в таком подходе потоковой обработки и поклониться подборная аплодисменты отлично"
}