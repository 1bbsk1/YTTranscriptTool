{
  "video_id": "_7DmerTFXsQ",
  "channel": "HighLoadChannel",
  "title": "«ML-свадьба» между миллионами товаров, или Как выдержать нагрузку в потоке / Ван Хачатрян (Ozon)",
  "views": 3513,
  "duration": 3102,
  "published": "2023-04-28T06:21:30-07:00",
  "text": "Привет меня зовут Ван Хачатурян в Озоне я с 2019 года пришел сюда как сеньорменный инженер сейчас руковожу отдел машины в обучении и мачинга моя мой доклад посвящен теме мачинга нашему алгоритму и как нам удалось его развернуть тайм-пайплайн не потеряв при этом продуктивность этого алгоритма давайте к сути Что такое матчинг в последние годы это стало очень популярной задачей в индустрии решает эту задачу в разных компаниях продуктах в чат-ботах рекомендациях я и голосовых помощниках А мы же в ecommercedes называем задачу товарного представления с целью ответить на достаточно простой вопрос является ли эти два товара одинаковыми для нашего потребителя при этом важно чтобы они были одинаковыми во всех смыслах слова чтобы у нас не было каких-то оговорок каких-то атрибутов провернуть этот факт применение алгоритма достаточно разное мы исследуем наши ассортимент условно если мы имеем 100 миллионов активных товаров это еще не значит что у нас 100 миллионов уникальных товаров Вот как раз матчинг внутри озона товаров между собой позволяет оценить полноту нашего ассортимента мы используем также matching в ценах имея вот товарные группы этих матчей мы можем посмотреть какой разброс цен в товарной группе и давать рекомендации нашим продавцам находиться в каком-то конкретном интервале для того чтобы товары оставались привлекательными для наших покупателей задачах контента зная наши мочи имея при этом хорошо заполненный товар мы можем рекомендовать другим продавцам также заполнять конкретные поля атрибуты того чтобы их товары становились более понятными зная товарные группы мы можем человеку подыскать наиболее подходящее для него предложение имея знания о том сколько есть уникальных аналогов этого товара Почему на практике это не так просто потому что имея десятки тысяч продавцов на нашем marketplace и ассортимент более чем 100 миллионов skyu мы не можем гарантировать с ней даже в условиях когда мы даем рекомендации что все продавцы интерпретируют атрибуты о товарах информацию о товарах максимально одинаково ввиду этого даже иногда пользователи очень сложно различить Ну или же ответить на простой вопрос является ли два выделенных товара одинаковыми иногда указывая атрибут совместимость с разными операционными системами например для умных часов на примере из предыдущего слайда кто-то указывает только Android а кто-то пишет iOS и Android но в технической документации девайса он совместим там яйцо из другой операционной системы но если мы строго сопоставляем два товара то все-таки как понимать они мочи или нет для каждого товара очень сложно опускаться до уровня технических деталей поэтому к делу подключается ML и используется практимированные подходы для того чтобы на уровне определенной вероятности определять что товар и скорее всего является матчами Ну и матчей нам приходится искать достаточно много поскольку по нашей экспертной аналитике каждый новый второй товар на нашем marketplace не является уникальным а это значит что я еще до этого товара существовала для товара мы можем использовать матчинга можем использовать практически все данные которые есть у товаре Это изображение это текст наименование описания атрибуты размеры продавца место в нашем каталоге то есть категории дереве ну эти все данные имеют разное значение разной значимости разные полезность Однако мы стараемся по максимуму использовать для того чтобы давать максимально точные результаты нам нежелательно давать мочи которые таковы не являются критерий точности задачи также очень важен я не буду очень подробно рассказывать про eml и про то как мы обучаем модели по их свойства плюсы и минусы поэтому я дам какие-то базовые определения для тех слушателей которые могут не быть экспертами в этой сфере и пойду дальше Наша задача Это задача бинарной классификации таргетом 1 или 0 1 если мы имеем матч но если мы имеем не матч эмбердинги это вектора которые превращаются сложные объекты о товаре например текст и картинку явно в таком виде передать алгоритмом машина обученным алгоритму можно но ожидая на выходе некие беддинг который Дальше можно будет сопоставлять а сопоставлять непосредственно картинки байты между собой очень сложно поэтому мы пытаемся свести к каким-то атомарным единицам в данном случае это медики а признаки в задаче бинарной классификации это те фичи которые которых может быть как э 10 так и 100 который позволяет э-э применяя сверху классификатор определить вероятность того что мы имеем матч обучаемые модели собрав заранее какие-то сет на старте любого алгоритма машинного обучения с учителем мы с вами нуждаемся в какой-то разметке мы используем cructors для того чтобы разметить парой положительных матчей пары отрицательных ночей и на основе этого дата Сета и признаков учим нашей модельки фреймворки мы можем использовать зависимости от типа задачи разной для разработки Берингов мы используем нейросети а для решения задачи классификации используем например градиентные бустинг при этом во время обучения модели есть несколько фаз во время обучения мышцы штрафуем функцию модель Lost функции оцениваем по итогу критериями успеха например такие как precision Recall то есть точности полнота этого алгоритма Ну и отдельно выделяем некий независимые даты сет который не используется во время обучения для финального тестирования и гравитации наших моделей про наш стек стэк у нас в основном разработка на пайтоне У нас есть маленькие сервисы на Go для расчета сложных фичей мы используем скалы иногда для построения крон жопу airflow а дипломимся по стандартному озонскому дфлайну про это мои коллеги очень подробно рассказывали на предыдущих докладах от нашей компании в kubernets используя себя хранение наших данных происходит разных системах постгальте в ходупе прям большая часть исторических данных София в пихаусе в зависимости от назначения этих данных для общения между микросервисом микросервисами мы используем кавкушей аналитики можем ещё пойти вертику а в мониторинге у нас а как у нас вообще работал матчинг и по технике и по смыслу как я отметил раньше для того чтобы начать сопоставлять какие-то товары между собой Мы сначала вынуждены посчитать их имбидинги реализовать картинки о них атрибуты и товары для этого мы ежедневно запускали кронд жопу верфу которая как раз занималась этой деятельностью запускалась эта кронжаба и на языке пайтона используя фреймворк запускались кастомные User defind функции которые высчитывали эти рейтинги применяя наши модели далее мы этим складывали в ходу это было достаточно такое трудоемкой задачей потому что объем товаров из-за ко дню очень сильно изменилась и соответственно мы не могли гарантировать одинаковое время прибытия этих имбидингов далее как только мы получили вектора мы можем какие-то товары уже сопоставлять для товарного сопоставления используется очень известный алгоритмы поиска ближайших кандидатов важно понимать что этот алгоритм может иметь если мы собираемся перебрать все возможные пары имеют очень высокую алгоритмическую сложность для этого могут потребоваться оптимизации разного рода того чтобы ускорить эту деятельность но базово тут есть два термина есть квери есть запрос то есть товары которые мы будем для которых мы будем искать матч есть База база это могут быть все товары к нам поступает квери и мы опять в рамках запускали поиск этих кандидатов получая в результате 50 кандидатов для каждого товара которые могут смачиться с ним Ну и поискав эти кандидаты мы шли опять же кружобой без какого-то понятного eto отвечать на вопрос является ли они мочом для каждого кандидата для каждого пары кандидатов генерились фичи те самые признаки составления например дистанции вклидовая дистанция между их бедингами категория товаров которые мы рассматриваем и так далее фичи разного плана какие-то из них могут быть пустые какие-то из них могут быть нулевые для этого модели заранее учится иногда она очень грязных данных для того чтобы они могли функционировать даже в таких сложных условиях но и в результате получали некий Скоро это невероятность это Score Но для простоты Я дальше буду называть это вероятность Однако интерпретировать В прямом смысле слова так нельзя Ну имея некий порог вероятности Мы отрезали полученные пары и доставали оттуда те которые мы считаем истинными матчами суммарно наш алгоритм мог работать от 10 до 20 часов чем больше становился ассортимент тем дольше мы начинаем работать в этот момент вы поняли что нам наших ресурсов в рамках ходу кластера А у нас этих кластеров 3 может не хватать Ну и хотелось не иметь pipeline который работает условно 20 часов для миллиона товаров которые постоянно как-то функционирует и имеет какое-то ожидаемое время прибытия для одного матча в случае батча мы ждем получается весь батч для того чтобы узнать мочи даже по одному товару в случае потока какого-то процесса мы запустили его в наш Flow и ждем когда он работает и Ну давайте тогда я наверное перейду к нашему Real Time pipeline у к нашей архитектуре и расскажу как нам удалось это осуществить архитектура база выглядит следующим образом тут достаточно понятно и простая цепочка событий которые позволяют найти эти матчи Давайте поэтапно пройдем по каждому из них к нам пришел клиент и спрашивает по ID товара найти матчи мы получаем это сообщение в каске дальше сообщения подхватывается нашим процессом сервисам который регистрирует целом все происходящее он сначала идет искать имбидинги какие сценарии тут возможны или же у него может быть уже какой-то имбидинг соответственно сразу вернет ответ Если нет то он начинает уже разбираться он идет в сервис хранения товаров достает оттуда нужные атрибуты нужные наименования И просит еще одного сервиса Тритон сервиса посчитать если у нас таковых не было э-э он считает эти имбидинги собирает складывает свои хроники хранилище и возвращает prothing сервису мы тут считаем что как в случае батч подхода mбяденьги мы посчитали первый этап нашей задачи Мы решили как только мы их получили как Мы помним мы должны теперь найти для этого товара кандидаты кандидатов мы ищем в рамках Спарк стриминг Application я чуть позже расскажу подробно что это за архитектура используя при этом машина свой индекс это индекс до поиска ближайших кандидатов считается 100 подходом в нечетком поиске ближайших кандидатов и очень хорошо подходит под нашу задачу А почему именно Spark streaming Application они традиционные микросервис про это тоже коротко расскажу но это очень любимое нами технология очень масштабируемая плюс еще в условиях того что в рамках расчета беддингов классификации всякого прочего мы отказались от Паспорта у нас появилось очень много ресурсов для того чтобы масштабировать парттрининг распределенный фреймворк и поднимать туда индекс в рамках которого можем искать миллионы товаров в течение дня вообще не вспотели как только мы нашли кандидатов для каждого товара условно 50 дальше мы отправляем на классификацию классификация у нас действует по ранее озвученному принципу Мы сначала должны посчитать какие-то признаки вот эти признаки мы уже не храним мы эти признаки считаем на лету Казалось бы это достаточно дорого в рамках микросервиса это так оно и есть но мы выяснили что Имея не очень большое количество признаков сопоставления это не так уж и тяжело э-э и решили попробовать вариант расчета их на лету потому что как только мы выяснили имеем матч или не матч нам эти фичи не особо интересны плюс сохранить ещё все фичи о нем очах это может быть очень дорого и бессмысленно собственно этот сервис обращается в product Service спрашивает информацию о товаре спрашивает у мэдинг сервис вектора и на этом этапе мы уже ожидаем что им без них сервис достаточно быстро вернёт ответ потому что на ранних этапах он уже посчитал этот бензинг забирает и считает парные сопоставление условно дистанции в клитовая дистанция между составляет какие-то конкретные атрибуты от аварии или берёт список э-э самых частых атрибутах атрибутов самых важных и их сопоставляет считает некий индекс и используют это сопоставление отдаёт вероятность и мы возвращаем клиентов кавку матч если мы его таковым определили Ну и храним эту информацию ещё в некому матче сервисе который с которым Дальше можно отдельно уже взаимодействовать для аналитики если мы хотим прийти забрать какие-то матчи и историю до наших успехов оценивать точность успешность сравнивать разные модели между собой ну и в рамках такой архитектуры нам удалось достичь достаточно хороших результатов Давайте подробно поговорим про каждый из этих вложенных стадий вообще как исходно у нас выглядит товар это сложная структура словарь просто с набором атрибутов здесь проведем пример товаров который уже имеет мочи соответственно в поле Sky можно увидеть что уже имеются какие-то мочи в рамках общего варианта ID частично это может быть нашей заслугой также отсюда можно дергать название этого товара можно дергать позиции нашим категориенным дереве рейтинг отзывы все что угодно Все что может только быть о товаре продавца картинки урлы и всякое прочее взяв эту информацию Мы можем приступить разработке этих данных обработке через наши векторизаторы энкодеры для текстов мы используем бертрансформеры это модели которые очень умело справляются с контекстом понимают могут понимать синонимы если мы их хорошо научили а для картинок мы используем сиамскую архитектуру сверточными нейросетями а именно средства 50 оба этих моделей Учатся с помощью Это значит что мы пытаемся похожие сущности сблизить Они похожи отдалить как можно больше И эти модели служат фундаментом задачи матчинга товарного сопоставление и вот мы эти вектора которые в результате рассчитываем отдаем в принципе всем они используются в разных задачах где ведется любая работа с товаром потому что для машины Это самый такой понятный способ работать с товарами сырым текстом работать порой очень сложно и дорого как мы считаем клиент к нам пришел наш процесс сервис отправляет Куда нужно сервис который по факту считает их сервере что это за тритоны сервер я про это поговорю на следующем слайде Это очень хороший фреймворк там видео которое позволяет модель обучена машина обученную модель подавать как сервис при этом обращаться по HP протоколу из коробки позволяет балансировать нагрузку между ГПУ в рамках вашей ноды поддерживает абсолютно практически все распространенные фреймворки на которых учатся эмэль модели Ну и с коробки также пишет метрики утилизацию GPU утилизацию мы на эти метрики постоянно смотрим в поисках способов оптимизации или масштабирования нашего алгоритма для инференса на GPU GPU тут Ключевая часть всей этой истории поскольку раньше моим безинги считали через пасть парк на ходупе на CPU за имев очень хороший набор GPU Note Мы научились это делать гораздо быстрее гораздо эффективнее это часть нашего прыжка с точки зрения производительности что нам позволило перейти на Real Time Ну и пришли к поиску кандидатов ближайших кандидатов мы используем для этого свой индекс это многослойный такой индекс которого мы сверху начинаем искать для каждого вектора ближайшие до него кандидаты Причем на самом верхнем слое мы стараемся держать минимальное количество товаров которые с которыми мы будем сопоставлять например настоящем их может быть 6 а на третьем например уже 50 это в целом весь индекс он параметризован в рамках его построения мы стараемся найти для себя трейдов двигаясь всеми этими параметрами для того чтобы во-первых найти на ближайших кандидатов как можно быстрее но и найти не просто кандидатов а кандидатов которые скорее всего приведут к тому что мы найдем матч НСВ вообще считается 100 подходом поэтому мы в поисках вот этого решения особо долго не думали хотя есть множество других очень хороших вариантов там свои со мной где можно заниматься задачей ближайший поиска ближайших кандидатов есть готовая реализация под Спарк от спарка Мы полностью не отказывались потому что у него есть достаточно большие плюсы но и сложность поиска для единицы товара логарифмическая небольшой ликбез про Спарк стриминг вот этот самый индекс мы поместили в спасательных приложений спад стриминг фреймворк позволяет слушать обрабатывать поток данных место обычного традиционного паспорта когда мы работаем с бочами с обеих сторон мы имеем Кафка топики мы можем на топик например из шести партийцы запустить Spark streaming приложение из 36 экзекьютеров и на каждый партицию натравить 6 имеет при себе какое-то количество CPU какое-то количество оперативной памяти и диск это все настраиваемое Если вы хотите сделать вот этот процесс оптимальным про спорт стриминг у меня был доклад на внутреннем этапе который мы устраивали в Озоне ссылка и qr-код на слайде если будет интересно про это подробно послушать Ну и сам СВ имея этот индекс мы делим его на шарды а именно 64 шарда и начинаем отправлять засылать туда товары для которых мы хотим найти мочи размер этого индекса порядка 100 миллионов это размер нашего текущего активного ассортимента с ростом этого активного ассортимента индекс растёт мы раз в день пересчитываем вот целиком количество шардов этого индекс 64 соответственно экзекьютеров спарка в данном случае будет 64 Ну и вектора С которыми мы ищем это текстовые вектора которые имеют тоже размер 64 это просто совпадение с таким же успехом Они могли иметь размер 128 Ну и приходим к финальному этапу классификации когда мы после того как нашли ближайших кандидатов отвечаем на вот этот самый простой вопрос матча они или нет в рамках классификации мы на лету считаем фичей сходив продукт сервис в имбидинге считаем 19 парных фичей которые позволяют нам с точностью 95 процентов В среднем находить вот эти самые матчи на одном позе Мы в рамках бенчмарка я решил показать способны в секунду держать 900 rps и соответственно если нужно масштабировать на большее количество то мы туда докидываем Просто больше в классификации у нас используется 19 фичей Несмотря на то что самое умное наша модель исторически имела 120 фичей тут надо понимать что чем больше признаков флой модели скорее всего она будет умнее но считается на лету 120 фичей при этом держа вот эту dreal Time архитектуру будет очень сложно и мы тут потеряли бы очень важно Это нас миллисекунды как мы нашли такую же модель Ну хотя примерно такую же умную модель но при этом имеет 19 фичей вот тут нам помогла хитрость дистилляциями модели это когда мы тренируем вторую модель с меньшими признаками пространствам которые имитирует поведение с коров вот той самой умной модели обучив на м с лося То есть когда мы Составляем с коры считаем их разницу абсолюты возводим в квадрат и пытаемся минимизировать во время обучения эту метку нам удалось достичь те модели которая очень хорошо и классно имитирует нашу самую умную Из плюсов то что нам это удалось сделать с помощью всего лишь 19 признаков самое важное фичи которые взлетели этот жаккард индекс над атрибутами и их ключами и значениями Метрика иначе иногда называется intersection Over Union я подробно рассказывать не буду потому что первый запрос Википедии в принципе вам подскажете расстояние между картиночными векторами расстояние между текстовыми векторами и такой простой признак как составление Света товара дата сет мы учили на 100 миллионов парах на тех же Пу на которых и довольно успешно эта модель помогает эта задача решать В итоге еще один снимок нашей архитектуры финально мы выглядим примерно следующим образом причем как я раньше отметил к нашему вот этому финальному матч сервису клиент всегда может не запрашивая заново найти матч прийти узнать если например матчи по конкретному айтишнику они уже могут быть ему свои аналитики для своей задачей уже этого может быть вполне достаточно Поэтому нам важно было иметь ещё один отдельные сервисом конце который может из нашего хранилища возвращать уже имеющиеся мочи переход на такую сервисную архитектуру позволил нам используя возможности нашей платформы из коробки получить мониторинг в ходупе нам все приходилось писать своими руками Все метрики После опять же расчеты вот этих бач алгоритмов А в нашем случае мы можем сразу подключиться к нужному топику или к нужному сервису для того чтобы посмотреть что там происходит дало нам возможность сделать наш весь файлайн более прозрачным более понятным для пользователя и возможность прийти посмотреть статус по этому товару мы строим разные метрики помимо технических Мы также смотрим на то сколько мы нашли матчей конкретном срезе в конкретной категории исследуя множество разных продуктовых метрик такие как точность полнота нашего алгоритма Ну из среднее время and обхода единицы товара сейчас у нас нам удается в среднем до за пять минут максимум найти матч для отдельного взятого товара в лучших случаях нам это дается сделать это за минуту но с тем что было до этого это прям очень большой прыжок и бенчмарки по каждому еще этапы инференция например в Тритон берде на пятом квантиле нам удается держать 80 получается на одном инстинность ГПУ 80 запросов А значит примерно 7 миллионов текстовых беттингов в сутки мы в таком случае можем посчитать в продакшене у нас запущена порядка 40 соответственно Мы в день способны посчитать 280 миллионов значит там за день можем пересчитать весь активный ассортимент озона в картинках не все так классно но опять же не из-за eml а потому что из расчета приходится на лету скачивать то есть тут есть ограничение сети но поскольку расчет картиночных Берингов у нас все еще спорт кластере мы можем эту это дело очень сильно масштабировать здесь бенчмар для одного стриминговой инстинса хотя мы используем порядка 300 стриминг на 64 64 шардах способен держать где-то 200 офсетов в секунду и возвращать для них по 50 кандидатов то есть заслав двести например товаров получаем 10 тысяч в итоге кандидатов которые дальше пойдут сервис классификации а классификация на одном поле собрано 900 пар работает и вернуть ответ Ну и в целом для того чтобы у вас система была более или менее консистента можно подобрать такое количество вот этих базовых юнитов для того чтобы и того сойтись примерно одинаковым скоростям у нас до этого ресурса есть мы стараемся следить за этими результатами того чтобы постоянно иметь некий алгоритм который держит постоянную нагрузку не сильно колеблется когда он борется какой-то например крупный сейлер с ассортиментом размером с размером краткие итоги нам удалось достичь прозрачности то есть в любой момент мы можем видеть статус отправленного на матчах товара скорость если мы раньше обрабатывали за очень большое количество часов искали матчей то теперь это мы делаем за 5-6 минут в среднем поддержка баз данных и сервисов доступно благодаря нашей единой платформе мониторинг также из коробки то есть нам достаточно указать метрику достаточно указать топики и сформулировать тип алерта то есть указать какие-то критические значения Ну и теперь в нас теперь могут ходить соседние сервисы и запрашивать эти мочи А в рамках большого подхода нашим алгоритмы могли пользоваться только мы а это все надеюсь вам понравился мой доклад для его оценки можете сходить по этому qr-коду теперь с удовольствием отвечу на Ваши вопросы Спасибо за доклад для вопросов поднимайте руки и первая рука у нас уже есть сейчас будет микрофон Спасибо вам очень крутой доклад вопрос про энкодер для текстов во-первых Как вы устроили у себя негатив сэмплинг То есть это у вас какие-то данные которые размещали ваши там клиенты на платформе они были достаточно чистые или вам приходилось что-то размечать Да это очень крутой вопрос Вообще вкратце расскажу обучение Это задача когда мы накачиваем наш дата сет негативными но при этом очень информативными примерами для того чтобы Мы научились различать позитивные отрицательного если мы например на примере матча краткие на примере матчи мы будем в рамках положительных примеров класть два одинаковых iPhone и в рамках негативных примеров класть iPhone и носки то наша модель скорее обучиться очень плохо и хорошая сэмплинг Это история про то что как можно больше хороших негативов условно два Айфона разных цветов два Айфона с разными размерами экрана того чтобы научить модель сложных ситуациях когда изображение маркетплейсе один почти одинаковая модель могла ориентироваться Изучая при этом разные признаки что касается самих биртов то разметка вот прям когда Мы только-только начинали 2020 году матча разметку мы делали через Яндекс Толока собрали какой-то набор пар это мы сделали путем то есть мы взяли набором рейтингов поставили их между собой срезали по определенным порогу для того чтобы найти такой добротный срез то есть более или менее похоже товаров и попросили по факту разметить разметить единичками и ноликами но первая итерация не увенчалась прям большим успехом мы поняли что датасет постоянно нужно постоянно инъекцию новых хороших нэготивов Изучая бизнес какую-то логику бизнес-средств который в котором мы могли работать очень плохо и выискивая какие-то категории например в которых у нас не все так хорошо Мы искали опять же в рамках некоторых прокси там по текстам по картинкам по атрибутам разные варианты найти сложные примеры когда мы даем предсказание наши же предсказания которые в итоге оказываются позитивами очень часто становится потом хорошим Примером для обучения потому что это тот кейс когда мы сами вроде бы ошиблись А значит мы сами до этого не знали об этом У нас не было этого знания нашей модели но теперь разметив как правильный нолик мы получаем хороший негатив который в дальнейшем может служить почвой для лучшего обучения А так в целом мой совет искать какие-то соседние пространства в рамках которых можно сравнить по какой-то набрать близкие товары разметить и накачать их модель потому что вот совсем небольшой вопрос вдогонку То есть у вас огромный ассортимент А как получилось находить Вот именно какие-то проблемные категории чтобы на них сфокусироваться вот когда я говорил что мы мониторим продуктовые метрики среди них точность полнота это просто делается путем где у нас полнота скачет волатильность полноты или там точности скачет больше всего товары условно электроники размечать проще чем искать мочи среди них проще чем в одежде потому что в одежде условно где-то люди делают фотки на моделях то есть на живых людях а где-то брюки Могут просто висеть 2D и пойти попробовать пойти попробовать Тут даже в целом Мы даже шли Однажды путем выделения объектов именно непосредственно брюк через модели и потом Это непосредственно джинсов до нужных нам объектов для того чтобы ответить на вопрос максимально правильно спасибо так не стесняемся поднимаем руки если есть еще вопросы слева справа у нас Два подарка Да да Давайте давайте у нас два клевых подарка есть спасибо очень хороший доклад вопрос Как вы обрабатываете кейсы когда заведомо некорректные данные были введены пользователями это уже задача ближе к модерации но как мы можем выискивать кейсы когда скорее всего данные были введены не очень хорошо процитированный ответ соответственно Если мы с вероятностью 95 очень щепетильном кейсе отдали матч это служит почвой дальше пойти поставить конкретно взятый атрибуты то есть мы видим что на основе текста и картинки товары скорее всего одинаковые но словно продавец в одном случае назвал товар черным другом случае темно серым Вот и когда мы отдаем эти результаты то есть мы непосредственно не взаимодействуем с сайтом мы отдаем нашим коллегам которые занимаются вот этой задачей поиск несоответствий у пар У пары найденных мочей если они не соответствуют то продавцу предлагаются варианты посмотреть еще раз на свой контент и может быть исправить и соответственно один вопрос примерно такой же оперы как получается избегайте такой ситуации когда у Вас например произошло изменение характеристику примеру двух товаров одновременно Они до этого были как бы одинаковыми А после этого они стали вообще из разных категорий может получиться Так что предыдущее состояние одинаковое но по-хорошему они разные Вот это тоже очень хороший вопрос задачи матчинга на тему сложна Что в итоге мы должны понять для потребителя несмотря на атрибуты множества атрибутов их разность они всё-таки одинаковые или нет Если мы Ну если меняется какая-то характеристика мы получаем событие апдейта этого товара товар пойдёт и Полностью заново пройдет через всю нашу архитектуру И если мы раньше имели там Позитив класс А теперь получили ноль мы опять же вернём эту информацию клиенту и последний наш вердикт всегда считается самым актуальным То есть если мы посчитали что всё-таки это ноль то в системе э-э матч изменится на матч Вот это решается вот таким образом лучший способ наверное нет мы стараемся себе не противоречить то есть если товар изменился теперь по какой-то причине он не может не являться матчем мы этот результат нолик тоже отдаем для того чтобы наш клиент знал о том что наш вердикт изменяется Спасибо так еще вопросы руки Судя по всему слева Добрый вечер Большое спасибо за доклад на коротенький вопрос вот немножко упоминал уже ты о том что в разных категориях может быть разные в одежде допустим картинка больше может влиять где-то текст может влиять Вот вы как-то подкручиваете под каждую категорию своей модели или несколько моделей может быть под разные вещи лучше работать мы непосредственно своими руками не подкручиваем вот наша модель градиентного бустингами признак я вот раньше на слайде У меня сейчас я покажу чуть больше было признаков По моему изображенного мы используем категорийные признаки о категориях например в данном случае категория зуд товары для животных которые позволяют вот этой модели в рамках скрытые архитектуры разобраться в каких категориях Каким образом себя вести и накачав дата как можно больше данных из разных категорий мы невольно Передаем модели этой информации модель у себя в боксе дистанции нулевой дистанции Ну или там очень маленькая дистанция между картиночным векторами в категории А относиться чуть лучше чем той же дистанции в категории B и по факту так и происходит Мы когда исследуем важность признаков в разных категориях Мы видим что хорошо обученная модель в итоге лучше реагирует на текст категориях где текст более там принципиальный Ну имеет более принципиальную важность например в одежде а точнее не в одежде а в одежде всё-таки в среднем картинки лучше а в таких местах как Электроника текст прямо играет Ключевое значение и там текстовые фичи они опережают даже картиночные в виду просто того что атрибуты и текст э в электронике где могут быть характеристик может быть уникальных там 15-20 да имеет всё-таки более ключевые Ключевое значение Круто Спасибо А вот что вы имеете тексты под тем что текст Это просто как бы всё есть jsoning всего товара или это там описание там название описание и название мы викторизуем как отдельные сущности в поиске кандидатов мы используем только название потому что описание иногда могут быть очень длинными текстами содержать очень много лишней информации атрибуты викторизуем только том случае когда они представляют из себя сложные структуры То есть это длинный текст если это атрибуты размера то есть они могут изображаться винтовом значении 44 там сопоставляем винтовом смысле Мы также пробовали добавить такую фичу Стак или просто все атрибуты в одну строку и викторизовывали вот эту строку целиком Но это хочу вот в этом мелкую на умную модель забрать не удалось потому что она долго считалась вот Поэтому в нашей Real Time архитектуре мы от этого отказались Хотя Ну и с небольшой просадкой по полноте но в большой этой умной модели мы эту фичу используем еще есть такой вариант использовать все атрибуты Спасибо большое вам здесь здесь Спасибо за доклад Меня зовут Сергей У меня вопрос про дистилляцию будет можешь чуть поподробнее рассказать то есть я понял что вы создавали новую модель на базе mse loss Да и выбрали просто первые первые признаки по значимости и на базе ее строили модель которая дистиллировалась было сделано очень много исследований на эту тему какие именно наборы признаков использовать дистиллированной модели но мы сначала попытались уменьшить со 100 до 50 взяли 50 самых важных и старые модели получили что в принципе получается имитировать почти те же самые Попробуй использовать производительности надо уменьшать постепенно шли в сторону они пришли Вот 19 самым важным из предыдущих моделей Да итеративно уменьшая и оставили их но при этом пришли к какой-то оценки мс-лосса но она была достаточно маленькой идейной если посмотреть на наши наборы признаков даже в этих 19 вот прям самые важные самые значимые в общем-то и целом задача решают те остальные 80 которые не вошли это были опять же среди них были очень хорошие признаки которые классно описывают корни в кейсе о разных категориях разных товарных ситуациях если они например имеют признак Global то есть заставляется из-за границы у них контент вообще может по-другому но нам нужно было найти все-таки трейдов между скоростью и продуктивностью этой модели оперативно уменьшает по теме Которые мы получали от предыду сейчас мы пришли к 19 и оставили эти 19 просто здесь дистилляция это когда мы как бы количество параметров модели уменьшаем вот при этом сохраняем Ну те же самые выходы А вот здесь это выглядит так как вы просто отобрали наиболее важные признаки и при этом Ну не сильно просела Метрика да да можно сказать но дистилляция так рунинг когда мы уменьшаем да глушим какие-то параметры для того чтобы просто ну не теряя метрики но при этом оставаясь на том же уровне качества здесь мы это грубо называем дистилляцией но по факту речь идёт о снижении признаков пространства где мы пытаемся использовать задачу ну типа не Таргет бинарные классификации а решаем задачу регрессии потому что в таргете у нас в лейблах у нас значение в предыдущих коров и новая модель должна То есть регрессионная за счёт этих фичей отдавать э-э похоже более или менее скажем Спасибо есть еще вопрос не забыть в конце так Спасибо большое за доклад так но у меня два возможно тупых вопроса значит Насколько я понял В этой схеме можно было бы запоминать результаты применения модели вот на тех парах на которых мы эту модель уже применяли и это бы нам позволило Как ускорить цвета ранжирования Ну вот в этой схеме вот правильно понимаю что отбрасывая знания о том что точнее используя знания о том что раньше Эти товары не были матчами Теперь тем более Ну они скорее тоже не являются мочами просто не использовать в поиске Ну Либо так либо наоборот что если они были мочами то то теперь мы их ну наоборот будем проходить заново если они были этап набор кандидатов то есть мы можем из этих кандидатов отсеять то что мы уже спорили вот ну из какой-то базы данных отскорить только то что ну новое она в этом Скорее всего будет не так уж Да я понял в этом месте мы так сразу скажу Мы так не делаем Почему Потому что опять же у нас атрибуты характеристики могут меняться описание Исходя из этого наш вердикт который вчера еще был положительный могут стать негативным имея ресурсы это делать заново мы это делаем но если мы жили в мире если наш вердикт один раз Вышел там на сцену и больше не меняется то естественно это был хорошим решением оптимизировать В итоге искать среди тех товаров среди которых мы уже искали Вот Но что часто не заниматься одной и той же задачей мы используем ещё ряды м-м со всеми этими сервисами кэш Пройдите где мы храним недавно пройденные там парой матчей то есть нолики единички Потому что если клиент придет еще раз спросить у нас пройти весь этот но весь этот процесс чтобы мы ему сразу ответили что за предыдущие 12 часов мы вот нашли какой-то список матчей и приходи пожалуйста позже потому что не хочется заново это всё делать то есть оп- оптимизация тут производится скорее таким образом но мы можем просто получить другой вердикт и это Вполне может быть правильный вердикт там если товар уточнился каким-то образом и теперь он не матч пользователь раньше мог продавать Только серые носки условно теперь он добавил какой-то уточнение к этому цвету что это тёмно-серый если раньше это было о чём сейчас поэтому мы заново обойдём и вернём наш новый вердикт это важно фиксировать поэтому мы не удаляем Спасибо так и еще второй вопрос Вот почему при обучении а дистиллированной модели мы ее обучаем на mse loss а не на красноатропии Ну как бы кажется что здесь это было бы логично Ну что мы как бы 16 основная модель распределение мы предсказываем Ну и пытаемся научить дистиллированную модель предсказывать точно такой же распределение как бы смотри мы пробовали и так и так нам просто вариант SMS больше подошел просто так получилось Хотя первая идея естественно у нас была раз вам спасибо за интересный доклад и интересная проработанное решение У меня вопрос про Спарк если кратко Зачем из парк стриминг если детально как я понял поток данных о которых мы ищем матча вот этих мэтч данных он идет через кавку стриминг его вычитывает и обрабатывает для обработки он использует индекс Как часто этот индекс обновляется Когда подгружается и как Ну и собственно еще один вопрос А не проще ли было использовать сервис и какой-нибудь кассандру кассандру вопрос как почему и нам нужно было реализовать эту довольно быстро имея тот стек который мы имеем имея те знания которые мы имеем в моменте да а это ресурсы менеджеры во-первых Почему я на свой потому что это Сота то есть сравнение если посмотреть но почитать статьи посмотреть как он себя ведет с другими алгоритмами поиска ближайших кандидатов он находится на верхах постоянно это в пользу Почему спортс-стриминг Потому что у нас очень большой ходу кластер где возможности масштабировать очень много и у нас спорт стриминг достаточно обкатанная технология в этом смысле мы с ней очень хорошо знакомы Мы знаем как отлаживает это все а своими усилиями поддерживает там тут уже например силу или кассандру мы не можем А у нас промышленном применении силы Кассандры в Озоне нет если мы хотим иметь сымитировать словно кивали мы Для этого используем хитрый индекс и скорее в поисках но пост Господа задача не подошел поэтому Ну единственным аналогом который у нас когда-либо применялся это был бы ластик но у нас не было в моменте инженеров своих условно которые могли бы это дело поддерживать то есть такой ментальное Legacy просто не хотели меняться да да вот но с Парковый стриминг Просто он Хорош тем что он в применении не очень сложен то есть с одной стороны Кафка с другой стороны Кафка внутри на питоне можно написать функцию которая делает все что угодно с потоком мы туда поместили еще индекс который Да мы обновляем раз в сутки мы можем это делать чаще в принципе но обновляем раз в сутки без обновления просто создается копия ставится заглушка на старую и после перешли на новую модель новый индекс Старый индекс удаляется Окей понял спасибо"
}