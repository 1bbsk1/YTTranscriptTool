{
  "video_id": "Rl4jGw-9_Wg",
  "channel": "HighLoadChannel",
  "title": "Угнать за 5 миллисекунд / Николай Карлов, Олег Уткин (Mail.Ru Group)",
  "views": 3261,
  "duration": 3008,
  "published": "2021-10-04T02:47:08-07:00",
  "text": "религии то образе очень рад вас здесь слышит видеть сколько лет не проводили конференции наконец-то собрались это очень здорово что ж давайте знакомиться мы работаем в mail.ru в отделе архитектуры систем хранения данных мы займемся пилотированием проектированием и проверка гипотез реализации сложных систем с нетривиальными требований как по нагрузке так и по обработке данных олег уткин разработчик я главный архитектор сегодня мы будем половину времени в прощении сегодня будем половину времени говорить о постановке задачи в постановке задачи как принято в научную дерзких работах в общем начинаем прошлом году к нам обратились коллеги из московской бирже задачи разделения торговых ядер как правило разделения чего-то одного требуют консолидации чего-то другого и часто очень большого количества этого самого другого и здесь не исключение разделении торговых ядер означают что нужно консолидировать потоки данных из торговых систем и доставлять их клиентам мы с коллегами из московской бирже провели пилот он был успешным по пути мы собрали много кораблей много интересных выводов сделали хотели сегодня об этом поделиться но сфера давайте поймем что же такое разделить торговые ядра рождения торговая да фактически это возможность проводить сделки на разных торговых рядах по различным критериям в инструментом например одни валютные пары на одном торговом ядре другие валютные пары на другом или например можно конкретную ценную бумагу все все сделки связаны с ней проводить на отдельно торговым ядре часто требуется при листинге крупных компаний и почему это важно то есть очевидно что такие архитектуры на изменения требуют огромного количества усилий вот и должны каким-то образом окупаться вот для чего все это нужно но кроме того что это масштабирование то есть очевидно это масштабирование на запись можно большее количество сделок секунду обрабатывать также это минимизация рисков вот представьте себе выход на биржу очень крупной компании не знаю вот представьте себе какой-нибудь сбербанк будет выходить на биржу он уже этом есть ну представьте себе как будто бы он будет делать вот поскольку бирже так или иначе происходит много разных процессов то выход листинг ценных бумаг может там каким-то образом аффекте с другими процессами и вот соответственно для минимизации этих рисков чтобы сделка не сорвалось часто держит запускают такие вещи на отдельных торговых рядах вот я думаю что самая главная мотивация заделать вот главное требование были примерно такие клиенты не должны видеть что-то происходит то есть уже есть существующие протоколы трейдеры и брокеры каким-то образом уже эти данные получают не должно быть существенного изменения это в очень важное условие все должно очень быстро работать не добавлять дополнительные задержки а кроме того если вы что-то реализовывать это транспорта он должен масштабироваться и на чтение и на запись то есть не быть узким горлышком вот прежде чем мы двинемся дальше давайте обсудим как работает биржа очень буквально на на пальцах сперва мы определимся такая заявка или торгов ордер в общем-то это желание кого-то одного купить что то при каких-то граничных условиях эта заявка попадает в биржу биржевой стакан встречается с другой заявка которая там уже находится но если все срастается то получается сделка в результате заявка менять свой статус вместе с той с которой она встретилась и что-то происходит либо если заявка долго находится в стакане то сделки не происходит и инициатор может ее снять вот так работает мастер торговая ядра это одна поточное приложение которое занимает всю память на сервере и горизонтально масштабируется на чтение за счет реплик которые очень интересно построена фактически это такие же копия торговых ядер только на них направляются абсолютно такие же заявки в том же порядке и когда все хорошо а к правило это сюда именно так эти реплики фактически практически не отстают от мастер иногда даже опережают и они при диски сверяются почек суммам и они являются серверами доступа и к ним уже подключаются трейдеры брокеры для того чтобы рассказать о сложности этой системы в частности нужно упомянуть о том какие есть важные вещи поскольку мы в первую очередь работали с ордерами то есть торговыми заявками и именно их мы доставляли потребителем соответственно определим некоторые вещи с ними связаны первое этой это глобальные счетчики в бирже в торговом ядре есть счетчик который монотонно увеличивается при добавлении каждой новой записи очень похожи на первичный инкрементирование ключ это рик он же рекорд нам бы есть еще другой счетчик более интересно работает он увеличивается с каждым апдейтом который происходит на торговом ядре то есть если какая-либо заявка обновляется что-то с ней происходит этот счётчик увеличивается на единицу и эти два поля есть во всех заявках то есть можно себе представить как будто бы есть биржи таблица заявок и в этой таблице есть колонки рек и сек и эти колонки используются для того чтобы клиенты могли получать максимально свежие данные потери мы обсудим как они получают того чтобы понять как проектировать систему доставки нужно понять как это работает сейчас а сейчас работ следущем разом клиент имея пару рек acer то есть зная о том что бирже был какой-то апдейт с каким-то номером это то есть запись с другим номером эти знания у него есть он просит максимально свежие либо изменившиеся либо новые данные он их получает и берет из последней заявки следующую пару для писек используйте как канте новейший talking таким образом клиенты получают данные постоянным полингом они хотят получать самые свежие данные но без пропусков и здесь есть также запросы на чтения по вторичным плечом поскольку не все пользователи хотят видеть все данные не хотят видеть их только свои или только фирмы в которой происходит торговля или толь конкретного брокера и так далее очень теперь мы готовы сформулировать требования вот к этому черному ящику . той системе которая должна доставлять торговые данные первое требование это удельная производительность то есть на один узел система должна уметь принимать и до 200 тысяч транзакций в секунду при этом время которое проходит между тем как сделка произошла на бирже до того как клиента не узнал должно в среднем быть одна миллисекунда но вместо девяти процентов случаев должна укладываться в 5 миллисекунд вот кажется что это похоже на очередь вы действительно какие-то события происходят клиенты получают эти события но как вы здесь это не совсем так во первых биржа дает только только изменившиеся данные клиенты хотят целиком ответствен нужно отдавать состоянии а кроме того если клиент отстал на несколько микросекунд или миллисекунду тон появились более свежие данные касается на одной заявки и клиент не хочет видеть старых ведь самые свежие вот таким образом у нас должна быть производительность на один узел 200000 рпс отставание должно быть в среднем одна миллисекунда клиент не должен знать о разделении должен гарантируется порядок данных и даны должны отдаваться без пропусков теперь давайте прошу прощения почему-то не работает clicker очнитесь кажется компьютер завис вот вот и тут мы понимаем что на самом деле мы имеем дело одновременно с базой данных с очередью с индексами с каждым вторичными индексами вот и тут возникает мысль как это делать либо действительно сделай сам взять и реализовать целиком систему с нуля либо взять какой-то инструмент который обладает всеми этими свойствами то есть может быть очередью может быть очереди с индексами и может гарантировать в этом си мы предположили что или этой задачи может подойти тарантул поскольку он такой же однопоточный in-memory как ядро бирже написан на си имеет эффективный асинхронный протоколу с мультиплексирование фактически является фреймворком для того чтобы строить базы данных у него есть система хранения и индексации то есть вторичные ключи таблицы первичные ключи может хранить данные на диске их восстанавливать есть репликация шара деньгам что в целом кажется все сходится но есть нюансы вот и дальше мы как раз поговорим о том как мы подходили к этой задаче доход в общем поход доклада мы будем ввести некий такой счетчик целесообразность использования технологий будем давать совет очко если технология подходят и глобусу если это попытки притягивания за уши или чего-то другого лет тогда передаю тебе слово давайте я подробно расскажу о том одиторов из канализации первых давайте вспомним как у нас выглядит структура данных у нас есть два ключевых поле поля рек поле acer соответственно не означает номер заявки и номер изменения зачем эти поля нужны по сути эти поля позволяют клиенту богини руется по данным это обеспечиваются следующими свойствами а при каждом in сердце у нас цементируется рек а прикажем апдейте у нас комментируется acer вот таким образом когда клиент приходит заданными мы можем быть уверены что данные ему пойдут нужном порядке он получит самые свежие версии данных об ордерах и у нас не будет пропусков вот и чтобы понять как это рисовать давайте разберемся как работают составные индексы на вот таком примере простом вот у нас есть составной индекс состоящий из двух полей field 1 и фил 2 и допустим мы хотим выбрать некоторую запись который будет у нас сходиться по ключу два , три что нужно для этого сделать соответственно мы идем по первому полю ищем двойку и уже отсюда дальше двигаемся ищем тройку и причем такой прыжок у нас будет занимать его графическое время и найдя этот момент в яндексе мы можем дальше же продолжить 3 руется по данным как по связан омске списку поскольку у нас используется три деревья в которых все листы прошиты связанным списком то есть мы дошли некоторые места в яндексе дальше уже спокойно можем за константам время переходить к следующему элементу и как-то будет выбить нашем случае нашем случае как я говорил ранее у нас есть поля рисе крик на первое место мы ставим сек поскольку секу нас означает он означает свежих данных вот arekkz tenses test на второе место и вот у нас в яндексе лежит некоторые ордер мы хотим его обновить что происходит таком случае в таком случае у нас комментируется acer то есть из этого же орды прыгать дальше в яндексе и у нас не корректируется рек и соответственно мы уверены что теперь этот ордер находится самом конце индекса аналогичная ситуация со ставкой случай со ставкой у нас происходит что данные который приходит от торгов ведра в них будет всегда максимальный сег то есть нам будет просто достаточно выставить максимальный редкие также стоит данные и тогда в таком случае у нас появляется границы того что самые свежие данные у нас находится в конце индекса когда клиент придет вот сможешь проецируется на забрать данные которых у него еще нет вот и можно сделать вывод что в данном случае тарантула очень хорошо на подходит потому что в нем несколько возможность соответственно плюс совет вот теперь давайте поговорим об верхний уровень stick туре поговорим о том что мы вообще должны реализовать ну главное основное само хранилище данном случае у нас хранилище был аризона tarantul что она делает ну очевидно хранилища хранить данные и кроме того внутри себя она содержит логику обработки этих данных и кроме того нам ещё необходимо ли заводь эмуляторы торговой ведра эмулятор клиента зачем это нужно в рамках тестирования к сожалению у нас не было доступа к реальному стенду заказчика то есть мы не могли процитировать на реальных данных на реальных нагрузки от клиента поэтому нам нужно реализовать некоторых эмуляторах которые мы сможем использовать при локальной отладки вот так же эти мулиа тары позволяют нам собирать большое количество метрик и таким образом уже делать какие то выводы о производительности о том какие можно оптимизировать вот чего мы начали мы начали с максимально простой структуры по сути нас было всего две хранимых процедур и 1 player and просто принимает данные кладет их сторож и 2 процедура get ордер с которой эти данные умеет давать клиенту работать следующим образом клиент приходит с некоторым ключом как мы говорили ранее то рек и сег который означает в какой момент времени клиент становился читать данные и когда он все еще раз приходит с этим ключом он может быть уверенным что данные которые запросит во-первых будет свежее тех которым допрашивал до этого и данный будет идти в правильном порядке кроме этого если данные который приходится торговая ядра по сути это событие то есть это событие о том что допустим заявка была создана событие о том что cs заявка была удалена либо там как-то обновлено вот а клиенту даны уже идут видео конечно состоянии то есть клиент получает среднем давление которое было в торговом ведре вот и мы решили начать тестировать тестирует мы начали с нагрузки папа записи вот и как казалось таком случае у нас мы легко проходим в слое то есть если нам там нужно 200 тысяч про загса в секунду на запись то мы легко выжимаем больше двухсот пятидесяти тысяч и даже можем какой-то момент дойти до 340 вот вроде бы все супер инкрементируем еще раз сову но затем мы решили протестировать чтение и вот обнаружили какую проблему в какой то момент времени при увеличении количества клиентов наступает момент которые отставания клиента торгово ведра резко возрастает такой рост происходит бесконечное система уже не может из него вернуться происходит а вот почему потому что наше хранилище перестает успевать принимать данные с торговой ведра виду чего сильнее увеличит отставание клиент от него вот и мы решили дегустировать до инкрементируем глобус появились ник небольшие проблемы и мы решили исследовать эту проблему вот начали мы с того что хорошо бы нам очень наглядно мерить то на сколько стоит клиенты как и говорил ранее при генерации ордера в нем у него кладется время создания ордера и когда клиент получает может сравнить время создание когда и время когда он прибыл клиенты уже вот и он может дать система мониторинга не можем за этим следить вот и действительно обнаруживаем что в какой то момент времени нас появляется резкий рост задержки вот что вы сделали дальше мы решили посмотреть а сколько же цыпа употреблять тарантул и обнаружили что сетевой поток тарантула перегружен то есть данном случае получается что он уже не может адекватно обрабатывать не только запросы от клиентов но и данные которые будут выходить с торговым ведра причем есть еще странное наблюдение в таком случае у нас резко https клиента то есть клиента на это очень-очень часто ходить в нашу систему при этом в этом все таких запросов очень низки то есть мы можем сделать некоторый вывод о том что клиент ходит очень часто но при этом запросу не очень короткий возможно не получая данные возможно еще как проблема вот и тут у нас есть несколько симптомов у нас перегруженность в поток нас выросли резко gps и клиентов и клетки запросы стали очень короткими есть какие-то предположения что могло произойти происходит что кратко объясню как происходит обработка данных по сути обработку данных у нас происходит видео очереди в эту очередь приходит данные новые из торгового ядра затем клиент эти данные пытается вычитать и в таком случае все хорошо то есть клиент выбирает кит кусочки данных при этом чуть-чуть стоит от торгово ведра и с работы хорошим но есть отдельно случай когда клиент становится быстрее чем уже чем торгового ядро то есть он догоняет уже торговые ядро иначе из-за этого данные которые выбирают они становятся очень маленькими очень мало чем от записи из этого делать все больше и больше больше запросов тем самым сильнее нагружать систему и тем самым замедляя прием данных от торгово ведра тем еще сильней усугубляя ситуацию и нас происходит быть конечно роста вот почему пришли ну мы сделали вы что хорошо бы теперь начать чем мониторить какое количество пустых ответов мы отдаем клиенту мы померили и оказалось что таких ответов более смеясь процентов и связь вот этого роста количества простых ответов ног распадается тем моментом когда у нас происходит резкий рост задержки от крепки задержки лент торговой ядра и делаем вывод нужно минимизировать от количества почему мы пришли если раньше процедура обработки данных была максимально простой то теперь мы делаем вот что когда приходят новые данные нашу систему мы смотрим насколько эти данной свяжем и сохраняем самым последнюю информацию о самым последним ордер который прошел нашу систему и в таком случае когда клиент приходит с некоторым ключом можем понять что этих данных у нас может не быть в системе и в таком случае мы цепляем клиента и пока они придут новые данные либо пока не пройдет тайм-аут клиент будет ждать это очень удобно резать в tarantul и поскольку в тарантулов есть 2 то есть никогда подобия крутин с моей файбер и и есть конечно верю было который умеет выступить файбер и разбудить его его уже с другого то есть таком случае когда приходят новые данные мы можем просто из процедуры которая пишет данная его разбудить причем стоит заметить что когда клиент рассыпается ему не приходится продавать новый оператор может перед использовать его то есть данном случае у нас что продолжить итерацию нам не нужно заговорить логарифмическое время опять искать позицию таро таро в яндексе мы можем сразу продолжит это делать к чему это привело ну во первых у нас простых ответов почти не стало ввиду чего у нас резко снизит количество пакетов секунду то есть мы уже сильно разгрузили сеть и мы разгрузились свой поток тарантула самом деле более чем 15 процентов какой вывод мы это сделали то что число двойных данных это очень важно метрика и это нужно контролировать а чтобы контролирует нам нужно еще и мерить тогда мы решили собирать сколько данных у нас приходит клиенту это было очень удобно сделать виде тип мо по сути гистограмм по времени и вот здесь хорошо видно что пустых ответов у нас уже нет но при этом почти все еще очень маленькие то здесь видно что у нас пик находится единицы большая часть пачку нас размера 1 и хорошо бы этот пик сдвинут правее то есть увеличить размер пачки которые будут клиенты получать вот что мы этого сделали самом деле нам получилось даже упростить систему теперь функция которая принимать данные у нас возвратился начали состоянии она просто кладет данные хранилище а процедуры который забирает данные она делает select если на понимает что данных которые ей нужны нет или патч к которым мы должны отдать ей отдать клиенту она слишком маленькая то он засыпает и просто идет какое-то время сделать это снова и если мы укладываемся в отнести лет инси запросы может еще раз сделать в противном случае мы даем дан как есть вот и такой оптимизация дала нам очень хороший прирост размера пачки то есть если раньше у нас было около 1 1 записи пачки то теперь уже 20 а сколько времени ожидать приходилось ну это зависит от того насколько большую пачку мы хотим от зависит от того на сколько у нас какая-то размер пакета например то есть все эти данные можно подобрать экспериментальным как раз нам в этом очень помогает метре который мы собираем о расставании клиента вот торговый ведра ну и в том числе разве пачки вот и мы решили померить что же получилось таком случае и тут уже видно что при таком подходе можно накапливать достаточно щепочки там по 40 до 70 элементов вот и очень это очень сильно разгружает свой поток и при этом позволяет нам оставить watenshi очень низким вот еще одно очко в пользу совы тут понимать что это long polling но только в размере половины мили секунды то есть там сотня микросекунд приходилось ожидать чтобы приходили новые данные потом можно знать его short полинг каком-то смысле да вот и давайте дальше уже поговорим о том как сделать так чтобы мы могли спокойно разделить торговый дом на несколько кусочков несколько родов и при этом чтобы клиент не знал об это сложности сортирования и при этом сохранять порядок данных который будет ходить клиенту вот начинается все 20 вот с чего у нас по сути изначально у нас есть одно торговые дро и чтобы клиента получить данные ему нужен по сути один ключ чек и рек и он может спокойно поэтому кучу сбирать данные сдавала торгово ведра но когда он остановится 2 торговых кедра появляется проблема то что клиенту во-первых ему нужно знать в каком торговом ведре же данные и для каждой торговой дыра ему ну по сути попадется иметь отдельные ключ вот и что же с этим можно сделать во первых можно вести определенный суррогатный ключ да то есть чем он хорош тем что нам не нужно менять протокол то есть что бирже раньше использована можно дальше продолжить это использовать ничего менять не надо какие же есть минусы во-первых появляется либо единая точка отказа либо данное у нас согласованным а если согласован это работает это очень медленным и второй вариант что то придумать что то другое и мы решили использовать векторные часы почему это хорошо это хорошо потому что во-первых это скроет сложность шарден га то есть клиент достаточно знать какой источник а точнее иметь ключ который отдаст наша система и он слизь раз может стать выключаем прийти и дать этот ключ роутера и ротор уже сам определить в какой sharp нужно отправить дан какой шар данных забрать данные может быть из нескольких когти данных мер жить вот и таким образом это проблему можно легко решить при этом минимально изменив протокол из сохранить согласованность данных вот и как же тогда в целом у нас выглядит sharding ну во первых как мы говорили у нас есть нет несколько источников источники напомню это кусочки разделен на торгово ведра и эти кусочки можем какой-то своей лодке как мы хотим поделить на нужен нам шарды если хотим можем в по дублю на несколько шагов вот мы можем делать и реплики сколько угодно нам нужно реплик и таким образом очень гибко масштабироваться по чтению вот и тут стоит вспомнить что на самом деле у нас 2 вида клиентов первый вид это клиенты которые хотят получать некоторые подмножества данных фильтру его и получать данные с низкой задержкой это могут быть различные брокеры это могут быть трейдеры которым нужно допустим только какой-то определенный инструмент или там какие-то только свои заявки к примеру и есть второй вид клиентов клиент который не хотят фильтровать данные то есть они получают весь поток данных которую нас приходит торговая ядра но при этом им задержка минимально не нужно и что мы можем с этим сделать поскольку мы знаем что минимально задержка наши системе находится на мастерах мастером можем вынести клиентов фильтрации которые хотят минимально задержку и данных и получают только некоторые по множество а всех остальных клиентов которым фильтрации неважно и и мне нужен минимальной пенсии мы их можем вынести на реплику причем мы знаем что клиенты без фильтрации ну фильтрами естественно нужны то есть индекс в нем тоже не нужны таким образом можем сделать редки в которых не будет индексов и таким образом во-первых мы экономим на репликации поскольку данный переход на реплику я не нужно по этим данным строить индексы и мы можем сэкономить по памяти потому что индекс этим не придется хранить вот и с таким подходом нас получается следующее данным во первых на нас получается сохранить очень низкую задержку у клиентов котором она важна и делать это метод на того что большую большое количество клиентов можем вынести на реплики причем реплики у нас имеет некоторые расставания вот и как раз это нам позволяет поддерживать низкое время отставания клиент от источников при этом сохраняя среднее время состава него на миллисекунды вот какие оптимизации мы делали еще у нас есть некоторое тело ответа это ответ который приходит от нашей системы клиенту и вот как он выглядит у нас есть некоторые трассировка трассировка хранит в себе информацию о том как сколько времени какие операции хранимой процедуры происходили то есть это нам уже будет очень полезна во время диагностики системы будем понимать где у нас что медленно работает во вторых сюда же мы кладем самый последний курсор в пачке то есть клиент может взять этот курсор не читая данные дальше и сразу же делать следующий запрос и кроме этого мы еще читаем когда была создана самая старая запись пачки вот причем все эти данные находятся заголовки в самом начале зачем это нужно затем что чтобы делать следующий запрос клиента достаточно считает только заголовок то есть вот он считывает следующий курсор берет сразу делать запрос при этом не декодирует тело ответа до конца почему это важно как мы отвечали раньше тело одного ордера занимает около 600 байт то есть это уже много а у нас целая пачка там по 20 элементов может нам по 7 из элементов и таким образом чтобы клиенту прочитать сообщением нужно потратить задач большое количество данных а таким образом можем оптимизировать и давайте вернемся аккумулятором поговорим чуть подробнее о них зачем они нужны ну как я говорю ранее у нас есть два типа эмуляторов это эмулятор торговая ядра эмулятор клиентам что они делают ну во первых это торговая ядра он умеет генерировать ордера который дальше уже пойдут систем причем в этот ордер и он кладет время создания ордера таким образом когда это то ради придет на клиента мы можем почитать время за которое эта заявка прошла от торгового ядро бедра до клиента то есть все путешествие заявки по нашей системе а кроме этого аккумулятора торгово ядра умеет генерировать всплески то есть когда такое происходит что какие-то инструменты например начинает торговаться намного интенсивнее умеет сохранять нужную нам скорость генерации данных умеет считать с какой скоростью до не будет даваться на самом деле и все это давайте уже в prometheus что дед эмулятор клиента он также собирает большое количество метрик том числе и собирает ресы который у нас приходит из самого хранилища тоже их и дает приготовил считает размер пачки вот и таким образом можем проследить как у нас целом работа система кроме этого есть еще отряд метре который у нас находится самом хранилище танг канада является сделать он во первых смотр собирает данные о том насколько нагружены его потоки по циpкa собирают различные метрики о хранилище в том числе там время скорость вставки апдейтов селектор замирает с какой скоростью растёт таблица и также все это дает вот и как я говорил ранее тестировать мы начали не у клиента а на своем личном стенде то есть у себя и в этом не было проблемой мы могли удобно использовать sealine и эмулятор виде семейных туров это ну нам это было удобно но затем нам же потребуют протестировать систему на стенде заказчика при этом прямого доступа к этому стенду нас не было нас был человек которым мы говорили пазу мы могли ему давать какие-то команды то есть мы пришли к выводу что нужно это как-то оптимизировать и таким образом эмулятор такого ядра обвиняется в один им нет некий демон который умеет автоматически паникую никому конфигу никому профиль нагрузки запускать нужных источников на нужную аккумулятор друга ведра и нужных эмуляторов клиентам вот и как мы можем сделать в комплексе как мы это делали у нас есть некоторые полные описания как должен выглядеть теста как должна выглядеть конфигурация кластера как должен быть как должны быть настроены эмуляторы ну клиенты из и торговая ядра и можем просто с помощью от конфига полностью разделяет систему и запустить тест и то есть человек на другом конце про достаточно сильную команду которая полностью все раз диплом это запустить тест но только остается отдать данные которые накопились примите оси и дальше все эти данные мы можем уже у себя дашбордов удобно анализировать то есть по сути у нас есть полная картина всего что происходит в кластеры во время теста и давайте подведем итоги что нам удалось сделать ну во первых нам удалось добиться того что система умеет принимать 200000 транзакции секунда на один узел на запись при этом у него хорошая задержка клиент никак не зная это разделение не знает сложности сортирования как наша система устроена внутри данные клиент удается нужном порядке причем эти данные без пропусков и клиент всегда получают самые актуальные данные и что не менее важно наша система умеет быстро давать не только холодные данные которые тур горящие дано которые только пришли потоково но и холодный данных пределах минуты или пределы определен сегодня вот что в итоге ну во-первых мы успешно literally архитектура лен систем доставки торгуй информации с помощью тарантула вот и пилот заказчиком был признан успешным и будущем будет дальше развиваться и это еще один плюс советовали куются можем сделать вывод что наш инструмент который выбрали для реализации задач он подошел почти идеально кого мы тут обманываем покажи настоящий счет да вот так лучше не все так было гладко гораздо больше было подводных камней мы не коснулись например того что любой компонент мог отказать и требовалось дать ответы и протестировать а что будет если откажет торгово ядро а что будет если откажет сервер практически там любая часть инфраструктуры вот но на это бы не хватило бы никакого времени поэтому в общем на здесь есть кое-какие выводы первое это если возникает какая-то проблема прежде чем завершает надо научиться измерять вот и выиграть находить ту метрику которая коррелирует с моментом возникновения проблемой только так можно хоть что-то решить можно несколько недель биться над тем что что-то не работает но пока нету метрики бесполезный от решать свою систему он уже строить итеративно от самого простого на самом простом как правило возникают самый банальный ошибки и в том числе самые сложные и необычный и потом уже систему можно масштабировать ответив на вопрос а как вот один экземпляр себя ведет и дальше уменьшается количество возможных путей куда систему нужно развивать важно мерить все бизнес метрики начинаю вот в этой задаче сквозное время прохождения через систему важно мерить различные технические метрики например стинга и петров для того чтобы смотреть число пакетов в секунду смотреть утилизацию различных потоков и так далее то есть это все очень важно и важно чтобы это все было в одном дашборде чтобы можно было видеть корреляцию того что происходит вы видите что у вас увеличивается количество пакетов в секунду вы видите что вас растет потребление сетевого потока вот видите здесь растет количество запросов можно сделать гипотезу но бежать чинить не надо надо найти еще одну метку которая бы эту гипотезу подтвердили бы опровергла это очень важно важно понимать алгоритм и как работают в данном случае мы описывали b плюс дерево мы смогли складывать данные так чтобы все свежие данные то есть это либо те которые были обновлены либо те которые были вставлены были в конце дерева это позволило нам сделать iterator который будет идти по этому дереву как по связанному списку это очень эффективно также когда нужно добиться высокой скорости низкой задержки иногда полезно делать замедление это кажется таким вроде бы очевидным моментом но если этого не делать то можно наступить на очень любопытные грабли как например клиенты могут перед получать ошибки приходить еще раз до их нужно каким-то образом замедлять и для этого либо circuit breaker используется либо можно искусственной задержки вставлять само приложение и несмотря на то что нам нужны доли миллисекунд задержки при высокой производительности пришел к нагрузке мы все равно клиентов замедляем это очень эффективно работает и эффективно работать вместе с объединением с контролем того как сколько мы записи клиентам отдаем вот и это очень важная вещь она позволяет минимизировать количество походов по сети и сэкономить довольно большое количество процессор на во времени вот и здесь так же важно не бояться тестировать разные инструменты в ходе этого пилота брали в тест совершенно разные инструменты разные версии не только тарантул и мы смотрели как что работает и в итоге мы выбрали именно тарантул потому что он подошел лица за счет такой фреймворк да и собственно говоря спасибо за внимание будем рады ответить на вопросы да олег николай смысле большое давайте тогда вопросы важно у нас есть вопросы как здесь такого онлайне а в плане тоже и стесняйтесь задавать если кто-то все-таки осмелится за сегодня выйти на экраны с дома то мы будем очень этому рады за лучший вопрос как обычно вручим книжку так что вы тоже видите какие вопросы мы сдаюсь это нужно запомнить так придется память тренировать здравствуйте не зато alexander ayzenband такой вопрос то есть какой-то мент вы решили разделить своих клиентов на тех которым важно получать ответы с низко лотностью на тех которым это не важно во-первых вопрос как вы планируете на продержать клиентов между теми которым важно задержкой не важно 1 так сразу на него есть хорошо на самом деле клиентам которые являются трейдерами и брокерами важно задержка регулятором например и администраторам она менее важно потому что они обрабатывают различные ситуации уже отложено спустя секунды хорошо тогда другой вопрос оценили какую нагрузку вас гниют клиенты категории какие категории у него очень разные профили нагрузки клиенты которые получают все и и сленг полингом то есть они очень сильно нагружают когда они отстают потому что они начинают в художник попытках догнать данные вот клиенты которые с фильтрами они нагружают немножко по-другому они нагружают одинаково сильно и когда они находятся в мейнстриме то есть для них данных чуть-чуть и когда они в конце и причем они нагружают сильно еще в том числе потому что там используются дополнительные ключи они имеют другой порядок они медленнее работают но если не проверить гипотезу что вас пять процентов клиент 50 нагрузки но я скажу так что те которые с фильтрами поскольку для них данных меньше они нагружают меньше в целом чем те у которых получают с той же частотой все данные по силам большое спасибо за доклад у меня два вопроса первый вот у вас клиенты они делают геты то есть они работают через полинг это вызвал вот проблема то что их надо иногда замедлять потому что они общем не знают когда geht es para да не думали перевернуть эту систему и на пушат сделать вместо вместо половины нету почему думали это это в планах мы там есть другие сложности клиенты могут переставать успевать обрабатывать и забирать данные и там можно упереться в сетевой буфер какие-то данные потерять и любая схема уши всегда имеет rollback виде гетто потому что клиент может что-то пропустить и до получить поэтому как бы эти любом случае необходимый функционал и потом мы помним что у бирже есть на самом деле через youtube и различные протоколы которые отправляют данные без каких-либо гарантий возможностью восстановления то есть надо понимать что этот конкретный транспорт нужен для определенных задач , допустим не раз не распространение сделок для блюмберга ли reuters и это не хайд рейтинг то есть это нечто что посередине то есть это подключение брокеров и трейдеров то есть фактически людей которые используя там эти данные какие-то дела пишут роботов или руками торгует то есть поэтому здесь ну и плюс неготовность наверное вот там самих компании которые эти данные получают и ходить иного протокола то есть там все довольно консервативно в целом фанов такое есть что это кажется более эффективным и понял спасибо очень интересно а второй вопрос вот вы сказали что там таргет и по задержке это 5 миллисекунд и там миллисекунды на 99 person силь а как считается задержка наоборот в среднем одна миллисекунда августа 9 5 считается от момента того как в торговом ядре сделка совершилась 0 изменилось заявка до момента как клиент ее прочитал то есть к нему пришел пакет с этими данными а на каких новых физически time stamp доберется то есть же разница между моментами с темпами и я просто веду по вопросу как вычислить экранизируются вот я рисовал слайд с серверами доступа to set a сиять с сервера которые практически на микросекунду консистентные с мастером вот на них как раз громко запускается таймер то есть к этому серверу доступа пишется модуль на на плюсах который пишет в таранто вот вот в этом месте происходит замер то есть момента гог того как вот мы собираемся эти данные отправить в socket систему доставки до момента когда клиентская библиотека уже на сервере клиента эти данные прочитала но да но получается что вот один таймс там берется вот на на этом сервере а второй все равно на сервер и клиент а как вы же не можете просто взять разницу между time с темпами на двух машинах там же на часы синхронить взяток в тестах они синхронизировались до микросекунд то есть у бирже есть железки на сетевой карты кота позволяют это сделать естественно если клиент находится в другом то центре мы не можем гарантировать времени это ненужность для colocation должны быть такие примерно там требования если в нету они естественно не такие то буду валяться твой задержка он спасибо большое здрасте спасибо за доклад вопрос такой вот вас там был насладись тезис роутера которого штиль изолировали это были отдельные узлы прошу прощения не расслышал встретились роутеры которые были у вас на арте в турне диаграмме это были отдельные узлы которые вот муж these равале на разные ядра это были развернуты на том же сервере узлы таранто монет просто было интересно почему бы не запихать в клиентскую либо на самом деле здесь есть определенные сложность в том что в таком случае мы вынуждены позволить клиентам ходить ко всем этим шар дам по сети и открывать доступ и то есть в этом случае раскрывается внутри не топология который можно в течение дня меняться и не хорошо я вот так чтобы клиенты вынуждены были перри конфигурируются довольно сложно понятно в цифрах там до 200 тысяч дтп с на запись там еще персистенции делался на даст пирсе стильность но вот мои например добивались того чтобы в одном узле хранилось от 50 до 100 гигабайт данных соответственно сверх этого мы сформировали какой протокол использовался для стерилизации там самом деле два один из них место чпок то есть я значимые поля по которым происходит фильтрация и правила выборки они вместо шапки для того чтобы можно было их учитывать бизнес никаких tarantul и остальные части не интересны для бизнес-логики запакованы просто фиксированном тонкую структуру и фиксируем про таком то есть продавцы какие-то были поверх этого там если например перезагрузить реплику таких запись традиционная до санкционное торговое ядро отправляет пачку транзакций в одном эти себе пакете и все отправленные пачки применяются атомарного традиционно спасибо у меня еще вопросик спасибо за доклад скажите пожалуйста а как ваша архитектура учитывают финансовые риски или считается что клиент может только читать данные но и писать может еще раз повторить пожалуйста интересуете на новые риски ведь клиенты могут как получать данные от биржи так и формировать поручение дам на покупку на продажу неважно вопрос как это учитывается схеме далее схеме точить не нужно потому что создание заявок это связь с помощью уже существующих механизмов есть речь идет только о раскрытии информации ты столько о получении информации об ходе торгов но не создание заявок до или крики других сущностей правильно понимаешь что данная система позиционируется как замена века не совсем замены квк это другой проект который мы обсуждаем с биржей здесь скорее фтор на mustang я пойду спасибо"
}