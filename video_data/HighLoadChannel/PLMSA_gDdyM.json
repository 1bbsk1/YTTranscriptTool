{
  "video_id": "PLMSA_gDdyM",
  "channel": "HighLoadChannel",
  "title": "Что нужно знать об архитектуре ClickHouse / Алексей Зателепин (Яндекс)",
  "views": 55993,
  "duration": 3062,
  "published": "2018-01-16T12:20:15-08:00",
  "text": "идея доклада довольно проста что если каким-то инструментом пользуешься или собираешься пользоваться то желательно хотя бы В общих чертах Представлять что там внутри происходит Да чтобы каких-то неправильных решений избежать и принять правильное решение вот такое понимание про кликхаус постараюсь сегодня донести немножечко вас значит знакомство я на самом деле хаусом занимаюсь недавно вот до этого я несколько лет работал в Яндек картах был прикладным разработчиком много там работал с базами данных с постгрес сом вот поэтому как бы я ещё вирусом Хауса не сильно заражён Вот я ещё помню что это такое быть прикладным разработчиком но в принципе довольно ро понимаю ха продакшене Так ну кое-кто есть а кто раздумывает я вижу кто-то и использует и раздумывает Понятно Так а кто вот вообще никогда не слышал что такое Хаус услышал из моего доклада только ну пару человек всё равно есть Так начнём сразу с задач на самом деле я вот дуй док бы предыдущий докладчик очень хорошо ВС рассказал Вот то есть кха это не база специального назначения везде её пихать не надо но Спектр применения достаточно широкий он как бы выражается вот такой формулой У нас есть некие события они постоянно приходят вот я тут выписал какие-то примеры там вот Яндекс Метрика это сервис для которого изначально создавался там какие-то действия пользователей на сайте дальше там реклама финансовые транзакции там покупки в магазинах что угодно или вот у нас Наши Любимые пользователи - это Cloud у них ДНС запросы Вот они по ДНС запросам строят аналитику Вот и мы значит что хотим с этими событиями сделать Мы хотим о них сохранить информацию и что-то о них понять потом то есть построить какие-то отч аналитики на них Поре что-то потом понять А ну как бы любой система которая задачу решает у неё есть какая-то идеология то есть что создатели системы что для них было важно А чем они готовы были поступиться да а что ну чем они готовы были пожертвовать А И как грубо говоря какие жертвы принести вот для кри Хауса самое важное - это интерактивные запросы что это такое Это значит выполняется за секунды А лучше меньше секунды вот Ну почему это важно как бы во-первых Яндекс Метрика Да когда она показывает отчёт пользователь не будет ждать если он там больше секунды загружается Вот Но даже если вы как аналитик работаете с Клик хаусом А с базой данных да вам очень важно Очень хорошо если ответы на запросы тут же приходят Вот и вы тогда можете их много задать Вы можете не отвлекаться А вы как можете прямо погрузиться в работу с данными это очень ну другое качество работы вот язык запросов у нас SQL это тоже плюсы минусы вот плюсы в том что как бы SQL декларативный и поэтому щем простой запрос его можно очень хорошо оптимизировать очень оптимально выполнить Вот Но как быги прово форма данных КАТО с помою не задать вот поэтому там у нас куча каких-то расширений очень много функций дополнительных вот Ну и конечно преимущество что SQL все аналитики знают всем очень привычно вот очень популярный язык дальше стараемся ничего заранее не агрегировать Вот то есть когда какую-то такую систему делаешь очень велик Соблазн сначала подумать Какие У мня отчёты нужны такой такое такое и как вот я буду у меня события поступать я их буду потихонечку агрегировать и когда э нужно будет показать отчёт я быстренько Вот это всё покажу вот ну есть проблема такого подхода Да что если вы два события а слили вместе са агрегировать то а вы уже их ни в каком отчёте больше не различить всё они у вас вместе поэтому в общем чтобы сохранить гибкость стараемся всегда хранить индивидуальные события сырые И заранее ничего не агрегировать Вот ещё очень важный пункт который требуется вот от прикладного разработчика который работает с клек хаусом а Нужно заранее понять значит вот у вас события Какие у него есть атрибуты нужно их самому выделить вычленить и уже вот эти атрибуты запихивать в лекха то есть какие-то жены в свободной форме или там текстовые блобы вот которые Ну вы просто берте там они как есть их пиете и там надеетесь потом распарсить вот так лучше не делать что ну иначе у вас интерактивных запросов просто не будет Вот ну и сразу возьмём пример да сист аналитики Значит у нас есть счётчик который мы на сайт ставим он идентифицируется колонкой Counter ID вот у нас есть таблица Hits в которую мы складываем Ну просмотры страниц и есть там ещё колонка refer Ну и ещё что-то куча всего там 100 атрибутов вот очень простой запрос ТМ группи по рефе считаем сортируем по канту и первые 10 результатов показываем вот запрос нужно выполнить быстро Да чтобы там во всяких бенчмарках потом было там 100 раз быстрее по как это сделать во-первых нужно вая организация то есть храним данные по столбцам по колонкам это нам позволит загрузить только нужные Столбцы то есть в этом запросе это три и и то есть я сказал там ещ Может быть 100 вот естественно если мы их будем все загружать Да это всё нас очень сильно затормозит дальше пос локально Вот то есть что это такое во-первых Конечно мы не хотим всю таблицу читать поэтому Нам нужен индекс Вот Но даже если мы читаем Вот эту вот маленькую часть которая нам нужна для Ну скорее всего какие-то данные для одного счётчика вот нам нужна локальность чтение то есть мы не можем по диску прыгать взад-вперёд А ну искать вот эти вот данные которые нам нужны для выполнения запроса Ну и обязательно нужно конечно данные сжимать потому что ну как бы они в несколько раз сжимаются и тоже э пропускную способность диска очень сильно экономит Вот и после того как мы данные прочитали нам нужно их очень быстро обработать вот в Хаусе там много чего для этого делается самое главное То что он обрабатывает блоками Что такое блок блок - этоша такая Вот почему это важно потому что хау - это интерпретатор Мы все знаем что интерпретатор это очень медленно Вот бы привычно но если мы вот этот охд размажет сч строк то он будет незаметен и зато это нам позволит инструкции для блок подняли в кэш там его обрабатываем Вот то это будет гораздо быстрее чем если он куда-то там в память будет проваливаться Вот и очень много низкоуровневых оптимизаций я про это не буду говорить Ну как пример там вот у нас г простейший Да он там есть 17 алгоритмов которые в зависимости от данных их кардинальность выбирается самый оптимальный так прос базах данных классических выбираем смотрим Какие условия будут в большинстве запросов у нас в нашей системе аналитики скорее всего это будет счётчик то есть хозяин счётчика будет приходить смотреть отчёты и дата то есть он будет смотреть отчёты Да за какой-то период времени или может быть он за всё время существования захочет посмотреть вот поэтому такой прове что он подойдёт значит сортируем таблицу мысленно по cid и смотрим наши строки которые нам нужны они занимают вот такую небольшую область которая ну то есть там без дырок каких-то вот небольшая область Это значит что индекс подойдёт он будет сильно ускорять Вот Но есть у хаусов индекса инно в отличие от Ну привычных индексов во-первых таблица будет действительно упорядочена по ключу физически Вот то есть а ну в других системах ещё называет cled Index значит такой индекс на таблицу может быть только один вот и второе что Несмотря на то что мы его называем первичный ключ он а не обеспечивает уникальности Ну просто нужно это помнить дальше значит как работает индекс во-первых что нужно понимать то что он разреженный то есть он не индексирует каждую строку в таблице а он индексирует каждую там десятитысячная первичного ключа записано для каждой 8192 строки по умолчанию вот такое значение Мы предлагаем оно в принципе хорошо работает вот и когда у нас этот индекс есть при выполнении запроса что мы делаем мы должны выбрать строки которые нам могут пригодиться для выполнения запроса вот в данном случае поскольку Нам нужен счётчик 1 2 3 4 и дата с 31 мая а вот тут только есть запись на 23 мая вот это знат что чия с прочитать и до счётчика до записи которая уже начина счётчик 1 2 3 5 то есть тут что получается что мы будем читать немножко Больше записи чем нужно вот и для аналитических задач Когда у вас как бы боль Ну много нужно строк прочитать на самом деле это нестрашно но Елим нуж какая-то од строка тобот не так хорошо то есть чтобы найти одну строку там вам придется 8000 прочитать вот дальше Вот наши эти Столбцы в которых лежат данные их нужно они упорядочены по вот тому же выражению первичного ключа и теперь из них нужно составить вот этот блок который будет потом в Хаусе обрабатываться для этого есть вот такие мы их называем файлы засечек которые содержат указатели на значения соответствующие строкам первичного ключа то есть чтение Как происходит значит понимаем Между какими значениями первичного ключа находятся интересующие нас строки по файлам засечек в каждом столбце Понимаем что нам читать читаем и дальше собираем блок и дальше он пол по конвейеру запроса за вот что тут Важно то есть ещ раз сценарий будет плохо работать потому что вот у меня тут светло-серебристый ке в столбце достаточно большие Вот например ну там не знаю может быть 100 бай а может быть там пара килобайт Да вот то вот это одна засечка которую вы читаете Да она может занимать довольно много вот поэтому ЕС у вас данные значения в столбцах большие имеет может быть смысл вот это вот значение чуть-чуть уменьшить а то есть вот эту гранулярность индекса вот идём дальше я вот сказал что таблица упорядочена Да но не рассказал как это сделать вот а нам очень хочется чтобы когда данные поступили в кха Они тут же были доступны для отчётов то есть после инсерта там типа секунда прошла и вы уже их видите в своих отчётах Вот и тут есть проблема потому что данные поступают упорядочены Ну примерно по времени да то есть события за последние какие-то там несколько минут вот а нам нужно по первичному ключу то есть по счётчику вот а событие поступает как раз по счётчикам перемешаны и соответственно нужно как-то их переу порядок предлагается такое решение двик табли идея примерно такая же если кто знает лсм дерево То есть у нас есть небольшое количество упорядоченных кусочков вот если их становится много мы берём несколько кусочков и из них делаем один таким образом поддерживаем каждый раз небольшой количество вот Ну примерно как вот это происходит вот у нас по иксу номер вставки Ну то есть это грубо говоря время да в котором вы вставляете по игре ч лю поступили данные новый бач вот там зелёненьким обозначено не упорядоченный Что делат Ха Он прежде всего их сортирует и потом записывает на диск появляется новый кусок Вот что тут важно что данные из вашего ирта они сразу попадут на диск Вот то есть буферизации какой-то не будет И поэтому индивидуальными записями будет очень плохо писать есть как бы средства Да там какие-то буфер таблицы в кликхаус которые позволяют это снизить эту проблему но всё равно нужно делать ставки большими кусками Да там раз в секунду мы рекомендуем как минимум 1000 записей вот иначе очень много будет езды по диску и всё будет очень плохо работать вот поно Потом доставляли значит нужно количество кусков уменьшить вот этот процесс происходит в фоне называется слияние или Ну тут в принципе Понятно У кха единственно есть особенность что слияние происходит только с кусками которые были вставлены подряд Вот то есть в нашем случае мы вставили на предыдущем слайде который был вставлен под номером N п1 мы берм их сливаем и получаем новый кусок от до n П 1 упорядоченный вот что тут важно что этот процесс происходит в фоне и за ним очень обязательно нужно следить потому чтото пот слишком часто вставлять и он не будет справляться то рано или поздно всё сломается вот в случае с хаусом как это будет выглядеть когда у вас будет на партиции А партиции - это месяц 200 кусков то у вас внезапно затормозит вставки вот таким образом Хаус попробует дать возможность слиянием догнать вставки Вот а если уже будет 300 кусков то он вам просто запретит вставлять потому что иначе данные будет тяжело очень прочитать из множества кусков вот поэтому А если будете использовать кликхаус обязательно вот это монитор вот настройте в кликхаус экспорт метрик в графит очень просто делается Вот и следите за вот этой метрикой количество кусков в партиции максимально вот если оно большое там вам нужно обязательно разобраться там у вас может быть что-то Дим или начали очень сильно вставлять и вот это нужно тут же чинить Ну всё хорошо Значит вот у нас есть сервер кликхаус всё работает вот но иногда его может не хватать Ну само банально данные на один сервер не поместились Вот Но это не единственный случай Например можно уко добавив компьютерм ластер кли Хауса стал таким популярным что очень много одновременных запросов Вот они начинают мешать друг другу вот просто нужно ещё железо добавить А что предлагает кликхаус пошарить данные использовать дистрибьютор таблицы Что это такое Ну шардирование понятно Вот у вас есть какая-то таблица и вы ставите несколько компьютеров шардов и на каждом компьютере часть этих данных а вот у меня на картинке они в таблице Local Table А дальше что такое дистрибьютор таблиц это такой View над локальными таблицами то есть сама она данные не хранит Вот она просто выступает таким прокси который отправит запрос на локальной таблице в принципе Вот её можно создавать где угодно там хоть на отдельном компьютере от вот этих шардов но ну стандартный такой способ это просто создать на каждом шар Тогда просто Приходите в любой шард и задаёте запрос значит что она делает Вот пошёл запрос Select From distrib Table она возьмёт его и перепишет distribute Table на Local Table дальше отправит на все шарды сразу же вот шарды запрос обработают причём они его стараются обрабатывать до самого конца практически вот Чтобы поменьше данных по сети передавать Вот то есть если у нас есть какая-то агрегация то эта агрегация будет частично проведена на Шарх они отошлю частично агрегированный результат на дистриб таблицы дистрибьютор таблиц уже сольёт и отправит полный результат пользователю вот такой забавный бенчмарк значит чуть больше миллиарда строк это данные о поездках йоркского такси То есть в принципе они в открытом доступе лежат можно самого попробовать вот ну посчитаем Там любой запрос вот тут Что тут у нас а средняя цена в зависимости от количества пассажиров Ну типично аналитический запрос вот ну на одном компьютере чуть больше секунды значит если мы Три компьютера доставим то в три раза быстрее вот если у вас есть 140 компьютеров как у нас например можно эти данные разложить по 140 компьютера они запрос вообще будет быстро выполняться То есть за э там несколько миллисекунд вот Ну конечно это уже не рокрайдер там уже начинают играть роль но всё равно то есть э запрос можно прямо ускорять до самого конца Вот как теперь Э раскладывать данные по шардам вот во-первых самый простой вариант и в принципе мы его рекомендуем это взять и вручную разложить по локальным таблицам потому что вот дистрибьютор таблица когда она делает запрос она не задумывается о том как данные Поша Она просто спрашивает у всех шардов одновременно вот поэтому Главное чтобы данные не были задули да иначе у вас там ерунда начнётся В результатах вот а так можете сами Как Вам удобно как вам чтобы всё было равномерно раскладывать данные по шардам но в принципе дистриб таблица Она и сама Это умеет делать но как бы есть несколько нюансов Вот во-первых запись асинхронная То есть если вы вставили в дистрибьютор таблицу она данные отложит куда-то во временную папочку Вот и дальше будет ПТА вставлять ей нужен ключ шардирование Вот она его посчитает разделит на три Ну там в принципе веса можно задавать выберет шарт и вставит туда а что тут важно что ключ шардирование в принципе он можно его даже Рандом взять Вот это тоже будет работать Единственное что если вы хотите какие-то делать сложные джоны Да и вы хотите чтобы у вас данные которые для Джона нужны были на одном шар тогда вам уже нужно задумываться о ключе шардирование Ну ладно вот есть у нас пластер Хауса большой быстро работает но иногда ломается Вот то есть иногда там диски с боят вот не хочется данные терять Вот и иногда просто там катока ют постоянно их тоже Нельзя терять то есть доступность должна быть на чтени на запись вот Ха предлагает для решения этой проблемы асинхронную мастер Маер репликацию которая работает на уровне таблиц то есть ну в принципе на сервере у Вас могут быть и реплицируемый таблицы и нереплицируемый значит как работает Короче это полный Хао и они вот тут изображены те же самые куски о которых я говорил предыдущей части презентации То есть тут в принципе понимание остаётся такое же то есть Это частично сортированный кусочки данных и реплики стараются вот этот набор кусков у себя синхронизировать друг Между другом вот при этом может происходить три типа событий чит вставка в реплику ч это одна реплика скачала кусок с другой и ж то есть э реплика взяла несколько кусков и слила их в один вот вставка Как происходит Значит вставляем на любую реплику то есть вот тут видно что реплика оди она в принципе не самая хорошая Вот но на неё всё равно можно вставить Вот и информация о вставке записывается в то есть для того чтобы репликация работа К сожалению Плохие новости пристать при этом Полный порядок на вставка вс-таки поддерживается То есть у вас все реплики Они видят вот эту одну один и тот же набор кусков и они видят в нём какие-то дырки которых у них нет и они пытаются их заполнить с помощью фе вот дальше ещё нам нужно выполнять мжи сливать куски жи нужно выполнять согласовано ибо кусков Разойдутся для этого ре мастером потому что масте это сразу ассоциация что вы только туда можете вставлять но это не правда Вот то есть у нас реплика 2 Лидер она вот решила что эти куски надо поржать записала остальные реплики об этом информацию получат и тоже сделат такой же МЖ при этом реплики они не так они выбросят кусок и заново скачаю Вот То есть в принципе пытается поддержать набор данных байт идентичным Вот это тоже место Нужно мониторить обязательно вот как у вас идёт репликация какае отставание чтобы не дай бог не сломалось Ну и как бы любое обсуждение репликации Да оно упирается в кап теорему То есть если у вас есть место где вы можете читать и писать вы его реплицируемый репликации Да там тот же постгрес вставляете данные в одну реплику на второй реплике они там Ну через пару секунд может появится А может через больше Вот Но как бы есть Зелёная звёздочка хорошие новости можно включить вот то есть указать настройку при вставке при чтении и тогда чтения будут консистентные Вот но Конечно вы за это Заплатите производительностью вот доступность доступность почти есть Вот то есть Как сделать такой неубиваемый кластер кликхаус берте значит три локации Три дата-центра З В трх а реплики как минимум в двух вот тогда если у вас одна локация взрывается Дант отключается то всё продолжает работать и на чтение и на запись вот тут часто спрашивают на самом мне в двух дата-центра сделать в двух не полу потому Вот то есть если у вас только две локации да то вы какой-то дата-центр объявляете главным и значит если не главно отключается то у вас всё продолжает работать если главно отключается то у вас только на чтение Вот но доступность Почему почти есть почему красная звёздочка вот строго говоря вот такой полной доступности нет Потому что нельзя записывать вр если он вас кипера То есть если это три НОД то есть от двух НОД отключён тогда вы не сможете него записать ну можете прочитать ничего страшного будут немножечко отстающие данные дальше вот эти две фичи Да dist таблиц и таблицы они в принципе независимы То есть их можно Независимо использовать но они очень хорошо работают вместе Вот то есть вот нормальный хороший кластер Хауса мы его примерно так себе представляем то есть вот у нас есть N шардов и каждый из них двукратно А лучше трёхкратно конечно реплицировать Вот и дистриб таблица она умеет понимать что вот это шард это реплики отправлять запрос только в одну реплику шарда и умеет отказ устойчивы То есть если у вас какая-то реплика недоступна она в другую пойдет вот и умеет то есть вот ещё один способ побороться с конн Да с отсутствием конн если у вас можете задать какую-то максимальное отставание То есть если ри табли пришла рабо в принципе на сегодня ВС значит ещ раз коротко Что такое Ха это столбцом база данных которая позволяет выполнять очень быстро аналитические интерактивные запросы язык запросов это S с расширения нет да потому что у нас разреженный индекс если вам нужна одна строчка то вы как бы много лишнего прочитаете и если у вас Да с какими-то большими бми это вообще будет плохо работать вот ну линейно масштабируется если шардирование активным коммьюнити вот Ну спасибо задавайте вопросы либо сейчас либо сейчас либо вот в один из каналов социального взаимодействия многочисленных Да здравствуйте Меня зовут Дмитрий Спасибо за доклад ничего нового А а есть вопрос про дублирование данных собственно я так понимаю по крайней мере пока я так понимаю что в кликхаус нет никакого способа решать эту проблему её надо решать на этапе вставки правильно или всё-таки есть какие-то методы которыми Мы можем побороться с дублированием данных у нас в базе значит дублирование данных откуда оно может возникнуть вот если у вас э значит вставляй Да который вставляет данные он отказоустойчивый да ено Вот и когда он начинает ть например отключился а он продолжает в это момент конечно может возникнуть дублирование данных но в оно не возникнет как Значит от этого мы защищаемся вот э вставка блоками тут настра но 100 неплохой вариант вот поэтому если вы вставили блок у вас что-то взорвалось вы не уверены вставили Вы или нет да Вставьте ещё раз вот если вставка прошла то Хас это обнаружит и не будет дублировать данные То есть если мы вставляем скажем Ну по 10.000 строк у нас там будет храниться миллион строк который будет нро неб дублирование Ро а в смысле получается кусок который мы вставляем он 10.000 строк Вот соответственно Значит мы можем рассчитывать что по идее последний миллион как бы у нас не будет дублировать Да если мы захотим повторить Да но только если вы вставляете прямо такими же блоками Вот то есть то есть идентичный блок Да идентичный блок для него там считается чекс сумма Если чекс сумма совпадает значит блок уже вставили и дублировать не надо Угу я понял и вопрос второй меня вот интересует запрос таб таблицам Я так понимаю ну Собственно как вы сказали запрос у нас идёт только к одной реплике можно ли как-то настроить чтобы какие-то тяжёлые запросы шли на обе реплики то есть чтобы часть данных оттуда часть данных оттуда каким-то образом доставалось Да можно так настроить То есть это значит ещё один способ за использовать больше компьютеров есть специальная настройка по-моему называется Ma вот и что она делает она в общем половину данных обрабатывает на одной реплике половину на другой но сразу оговорюсь это работает только если использовать если при создании таблицы был указан ключ сэмплирования Вот то есть в Хаусе есть ещё такая фича сэмплирования То есть вы може пос запрос по всем дам а по 1 скажем да тогда если у вас э в реплицировать ключ сэмплирования то э значит при указании вот этой настройки Max parallel replicas он сообразит что можно 1/2 данных посчитать там и другую половину на второй реплике и вот а будет использовать обре Ну если что он концентрирует там 1 1 де и всё Ну если вы не указали СМЛ да Вопрос был вопрос был значит не будет ли ещё раз сэмплирование да прочитает ли все данные Если вы не указали при запросе СМЛ Вот то сливания не будет то есть он просто это использует для того чтобы разделить работу по двум репликам понял спасибо спасибо за доклад у меня вот три вопроса вы говорили что индексы вот размазаны да там 88.000 чего-то и нужно писать большими объёмами существует или вы используете какую-либо пред буферизацию то есть или вы рекомендуете что-то использовать Ну на самом деле конечно больной вопрос Да потому что все норовят по одной строчке вставлять вот у нас вот в метрике например да там на самом деле очень умный батчер Да который там отдельная команда разрабатывает которая там много дополнительной работы проводит вот поэтому естественно в кликхаус его нет Вот что есть есть так называемая буфер таблица куда тоже вот по одной строчке Не надо вставлять Да потому что будет тормозить там на каких-то на какой-то ерунде Вот Но в принципе она вот если вы туда вставляете она по диску меньше ездит да то есть о не бут на каждую вставку прямо делать запись на диск Вот И очень многие которые более серьёзно уже подходят к кликхаус они используют кафку например вот то есть у вас в кафке ЛОК э вот вы ваш ваша писалка берёт а записи ивки и вставляет их в кликхаус тоже хороший вариант Ну да То есть можно можно это вручную настроить А ещё Вопрос вот у нас есть distributed таблица Да которая вот у нас управляет всеми шарми а вот смерть этой таблицы Да вот она где-то на своём шар вот этот шард с дистриб таблице и умер это значит все данные у нас умерли Ну дистрибьютор таблица она не хранит ничего То есть если она у вас умерла то вы просто создаёте заново и всё также работает Главное вот сохранить вот эти Local Table в которых собственно данные лежат поэтому конечно их нужно реплицировать Если всё серьёзно и последний вопрос Вот вы ещ говорили можно так вручную там реплицировать е или шарди кае нцис несь туда вот это всё Вот соответственно отменить Как ещё раз если но какие-либо транзакции при ручном шардирование Да я же пишу на Три разных шарда нет если вот какой кусок данных вам прил вы его должны на один шарт записать то есть вот только на один чтобы не было дублирования данных вот в одно место записали всё хорошо а просто я должен хранить где-то куда я записал и вот не обязательно это всё хранить потому что именно что дистриб таблица она спрашивает все серверы все шарды вот то есть а если бы в принципе когда вот у вас уже 500 серверов как у нас да то уже начинает этого не хватать потому что на 500 серверов одновременно не прикольно ходить вот поэтому у нас там такое двухуровневое шардирование второй уровень он уже знает куда он положил данные вот и он на это обращает внимание Да но в принципе этого ну вот до 100 серверов за глаза хватает То есть просто во все серверы сходить и забрать результат обратно Да спасибо большо да Как изменять Данные есть там возможно можно ли как-нибудь чего-нибудь применить целиком вынести и заново закачать то есть чтобы не целиком с нуля всю таблицу Угу А значит Да можно изменить целиком блок но не блок а всю партицип очень приоритетная задача то что у нас будет произвольные партиции Вот то есть вы берёте Говорите alter Table Drop Partition вот Он убирается и вы можете обратно залить данные вот предыдущий докладчик тоже хорошо ВС рассказывал как тоже самое делается Вот и ещ есть кейс да Когда у вас Ну какие-то данные которые нужно вот подв скажем вот они есть да И они немножечко изменяются в реальном времени последни данны то есть Вот например там не хиты у нас да есть а визиты пользователь то есть пользователь он пошл там на одну страничку на другую у него там длина визита раст вот в Хаусе для этого есть такой движок называется 3 Вот и на не очень удобно пользоваться но эту задачу Он решает То есть Вам что нужно вам вот эти последние визиты которые вы хотите изменять вам нужно хранить Вот и когда вы хотите что-то в НМ поменять Вы записываете две записи Первое это грубо говоря Удалить предыдущие предыдущую запись и вторая - это записать новые данные вот и Эта таблица она где-то у себ в фоне это всё будет компактизация на две точки А не натри то проще поставить каку и с не провеса не парится Ну когда два центра а третьего например нету ну такой реальный сценарий когда вот 2 DC есть а третьего только под это дело поднимать не хочется мы всё-таки рекомендуем Ликей таблицы Почему Потому что вот дистрибьютор таблиц она тоже на самом деле умеет реплицировать Как repc сделать как по на три на два ДЦ не разнести то есть тогда всё равно у меня в результате получается что у меня в некий момент если падает мастер у меня писать никуда нельзя Можно только читать и или там какие-то простые способы там СВ сделать мастером а потом догнать первый мастер до Сва Подожди а с кавка у вас как кавка А с кавка Ну как я буду вылизать вливать каждую Независимо один упа Ну с какой там всё равно придётся делать на три неё данных меньше надо но она только там на пару дней это будет хранить а не за всю историю то есть в кафке просто гораздо меньше ресурсов Ну чтобы как локально хранилище в не в общем на 3 дешевле чем ха на 3 Хаус сам не обязательно размазывать на три вам только нужен зуки по а зупер только А всё то есть только для кворума киперс то есть данные дублируется только два раза можно всё нет тогда для коров ус есть Т Вот и Почему ещё вот мы рекомендуем именно таблицу а не просто вот в две таблицы запихивать потому что очень много проверок происходит то что данные именно идентичны вот если так будете записывать самостоятельно или вот через стриб таблицу легко получить какое-то расхождение Да и потом оно уже никогда не исправится потому что ну всё записали и до свидания там Непонятно разошлось Не разошлось вот а реплика таблици они непрерывно вот пытаются поддерживать вот эту общность Да и Единый набор кусков вот там был вопрос СБО Давайте задам вопрос касаемо утилизации памяти как наиболее эффективно распределять её сколько под инстансы выделять Угу про память такая история что в Хаусе есть настройка Max Memory usage да то есть это сколько вообще вы можете отъе когда обрабатывайте запрос Для чего ещё нужна память память нужна под дисковый кэш то есть там нет какого-то хитрого кэша Да который некоторые вот системы Как делают Они читают Оре с прямо с диска Вот и как-то у себя кэширует Хас так не делает то есть какую-то часть памяти довольно большую нужно оставить под дисковый кэш То есть у вас данные которые недавно читались диска они потом будут из памяти прочитывать Вот И какой-то там ну не знаю может быть треть Да вы отводите на память которая именно нужна в запросе значит ха Для чего расходует память если у вас запрос такой как бы стриминговый просто пройтись и что-то там посчитать например да то будет от единиц памяти расходоваться вот где может понадобиться Память Когда у вас груба с большим количеством ключей Вот то есть например вы там вот по тем же самым рефере что-то группируется да и у вас очень много различных рефе урв они вот все эти ключи нужно ранить если вам хватило памяти то хорошо Если не хватило то есть возможность груба выполнить на диске Вот Но это конечно будет гораздо медленнее а это он сам определит нужно включить Ну а всё равно какой-то есть объём который вы рекомендуете там зна 32 гиб на ноду эктив когда использу болу 128 в принципе Нор и полностью вот один ин все 128 Да да конечно он их все за использует хорошо Не ну просто мало ли Конечно если у вас данные не такие большие Да там вот сколько там гигабайт Да вот сколько данных столько и памяти берите Вот Но если у вас данные уже в память не помещаются то Чем больше тем лучше будет обычно да Такой вариант рассматривается Алексей спасибо за доклад такой вопрос а вы не смели проводите при сильной фрагментации файловой системы Ну я сейчас конкретных цифр провести не могу конечно такая проблема есть то есть когда диски почти заполнены да то файлы уже как бы они не так расположены локально Да там начинается вот эта фрагментация просто нужно следить Затем что у вас не сильно запол дис ЕС запо ноду ставить конкретных цифр к сожалению не могу привести Ну примерно порядок хотя бы ну не знаю там процентов до 70 нормально будет спасибо а Добрый день а у меня будет два вопроса А насколько я знаю сейчас хау у него только штп интерфейс для обмена данными с клиентам А есть ли какой-то roadmap чтобы сделать бинарный интерфейс на самом деле история такая что у нас есть два интерфейса Да это http который Ну можно как бы любым http клиентом использовать который jdbc драйвере используется Вот и нативный Интерфейс Да который мы всегда считали таким приватным вот и не хотели для него какой-то библиотеки делать пото что мы его изменяем иногда Вот Но интерфейс этот не такой сложный протокол там и мы поддерживаем там прямую обратную совместимость вот поэтому как бы добрые люди пошли просто использовали исходники как документацию и вот в Я слышал отличный драйвер который нативные клиенты используют Ну и вот для c+ коллега сде тоже отдель дра Котово интес и вам не нужно Скажем так ликова со всем Клик хаусом Да чтобы его использовать Ну и для не знаю там каких-то других языков тоже наверное есть точно не знаю вот то есть как бы формально мы его считаем нашим приватным но по факту он уже публичный то есть из некоторых языков им можно пользоваться Спасибо и хотел узнать написали свою систему репликации данных достим и она использует для репликации данных она делает реплика самостоятельно другие альтернатив системы Почему репликацию Чем она лучше допустим чем интересный вопрос Ну она лучше тем что вот как развиватся посло с в таблице потом появилась для них репликация и вот вот эта схема с кусками которые мёрт вот она м ну просто так на hdfs она не ложится наверное То есть наверное можно было бы использовать hdfs просто как файловую систему и там хранить куски но как бы проще как бы на локальной файловой системе это делать не знаю напрямую не сравнивали Ну ещё раз как бы вот нам нужно чтобы вот эти сния кусков они тоже были неотъемлемой частью репликации то есть какое-то Готовое решение использовать по-моему для этого нельзя може один кусок это будет один блок на ИС будет если это возможно Ну есть исполь уже реплицировать каза устойчивость Угу Ну а когда читать придётся читать-то Мы хотим с локального диска Ну раз поддерживать локальное чтение То есть вы можете узнать на каких нода хранятся данные и течение запускать там где они хранятся Угу Ну интересная мысль Надо подумать Угу спасибо К сожалению время подошло к концу Давайте попло Спасибо а"
}