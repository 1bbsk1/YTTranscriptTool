{
  "video_id": "Fle3i1OzsWc",
  "channel": "HighLoadChannel",
  "title": "Решение задачи автомасштабирования сервисов в Яндекс.Облаке / Рюрик Крылов (Яндекс)",
  "views": 517,
  "duration": 2799,
  "published": "2019-05-15T04:13:32-07:00",
  "text": "всем привет меня вот рюрик крылов я делаю облака яндекс индекс облака это не только инфраструктура состоящая из дисков виртуальных машин с файловых стара j баз данных балансировщик of но и средства автоматизации управления всеми этими ресурсами и одним из таких средств автоматизации занимаюсь непосредственно я я разрабатываю сервис instance групп который автоматизирует работу с виртуальными машинами то есть занимается артист рацией дипломанта виртуальных машин и масштабированием кластера горизонтальным масштабируем кластеров в автоматическом режиме к сожалению сегодня не смогу рассказать про процесс дипломаты про оркестрацию этот отдельный прям доклад но я сконцентрируюсь на авто спиллинге и расскажу как она работает внутри основная цель чтобы понимали что внутри это работает довольно просто там нет никакой чёрной магии и чтобы вы могли это использовать и быть как бы уверенными что она работает просто собственно доклад будет начнется с начну с того на расскажу примерно зачем все это нужно то есть какая-то мотивация к использовав то скиллинга имена вами затем углублюсь и расскажу как работает отказ клинг внутри то есть наша архитектура из чего все это состоит и как мы принимаем решение о спиллинге инстансов отдельно углублюсь еще сильнее расскажу про метрики потому что это основа на чем of the steering собственно базируется и затрону еще одну тему важную связанные с of the skin это мульти зональный deployment то есть дипломант в несколько дата-центров собственно зачем нужен авторский эллинг представьте что вот вас есть балансировщик и под ним несколько инстансов виртуальных машин довольно стандартный сетап кто кстати плодиться виртуалками так же довольно много а кто тепло и ца контейнерами в больше отлично ну смотрите есть просто кейсы где полезной виртуалке где полезные контейнеры вот и соответственно те кто для кого облака это новое что то кто в облака придет и самое главное в яндекс в облака потому что этот продукт именно работает в яндекс облаке он не чуждо им это не open source как я уже сказал вот тот захочет использовать instance группы и авто скиллинг для удобства работы с виртуалками так вот у вас есть такой простой сетап есть балансировщик под ним несколько виртуальных машин группу этих виртуальных машин мы называем группой инстансов виртуальных машин или просто install группой вот такое вот название так вот вы решили за деплоить сервис свой и посчитали сколько одна виртуальная машина может держать нагрузки предположим ваш обстрел показал что одна виртуалка тащит 1000р псы вы хотите за деплоить сервис в ну который выдержит нагрузку до 10000 рпс что вы делаете делаете из нас группу в 10 виртуальных машин деплоить и запускаете получаете вот какое такое распределение что отсюда можно сказать что там видно циферку в 10000 да то есть вы примерно при рассчитали свой кластер на нагрузку в 10000 а реально нагрузка половина времени там была сильно меньше а часть времени вообще 1 insa хватило бы с головой чтобы обслужить и получается что вот вот это вот все вся вот эта зеленая зона это ваши просто потерянные деньги то есть вы выделили ресурс ресурсов на действий черкес а реально пришло там меньше тысячи ну или да то есть вот просто визуально по графику можно увидеть что половина ресурсов проставилась соответственно примерно половина выплатили зря вот хорошо было бы чтобы нам чтобы можно было использовать только sensas а сколько нужно но это еще полбеды потому что график показывает вам прошлое то есть что было раньше но он не говорит что будет дальше и а дальше может быть что то такое то есть ситуация когда вы рассчитали что вот он максимум 10 тысяч ужину точно хватит всем оказалась то пришло еще больше и тут мы нарушаем из целей мы теряем request и мы как следствие теряем пользователей и конечно же в сумме в снова теряем деньги и если зеленые зоны то где мы теряем деньги уже наши кровные заработанные но вот эти зеленые та красная зона это где мы теряем деньги еще не заработанные вот ну понятно да of the spelling нужен тебе поняли соски ринг нужно ну собственно расскажу теперь как он работает чтобы вы не боялись его использовать глазами авто скиллинга является метрики и мы выделяем два типа метрик первый тип не только эта нагрузка на группу мы их считаем снаружи то есть метрики которые мы целиком снимаем со всей группы это например request a persian пакет с персиком с балансира или срок put измеряемый в мегабайтах персиков и второй тип метрик те которые мы собираем с каждого конкретного инстанса например ну в данном случае будем говорить про европу первый тип метрик мы собираем таким образом мы на load balancer устанавливаем наш агент нашла bells это или требовать что было понятно на него мы установим наш агент который смотрит сколько проходит пакетов через него отправляет эту информацию на агрегатор авто скиллинга у нас там лесбор идется многого количество балансиров на балансе у нас нами ни один из здесь визуально это как одна сущность просто выражается собираем эти данные агрегируется и уже в понятном в компактном виде отдаем сервисами из групп который принимает решение что нужно сделать увеличивать количество инстансов и либо уменьшать во втором случае мы устанавливаем агенты прямо наверно на виртуальной машины ну и точнее говоря мы их ставим на гипервизор и в которых установлен виртуальный машин и они собирают метрики с виртуальных машин не изнутри виртале начинается рядом то есть пользовательская виртуальная машина она не аффекте c да то есть туда мне нужно пользователь ничего устанавливать соответственно эти агенты собирают значение циpкa отправляет на агрегатор там все это дело считается по формам которые дальше по покажу и уходит services group который также принимает решение что делать увеличивать кластер либо его сужать ну еще раз про когда у нас есть нагрузка на группу мы считаем просто берем всю пропускную нашу способность делим на то количество запросов который может обслужить один instance округляем вверх и получаем требуемое количество инцестов это самая простая схема вот для примера вот у нас есть поток 3200 rp с мы его делим на сколько вот у нас 11 готов тысячу обслужить получаем сколько 3,2 инстанса но мы еще не научились деплоить дробное количество инстансов ну поэтому мы вот решаем округлять их диплом 44 солнца и они уже выдержать нашу нагрузку а во втором случае мы берем циpкa со всего кластер а то есть каждой машины у суммируем и делим на торги циpкa который мы хотим на 1 машину в норме это там какое-то значение уровень там 80 например там процентов если мы хотим хорошую утилизацию и вот на примере вот у нас есть предположим кластер из трех машин в среднем на каждой машине порядка 40 процентов сейчас мы хотим чтобы у нас было где-то 80 процентов но вот мы делим 128 получаем полтора инстанса ну опять мы полтора не умеем 22 кругом но почему 2 ну потому что один это было бы слишком много до 120 на сколько там ну если бы он был бы один там было бы больше 100 процентов до а если она 2 инстансов получится 60 процентов всего ближе к 80 чем сейчас 40 вот в обоих случаях у нас есть эффект округление вверх то есть мы все равно чуть чуть берем запас но потому что если мы уменьшим на вот последнего ты ты скажем добавляем если мы уменьшим его да мы ну получим уже перегрузку поэтому вот зеленая вот это вот округление показывает она говорит вот пред показывает некоторую эту избыточность в ресурсах но эта избыточность конечно она не сравнима с тем что мы имели на первых мотивационных графиках и здесь вот эту зеленую зону ну в общем ее можно игнорировать если количество инцестов очень большое то процент этого это зеленая зона будет очень маленьких количествах маленькая то стоит просто подумать о уже образом его вертикально масштабирование может быть сделать инстанса чуть чуть поменьше чтобы получить эффект уже масштабирование ну собственно давайте про метрики поговорим потому что вся вот эта история кто рассказал это общее скажем так представление механики и динамики которая работает вокруг instance гроб ну вот вот это интуитивное понимание что она вот-вот тут мало тут она сделает больше тут много она делает там меньше а вот на практике все несколько сложнее и вот чтобы чуть-чуть понять про практику здесь хочу показать как мы обрабатываем метрики вы смотрите во первых любая метрика которая нам приходит она приходит в довольно шумном виде то есть мы каждую метрику если мы будем прямо на основе ее принимает решение то мы можем сильно с масштабироваться сразу вверх или вниз и но это будет просто лишнее движение до поэтому в первую очередь любую метрику нужно усреднить в данж просто вот есть график который показывает request per second это же самый график на усредненный в окно окно в минуту мы видим что график более сглаженной и его использовать просто просто лучше а вот дальше мы немного по-разному работаем с метриками которые мы получаем вот балансира который нагрузка на группу и с метриками которыми получаем изнутри дело в том что нагрузки который на бал сбалансируют они нам дают прямо сразу хорошее решение то есть мы видим какая нагрузка мы точно знаем какой мы хотим на instance и мы точно знаем сколько количество инсов здесь прямо все просто а вот когда мы снимаем циpкa тут посложнее и вот вот тут мы провели серию тестов и сейчас покажу что вы получили то есть тест выглядит примерно так так у нас есть один сейчас instance на него подано нагрузка такая что он там по моему порядка шестидесяти процентов циpкa сейчас на нем и мы хотим смажьте чтобы классе у нас масштабироваться с одного intenso до 10 ну то есть мы увеличим нагрузку в 10 раз и ожидаем что он ну масштабируется до 10 а второй раз мы подадим снова нагрузку увеличив его два раза из масштабируем с 10 до 20 вот такой тест собственно запрограммировали запустили ожидаем что вот получится так и получилось вот так но как думаете какие тут проблемы есть ну сразу бросается в глаза что у нас за чем-то слишком много of those келлер добавил инсов причем смотрите он в принципе работу выполнил с 1 до 10 на сафонов масштабировал из десяти до двадцати он тоже с масштабировал то есть ну в принципе рабочие но зачем было масштабировать слишком высоко зачем было добавлять лишние нас и которые потом удалять и вот причем и и на маленьком и на большом скерри одна и та же ну чтоб понять почему это произошло надо понимать жизненный цикл виртуальной машины каждый раз когда мы диплом виртуальную машину она проходит несколько стадий на практике их на самом деле больше ново для целей вот этой презентации я оставил только основные вот 5 в состоянии deploying иди letting происходит работа под системы компьют то есть базовая инфраструктура и облака которая создает виртуальную машину она подсоединяет сетевой диск подсоединяет ну собственно выделяет ресурсы на гипервизор и и поднимает виртуальную машину в состоянии удалить ему происходит все то же самое в обратном порядке это все разбирается в промежуточных состояниях собственно происходит работа виртуальной машины где поднимается состоянии starting поднимается операционной системы и пользовательское приложение состоянии shadow собственно это все выключается состоянии running происходит собственно прием уже пользовательского трафика и наш подход был собственно в том что мы в состоянии running собираем метрики кстати если интересно как мы приходим между этими состояниями мод можно будет потом обсудить отдельно с вопросами а здесь мы состоянии running собираем метрики и получается тогда же когда у нас приходит трафик пользовательский это значит что мы запустили виртуальную машину а балансировка работает так что ну вот или три балансировка она работает так что она посылает одинаковый трафик на все машины instance группы ну те которые состояний running и получается только что созданной а машина принимает принимает трафик такой же но работает менее эффективно чем все остальные почему она это делает менее эффективно потому что там происходит прогрев к шее там прогрев там нет компилятора ну как как какая-то стартап активность еще не за не завершены до это может длиться там условную там допустим одну-две минуты в зависимости от от сервер может может больше и в этот в это время instance обрабатывает то же самое количество запросов нори портит большее потребление циpкa соответственно когда таких инстансов но воссозданных много по сравнению с тем количеством листов которые уже уже прогреты они портят статистику потребления циpкa умри портя больше и в сумме получается что авто skewer думает что слишком мало инстансов надо больше чтобы вернуться к тому самому таргет значению которую мы хотим достигнуть и то что мы видели на графике взлет а потом уже когда они все прогрелись она возвращается обратно собстна как с ним бороться ну да и достаточно простое решение мы просто выделили дополнительные состоянии то есть состояние в котором он и нас прогревается мы его учитываем в тех формулах там где мы вот делим там одно на другое но мы не собираемся его метрики чтобы не портить статистику вот и собственно мы взяли этот подход до имплементировать и его применили и получили такой график с проблему горбов она ушла но он остались какие-то еще здесь проблемы вот я расскажу про них что бросилось в глаза вот смотрите такие полочки на графике то есть везде где у нас графика растет масштабирование у нас есть такие небольшие полочки вот стало интересно почему откуда взялась эта задержка это феномен объясняется очень просто дело в том что у нас каждый раз когда в тоске ли добавляет инстанция машин он нового созданный с и находится состоянии deploying и либо starting что они в этот момент не принимает трафик из них не собирается метрики а сколько времени это занимает но это занимает вообще старт машин в облаке занимает примерно там бренне одной минуты подъемного воинственно понимали некоторых случаях это можно время уменьшить там до полминуты ну вот порядке пример таки и старт пользоваться кого приложения ну сами знаете сколько занимает там старт вашего приложения у кого-то это секунду кого-то это минуты кого то может быть и значительно больше и вот это все время инстанции не выполняет полезную работу не участвуют статистике а циклов то скиллинга он более частой то есть of the skin не запускается каждые 15 секунд и каждые 15 секунд он проверяет состояние кластера в данном случае мы добавили машину она не поднялась еще через 15 секунд мы проверили состояние метрики мы получили те же самые количество машин под балансировкой то же самое то есть принял решение of the screaming ровно то же самое добавить то же самое количество машин но так как они уже добавлены он их не добавляет поэтому палочка это когда просто of those келлер принял то же самое решение что на предыдущем шаге то есть по сути не не повлиял никак а как только прошло некоторое время новый инстанции стали присылать новые значения статистика поменялось и новый шаг поднял собственно до следующих значений но остается вопрос а почему вообще мы здесь наблюдаем вот эту всю итеративно если взять например от балансировку подсчетов тоске лиц по балансировке там у нас четко известно количество трафика входящего то есть нагрузка и сколько один из он станет и мы в силу линейности формулы сразу делим 1 на 2 и получаем количество инсов если мы применили бы вот здесь вот ровно это мы бы получили бы вот ту самую 1 играть картинку сразу хоп из одного 10 инсов все хорошо а здесь так не получается почему ну приведу пример чтобы было понятно если мы возьмем например один instance на нем сейчас предположим 80 процентов циpкa показывает а мы хотим чтобы был на в кластере 40 процентов циpкa как мы это сделаем мы добавим еще один из нас будет два инстанса в среднем по 40 циpкa на них то есть это интуитивно понятно что надо делать а что если у нас для той же самой задачи на одном инстанции сейчас сто процентов циpкa как вы думаете если мы добавим к этому ин сон су еще один у нас там станет 50 далеко не факт а если 2 добавим что там будет то есть мы столкнёмся с такой проблемой что когда у нас инст он когда у нас цикл в полку мы не знаем реальную нагрузку мы знаем что эта нагрузка выше чем чем вот то что мы можем померить и вот в этой ситуации мы здесь применяем такую спекуляцию на самом деле мы как только видим саппов полку то есть значение близко к процентам мы считаем что типа у нас равно 150 процентов то есть просто эмпирический по такое значение просто что она в полтора раза больше и это дает нам чуть большую сходимость то есть мы быстрее с гелем с условиях неопределенности быстрее гелем наш кластер вверх но вот во втором случае мы тут стали наблюдать артефакт такой смотрите то есть мы немножко здесь перестарались и добавили инсов даже больше чем нужно было вот мы стали думать что с этим делать ну потому зачем нам лишние мы уже видели там лишнее и снова стали думать и гадать и решили ничего с этим не делать потому что ситуация здесь такая что представьте себе у вас есть кластер да и вдруг у вас на нем сцепу в полку сто процентов что вам делать вот ну добавить много инстансов или добавить мало инсов вот в одном случае вы добавите много инсов ну и там потратите сколько там денег но потом вы уже буквально через две минуты это историю разберете вернетесь на нужен от на целевые на нормальные значения либо же вы добавите инсов малой уже начнете терять трафик прямо сейчас и вот мы решили что это такая ситуация когда лучше лучше перебдеть чем не дадите добавить инсов иисуса больше и решили что вот этот вот коэффициент полтора в условиях неопределенности это хорошее решение и лучше с ним остаться вот ценой вот такой так таких эффектов но надо сказать что когда of those когда скиллинг когда нагрузка увеличивается плавно той скиллинг происходит плавно то есть этой ситуации когда у вас просто одномоментно трафика в раз два раз два раза и да и то есть такой эффект может быть но он совершенно не обязательно будет в естественных условиях ну и еще что здесь мы заметили это вот эти вот флуктуации вот это пила на графике справа причем заметьте она есть справа на ее нет слева что это такое вот предположим как бы вы не считали метрики как бы вы хорошо их не усреднять вас все равно есть пограничная ситуация то есть когда вам нужно плюс-минус 1 in stores ну предположим of the skin говорить нужно 9,9 инстанса но это значит а нужно 10 до мы округляем наверх а в следующий момент нужно 10 и 1 это уже 11 toy совсем чуть-чуть а добавляем целый incense а следующий момент снова девять и девять совсем чуть чуть снизили и нужно убрать уже один из за то сюда есть пограничное состояние когда мы между вот этими коридорами целых чисел просто переходим с одного из заново в другой и чтобы мы не делали всегда такая ситуация остается при любом подходе а почему моя справа видим а слева нет а потому что естественная deviation в нагрузке она показывая она выражается в процентном соотношении и если в 20 инстансах этот процент уже больше и он переходит через вот это вот границу а в районе 200 инсов он просто меньше и он оказался в данном тесте просто внутри коридора если бы у нас была бы здесь стоит софтом было бы еще больше бы флуктуация было бы и там уже бы прямо по несколько инсов было бы это пила вот почему это плохо потому что когда мы добавляем - как уже я на четыре раза сказал он в это время ничего не делает он не обрабатывает трафик он ну толку от него никакого нам бы хотелось бы до чтобы они сразу были подняты и когда мы его удаляем это же некоторое время там разбирается снимается пока балансировка вот это все тоже ничего не делает и тоже только деньги наши тратить поэтому добавлять и удалять из вас постоянно это плохо и здесь мы просто применяем в контакт такую задержку удаления то есть математически это как звучит что на мы берем все принятия решения of the screen газа период применяем к ним окно конфигурируем пользователем обычно там 10 минут и авто скиллинг должен сказать такое количество емцев требуемое чтобы она удовлетворяла нагрузки последних 10 минут вот а на практике это выглядит просто так если мы целимся вверх мы съели мся сразу то есть ну как бы без без без вопросов потому что ну трафик пришел надо его обслуживать эти скинемся вниз мы не торопимся сразу убирать иисуса подождем все успокоилось а стакане лась ну как бы снизили вот ну давайте еще поговорим про мультизональной of the spelling когда у нас есть deployment несколько дата-центров та же самая история у вас есть балансировщик под ним несколько единиц iso виртуальных машин но вы решили deep ловится сразу несколько дата-центров ну вообще это крайне рекомендуется делать потому что как известно виртуальной машины могут выходить из строя и поэтому вы де плоть сразу несколько не только для того чтобы обе обслужить какой-то большой трафик но для того чтобы обсудить hail ability и с такой же целью вы деплоить из несколько дата-центров чтобы в случае какого-то кошмара уметь пережить выход зоны из строя ну да нас учит это центра обычно когда вы деплоить из несколько дата-центров вы используете aver provisioning то есть если у вас есть x ресурсов то есть виртуальных машин вы деплоить и еще 50 процентов этих же ресурсов для того чтобы при выходе 1 до зоны у вас трафик переключит переключиться на остальные 2 2 дата центра и количество ресурсов в этих двух будет расчет на ну такой же как как-то расчетное значение до того как вы добавили 50 процентов инстов но на примере у вас было значит по 4 часа в каждом dc до всего 12 вы вместо этого за тепло или по 6 in солнца в каждом dc то есть в двух тоже 12 ну здесь вы просто тратите в полтора раза больше денег чтобы вот пережить вот это вот достаточно редкую ситуацию есть еще подход когда мы агар прореживание делаем в две зоны то мы вообще должны резервировать плюс сто процентов чтобы выход одной зоны на спецназ охране и сохранил количество из этого достаточно для обслуживания от начального трафика вот как тут поможет of the spelling но смотрите если зона выйдет из строя то ну во первых на нее переплетаем попадать трафик если при этом сохранится связанность то из нас в этой зоне будут будут удалены of the scanning начнет сужать эту зону потому что там нет трафика а остальные две зоны он будет увеличивать потому что до пойдет больше трафика там либо повысится циpкa либо вот это вот метрика с балансира начнет увеличиваться из тестов тоске link просто увеличить количество инстансов что это нам дает ну собственно сохранение тех самых 50 процентов денег потраченных на виртуальной машины ну конечно это не бесплатно не смысле что сервис instance гроб стоит денег он абсолютно бесплатный и платите только за виртуальной машины а таким подходом вы можете платить за немного за качество дело в том что в тот момент когда трафик переедет вот в эти две зоны у вас там количество инцестов недостаточно для того чтобы обслуживать этот трафик это время когда пока инстанции создаются этот трафик будет куда-то деваться зависит от того как набью написано приложение либо будут копиться буферы либо будут реджекты пользователям либо и то и другое но в конечном итоге это все восстановится буквально за минуты то есть если без оверпара визинга и выпадение зона вы бы просто стали бы терять например треть трафика в течение там долгих часов то здесь вы потеряете просто в течение там пару минут 10 как бы стартует приложение вот но при этом вы не будете платить плюс 50 процентов денег за это по сути вы это как бы некоторые дом вы сами выбираете насколько здесь для вашего бизнеса там это критично и можете здесь пожертвовать немножко чтобы чтобы что то получить вот ну хочу резюмировать я постарался рассказать вам кейсы с авто скиллингов где это нужно и почему это позволяет сэкономить деньги вот как как как минимум два случая с с мультизональных dc из общей нагрузки меняющейся по времени и собственно немножко показал внутренность как это работает для того чтобы все таки была у вас понятие и спокойствие попова того чтобы это достаточно простая вещь внутри и это не то что взорвется и просто съездом все ваши деньги а у нас сейчас все это находится во внутреннем тестирование в облаке вот вчера я не докладе рассказывал что мы это активно дак судим все сервисы облака использовать сервисы облака и это уже используется но совсем ближайшее время мы планируем запустить закрытое альфа-тестирование в котором в которой мы приглашаем всех вас вот участников конференции highload мы готовы раздать вам промо-коды у нас настойки для того чтобы подключались в тестировании ну кто пользуется и кто хочет пользоваться яндекс облаком нас есть промо коды на яндекс облака кто захочет использовать еще в дополнении к этому инсцес группы у нас есть промо коды на instance группы вот давайте улучшать облака вместе вот и есть возможность повлиять на продукт до его публичного запуска то есть добавить туда те фичи которых у которой возможно нужны больше вам чем вот ну а если вы мечтали работать в облаке то мы нанимаем белкам спасибо ну и вопрос конечно же книжка сама себя не это а микрофон да есть здравствуй у меня собственно такой вопрос вывозил афоризм по поводу использования допустим демпферных узлов но вот я имею ввиду у вас от балансер разграничивает нагрузку вот по двум узлам там 50 на 50 если бы мы ввели ну примеру допустим 3 узел на которые вы подавали порядка десяти процентов нагрузки то в момент взлета пика мы просто даём команду балансировщик у распределять равномерно нагрузку и в это время добавляем узлы также оставляем один узел как бы в таком демфер нам состояние и это бы реально уменьшило бы как бы время downtime а когда срабатывает нутри балансировка кластерных групп вообще была такая идея я правильно понял что речь идет как я слышно было все вопросы повторить я правильно понимаю что речь идет о том чтобы просто сделать некоторый внешней буфер и за счет него с вот нагрузку плавно подавать на другие но в целом использовать просто еще одну виртуальную машину на которую не давать ну сто процентов нагрузки то есть она уже прогрета она уже запущена но она как бы работает ну процентов на 20 и тогда в момент пика мы просто ее за использованием на сто процентов и добавляем новые узлы я понял а у вас вот этот вот горб точно бы исчез я понял но на самом деле смысла особо просите я либо либо я не понял либо и либо мне кажется что смысл особо в этом нету потому что uber provisioning он собственно это и дает то есть это тот самый буфер но он не в виде одной машины готовы приятнее на себя нагрузку а виде процентик а дополнительно выделенного на каждой каждый каждый и поэтому когда нагрузка увеличится она просто этот процент сначала выезд то есть те самые 20 процентов 50 новых случаев про визинга в максимум это должно быть 50 до но сколько будет столько будет да все так так мы же идем не ну вот если мы допустим балансирования что подсыпку что prps мы же идем не от 100 процентов мы как только до находим кого-то порогового значения то мы идем вверх если вы установили условно 60 процентов то по сути 40 процентов буфера у вас этого есть и еще там но добавлять - конечно будем сразу же после достижения этого порога потому что вот та самая простая линейная формула она скажет таинствах уже надо больше возраст рюрик спасибо за доклад вопрос такой как интегрируется of the spelling с deployment там новых virtual чик и их откатом то есть я бегу по списку virtual чик хочу обновить новую версию тут включился of the healing что дальше мы при откате то же самое спасибо да отличный вопрос ну вот я боюсь что это это прямо вот это вот к жизненному циклу там стоит стоит машина сильно больше и я попробую ответить да но лучше лучше бы нам не обсудить этот вопрос чуть-чуть потому что я говорю это целая тема доклада но я буду прям рад посвятить еще час кулуарное про это рассказать поэтому кому интересно будет подходить и потому что дипломант это прямо интересная вещь мы проходя по всем этим состоянием вот это состояние каждого инстанса есть в состоянии всего кластера целиком и кластер все время находится в живом состоянии то есть он тепло и новую версию когда он диплоидную версию она проходит по всем этим состоянием и если мы сажали нет простоватой у нас такая большая красивая диаграмма перехода состоянии вот мог бы на компьютере показать но если мы переходим из состояние и состояние running хотим за деплоить новую версию у нас будет переход в состояние где мы снимаем с балансировки потом переводим его по по сути начинаем уничтожать и создаем его заново то есть у нас в классе одновременно будет несколько версий но в идеале 2 и она будет накатывать одну версию на вторую а если мы вдруг хотим сделать откат у нас будет происходить разбор тех инстансов которые не нужные нам версии да и постепенно вот за других то есть вот это вот rolling апдейт в разных разных вариантах он продуманные просчитан здесь примерно ответил ну поподробнее игры подходите и расскажу страсти спасибо за доклад я здесь с другой стороны справа скажете о поддерживается ли в рамках облака клиент persistent на я балансировка и что в этом случае происходит при изменении количества инстансов ну опять же вопрос да больше больше как команде балансиров можно будет глубоко ознакомиться на стойке но вообще да affinity совершенно finiti поддерживается на айпи хотя сейчас на балансировки я скажу на случай что это речь всё про или три балансировку ну получается если меняется количество instance of the вся но вся консистенция если стид и к клиентам cosyns тот хорошо используется конечно же никуда она не денется ну то есть те единицы которые были на ней на них будет подаваться trophix тех же самых условной пи адресов что и раньше а новые будут уже lacie равана заново но это достигается по сути хотите ну стабильными хэшами просто в момент когда мы нам нужно добавить новый instance у нас нагрузка с тех клиентов уже наши сервера с ней не справляются правильно и мы добавили новый индекс нам нужно часть из тех клиентов перевести на новый инстанции то есть просто какая-то часть выбирается и переносится на новый инстанции или так я кажется понял вопрос то есть если пользователь если уже запрос прилип к инстанцию да ну например было у нас 100 онлайн вышла статья на хабре сразу 1000 1000 запросов прилетела на наш 2 инстанция и разделилась между ними но они стали не справляться естественно поднялась еще там десяток инстансов но эти-то запросы уже прилепились к тем сервером да я думаю что они будут просто ott lepland серверов я честно , прям точно не скажу но я полагаю что после того как они получат соответствующие reject это или 3-х просто перри балансирует на себя вот так грязь спасибо за интересный клад у меня вопрос такое как вы определяете что а виртуалка переходит из 100 не running то есть это определенного времени фиксирую сама может сообщить что я прогрелась можете раз отличный отличный вопрос я выждал здесь прямо целое поле для возможных решений и здесь начинается искусственного интеллекта и кончая пользовательскими хуками здесь но нас реализован здесь таймер достиг пользователь задает просто время через который в армен читает этот но в будущем мы можем добавить сюда собственно hellsing ну как дополнительных алчак 1 кл по одному халтеку у нас переходит из состояния starting вот собственно в на балансировку на данном случае formiga это стандартный наверно подход а по второму халтеку можно переходить состоянии running если пользу если хост может сама диагностироваться это несложная как раз фича то есть если если будет от пользователя запрос на это поэтому легко сможем добавить но вот сейчас у нас сезон просто таймер который завис в конфигурации то есть первенство из групп здравствуйте спасибо за доклад ansmann стегал их наверное даже три вопроса первый вопрос собственно говоря как у вас под капотом устроена то есть как вы как вы эффективно утилизируйте сами железки сами баре металл и потому что виртуалке которой она барами этого есть они могут обладать разными профилями и вот как их туда упаковать так чтобы ваше железо лучше всего утилизировать вот этот к вам вопрос вы совершенно не рассказывали ну наверное у вас там есть какие-то внутренние понимания как это работает следующий вопрос опять таки вот в попытках стримить скруглить там или наоборот какие-то нелинейные характеристики на функцию подавать а пользовались ли вы какой-нибудь обратной связи положительной или отрицательной от балансира то есть вот я не уловил этот момент то есть понятно что балансир он обладает информация гораздо более свежий по сравнению с фидбэк am уже на циpкa или там на труд путах на каких-то и вот когда нужно резко ускориться лучше информацию получить балансира ну а затухать это понятно уже как решение с отложенной протух они им это прекрасное решение вот и еще один на вопрос был связан с деза 100 recovery когда вы говорили про 3 дата центра но допустим 3 д т центр находится где-то далеко и туда вероятность падения что ли очень низкая но нам нужно там какой-то резерв иметь то есть как быстро вы сможете мигрировать туда при этом обеспечивает качество сервиса вопросы понятно все понятно его продолжить пожалуйста я теперь попробую их из стека можем любом порядке у меня стэк поэтому я назад пойду по поводу дата-центров у нас дата-центр расположены рядом то есть это все центральный регион то есть сейчас индекс облака запущена в одном регионе и в трех зонах поэтому такой проблемы не стоит и в принципе они по анонсу равноудалены эти ну регион то есть то есть туда действительно попадает равномерно трафик поэтому такой задачи у нас не стояла и мы естественно не решали вот по поводу второго вопроса да здесь так напомню вопрос можно ли получить вот эту обратную связь с балансира и ускорить собственно авто скиллинг вместо того чтобы ждать пока вот в этой находясь в определенности в неопределенности по циpкa да именно это именно рекомендованный подход использовать сразу 2 метрики одновременно то есть мы собственно задаем из балансира из циpкa и тогда только с балансира когда мы сдаем мы должны указать некоторые значения сверху несколько мы выдержим максимально а сколько мы скажем так точно не выдержим минимально чуть чуть поменьше выдается пришел показать тогда когда у нас трафик пошел вверх мы сразу линейно четко понимаем сколько нам точно нужно и точно выделяем а циpкa получается балансировка подсыпал потом уже доводит уже вот эти для того чтобы вот именно сохранить минимальное выделение ресурсов то есть ну если стоит стоит как бы сказать что авто скиллинг в случае работы с двумя метриками принимает решение по каждой из них и берет максимальный ответ то есть вот то что я рассказал именно по вам решит вот этого проблема не в том то и дело что нет конечно он будет папа побеждать сильнейший в этом собственно суть алгоритма но если именно балансировку по трафику сделать сделать рисовал поменьше да извините так очень побольше побольше да тогда он не он типа будет всегда доминировать кроме тех случаев когда подсыпку пoeздe c побудет в неопределенности тогда будет сначала резкие вот в случае резкого трафика будет быстрый скачок вот там в разы например по балансировке а потом доводка подсыпал если вы говорите про более там такие софистики этот механизм и когда мы прямо с балансировщик am собрать на связи работаем наверное это можно сделать но это уже не будет такой простой схемой вот как описано здесь все просто и понятно а вот то что о чем вы говорите это наверное хорошее развитие для того вот наверное такие conference какие лоты нужны что получить обратную связь по этому спасибо большое а по поводу первого вопроса я на самом деле ничего не скажу потому что но вы спросить скажите как например google распределяет машина как amazon распределяет машины мне кажется что никто про это не скажется вот нам тоже интересно а вам спасибо можно еще вопрос касательно метрика немножко и масштабирование а вы другие искусственные метрики не смотрите при этом на настоящий момент нет то есть у нас есть built-in собственно вот 2 метрики это подсыпал и по трафику а дальше мы хотим собственно ну таким будем поддерживать те метрики которые мы можем собрать самостоятельно мы их будем поддерживать но и конечно же мы будем поддерживать пользователь метрики это хорошее кейсы там есть например например когда вы мониторите очередь входящих сообщений и поднимаете свой кластер для обработки собственно данных из очереди тогда можно стелется до нуля и то же самое касательно бизнес метрик то есть бывают ситуации сервис деградировала из-за зависимости и нужно несмотря на метрики собственно ресурсный нужно немедленно от масштабироваться кровь из носу может газом клиентской api какой-то который да здесь и здесь я вижу два варианта нам так на поверхности они лежат это либо пи через который вы взаимодействуете системой просто даете им но обратную связь что вам нужно либо это работа через внутренний мониторинг то есть когда вы окружаете метрики просто в систему мониторинга мы предоставляем собственно на базе неё в туза графики там вам надо сбор да это дали а мы уже из нее берем эти метрики повторно графики и логику соответствует грязь графики логику да ну это это про развитие то про будущее сейчас нет а еще один вопрос в догонку вот вы сказали что при down спиллинге идет задержка перед удалением машины а кто за это платит это платит пользователь или яндекс при down пользователь это регулируемая вещь как как грится ну дела барина можно не платить но тогда не будет задержки это конфигурируем параметр да где сказал что он рекомендуется вставить его в 10 минут но можно выставить в ноль будет сад с он сразу принять решение"
}