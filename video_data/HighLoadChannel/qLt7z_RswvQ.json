{
  "video_id": "qLt7z_RswvQ",
  "channel": "HighLoadChannel",
  "title": "Применение изображений в рекомендательных системах / Руслан Вергунов (Umbrellio)",
  "views": 339,
  "duration": 1506,
  "published": "2024-04-17T01:10:29-07:00",
  "text": "Так прием Всем привет Меня зовут вергунов Руслан Я представляю компанию ombrelia сегодня расскажу о применении изображений в рекомендательных системах Наша компания на рынке работает уже 9 лет двигаемся в различных направлениях такие как Back офисы различные финтехпроекты занимаемся продуктовой разработкой один из наших проектов это система рекомендаций игр сегодня мы с вами обсудим о том как вообще можно учитывать изображение в рекомендательных системах Какие подходы себя зарекомендовали успешно и о том как на все это тратить меньше ресурсов для этого мы с вами посмотрим как это выглядит с технической точки зрения продуктовой Как можно вообще добавлять информацию об изображении в рекомендательную систему и какие результаты получаются когда мы начали работать на данной задачей мы начали С простых подходов которые учитывают только лишь матрицу взаимодействий пользователя и айтема напомню что на пересечении мы расставляем отметки о характере взаимодействия пользователя с айтемом это может быть наличие или отсутствие взаимодействия лайк дизлайк или отсутствие взаимодействия а также мера взаимодействия например Время проведенное в игре и задача по имеющейся значениям предсказать пропущенные значения применив несколько подходов мы пошли и посмотрели как это выглядит продуктовой точки зрения во многом многие игры пользователи неизвестны их название ни о чем не говорит и опирается он в первую очередь на то что он видит Нравится ему изображение или нет и появляется желание кликнуть или нет Таким образом мы бы хотели в наши рекомендательную систему занести графическую информацию так чтобы повысить вероятность клика но при этом не стать кликбейтом и при этом увеличить глубину пользования продуктом с технической точки зрения наши рекомендательная система выглядит следующим образом у нас есть примерно 70 тысяч пользователей 30 тысяч товаров и для каждого пользователя необходимо отранжировать все игры затем применить бизнес-правила и сложить результаты в базу откуда различные сервисы могут подтягивать и использовать по своему назначению например отображать в разных местах например в разделе рекомендованная или Stories Давайте посмотрим что нам вообще доступно о нашем айтами в первую очередь это различные категориальные признаки например жанр теги есть различные информация о взаимодействии пользователя с каждым айтом лайки дизлайки время проведенное в игре и так далее У нас есть небольшой текстовое описание и логотип мы с вами попробуем извлечь максимальную информацию из логотипа внести в рекомендательную систему и улучшить её когда мы начали работу над данной задачей мы выписали основные гипотезы которые Как нам кажется влияет на характер из влияния изображения на пользователя первое что кажется очевидным что наверное существует красивые некие изображения красивые Это наверное те которые нравятся большему числу пользователей Но конечно все-таки это субъективно затем мы увидели что на некоторых изображениях есть текст на некоторых его нет это также влияет на использование кому-то нравится чтобы был какой-то текст по которому он примерно мог понять что там кому-то же кажется это не симпатичным И следующий наш гипотеза была Давайте ни о чем не будем думать попробуем какую-нибудь нейронку засунем туда логотип и получим признаки и затем уже их будем использовать кажется у нас готов дизайн эксперимента давайте как в классической задаче рекомендательных систем пользователей разделим на два вида на холодных и обычных холодных назовем тех пользователей у которых еще нет взаимодействия с нашей с нашим продуктом обычный у них уже заполнена Матрица взаимодействия пользователя и товара затем мы выберем какую-то модель машинного обучения которая может ранжировать товары для каждого пользователя затем добавим признак или несколько много признаков из гипотезы померяем качество и сравним с байзлайном Итак первое наша гипотеза касается красоты красота достаточно субъективное понятие но как оказалось есть способы как можно приблизиться к этому через алгоритм машинного обучения оказалось что есть датасеты размеченные на которых профессиональные фотографы отмечает отметками от 1 до 10 насколько сильно им понравилось изображение кажется что тогда можно наш логотип взять пропустить через какую-то нейронку и научиться предсказывать средний рейтинг например один из данных подходов реализует мимо на слайде представлена пример применение данного подхода одна картинка специально взята в оригинальном качестве а вторая специально ухудшена видим что на выходе мы получаем скор у оригинальной картинки выше чем у ухудшенного качества но при этом это наверное может работать не всегда здесь представлены картинки которые кажется субъективно примерно одинаковыми скоро при этом у них разные Почему так получается непонятно Но все равно Давайте попробуем использовать признаки которые мы получаем например рейтинг стандартное отклонение и границы доверительных интервалов следующее наша гипотеза касается текста в принципе задача стандартная относится к категории оси R библиотека существует тоже достаточно много мы выбрали библиотеку Изи осиар и с помощью неё можно получать все границы на которых расположен текст мы можем составить следующие признаки например количество символов количество цифр доля которая занимает текст от всего изображения расположение например Где находится крайние найденный текст слева справа сверху внизу и так далее возьмем эти признаки следующая наша гипотеза касается различных нейросетевых подходов Мы хотим получить на выходе такое представление после работы нейрости чтобы похожий логотипы располагались близко друг другу в неком пространстве векторов а не похоже располагались дальше Давайте попробуем взять что-то простое что-то посложнее для начала возьмем reset обычные на imagenetty и в конце получим результат выход последнего слоя так называемый medding возьмем Вектор который получается размерности 512 и эти 512 чисел и будут нашими признаками то же самое проделаем для подхода Дина о нем чуть поподробнее ребята из Facebook research задались целью необходимо получить такие вектора которые можно применять в различных задачах машинного обучения добавили туда Трансформеров селф супер Вайс обучение и на выходе мы можем получать также Вектор признаков который семантически отображает сущность изображения на слайде представлена картинка и визуализация atention слоя который получается на выходе нейронной системы данный Вектор мы как и в предыдущем случае можем использовать в качестве набора признаков Итак мы получили набор признаков давайте выберем какие-то модели в котором мы будем добавлять давайте для обычных пользователей возьмем что-то такое Что хорошо работает всегда например Light FM и возьмем что-то чуть сложнее например двухуровневую модель для холодных пользователей возьмем только Light FM так немного напомню о данной библиотечке она очень популярная Она позволяет работать с различными рекомендациями так при этом чтобы можно было легко добавить признаки пользователя и айтема кажется это то что нам нужно во многом эта идея этой библиотечки родилась из задачи желания решать сразу и обычную задачу и сдачу колд старта тогда в задаче Call Start мы можем опираться лишь на метаданные То есть например пол возраст жанр и так далее Итак двухуровневая модель как Понятно из названия Она состоит из двух этапов на первом этапе мы составим небольшой набор кандидатов которые будут выдавать айтемы которые необходимо отранжировать чтобы на втором этапе отранжировать уже не все а только лишь часть на данном этапе мы будем стараться максимизировать Recall метрику так чтобы представить как можно более разнообразное число атомов например простыми вариантами является топ по стране топ по жанру и так далее мы получили набор кандидатов и затем их можем отдать уже на второй этап на втором этапе мы можем применять классические алгоритмы которые мы любим и которые зарекомендовали себя например бустинг но при этом в качестве таргета можно использовать различные значения единица и 0 они могут быть разные например единица это наличие взаимодействия в тестовом множестве ноль отсутствие например единица может быть добавления в Избранное или нет здесь все зависит от того насколько большой дисбаланс класса Вы можете получить поэтому мы опирались на в первую очередь на наличие взаимодействия тогда как в качестве признаков можно взять помимо признаки которых характеризует взаимодействие также и взять метаданные и признаки контекста Итак выбрали модель давайте выберем способ как мы будем все это измерять Наша компания мы опираемся чаще всего на тайм-сирис кросс валидацию напомню в чем она заключается когда мы модель используем в продакшене нам доступна лишь данные которые доступны в этот момент времени Давайте попробуем смоделировать это на исторических данных и будем брать в какую-то дату лишь те данные которые доступны в этот момент затем при различных параметрах модели запустим их и найдем лучше уже оттестируем на следующем временном интервале получим какую-то метрику затем повторив данный подход на различных датах постоянно увеличивая размер доступных нам данных мы получим набор метрик здесь мы уже можем измерять различными способы например сравнивать среднее по всем метрикам сравнивать границы доверительных интервалов Итак какие метрики мы будем использовать Давайте возьмем какие-то стандартные метрики которые просто показывают качество использования рекомендательной системы но при этом который не учитывают ранжирование например престиженный рекол и метрики которые уже учитывают ранжирование так чтобы Объект который более вероятно лучший он распался выше в нашей выдаче на данном слайде представлены результаты модели Light FM при различных гипотезах как оказалось что лучше всего показывать себе подходы которые не используют информацию можно сказать из головы то есть мы не конструируем никакую гипотезу сложенную и не чем Малое количество признаков мы сразу просто используем какую-то нейросеть получаем много признаков и это дает качество схожие результаты мы видим при работе двухуровневой модели на данном сайте представлена в таблице значение прироста метрики по сравнению с безлайном схожие результаты мы видим задачи колд старта Итак мы улучшили нашу систему но при этом мы тратим значительно больше ресурсов например CPU и память Давайте попробуем исправить и кажется очевидно что первое что с чего можно начать это Давайте попробуем уменьшить размер Вектор который получается после выхода работы не расти второе Давайте попробуем сделать какие-то трюки с памятью в качестве способов сокращения размера существует достаточно много мы выбрали алгоритм pca напомню что он помогает Вектора из большей размерности перевести в меньшую так чтобы координаты в меньшей размерности описывали максимальную дисперсию Таким образом мы можем сократить размерность например в нашем случае с 512 до 64 данный параметр Вы можете выбирать опираясь на то Сколько памяти есть на вашей машине И следующий способ который мы применили это квантование квантование помогает перевести набор чисел из чисел с плавающей точкой в целочисленное представление алгоритмов квантования достаточно много все они дают различные прирост по сокращению памяти мы выбрали следующий алгоритм Давайте попробуем найти точку с максимальным значением по модулю затем на интервале от минус экстремума до плюс экстремума разобьем на равные интервалы количество интервалов может варьироваться и вы можете выбирать это как параметр мы остановились на числе 256 затем каждая точка определяем В каком интервалу она принадлежит и тогда можем поставить целочисленное значение на данном слайде представлены результаты после применения всех оптимизаций Да они уступают изначальному Pay плану но при этом дают также значительный прирост то же самое мы видим в двухуровневой модели после работы с данными алгоритмами следующее что кажется очевидным хочется попробовать это попробовать другие mbdding который получается после выхода в различных сеток их можно комбинировать как-то сочетать первую очередь мы хотим попробовать Дина которая вышла недавно во второй версии например нам может стоить наверное улучшить нашу двухуровневую модель потому что обычно двухуровневая показывать себя лучше чем тот же например Lite FM в нашем случае этого не получилось и применить DSM подход потому что он позволит не только сразу скорее всего дать хороший спор но также и работать быстро Итак во-первых я всем советую попробовать какие-то нейронки засунуть изображение и применить Их кажется что во многом еще сильно влияет домен того в котором вы работаете в нашем случае домен отличается очень сильно от стандартного изображения Возможно это является причиной Почему не заработали подходы с например гипотезой а красивости изображения при этом Это все можно также применять и работать достаточно быстро даже в Real Time вот Спасибо за внимание голосуйте за доклад Если будут вопросы Можете писать в Telegram Вот мой handle Спасибо Руслан лаконичный доклад А теперь время ваших вопросов вопрос можно задавать в зале можно в чате писать Давайте вот человек вот не работает что трасса Спасибо за доклад хотел спросить Зачем сжимали бединги кажется что айтмов не очень много юзеров тоже не очень много в одну точку влезали бы в любом случае или нет не всегда то есть это среднее значение на некоторых у нас было так что просто не влезали и все падало поэтому пришли к сокращению размерности и при этом получили хороший прирост Окей тогда если можно еще один вопрос вдогонку поэтому же если из сжимать деньги то почему взяли линейный писей а не попробовали какой-нибудь да мы тоже думали об этом это тоже что стоит попробовать это у нас даже стоит таски писей например попробовали в отличие от каких-то нелинейных алгоритмов нравится больше потому что достаточно предсказуем стандартен и задача была проверить вообще это будет работать или нет достаточно просто поэтому так Спасибо Спасибо дальше в конце Добрый день спасибо за доклад Руслан У меня два коротких вопроса Были ли гипотезы поработать с обучением без учителя просто порешать задачу кластеризации и какие из этого может быть были выводы и пробовали ли вы с форматами изображений тоже что-то делать что вот например выпи сейчас на всех популярных сайтах все больше появляется и больше дает скорости что влияет ли формат изображения Еще также на обучение Спасибо так Спасибо за вопрос насчет форматов Нет не пробовали А первый вопрос про обучение без учителя без учителя тоже хотим попробовать есть различные информация на которой можно попробовать обучиться вот так при этом чтобы не пронести Лик в затем наш pipeline вот при этом в общем это стоит хотим то что попробовать это наверное стоит попробовать здесь Наверное большую роль играет то не только о кластеризация которую вы сказали но и возможно У вас есть какие-то еще данные на которых можно обучаться Вот мне кажется стоит попробовать Давайте дальше в первом ряду в углу а у меня такой вопрос вы использовали этот сервис для рекомендательных систем часто некоторые там условно товары могут быть одинаковые но отличаться по цветам допустим 10 разных футболок разного цвета учитывали ли вы эту информацию как-то Если да то как у нас все-таки такой домен что грубо говоря каждая картинка отличает Это другая игра то есть в случае например футболок кажется что футболки похожи и это примерно что-то одно и то же но здесь кажется что это не стоит учитывать в нашем домене по крайней мере спасибо Еще вопросы там Спасибо за доклад Я правильно понял Вас что Вы использовали изображение только как признаки рекомендации Да А вы пытались экспериментировать с признаками изображений для пользователей например смотреть на его историю или как-то это учитывать не совсем правильно вас понял ну то есть у нас есть этим которым уходит хотим порекомендовать у него есть картинка но У пользователя например было тоже взаимодействие с какими-то айтемами и смотрели вы на картинке там Какие например пользователи любят картинки или вы учитывали только факторы айтмов собственно во многом чаще всего логотип не меняется то есть и соответственно когда мы заносим информацию о айтами например Матрица Да взаимодействия во многом это будет уже отсылкой связанные с графической информацией Но скажем так более расширенная вот поэтому мне кажется что этот кейс как раз покрывает спасибо Еще вопросы а вот рядом Добрый день спасибо за доклад Вы упомянули про схему квантования которую вы используете Насколько я понял это равномерное квантование Да ну в диапазоне от экстремума до похоже Ага Почему именно равномерное квантование вы делали какие-то исследования по распределению данных То есть фичей как они распределены и возможно там можно более хитрую схему квантования применить Чтобы повысить качество да Как раз я сказал о том что существует много мы посмотрели несколько еще мин Маск Скейл и соответственно выбрали тот который все лучше показал по метрикам так вот здесь рука была Пётр Если не ошибаюсь вопрос Не совсем мой но задам я не думали над тем что решать проблему не ранжирования картины картинок А создание более картинок для тех или иных игр то есть мы просто делаем те картинки на которые пользователь вот Стопудово кликнет кликбейтинг короче ну мы даем красивый мы знаем что внутри находится Какой жанр и так далее мы знаем лучше него что ему надо Но картинка ему почему-то не нравится да Но мы вот Делаем тогда картинку чтобы на неё Евгения это ваш вопрос так понимаю мы об этом думали но здесь бизнес модель построен настоящим образом что игры нам не принадлежат их делает какой-то провайдер Мы думали поэкспериментировать посмотреть что примерно получится Если получится что-то адекватное то как вариант предложить но пока что это к сожалению не нашел область Спасибо еще Похоже что все давай выбирать лучший вопрос Какой тебе больше понравился так наверное Давайте вот там был вопрос про кластеризацию и второй был про формат изображения У нас два приза Да нет ну это один человек который задал вопрос Давайте кто это кто вот пожалуйста ему от организаторов книжечку а тебе спасибо большое Если что можно подойти всегда спросить дальше попытать подарок это организаторов спасибо спасибо Руслан аплодисменты"
}