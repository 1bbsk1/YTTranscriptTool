{
  "video_id": "WE4Rvox_oOI",
  "channel": "HighLoadChannel",
  "title": "Генеративные диффузионные модели. Разработка, обучение и релиз модели Kandinsky 2.1/ Андрей Кузнецов",
  "views": 346,
  "duration": 2919,
  "published": "2024-04-17T01:10:26-07:00",
  "text": "так Всем привет Так гораздо лучше зовут Меня Андрей Кузнецов я руковожу разработкой исследованиями в области компьютерного зрения мультимодальных моделей в сберея и сегодня хочется рассказать про очень такой актуальную тему в сфере искусственного интеллекта и в сфере там генеративных моделей это диффузионные модели с помощью которых можно в современном мире генерировать очень крутые картинки по тексту описанию И я расскажу подробно про то как мы делали свою модель как мы ее релизили и остановлюсь на каких-то аспектах связанных с релизом история задачи это будет Первое о чем мы поговорим потому что классическая компьютерное зрение оно воспринимается все-таки нечто как нечто другое потому что типичном понимании компьютерное зрение про картинки Потом я чуть-чуть расскажу про диффузионный процесс покажу существующие приложения и существующие модели которые разрабатываются в мире вокруг диффузии расскажу про кандинский 2.x Почему X тоже станет Понятно подробнее попозже и потом эксперименты приложение Ну и некоторые мысли собственно история задачи Так повелось что компьютерное зрение как я сказал Оно обычно концентрируется вокруг картинок и где-то года до 2014 пока не появились генеративно состязательные модели все компьютерное зрение было завязано на картинке видео и в принципе вот с этим связаны с этой модальностью связанные решения после появления генеративных моделей именно ганов Да стали появляться новые решения которые позволяют принципе синтезировать изображение создавать их очень естественными тогда появились такие сайты и такие модели там как стоялган и сайты типа despress Exist Disco Это должно так Exist Я думаю Те кто с областью севий знакомы наверняка видели эти сайты ну и собственно где-то года с 2016-17 стали появляться решения которые позволяют генерировать изображение по текстовому описанию и вот этот трек стал очень активно развиваться мы взбирая и начали заниматься генеративными моделями с 2021 года Это был наш первый такой вхождение в генеративный искусственный интеллект тогда мы сделали модель Малевич это первая модель которая была построена на авторегрессионной архитектуре и ну качество генерации оно конечно оставляло желать лучшего потому что эта архитектура она не позволяла добиться высокого качества просто ну просто по своей вот виду особенности архитектуры в двадцать втором году мы стали разрабатывать другие модели это ruclip Модель которая позволяет мерить расстояние между текстом и картинкой чтобы их как бы объединить в одной модельности полезная штука и стали развивать модель кандинский первично увеличив размер Малевич модели то есть в той же архитектуре и сделав такую же архитектурную модель но в большем количестве параметров в надежде что это даст Босс по качеству но не сильно дало и мы стали погружаться в диффузионной модели собственно в ноябре мы выпустили модель 20 она уже работала на диффузионной архитектуре но имела определенные ограничения которые не давали модели генерировать там сложные объекты пальцы Ну и все в принципе Что является сложным для диффузионок Ну вот 4 апреля мы выпускаем кондитерский 21 Это был прям такой серьезный буст по качеству Несмотря на то что в названии там версии модели прибавилось всего там единичку во втором знаке но тем не менее качество было очень высоким и э мы даже как бы подсели на релизе потому что бэк не справлялся поначалу с тем количеством запросов которые стали выходить после pr-компании Ну и дальше Вот собственно в 2023 мы продолжаем развивать генеративные модели работаем там над кандинским для видео кандинским для 3D улучшаем продолжаем архитектуру Ну это уже будущие Наверное мои рассказы будут собственно что же такое диффузионный процесс диффузионный процесс это такая архитектура которая позволяет интерактивно восстанавливать данные из некоторого шума при этом под этим шумом мы можем понимать что угодно в контексте генеративных моделей которые позволяют создавать изображения диффузионный процесс умеет восстанавливать изображение из белого шума который по сути является представлением текстовой текстовый инкодинга То есть у нас есть некоторые текст которым мы каким-то образом кодируем и по сути представляем пытаемся моделью восстановить из этого текста некоторую картинку которая с этим текстом связана смысл заключается в том что есть два процесса прямое обратный прямой процесс он по сути позволяет оперативно зашумлять То есть каждый шаг диффузии это некоторая вероятностное зашумление изображения с некоторым шумом определенными параметрами там от ожиданий дисперсии задача при обучении моделей это как раз научить ее обратному диффузионному процессу То есть как восстанавливать из этого шума исходные картинки Ну имея в арсенале большой набор связанных пар тексты картинка мы можем научить модель правильно искать соотношение между закодированным текстом некоторым энкодером и картинкой которая тоже может быть закодирован с точки зрения вероятности если посмотреть то этот процесс представляет из себя просто некоторое произведение вероятностных переходов между каждыми шагами и задача восстановить соответственно нормально из нормального распределения из шума распределенного по нормальному распределению восстановить исходную картинку и в зависимости от количества шагов их может понадобиться больше либо меньше мы восстанавливаем картинку с разным уровнем детализации с разным уровнем там каких-то особенностей картинки и так далее что же существует в настоящее время с точки зрения референсных каких-то моделей на котором опирались когда исследование проводили но первая модель эта модель выпущенная компанией openoi это дали 2 она представляет из себя классическое первое представление диффузии для процесса создания изображений Ну и смысл ее как бы вот понятен и соответствует просто классическому-то описанию про которое рассказал с точки зрения диффузии У нас есть некоторые текст он слева он попадает в некоторую Модель которая позволяет кодировать текст превращать её в мб-зинг и дальше этот им боетинг через набор подобных таких слоев он этот архитектура которая очень похожа на архитектуру для сегментации то есть некоторые там уменьшающие преобразования и увеличивающие в размере преобразования позволяет восстанавливать из картинки текст и картинку так далее и в принципе работали над моделью клип эта модель которая позволяет находить расстояние между текстом и картинкой Они использовали эти наработки Для того чтобы можно было построить некую Приору модель для того чтобы можно было восстанавливать картинку не просто из текста но еще и перемешивать туда какой-то картиночное кодированное описание после этого компания Google буквально там через несколько наверное недель выпускает свою модель диффузионную она отличается тем что у нее появляется несколько диффузионных моделей каждый из которых она значит первая из закодированного текста восстанавливает картинку маленького размера 64 на 64 и потом следующие модели они увеличивают картинку в разрешении Ну то есть такие тип модели для суперреза ни одна из этих моделей к слову не вышла Open Source А у нас как бы подход как раз наоборот мы пытаемся все наши ресеть все наши исследования все результаты выводить в Open Source и вот эти эксперименты мы опираясь на те данные которые были в статьях как-то пытались проверять насколько это работоспособно вот эта тема она э тяжеловесная она долгая потому что несколько диффузионов ну и плюс если возникают какие-то ошибки при восстановлении картинки из текста то каждый следующая модель она с трудом их исправляет она скорее их начинает мультипликативно увеличивать в прошлом году также вышла интересная модель про неё Я думаю все слышали она называется Table defusion она построена также на диффузионном процессе но единственный ее Ключевое отличие заключается в том что восстанавливается не сама картинка когда мы декодируем текст и восстанавливаемость текста через диффузионный процесс а восстанавливается закодированное представление картинки то есть некоторые есть некоторая модель которая умеет картинку кодировать вектор и есть симметричная Модель дикодер которая может из этой картины из этого вектора восстанавливать картинку Это значит что нам уже нужно работать не с пространством пикселей А с пространством размерности того Вектора в котором мы кодируем картинку Это увеличивает скорость работы моделей это снижает вычислительную сложность и позволяет быстрее больше учить модели этот подход был достаточно интересен и мы в кандинском 2.0 попытались вот по сути его воспроизвести и посмотреть насколько он работоспособен добавляя какие-то свои изменения по архитектуре но в целом Работая в пространстве Ну вот это называется латентная диффузия в пространстве латентной диффузии а что интересно диффузия нашла себя и в других приложениях не так давно вышла модель называется compose baldi Fusion это подход уже мультимодальный То есть это подход Когда мы можем каждую модальность под модальностью мы понимаем текст видео картинка аудио можно кодировать специальным энкодером который построена диффузионной модели и сводить все в некоторые единое пространство общее для диффузии для того чтобы можно было решать абсолютно разные задачи и связывать разные модальности между собой Например у нас есть модальность картинка текст и аудио и Вполне логично можно найти приложение в которых связано например аудио и текст Да это типа речь и расшифровка речи и есть например модальность картинка и текст где у нас есть изображение и его описание но почти никогда не возможно найти пары между текстом и аудио между картинкой аудио тем самым используя вот этот подход мы можем через какую-то модальность начинать связывать не связуемой Казалось бы данные Это позволяет строить там сложные чат-боты через такой подход можно строить разные связи между модальностями которые в природе не всегда существуют и даже дата сетов таких не найти Ну и в принципе ребята вот предложили такую модель предложили очень интересный подход Ну вот мы сейчас с точки зрения чат-ботов пытаемся в этом направлении тоже работать и следовать насколько диффузия способна работать действительно с разными модальностями с разными типами данных а Ну теперь перейдем собственно кандинскому кандинский представляет из себя латентную диффузию мы сейчас будем говорить про кандинские 2.1 чтобы не тратить время на предыдущую версию это актуальная версия она содержит чуть больше 3 миллиардов параметров это в принципе для диффузии достаточно такой среднее значение в основном все где-то там выходят за 6 там 5 миллиардов в зависимости от того какая Ключевая модель диффузионная берётся Ну и собственно здесь несколько примеров показано Как работает модель мы сравнили ее первым делом с кандинским 2.0 увидели существенное качество именно в детализации и как бы стали дальше уже дальше развивать модель собственно кандинский 21 это по сути первая латентная диффузия которая использует еще и так называемый sprayer Image priyer - это механизм который показан здесь вот на слайде в левом столбике что Он позволяет сделать ему же праймер это по сути Fusion mapping это в серединке красный блок Он позволяет зама пить предварительно текст и картинку закодированные определенным энкодерами клиповыми Почему мы взяли клип Потому что он очень хорошо при добычен в принципе выложен в опен Source его удобно использовать для того чтобы можно было кодировать модальности тексты картинку в некоторые Общее пространство нам нужно было добиться большей связи между картинкой и текстом для того чтобы можно было по тексту найти некоторые это такой предварительное что ли состояние картинки из которого мы бы уже могли восстанавливать тем самым если посмотреть на столбик справа у нас появляется вот там желтенький такой кусочек в векторе это как раз кусочек который отвечает за картинку за ту картинку из которой мы бы хотели восстановить уже идеальное изображение конечное в классической картине мира У нас нет этого желтого кусочка справа у нас есть только закодированный некоторым текстовым энкодером это вот голубые блоки наверху закодированный текст и он собственно попадает сразу латент на диффузию в зелёную и дальше уже восстанавливается картинка этот подход как раз и был в основе Кандинского 2.0 и он и не давал модели нормально развиваться потому что чего-то ей не хватало как только мы добавили вот этот фраер блок он стал существенным образом давать модели лучшее понимание текста то есть мы могли генерировать картинку просто из текста А ещё из некоторого э промежуточного визуального представления Ну и второй существенный Boost это новый кодекодер это вот как раз картиночный декодер который очень хорошо работает с текстами То есть если мы кодируем текст он его очень хорошо декодирует и с лицами это тоже была проблема кондинского 20 там лица бывали такие искорёженные что прямо ужасно было показывать было невозможно И никакие постобработки особо не позволяли это сильно порешать Ну и собственно за счёт вот этих всех изменений у нас появилась модель основные функции они показаны здесь на слайде и дальше я просто буду показывать примеры этих функций как они работают сейчас В текущей реализации модели это общий вид всех вариантов то есть у нас есть левый столбик это вариация картинки когда мы подаем изображение оно превращается в какой-то другой изображение У нас есть собственно смешивание изображений но тут в качестве примера Чебурашка и Крокодил Гена не превратились нечто среднее есть соответственно связка и Fuse текста и картинки когда Ну по сути мы делаем стилизацию изображения мы добавляем к описанию как картинки некоторые описания текстовые и в зависимости от этого описания картинка меняется Ну и модели точнее приложения связанные с inpending Когда мы можем взять картинку и дорисовать какой-то стороны с использованием генеративной модели кратко если посмотреть на структуру модели то она представляет из себя 5 ключевых блоков первый это текстовый энкодер клиповый который состоит всего 560 миллионов параметров блок картиночного прайера на 1 миллиард параметров клипового энкодер картиночные 400 миллионов параметров сама латентная диффузии порядка там чуть больше миллиарда параметров Ну а молоко это как раз картиночный энкодер который представляет нам латентное состояние визуальной части модели он собственно совсем маленький при обучении мы использовали собственно собранные dtset которым Мы собирали там где-то года с 2021 совместно с коллегами из Бер девайс у нас получился такой большой сет состоящий из около миллиарда пар картинки и текст и там внутри содержались разного рода описания там на разных языках То есть это были картинки и связанные с ними описание это сеты открытый это какой-то scrapping с разных сайтов это разные открытые фото стоки где можно брать данный и это разрешено лицензионным соглашением Ну в общем так или иначе у нас получилось этот сет на одном языке и собственно эти данные используем при обучении но продолжаем его пополнять еще несколько примеров того как работают разные режимы в модели кандинский сначала покажу базовые генерации по тексту смешивание изображений по сути стилизация картинки при помощи другой картинки смешивание изображений текста вариации изображений тоже очень удобно Если делаете какие-то например изображения для картинки для слайдов то одно и то же картинку вставлять все время стрёмно но когда ее начинаешь как-то видоизменять ее можно периодически подсовывать свои слайды импентинг еще раз мы берем картинку берем инструмент типа ластик замазываем какую-то часть картинки и отправляем ее в инвентинг модельтинг модуль он есть там на сайте fusionprime.a и там попозже будут ссылки и там можно собственно поиграться с этой механикой то же самое только дорисовка снаружи они внутри когда мы хотим сделать там из квадратной картинки потому что 21 она генерирует сейчас пока только Квадратное изображение в разрешении 768 пикселей и мы хотим ее как бы расширить сделать какое-то Полотно Ну вот можно использовать механизм outpainting а есть еще один очень интересный режим который мы Ну как-то хранили внутри но не особо использовали но стали возникать вопросы типа что делать если мы хотим сгенерировать какого-то конкретного человека обучить модели тюнить ее под набор конкретных лиц это долго надо собрать сет Если ты хочешь там вставить с ней какого-нибудь там известного человека условно там соседа друга то нужно с него собирать dtset надо собирать с описаниями это достаточно сложно мы придумали такую механику для каждого фамилии имени условно Да идентификатор известного человека мы делаем некоторые описание его внешнего вида лицо форма там головы прическа и так далее и храним В некоторой таблице как только у нас приходит запрос типа сгенерирование условно там Германа грефа на фоне Колизея вместо Германа грефа подставляется описание которое хранится в таблице то есть мы генерируем такую похожую похожий шаблон похожий Аватар для этого человека и потом отдельной моделькой которая тоже делает одна из моих команд мы переносим лицо при помощи технологии Face Swap с какой-то фотографией условно там Германа грефа на соответственно лицо вот этого сгенерированного персонажа Таким образом у нас получается возможность синтеза генеративной модели людей которые абсолютно в точности соответствует человек которому мы хотим сгенерировать несколько примеров и вот один из моих хороших знакомых Андрей Смирнов Он согласился поучаствовать тоже в этом эксперименте взяли добавили его лицо сделали описание и вот он с удовольствием меня периодически спамит своими образами в разных ипостасях то он там индусский какой-то принц то он Гарри Поттер то что-то из Во все тяжкие Ну и так далее В общем можно сгенерировать себя абсолютно любых образах такая прикольная как кажется вирусная штука еще один режим это генерации стикеров тоже прикольная вещь Она позволяет в Telegram Боте сгенерировать набор стикеров сохранить его и там делиться с кем угодно там с друзьями с коллегами можно сгенерировать абсолютно любые штуки Совсем скоро мы выпустим модель 22 она будет отличаться существенным бустом по детализации изображений добавится возможность генерировать изображение не только квадратный но с разным соотношением сторон И добавить разные фишки типа Control на это когда можно генерировать картинку и посредством описание изменять ее какие-то локальные части И на самом деле это прям существенный буст я бы сказал что это наверное по качеству Судя по экспериментам сейчас где-то в районе 5 то есть принципе модель идет на уровне с современными аналогами что касается экспериментов самый такой типичный эксперимент для генеративных моделей это подсчет метрики фид Метрика Фит позволяет если расшифровать это в решении сообщена с дистанции по сути это расстояние кульба коллеблера между двумя распределениями то есть у нас есть распределение вероятности для исходных изображений которые не сгенерированы и мы по для этих изображений по описаниям их соответствующим генерируем картинки то есть условно У нас есть там 5 30 тысяч картинок 30 тысяч их описание мы на эти 30 тысяч описание генерируем 30000 картинок из подставляем два распределения И чем ближе эти распределения тем меньше это значение соответственно вот среди существующих моделей наша модель Сейчас занимает по метрикам третье место при этом все модели которые на первом и втором месте они него по ресурсе поэтому их проверить как-то не удается формально с точки зрения консурса сейчас модель на первом месте кажется там что-то выходило из команды по моему Флойд но мы пока не проверили соответствие этих цифр к настоящему моменту если посмотреть на количество генерации в разных источниках которые в которых представлена модель значит число запросов составляет почти 70 миллионов и 5 миллионов уникальных пользователей при этом 1 миллион заработали на первых 4 днях релиза есть несколько источников вот они здесь показаны это соответственно Fusion Brain API чуть больше чуть дальше покажу ссылку Telegram сайт rudali.ru Салют приложения там можно через запрос ключи художников включить модель и вот в телеграме если посмотреть на статистику запросов то мы в Пике доходили там до двух с половиной миллионов в сутки это как раз были самые пиковые дни где-то там 3 4 день выхода модели и вот там конечно было тяжело потому что как-то не были готовы к такому объему загрузок и в первые дни были определенные трудности но с течением времени там где-то день на 5 мы все-таки это починили и собственно сейчас работает достаточно стабильно и никаких серьезных ошибок уже нет если посмотреть на кластеризацию запросов то вот здесь Есть такая карта где можно видеть что люди больше всего генерируют чаще всего генерируют один орна одинарные запросы представления каких-то известных личностей в необычных образах генерирует просто объекты на каких-то сценах Ну вот самый такой типичный вариант с точки зрения приоритетов пользователей когда вот они что-то генерируют модель выложенного Open Source код к ней лежит на гитхабе и веса лежат на хайгенфейсе их можно открыто скачать можно развернуть дома на локальной машине достаточно там какой-нибудь карточки типа 380 что-то такое и можно даже локально поднять сервер который будет эту модельку поддерживать мы сравнивали шедевром к сожалению еще пока не получилось сделать нормальное сравнение надо просто генерировать большое количество запросов и отправить их во что-нибудь связанное там с человеческой оценкой типа СБС есть такая Метрика сайт бай-сайт когда люди отвечают на вопросы Какая модель лучше генерирует потому или иному запросу Ну вот как-то пока пока мы остановились на сравнении что кажется что кандинский 21 обходит шедевром но возможно субъективным петь улыбается по фидбэку по фидбэку можно сказать что модель достаточно активно разошлась и разные пользователи игрались и в рамках PR компании и просто При этом в международном поле тоже было интересно SEO H1 Face прокомментировал выход модели и мы как-то стали с ними сейчас вот сотрудничать в части развития модели на medium.com вышел интересный обзор также была ветка на реддите достаточно активная много разных платформ которые реализуют у себя какой-то функционалом или моделей они имплементируют к себе эту модель и разворачивают там для того чтобы можно было с этой моделью поиграться Ну вот я и вполне интересный такой проект там даже есть marketplace и ты когда генерируешь какой-то модельки картинку ты можешь там типа выставить на продажу и на этом зарабатывать какие-то деньги Ну вот Вот такая интересная штука как я уже сказал сходил фейс мы подружились и с летом команды диффузер с Это самый крупный наверное сейчас фреймворк открытый в котором появляются все генеративные модели Мы с ними заколабились и выгружаем туда соответственно версии модели для того чтобы они у себя имплементировали разворачивали но и модель попадает во все продукты Где используется дифферс тем самым модель можно использовать абсолютно в разных приложениях которые построены на этом фреймворке тоже очень интересный выход Ну вот считаю что это отражает в принципе популярность модели с точки зрения гитхаба здесь кратенькая статистика в принципе по ней все видно даже комментировать особо нечего просто видно как увеличилась популярности модели после выхода в апреле версии 2.1 что касается применения понятно что все кто работают в бизнесе они как правило хотят найти какой-то фин-эффект от любого применения от любого добавления какого-то какой-то фичи в свои продукты и конечно генеративные искусственный интеллект Он позволяет генерировать очень разные изображения под разные продукты под разные запросы делать их вариативными и с точки зрения там каких-то маркетинговых компаний с разработкой там логотипов каких-то брендированных продуктов это в принципе позволяет давать буст с точки зрения бизнеса для сравнения с конкурентами Это хороший такой кейс для демонстрации связки современностью с каким-то современными тенденциями и с возможностями которые можно использовать вот генеративную искусственного интеллекта вот несколько коллабораций которые у нас были самые интересные наверное кофемания настоящий момент мы делали два блюда два таких продукта с ними в прошлом году мы дегенерировали десерт и напиток А в этом году генерировали завтрак и вот как-то завтрак так хорошо зашел что он по моему попал сейчас в основное меню смысл заключался в том что мы по набору по описанию набора ингредиентов просто генерировали разные образы визуально этого продукта Ну и потом этот визуал он просто как бы имплементировался кондитерами и попадал в меню с использованием технологии генерировались вот такие длинные развертки на стаканы для того чтобы можно было создавать картинки связанные вот в контексте какого-то единого описания есть еще очень интересный кейс это возможность использования генеративных моделей для того чтобы создавать видео вот здесь у меня есть пару роликов которые мы делали 12 апреля смысл заключается в том что используя механизмы рейтинга можно моделировать процесс Зума картинки в плюсы в минус И тем самым создавать новые картинки делать какие-то динамические переходы и по сути синтезировать видео еще один вот такие залипательные истории мы делали вместе с коллегами из Бер девайс для демонстрации возможностей генеративного искусственного интеллекта здесь текстовое описание подбирались музыка генерировалась и видео тоже генерировалось как раз на основе создаваемых картинок а как все знают мы еще делаем такую штуку которая называется гига чат это аналог Чад gpt на русском языке Он позволяет работать с текстом строить диалог текстовой форме Но пока он не зарелизен и все что я могу вот рассказать из его возможностей с точки зрения связки с кандинским мы сделали так называемый фьюзблоки которые позволяют использовать для генерации картинок Это означает что модель умеет понимать те инструкции которые пишут пользователь и в зависимости от того есть ли в запросе потребность на генерацию изображения она отправляет запрос в модель кандинский и кандинский уже генерирует картинку по тому запросу который содержится в контексте при этом следует отметить что вне зависимости от длины контекста модель правильно создает вот этот вот описательный текст для модели кандинский для того чтобы она отправилась уже она с правилась уже с этой генерацией что касается выводов здесь я провел лишь несколько примеров того Где используют сейчас генеративные модели на основе них строится разные продукты связанные с графическими редакторами онлайн редакторы строятся различные курсы по архитектурному проектированию чтобы можно было создавать какие-то визуалы потом их переносить в какую-то трехмерную форму то с чем работают в принципе допустим архитекторы То есть это некоторые механизм который позволяет избавить от определенной рутины и создавать какие-то затравочные образы чтобы архитектором дизайнером было проще развивать их и дорабатывать до какого-то более интересного продукта есть продукт лексика который представляет из себя по сути поисковый движок но в случае если ты не находишь чего-то в этом поисковом движке то ты можешь эту картинку сгенерировать тем не менее настоящее время наверное Ну я думаю многие уже слышали про такие модели миджорнисты был дифьюжн кандинский длинный ряд и на самом деле кажется что Все только начинается начинается в том смысле что неохвачены модальности видео потому что все что сейчас генерируется достаточно крыжово выглядит и чего-то красивого кроме там вот составных смоделированием разной динамики видеороликов типа того как я показывал особо не получается есть модальность 3D Но и так или иначе я думаю что мы с течением времени дойдём до какого-то существенного преимущества и даже недавно было выступление или там интервью одного из руководителей Marvel Marvel Studios Он сказал что где-то через два года видео фильмы будут синтезироваться полностью с помощью искусственного интеллекта Ну два года конечно звучит амбициозно с точки зрения качества но я думаю что через пару лет в принципе факт создания видео по текстовому описаниям по каким-то сюжетам будет уже не чем-то таким изрядном выходящим а Вполне себе Вполне себе понятным и ожидаемым явлением Я здесь оставляю контакты и ссылку на опрос Можно мне написать если вдруг возникают какие-то вопросы еще там на стенде будет крутиться презентажкой я туда даже буду подходить можно там пообсуждать но и ссылка там на мой канал кому интересно там пишу про наши исследования про результаты и в целом рад ответить на Ваши вопросы и пообщаться Спасибо Спасибо тебе за замечательный доклад в очередной раз узнали новое просто даже и думали маленький брезент от организаторов и у нас первый вопрос Давайте спеть начнем в первую Да у нас легкая высоко нагруженная кладку на всего лишь два микрофона то что остальные 3 я забрал да спасибо большое за Open Source и за двигатель прогресса Таким образом у меня два вопроса без подколок вы обучались на миджорни на результатах мы использовали некоторые результаты для Тюна но не в общем Хорошо зачем это сберу генерировать картинки Слушай у меня команда чистый ресёрчивый и мы Нам очень нравится следить за там хайпами технологиями следить за тем что актуально Что популярно и делать Boost в качестве вот этих направлениях то есть для меня как исследователи это интересное направление тренды То есть я не зарабаты ваю с этого у меня нет цели У меня нет цели с этого заработать у меня kpi сделать на норм статью интересный результат запостить и вот рассказать про то что мы выпускаем а она твой взгляд когда нейронка сможет жить выступить с таким докладом сейчас вот ЕГЭ чат выпустим и все ездить перестанем коллеги друзья просьба голосовать за доклады чтобы мы знали как очень не Рокки чтобы классно у нас все И у нас следующий вопрос есть у сбера план сделать какой-нибудь крутой юань как типа автоматика leveline чтобы он дефорум был контролл нет вообще все вот есть первая такая версия называется fusionbrain.a это такое видео фоторедактор Да где ты можешь загрузить картинку можешь там попользоваться функциями мы продолжаем развивать Но не супер активно Но вот скажем так это Шаг в направлении как раз вот ЮА и Генерала для фото изображений то есть какие-то фоторедакторы и так далее очень круто потому что кейберы они вообще куча денег на этом заработали и это хоть начнет окупать все эти Ну да это правда и у нас следующий вопрос Всем привет Большое спасибо за доклад самого тема очень нравится Хотя обязательно подпишись такой вопрос как ты думаешь упремся ли мы в тупик обучение Ну то есть в рекурсию не помню как называется то есть когда все тексты уже сгенерирован нейросетями и не на чем обучаться также все картинки сгенерированы и фильмы то же самое ну то есть это наверное продолжение к вопросу про обучались ли вы нами джорней Ну то есть это будет какая-то остановка в развитии как будто бы Ну на самом деле некоторые домены всем моделям ещё дают с трудом и как ни странно до сих пор модели не научились нормально считать то есть очень сложно создать картинку где ты точно указываешь какое-то количество объектов собственно пальцы это была как раз проблема оттуда же сейчас она более-менее как-то нивелировалась и модели стараются генерировать пальцы более-менее естественно мы там даже для этого использовали dtset жестового языка который Вот ребята в девайсы делают мы его брали просто имплементировали в обучающий выборке потому что ну это дало буст именно вот для генерации пальцев я думаю что всегда будут оставаться доменой которых будет что-то что улучшать потому что генеративные модели они Ну пока это не не идеал который даст тебе стопроцентный качественный результат сложно сказать когда это закончится но пока проблем ещё в итоге предостаточно Ну слушай Мне кажется человеческая культура гелевого каким-то тысячей летями и у нас ещё и опасный наверное лет 50 вопрос Андрей Спасибо за выступление очень интересно у меня вопрос такого рода лет 15 может быть 10 назад активно говорили о двух направлениях генеративных Это первое электросхема второе оптимизация структура инженерных в эту сторону работает ты имеешь в виду изображение электросхем Я имею в виду когда мы не картинку генерируем А генерим реально работающую технику или же оптимизируем Эйфелеву башню мы конкретно этим не занимаемся но направление интересное Безусловно у нас вопрос пока чата и если способ ограничивать использование памяти чтобы ты не значило ограничить использование памяти Да но дистиллировать модели Если вдруг они не влезают в память и для того чтобы заносить на какие-то маленькие устройства но наверное надо как-то дистиллировать уменьшать число параметров квантовать параметры ну у нас есть небольшое направление в рамках которого пытаемся оптимизации заниматься моделей для того чтобы как раз вот на какие-то конечные мобилки затаскивать но пока это тоже не Core направлении исследований поэтому вопрос да спасибо за доклад Вопрос такой очевидно что модель может генерировать абсолютно что угодно включая шок-контент но различную порнуху и так далее Как вы с этим боретесь и боретесь ли вообще с этим Да боремся и это были первые как бы проблемы которые возникали у нас после релиза потому что всем непременно нужно что-то такое Суровое загенерировать У нас есть несколько механизмов фильтрации Один он реагирует на стоп слова после которых мы выдаем определенную картинку типа с цветочками поле или ещё что-то есть набор слов сочетания которых дает нам там через sentensbert некоторую оценку близости к негативному контенту мы это тоже фильтруем и есть слова которые мы просто подменяем если вдруг они появляются в запросе для того чтобы там убрать какой-нибудь мат Там или что-то такое чтобы опять картинка генерировалась приличная вот слушай это звучит прям как Челлендж сделать не ромку чтобы она генерировать обходила все ваши фильтры битва неронок Кто знает есть веселый кейс синицами Но мы его прикрыли вообще орнитология очень богата на пошлые слова Я не знаю почему у меня нет знакомых орнитологов но я бы спросил почему на английском языке многие слова имеют двойное значение и у нас следующий вопрос Андрей Спасибо за доклад скажи пожалуйста вот ты перечислил метрики одну fidd а за какими продуктовыми метриками вы следите Потому что ты говоришь с какой-то версии у вас становится картинки очень четкими где-то есть проблемы с пальцами и еще наверное есть каких-то какое-то количество проблем по которым вы можете понять там что у вас модель перешла на новый уровень Вы эти метрики как-то размещаете сессорами либо еще как-то из-за ними отслеживать либо просто качественные разработчик теперь четко стало как-то происходит на самом деле мы сейчас поставили эксперимент на разметку как я сказал СБС это сайт смысл заключается в том что на один и тот же текст генерируется изображение разными моделями и отдаются разметчикам которые смотрят и ранжируют Ну типа это лучше это хуже или там это хорошо сгенерировал Это плохо Ну как правило это делается для двух моделей то есть мы выбираем условно кандинский допустим там stable цель какой-нибудь Да генерируем там тысячу картинок на 10 доменов по 100 штук и разметчики смотрят типа это лучше это хуже обе плохие обе хорошие и мы такую разметку делали на первом кондинском и она в принципе отражала как раз качество моделей Вот я думаю что это более объективная вещь чем решение здесь Потому что она хоть и такая количественная Да точнее даже качественная но не отражает визуального восприятия человека то есть условно можно сгенерировать очень похожую картинку с точки зрения метрики Fit очень похоже но за счёт того что она будет стилизована под Нечто такое слегка мультяшное они естественно у тебя Метрика фид может упасть Ну в контексте вырасти Короче говоря то есть она станет хуже но в реальности у тебя будут совершенно качественные картинки и любой разведчик даст по вот оценке СБС а у нас следующий вопрос Здравствуйте спасибо большое за доклад было интересно у меня два вопроса есть первый это в рамках скажем так борьбы с фейками используются ли какие Вот какие-то вот сгенерированных изображениях ну потому что например вот stable Fusion они у себя в кодинге добавляют watermark что можно было отличить с генеральную картинку и второй вопрос Вы уже сказали что вас используется проверка на нецензурный контент скажем так вот собственно вопрос это прямо в кодинге прописано Но для текста или это что-то как-то модель устроена Ну что если по сути Ну какой-нибудь программист Может это убрать и там генерить что-то не очень хорошее Спасибо за вопрос на первый вопрос ответ точнее Давайте со второго начну с точки зрения фильтров все фильтры они встроены в продукты и там модель которая лежит на гитхабе она не задушена то есть она Ну то есть Любой человек может ее развернуть но это уже на его ответственность и в пользовательском соглашении Там аккуратненько написано что если вы разворачиваете модель то вы сами несете ответственность в принципе за эти генерации которые создаете То есть это ну не интересно выкладывать модель которая задушена потому что у каждого фильтра у него есть ошибки Да если бы Мы выкладывали и вносили вот эти фильтры именно в саму модель то скорее всего портилось бы и другие генерации то есть любая фильтрация на уровне модели она создаёт определённый Бас и этот боец он ну его тяжело потом исправить Вот первый вопрос еще раз повторите пожалуйста а при генерации моделей используется ли какие-нибудь марки которые добавляются никакие не используем Мы думали на этот счет Ну что-то отправили в маркетинг на согласование вариантов марок где-то там Эта история потерялась поэтому мы особо не следим Но идея хорошая она нужна то есть сделать какие-то вот подписи внизу чисто вот в теории можно сейчас отличить что модель была сделана в кандинский какой-то изображение визуально какие-нибудь инструменты визуально Ну нет Если вы скачаете себе вы будете отправлять просто как картинку то типа Ок понял спасибо большое И у нас финальный вопрос Да спасибо за доклад мне вопрос такой как ты думаешь может ли нейронка воспринимать через какое-то время более абстрактный пронты То есть я имею ввиду ситуацию Когда нужно не только сгенерировать как Но сгенерировать что я пыталась честно говоря на кондинском что-то такое сделать и не получил Ничего хорошего Как думаешь вообще возможно и какие концептуальные сложности это возможно и это на самом деле задача промт инжиниринга Потому что когда ты хочешь сделать что-то сложное и очень интересное то ты во-первых должна понимать у себя в голове как это выглядит То есть ты должна визуализировать Потому что если ты придёшь и скажешь модели нарисуй мне э Скажем я не знаю перфекционизм Ну вот я не знаю как это визуализировать что она Нарисуйте Я тоже не могу себе представить э-э Но если ты начнёшь этот образ расписывать каким-то ключевым словам что ты связываешься словом перфекционизм что это там идеальная форма идеальная структура ровный контур ещё что-нибудь и начинаешь вот это вот набрасывать то у тебя получается В итоге картинка которая похожа Возможно на то что ты для себя пытаешься визуализировать То есть я веду к чему что если по твоему запросу что-то не получается не факт что еще проблема в модели вот промт Инжиниринг это действительно сложная штука и вот там у меня в команде есть два человека которые этим занимаются вот у них двоих всё обалденно получается как будто с первого раза Я сажусь Берусь что-нибудь делать У меня вообще нифига не выходит То есть это вот какой-то подход именно с точки зрения декомпозиции запроса на какие-то образы и ну э с этим надо просто вот экспериментировать сидеть и Вполне возможно что можно сделать накидай мне эти запросы которые не получались я им отдам Пусть они по челленджи друг другу Ну я просто имела в виду ситуация знаешь как бы помощи скажем так помощи в креативном виде Ну например а в корректора Да там есть такой режим там креативным помощником и так далее накидывает идеи да соответственно э визуально Мне кажется тоже можно было бы накидывать идеи да когда ты не можешь сформулировать в голове да Ну что-то ну как бы не только помогает тебе сформировать А да Ну вот такие решения есть и в принципе которые помогают создавать запросы правильные но мы вот вот направление особо не копали но да Мне кажется это отличная тема для дискуссии в зоне феей это правда да и он сейчас наверное самый интересная Выбери лучше вопрос и мы вручим подарок книгу мне понравился вопрос Петя все у нас один один Все спасибо спасибо"
}