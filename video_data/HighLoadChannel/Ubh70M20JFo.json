{
  "video_id": "Ubh70M20JFo",
  "channel": "HighLoadChannel",
  "title": "Эволюция платформы данных для своевременных коммуникаций со 100+ млн клиентов / Илья Нечаев (Сбер)",
  "views": 146,
  "duration": 2351,
  "published": "2024-10-29T03:04:18-07:00",
  "text": "приглашаю Илью Нечаева Прошу прощения ле супер незаметный всё всё внимание на Илью так Всем привет Меня зовут Нечаев Илья Я являюсь лидером разработки витрин данных на платформе дуп занимаюсь данными более 6 лет начинал как аналитик данных сейчас японя выполняю роль чиф продук Ора команд разработки за время пока я выполняю эту роль мы реализовали более 240 витрин общим объёмом Почти 10 пиб и сегодня расскажу как мы это сделали с чем мы столкнулись и как мы решали проблемы которые у нас возникали но в первую очередь я расскажу нашей бизнес зада и то что мы делаем в рамках сра а мы занимаемся созданием точнее мы занимаемся коммуникацией с клиентами нашими А и наша основная цель - это сделать коммуникацию персонализированной а и дать почувствовать клиенту сбера себя уникальным при взаимодействии с нами то есть мы не хотим каждому клиенту делать одинаковую коммуникацию а хотим эти коммуникации персонализировать например А мы знаем что клиент каждые 2 дня покупает в супермаркете продукты чтобы при готовить себе ужин и зная это мы можем предложить ему закрыть его потребность через например МегаМаркет предложить ему оформить доставку продуктов которые емы нужны напрямую в квартиру человеку не нужно будет идти в супермаркет тратить время он сможет его потратить на более полезные и важные для себя вещи но такая персонализация невозможна без данных и для того чтобы этого достичь нам требуется действительно максимум Да И помимо этого данные должны быть достоверны и актуальны начинали мы с платформы размером в 100 теб это Примерно 200 Айфонов Да если там нас умножить в два раза примерно Мы можем с помощью наших телефонов такую платформу собрать за 3 года мы выросли в 100 раз и достигли размеров 95 теперь расскажу как мылись и какие проблемы у нас возникали начинали мы роты это была система в которую реплицировать порядка де ключевых банковских систем это данные по картам депозитам кредитам реплицировать нормально и при этом стоимость хранения данных была довольно высо 000 долларов понимая что нам не нам будет необходимо и количество данных у нас сильно увеличится необходимо хранить больше данных а также на теро дате мы не могли хранить большую глубину да то есть мы хранили например всего год транзакций в то время как нашим моделистам требуется почти 5 Ну не меньше чем 5 лет Да очевидно что нарада мы такое развить бы не смогли и мы посмотрели в сторону платформы дуп Какие ключевые фичи этой платформы на нас оказали влияние Почему мы её выбрали в первую очередь это стоимость хранения то есть ходу позволяет нам довольно дёшево хранить большой набор Информации а помимо этого позволяет хранить ещё и не структурированную информацию например файлы видео текст вместе с этим платформа ходу позволяла нам реализовывать и иную механику помимо Бах обновлений витрин это realtime обновление витрин и работу с потоками данных также то о чём я говорил о глубине хранения мы можем на ходу хранить сильно больше и это очень круто для наших моделистов Ну и вместе с этим мы не забываем про актуальность качество и Надёжность ведь построение платформы эти компоненты крайне важны Сейчас я покажу промежуточную архитектуру которая у нас получилось когда мы начали внедрять платформу У нас есть слой источника У нас есть источники их довольно большое количество они реплицируемый интеграцию источников также начали реализовывать в платформу и отдельно мы стали разворачивать платформу как потенциальную замену роты у на были пользователи которым которые выполняют аналитические запросы и mpp система для этого подходит сильно лучше чем Ду следующим слоем после сри данных это у нас был слой витрин данных витрина данных мы реализовывали на платформе идея была в том чтобы мигрировать всё что мы сделали в на эту платформу и в конечном итоге заменить вывести её из эксплуатации оставить в текке только ходу и гнп и мы конечно как и все думали что миграция - это просто что у нас есть написанный код У нас есть все алгоритмы мы возьмём до эмигрируй делов Да но оказалось что это не просто совсем в первую очередь мы столкнулись с основными проблемами это другой стек У нас не было разработчиков на дупе нам Срочно пришлось искать команду которая всё это будет делать также реализованные на ходу витрины и бизнес-процессы не были описаны это отдельная боль и мы потратили Очень много сил на то чтобы решить эту проблему но решая проблему и проверяя гипотезы и понимая какой алгоритм нам необходим для того чтобы эту витрину построить ну этот набор витрин построить У нас не было тестовой среды нас не было среды где мы могли промышленные данные куда мы могли принести прототип алгоритма и понять корректной оно или некорректной поэтому все гипотезы мы тестировали через релизы мы релизинг быть четыре-пять вполне на один атрибут учитывая что нам необходимо было каждый раз перебирать дистрибутив и выкатывать его заново время на релиз было почти Ну наверное 1-2 дня на одну итерацию и это довольно много Это очень много и также Нам необходимо было подтверждать корректность данных например Мы часто сталкивались с ситуацией когда что-то реализованное в теро дате и Мы считали что это корректно при реализации этого на хопе сравнивая данные Мы понимали что что-то идёт не так что-то разъехались и в итоге выясняли что проблема была в теро дате в хопе всё классно всё здорово всё работает в теро дате проблема И всё это нас приводило к тому что в среднем мы тратили почти полгода на разработку одной витрины это очень много учитывая количество витрин которые нам нужно было мигрировать а учитывая наши амбиции и то что Сбер рос и количество партнёров сбера увеличилось и Мы понимали что и новые витрины Нам нужно будет реализовывать С такой скоростью мы бы мигрировали году в 2030 очевидно Не бизнес не нас это кардинально не устраивало поэтому мы пошли в попытки в попытку оптимизировать наш процесс и в первую очередь мы начали с платформы прототипирования мы разработали отдельную платформу А куда пользователь может прийти и погонять на промышленных данных свои тесты таким образом А увеличив количество итераций с там одной в д оди день до чех за один день Мы очень сильно тут ускорились и отдельно мы посмотрели на разработку и задумали и реализовали фреймворк который позволил Нам её ускорить в три раза в чём его основные преимущества в первую очередь мы посмотрели на разработку с точки зрения конвейера мы разработали ряд модулей которые выстроили последовательно каждый модуль отвечал за собственный фую имел например там откидывание логов аудит склейка мелких файлов если она нам была нужна в процессе и мы могли очень гибко эти модули подключать и отключать то есть если нам в проекте какой-то модуль был не нужен мы его смело выключали и не тратили на это сил при этом модули легко конфигурируется то есть нам не нужно было понимать что в НМ За какой код мы конфигурирование легко эти модули подключали также эти модули позволяли нам гибко управлять ресурсами то есть мы можем на каждый модуль заложить необходимые этому модулю количество ресурсов таким образом а не въ едая лимит нашего кластера и отдельной фич реализовали парализации вычислений то есть на одном из шагов мы можем считать 1 2Т потоков параллель при этом следующий шаг не стартует пока эти три потока не завершатся успешно и также немаловажно для нас была была возможность чтобы разработчики могли взаимодействовать с нашим фреймворков не только те разработчики которые знают джаву но и те которые знают скалу это также серьёзно позволило нам Ну то есть больше команд больше людей смогли нашим фреймворков одно из витрин которую Мы собирали на старте которая состояла из 100 таблиц такую витрину команда из че Человек формировала почти разрабатывала почти 6 месяцев Если бы эта же самая команда приступила к реализации задачи с использовани фреймворка это заняло бы 2 месяца а команда которая ранее с фреймворк быстро и выводить новые и новые витрины в пром мы начали сталкиваться с проблемой что не все витрины расчёт не всех витрин успешен Да часть витрин ночью падает по каким-то причинам А например не знаю отвалилась нода на кластере что в целом для хадуп вполне нормально или не хватило памяти потому что нам в инкремент приехало больше данных чем мы ожидали и мы стали думать в сторону а мы стали думать в сторону того как сделать наш тракт более надёжным и в первую очередь мы посмотрели на процесс восстановления расчёта с точки падения то есть мы в нашем расчёте расставляем чекпоинты после каждого шага и если этот расчёт Этот шаг успешно пройден мы откидывать влог КПО что этот шаг пройден и если поток падает то после падения мы анализируем понимаем На каком шаге мы упали и с этого шага расчёт то есть мы не тратим Лишнее Время на то чтобы повторить то что мы уже Считали и также вдобавок к этому мы реализовали автоматическую обработку этих ошибок то есть чтобы не зависеть от инженера который смотрит за нашим потоком и должен предпринимать какие-то действия чтобы его поднимать мы реализовали автоматическую обработку этих ошибок которая позволила намм типовые Проблемы такие как проблемы с там недостатком памяти или проблемы с сетью которая там моргнула в ненужный для нас момент а легко проходить и продолжать расчёт и также немаловажным для нас было реализовать процесс ба копирования У нас не было централизованного ба копирования в системе как таковое и но при этом витрина даже если она технически обновилась успешно не всегда была консистентная поэтому часто особенно в самом начале у нас Мы Нели и продолжать с этой витриной дальше работать витрина не консистентная чтобы её обновить пока витрина обновляется она не консистентная нам в этом сильно помогает мы обновились поняли что обновились неуспешно откатились но пользоваться Ей можно а при этом в параллеле с этим мы повторяем расчёт для того чтобы догнать актуальность а также мы смотрели и на качество данных мы реализовывали проверки уже готовых витрин то есть процесс был такой что витрина построилась витрину проверили после там того как витрину проверили узнали качественная она или некачественная такой процесс не всегда рабочий А почему потому что пока мы когда мы витрину Обновили и пока мы ещё её не проверили в этот момент витриной могут начать пользоваться она может начать идти в бизнес-процессы или аналитики могут на ней начать что-то собирать и таким образом результат который коллеги получают Ну и и которые уходят в бизнес-процессе был сомнительного качества и мы решили встроить проверки внутри Тиля Это позволяет нам добавлять проверки на любой шаг расчёта нашей витрины таким образом контролировать этот расчёт И если в ходе расчёта что-то пошло не так и мы поняли что мы пробили пороги проверок качества мы прекращаем расчёт таким образом не обновляя финальную витрину финальная витрина остаётся консистентная разбираемся что пошло не так Почему возникла эта проверка и что делать чтобы её исправить Надёжность и качества хорошо но также нам важно было достичь и быстрое время обновления часто в начале это было почти всегда витрину мы обновляли с актуальностью в т минус день примерно к середине рабочего дня а нам нужно было обновлять эти данные к началу рабочего дня для того чтобы и аналитик и инженер и ML ML инженер который приходит на работу мог сразу пользоваться корректными актуальными данными Но не все наши витрины простые а часто совсем Непростые вот тут мы на примере видим А что у нас м довольно развесистый довольно развесистый Граф а довольно много джоно в процессе и как бы мы не оптимизировали код не всегда у нас получалось сократить время расчёта и уложиться в нужный нам тайминг поэтому мы стали смотреть рядом а что мы можем ещё сделать и как мы можем ещё изменить наш процесс для того чтобы достичь того времени которое нам хотелось и мы посмотрели на сырой слой данных и на возможность его изменить для того чтобы мы могли быстрее вычитывать данные и общий наш процесс работы также был быстрее но это тоже не всегда работало и не всегда приводило нас к успеху Например у нас была довольно сложная витрина сложная аналитическая витрина коя стояло более чем из ри таблиц источника которые нам нужно было между собой пересекать а вместе с этим Нам необходимо было применять ещё сложны аналитические функции для того чтобы получать производные атрибуты такую задачу как бы мы не пытались её оптимизировать на ходу быстрее 8 часов нас ничего не получалось закидывать ресурсами тоже не вариант а но у нас есть рядом платформа Green mpp система которая прекрасно справляется с такими задачами и подключив эту платформу и создав трак данных что в дупе мы формируем детальные данные передаём в Грин Плам рассчитываем сложную аналитическую витрину возвращаем её назад суммарно У нас на это ушло 4 часа и мы ускорились более чем в два раза и достигли нужного нам результата отдельно мы ещё и посмотрели на возможность расчёта несколько раз в день Это давало нам преимущество особенно хорошо это работает для витрин фактов и например транзакционных витрин на примере одной из таких витрин - это кстм мобильного приложения когда мы в день получали Почти 10 теб инкремента и время применения этого инкремента если мы обновляемся раз в день достигало 8 часов это время выедания дом все остальные витрины Таким образом мы и имели не очень хорошую актуальность и при этом ещ и вреди основны другим потокам которые в параллель считаются поэтому мы посмотрели на возможность разбить этот расчёт в течение дня применяя маленькие часовые инкремент актуальность и распределить нагрузку На кластер какие тут минусы да В первую очередь это минусы для наших ну такие Это скорее не минус А это скорее особенность работы с этими данными что пользователь когда понимает что витрина часто обновляется в течение дня должен уметь с ней работать да два запроса которые он может сделать к витрине В разный момент времени могут дать разный результат поэтому опять же важно а уметь работать с этими данными и понимать как с этими данными работать следующим шагом когда мы разобрались с бачо и более-менее у нас ВС работало классно и хорошо мы начали смотреть в сторону реалтай и нетай обработке данных одной задач которые мы с помощью этой этого процесса попытались решить Это задача расчёта транзакционных агрегатов то есть идея была такая что Мы считали агрегаты по транзакциям на клиента и если этот агрегат перевалил некоторый порог мы формировали трир который отва систему которая взаимодействует с клиентами для того чтобы сделать клиенту то или иное предложение как эта штука работает у нас есть набор транзакций который лежит в баче и доступен в ми в т ми1 день на основе этих данных мы сформировали нужные нам агрегаты положили их и дальше имея поток каки поднимали уже Посчитай агрегат изза обогащая сравнивая Посчитай агрегат с пороговым значением если если оно удовлетворяло условию передавали тригер дальше теперь как ОЮ покажу архитектуру и то к чему привольно много ини в виде автоматизированных систем которые грузятся в сырой слой данных Где остался только дуп там больше нет теро даты у нас порядка 100 реплик и порядка даже больше 15 петабайт данных которые там лежат дальше на основе этих данных мы формируем уже слой витрин данных а также формируем онлайн обработку этих данных и дальше с помощью каки передам сообщени в аналитические или системы принятия решений для взаимодействия с клиентом помимо того что у нас работают промышленные процессы и процессы взаимодействия с клиентами А у нас также есть обычные пользователи это как я уже говорил аналитики модельеры которые с этими данными работают у нас порядка 200 пользователей ежедневно ежедневно уникальных и 600 пользователей ежемесячно переход на новую платформу позволил нам не только получить лучшую актуальность и сэкономить но ещё и за счёт опять же повышения актуальности данных и за счёт того что мы стали больше данных иметь мы снизили количество жалоб и повысили доходность части компаний что хочу сказать в конце а пройдя этот сложный этап эволюции и столкнувшись с теми проблемами с которыми столкнулись А самое наверное первое что важно чтобы команда разработки и команда которая делает витрины интеграционные процессы понимала что она делает И зачем она это делает то есть не просто были исполнителями задачи которые для них написали Да а тоже понимали бизнес смысл этого решения это важно потому что повышается вовлечённость команды в решение задачи и также сама команда когда прокачает и понимает что она делает она может предлагать совсем другие решения которые могут быть эффективнее Чем то которое команда получила на вход Также важно иметь единый инструмент для разработки и отдельную команду которая этот инструмент которая этот инструмент развивает на примере нас у нас нет отдельной команды Я честно думал что я смогу этот инструмент развивать с помощью продуктовых команд А просто добавляя в клок задачи на развитие на развитие фреймворка но бизнесов выигрывают над развитием фреймворка поэтому аэ идея была ну не самая лучшая также как следующие шаги мы хотим а внутри нашего инструмента а реализовать а интерфейс работы с ним таким образом Аа позволить решать простые задачи с помощью Low кода или даже Ноу кода и то чего нам наверное ещё не хватает на то к чему мы идём это лучше описать фреймворк чтобы снизить порог входа для его использования И как я уже говорил в середине своего доклада очень важно иметь область прототипирования то есть область где можно проверить гипотезы которые аэ помогают реализовать финальную задачу ну и в конце хотелось бы сказать что миграция - это с одной стороны страшно с другой стороны это то а что что необходимо и что нужно сделать потому что большие данные - Это здорово Спасибо Да так Спасибо за доклад Да и я напоминаю то что у нас за лучший вопрос положен приз Поэтому в голову записывай и выбирай потом автора лучшего вопроса А даже два вопроса опять мне говорят Вопрос такой не замети на архитектуре метку данных моделирование данных определение мастер данных вы как сейчас сделаете согласованность модели данных вот В текущей архитектуре и планируете ли использование систем МДМ А смотри скорее мы знаем а целевые системы которые хранят данные и зная это мы уже как непосредственно команда которая делает решение понимаем откуда нам лучше эти данные забрать Здравствуйте спасибо за акат А вот про качество данных То есть вы в каком где вы его тестирует где Ну два вопроса Первый первый вопрос - Это всё-таки про каким образом вы выкатывается там на прот то есть Есть ли процесс который автоматизирует выходку и изменение тех там скриптов тех процессов тех тел процессов которые вы там разрабатываете в том потому что там у нас много было был niifi чтобы это автоматизировать Это достаточно такая серьёзная солянка И вероятно достаточно сложно вот и есть решили этот вопрос У нас есть devops у нас реализованы devops трубы которые мы собираем дистрибутив в devops трубу и он уже оказывается на пред пром среде и дальше в пром среде Ну предположим Нет просто к тому что niifi он э по определённому там э конфиге там на него накатывают там отдельные технология для него у нас развернут отдельный кластер Для Линка там тоже другие технологии накатывание как бы тех новых конфигураций для дупа ещё вообще регистрация есть какая-то нет какой-то страции смотри скорее мы технологию не катим вместе с ретим витрино а сопровождение стендов и там изменение версий и конфигурирование это отдельно и у нас есть отдельная команда которая этим занимается а команда разработки витрин уже и даёт рекомендации к тому как его нужно настроить Ну и с чего начал по поводу качества то есть где вас оно контролируется В каком виде как вы это оркестри ете этот контроль качества м как у нас контролируется качество Ну как я говорил у нас есть а два элемента контроля первый элемент мы зашиваем внутрь нашего Иля результат а проверок Мы откидываются за метаданные и дальше из этой системы общий дашборд контроля качества данных подтягивает те результаты которые мы туда отдаём для отображения и второй шаг - это опять же проверки А уже построенных витрин там работает всё примерно так же а поток с неким набором функций проверяет то что у нас построено то что у нас построилась проверяет качество и дальше результат также передаёт в качество данных мы сэлем проверяем базовые проверки то есть базовые проверки которые на наш взгляд не которые витрина Обязательно должна проходить Да мы пишем SQL Но на самом деле это неплохо да отдельно У нас есть а инструменты контроля например в том числе и ai инструменты контроля с помощью которых мы проверяем потоки данных так а добрый день а большое спасибо за доклад было очень интересно у меня сложилось впечатление что при миграции вы всё-таки делали акцент на бе Metal решение Несмотря в облака это так всё правильно Подскажите А почему вы не стали использовать openshift который решает те же проблемы с авто слингом либо падением нот а потому что мы Сбер И для нас важна Надёжность и важна безопасность А чем облака они устраивают с точки зрения надёжности Ведь вы можете установить авто скейлинг и у вас упал под вы подняли новый упала нода взяли другую Ну любое Облачное решение А смотри Это здорово но у наших коллег из безопасности другое решение и другое мнение на этот счёт поэтому имеем то что имеем Как же сберклауд это следующий этап но опять же в сберклауд будут далеко не все данные Спасибо Здравствуйте спасибо за доклад такой вопрос Я не совсем понял как у вас данные катаются между ГП и хопом и Как вы Как вы это оркестри ете и Где самое главное потребители потребляют дупе или вгп или там и там у нас потребители есть и там и там то есть у нас есть потребители которые данные используют в дупе потребители которые данные используют в Грин пламени данные мы между ходу пом и Грин пмо А у нас есть такой общий глобальный а оркестратор планировщик А который может получать результаты расчёта в качестве а в качестве какого-то триггера Да того что почалось на хопе того что почалось на грип таме Таким образом мы можем автоматизировать Старт а перекладки данных между из а дупа в грим plam из гпма в ходу А мы используем pxf мы используем СР конектор для того чтобы забирать данные например из гринна в ходу и ещё вопрос Сколько у вас ГП и какой объём примерно тут к сожалению не подскажу о не очень не очень сильно знаком с с технической с технической конфигурацией гпма но прохо вопрос тоже был нет хоо Добрый день СБО заклад больному когда сказали про то что ночью падают витрины не всегда зависит от нас Вот и у меня вопрос там был пунктик про восстановление с точек отказа Да вот какими механизмами вы это реализовывали То есть это было просто как логирование чтобы понять На каком месте оно упало или вы как-то сохраняли промежуточные данные на диск промежуточные данные мы в любом случае сохраняем А и отдельно мы сохраняем чекпоинты успешности расчёта то есть после падения мы анализируем какие чекпоинты мы пошли соответственно все промежуточные данные доступны с уже собственно готового промежуточного расчёта с той точки где мы упали Просто насколько мне известно и на нашем опыте что это довольно сильно нагружает расчёт потому что ну вызывает повторные расчёты Ну как Ну в общем запись затрагивает много ресурсов и времени Вот чем просто при расчёте всё в памяти или вы не замечали такого всё нормально но мы на самом деле это не замечали А и вместе с тем хранить всё в памяти Мы тоже не можем У нас очень много данных сложные расчёты физически сложные расчёты Если всё хранить в памяти Ну нам просто не хватит кластера для того чтобы это всё считать поэтому очевидно что мы прочные расчёты скидываем хорошо спасибо Добрый день Спасибо большое за доклад у меня такой не технический вопрос а больше такой организационный может быть была ли у вас Ну бывает ли у вас ситуация когда бизнес очень много всего просит не не до конца понимает Зачем И при этом просит какую-то большую глубину хранения вот как с этими ситуациями справляетесь Ну то есть постоянно это происходит постоянно а ну мы тут подходим с точки зрения и нашего понимания того сколько это будет стоить и с точки зрения того чтобы бизнес всё-таки осознавал и понимал что он хочет И для чего он хочет Ну то есть если это какой-то Пилот если нам необходимо А ну если бизнесу необходимо что-то там маленькое посмотреть мы можем временно для них не знаю расширить глубину хранения чтобы ребята посмотрели поняли что да работает да не работает после этого уже принять решение оставляем или возвращаем всё как было Ну то есть тут кес by кес индивидуально короче каж Привет В общем вопрос такой по архитектуре Миша Одноклассник иногда представляться просят Вот про архитектуру проп всё такое вы сделали ходу плюс НП в принципе популярная тема но некоторые компании в России изначально начинали своё ДХ с гпма или там Верки и сейчас они все ну большинство из нихто крупные меняют это всё на типа когда Всё лежит поверх этого три на какой-то считается цели Spark вот не думаете ли вы что вы тоже столкнётся что НП Ну в его классической формулировке типа плохо слится когда данных будет 50 пиб то всё равно придётся что-то другое придумывать типа там Спарк не трина заводить и гнп выносить опять мигрировать куда-то а но мы скорее идём в то чтобы создать а некую а некий UI для наших пользователей который бы позволял одновременно работать и с данными хадуп и с данными Рима в одном месте то есть нам не нужно было бы данные дупа тащить в гпм для того чтобы с ними работать из Грима работать с данными дупа или как Да ну не из Грима А из отдельной области работать как с данными ходу так и данными Грима просто имею в виду что вы настолько много захотите положить гнп Вот в эти вот аналитические витрины что перестанет как бы помещаться и придётся что-то новое опять пилить Ну вот как раз и этот подход должен нам с этим помочь НУП будет для того чтобы в Грин план Всё не тащить Ну да Ну а на хадуп вы сказали у вас медленно получается пока Поэтому собственно и Грин план появился медленно получается Ну вон там был пример что на ходу бе что-то 8 часов на на Плам че Да чтото что-то действительно в хаду бе считается медленно о Такова жизнь вопрос nme пробовали поставить кстати что nvme под спаркли там по тринус считалось м диски SSD а говорят быстрее считается ну оно может быть считается быстрее но у нас SSD диски скорее используется для ускорения нрт расчётов да то есть например под флинк положить SSD под хранил Ну довольно дорого На самом деле без микрофона не надо говорить пожалуйста а то люди которые смотрят нас трансляции потом смотрит записи не будут слышать этот комментарий так всё все вопросы там вот ещё рука вдали вон тамлин Здравствуйте лек МТС А подскажите а в процессе миграции у вас модель данных менялась как-то были изменения Да конечно мы в том числе при миграции старались от старых костылей которые мы сделали в рода или от неоптимальных решени уходить при этом пытаться расширить модель данных новыми данными которых например раньше в те просто не было новыми атрибутами либо создать новые атрибуты которых раньше не было Но которые нужны для новых бизнес-процессов Спасибо вот тут ещё одна рука у нас ещё есть время вроде даже да время есть но чуть-чуть да спасибо за доклад А вот такой вопрос а кто придумал архитектуру этого процесса то Ну вот Собственно как ВС сделать может быть перейти там на ходу добавить там к этому гм То есть это бы какой коллегиально или там может быть архитектор У нас есть отдельный отдельная команда Архитекторов отдельная команда ну Архитекторов том числе технических технических Архитекторов которые собственно это решение и предложили Мы в него поверили и в него пошли Вот кто придумывал использовать например неке какой-нибудь вот такие это уже совестно мы как команды разработки Ну то есть Мы понимали что ну то есть РТ процесс с H безо работает плохо о с hdf работает плохо сзм он собственно для этого и нужен и ещё один вопрос и мы заканчиваем Вот спасибо за доклад Маленький вопрос Вот вы упоминали что один из ключевых параметров было использование нагрузочной платформы профилирования гипотез А в конечном итоге она используется Ну то есть после миграции мы проверили гипотезы мигрировали дальше при разработке мы её продолжаем использовать и мы её используем на всём стеке технологий который собственно получился В итоге Да помимо этого эта концепция разрослась то есть теперь Э область прототипирования доступна не только командам которые что-то разрабатывают но и аналитикам и модельером которые с данными А собственно их отчёты или их ML модельки Ну то есть условно мы её используем и для проработки формирования витрин и для работы бизнес уже там технических пользователей Да спасибо Итак тебе нужно выбрать двух авторов самых интересных вопросов Ох самое сложное Да это самое сложное всего твоего выступления но ты справишься но давайте а первое место - это вот последний вопрос удобно хорошо да Так а второе место предпоследний вопрос а а я не помню последний или предпоследний А вот там молодой человек вот этот предпоследний вопрос Ты молодец прекрасно хорошо а и у нас для тебя есть небольшой Презент Я почти до него дошёл Спасибо тебе большое спасибо"
}