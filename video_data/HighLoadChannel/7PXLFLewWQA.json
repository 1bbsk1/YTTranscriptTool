{
  "video_id": "7PXLFLewWQA",
  "channel": "HighLoadChannel",
  "title": "Распределенная трассировка с Jaeger и Clickhouse / Филипп Бочаров (МТС Digital)",
  "views": 323,
  "duration": 2308,
  "published": "2024-10-29T03:04:09-07:00",
  "text": "и Филипп нам расскажет как не делал ПЛН трассировку джагера и кликом который не тормозит и главное для чего вы это делаете Приветствую Привет краткий экспресс вопрос А для чего это всё как для чего для того чтобы контролировать качество наших сервисов для того чтобы аварии предотвращать дать нашим продуктовым командам инструменты диагностики если вс-таки что-то произошло быстро в этом разобраться отлично Дума ближайшие 30 минут мы про это узнаем более детале я тоже на это надеюсь Всем привет да речь сегодня пойдёт Про Сервис распределённой дрессировки который мы разрабатываем ТС Меня по-прежнему зовут черов Филипп в т я жу цент мониторинга наблюда моя команда делает одноименную платформу который предоставляет ряд коммунальных сервисов а всем другим продуктам в нашем ландшафте это централизованное логирование сбор визуализация Трик и конечно же распределённая дрессировка про которую мы сегодня с вами очень подробно поговорим а для чего всё это нужно только что мы узнали поэтому перехожу сразу дальше а доклад является продолжением доклада двадцать второго года а там мы с вами строили наш сервис на базе кластера elastic Search и разгоняли его до 50.000 спано в секунду до этой нагрузки за год у нас произошло множество изменений Как архитектурных так и по нагрузке и об этом увлекательном опыте Я вам сегодня расскажу Для начала о задаче Зачем вообще бы что к чему мы идём Да что мы хотим достичь а МТС - Это довольно большая экосистема и Когда наш пользователь выполняет какую-то там важную бизнес операцию обычно в этом участвует не один продукт а целая совокупность Ну вот например как в этом примере Да у нас там четыре продукта а там пользователь оформляет подписку на услугу один продукт занимается там коммуникацией с пользователем отправляет вам эсэмэску второй биллинговая в команде эксплуатации или S инженерами и отвечали бы за вот эту бизнес функциональность оформления подписки А мы бы очень многое отдали за то чтобы если у пользователя что-то происходит Так да есть какая-то проблема мы бы вот эту схему увидели каким-то образом автоматически Да что здесь мы видим наш пользователь пытается оформить подписку на услугу запрос приходит к продукту А и уже между продуктами а и б начинается какая-то проблема Да процесс затягивается Нони А ни Б в этом не виноват виноват следующий в цепочке продукт C к нему б обращается постоянно идут какие-то ошибки ретра и в результате пользователь не получает ту услугу которую так хотел так вот чтобы такую картину каким-то образом автоматически собирать служит сервис распределённой трассировки Да по сути это структура данных такая древовидная которая показывает нам как во времени общаются наши распределённые сервисы между собой кто кого вызывает Сколько времени это занимает и есть ли там ошибки и вот такую картину мы хотим видеть по всем бизнес функциям во всей нашей экосистеме А как мы это делали в д втором году архитектура была следующая Итак у нас есть множество инструменти продуктов и сервисов этих продуктов Это значит что там внутри встроен СДК который собирает распределён ную трассировку с продукта То есть например все входящие запросы регистрируют к сервису исходящие и так далее вся эта трассировка собирается и отправляется на энд нашей платформы где её подхватывает множество инстан сов др коллектора а коллектор кладёт весь этот поток на промежуточное хранение в очередь Апачи кавка это нужно нам для того чтобы сглаживать различные пики нагрузки из каки это всё достаёт другой сервис J inest и он клал это всё в Клар на уже постоянное хранение для того чтобы работать с нашей распределённой дрессировкой у нас было Два интерфейса первые - это UI собственно Это родной интерфейс Джаггера который позволял делать различную операционную работу то есть по сути искать конкретные трейс по параметрам по конкретной проблеме также у нас была кибана в ней мы делали различные аналитические дашборды то есть имели возможность проанализировать не один а какую-то совокупность также мы с вами научились долгосрочные тренды по трассировке вычислять метрики так называемые метрики Да метрики производительности приложений мы написали для этого отдельный сервис serv который обрабатывал тот же самый поток трассировки высчитывали по каждому сну ту или иную метрику он понимал что вот это Спан это вызов базы данных этот входящий Запрос к нашему сервису и соответствующие метрики вычислят всё в та Ser базу данных в нашем случае это р vix и у нас была графана в которой мы могли наслаждаться дашборда например там как менялась производительность того или иного метода за там 6 месяцев и в принципе вся эта схема нас на двадцать второй год устраивала она обрабатывала 50.000 снов в секунду но времени не стоит на месте и нагрузка у нас растёт А ну вот для примера на скриншоте видно что по сравнению с двадцать вторым годом Сейчас мы имеем практически четырёхкратный рост нагрузки в дневные часы он достигает 200.000 есть пики выбросы до 300.000 и в течение времени наши пользователи жаловаться на медленный и нестабильный поиск Трей сов но это не самое плохое самое плохое - это то что вот этот подход к горизонтальному масштабированию кластера elastic сч перестал нас радовать Да своей производительностью то есть мы закидывали проблемы железом добавляли количество нот а производительность росла не то что нелинейно Да она увеличивалась там на небольшой процент и мы начали понимать что если нагрузка начнёт продолжит расти такими же темпами то никакого железа нам не хватит а была ещё одна проблема связанная с аналитикой Да О'кей у нас была кибана в ней мы могли строить какие-то аналитические дашборды но они нас не до конца устраивали по своему функционалу А вот в качестве примера слева тут приведён относительно сложный Сколь Запрос который бы мы хотели выполнять по нашему хранилищу что в нём происходит если читать его из наиболее вложенного Да а запроса к верхнему А что здесь происходит здесь мы находим все трейс а которые содержат определённую операцию Ну в данном случае Order fulfilment Да некая операция с заказом с ордером А дальше мы для каждого нашего рейса вычисляем его полную длительность то есть время от первого спанакопита ть этот запрос можно как время в который укладывается 95% выполнения той или иной бизнес операции например там выполнение нашей подписки так вот такой запрос выполнить по эластико в принципе невозможно нет под запросов нету джоновна и работает Это достаточно медленно была и вторая проблема связанная с тем что тяжёлые запросы аналитические с этих дашбордов могли приводить к дестабилизации нашего кластера elas sech в elas есть механизм защиты он называется seet Breaker Когда вы выполняете сложный запрос себ может сработать обрубить ваш запрос заодно обрубить запросы ваших коллег и вообще в принципе привести к тому что кластер начнёт работать значительно медленнее эти проб привели нас к тому что нам нужно искать какое-то альтернативное хранилище для наших рейсов которые и проблему с нагрузкой решит и аналитику нам позволит делать и наш выбор Пал на ха почему собственно на него дело в том что д из коробки поддерживает три типа хранилища Первое - это хранилище Это чисто тестовая вещь El И канги храни Моть пожа Смени ши Джагер написать свой плагин и поддержать там любой сторч который Вам нравится и для кликхаус это как раз такой плагин был он написало сообщество и мы здесь начинали не с нуля мы брали готовую разработку А первые же результаты r& были вдохновляющие мы увидели что на той же нагрузке jer UI работает на 20% быстрее быстрее ищет нам данные а хранение стало компактнее в несколько раз и мы как раз получили возможность делать те аналитические запросы к которым мы так стремились Окей раз с R всё удалось Давайте заводить эту машинку на продукти для начала как вобще Джагер работает с Клик хаусом как я уже сказал это реализовано через плагин и Джагер и плагин написаны на Go по сути плагина - это отдельный бинарный файл его можно передать в качестве параметра дге Джагер запустит его как отдельный дочерний процесс и будет с ним общаться по grpc То есть если вы хотите там какой-то свой ч реализовать ой пожалуйста вы пишете свой jpc сервер реализующий определённые а др с ним общается и таким образом абстрагируйся такого А мы взяли минимально вообще возможную конфигурацию никаких кластеров просто обычная Синода кликхаус наши сервисы Джаггера мы запустили с плагином нацелились её аналитикой мы взяли фану в ней есть замечательный Клик House плагин который позволяет кликхаус обращаться визуализировать результаты запросов и строить аналитику А на тот момент на сч ко нагрузка была 25.000 спано в секунду а кликхаус её прекраснейший образом выдержал и мы решили использовать это значение как референсное Да как некую схему масштабирования то есть на каждые 25-30 000 спано в секунду нам нужна будет отдельная нода а кликхаус О'КЕЙ на стейджи Всё завелось Давайте посмотрим как это завелось на проде нагрузка была 75.000 спано в секунду мы поделили её на 25 и поняли что нам нужно три нода Клик Хауса всё просто А развернули кластер из трёх шардов а наученные некоторым опытом работы с elastic Search Мы также добавили балансировку А между всеми компонентами и нашим кластером чтобы запросы на чтение и запись равномерно распределялись по а нодом Клик Хауса А и тут нас ждала первая проблема а три ноды у нас были а трёхкратный скорости у нас не было скорость выросла на самом деле там примерно в полтора раза а и разбираясь в этой проблеме Мы заметили ещё одну интересную аномалию это рост метрики delayed inserts вот видно как она бодро растёт на наших графиках А мы стали разбираться что это за Del inserts О чём это вообще И выяснили что это связано с механизмом дистрибьютор таблиц в кликхаус как вообще Джагер Да Какую структуру таблиц он создаёт создаёт таблиц двух типов это локальные таблицы которые физически хранят данные вот они зелёненьким здесь показаны там есть postfix Local там физически хранятся данные на вот конкретном рде и также создаются дистриб таблицы по сути это некий там прокси который позволяет нам вычитывать данные связанных с ней таблиц со всех нот То есть он объединяет результаты запроса со всех но как казалось Жар используют таблиц не только для того чтобы читать но и для того чтобы записывать наши данные когда мы записываем данные через таблицу начинает работать механизм шардирование то есть старается разложить наши данные по ключу шардирование по ном Да мы чётко знаем На какую ноду Какой трейс должен лечь а в качестве ключа шардирование у нас используется ID да то есть целиком попадает на Ту ноду которой он предназначен а что произойдет если Мы попытаемся записать данные не на ту ноду которая там по внутреннему вот этому маппингу должна ити данные содержать на самом деле ничего страшного не произойдёт их запишет и потом в фоне будет пытаться передать эти данные на Ту ноду которой эти трейс предназначены То есть у нас появляются такие фоновые процессы передачи данных между нодами и Метрика она раз говорит о том что это механизм запаздывает что эти данные не успевают на передаваться и лак вот этой репликации у нас растёт мы выдвинули гипотезу что именно этот механизм нам мешает да что вот из-за этого растёт Метрика из-за этого мы не вышли на нужную производительность что же с этим делать Давайте всё ломать откажемся от механизма дистриб таблиц будем писать сразу в локальные таблице сделать это очень легко Мы подмела так чтобы он забыл про всякие кластера как будто он работает с обычной сидой в этом случае всей всём распределение запросов занимается наш балансировщик в данном случае ДНС который просто равномерно Робином раскидывает данные записывает их сразу в локальную таблицу всё Никаких ключей шардирование данные остаются там куда Они записались А что с чтением чтение мы не трогаем jer UI графана как читал из дию таблиц так и продолжает это классный удобный механизм менять его в данном случае не нужно мы получили Ну был естественно положительный эффект Мы вышли на ту расчётную производительность 75.000 который так стремились у нас ушла вот эта проблема с insert ещё бы мы дистриб таблицу больше не используем но как говорится у медали две стороны а если раньше мы чётко знали где у нас трейс лежит он лежал целиком на конкретной ноде то теперь наши данные равномерно размазывается по всем нодом мы не знаем где у нас какие части рейса лежат для того чтобы целиком собрать нам нужно по сути запрашивать все ноды это как бы здорово для записи но не очень удобно для аналитики но в целом Мы решили что это хороший трейдов Потому что пишем мы много пишем там каждую секунду а читаем мы эпизодически когда у нас случается какать проблема инженера нужно провести расследование Вот примерно так у нас выглядела картина с балансировкой Икс раскидывал запросы по ном Клик Хауса более-менее равномерно каждой ноде доставалось примерно по д запроса в секунду по 20 Сток записывающих в кха естественно кха - Это не единственное как бы там узкое место которое нужно тюнить во всей этой цепочке др тоже нуждается в тюнинге очень большой прирост производительности нам дало включение сжатия на джагере это до сих пор Экспериментальный параметр То есть это параметр который задаёт сжатие потока снов который записывается и читается из каки параметр показал очень хорошо а к другому классическому параметру относится размер Бача да то есть известно что есть некая рекомендация что в кликхаус лучше писать там типа раз в секунду но большими батчат ветственно Вы можете исходя из вашего трафика подобрать размер батчат вам нужен чтобы раз в секунду кликхаус обращаться но в целом вот все эти параметры их нужно подбирать экспериментально вы их выкручивается Да смотрите как это влияет на а пропускную способность вашей системы вашей инсталляции А тут как бы значение чисто референсные Надеюсь ваше сегодняшнее утро началось с хорошей ароматной чашки кофе потому что наше утро начиналось После перехода на кликхаус не с кофе а со всплеска с нагрузки на нох как по расписанию с 6 до 10 утра мы видели вот такую вот замечательную картину со свечками А у нас росло потребление цпу на нох из того что это было какое-то постоянное воспроизводимое в одно и то же время проблема Мы решили что дело опять в какой-то фоновой операции в кликхаус и мы были правы Оказалось что в данном случае это фоновое удаление старых данных естественно данные в нашей дрессировке мы не храним бесконечно У нас есть ограничение в 14 дней хранения оно реализовано с помощью механизма Time to Le в кликхаус ttl на таблицу вешается это ограничения ха эти данные сам в фоне удаляет проблема оказалась в том что удаляет он их по дефолту построчно и это приводило к очень высокой нагрузке на сам кликхаус к счастью есть замечательный параметр Only drops который инструктирует кликхаус удалять не построчно удалять целыми частями да то есть когда мы записываем какие-то данные в кликхаус они складываются в части части объединяются между собой в большее части Да какой-то внутренний механизм А кликхаус по работе с данными естественно удаление данных вот этими частями пас оно более эффективно чем удаление построчно когда мы параметр включили У нас вот эти утренние пики нагрузки ушли и мы продолжили по утрам пить кофе Окей мы с вами справились с записью мы с вами справились с удалением теперь осталось дожать поиск и аналитику А вот на экране у нас пример дашборда в фане по данным Клик Хауса здесь мы как раз считаем длительность наших бизнес операций но мы наступили в ту же самую проблему в которой были с elastic sech а именно тяжёлые аналитические запросы могли приводить к дестабилизации кластера ха к выпадению него и это в общем была проблема чтобы с ней как-то побороться Мы решили разделить нагрузку на чтение и на запись то есть мы решили что у нас будут выделены сервера ха которые нагружены записью и реплики с которых у нас будет идти чтение и которые мы выделим под аналитику собственно мы к тому моменту нагрузка на наш стенд уже достигло 200.000 спано в секунду поэтому мы от шардов и 10 реплик Да каждому шард соответствовала своя реплика А всё чтение шло с реплик а но как вы знаете пользователи вообще говоря люди талантливые и могут написать такой Запрос который выведет из строя даже там железо выделенное конкретно под аналитику поэтому мы в любом случае нуждались в неком механизме ограничений Да мы должны были наложить какие-то квоты ограничения на аналитические запросы чтобы наши ноды не страдали именно так в нашей схеме появилось нечто под назва между репликами и фано собственно пси - это htp балансировщик он как раз таки ограничения умеет настраивать он умеет ограничивать конкурирующие конкурирующие запросы тайм-ауты ставить и даже кэшировать ответы для любителей постоянно жать на рефреш на наших дашборда собственно закручивая вот эти гайки закручивать ограничения мы добились того что тяжелые аналитические запросы с дашбордов не каким-то проблемам на самих нох Хауса ну максимум У пользователя не загружался дашборд он понимал что ему надо там свой запрос оптимизировать или там сократить время за которое он его выбирает Ну что ж Давайте посмотрим как наши пользователи такие запросы пишут вот простенький запрос поиск снов по тегу мы здесь Ищем все Сны которые содержат там Значение Наверно это не то чего вы ожидали дат какая-то очень сложная комбинация Сначала мы проверяем есть ли такой тег вообще или нет Потом какой-то лошадиной конструкции пытаемся там приравнять его с Get В общем это совсем не то что мы ожидали почему это происходит А всё из-за того как др хранит свои данные Дело в том что теги в нём хранятся как два массива отдельно ключи отдельно значения очень удобно для записи абсолютно отвратительно для аналитики и для написания запросов к счастью поправить это очень легко Для написание запросов мы просто сделали дополнительную вычисляемый колонку тек А с типом Map то есть по сути словарь Да ключ значения А колонка была вычисляемое то есть она вычисляется при вставке туда данных материализованная данные хранятся сразу на диске Да что облегчает к ним доступ и наш запрос сразу становится гораздо чище короткий интуитивно понятный а согласитесь в таком стиле писать запросы гораздо удобнее Ну что запустили расслабились прошла неделя ничего не работает упал и не открывается Ну это веб-приложение поэтому мы открыли консоль chome посмотреть что же там загружается и узрели удивительное Дело в том что когда джар загружается он сэнда тащит уникальные значения сервисов и операций чтобы сделать Вам выпадаю ф чтобы э су чтобы этот седин не делать на литу у джагера есть специальное материализованное представление operations Куда эти данные складываются прямо по время вставки А Мы залезли в эту таблицу и увидели там десятки миллионов строк а что было очень странно потому что у нас полторы тысячи сервисов там ну десятки тысяч операций но никак не миллионы естественно всё это были дубли А как оказалось был небольшой баг в самом плагине А когда вы создаёте таблицу в кликхаус Вы можете выбрать целого там семейства движков доступных вам там есть допустим какой-нибудь replacing merch 3 который удаляет дубликаты Есть са merch 3 который может эти дубликаты агрегировать да то есть допустим дополнительно посчитать вам количество этих дубликатов положить какую-то отдельную колонку так вот здесь использовался обычный Mer 3 который с дубликата ничего не делал и мы получили такую бом Да замедленную проблему Когда строк дубли набралось в таблице достаточно всё это просто начало тормозить и перестало открываться понятно что мы заменили движок в таблице дополнительно Каширова запросы на список сервисов и операций чтобы всё это ускорить и наш д снова залета бак кстати был потом поправления архитектура пришло время посмотреть на неё у нас по-прежнему множество продуктов инструменти либо оренго либо омет которые отправляют трассировку на наш её подхватывает множество инстан сов J колектора или Open колектора который мы сейчас используем также всё проходит через кафку главное изменение у нас в области хранилища да то есть теперь наш jer inest уже с плагином работает с кликхаус записывает данные на шарды чтение у нас идёт с реплик jer UI читает через балансировщик фна обращается через для того чтобы вот эти дополнительные умные ограничение сделать То есть у нас два UI которые нам обеспечивает операционку графана обеспечивает аналитические запросы Окей что-то запустить и даже выдерживать нагрузку - это не то же самое что постоянно обеспечивать какой-то достаточный уровень сервиса и качества по этому сервису Давайте посмотрим что нам нужно мониторить в этой схеме Ну понятно что нам нужно мониторить кликхаус место на дисках которое имеет свойство кончаться неожиданно а количество соединений к клик хаусу и конечно количество запросов на запись Мы помним что нужно стремиться свести их там к одному запросу в секунду в идеале у нас чуть больше получилось а по кафке понятно что один из самых важных показателей - Это лак в кафке отставания обработки спано от риал тайма если лак Копится Это значит что пропускная способность нашей системы ниже чем та нагрузка которая она воспринимает если это кратковременно О'кей это может быть какой-то всплеск но если это происходит долго это значит что мы не справляемся а чи прокси выдаёт нам множество интересных метрик связанных с тем как наши аналитические запросы выполняются через фану Да сколько там пользователей А насколько долго эти запросы выполняются насколько успешно Ну и конечно по Джаггера Мы хотим мониторить различные дропы а Джаггер так устроен архитектурно что если он что-то куда-то не может записать он не ку не копит какие-то внутренние буферы он эти данные сбрасывает то есть они могут пропасть Поэтому если у вас возникает дропы это повод присмотреться Где же у нас узкое место Ну и также у нас есть jer UI веб-приложение по классике мы должны контролировать его lency ошибки да то есть вот четыре золотых сигнала А как с серверной стороны так и БК боксом то есть глазами пользователя Да настроить некий Black бокс мониторинг нашего jager uui А как это можно сделать А к счастью большинство компонент нашей схемы jer CH Proxy Click House умеют выставлять метрики в формате prus прямо из коробки а для того чтобы реализовать Black BX мониторинг Ну можно взять там blackbox экспортёр прометеус и заставить его периодически запрашивать список сервисов запрашивать последние трейс для того чтобы убедиться что и пользователь это может сделать да то есть посмотреть на наш сервис глазами пользователя а все эти метрики у нас собираются в CL Victoria Matrix в фане у нас построено по каждому компоненту множество дашбордов они тоже есть все в каталоге графана ничего в принципе изобретать не нужно Ну естественно у нас есть аленг когда какая-то Метрика из этих ключевых по компонентам выходит из порогового значения мы об этом узнаём тревожным звоном телефона А что ж пора приступить к выводам сначала буду хвастаться метриками Итак значит наш сервис сейчас обрабатывает в среднем 150.000 спано в секунду С пиками до 300 эти данные там приходит от более чем полутора тысяч сервисов подключённых к там продуктов а самом в самом хранилище сейчас 180 млрд снов а объём его 60 ТБ это с учётом реплик и данные у нас хранятся за 14 дней а поиск Трей сов по тегам а занимает 6 секунд это не Real тайм Да не мгновенно Но это в разы лучше чем то что было с elastic Search А ну и поиск конкретного треса Да если вы знаете его ID занимает 200 мсн а если просуммировать наш опыт Да какие можно дать рекомендации Если вы строите А сервис распределённой трассировки и а рассчитываете на поток скажем 50.000 слано в секунду и больше Аа логично брать сразу кликхаус Да потому что ну чтобы потом не переходить на с одной технологии на другую А запись дистрибьютор таблицы может снижать производительность Если вы пишете через стриб таблицы Попробуйте без них возможно будет лучше если вам нужно ограничить запросы кликхаус на чтение ввести какие-то квоты ограничения пси ваш лучший друг Ой а старые данные лучше удалять сразу частями Да не построчно и если ваш профиль нагрузки похож на то что вы увидели у нас то возможно вам тоже Стоит подумать насчёт разделения нагрузки на чтение и на запись на этом У меня всё большое спасибо готов ответить на вопросы Филипа Огромно тебе благодарен за доклад мы теперь знаем как всё готовить для чего это нужно друзья не забывайте давать обратную связь Это очень важно и для спикеров и и для организаторов и у нас первый вопрос да Филипп Спасибо большое напрашивается очевидное решение построить сверху велосипед который пой ID сделает автоматически партиционирование в одну и ту же ноду думали ли над этим Почему решили так не делать Ну то есть у Хауса есть стройный велосипед который это раскидывает да этот велосипед едет медленно делать свой велосипед но я на не уверен что мы реализуем это лучше чем Хаус на самом деле потому что ну потому что вот и на самом деле сейчас нет особой проблемы в этом то что данные лежат не по ID на текущий момент нам не сильно мешает да Окей мы читаем с множества нот а пока это нас не тормозит как только начнёт мы об этом задумаемся спасибо И у нас следующий вопрос подскажите пожалуйста вы когда тестирует jer UI у вас там просто хелс чеки открыты или у вас авторизация - Это первый вопрос а второе Вы какой-то ответ специальный ждёте или просто чеки доступны недоступны ну у нас есть корпоративная ссу авторизация А мы делаем то есть у нас настроен б бокс мониторинг который из коробки да круток ваших личных каких-то не не именно Black BX Я имею в виду ну как мы берём экспортёр Black BX и дёргаю всё А Джаггера серверное да это поиск рейсов это вытаскивание списка сервисов операций то есть всё то что используется то то что вызывается при работе jer UI мы это периодически опрашиваем чтобы убедиться что и пользователи это могут сделать А есть не секрет как часто Ну плюс-минус примерно каждые 30 секунд каждую минуту или гораздо бо порядка минуты то минуту Спасибо большое И у нас Следующий вопрос Следующий вопрос Добрый вечер хотел узнать не рассматривали ли вы возможности интеграции заксо вот этих анализа метрик проче так я не вижу Где спикер Ну да ладно А вот увидел ровка плю Трик у нас компания используется не могу сказать что он там как-то активно развивается Мы вс-таки стремимся развивать там другие инструменты в частности там Рик телеграф как-нибудь об этом расскажу а в части рейсов вообще не думали там про закс Я даже не знаю есть ли там у закса вообще своя какая-то трассировка вот части метрик У нас есть интеграция метрики собираемые заксом у нас прикладываются Вот как раз в кластер Victory Matrix то есть вот с джаггеров зано с телеметрию каким-то образом в закс не сбрасывайте нет И у нас следующий вопрос пока не микрофон но записи как таковых рейсов нету это будет косты через метрики смысла просто нет вопрос Спасибо Денис Маркет Гуру у нас схожие были проблемы тут скорее наверно просто поделиться чуть-чуть опытом по поводу дистриб табли решение было вки неудачное потому под капотом по чуть-чуть в настройках есть такая штука insert и соответственно уже таблица до отправки уже вот тем эндом она будет укп эти Бачи и они будут уезжать то что вы на уровне Джаггера 10 Мб выставили это прикольно но дефолтная настройка 1 любом случае будет сда его надоть по поводу того что запросы тормозят и вот там на последнем слайде 6 секунд и это типа Норм у нас тоже были похожие проблемки тут момент Какой у вас слишком размазано эти самые й ID по всем шардам это как раз вытекает из неправильного Ну шардирование вы нарушаете этот принцип и нарушаете принцип локально вычислений из-за этого друзья я мешаю направи ведущего это отличная тема для дискуссионной зон мы сможем обсудить Какие настройки будут более корректны А у нас следующий вопрос спасибо спасибо за доклад я вас запомню такой вопрос вот в продолжении вопроса про первая идея была собственно говоря вычислять В какой писать по Trace ID А вот у меня есть сомнение что у вас все сервисов одними ID они Явно же делятся на группы и грубо говоря этих групп явно больше де и можно было просто 10 отдельных кластеров вот без вот этого Чтобы мучить на один запрос все 10 так а а Эли завтра будет 20 запросов они большие но не настолько Нет я понимаю но просто как бы в крупной организации в любой склеивать все ы искать во всей организации странный подход Я честно говоря не до конца Понял Вопрос Я предлагаю это обсудить в кулуарах более детально совместно с настройками Я думаю вы втроём найдёте общее мнение У нас следующий вопрос Здравствуйте Денисов ми два вопроса первое у вас кликхаус на барика или Тука не тормозят Нормально Ну как Видите виртуализация какая хорошо второй вопрос Сейчас секунду Open вы сейчас переезжаете с джагера Open вы льё его параллельно как он у вас появился как они дружат друг с другом льётся ли это туда же хороший вопрос значит мы немножко старше чем начинали с как бы с он Рейсинга Вот и сейчас потихонечку всё заменяем на он телеметр новые продукты уже Естественно С омет раскатывают А они живут параллельно То есть у нас параллельно есть др коллекторы есть Open коллекторы но как бы на коллекторах всё и заканчивается то есть всё это льётся в одном формате в кафку вот дальше из Кафки достаётся уже джерами кладётся вот в формате джагера вха понятно То есть вы переезжаете на потихонечку да да Ну это будущее безусловно всё понятно Спасибо большое И у нас следующий вопрос А да иногда пользователи с вашей it системы ставят такие задачи как артин на основании Трей сов То есть когда они хотят видеть А какие-то алерты например при превышение респонс в той или иной операции Как вы решаете подобные задачи учитывая что ну это неплохая такая нагрузка в связи с вашим шардирование Да мы стараемся не делать на самом деле аленг по данным самой дрессировки для этого у нас есть производные метрики вот те самые метрики которые мы считаем во-первых они не хранятся дольше подходят там для долгосрочных трендов во-вторых они подходят именно для артин у нас как бы там ключевой механизм артин компании это как раз Victor Matrix и алерты вот поэтому мы вычисляем метрики а по ним уже строится весь артин и можно ещё второй небольшой вопрос коллеги который задавал вопрос прок у него есть веб мониторинг который пошагово позволяет проверять UI это может Да у нас тоже есть похожие инструменты для там мониторинга веб интерфейсов но здесь можно обойтись просто б боксом на самом деле и у нас следующий вопрос Спасибо за доклад Мы тоже используем егере с Хаус Ну в меньших объёмах понятное дело не МТС а вопрос такой вы предоставляете yer uui клиентам не думали что-то своё написать чтобы было покрасивее по поинтереснее скажем так или запросов не было Ну тут как это суровые инженеры собрались поэтому тут не красота нужна тут функциональность а написать что-то своё Ну наверное можно был бы как бы запрос сформулированный Да что улучшить для каких-то базовых потребностей вполне неплох На мой взгляд Ну то есть Клиенты конечно не жаловались на веб интерфейс Ну там есть конечно какие-то косяки Да например там не очень удоб фильт там нельзя допустим когда подгружается список операций если у вас юрле тамм какие-то эдификаторы они будут все выгружены списком это конечно всё очень бесит но не препятствует операционной работе Спасибо И у нас финальный вопрос финального доклада первого дня вопрос папам вот у нас есть вопрос успел Спасибо за доклад вопрос Ну таких два маленьких вопроса Я правильно понял что все в принципе взаимодействия попадают в систему то есть не части А 100% да мы не используем сэмплирование собирается 100% данных а вот когда логи взаимодействие между сервисами тела запросов тело ответов тоже попадают Это зависит от того как инструменти сервис по дефолту Нет по дефолту попадает Мета информация л код ответа вот такие вот вещи там протокол вот тело вопро я бы вообще не стал добавлять в трассировку трассировка должна быть легковесный это мы уже на шишках набили Потому что если спа будут очень большие они будут там теряться по дороге в куче мест они будут долго долетай мы стремимся сделать трассировку максимально легковес для тел запросов есть логи Ну это наш подход Понятно спасибо большое спасибо за вопросы Спасибо за доклад и Дета с кото поделился и выбери лучши вопрос ух у нас был сча и буде белый пакетик а так ну наверное многообещающие комментарии про размер Бачи который я надеюсь узнать достойно Прошу выйти нану и не забывайте давать обратную связь по QR коду Напишите всё что думаете благодарю Спасибо всем спасибо L"
}