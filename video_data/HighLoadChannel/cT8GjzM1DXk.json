{
  "video_id": "cT8GjzM1DXk",
  "channel": "HighLoadChannel",
  "title": "Continuous Integration на стероидах / Александр Акбашев (HERE)",
  "views": 1681,
  "duration": 3280,
  "published": "2017-04-22T14:48:24-07:00",
  "text": "здравствуйте сегодня планирую рассказать он доклад continues in the графе на стероидах я приехала из берлина из компании kia компаниях и это один из ведущих картографических провайдеров среди наших клиентов являются почти всем автомобильные производители так или иначе бмв volkswagen audi ягуар honda hyundai mercedes можно долго перечислять volvo так далее вот из тех которые имеют более тесные отношения сайте это на amazon фейсбук различные сервисы доставки из сервиса такси у нас достаточно очень много продуктов вот но сегодня я буду рассказывать про систему continues in the гриффин которые ориентированы на один из основных продуктов да и это продукт который основном написан на си си плюс плюс это нужно делать скидку над которым работает приблизительно 600 разработчиков вот продукцию историей он пережил несколько слияния несколько поглощений то есть куда базе лет 15-20 собственно план сегодняшнего рассказа сначала небольшое введение в континента гриффин потом историю о том как мы это все наблюдаем мониторим про масштабирования в общем дальше по списку continues in ты грешен нашей компании имеет большую историю используется достаточно давно использовались разные практики continues in the гриффины до совсем недавнего времени буквально полутора лет назад это было что-то вроде continues in the грешим на одну команду то есть грубо говоря есть команда у них есть свой дженкинс там я не знаю под столом или в дата-центре эта команда сама определяет как запускать тесты как релизиться собственно такие плагин использовать как это все как это всем управлять так далее но это приводило к достаточно плачевным результатам то есть нужно было тратить время на синхронизацию между командами иногда показывалась что те изменения которые было бы хорошо протестировать еще и соседней команде естественно оставались без тестов и соответственно оказалось что есть команды молодцы у которых все без practice и собраны из команды не очень молодцы которых все worst practice a собраны вот и были решения сделать единую систему continuous integration который будет общей для всех разработчиков платформы и и так система continues in the grace of целиком полностью должна заменить все эти индивидуальные инстанции также обязательно было то что есть конкретный набор людей которые отличаются весь этот процесс собственно с команде этих людей я работаю собственно еще одним обязательным нововведением этого процесса было требование того чтоб каждый каждый абсолютно каждый камень должен проходить независимо всю цепочку тестов то есть на практике это выглядит приблизительно так разработчик делает изменения локально на компьютере кто-то проверяет что-то нет потом отправляет эти изменения в геррит дальше геррит плагин в 2 кинси запускает релевантным для этого к метро джо бы триггеры там дальше код компилируется con компилироваться под абсолютно разные наборы то есть там лин 64 бита linux 32-bit windows qnx arm android ну и дальше уже запускаются тесты которые непосредственно завязаны на эти билды тесты проходят тесты он начинает возвращать результат обратно пользователю в геррит и таким образом где-то через 20-25 минут разработчик знает насколько успешно его изменения обратная связь он получает независимо от каждого проекта билда но соответственно если хоть один тест с 200-300 тысяч туристов упал тоже рабочих у нужно переделывать свои изменения и опять их отправлять обратно в геррит таким образом в системе получается очень вы очень высокая цена флаке и тестов тестов которые имеют нестабильное поведение и никоим образом не зависят от самих изменений ну и соответственно также высокая цена инфраструктурных ошибок то есть если разработчик из-за вас не может закомитить свои изменения потому что вас где-то там имеет место переполнилась там еще какая-то беда обычного вечера вот то собственно вы получаете минус карму также чтобы более детально чертить какие-то цифры до с чем приходится иметь дело то есть обычные день это где-то порядка 100 тысяч билдов под термином build я понимаю build 2 кен со то есть это запуск одной одно из job до одного из pipeline авто мог быть компиляция могут быть тесты мог бы кидают статистические проверки общее число билдов очевидно коррелируется общим числом коммитов и на самом деле как бы у нас нет цели сделать как можно больше билдов у нас есть цель позволяет пользователям делать как можно больше коментов если по какой-то причине commit не может быть сделан из за того что наша система не пропускает больше коментов это очень плохо и этого хочется избежать также битов вы обычное время у нас полторы тысячи конкурентных билдов идет в один момент времени на дженкинс и как правило пике активности программистов на графиках очень хорошо видны это что-то вроде я пришел с утра заметил на свежую голову я заметил перед обедом это пока я ем пусть там идут всякие тесты ну и соответственно последняя попытка на сегодня вот соответствие мы видим три спайка за день и количество экзекуторов то есть экзекуторы это сервера на которых исполняется тебе lga их число измеряется где-то от 1300 до 2 с половиной они поднимаются по мере необходимости то есть если у нас есть очередь мы начинаем поднимать новые компьютеры также там есть огромное количество различных проверок то есть например на экзему 3 кончилось место там его просто отключаем например начинаем разбираться как так получилось ну и соответственно многими другими ошибками мы делаем тоже самое ну и соответственно внимательный слушатель заметит что нас полторы тысячи билдов идет одновременно экзекуторов сильно боев иногда собственно это связано с тем что дефолтная стратегия дженкинса не оптимизирована под этот ну под случае с облачным решением и соответственно экзекуторы просто не занятые стоят да потому что мы когда-то подняли и пока нам ноги все экзекуторы не будут пустыми но до т.к. будет висеть что называется ну эти цифры все были получены системы мониторинга то есть на мой взгляд с тем мониторинга the sun собственный краеугольный камень даже в канте ньюсом ты грешен системе было бы неплохо и и использовать у нас используется следующий подход у нас есть собственно информация с каждого билдов дженкинс и попадает в плагин который называется groovy event list in our который слышит абсолютно все события которые происходят дженкинс и дальше эта информация записывается в индии это демоны диспетчер событий ну клинки уже записывает винтик сгибе это собственно база данных time серия эта база база данных и собственно и сын фиксом уже читаем в графа ну весь этот стек где-то был смонтирован за четыре часа вот в качестве пруфа в концепт и в принципе достаточно долгое время порядка полугода все так и оставалась вот хочется также отметить что флю indev мы выбрали в первую очередь за того что он очень простой и никаких проблем кот очень простой код наруби не любой человек который даже не знают руби вполне может туда зайти посмотреть написать какой-то свой плагин для какого-то своего специального источника либо источника данных либо для собственно базу в которые вы хотите записать собственно мы также заметили что лучше лучше всего справляется с качество предсказания скажем так того поведение системы которая будет через минут 10 20 статистика г н то есть так как дженкинс это java-приложения соответственно восполняется виртуальными фильтровые соответственно очень хорошо иметь было бы статистике которые которые вам предоставляет из коробки то есть нашем случае например эта логика c то есть буквально там за час-два внутри крутили один еще дополнительный коллектор флю индии начали писать данные о том как у нас живет наш дженкинс таким образом когда мы на графике видим спайки валдресе мы понимаем что скоро у нас идет какое-то величайшие события и все будет очень плохо этого приблизительные view граф анны да это вот интерфейс который мы наблюдаем каждый божий день который помог помогает нам мониторить производительность системы правый верхний угол цифры k9 это очередь до которые есть на данный момент второй график снизу это собственно графика 3 желтые точки атаками ты видно что когда у нас иногда бывает коммитов много очередь маленько иногда бывает наоборот очередь имеет свои спайки также график повыше это допустим экзекуторы до 2 конца то есть когда у нас мы видим что у нас какой-то экзекутор пробивает потолок это означает что он пробил сто процентов это свою очередь означали что вот-вот будет где-то очередь то есть на каком-то конкретном типе билдов график выше это фидбэк time если степи бак тайм для разработчиков превышает 20 минут там вот из цифр 30 например красненькая да то есть это значит что в системе что-то не так то есть это может быть опять очередь либо кто-нибудь из разработчиков заметил что-то что замедленном везде компиляцию что то в этом духе ну и соответственно график снизу как я же помню сказал это график gc сборок в идеале этот график должен быть абсолютно пустым но дженкинс к сожалению по крайней мере на наших объемах этого не позволяет собственно как мы все это дело масштабируем и какие вообще есть варианты масштабирования ну для начала давайте по гриму том что вообще стремились достичь первым требованием было предельно четко обратная связь сборщик обратная связь разработчик должен получать в течение 20 минут больше чем 20 минут разработчик не может держать контекст голове например и если он получает результаты через часто слишком дорого получается ему вернуться к предыдущему комету и там внести изменения тестировать так много как только возможно то есть когда мы только начали тестировать до у нас там я не знаю была подключена 10 тысяч тестов до после того как люди ли поняли насколько это удобно и важно чтобы каждый изменения dota волк она попадает в общий куда базу была протестирована они начали очень агрессивно увеличивать количество тестов соответственно мы считаем что разработчики имеют полное право писать новые тесты и подключайте к да к проверкам средства мы должны делать расчет на то что тест количество тестов будет только расти также разработчики хотят чтоб иногда эти тесты были среди важной информации для того чтобы они видели стектрейсы для того чтоб они могли быстрее повторить ошибки не их не волнует что в принципе с де важными информацией тесты могут идти медленнее не которые также хотят собирать катка вершину всем этом то есть и при этом опять же это наши проблемы мы должны сарнов укладываться в 20 минут ну и соответственно самое любимое требование все это должно работать на физических девайсах то есть там на комиксе на андроиде на оси собственно как же мы с этим живем первый вариант это собственно варианта масштабирования это просто увеличивать количество компьютеров то есть если вам нужно запускать больше тестов но больше железа как это можно сделать это можно сделать с помощью дженкинса с помощью и ситу плагина который позволяет вам поднимать ноды в реал тайме в амазоне да то есть это и ситу эта услуга который предоставляет amazon который позволяет вам собственно любой любой каприз за ваши деньги то есть если вам нужно больше нот больше платить и получаете больше nude собственных тафта второй сервис этот droid он предоставляет ту же самую услугу только для девайсов айфонов и андроидов так далее у нас с этими ребятами были достаточно очень интересные слишком тесные отношения одно время а потому что например умы загоняли так много тестов и так часто что мы полностью разрешали все их телефоны которые у них были вот так же нам надо было иногда очень часто обновлять карты карта весят достаточно много то есть полный комплект карт весит 32 гигабайта и быстрее было отправить деятель semc flash картами чем сделать это через интернет вот но в принципе сейчас уже качества на должном уровне можно пользоваться собственно еще один способ масштабироваться просто уменьшать время выполнения каждый дроби вариант первый самый простой то есть разбивает тесты по типам понятно что если у нас есть теперь в то время обратный обратно реакция должна быть меньше 20 минут от теста идут 20 минут то это никак не достичь соответственно тесты должны быть разбита на такие чанки чтобы время компиляции prius тест было меньше 20 минут собственно поэтому нас дома разбивают тесты по типам то есть клиентские тесты клиентские тесты на какую-то определенную фичу то есть все делается так чтобы время теста тесто водил бы было минимальным для того чтобы лучше утилизировать железом в том числе собственно параллельное за появление запуска тестов да то есть если у вас есть вы пишете примерно 2 тыс да то есть тесто на си плюс плюс вы можете запускать в параллельно если вы там java теста тоже то есть если ваш фреймворк и собственно самая важная реализация непосредственно тестов поддерживают параллельное выполнение прекрасно нужно это использовать лучше заплатить за железо чем за время разработчиков которые будут страдайте их дать и обратной связи также несмотря на то что мы например используем докер то есть у нас в докере хранятся все deep and is sick тестом артефакты так далее пакета для питона мы тем не менее с равно используем саму ноду то есть сам сервер до в качестве хранилища крышам и на нем к ним там репозитории мы его не выкачиваем каждый раз на нем храним кэш компиляции чтобы не контролировать все с нуля также манем храним там карт и так далее то есть как можно больше мы стараемся хранить на ноги чтобы использовать ее в качестве как 100 роджер в этом есть минус в том что когда у нас есть допустим момент разогрева до когда у нас идет спайк новых комментов у нас кэш холодный надо как бы подождать немного ну собственно достаточно полезная штука которая очень серьезно помогла нам сэкономить это распределенной кэш компиляции то есть грубо говоря сикош которые используются для компиляции си си плюс плюс позволяет использовать в качестве бэг-энда мид нкр и также кэш который мы используем для компиляции с помощью visual studio в нашей версии внутренней тоже позволяет это делать таким образом когда один разработчик на мель например меняет какой-нибудь один файл который требует полный перекомпиляции всех всего-то это требуется сделать всего лишь один раз потому что все остальные ноты получить эти изменения у жизнь нам кашу это вот то что у нас очень хорошо зажгло ну и соответственно мой самый любимый пункт это профилирование то есть если тест виду долго скорее всего их можно по профилировать найти там я не знаю какие нибудь slip 1000 которые там ничего не делают то есть куча других прекрасности здесь ещё есть один очень любимый мной трюк как пока до тех пор пока тесты проходят вообще никого не интересуют что там происходит то есть это касается консольных логов так далее любых красивых отчете cove это все никому не надо если тесты проходят то есть например у нас была одна команда в которой мы выключили обязательно генерацию report для тестов которые проходят и получили просто при длительности где-то в 200 раз то есть теста место автопати там 20 минут начали выполняться буквально там считанные секунды то есть всегда есть на чем можно сэкономить если знать там какие-то определенные трюки да то есть если тест проходит зачем много информации то есть просто прошел прошел если кому-то захочется party божиться он всегда сможет локально воспроизвести ну собственно самая интересная часть я думаю ядром нашей системы continues on ты грешен является дженкинс дженкинсон де факто стандарт то есть несмотря на то что он как бы некрасивый может быть может быть не по нему много вопросов но тем ни менее альтернатива нет то есть если смотреть на время в сторону платных решений например ten city они требуют деньги за там каждый agenda то есть тюремной г-н кац экзекутор если нам надо там миллионы экзекуторов нам нужно миллиарды денег вот соответственно мы также используем drinking главный вопрос который нас мучил все это время это дженкинс такой медленный или мы делаем что-то неправильно и нужно сказать что в целом замки с дженкинс нормальный то есть если вы работаете не на наших масштабах по дженкинс должен летать ну как всегда есть нюансы первый нюанс который просто заставил вас встать дыбом это ротация билдов да все знают что такое как бы ну гласит билды до вас есть история про тысячи билдов вы хотите чтобы билдов было не больше тысячи вот и оказалось что код который отвечает за это который позволяет держать ровно 1000 билдов он потребляет 25 процентов всей памяти то есть но при этом здесь тоже есть интересный нюанс он потребляет 25 процентов памяти только в том случае если вы хотите точное количество билдов потому что он под ним загружает все билдов память считает сколько их есть на самом деле потому что вы могли руками удалить некоторые из билдов и собственно хранит только заданную вами тысячу а если например вызовет забили и значение там семь дней то все как бы загружать билды не надо достаточно посмотреть таймс темпа и поудалять потом с темпом таким образом если вы используете количество платить 25 процентов всей вашей оперативной памяти + там где-то 20 процентов процессорного времени если вы используете количество дней то вы не платите ничего это собственно была одна из самых интересных вещей которые мы пофиксили в отдельном плагине второе это оказалось что в принципе дженкинс работает гораздо гораздо быстрее если воспитатель феникс например здесь в этом конкретном примере там показывается что 40 процентов всех запросов могут идти напрямую в and phoenix не загружать дженкинс не приводить к дополнительным нагрузкам с живым не приводить дополнительным сборкам как средство не приводить дополнительным паузу также gemix позволяет напрямую раздавать различные устоять якутам логия не знаю артефакты какие-то так далее то есть в принципе спрятать ingenico дженкинса in 2 next а очень-очень хорошие решения а и также оказалось что в дженкинс и есть некоторые кнопки который лучше впринципе никогда не кликать пусто каждый клик этой кнопки может просто остановить работу всей команды это не перестал место тот просто мои самые любимые кнопки например кнопка workspace когда пользователь кликает на кнопку workspace и счетам файлики так далее для него все выглядит очень прикольно то есть я даю навигация по удаленному ser ru но в это время под капотом все эти данные с бедного слева которые там на самом деле еще занимается кого-то основной своя работа не все идут на мастер она там все декодируется но все там передается то есть если пользователь еще хочешь скачать как 10 гигабитный файлик то это все просто можно перестать и сразу вот поэтому мы отказались от этой кнопки спасибо ng nexus предыдущего слайда вот мы просто на уровне индекс ur love запретили пользоваться workspace он бил history например очень долго для нот то есть когда вы смотрите белки history но но но ты именно он посылал на каждый день в истории запрос на загрузку всех билдов для этого дня в истории независимо от того диапазона который был выбран в истории то есть как правило это приводило к тому что все request хендлеры были заняты у дженкинса и точки зрения пользователя дженкинсон работает с точки зрения джесси дженкинс умирают в висе но какие-то процессы в баграм где идут это тоже была нами пофикшен а в ядре буквально там неделю две назад дженкинс вышел с этим фиксом ну и соответственно логе да то есть логе это вообще отдельный разговор мы к нему еще вернемся собственно в целом замки там все хорошо но есть одна фундаментальная скажем так фундаментальная особенность да все что происходит дженкинс и все абсолютно все идет через мастер все данные счастлив вода через мастер пользовательские запросы все требует масть два слова не могут пообщатся напрямую нужен мастер все это приводит к тому что мастер от это вот есть единственно единая точка отказа до которую постоянно умирает в муках тормозит и так далее то есть все этим недовольны и пользователей и свои вы и сам мастер вот какой-то момент мастер обязательно умирает по out of memory естественно потому что ну нельзя так жить дальше нужно быть мужчиной и сделать суицид что же мы видим там вымершим мастере третье место занимают консольные логе для того чтобы найти какой-то workaround для этого мы внутри команды договорились что мы будем двигать следующее правило логе должны быть меньше какого-то определенного количества мегабайта то есть никто не имеет право писать гигабайт налоги если логе меньше десяти мегабайт это хорошо меньше двух мегабайт прекрасно 100 килобайт вообще любимая команда вот любые verbo услуги должны идти файл никто никогда не будет кликать на билды смотреть эту информацию пока этот билд не упадет когда бьет упадет разработчик пойдет смотреть почему и тогда вот ему потребуется уже какие-то детальные логе в реальном режиме реального время эти лаги никому никогда не требовались ну и соответственно перенаправление в файлик работает просто прекрасно и чинила проблемы с перф он нам сам и помогала нам выжить много-много раз столь же на втором месте на 2 месте у нас история бил-бил собственно во первых очень много плагинов не только как бы ротация истории но и очень много плагина страдает той же болезнью они хотят непременно на каждый клик пользователь загрузить всю историю которая есть поэтому нам пришлось ограничить историю 2000 сущностей ну либо наши нашу на наших реалиях это как tylo где-то три дня ну и собственно мы написали эффективный ротатор лагов которую называли builder питер плагин вот он буквально со дня на день будет доступен в в день кинси скажем так и собственно победитель то собственность за чего дженкинс чаще всего мира и от этот артефакт и так как по дефолту все артефакты передаются через мастер то есть даже между мясо и вами нам повезло в том плане что мы уже сидели на amazon узком решение да то есть и кроме амазонского ситу но стали использовать s3 как ст в качестве хранилища наших артефактов таким образом теперь возможно отправлять артефакты на s3 vs 3 напрямую минуя мастер и соответственно скачивать также можно с мастера ну и следующим шагом мы забрать или кому бы то ни было хранить кто бы то ни было на мастере то есть статика у нас вернулся на мастер задница статика идет только через яндекс артефакты только через s3 то есть любые другие запросы идут просто некуда но соответственно день kiss равно тормозит что делать мы вспоминаем о главном плюсе дженкинса это его скажем так большом комьюнити его разнообразных плагинах возможностях расширения так далее но как как оказалось почти все наши болью самые страшные кошмары будут проблемы были связаны именно с плагинами теперь игра была вот такая то есть у нас есть какой-то лимит билдов до который мы в данный момент можем пропускать когда мы перевариваем через эту цифру нас начинают какие-то странные вещи вас начинается очень много сборок мусора у нас деньги начинает тормозить вас начинает отваливаться своего у нас не проходит ками ты у нас просто restart дженкинс и все с самого начала и вот мы начали с цифры в 20000 1 подвох оказался от грузии want ли стану плагина который слушал все винты это как бы было ожидаемым и желаемым поведением но проблема в том что он слушал их под ключевым словом синхронность то есть ни один поток не мог у исполняться то есть только один поток мог исполняться в момент времени все остальные потоки стояли и ждали если у вас две с половиной тысячи компьютеров это означает что один поток выполняется еще 2499 ждут когда что-то произойдет и это все усугублялось тем что groovy код который исполняется этим плагином каждый раз компилироваться то есть кроме кроме того что нужно исполнить четыре строчки скриптик отступник нужно еще скомпилировать для этого нужно пройтись aqua спасу так далее там подобно и вот тебе как бы минутное минутная задержка которая в сутки худшее минуты вырастало до дней то есть когда у вас несколько потоков тысяч ждет как бы одна секунда превращается в dice половиной тысячи секунд вот но соответственно эта мы пофиксили и перешли к цифре 40000 билдов в день после этого мы заметили что когда у нас идет большое количество компиляции то есть когда исполняется большое количество job которые компилирует что-то нас опять же всплески нагрузки и мы начали смотреть из-за чего мы обнаружили у нас есть вор не с плагин до который говорит о том сколько у вас данный момент ошибок компиляции во-первых главный минус этого плагина что он парсит не только прошедшие билды но и точнее не только упавший билды на you просто профессию потому что им нужно знать число ошибок в любом случае слова орингов вот ну и соответственно все это делал из консоли консоль как известно хранится в днк msi на мастере соответственно весь этот ваш ник был на мастере соответственно мастер умирал собственно мы не стали ничего фиксить самом плагине мы просто за использовали еще один workaround мирно мы перенаправили seo логе с помощью киев файл таким образом стали парсить файл при этом parse.com sol метод мы загиб реке и till dawn теперь невозможно но как бы это опять же workaround еще лучше будет если мы просто говорим всех разработчиков писать без вороненков пофиксим сегодня и тогда мы сможем просто выглядит плагин и сэкономь где-то 16 процентов текущих аллокаций таким образом мы перешли к цифре 60000 дальше на этой цифры мы опять столкнулись извечной проблемой с лагами оказалось что опять дженкинс упал мы открываем блок дамп памяти смотрим что же у нас там в памяти скушала все эти гигабайт видим там огромнейший лог там 2 гигабайт или там и 5 не помню 1020 неважно там огромный лоб и огромное количество локаций вокруг этого огромного лог-файла начинаем спрашивать разработчика как так о чем ты думал зачем то все в браузере пытался открыть два гигабайта он мамы клянется что ничего такого не пробовал этот мы ждем получаем удар спину а там где мы не ожидали от таймс темпер плагина оказалось что плагин чик который дописывает время запуска даже когда вы смотрите превью на 150 кило байтов он также просто ни о чем не думая идет читать абсолютно весь лог-файл потому что им нужно понять какой именно момент поставить правильный таймс темп таким образом все те оптимизации к которых задумывались вы создатели дженкинса перестают работать если вы используете им стоит плагин для отображения логов счастью это мы тоже пофиксили теперь вас там suntour плагин случае тейла считает линии с конца таким образом удалось отлично вас оптимизироваться но это нам не помогло увеличить лимит потому что оказалось что это достаточно такой условный корнер кейс и помогло нам следующее как я уже сказала мы используем если ту плагин для того чтобы поднять новые инстанции идея такая что новые заз и мы поднимаем в те моменты когда у нас есть очередь очередь в свое время тоже хранится в памяти тесно дженкинса тоже не хорошо для того чтобы понять новый ест нужно запросить у через api . у амазона да ему могу имею ли я право на этот instance этот запрос был написан я не знаю лет шесть-семь назад когда amazon был маленький и этот запрос запрашивал все-все-все инстансы которые были а потом в цикле for пробегал и просто методом string и класса сравнивал хороший инстанции или нет и это приводило к тому что сначала работала достаточно быстро пушит amazon был маленький всего образов было пять все работало прекрасно сейчас образа в 2000 вот все стало работать сильно хуже таким образом каждый раз когда мы поднимали новый iwc мы прождали спайк вести потому что мы ассоциировали порядка низкий гигабайт только на запрос дай мне полный список всех доступных образов таким образом мы перешли к цифре цифре 90 тысяч девяносто тысяч помог следующий этот плагин делает все то же самое что делают обычные плане он анализирует результаты график график имеет под собой что-то вроде билды по оси x и y количество вы так сказать методом собственного исследования опыта обнаружилось что зеленые графики почему-то работает сто раз медленнее чем сенеки и графики начали изучать в чем причина то есть это где-то неделю продолжалось оказалось что во-первых имеет значение порядок инициализации плагинов в для nancy до touch если первым идет у нас робот from our плагин у нас зеленки график это работают очень медленно если x-wing плагин то симки работает очень быстро оказалось что их sewing плагин у себя хранит результаты тестов то есть он у себя хранит в файлике на диске что у нас 5 тестов упала 100 тестов прошло а робот плагин он не такой он хранит только сырые результаты тестов то есть каждый раз когда нужно отобразить пользователю количество прошедших либо не прошедших тестов он идет на диск поднимаете тестовый прогон и и начинает их просто посетить parcel парсить пытаясь понять сколько же тестов прошло собственно мы не скрепя сердцем мы пили лет плагин полностью заменили на икс тюнинг ни в чем не потеряли и всем советую таким образом и подобрались к 120 тысячам следующий наш лимит был билл тейлор она lider плагин этот плагин который позволяет парсить упавший билды и говорить помогает пользователям понять на какой же строчки что-то пошло не так а у него есть очень интересная архитектурная особенность на каждый регулярное выражение которое задал пользователей открывается отдельных файл в отдельном с тремя и все это происходит в отдельном потоке соответственно если у вас например 20 гуля рак в этом файлик это вам нужно открыть 20 20 раз открыть файлик для этого открыть еще 20 потоков все это приводит к тому что если у вас например у палатами не знаю 10 билдов одновременно что вполне себе вероятность 1600 то у вас получается соответственно 20 гуля рак умножить на 10 и умножить все остальное собственно это было пофиг что надо теперь все регулярные выражения проверяются последовательно для каждой линии logo вот но этот пул request не был принят по идеологическим соображениям monte nero плагинов вот если вдруг кто-то еще пользоваться этим плагином увидите вгика гид хоп поднимаете вайп кричите все пропал и так далее я очень буду благодарен таким образом мы подошли к цифре 140000 годов так сна это где-то вот сейчас наш максим для одного инстансов для этот собственно весь разговор про один из дженкинса ровно один мастер без всяких там multimaster так далее тому подобное и дальше у нас еще иногда бывает до сих пор трагедии разные технологического плана в один прекрасный день случилась история что где-то 20-30 часов у нас ничего не работало это было связано с целой цепочки событий который началось того что один разработчик заметил mode в код ну просто но германия что умрет как кого удивишь вот оказалось что пин-ап workspace плагин работает не совсем симметрично то есть если вы удаляете workspace перед началом билдом тогда он падает случае если он не смог удалить если после билда то он не падает он просто молчаливо копирует workspace и все это могла что уже удалить часть часть историю да так скажем вот и произошла следующая картина мы удалили большую часть репозитория до 1 mode у меня от мы не смогли удалить потому что в тот день в амазоне случился бак что всех инстанций которые у нас поднимаясь они поднимались без без поддержки tf локали соответственно система не могла распознать умлаут клин отпадал дальше нас шла следующие два банана обнаруживала что нас репозиторию не консистентной состоянии мы шли в репозиторий за изменениями это происходило параллельно на 200 300 400 экзекьютора это все привело к тому что у нас упал репозиторий в общем день был очень веселый вот и как следствие мы исправили эту бабу таким образом чтобы теперь разработчик не мог закомитить умолял первом месте потому что помог ли нам workspace плагин вернул ошибку но по опять же долги идеологическим причинам man тренер не принял этот у рыб pull request вот мы и живем на форки все остальные живут на пороховой бочке мораль собственно если вы планируете построить какое-то сложное решение дома нужно думать о масштабировании самом начале то есть что будете делать при тех или иных обстоятельствах как добавлять 10 build соты бил 1000 10-тысячный иначе просто процесс не сойдется например создатели дженкинса никогда не думали о том что drinks будет использоваться для команды больше чем из 2 3 4 5 человек из-за этого у него очень много архитектурных недостатков которые можно решить но это опять же требует определенных усилий мигающие тесты нестабильной инфраструктуры все это может быть огромной проблемой если вы идете по принципу каждый камень должен быть проверен continues in ты грешен системой потому что разработчики начинают терять в вас веру терять веру вообще что-либо потому что ты вроде бы к метис хороший код ну или ридми файл я не знаю лещева что-то ты не можешь потому что тебя падает здесь падает там собственно нужно очень жестко бороться с плавающими тестами и проблемами инфраструктуры а если у вас есть два приложения то скорее всего на ос тормозит из именно аллокаций огромное количество локаций которые даром никому не надо все те проблемы которые я рассказывал в плагинах это как бы это просто яркие примеры да то есть мы пофиксили еще больше плагинов то есть там два в три раза больше плагинов просто паттерн почти один и тот же то есть плагин ну например вот пример с таймс темпер плагином также этому подвержен плагин который отправляет вам песенку с результатом билда то есть email extension плагин план как-то так называется он также читает обязательно весь лоб для того чтобы послать вам 10 последних строчек этого logo то есть как бы это тоже уже за fiction а в следующих версиях дженкинса через три месяца мы это увидим но статус кого-то кое-что очень много плагинов в принципе не задумываются оба локациях и творят что хотят нужно копировать как можно больше съесть можно засунуть сделать кэш распределенном доступном кое-что нужно сделать если можно что-то не удалять надо это можно не удалять в общем кэширование сильно помогает жить ну и собственно continues on the gray scheme самые дорогие билды это упавшие билды потому что эти билды несут за собой нот на нашем примере нужно распавшись влоги для того чтобы дать разработчикам меняем и ответ на вопрос что же пошло не так после этого разработчику нужно еще путать к в это время в топ по фиксирует build то есть так это приводит к новым перезапуском торговать на подобное и очень много плагинов которые нужны именно в ситуации с упавшими билдами естественно как бы если билды падать из-за проблемы с мигающими тестами это еще хуже но остаться на workflow которое предлагаю для работы это если вы видите что вас что-то тормозит пожалуйста попробуйте попросили ровать это за фиксики язык интервью идти ну или в лучшем случае просто увидели что тормозит по профилировать создали ticket ну или в самом самом худшем случае тормозит ну напишите разработчикам потому что очень многие проблемы они в принципе не видны то есть для разработчиков то есть пользователи очень часто задают тикеты на гитхабе в разряде у меня вот кнопка не сработала без объяснения того как это повторить так далее и тому подобное то есть и как бы я бы с радостью помог человеку да но он не предоставил никакой информации а я даже не знаю что с этим делать поэтому не надо стесняться да то есть этого open source его пишут обычные люди то есть например судя по исходному коду дженкинса его плагинов от отнюдь не дрова разработчики поэтому как бы любой желающий пожалуйста помогите собственно давайте делать жизнь лучше и в конце список всех плагинов которые использовались докладывал sensors технологий синенький этот те которые пришлось немного пофиксить для того чтобы они работали на нашем масштабах но желто это там где я являюсь моим тренером то есть если у вас есть какие то по ним вопросы пишите все будет хорошо спасибо вопрос вопрос вопрос простой а почему вы изначально решили масштабироваться так где они везли с a10 спасибо а почему изначально решили масштабироваться вертикально не горизонтально можно было поставить там 2 3 мастер большая часть работы которую вы сделали она она бы не пришлось этого делать вместо работ справились с неким правильно помимо вопрос почему мы не использовали мастер multimaster для дженкинса нет ни multimaster не поставили еще один мастер то есть нужно было поставить например мастер плюс там половину своего в переключить текущей мастер больше часть проблем она связана с мастером по слайдам нет ну да то есть большая часть проблем связана с мастером это раз во вторых как бы весь этот все что я рассказывал то один конкретный продукт продуктов у нас гораздо больше 1 года то есть и очень хочется сохранять контекст пользователя что пользовались каждый момент времени знала что я кликаю сюда вот здесь мне доступна вся история все переходы так далее я он может восстановить контекст из одного окна мы не хотели это разбивать через там сложную систему мастеров да то есть поддерживать несколько master of в том плане что например иметь одинаковый набор и билдов да там и просто разделить продукт на две части то есть это этого хотелось избежать с одной стороны с другой стороны мы в себя чувствовали силы вполне справится с нагрузкой на одном мастере то есть сейчас у нас не знаю у нас 5 мастера все есть master of наверно которые которые сильно питаются плодами которые мы получили на этом mach3 да то есть почему нет александр спасибо за доклад у меня к вам такой вопрос вот значит ну что-то пишутся тесты проходят год например вы говорите отлично у нас 10 тысяч тестов выполняется дальше вам заказчик говорят о чем вообще на тесте лета вы смотрите в чужом он от с телика отсюда вопрос как бы есть какая-то система документирования тестов ну не так что как бы документирование хранится отдельно от тестов до что-нибудь его java дока topsy гена там во-первых достаточно специфическая сфера дав которые этот продукт работы тот автомотив рынок как как это выглядит то есть это не та же выглядит как не знаю 200 300 страниц юз кейсов да то есть вот то что называется бдд прямо во рту да то есть там водитель едет по этой дороге допустим да он там видит такое это препятствие должно произойти следующее то есть все эти требования загоняю делаются в качестве тестов то и загоняются в качестве тестов бдд я собственно и они же используется continues в грешном системе это первая часть то есть собственно это вот воды для описания human readable да то есть человеко читаемая она служит нам ответом заказчику что же мы тестируем да с одной стороны с другой стороны по требованиям заказчика да под требованием сертификации мы должны уметь восстановить систему на любой момент времени то есть если мы допустим не знаю отдали какому-нибудь авто по концерну версию в июле да через год случилось поймать авария мы должны иметь возможность полностью устранить у continues in ты грешен систему которое у нас было на момент в июле чтобы понять причины по которым произошла авария как этот тест не попал в flow не ответил такая в результате какого slowly я не очень понял ну вот систему которая была год назад ну каким образом есть во первых весь все исходные коды в репозитории во вторых вся continues on the creation система каждый день делаются бэкапы всех 2 всех настроек так далее то есть по обычным правилам таким способом я понял ладно спасибо здравствуйте куда смотреть вот хотел спросить у вас вы упоминали что за прям запускаются мастер запущен с контейнеров а essence и запускают через е ц 2 плагин вы запускаете непосредственно с именно с докера и леса и cs мастера мастер работает не в докере докер запускаются все тесты то есть грубо говоря слоев опять это обычный из твоего да и счастливо мы запускаем докер обычным шоу под обслуживания слоев лизните количество нот под обслуживание слоев где стоит докер ну просто интересно сколько вы тратите на continues integrations вот неизвестно так и должно оставаться хорошо требует требует требования маркетинга то есть я не имею права разглашать информацию принципе вы можете посчитать если у вас есть карта континента гриша можно принципе прикинуть из числа экзекуторов вот но как бы поверьте мне стоимость континенты грешен в этом бизнесе это копейки по сравнению с отзывом всех автомобилей которые пользуются данным софтом спасибо а вот есть вопрос есть микрофон спасибо за очень хороший оклад у меня такой вопрос возник наверное даже это упустил ну вот хотелось узнать вы как подходите конфигурации именно самих job то есть вручную как-то через интерфейс они настраиваются или какая-то конфигурации я понял метров pipelines сейчас который в жизнь тисе то есть ну во первых как бы была мечта перейти на pipeline плагин вот он оказался совсем далеко не production рейде то есть мы последний раз его проверяли два месяца назад он не держал нагрузку юзер экспириенс был не тот который мы ожидали следующий этап revolution а то есть когда мы сейчас будем мы на него смотреть to get a февраль вот собственно pipeline плагин позволяет писать обычный groovy код и собственно конфигурировать робота есть пока так рано делать вот соответственно потом есть dsl плагин на который был написан и от фиксом которые позволяют конфигурировать очень много job done три тысячи пять тысяч какие такие цифры фигурируют вот но только некоторые команды его используют то есть очень многие также предпочитают ручной стиль вот ну то есть клик-клик-клик и вот тебе готовые гроба вот но для того чтобы запрещать какие-то вещи на этом этапе у нас есть набор саммите чеков то есть мы каждый день про гонениям и смотрим что все трубы отвечают тем требованиям которые мы хотим то есть там например коли история билдов размер там определенное использование настроек так далее то есть как-то так еще один вопрос по поводу самого джин this мастера то есть какие-то плагины используйте для хранения конфигурации там то есть при допустим поднять и нового мастера чтобы не приходилось вручную 10 совершать мы используем маги который предоставляет amazon то есть мы грубо говоря просто со нам нужен новый мастер мы его поднимаем из бэкапа вчерашнего дня например и все сами контейнеры просто то есть грубо говоря запросто все тесты в контейнерах 2 бы все там то есть но ничего больше не требуется то есть понятно что хочется полностью сто процентов 2 переписать на использование dsl плагина да но для этого нужно чтобы все команды все члены команд с высоким техническим уровнем и с низким химическим уровень это могли сделать не мгновенный процесс то есть мы к этому идем ну прям не знаю ли спасибо спасибо за доклад я так понял что у вас теста стоят на про commit ну можно и так сказать на самом деле нет но решили проблему с промежуточным сохранением кода то есть когда разработчик не доделал код уходит выкидывают буква окно и хочется хранить код на сервере но собственно это была первая часть ответа на ваш вопрос нет мы не используем криками тут мы используем геррит то есть когда разработчик камере комитет сварить изменения в герат он их комитет на сервер удаленный то есть гель это такая красивая обертка над бетон то есть тот же самый вид но просто есть одна ветка мастер да то есть все остальные ветки они мифические до грубо говоря вот соответственно для тех пор пока тесты не проходит разработчика нет кнопочки сабмит когда тесты прошли появляются кнопкой сабмит и в этот момент код попадает в мастер то есть а так все чем же хранятся на сервере получается его код сохранил но не может мэр жить в общем именно спасибо вот вопрос там спасибо большое давай давайте здесь здесь первым определитесь давайте я спрошу вы сказали что используете джи пи эс джи эм для предсказания плохих ситуаций представим что световые видите на графике что вот вот сейчас все будет плохо что происходит дальше как работают дальше программисты они продолжают комитете ли у восстанавливаются работа конечно они предлагают комитет то есть грубо говоря прага место в идеале не должны знать что у нас все плохо то есть грубо говоря если у нас все плохо длить длится одну две минуты мы ждем дольше вот если допустим 10 минут то мы делаем анонс что у нас типа может случиться что угодно держитесь крепче вот следующий момент либо запускается профилировщика чтобы снять дам понять почему сейчас собственно нас есть проблема это делается только в том случае если у нас например нас работу какие-то другие стоп-сигналы например там я не знаю мы видим что нас какая-то проблема на стороне амазона да то есть на основе ну то есть понятно что мы видим что у нас все плохо да каталоге мы пытаемся понять почему если мы видим причину с мужем и и пофиксим и фиксик естественно если нет то мы анонсируем что у нас сейчас в данный момент проблема но из-за именно food вести так далее то есть мы очень давно не перезапуска ли дженкинс то сейчас большинства проблем от этих магических катастроф и то есть это достаточно редкое явление спасибо строй спасибо за доклад есть вопрос вы гоняете набор тестов всегда один и тот же или в случае если и вылиться какой-то определенный набор базовых тестов мы дальше не гоняем интеграцию и дает хороший вопрос то есть во первых есть очень много оптимизации на тему того что если у вас например на скомпилировалось под linux мы просто все на этом останавливаемся дальше с вами разговаривать смысла нет если все скомпилировалось то дальше допускается все тесты и обязательно все тесты будут выполнены это те тесты которые у нас относится к при commit тестом то есть также есть интеграционные тесты которые могут ли там четыре часа до там 8 часов эти тесты запускаются по своему собственному расписанию то есть они никак не связаны с криками там естественно при commit гоняется все то что может влезть в китае 20 минут спасибо ещё вопросы есть спасибо тогда всего доброго удачи"
}