{
  "video_id": "x0gbehtGCms",
  "channel": "HighLoadChannel",
  "title": "ClickHouse не тормозит в Self-Service BI: как мы достигли этого в Visiology / Никита Ильин",
  "views": 322,
  "duration": 3020,
  "published": "2025-01-17T02:21:23-08:00",
  "text": "Всем привет Меня зовут Никита Лин я главный архитектор Vis Давайте сразу начнём материала очень много так материала очень много кликер Ага вот для кого доклад значит Прежде всего это конечно для коллег которые очень много занимаются тем что технически оптимизируют лиха работают с ним рамик кликхаус для тех кто разрабатывает какие-то свои кастомные решения Тулы на баз Клик Хауса какие-то системы рекомендательные Как можно там не знаю оптимизировать кликхаус и конечно Для тех кто работает с ет etl процессами Ну и для коллег которые работают с Bi инструментами а начну с содержания расскажу кратко о своей компании расскажу что мы подразумеваем под сценарием селсе Виса расскажу про архитектуру и расскажу три основных вещи на основе которых в общем-то все вот эти оптимизации построены во-первых это модель данных во-вторых это оптимизации загрузки данных оптимизация SQL и в конце вопросы значит о компании в общем-то наверное ближайший аналог нашей платформы это наверное все слышали там powerbi табло Клик из зарубежных аналогов мы разрабатываем собственную Bi платформы visy в которой люди могут загружать данные через интерфейсы они могут выбрать источники базы данных файлы любые ошки и загрузить их в нашу базу соответственно разметить схему данных и дальше уже строить свои дашборды отчёты и проводить ОТК аналитику то есть мы именно данные контролируем процесс загрузки данных и за счёт этого мы можем некоторые оптимизации применять Ну и это полностью коробочное решение то есть это не сервис это заказчики берут на дистрибутивы у себя развёртывать устанавливают и в общем-то всем этим управляют также у нас используется не SQL а именно dax для пользователей то есть аналитики не на SQL пишут Потому что часто на самом деле вот в сценариях Bi у людей нет достаточных компетенций в SQ и поэтому используется другой немного язык который называется Дак это язык был создан в компании Microsoft Мы в общем-то его имплементировать Ну вот здесь пример такой меры на языке Дак то есть здесь берётся таблица sales и в общем-то считается сумма количество умноженное на стоимость А одного товара ну и соответственно пользователь написав такую простую дакс меру может уже в интерфейсе её в на ось Y определить и дальше уже в интерфейсе прямо динамически её агрегировать по разным там срезам по разным фильтрам то есть дальше уже эта мера очень легко может быть ну и соответственно Дальше он уже Может на основе вот UI строить различные графики фильтры сложные дашборды репорты Ну а под капотом конечно строится SQL который в общем-то нужно выполнить для того чтобы такие графики отрисовать и вот здесь видим что в сле здесь уже Конечно есть там Join From sales Joint product то есть система понимает как правильно этот дакс преобразовать в SQL Как правильно сгруппировать что именно на виджете сейчас выбрано чтобы там правильные джоны проставить правильные агрегации но она это понимает за счёт того что в системе встроенная модель данных то есть там например есть информация о том как таблицы друг с другом связаны где связь один где связь к многим какое направление связи и это всё происходит автоматически то есть пользователю нужно Меньше времени уделять там написанию SQL он больше может сосредоточиться на написании на создании дашбордов А вообще Давайте такой небольшой дисклеймер про какие сценарии Я буду рассказывать значит кликхаус который находится в центре нашего движка это про архитектуру дальше расскажу он конечно используется обычно в сценариях realtime аналитики Как вы знаете анализ Лог логов интов рейсах в машин Ленинг и вот наверное эти сценарии основные для Клик Хауса но также есть в принципе и другие сценарии в которых хау в принципе я бы сказал используется реже но тем не менее это сценарий бизнес сценарий Bi это вот именно про отчёты про репорты про такую простую ОТК аналитику А обычно Типовой проект выглядит Так у нас порядка там от 1000 до 10.000 бизнес пользователи это те кто смотрит непосредственно отчёты есть аналитики так называемые Power юзеры это те самые пользователи которые генерируют там вот эти дакс создают отчёты и создают и меняют данные их апдейт а суммарный объём витрин обычно там до десятка терабайт это всех витрин имеется в виду это все-все-все таблицы обычно таблицы у нас на проектах занимают Ну единицы терабайт То есть это не какие-то там петабайт конечно но тем не менее а и также обычно это конечно сценарий исторических данных и не near Time То есть это не realtime аналитика у нас здесь нету миллионов вставок в секунду ну за счёт этого Как раз некоторые оптимизации мы можем сделать Ну и самое главное сложные аналитические запросы и высокая вариативность то есть сложно понять пользователь будет по каким группировать атрибутам по каким фильтровать то есть там используется Ну то есть может использоваться совершенно непредсказуемый сценарий Ну и ОТК аналитика тоже А значит что такое сел сервис именно в контексте этой презентации То есть почему это важно важно в этих сценариях это то что как я уже сказал казал Мы хотим минимально привлекать it специалистов Или вообще не привлекать то есть пользователи сами должны загружать данные из источников в интерфейсе свои файлики подгружать Да обогащать а пользователи должны уметь всё-таки и большие таблицы в том числе настраивать э должна быть возможность настройка инкремента загрузки опять же без привлечения специалистов то есть пользователь как-то сам должен уметь в интерфейсе настроить и система должна автоматически начать инкремента грузить данные система должна масштабироваться должны быть права доступа безопасность управление метаданными происходить Ну и в общем-то интерактивные дашборды рассылки массовое отчётности Ну и самое главное система не должна тормозить всё должно работать быстро и с минимальным привлечением it специалистов чит Типовая архитектура на входе у нас поставщики данных они могут быть там предварительно загружены в какой-то промежуточный Ну не промежуточное в какой-нибудь Даха Я здесь умышленно детали опускаю Это здесь не так важно Но именно мы отвечаем за то чтобы уже конечные витрины B для анализа данных работали быстро надёжно и соответственно есть дополнительные модули которые уже Мы разработали которые вот эти все оптимизации и автоматизации э соответственно упрощают то есть есть у нас первая часть модулей ближе к данным это тот кто отвечает за загрузку из из источников отвечает за оптимизацию э вот этих витрин на этапе загрузки и про модель данных про неё тоже позже расскажу ближе к пользователям - это оптимизаторы запросов вот этих Дак запросов про которые я говорилось запросов которые в кликхаус В итоге летят Ну есть сопутствующие модули которые там менеджмент кластера управление правами безопасность и так далее А ну и какие вызовы вот хотим мы разработать такую с-сервис платформу чтобы не привлекать или минимально привлекать эти специалистов но какие вызовы при этом есть а мы должны выбрать как-то автоматический движок таблицы мы должны например как-то выбрать ключ сортировки первичный ключ мы должны как-то подобрать оптимальные типы колонок должны оптимизировать SQL запросы реализовать инкрементальные что кликхаус с большим количеством джоновна нет Как сделать так что пользователи например грузят данные и не случилось так что вот он нажал там F5 в браузере видит одни данные по продажам ещё раз F5 нажал другие То есть он должен не бояться что данные например ещё наполовину загружены а не пол доже всегда понимать что вот эти данные актуальны это тоже очень важно Ну и как ВС там реплицировать загружать инкремента загружать и так чтобы У пользователя всё работало не было каких-то промежуточных данных отка и отказоустойчивого дальше с кластером там тоже есть вопросы как правильно распределять запросы к таблицам и как следить чтобы если улоки восстановить или таких три три основных столпа на которых вся все наши оптимизации и автоматизации работают Значит первое - это загрузка данных а то есть на этапе загрузки данных Мы производим некоторые оптимизации о которых я расскажу во-вторых это модель данных а модель данных помогает все эти оптимизации имплементировать и оптимизатор запросов это уже то что в конце происходит когда пользователь собственно генерирует вот эти самые запросы из отчётов начнём с модели данных Значит она выглядит примерно так то есть у нас есть какой-то набор таблиц а они там связаны между собой в центре обычно витрины Ну в нашей платформе такой подход Что обычно это там звёзды созвездия соответственно пользователи должны подготовить таблицу фактов а подготовить измерения То есть например факты - это факт какой-то продажи по датам и есть измерения которые описываю там магазин например этой продажи продукт в рамках продажи камера дату и так далее ну и пользователь в интерфейсе может каждый из этих таблиц соответственно там динамически загружать из разных источников и уже в нашей платформе их внутри объединять Ну и вот эти все данные они автоматически загружаются соответственно в кликхаус Ну и дальше пользователь создаёт показатель на языке дакс и дальше используют эти показатели для расчётов в своих отчётах значит что по что в себе хранит Какую информацию хранит вот эта модель данных что позволяет оптимизировать витрины во-первых тип источника то есть мы мы знаем например Это постгрес был То есть откуда мы эти данные получили из поса из кликхаус там из какого-нибудь ДХ из из цсв например файла А мы пользователь настраивает связи то есть мы знаем что вот эта таблица это измерение значит это справочник там есть ключ какой-то она находится со стороны связи один и это таблица фактов Она со стороны связи многие мы знаем Ну то соответственно мы понимаем разницу этих таблиц и Мы также обладаем некоторой статистики статистикой из источников То есть за счёт того что мы контролируем вот этот процесс загрузки мы можем понимать Какие ключи есть на источнике Какое количество уникальных значений было на источнике Какие типы данных хранит вот эти самые показатели и хранит статистику использования То есть когда пользователи смотрят отчёты и их формируют мы соответственно за счёт того что опять же контролируем процесс доступа к данным мы понимаем по каким там атрибутам он их группирует таблички по каким дан по каким колонкам он фильтрует эти таблички эта информация тоже помогает Ну и конфигурация инкремента загрузки для того чтобы понять как правильное перестраивать все оптимизации с нуля вот когда мы эту модель данных подготовили начинается процесс загрузки данных и здесь есть ряд автоматизаций которые мы делаем у себя в платформе в общем-то это очень похоже на то что администратор баз данных бы делал ну или там разработчик решение делал бы самостоятельно мы пытаемся максимально это процесс автоматизировать както выть в Тали Мы например можем для некоторых колонок использовать Join Engine мы можем подобрать тип данных так чтобы быстрее и оптимальные запросы выполнялись мы можем сами выбрать движок таблицы потому что в кликхаус их большое количество мы можем нормализовать таблицы и мы можем А ну и соответственно есть ещё одна автоматизация которая позволяет там загружать ещё реплицировать и отвечает за по каждому пункту по порядку значит как можно подобрать Order by ключ в автоматизированном режиме Ну все вы знаете да что Вот ключ в кликхаус очень сильно влияет на то как данные потом на то как таблица потом обрабатывает запросы но здесь рекомендации на самом деле типовые которые понятно что там не в 100% случаев но в 90% случаях вот делают именно так то есть берут и чем меньше кардинальность есть например у вас всего 10 штук тем значит левее это чем соответственно больше уникальных значений тем правее опять же чем чаще фильтруют То есть например Мы например собираем статистику и понимаем вот эту колонку чаще фильтруют Значит мы можем например При следующей загрузке данных эту колоночная рекомендация она по нашим тестам при Там они поему п советуют колонок Ну вот 3-8 колонок в ключе это такой нормальный компромисс Ну и можно стараться учитывать иерархии То есть если вы понимаете что есть настоящие такие честные иерархии между какими-то колонками то Ну например Город страна то эту информацию вы тоже можете использовать Ну и в общем-то всё это основывается на кардинально количество уникальных значений как мы эту информацию можем достать Сначала мы можем первый вариант мы можем наме положить промежуточную таблицу посчитать значение и загрузить в итоговую мы можем посмотреть так как мы обладаем информацией об источниках Наших мы можем к ним сходить и узнать статистику и мы можем собирать статистику использования нашими пользователями И это тоже использовать по каждому варианту подробнее значит Ну вот Первый вариант - это загрузить промежуточную таблицу Это самый простой вариант здесь можно использовать наме вместо который примерно считают количество потому что точно нам считать и не нужно нам надо примерно оценить количество уникальных значений ну этот вариант хорошо работает когда данных мало Когда у нас нет информации об источнике но требует промежуточную таблицу и требует дополнительные затраты по времени памя из источника к примеру можно сходить в постгрес в статистику постгрес и достать примерную информацию о количестве уникальных значений в каждой колонке здесь у нас получается нет никаких доб затрат Мы это можем быстро эту информацию получить но к сожалению не все источники поддерживаются Ну и по нашему опыту не всегда дадут такие права то есть так как мы коробочное решение мы не всегда контролируем там права доступа какие есть у наших заказчиков поэтому не всегда к источникам Т доступ Ну и слушать запросы пользователей Вот например мы первый раз загрузили посчитали Что у нас там Type категории прок такой порядок Потом немножко несколько дней послушали запросы поняли что категории намного чаще фильтруются по категориям и мы можем например в какой-то момент полностью перегрузить таблицу и поменять местами категория ID Type за счёт того что Чаще всего именно фильтруют по ней то есть по тапу наверно станет чучуть хуже Но зато большинство запросов будет выполняться быстрее Ну и дальше можем комбинировать варианты в зависимости там от объёма таблицы типа источника от ограничений источника типа загрузки в принципе там ускорение оно в два-три раза ну я там дальше ещё покажу детальную разбивку по ускорению Ну и пока я готовил презентацию в кха 2 недели или 3 недели назад уже создали порек на основе вот такой статьи они в принципе примерно очень похожи делают То есть можно опция выключена по умолчанию но вы её можете в кликхаус включить и кликхаус будет автоматически на при вставке блока данных предфильтры То есть он будет опять же точно Ну почти также анализировать кардинальность колонок и примерно их сортировать по умолчанию она выключена потому что это Дополнительные расходы по цпу по времени Ну в принципе это что-то очень похожее на то что делаем мы но на уровне одного блока данных второй сценарий например вот у нас есть такая табличка простенькая там цвет и количество продаж там например сумма продаж цве Color цвет - Это тип string То есть это строки и загружено в merge 3 что мы можем сделать для ускорения А мы можем например э отсортировать то есть взять все disting значения колора отсортировать их по алфавиту и проставить ключи инто вые ключи И преобразовать факты вот ну то есть табличку изначальную к интом ключам вместо стрингов соответственно вот допустим возьмём запрос если бы мы это не делали То есть просто берём col суммируем аут и группируется там полторы секунды на Большой таблице А вот в том варианте котором я рассказал используя вот эту специальную таблицу для строковой колонки а используя специальную функцию дн Gate кликхаус мы можем сильно ускорить этот запрос вместо полторы секунды он станет 06 секунд но есть ещё конечно Альтернатива в кликхаус есть так называемый Low cardinality Мы тоже это можем использовать То есть если мы знаем что уникальных значений в колонке не очень много мы можем выбрать специальный тип Low cardinality и в принципе он тоже довольно хорошо ускоряет до 0,8 секунд а следующий вариант следующий тип автоматизация это автоподбор типа данных но тут совсем Всё просто То есть он работает только в случае с промежуточной таблицей когда эта таблица не супер там огромная или мы можем себе позволить время А потратить на то чтобы загрузить э данные Ну это в сценариях Bi это очень часто можно себе позволить под там ночью загрузить данные потратить время и данные автоматически там оптимизируются ну и в случае инкремента ой в случае автоподбора типа данных А мы можем просто там взять максимальное значение Итого столбца и понизить его тип данных то есть изначально он мог быть н 64 потому что он так был в источнике или потому что это цсв была Где мы не знаем какой тип мы только знаем что это инт а но в реальности максимальное значение 97 Ну то есть то есть мы можем выбрать тип Unit 8 и вместо UN 64 и это очень сильно И хорошо оптимизирует и запрос и использование памяти в случае инкремента вопрос Что делать в случае инкремента Ну допустим я что что если вот я ещё раз загрузил догруз данные А у меня стало не 97 а 257 и я вышел за эти рамки но тут тоже как бы волшебства не бывает что мы делаем у себя то есть либо в случае инкремента Вы можете вообще выключить эту опцию либо есть режим Когда умножается тип Ну то есть вот в этом случае назначил бы не 8 например а 16 и в принципе запаса было бы больше и в случае если бы всё-таки этот запас был превышен то система автоматически начинает полную загрузку А дальше мы можем автоматом выбрать движок таблицы за счёт того что мы как раз имеем информацию об этих связях и о кардинально то есть мы например знаем что вот есть sales таблица фактов и есть продукт это справочник измерения в продуктах мало значений это там маленькое количество огромна связь Он ко многим классической сценарий для использования 3 п или таблиц в общем-то тоже за счёт того что эта информация вся собирается есть Мы это можем делать автоматически Ну и классика денормализация вот мы можем просто на этапе загрузки просто приони все справочники за счёт того что мы имеем вот эту информацию связях кото Постав Ну тут в общем-то всё довольно классически сильно очень ускоряет запросы потому что это основной вообще сценарий использования кликхаус одна большая Широкая таблица Ну и сложно обновлять то есть в справочнике что-то поменялось сложно дальше с этим работать приходится перезагружать данные А ну и в общем-то все эти автоматизации они работают на уровне загрузки и вот так выглядит алгоритм он приведён на примере инкремента загрузки то есть пользователь настроил инкрементальные автоматически будет по такому алгоритму идти то есть допустим у нас есть какие-то уже данные в таблице а они разделены на парше э соответственно пользователи все отчёты именно ходят вот в эту таблицу один для отрисовки что мы делаем при загрузке мы создаём новую таблицу и очим новые партишен и старой эта операция tch Partition From в кликхаус не создаст копию данных она на уровне линуса Просто ссылки создаст на файлики и таким образом вы создали такую просто легковес ную копию таблиц без копирования данных дальше мы загружаем n+ первы Partition из внешней суд и создаём на втором кликхаус такую же точно табличку с движком replicated meram значит таблица сдаётся мы вызываем Select Count и просто банально по количество колонок не совпадёт с исходной таблицей которая загружена уже на сервер 1 Ну и как только все данные загружены мы переключаем отчёт на новой таблице моментально и удаляем старую таблицу таким образом пользователь не видит что там па N п пер там в первую секунду там 100 строчек там добавилось во вторую ещё что-то то есть в отчётах графики не Скат они вот моментально переключаются на новый слепок данных вот здесь такая табличка Я просто некоторые из наших тестов привёл здесь Соответственно по колонкам идут те оптимизации которые применяются а слева идут запросы вот эти оптимизации сделаны точнее эта табличка сделана основе Стар схема based Benchmark он сделан на основе tpc довольно старый бенчмарк но тем не менее в принципе он хорошо показывать некоторые паттерны Ну и как видите некоторые оптимизации вот там где красная жёлтая где жёлтая они почти ничего не делают хуже где красное они делают хуже Ну и где зелёное делают лучше и Вот видите что В некоторых случаях в принципе Даже эти оптимизации могут там В некоторых случаях в малом количестве кейсов сделать хуже Но тем не менее в комбинированном варианте эта самая правая колонка почти всегда получается намного быстрее Ну и в целом там разброс конечно большой но в целом от X3 до X100 вот основная масса сценариев она оптимизируется оптимизируется конечно там выбросы Но вот основная часть именно попадает в этот диапазон Ну и в общем-то Когда у нас все данные загружены Когда у нас схема определена данные загружены нам нужно обработать запросы приходящие от пользователей значит напомню пользователи пишут на языке Дак а не на языке SQL этот язык проще для них и лучше позволяет переиспользовать их расч в рамках разных виджетов разных сценариев потому что э там например Здесь там нет никакой предопределённость у нас модуль который отвечает за транспак запросов в SQL дальше этот SQL нам нужно оптимизировать Ну наверное Многие знают что в кликхаус оптимизатор там ещё не самый классный но в принципе там требует каких-то дополнительных оптимизаций В некоторых случаях Ну и в конце выполняется всё на кликхаус значит когда мы подступили к этой задаче в принципе мы довольно быстро разработали первый вариант решения что мы делали мы брали вот этот дакс слева представлен дакс запрос с помощью библиотеки А мы его преобразовали вот преобразовали вот в такое дерево и в общем-то дальше был просто там ко по сути который состоит из кучи ичико генерировать просто очень реализовать но было очень много ивчик и очень сложно было дакс развивать потому что дакс на самом деле позволяет очень сложные конструкции писать там даже переменные есть вложенные контексты Есть подзапросы Ну то есть там всякие итераторы то есть здесь просто очень простой пример а на самом деле там всё намного сложнее ну поэтому мы мы разработали вторую версию транспарант в подзапрос на SQ То есть к примеру вот у нас есть слева Запрос который суммирует а колонку amoun из таблицы sales э соответственно как это выглядит с точки зрения алгоритма Сначала мы берём самую нижнюю ноду и пишем для неё SQL например Select amount From sales То есть просто достанем все ауты из sales потом мы поднимаемся выше и пишем новый запрос содержащий первый в качестве подзапроса Ну типа Select some From Select amount From sales то есть оборачиваем Нижний запрос более верхний с некоторыми расчётами Ну и так далее мы поднимаемся поднимаемся поднимаемся и получаем такое довольно большое SQL дерево вот Это пример уже более реального а а дерево дакс Ну чтобы понимали что сложность Ну то есть намного сложнее там получается конструкции в реальности а ну и соответственно во второй версии транспарант Легко дорабатывать легко развивать его а но на выходе очень сложный SQL который требует множество оптимизации то есть много там вложенности получается джоновна на уровне кликхаус они Ну редко когда спасают а а соответственно нам нужно что-то какой-то оптимизатор который превратит большой запрос в намного меньше который быстро выполнится на уровне кликхаус как у нас сейчас это работает а значит мы реализовали много оптимизаций а значит используется pattern visitor который проходит дерево и мы в основном используем rule based оптимизации Что это значит Это значит что у нас есть просто некоторые правила в этом SQL дереве которые мы можем оптимизировать то есть мы всегда знаем что вот эта оптимизация если мы найдём такой паттерн её применим она точно сделает либо лучше либо оставит также хуже Она не сделает а в отличие например от cost based оптимизации где там надо разные ветви рассчитывать и выбирать лучшую из них за счёт того что но за счёт того что мы именно сами контролируем процесс генерирование вот этого Эля мы сами понимаем что у нас очень много паттернов которые мы легко можем упростить также используются различные эвристические оптимизации но в целом Мы всегда Ну то есть там эти эвристики они обычно в 99% случаях в наших сценариях именно B они срабатывают используются кэш таблицы Ну то есть например мы знаем мы видим этот большой SQ видим что некоторые части очень похожи и мы можем сначала там что-то предавать положить в кэш и в рамках этого запроса уже не не описать сложность SQL А селекти из вот этой кэш таблицы Ну и эти кэш таблицы можно переиспользовать и в других запросах А ну ещё важно что вот вот эти rule based оптимизации эвристические они могут что-то в SQ дереве поменять Так что что откроет а возможности для других оптимизаций ну и соответственно мы поэтому повторяем в цикле То есть к примеру мы проходим все там 50 оптимизаций прошли один раз дерево и оказалось так что первая оптимизация не смогла выполниться потому что она зависела от того что там дальше оптимизации сделали поэтому мы просто гоняем в цикле А пока Ну не не закончится Ну то есть ни одна оптимизация не не не будет применена а ну и соответственно Здесь э несколько примеров аэ здесь именно я буду примеры простых оптимизаций показывать Ну сложные там быстро не объяснить там большой скель и много нюансов Ну к пример самая простая - это просто схлопнуть запрос то есть мы видим что внешний запрос на входе вот Select где две колонки он ничего нового не делает он просто селекти уже то что есть Поэтому Зачем это делать Давайте сразу за секм сраз Ну из таблицы может Ну и эти на самом деле оптимизации могут быть сложнее то есть там внутри какой-нибудь груба ещё может быть как здесь какой-нибудь w и так далее То есть там есть разные ветвления которые Мы тоже учитываем например мы можем поменять местами таблицы в джои то есть мы так как вот я рассказывал уже знаем и обладаем информацией о статистике обладаем информацией о том сколько строчек В какой таблиц мы понимаем что sales там миллиарды строк в продуктах там 100 строчек Это значит что нам надо sales не справа от добавить а слева потому что тогда ха создаст таблицу для продуктов а не для sales и это будет намного быстрее работать и намного лучше будет работать по памяти а потом например более такие неочевидные оптимизации То есть к примеру У нас есть line Order таблица фактов и SU таблица справочник мы жоним и фильтруем и не группирует ни по одной колонке какой-нибудь показатель просто на дашборде Как число выводим вот такой запрос выполнится 12 секунд но мы можем его переписать и доставать данные из из лайно ордера Без дна И дальше сделать подзапрос который достанет предварительно всех сулаев Вот по этому фильтру из таблицы справочников дальше мы уже ином фильтруем по ключам вот этот запрос выполнится намного быстрее то есть вместо 12 секунд это будет 2 секунды Ну и здесь вот некоторые просто примеры реальных уже SQL здесь недо всматриваться прямо в текст это просто чтобы наглядно было видно то есть вот такой был У нас исходный SQL вот мы его там немножко оптимизировали потом ещё немножко оптимизировали ну и в конце получается такой который уже в принципе довольно быстро выполняется без каких-либо проблем вот у меня всё переходим к вопросам большое СБО что послушали Спасибо большое за доклад тебе перед тем как перейти к вопросам хочется поблагодарить нашего генерального спонсора за то что он помогает нам делать эту конференцию компания МТС она занимается На самом деле вообще там кучей всего делает различные платформы экосистемные продукты спасибо им большое и Давайте вот вопрос с первого второго ря Здравствуйте спасибо за доклад Меня зовут Роман Васин компания Арена дата мы вот как раз главный контрибьютор кликхаус в России сейчас вот хотел уточнить вот как бы на самом деле две группы вопросов как бы первый вопрос про движки таблиц Вот как я понимаю вы вообще не используете РИБ таблицы Да и шардирование вы не использовались Да и вся вот эта вот идёт как бы математика оптимизация больше на уровне как бы вот вы не используете там суммирующий merch 3 именно просто Используйте merch 3 И тогда вот как бы ну я понимаю То есть как бы вот такое как вот определить когда у вас исходных данных там 10 таблиц из разных из двух источников сколько вы создадите широких таблиц в кликхаус одну или две или три и может быть у меня когда я смотрел ваш доклад как бы сложилось впечатление как бы что вы идёте как бы от источника к модели может быть надо наоборот идти от дакса к модели и кто эти модели делает вы вот говорите что это мы делаем А мы это человек аналитик или Это скрипт ваш то есть кто создаёт модели и как они адаптируются потом вот вы это немножко тоже немножко как бы подсветить именно скрипт или человек адаптирует модель Как быстро он её адаптирует то есть вот это вот момент ещё жизненный цикл от источников к дасу и от дакса к модели и Ну да Попробую ответить значит ну сценарии могут быть разные в принципе классический сценарий пользователь готовит сначала модель данных То есть он например выбирает Excel загружает Excel выбирает таблицу из постгрес загружает пог выбирает таблицу там например из ещё какой-то базы данных загружает видит вот эти вот таблички начинает их связывать руками то есть он прямо мышкой связывает эти таблички и когда вот эта модель готова всё он переходит к к отчётам и уже может разные группировки э добавлять и накидывать соответственно понятно что некоторые оптимизации могут быть применены только при следующей загрузке То есть он разметили модель он загрузил данные он дальше может например нажать заново загрузку всех данных или в следующий раз по расписанию ночью вся загрузка данных произойдёт и система дальше уже автоматом за счёт ну она уже всё она уже знает про модель она уже имеет данные она уже может вот эти все оптимизации применить но в принципе можно и скриптом это сделать То есть есть AP которые позволит То есть вы сами можете в своих инструментах например написать скрипт который эту модель будет как-то автоматически создавать То есть в принципе здесь довольно большая Свобода А ещё был вопрос про то как как мы выбираем Какие таблицы жой Нева а какие нет то есть здесь а вот да но вот это как раз зависит от модели данных То есть за счёт того что мы понимаем что таблица фактов - это всегда связь многие пользователь указал это в явном виде он в явном виде когда чертил вот эту модель данных он сказал вот эта таблица условно то есть там нет как бы термина таблица фактов но там за счёт связи Это понятно И за сч управление связи он понимает он системе сказал Обозначил вот э таблица фактов вот э таблица измерений соответственно система смотрит связь есть или нет И смотрит Сколько в измерении там значений сколько фактах значений на основе этой информации она решает там например жой Нева и ещё учитывается инкрементальная загрузка потому что хорошо Если вы раз ночью можете себе позволить се перезагрузить без вопросов там при Джоли да Можете потратить много там часов времени всё приони в случае мента вот эта оптимизация не будет работать и не работает потому что ну вам вы не можете себе иногда позволить всё жони заново вот для маленького инкремента это по сути пересчёт всех таблиц и это очень сложно Надеюсь ответил так давайте вот из второго ряда и потом дальше Из третьего Прошу прощения и дальше с левой стороны в синей толстовке да Меня зовут Василий Никита Спасибо большое за доклад Вау если честно Ну то есть очень амбициозный проект и ну очень впечатляет то что вы делаете а первое что ну как бы мне услышала непонятным это всё-таки как происходит работа сст то есть ну это наверное отдельный доклад потому что Ну наверняка Ну я услышал некоторые моменты то что соответственно итеративности не очень понятно Как как вы потом это дело постоянно преобразуете По всей видимости вы там генерить сикл и его гоняется уже э ну или вряд ли это происходит именно на АСТ вот ну то есть вот если вы сделаете такой доклад Я думаю всем Будет очень интересно а второе Я не понял почему Ну когда вы говорили про ци транзакционный чтобы пользователь не пугался да то что у него Данные льются вы создаёте новую таблицу Вот но вроде как по классике создаётся там merch 3 и дальше у просто ему подсовывает Пан и вроде как это везде достаточно быстро происходит вы с чем-то столкнулись с таким что такой подход не сработал совать таблицу целиком а новую партию и её подменить её подложить вы имеете в виду залить новую партиции в Новую таблицу и потом Ну да здесь просто проблема в том что мы это должны сделать на всех кла на всех серверах одновременно а то есть репликацию вы хотите ещё и покрытие репликации чтобы репликация чтобы сервер не гулял на разные сервера и не видел разные данные и так не получится сделать Спасибо Никит я напомню тебе что нужно будет потом выбрать лучший вопрос за который у нас полагается фирменная матрёшка а пожалуйста вот в синей толстовке Привет Интересно Меня зовут Сергей группа компании Сбер А так уж получилось что я люблю считать деньги вот скажи пожалуйста а ты в начале своего доклада говоришь о том что эта система - это платформа для не айтишников то есть ну бизнес подразделения могут сами настраивать отчётность будут риски Финансы и так далее и тому подобное смотри оптимизация модели работа с моделью данных оптимизация загрузки настройка правил оптимизации выбор лучшей оптимизации админ-панель скажи пожалуйста всё вся вот эта команда которая занимается всей этой историей плюс кривая обучение чем это лучше чем выделенные трушные айтишники Понятно ну в этом-то я понял вопрос Спасибо но в этом-то и смысл что мы э мы занимаемся разработкой продукта то есть коробочное точнее решение то есть мы вот всё то что вы сказали все эти сложности как раз у нас пытаемся автоматизировать так чтобы наши заказчики которые взяли наш дистрибутив уже не занимались созданием индексов оптимизация инкрементальные загрузками вот eventual конн проблемам и так далее в этом-то и есть весь смысл что мы вот эти все проблемы заказчиков собрали в коробке сделали и предоставляем нашим заказчикам Ну согласись из того что сказывал этим надо управлять это надо как-то нать чтобы Настраивать надо понимать Я могу сократить расходы Ну за счёт того что я паттерны правильные подготовил как вы это сделали но чтобы выбрать лучший паттерн нужно разбираться в этом всё равно кривая обучение она Ну мне кажется будет такая нормальная Ну я возможно не до конца донёс мысль что эти паттерны пользователь сам не выбирает система сама эти паттерны выбирает А это важно но конечно как и в любой системе нужна поддержка Ну там Стоимость эксплуатации она конечно есть но она ниже чем если вы с нуля возьмёте кликхаус и все эти индексы будете создавать понятно что каждый кейс индивидуален там это надо смотреть конкретно В вашем случае но по нашему опыту это очень сильно упрощает так можно вот в первом ряду вижу с бейджика зовут Максим Здравствуйте Я прослушал может быть у вас кэширование есть редис какой-нибудь Если нет то почему кэширование есть можно просто in Memory каширование своё встроенное но в принципе вот мы сейчас разрабатываем возможность прикручивания редиса Ну и может ещё каких-то баз потому что мы понимаем что в наших заказчиков может быть ris а может быть не ris А может быть ещё какая-то база и нам нужно быть гибкими в плане выбора вот этих subd для Memory каширования и в том числе Мы каширу ещё важно Вот в Клик Хаусе в самом то есть вот эти кэш таблицы которые я рассказывал они прямо в кликхаус создаются Преда агрегаты условно то есть мы знаем что например для многих запросов проще какой-то предает посчитать а потом его уже в разных запросах переиспользовать вот эти вот это каширование тоже есть а то о чём вы говорите Это скорее уже больше какие-то вот уже конечные самые то есть виджет отрисовывать и вот для конкретного виджета мы можем эту информацию Ну закоротило очень быстрым вот как-то так Спасибо за во так можно вот в клетчатой рубашке мужчина раз раз добрый день спасибо большое за дект было интересно Меня зовут Борис я бы хотел уточнить один момент про загрузку данных там вы используете партиции я вот хотел уточнить насколько мне известно я могу ошибаться что При таком подходе структура данных должна быть одинаковая То есть если принято было решение изменить например денормализация Вы поступаете то есть как ну здесь волшебства нет то есть полная перезагрузка только так ну здесь Никак это ну Но это сценарий не то чтобы прям ну то есть сценарий инкремента Он намного чаще происходит Чем сценарий инкремента с изменением структуры там есть ещё нюансы про которые я рассказывал например не только таблица там столбец может добавиться а тип данных может поменяться Да мы решили что Т 8 а он вдруг стал UN 16 что с этим делать Да в этом случае мы просто там ну какие-то эмпирическим путём просто изначально повышаем там например тип но мы можем вот в ту ситуацию которую Говорите попасть но здесь только полная перезагрузка с этим никак но у нас система никак хорошо Спасибо Давайте последний вопрос вот на в середине зала Да с левой стороны в серой рубашке Да рука тянет благодарю Я меня зовут Сергей из X5 теха У меня вопрос Следующий касательно автогенерация сортировки а в том плане то что почему бы ещё не смотреть на уже созданные объекты и ну Собственно наследовать какие-то как бы сортировки пользователь же простра иватк определили Ну например из базы источника что кардинальность там низкая то как бы можно сразу же автоматически не просчитывает вые таблицы Да не сомневаясь в том что там тип данных как бы нужно с запасом или нет брать взять получается и уже как бы уже загруженный объект использовать Да как бы какие мы параметры выбрали для уже созданного объекта вот рассматривали такой вариант Ну вообще нет интересной мысль такого не было но вы имеете в виду что мы знаем справочник мы знаем его кардинальность он уже загружен нет такого нету но мы с или другой факт например то что мы как бы уже напоролись там может быть вот говорили то что сортировка менялась То есть как бы увидели что пользователи чаще сортируются по категории А не по типам сортировку поменяли если факт будет с такими же похожими атрибутами Ну как бы у нас при использовании Хауса было такое что мы товар магазин меняли местами Вот то как бы интересно надо будет пообщаться после презентации обсудить так друзья у нас время на последний вопрос осталось есть ли у кого-то Вот в конце зала да Спасибо расскажи пожалуйста как ваши Меня зовут Евгений компания Озон как ваши оптимизации повлияли на Клик он стал быстрее работать или там данных больше стало помещаться ну стал быстрее работать то есть это основной сценарий стал быстрее работать стал использовать меньше оперативной памяти А насколько ну вот у меня там была табличка опять же так как мы разрабатываем коробочное рение у всех заказчиков очень по-разному то есть совершенно разные у всех структуры данных совершенно разные а там количество кардинальность справочники то есть сценарии совершенно разные Поэтому вот точно ответить на этот вопрос невозможно Вот однозначно вот я здесь показывал слайд про например основанный вот здесь на Стар схему Benchmark если все комбина Если всё скомбинировать все оптимизации то основная часть запросов ускорения в 3 100 раз по сравнению с тем если бы мы вообще там загрузили merge 3 и почти его не оптимизировали в основном это там в 10 в 20 в 30 раз происходит ускорение А вот можешь на цифрах конкретно пояснить допустим Вы писали там миллион в секунду а стали писать три вот такого рода в худшем и в лучшем случае вот это важный вопрос прописали а то есть я рассказываю про сценарий сесс аналитики здесь в принципе нету сценария что мы интим миллионы строк в секунду То есть миллион строк в секунду - это обыч какие-нибудь логи трейс там Не трейс метрики там кстм аналитика Да вот сценарий про который я рассказывал Это обычно мы грузим данные раз в день несколько раз в день например ночью там Раз в час или там раз в 15 минут и на вставку У нас нет таких требований больших то есть обычно у нас Мом прочтение поговорить прочтение тогда какой вопрос аналогичный Насколько больше вы стали читать данных или быстрее выполнять запросы Ну вот вот на примере вот этого ч марка в 3 тире в 100 раз но опять же у всех заказчиков может быть очень по-разному у кого-то например получилось так там простая модель де нормализовать там может вообще там в 100 раз вырасти скорость и классно а у кого-то сложная Вить Ева Тая структура очень много уникальных значений очень сильны сильной кардинальность справочники и там будет в пять раз в 10 Ну то то есть вот надо конкретно кейс анализировать И только так отвечать на этот вопрос А вы как-то оперируется настройками самого клика ну там чом или как он устроен то какого размера сами реплики к примеру вот для этих цифр друзья Я предлагаю на самом деле дискуссию уже переместить как раз в дискуссионную зону у нас время на вопросы и ответы подходит к концу а Выбирай пожалуйста вопрос а один или два у нас один лучший вопрос Выбирай пожалуйста Ну наверное вот коллега который новую идею предложил будет интересно с ним пообщаться Спасибо А подарок получаешь оригинальную фирменную матрёшечки которая символизирует вклад в развитие сообщества Спасибо тебе большое"
}