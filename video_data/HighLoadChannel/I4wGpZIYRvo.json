{
  "video_id": "I4wGpZIYRvo",
  "channel": "HighLoadChannel",
  "title": "Our experience at Etsy com with building “Big Data” analytic capabilitie / Chris Bohn (Etsy com)",
  "views": 65,
  "duration": 3025,
  "published": "2017-04-22T14:45:53-07:00",
  "text": "крис богом ведущий разработчик б.д. вы точка ком именно он разработал инструменты репликации которые будут представлены на конференции highload плюс плюс что же рад всех приветствовать на мои лекции зовут меня перезвон все зовут меня просто себе я являюсь инженером по базам данных в excel dot com а кто из вас слышал про s7 отлично для тем кто не знает хочу сказать что это такое это сайт где люди которые изготавливают штат своими руками могут это что-то продать со всего мира вот примеры ювелирные изделия старинные какие-то штучки антикварные и тому подобное мы продаем это через сайт exe открывает магазин называют что они продают и могут торговать я хотел бы рассказать вам каким образом поменялись аналитические возможности в течение ряда лет я у них самый старый сотрудник из технической службы я наблюдал за ростом этой компании хочу его в этом рассказать для того чтобы понять каким образом мы добрались до той точки в которой мы находимся сейчас надо понять где мы были раньше но сначала хочу рассказать вам немножко об истории я изначально из сан-франциско мне всегда нравится рассказывать об интересных фактах в на а сан-франциско я родился здесь не очень интересно находиться в москве у нас тоже есть кое-что а русская почему потому что к северу от сан-франциско есть такое местечко котором взяться форт росс форт росс это местечко называется потому роз вообще это сокращение от слова россия это ford который был построен 200 лет назад построили его россияне и это был торговый форпост российской империи российская империя распространялось на аляску и она простиралась свое влияние и до калифорнии сегодня там находится национальный парк это музей это местечко находится примерно в часе езды от сан-франциско все это было построить 200 лет назад и до сих пор это сохраняется как музей там также есть городок под названием sevastopol севастополь есть также и речка в калифорнии который называется русская река калифорнии есть много известных виноделен и некоторые из наиболее известных марок вина выращиваются как раз для меня виноград из которой делаются эти марки вина вдоль берегов русская реке есть местечко которая называется русский холм в сан-франциско там когда-то было кладбище русское кладбище на этом хаму там есть православная церковь на другом склони это холма вот теперь вы знаете немножечко о том что существует русского в области вокруг сан-франциско думаю что это интересно а теперь поговорим про обработку бочка пива в данных в 57 мы поговорим о про историю компании даже поговорим по архитектуру и от всей которая менял за годы мы поговорим о потребность в политике мы поговорим о возможностях и потребностях сервисе поговорим про hadoop и других решениях потом поговорим про персикова после этого поговорим про те инструменты которые мы написали который мы сделали инструменты открытого кода шляпы autoshop несколько слов про компанию компания была организована в нью-йорке в 2005 году и организовали три выпускника считаем был тогда лет по 25 отличные ребята у них возникла идея и они создали компанию с и сейчас эта компания является ведущей в области продаже таких товаров по вам даже это из россии люди торгуют через специи сайт получился глобальным а у нас имеется 20 миллионов пользователей из них часть это продавцы примерно 1 миллион продавцов мы продаем в этом году примерно 1 миллиард товаров у нас есть 400 сотрудников из них 200 это инженеры на штаб-квартира находится нью-йорке но у нас компания многие работают удаленные например работают а и сан-франциско нас есть люди которые работают а проживаю в берлине в париже в лондоне есть несколько человек отражают в австралии как мы работаем мы работаем через версии все работы через версии я например ощущаю себя работающим в тесном единении со своими коллегами которые работают в нью-йорке там наша компания занимается работы на четырех этажах и никто между этими этажами не переходит для того чтобы поговорить с коллегами если можно говорить через r7 находясь на разных этажах точно также можно работать и находясь в любом городе у нас работает примерно 50 сотрудников которые живут не в нью-йорке а в самых разных точках мира мы недавно выпустили приложение для обеда повернет в начале года у нас был приложение для айфона и сейчас уже до 20 процентов всей торговли войти идет через мобильные устройства хочу рассказать вам про стек предложения все у нас имеются frontend феечки и создал а печки расмус лорда чем которые сейчас работает на нашу компанию он тоже работает проживая в сан-франциско вернее рядом с сан-франциско в зоне залива изначально вас так был такой печка взаимодействовал с бетонным отыскать фреймворк и после этого дошло взаимодействия сквозь gres я об этом рассказывал несколько более подробно а сейчас мы ушли от этой схемы сейчас у нас php взаимодействует с общим менеджер который за 52 печки который взаимодействует с массе тьму и по сгрыз об этом я тоже хотел бы вам рассказать поподробнее вот изначальный стек печь пи frontend сервера по промежуточного слоя был написанная в питоне как все это работало были функции бетон и которые были привязаны к сохраняемыми процедурам в обход gres apeach код взаимодействовал со слоем a500 допустим я хочу провести вот такую процедуру я хочу провести такую функцию и в конце концов этот вид он проводил эту процедуру мы начали с одной базой данных postgres там было все пользователи листинге а вся информация по продажам транзакции форумы разговоры все образцы всем храма все было то в одной базе данных теперь по мере роста компании этих мы решили что нам нужно как-то масштабировать наш сайт формы что мы сделали мы создали логическое разделение между компонентами в различных базой данных мы сохранили мастер базу данных где находятся листинге пользователей транзакция потом мы создали отдельный базы данных по форумов вот как это все происходит здесь вы видите что происходит базе данных интересная проблема возникла в том что в начале смотрели сколько раз лизинг рассматривался вот это все хранилось в памяти и каждый раз когда мы перезапуска ли сервер вот это все обнулялась большая проблема и мы создали еще одно одну возможность для просмотра этой информации чтобы эта информация не обнулялась и в начале функция поиска в postgres плохо масштабировались потому что в базе данных происходило очень много всего поэтому мы внедрили в 2009 году систему поиска solar это полнотекстовый поиск через базу данных и если вы ищете браун ту они значит проверяли везде где браун ходила по ключевому слову находила это все и так проблемы с оригинальным стеком идти плохо масштабировал ся 1 мастер база данных это не масштабируемая архитектура если вы разрабатывали сайт с нуля то самого начала нужно встраивать туда возможность горизонтального расширения потому что нам пришлось очень много поработать когда у нас была одна база данных и приходилось я как-то расширять еще одна проблема в хранимых процедурах было очень много бизнес логики в результате базы данных накладывала большую нагрузку на главный процессор на циpкa и это не очень хорошо что интересно нам было трудно находить инженеров потому что так стык был написан что им нужно было инженером знать пейдж пи и храни хранимые процедуры для бизнес-логики на уровне питон именно так увязывались его процедуры с хранимыми процедурами по этому номеру и как если мы хотели изменять хранимые процедуры то postgres присваивал им новый идентификатор и все что спраут арея происходило менялась потому что справа утар думает эта процедура 123 но там уже все перестроена и там мисс 123 было пять шесть семь то есть не работал каждый раз когда мы меняли сайт нам нужно было все перестраивать перегружать это было очень плохо это было архитектура версии 2 до того было все еще хуже я об этом даже говорить не года но разработка этой системы второй версии заняла полтора года и почти компанию убила это все вот поэтому будьте внимательны и с версией 2 она эта версия 2 убила больше компании чем вы думали вот я поэтому написал все большими буквами смотрите внимательно вот и избегайте строительство полной версии 2 потому что на самом деле объем этого проекта всегда больше чем вы думаете с самого начала поэтому лучше всего идти маленькими шагами и так у нас появилась новая архитектура я сейчас они поговорю все началось когда мы приняли на работу хороших специалистов из flicker а они прекрасно масштабировались лидер с помощью sharding горизонтального и распространения и действительно это были хорошие специалисты мы их приняли на работу потому что человек который основал флиттер катерина фей член совета директоров сказала я знаю этих людей они сплиттером это все сделали поэтому из у вас тоже все получится и поэтому с помощью этих людей мы перестроили архитектуры мы ударили бизнес-логику из базы данных никаких хранимых процедур база данных просто теперь хранилище и все которое хранит факты и измерения мы избавились от уровня спраут ира мы создали новый уровень psp бизнес лучик и логики который назывался и ч а р м и crm вот мы разработали более качественные шаблоны печки внедрили интерактивную клиентскую логику очаг мы заменили по склизкий самой с келли под греции прекрасная база данных конечно но люди из flickr были лучше знакомы с моей sql и эти базы данных и поддерживали sharding вот они хорошо работали с php таким образом когда мы создали такую базу данных мастер базу данных пост резки у нас появилось много места на сервере нам не нужно было дублировать данные постоянно и все наши данные разделили распределили так как это было логично по урок по пользователям по листингом все пользовательской информации жила на одном сервере другая информация другом сервере и у нас был сервер тикетов который выдавал универсальные ключи для всех шар дав и потом у нас были индекс серверы и когда мы искали пользователям и запрашивали этот сервер яндекс сервер и спрашивали значит пользователь 123 в каком шар где живет и он нам выдавал соответствующей информации и мы увидели что нам нужно связанные данные хранить как можно ближе друг другу это очень важно для масштабирования потому что избыточность это нормально хорошо потому что дисковое пространство сегодня не дорогое поэтому для некоторых пользователей мы можем хранить избыточные данные для их листинга в той же таблице у нас очень много слияние между таблицами мы не хотим дублировать данные мы от этого уходим и мы где нормализуем это все по возможности у нас большие таблицы возникают больше данных в этих таблицах хранятся но зато для поиска все это гораздо быстрее если вы разрабатываете систему для обработки больших объемов то пусть данные будут избыточное все нормально а вот архитектура на сегодняшний день облака оттуда приходят и облачные запросы есть это село который выдает сидит и которые моей осколки тот сервер мы по-прежнему пользуемся пост крисом как мастер базой данных для транзакционных данных по продажам почему мы это делаем потому что прост грез хорошо работает с агрегированные запросами по сравнению с моей скилл вот поэтому если мы смотрим и того то лучше смотреть в пост грессов бази даних вот такая архитектура вот плюсы и минусы этой архитектуры данные с шоппингом это великолепная для поиска каких-то отдельных записей в большом объеме записей потому что нагрузка распределяется по многим сервером и и вы можете делать множество запросов и поскольку данные распределены поиск проходит одновременно и очень быстро масштабирование данных идет в горизонтальном плане вы просто добавляете новые сервера в базе данных нет бизнес-логики логике вся логика находится на уровне о р м но как я уже говорил было трудно раньше находить инженеров которые должны стать и печки хранимые процедуры вот и питоны печкой теперь они все равно должны знать печки потому что вся бизнес-логика на уровне арма реализуется в печке вот но все равно нам стало легче находить инженеров поэтому хорошо не делайте свои системы слишком сложны и потому что трудно будет найти специалистов делайте такие системы для которых специалистов можно найти и так данные шарден гам горизонтально распределенные здесь есть и минусы хорошо для поиска отдельной записи это хорошо для агрегации не очень данные распределены по разным машинам не сконцентрированы на одной машине если вы хотите узнать сколько листинга в определенной категории надо сделать запрос надо просить все распределенные шарды точки зрения агрегации хорошо иметь один сервер потому что если все данные на одном сервере простая команда и вы все получаете кроме того и не иногда вам нужно перри балансировать шарды потому что иногда пользователи приходят в компании уходят из компании на некоторых шарда накапливается больше активности на некоторых меньше и необходимо балансировка перебалансировка и у нас есть для этого инструментальные средства все это работает но это не то что проблема на вопрос архитектура шарден гам помните требует периодического перри балансирования нагрузки между сортами значит к сейчас запрос агрегированных данных усложняется вы не можете работать с простыми командами из киев потому что допрашивать все сервера все разделы и это сзади задача инженеров теперь потому что надо знать где на эти данные находятся трудно анализировать бизнес потому что при анализе работа идет с агрегированные данными с шахтами это затруднено у нас есть два типа пользователей аналитиков во первых это ученые которые работают с данными умные люди математики печки и все такое вот работают интересных областях они используют ходу каскадирование для анализа данных каждый день и мы начну отправляем данные входу и все данные переносим в matlab используем это для разработки алгоритмов упреждающего поиска со временем они все эти данные считывают и мы видим что обычно люди вот такие данные ищут вот с такими данными работаем и если мы это все учитываем то тогда мы данные которые нужны этим людям ближе к ним храним я не быстрее получают эти данные есть еще бизнес-аналитики которые анализируют данные с финансовой точки зрения и они пытаются отвечать на такие вопросы в какой категории продукты продаются лучше всего сколько мы заработали какова средняя цена и так далее это другая работа не такая как у людей первой категории и здесь мы в основном конечно работаем больше с бизнес аналитиками больше всего их так нет это слайд уже было вот наша архитектура бизнес-аналитики business intelligence у нас есть так называемое база данных би ай да the bass это было просто копия мастер базы данных когда у нас был просто postgres и тогда все было очень просто мы его и дублировали все было нормально но потом мы добавили шарды и теперь у нас все данные из шар дав нужно переносить в эту базу данных и каким образом мы это делаем у нас есть классы печки которые опрашивает все таблицы и говорят пожалуйста все изменения с последнего запроса вы дать мне то есть они обновляют измененные данные и в общем то если данные обновлялись то тогда эти этой информации обновляется и в мастер базе данных как это все работает печь пекут запрашивает шарды каждый по очереди из спрашивает все изменения все новые данные пожалуйста дайте но функции удаления делить пропускаются если мы что-то удаляем из таблиц это таблица полностью пропадает или правил запись сверли в таблице полностью пропадает если данные не обновляются а удаляются the master база данных не знала о том что они удаляются и тогда надо было такую функцию нам прибавить чтобы таблица знал а ты чтобы базы данных знала что данные удалены но этот процесс идет медленно я и сервер стал мастер базой данных у нас таким образом был один сервер postgres был где были все данные так у нас было самого начала этот сервер перегружен задачами репликации данных потому что все данные нужно переносить всех на сервер bio и потом есть утилиты в печке которые получали данные из шар дав а тоже переносили на сервер bio и то есть очень много работы было данные туда-сюда переходили все шло очень медленно почему не пользу использовать ходу для всего тоже есть проблемы ходу ориентирован на пакетные задачи б чаре задачи для случайных запросов он не очень хорошо подходит и он работает медленно с такими случайными запросами чтобы hadoop работал хорошо необходимо программ места очень хорошо поработать и нужно идти путем проб и ошибок в общем то долго и сложно конечно ученые могут это сделать все это их жизни но для бизнес-аналитиков это не нужно бизнес-аналитик хотят задать вопросы они хотят немедленно получить ответ и у них запросы всегда непредсказуемый и hадeюcь для них не очень подходит так как мы решили эту проблему мы посмотрели и попытались найти другой подход мы посмотрели на решение которые там были и нашли семь верьте к кто слышал vertica что такое это лицензированный продукт который в прошлом году купил компания hewlett-packard теперь это hewlett-packard разработана все майклом стон брекером отцом пост gresso я не хочу здесь вам продавать вертик у это пусть филиппа карта вам продает я просто расскажу о своем опыте если вам понравится посмотрите сами в это ваше дело и так vertica имеет много общего с пост грессов почему потому что sql похер и команда команды строка vez que al взятый спуск bereza но есть разница если вы меняете лицензию chappell вам нужно опубликовать это изменение для чтобы все вулкан source мире могли это использовать вы можете взять кстати этот код и сделать его частным с вертикаль они поступили компании так они взяли и сиквел клайн ты спас криса и клонировали сделали в сиквел но он выглядит почти как и сиквелл и они также парся взяли сиквелл это кстати не очень хорошо задокументирован это взято из postgres а если вы знаете postgres вы знаете там есть команда для двойная черта и вы можете выбрать а вернее двойное двоеточие двойной : для выбора данных это все низ документировано в верте ки но это работает мы попробовали работает это лицензируемый продукт но есть бесплатная версия бесплатная версия достаточно мощная один узел и 1 терабайт данных достаточно полезно я помогу вам показать демонстрацию о том почему это все может быть вам полезным даже если вы не хотите платить за этот лицензированный продукт вы можете загрузить бесплатную версию и вовсе то воспользоваться теми инструментальными средствами которые там есть это достаточно полезно vertica эта архитектура для множество сотрудников типичная инсталляция имеет несколько узлов в каждый юсиль равен другому нет одного лидера из этих узлов все они равны sharding поддерживает изначально и распределяет все данные когда вы загружаете данные вверх теку vertica распределяет данные по всем узлам и для малых таблиц она копирует копии малых таблиц на каждом узле а для больших таблица наносит небольшой таблицы делит на сегменты и использует внутренний хэш алгоритм и какие-то части данных на одном узле уст размещает какие-то для другую на другом и вы она знает как запрашивать эти данные вы об этом не заботьтесь она знает как она распределила эту таблицу она знает как это все запрашивает какой узел запрашивается какие данные и она выдает ответ и достаточно быстро это очень богатый язык сиквел хорошими аналитическими возможностями поддерживает функцию в in dublin достаточно интересно и что еще интересно и важно для нас мы искали решения для аналитики и мы не хотели чтобы наши аналитики учили что-то новое и если бы мы имели решение которое могло бы писать отчеты по той форме которые уже были с обратной совместимости by здесь мнение мы увидели shoes вертикаль так она есть что все эти отчеты они работают так же как в поскрести без изменений единственное изменение что они работают гораздо быстрее чем раньше немножко объясню о том что такое vertica в что в ней разные это база данных которые хранят данные в колонках традиционные реляционные базы данных хранят данные в строках в рядах вот посмотрите там реляционная база данных слева от а которая в колонках справа вы видите за час два типа user1 читает и там начать сэлфи листинг 9 как в реляционной базе данных это хранится и как персики эта хранится indexof нету персики есть основной ключ есть внешне ключ прайма реки и о рынке вот и данные сегментированные если вы производите слияние все эти данные сливаются если необходимо vertica хранит данные так она использует including что происходит при этом она группирует колонки вместе по значению как видите первые два ряда это листинг а дальше 3 sails каким образом они группируются 2 2 строки для листинг и три для листинга и три для sails и вот так они хранятся вот листинг на 2 на диске все листьев где хранятся вместе не когда вы производите запрос агрегированный запрос опустим я хочу выбрать сумму и того сумму и того в ле цион и после данных идется последовательной скан всего что там есть они вот этот e-mount который там вот чипа союзом складывает 233 до 122 потом ступить 020 от не надо 020 и надо 356 она нас опять записывай им все равно где что хранится причем один cells на одной части диска другой на другой один лишь одном другой на другом сервере вот а персики все очень хорошо допустим вы говорите я хочу номер 5 и яндекс night точно где номер пять живет и передает вам данные тут же vertica работает очень быстро верьте как группирует все данные и хранит исходные данные на диске рядом и когда вы сделаете агрегированный запрос допустим и того по типам все получается очень быстро я знаю что эти ряды находятся здесь те ряды находятся тут и они сразу обращаются к этим строкам и выдает информацию практически мгновенно ну не то что мгновенно но гораздо быстрее примерно в 100 раз больше чем в реляционных баз данных так теперь перенос данных наверх текут представлял для нас проблему потому что не было средств и сил для верте ки просто нам продавали верьте cool игорь фото на есть а как данные туда а это ваша проблема есть конечно и инструменты для переноса есть файловой системы ходу но все равно надо программировать начали как перенести спуск раз мастера вертик у как мы это сделали мы построили два инструмента хлеб и авто шло и именно об этом я хочу сейчас немножко рассказать хлеб и английский язык хороший очень гибкий но у нас нет слова для какого-то понятие мы можем к любому языку обратиться хлеб это слово и съедишь а значит нести большую большой груз на большое расстояние и не хочу я шлепать так с это шлем не стену в америке это слово распространена что vertica позволяет сделать она позволяет создавать функцию сиквел которая вызывает внешнюю программу и что мы сделали мы построили шляп как внешнюю программу писан и для вызова его мы набираем команду select from хлеб и также пользователь и имя таблицы и дальше вызывается программа питон и все работает вертите эта команда используется и переносит таблица из postgres на вертик у вот таким образом значит идет подключение к машине postgres получается ддл для этой таблицы потом происходит анализ идеал производит мэппинг типом данных какие-то типы не на 100 процентов эквиваленты между поскорее самой вертикаль тогда мы создаем мэппинг вот создается таблица с правильными требований для верте ки вот и затем через pisik в окопе данные переносятся в верте q то есть вокруг physical происходит такой процесс я вам говорил что после с и vertica очень похожи и в частности формат команды копии и идентичен если вы используете команду корень если вы говорите скопировать данные с этой командой в пост гресь и вы можете точно так же и с vertica и сделать лечение для записи мы просто делаем такую оболочку вокруг pesiq в питоне и не говорим скопировать таблицу копии вот туда и потом данные переносятся в верте q соблюдением стандартов вертите работает все достаточно быстро и с помощью команды копии лучше всего переносить данные сплошь gresso в верте q и кстати документация тоже есть пользуйтесь командой копии поскольку и в поскрести копии работает быстро и верте ки тоже быстро и все переносится очень хорошо кстати даже быстрее работает чем при переносе данных из postgres акс postgres у потому что vertica не проверяет ограничения переносит данные напрямую данные ведь уже в паз гресь и находится мы знаем что эти данные правильные и мы не проверяем там ничего просто переносим есть две версии этой программы хлеб и аута шлёп-шлёп это статический snapshot и часто бывало так что аналитики создали таблицу в пост грессов переносят его реплика через хлеб очень быстро 10 миллионов строк за несколько секунд переносится хлеб работает спас gresso мой секунды applications будет выпущена в начале ноября потому почему потому что работает так немножко по-другому моя команда postgres использует триггеры таблицы state and elbows а мой сиквел должен учитывать двоичные логика хорошо но это немножко по-другому как сейчас мы реплицирует шарды я говорил вам мы обновляем смотрим обновленные данные а вот операции удаления делить мы пропускаем а вот мой сиквел позволяет считывая двоичные коды учитывать и операции удаления данных поэтому мы разработали вторую систему аута шлем которая позволяет реплицировать данные из вертите тоже поскрести у нас есть триггер на таблице источники и если есть команда какая-то апдейт или gelid это все записывается промежуточных таблицах и через ваш скейлер все это копируется и переносится в верте q но не сливаясь с первоначальной таблицей и все работает после мы это используем авто шляпы шляпа миллионы записей перенес спас кресса с вертикаль синхронизация занимает не более 15 минут имя схемы имя таблицы в общем там множество ключей поддерживается и так где взять вертикалом и инструмента шлем в африке есть бесплатная версия если вы хотите вы можете зайти на сайт мая vertica точка ком и скачать эротика они собственно вас даже поощряют потому что они надеются что вы можете стать их клиентам я хочу вам показать что вы можете сделать вы качаете время я хочу провести короткую демонстрацию я сейчас нахожусь в делах клиенте я все это вот где также как под газ и я хочу получить список от таблиц схеме каждый раз когда арта штаб что-то делает или шляп там сделайте комментариев таблицы так что вы видите что некоторые из этих таблиц в автостопе они репрессирован и как сегодня об этом было сказано сейчас я хочу зайти в таблицу который называется риджентс и вы видите что она сеанса шляпам она не сделано при помощи авто шляпа а при помощи просто вышли то это очень хорошо потому что когда анализ те кто чит узнать насколько свежие данные он может быстро получить информацию о том а какова самая последняя версия здесь данную здесь я провожу тесты я начал а этот запрос до того как я вышел сюда на сцену выступать и запросу еще идет у нас есть таблица со всеми нашими счетами по всем нашим пользователям такие таблицы создаются каждый месяц когда люди хотят посмотреть свои счета мы хотим предоставить им возможность сделать это очень быстро возникли проблемы нужно сделать так чтобы у нас была полная и точная информация в идеале ценность всех транзакций нормальности который закрывается должна равняться открывающийся стоимости и балансу следующего месяца допустим закрывая месяц на 100 долларов следующий месяц мы должны открыть на 100 долларов если никто ничего не делал в течение нескольких месяцев то от ул возникает ошибка и мне нужно провести проверку я хочу провести несколько команд в паз грассе для того чтобы проверить все выписки мы хотим открыть открыл ваще баланс открытие ты посмотреть отличайте ли он от пола до закрытия и посмотрите если отличие в с грассе это занимает много времени для этого потребовалось будешь четырех часов и это конечно было очень огорчительно я перешел что я готова устал и я использовал шнек для того чтобы обработать эту таблицу и сейчас я проведу здесь тоже вторую команду и пройдет а проверка данных потребуется всего несколько минут смотрите мы уже получили ответ здесь мы идентифицируем а всех пользователей у которых баланс открытия не соответствуют балансу закрытие и мы также видим в каком месяце этот разлад и начал появляться это такой непонятный бак но мы хотим выявить у которых из наших пользователей имеется эта проблема вот а в паз грассе это задач по прежним выполняется хотя не запустил я уже давно ведь как долго допустим я хочу провести комплексный запрос хочу ещё раз показать вам насколько быстро эта штуковина работает у нас есть таблица со щитами когда кто-то что-то продает как то что то что то выставлять на продажу возникает соответствующая сумма оплаты у нас 5 миллионов записей обожай таблицы для того чтобы все лизал спас грассе я задаю вопрос мне нужно поднять а тип выплаты и сколько их всего вопрос грассе этот длительный процесс если сделать это здесь бум вот сразу вот насколько быстро будет бортика вы видите все транзакции которые проходили вот именно поэтому инструменты полезен даже если вы не работаете через лицензированную много узловую версии вертаки все равно вот инструмента очень удобный полезный не показывает что время мои уже истекло поэтому я хочу и помадка за внимание я буду находиться здесь еще какое-то время если вы хотите со мной поговорить я могу дать вам своей визитки мы можем поговорить с вами о этих системах пошли под бесплатные системы vertica также бесплатная вот вы вполне можете воспользоваться этими инструментами они хорошие удобные спасибо да если у кого вопросы есть я наверное могу на них ответить что у нас там со временем на вопросы ответы есть спасибо за рассказ о мне один небольшой вопрос вы сказали что вы храните данные мы мы храним данный как непригодных таблицах вначале они были приведенными потому что мы не хотели у девятерых данные а каппа обеспечиваете последовательном сданных если у вас большая таблица большое количество строк и какие-то данные дуплицирования как бы произойти обновления для того чтобы избежать появления ошибок и так далее и уж так понятно номер я вам больше скажу что одна из самых больших проблем организует своих мест в афганских базы данных со следующим и делали такую вещь как парень key integrity френки замедляют под gres а поскольку они ставят замки на таблице вот эти проверки осуществляются через времени замков и это очень замедляет систему мы не хотели этого мы решили чтобы уровень rm обеспечивал полноценность и точность данных мы решили что мы не будем использовать базу данных для проверки точности данных мы сделаем это на уровне приложения и мы этим очень довольны есть люблю бы был крупным банкам тогда в этом случае мы бы использовали все эти от проверки по вручения но то что мы делаем вот этого не требует нам лучше делать проверки уровне программирования а что вы делаете со ошибку выправить какие-то юнит-тесты да действительно мы используем дени тесты когда кто-то заставляет новую функцию пишет новый класс все должно пройти корзинка из тира вания и мы делаем большое количество развертывание каждый день 2 отчислим наших инструментов такие которые используются даже углам 17 называется деплоя унтер он позволяет развертывать всякие изменения в epam коды во франции веб-сервисы если вы зайдете в google и посмотрите теплее maker вы найдете информацию в год инструменте но нам не нравится большое развертывание набухшие по душе маленькие развертывание oriflame это также исполняет роль б вывез когда садитесь за ужин вы ведь не забиваете сразу так чтобы заглотить все что лежит на таблетки откусываете по кусочку спасибо за доклад крис вначале не высказывались что мы хранили а и мясники аккаунты в память а потом они стали сохранять их в пост грызть да это бейся а почему сначала вы этого не делали я говорю что в начального у нас все было в мастер база данных потом вы решили что там всего лишь по многу надо перейти к другой системе вот форму своей базы данных канва в свою базу данных потом мы решили что подсчет просмотров вот сразу упал до нуля мы оказались вот такими тупеть сами продавцы вот нас возненавидели мы решили проблема в том что мы не можем все сохранить в от памяти давайте вот сделаем вот что давайте сезон такой хак мы заставили делать под газ все это дело вещь это было просто решение но как в любом о таком решении вот оно какое то время живёт самостоятельно вот и у нас тоже одна прожила данный года 22 того как мы перешли к новой системе вот подсчета просмотров мы вообще мне нужно сказать что мы самые умные на свете мы делали так как умели"
}