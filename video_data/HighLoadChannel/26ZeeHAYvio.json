{
  "video_id": "26ZeeHAYvio",
  "channel": "HighLoadChannel",
  "title": "Sphinx 2013 / Андрей Аксёнов (Sphinx)",
  "views": 261,
  "duration": 3495,
  "published": "2017-04-22T14:46:44-07:00",
  "text": "вот тут написано сфинкс 2000 на свете значит собрали что это название сервер такой на самом деле название сервера кэш просто сфинкс четыре буквы 2013 символизирует то что буду ну рассказывать про то что мы сделали в 2013 году попробую это сделать сравнительно быстро соответственно никто ничего не поймет вот так теперь надо понять куда жать целиться в монитор не получается целиться туда началось о нормально просто пинге у кликов по три секунды поэтому когда я три раза нажимаю но через 15 секунд проматывает все для тех кто пришел а значит послушать доклад потому что слово сфинкс слышат в первый раз вот написано что это такой это сервер текстового поиска это значит софт который ставится на вашу машинку они веб-сервис который гоняется где-то там далеко и соответственно на который вы заходите и вбиваете свои ключевые слова для поиска в волшебную формочку как на google и он за все мои грехи с открытыми исходниками бесплатный распространяется под теперь им будь она проклята достаточно неплохо масштабируется самый толстый instance количество документов 50 там терабайт скорее всего уже может быть даже побольше самый другой пласт и instance 300 миллионов запросов в сутки потому что если бы это были два одних и тех же инстанс а ну то есть 300 миллионов запросов в сутки по коллекции калибром десятки терабайта я бы назывался яндекс или даже целый google и здесь бы не стоял вот кроме поиска сервер умеет ещё кучу всякого интересного и про это собственно и будем рассказывать ну точнее про малую часть того интересного что добавили в очередном году вот про что доклад у нас в этом году актуальны две новые версии 21 и 22 разработку 21 начали в принципе еще в 2012 скорее во второй половине выкатили бета-версию первую в феврале по моему в конце февраля мы практически в марте и почетную назвали ее релизом где-то вот совсем недавно в начале октября версию 22 но собственно пилим весь 2013 год если еще не выкатили то выкатим либо на этой неделе либо в крайнем случае на следующий ну то есть новые фичи которой вот делали традиционно для нашего странного проекта каждый новый релиз ознаменовывается десятками новых вещей буквально десятками но фича как вот говорил дядя поль и своему менеджеру это может быть много а может быть мало в зависимости от того как ты поставишь бизнесом соответственно попробуем поговорить о всех вещах на самом деле в основном тех которые я считаю большими галопом по верхам большие области изменений в сервере вот версии 21 влив в линейке версии 21 скажем так они вот такие встроенные значит адаптивные штуки которые позволяют кое как бороться с high availability и балансировкой нагрузки отдельная трубка fitch про борьбу с качественным поиска довольно разнообразную отдельная группа фич про начальную поддержку jison чиков в версии 21 отдельная группа fitch про инструменте рование то есть профайлинг но не только профайлинг ну и понятное дело оптимизация оптимизации вот версия 22 но немножко иная добавили ряд всяких штук про манипуляции с индексом него колонна движемся к совсем динамичному индексом скажем так который может ему литу создавать убивать как угодно ими манипулировать и так далее еще пока не пришли но туда движемся опять занимались качеством поиска довели поддержку джейсон до полноценной совсем поддержки и приделали лет ряд интересных спиц функций из которых я вот на слайды в доклад вынес но в основном наверное расширение группировки по сравнению с обычным москва ли сером поскольку они самые интересные прикольные бету собираемся выкатывать вот буквально на этой неделе может быть повторюсь в крайнем случае на следующий пререлиз принимаю ставки я-то его хочу понятное дело успеть сделать в это году а не затягивать на вот еще но как получится так и выйдет clicker опять повис а нет не повис значит про встроенный high availability и так далее я говорить практически не буду потому что чисто теоретически следующий доклад товарищи крюкова он должен в основном будет быть как раз про это но становлюсь совсем коротенькую коротенько что вот есть масса разных видов построить кластер основные на слайде перечислены еще пара совсем эзотерических на слайде не перечислена на самом деле в основном в основном для задач когда у вас все скажем так либо не слишком гигантское либо как минимум гомогенная ну то есть железо более-менее одинаковые странных пиков производительности странного дисбаланса производительности самого железа нет и странных постоянных пиков производительностью этого железа тоже нет во всех этих случаях вам на самом деле какие-то сильные большие сложности городить не надо и работает дубовый вариант под названием если мы ставим много реплик мэтти и реплики балансируем через х прокси все живет до тех пор пока вы значит успешно отделаетесь более-менее идентичными репликами поискал и кусков поискового индекса шарда в поисково яндекса как по объему этих самых реплик так и по железу которая обслуживает балансить и их чем угодно типичных a proxy потому что конечно денег заносить за железный балансира очень жалко машинка с х прокси стоит существенно дешевле и все привет но есть тем не менее значит адские странные ситуации когда у вас большой сложный кластер когда у вас яндекс не влазят в одну машину надо его шар бить когда из соображения чтобы она не рухнула и не завалила всю вселенную но три года необходимо внутри каждого шар да еще делать копии этого самого шарда и более того они же геморрой заключается в про что эти копии приходится разносить на либо отличающиеся по нагрузке машинки либо на этих машинках регулярно встречаются в всплески производительности какие то неважно из-за чего может быть какие-то фоновые работы запускаются может винты отказывают но тем не менее эти всплески производительности хочется отлавливать автоматически в момент когда такой всплеск произошел нагрузку с этой реплики снимать вот это при помощи х прокси как мне докладывают не выпилить в принципе ну то есть теоретически как то наверно можно но может быть в будущем будет можно это делать адаптивно но на данный момент нет поэтому штуки про поддержку такого вот динамического переливания нагрузки между репликами мы встроили в сам сфинкс для вот этого подчеркивают самого муторного случая он муторный он сложный если я правильно понимаю практически ему одному весь следующий доклад посвящен вот можно почитать про директивы legend мира и через 3g и так далее либо послушать тот самый следующий доклад такая вот минутка рекламы спим дальше 2 из 7 по моему штук которые занимались я естественно здесь сваливаю вместе все что и в 21 и в 22 делали речь на pro 2013 года не конкретную версию вторая штука которая там была на слайдах это качество поиска качество поиска это нифига не ранжирования это не только а местами не столько ранжирования вот ранжирование это вот примерно вот такая вот штука то есть та самая вершина айсберга ля-ля-ля совершенно понятно какие будут дальше слайда вот на самом деле у айсберга есть еще подводная часть и в этой подводной части закопаны большие подводные грабли на которые так и хочется наступить ранжирование это вот верхушка в лучшем случае а может быть и не верхушка может быть только верхушка верхушки потому что на самом деле качество поиска это еще вот вся вот эта вот штука весь вот этот фарш таки не зация морфология с одной стороны возможно опционально дополнительная пред обработка индексируем его текста в момент когда то его собственно индексирует с другой стороны после этого недостаточно скорее всего не удастся если сильно бороться с качеством поиска скорее всего не удастся все сделать в момент индексации и придется в момент поиска запросы тоже переписывать я сильно сомневаюсь что в принципе возможно умудриться сделать так чтобы запрос в момент поиска переписывать не было надо ну вот слайд потушили том как бы масса интересного текста и за счет того что запрос при поиске надо переписывать со всякими фокусами кворум коррекция транслейт опечаток расширение запросов и возможно оптимизации запросов и так далее 1 поиск на самом деле может выливаться не вадим в поисковый запрос к серверу а в произвольное количество запросов на у до трех штук кроме того после того как вы всем этим значит начали заниматься внезапно стает но тот же самый вопрос куда предыдущий оратор поднимала собственно качеству тут как-то изменилась упала поднялось хуже стало лучше как оценивать но надо выводить офицерские оценки и в этот момент уже можно сколько-то осмысленно только в этот момент можно сколько-то осмысленно работать с формулой ранжирования поскольку пока покуда у вас нету живыми людьми проставленных оценок вот этот запрос и релевантен этому документу и нету определённого механизма который по этим оценкам генерирует некий метрики качества но формулы ранжирования заниматься можно интересно и прикольно но совершенно бесполезно потому что в башке у вас поместится скорее всего ну максимум 10 запросов у меня получим у меня лично помещается вот 5 до 7 начиная с 8 у меня уже как бы она всё сводится и когда ты анализируешь вручную 8 запрос ты уже не помнишь первый практически гарантированно ну вот может быть у вас как бы бошки шире и поэтому все значит будет лучше если рукой дел но тем не менее я гарантирую что на 10 и запросах с выдачей хотя бы по 10 документов вы сломаетесь apple придется все это автоматизировать все рамку мы работали работали работали и как бы наработали массу всякой херне которая помогает вам на разных стадиях всего перечисленного на предыдущем слайде которая опять бодренько убрали в части про индексацию ну с таки низации эту сильно много не придумаешь у нас и так много всяких штук таки не затар чуть не одна из самых сложных частей проекта а вот marfil морфологию немного по улучшили значит прикрутили арабский стример а р это означает arabia да это арабский язык это не аргентинские в аргентине испански прикрутили ли мать yzer взяли небезызвестный проект под названием а вот и наконец-то за интегрировали его словари под понятное дело переписали потому что код там был радость тем не менее основная проекта конечно в словарях примеры в какие примеры случаев в которых со словарем получается сильно лучше чем без словаря они вот масла и дст мир для английского языка по словам бизе бизнес генерирует какое-то анти слово это вообще ни слова не корректно и слова ли мать yzer извините генерирует во-первых и во-вторых во-первых корректную лемму а во-вторых ну различает между словами бизнесе и бизнес или дебильных ошибок не делать кроме того в момент когда ли мать yzer не знает какую то нормальную форму он довольно бодренько угадывает понятное дело что поскольку он угадывает грубо говоря основываясь на окончаниях слов делает наиболее вероятная гипотезы чтобы это такое могло быть он иногда делает интересные ошибки ну например классическая которую в свое время и яндекс сделал и а вот по моему честно говоря не помню делает его до сих пор аут или нет классическая мой любимый пример что вот гюльчатай это конечно же императивная форма глагола гюль читать ангер читал ее всю ночь вот тут классика жанра в обработке текстов вот но если я правильно помню то даже в момент этого эпического файла ну не совсем эпического поскольку слова гель читать он встречается редко и когда можно руками перебрать даже в этот момент он генерирует если я правильно помню пару гипотез то есть он генерирует гипотезу гриль читать но по модель читай тоже оставляет в покое вот но радость том что процент таких ошибок он довольно не велик я тестировал на паре тройке коллекцию таких умеренного размера в несколько гигабайт меня получалось что процент незнакомых слов но он реально маленький там от одного может быть трудно мне зной максимум 5 процентов понятное дело что значит на блок-постах процент будет сильно больше чем на классических значит литературных текстах тем не менее и там и там процент не гигантский теперь значит можно щелкнуть наверное слайдером не нифига надо спец команду подавать верхней this light вот у работает второй кусок слайда как раз про это про несколько форм все предыдущие марфа ля тары обработчики морфология стэн меры этом saunders и проклятый и так далее которые у нас были они все были устроены как mapping один к одному к несчастью берем одно слово на вход выплевывает одно слово на выход но теперь это не так у нас добавился режим соответственно limo toy за рулон и соответственно для английского и немецкого тоже два таких режима которые для по все те словоформы которые соответствуют одной сети нормальные словоформы которые соответствуют ненормальные слова форме но в яндекс помещают вот пример для английского языка собственно на слайде когда слова форму лифт можно значит интерпретировать двумя разными методами в зависимости от контекста в идеале конечно надо смотреть как в контекст делать так называемый worlds and decent игре ещё и понимать что в первом случае лифт это прошлое об этом глагол алиев а во втором ну соответственно это вот просто вот прилагательные левой мы это геморрой а если вы тупо складывать все формы в яндекс то выясняется что индекс растет незначительно буквально процентов на 10 соответственно там буквально процентов на 10 изменяется время индексации время поиска практически не изменяется совсем а все варианты словоформы мы находим и соответственно все что хотим матчем матчем не совсем точно но захватываем мусорок ненужный по лишней которая захватывается как бы такими неоднозначными слова формами результатов по меньшей мере не теряем вот пример для русского языка он как бы обезображен на слайде но его мастерски накрывает видео потому что никто не предупреждал что этот угол будет накрыт видео вот там значит нет вообще ничего не видно для тех кто скачает слайды нет отставить для тех кто не скачает слайды там изображен перстень с полудрагоценным камнем есть в зале специалисты кто нибудь знает что такое кстати поиск обратный индекс специалисты по геологии есть но это кто знает нам как бы как вас чтобы не надули в лавке где к драгоценные камни продают нет никто а вот значит есть минимум один специалист по геологии и это наверно единственный человек в зале который способен по картинке вот там под видео понять что нас перстня обезображен опал это было задумано мощная шутка искать поручик ну как раз вот про неоднозначность словоформ в русском языке поручик что это у вас за перстень стекло или опал поручик краснее это говорит ну сначала стекло потом опал но как бы видео и поэтому шутка не очень получилась спим дальше морфология морфология есть ещё такой момент под названием предобработки предобработки данных в зависимости от бизнес требует вообще бесконечная значит тема можно петь про нее долго я расскажу про один момент который мы вот сделали паузу для которого мы сделали разбить ее доменов и она же разбить ее компаундов значит есть две боевые задачи которые казалось бы разные а решаются совершенно одинаково боевая задача номер 1 нам дали какой-нибудь лориэль в котором как это принято все написали без пробелов но хотелось бы ключевые слова из этого реле все равно достать чтобы ну пустить результаты поиска если у нас ключевое слово извините совпало в целом домене я понимаю у ирель за спамить там как бы написать кучу говна в этом самому реле проблем не составляет но за домен еще и деньги приходится платить поэтому возможно возможно это не очень плохой сигнал ключевое слово в доме и вторая задача которая тоже иногда встает во всяких странных языках типа германского финского и немецкого финского и так далее это задача под названием у нас есть вот такое вот слово фалик сегодняшний день циркуль хенде хох без пробелов хотелось бы его развалить на отдельные куски слова такие называются компаундами и то и другое решается совершенно одинаково нужен частотный словарик нужно спец утилита частотный словарик мы уже сто лет как умеем строить есть там мычко build stops в яндекс atari а утилиту для того чтобы при помощи частотного словарика разваливать вот такие вот простынки без пробелов на отдельные слова они вот как бы есть поскольку к несчастью словарь был сгенерирован по значит нормальным текстом to the men expert extension развалил на два слова именно эксперты exechange они на эксперт секс cinch как хотелось бы но ошибки случаются ещё один момент про постобработку реально синтаксический сахар окна очень удобный и приятный синтаксический сахар а потому что делать его вручную без него но геморрой просто нечеловечески это возможность задавать regexp фильтры для всего для контента который поступает на индексацию и одновременно поступает на поиск с одной стороны казалось бы легко и непринужденно делается снаружи с другой стороны как только начинаешь делать снаружи это выливается там вот такую простыми который этом скрыт дебильные который данные не вытягивает из базы травит на них рик bags по и так далее еще такой же дебильный скрипт который надо в приложении в строго встраивать num утром при помощи директив kirigaya ксп фильтр такие фильтры можно всунуть прям в яндекс ну тут у меня хорошему модельного примеру наверно нет можно придумать что-нибудь типа ну не тяжело стало написать riddex который возьмет любой вид написания телефонного номера и его нормализует просто в тупую в одну значит строчку еще и префикс это телефон припишет и ещё один момент про пред обработку которая опять-таки за счет заботливо потушили это такая штука странная но не очень на самом деле довольно полезное под названием пост морфологические словоформы что это такое изначальная реализация словоформ которая у нас была она как бы задумывалась как такая морфология для бедных морфологии в тот момент не было вообще никакой ну и вот было гипотеза что значит особо отмороженные пользователи могут написать гигантский морфологический словарь сунуть его в файл словоформ и оно реально работала ну то есть она реально рассчитана была там и до сих пор рассчитан на очень большие словари словоформ индексация и поиск не сильно тормозят вот но понятное дело таких отмороженных мало как бы люди хотят как максимум включить там мы чашку морфология равно русский язык в конфиге они словарь на 20 миллионов словоформ писать с одной стороны но с другой стороны те вооруженные люди которые все-таки такие слова формы пишут а главное те значит нормальные люди которые отдельные ошибки с теми ралли матиза тары и так далее хотят чинить они регулярно втыкались значит в проблему под названием словоформы работают даст им мерах или марфой или морфологии или чего еще если мы хотим завопить какое-то слово в языке который для 1 для одного слова 27 склонений может сгенерировать нам блин 27 склонений надо перечислить в этом самом файле слова for ну вот этой проблемы больше нет добавилось концепция поста морфологических словоформ то есть толкин раньше сначала уходил слова формой если уходил то не выходил в морфологию это осталось но есть теперь возможность вот с помощью тильды в начале строчечки сказать что вот этот for a token сначала отправить в морфологию а потом уже базовую форму профильтровать через файл word for ну вот для тех задач которым не надо совершенно безразлично для тех где надо очень удобно спим дальше про качество поиска пункт 2 7 до нормально ранжирование про ранжирование но вот пачка разных штук исправили реализацию б м 25 которая 12 лет назад от бедности и для скорости было сделано так что на самом деле являлось бы им 15 добавили директив куда индексации автоматической длин полей добавили ну канонического реализацию б м 25 переименовали ее как бы n25 я добавили реализацию pn25 тип функции со взвешиванием полей добавили пачку всяких факторов ой отставить факторов все всяких директив для того чтобы разнообразное творить с вычислением idef потому что во первых во вторых во первых у нас она была не то чтобы криво реализовано реализовано определенным значит методом с нормализации так далее который был актуален 12 лет назад сегодня уже не очень актуален а во-вторых собственно в научных работах 2 нет еще расчета и древ и как бы в зависимости того какую научную работу ты открыл естественно тот который в не используется считается единственно правильным вот но как бы у нас нет такой уверенностью что один из них абсолютно кинется на правильный поэтому мы просто делаем мышки переключатель общиной диеты даем пользователю все контролировать следующий кусок на слайде с массой непонятных аббревиатур это новые сигналы ранжирования по на добавляли пачку новых сигналов ранжирования чуть попозже они будут на слайде попытались чуть подробнее объяснить соответственно весь этот фарш с кучей разнообразных циферок правой idef и рассчитываемые разным образом разнообразные сигналы ранжирования это конечно очень интересно но когда это происходит все исключительно внутри поискового сервера пользоваться невозможно надо как-то уметь экспортировать надо как-то уметь работать добавили чтобы под названием пи тит фактор с это такая двоякая отзовем и и так функция которая в контексте ну просто обычной текстовой выдачи через и скверный интерфейс через ebay дает вам ну просто текст который вы можете распарсить вставить на машинное обучение и так далее а в контексте ядре функции вычисляется в адский блок который можно распарсить некими функциями сфинкс get that field фактор с допамин фактор за так далее то есть с одной стороны и с другой стороны с одной стороны это одновременно интерфейс для экспорта всех сигналов ранжирования а с другой стороны это интерфейс для эксплуатации этих сигналов ранжирования в том случае если вы написали настолько сложную функцию ранжирование что она не влазит в expression ranker надо ее написать надо ее засунуть в девку иначе считается дико медленно ну вот значит простой пример во что это выливается для обычного человека много лет подряд ранжирование в дефолтном в режиме оно выглядело примерно вот так то есть как-то ранжирует чё то там считает если обратить внимание на строчки начиная с 4 и вниз включительно видно что вот эти вот vesa 2642 которые получены смесью фактора lcs про совпадения фразы двоечка и фактора статистического они одинаковая статистический фактор б м 25 который у нас не б м 25 обоим 15 он ну для всех документах одинаковые что немного неправильно вот вот эту мелкую пакость можно починить и возможно несколько улучшить ранжирование я думаю возможно потому что экспериментов никаких про не производил у меня никаких там клёвых отчетов о том что там энди сиджей вырос на 3 процента нет тем не менее вот эту вот проблему если она для вас проблемы можно легко исправить теперь можно включить значит в два удара буквально в две строчки можно включить директиву индекс филдинг поставить ее в единичку после чего станет можно написать вот такой вот немножко усложненный фактор немножко усложненный ranker который комбинирует ну честным образом рассчитанный вариант б м 25 которой барабанная дробь и принимает все таки в учет наконец длинный полей видно что visas стали скажем так поразнообразнее видно что порядок этих как их порядок матчей изменился ну и в некоторых случаях я думаю это дает просто без затей сразу улучшением качества ранжирования мелочь а приятно это вот такой простой шаг который можно сделать понятное дело что после этого простого шага в ходе борьбы с качественным можно сделать еще миллион шагов сложных например вот в этот ранки равно экспорт можно написать не два слагаемых а 15 после этого можно выяснить что значит оно вот так все-таки подтормаживает и осмысленность вынести этому девку после этого можно выяснить что значит еще круче получается не рукой под ним подгонять коэффициенты для наших 15 слагаемых а экспорт нуть вот эти вот сигналы ранжирования засунуть их в машинное обучение у нас получится вот такая вот гигантская авто генеральная функция ранжирования но она даёт ещё лучшее качество вот теперь сфинкс все это дает значит доблестно делать начиная с версии 21 по моему в какой-то мере потому что пойдет factors появился там и ну соответственно начиная с версии 2 2 еще лучше еще быстрее больше сигналов ранжирования и более быстрый интерфейс куда их функциях я обещал не может рассказать про вот эти вот подсвеченные желтеньким факторы мин гипс экзо the orders так далее кратко говоря это разнообразные забавные факторы ранжирования которые учитывают близость слов вплоть до версии 2 1 включительно у нас был только один такой фактор lcs который считал в точности следующую штуку сколько слов запроса в точном порядке совпало с документом причем без учета дырок ну то есть если совпало первое третье пятое седьмое слово то фактор равнялся 4 и ни на что не смотрел гаденыш не на дырке не смотрел ни на относительный вес слов не смотрел ни на что не смотрел просто тупо как бы считал как положено ну как известно там баранов по головам считают академию наук по членам вот он ключевые слова тоже считал по ключевым словам ну это как бы надоело добавили пару еще факторов интересные есть lcc с это тоже самое но все-таки без учета дырок наконец то есть если четыре слова подряд совпало без дырок то lcc с будет 4 и lcs будет 4 если совпало 1 3 5 7 слова запроса именно в таком порядке а между ними какая-то гадость то lcs будет по-прежнему 4 lcc с будет единица потому что у нас нету последовательности из двух слов запросов длиннее чем единица в документе в lcs от тоже самое ну wlc с но еще вдобавок с нормировка янао и df то есть учитывается отдельный вес слов ну и наконец а то цвета и веры что упал клоун с некий эзотерический фактор который грубо говоря растет чем боль растет в тех случаях чем больше пар чем чем больше пар чем более редких слов в документе найдено идеальное в совпадении миллионов раз максимизирует этот фактор чем дальше слова тем хуже чем в 1 и в случае если у нас в одном документе одна пара совпало это слов в другом документе другая пар совпало слов ну вот lcs такую ситуацию не различал он равнялся двоечки в обоих случаях а tc различает поскольку смотрит на и геев на грубо говоря метрику редкости слова вкратце вот добавилось пачка факторов которая позвали которая смотрит не только на статистике слов а еще и на их близость взаимную делает это существенно более интеллектуально чем все что было до этого все добавилось версии 2 2 можно как бы прикольно играться вот мои на кой черт все это над это надо для того чтобы строить элитный поиск с элитным ранжирование процесс вкратце выглядят вот так то есть вот этих factors он вам выплевывает кучу циферок сигналы ранжирования вам к несчастью в добавок к этим циферкам который мы вам даём потребуется еще и масса других циферок которые придется сделать значит плохая новость самостоятельно хорошая новость несколько сотен или даже тысяч запросов можно оценить за время порядка единиц дней при помощи этих циферок и данных асессорская оценка с арских оценок но можно значит все это грубо говоря запилить в машинное обучение засол не после этого факты получающегося формулу ранжирования в сфинкс можно не записывать можно отход к образом ну грубо говоря подгонять коэффициентов формуле ранжирования это вот такие появились интересные возможности для тех кому интересно значит очень сильно загнаться про ранжирование для прикладных математиков развил раз сразу этот как его раздолье просто гигантская так время медленно и неуклонно кончается у меня второй пункт только кончился из семи надо чистить третий пункт код кто догадается про что третий пункт он очевидно про моду мода приходит и уходит раньше было модно считать сейчас не очень соответственно раньше было модно как бы вот кто знает вот этого парня никто нет все знают вот этого парня за то вот и сквер стал немного не будет новый сквер набирает обороты поднимает голову вот в пересменки как наверное расцвет и сквере он был в пересменки с 2003 по 2007 года в 2003 году конечно же эдгар под скончался и вот некому стало палкой бить и конечно же в 2007 году придумали манга деби сразу я думаю это связано и явление вот так и эдак новый сквер поднимается собака голову это как бы модно приходится соответствовать вот мы долго думали как прикрутить ладно в руне долгом и думали о том как прикрутить псевдо поддержку новые склеили к сфинксу который изначально все-таки там сто лет назад рассчитывал с навигационной базы данных придумали давайте сделаем для начала поддержку атрибутов от жетончик авто есть давайте сделаем возможность запиливать документы джисона вс киева к нам в сервер ну сказано сделано не сразу конечно в 21 мы сделали то по частичную поддержку в которой можно было ограниченный скажем так ограниченное подмножество документов класть в атрибут в буквально кизельгур пачечки в 22 мы эту поддержку довели ну как бы до победного полного конца теперь собственно абсолютно любой документ в том числе массив высоко уровня не отстоять низкоуровневый массив первого уровня можно положить в джейсон документ внутри она хранится как бы вот тут написано умеренно эффективно там blu масочка для ключиков чтобы быстро-быстро откидывать документы в которых того или иного ключа нет массивы хранятся не так не как в php php это наверное мой идеал на предмет того как надо хранить массивы потому что как конечно же все знают php php нет массивов там есть hash и там у каждого значения колющий когда вы делаете массив на 10 элементов то там значит 10 ключей целочисленных при этом внутри целочисленных ключей есть магические значения в итоге если ты кладешь там число там два в 32 минус единица в качестве ключа в пах и пышный массив она супа меняет тип числа на строку вот это мой идеал и я конечно сделал совершенно не так у нас сама слава богу сделано нормально пар серджи xone-чика детектив детектив содержимое анализирует содержимое массива детектив минимальный тип который можно него тянуть и например если его можно про складировать в четыре байта назначение если видно что там исключительно int и мы его так и сохраним если видно что надо по восемь байт моего так и сохраним если видно что в дабл помещается сохраним так если какая-то напихала массив совершенно разнообразных документов чисел строк из так далее но мы как бы крикнем но вот в этом случае сохраним уже ассоциативный массив тут делать нечего но умеренный эффективный формат пишу умеренный эффективный потому что как бы как обычно значит сделал сделали первую версию вторую сразу есть идея как улучшать дальше могут будем в следующих версиях как собственно пользоваться ну сконфигурировать атрибут типа реляционный директив коми либо я сквозь эти tear джейсон либо карте эти tear джейсон и класть туда джисон документы есть еще двое полезные директив ки которые автоматически конвертируют числа и автоматически конвертирует приводят в нижний регистр именно ключи автоматически конвертировать числа удобно потому что некоторые уродские генераторы g сонов норовят число 1 2 3 4 5 не по стандарту обернуть кавычками когда вам пришел такой уродки джейсон то вот авто конверсия реально спасает что можно значит делать в этом самом jison чеки ну довольно много всякого практически все понятное дело работает просто там выборка по ключу причем креативная выборка по ключу там с произвольными под индексами и так далее он как в первой строке g точка b c d e f она тоже работает работает vr ордер buy грубое все это живет работает insert в real time индекса естественно и даже работает вот самое наверное большое достижение из недавних это вот предпоследняя строчка select a и d и не и так далее засчитывать в слух и это не буду вот такая вот забавная функция синтаксисом неуловимо напоминающим питание очки для того чтобы работать с массивами в g sony и скалярные значения можно обновлять не скалярные значения обновлять нельзя ну то есть вот можно джейсон документ к нам положите довольно таки и бодренько и манипулировать почти все что угодно можно с ним делать что пока нельзя вот в 21 нельзя как бы положить документ отличающиеся от свалки ключ-значение для этого нужно пользоваться 22 есть дебильное внутренние ограничение архитектурное что в яндекс в данный момент у нас влазит не более 4 х 4 гигабайт строп все сразу понимают откуда оно растет ага ну пока дебильное внутренняя ограничение есть когда-нибудь мы его уберем пока не убрали придется шортить вручную и последний момент это то что апдейт которая у нас реализован поверх jison щиков он патчит документы патч от не заменяет сэм и все то же самое внутреннее ограничение из того же грубо говоря куска кода который хранит все строчки в блоге с яндекс 32-битными индексами из того же куска кода растет ограничения что просто так стереть там строку произвольной длины вставить новые мы не можем это большой кусок кода которая надо радикально переписать под они переписали почтить его внутри мы можем а заменить не можем а следовательно новый ключ добавить в джейсон не можем новые этот как его звать убрать существующей ключ ну тоже не очень и так далее но в случае с real-time индексами никто не отменял риплейс который по существу старую версию все строчки хери ты новую стою версию заставляет если вы сделаете replace a real-time яндексе вместо апдейта то естественно она и на джейсон повлияет тоже работать все будет про скорость склад jison это наверное важна скорость этого дела всегда волнует скорость может отличаться от 18 процентов по сравнению с традиционным атрибутом до 18 блин раз самый наверное наглядные один из самых радикальных примеров он наслоить и дело в том что по умолчанию мы же не имеем права интерпретировать значение внутри этого джисона как что-нибудь кроме строке не имеем и все мы не знаем что там лежит и в тот момент когда мы вот например начинаем ловко конвертировать я числа которые лежат в джейсоне в стропу и по этим строкам сортировать наступают тормозов 18 1 м и слайд соответственно ну если знаешь тип-топ и маги движку это может очень сильно значит изменить производительность в тот момент когда сравниваем сравнимое ну то есть было сравниваем сортировку по числу с сортировкой по числу они генерацию миллиона строк и сортировку по строке но вот в этот момент производительность падает на удивление не сильно 20 процентов за возможность как бы класть джейсон of ski и документы в яндекс я считаю это совсем немного и приятно спим дальше про более динамические индексы attache alter оптималс вальтер этот каллум добавили он работает он работает довольно быстро потому что лапать это естественно не весь индекс на лету скажем так перри собирается тот же мотор где мы храним атрибуты доделали от touch изначально attach работал только для конверсии скажем так он изначально attach требовал того чтобы целевой индекс в которой вы впитываете большой пакет данных проиндексированных при помощи дисковые индекса вот мы требовали чтобы индекс был пустым этого требование больше нет и можно делать теперь прикольную штуку как бы вы в штатном режиме жизни льете льете помаленечку данные в real time индексы вам внезапно а тут вам внезапно пришёл какой-то пакет новых данных на там грубо говоря 30 миллионов строк и понятно что в режиме по одной записи за раз он будет индексироваться ближайшие трое суток на самом деле как бы цифры не такие я думаю тридцать миллионов строк несчастных будут индексироваться существенно более быстрее трех суток но тем не менее вот хочется быстрее для того можно теперь быстрее совсем просто можно состроить временный дисковый индекс который быстро быстро проиндексировать дисковые индексы ну как бы батч индексатор работает как батч индексатор быстро как пулемет после чего этот самый батч индекс в мер жить грубо говоря в real time индекс attach вне котором смысле работает как мертв между real-time индексом индексом dice кого можно состроить сравнительно быстро построить сравнительно быстро индекс дисковый и при помощи аточа вкатить эти данные в существующей real-time индекс они как бы дописываются в конец перекрывают те данные которые там уже лежали и понятное дело фрагментацию никто не отменял в real time индексах когда-то надо было сделать optima из вот мы его сделали работает в фоновом треде есть какие-то директивы для того чтобы контролировать размера нагрузки которая этот самый фоновый трек оптимизации но наливает на сервер можно количество и об софтом ограничить и так далее вот мелочь а приятно общее направление говорил и повторю еще раз вот динамичность становится более динамичной потихоньку стремимся сделать так чтобы индексами можно было абсолютно ну динамично манипулировать на лету спим дальше про 3 спец функции понятное дело что всяких странных эзотерических спиц функций в списке 50 свечей плюс 40 свечей можно нарыть довольно много я сюда решил вывести 3 одна занятная функция за которой я считаю имеется у которой я считаю есть определенные потенциала которая сейчас не используется ха ха совсем это механизм табличных функций в двигло я приделал механизм который позволяет взять result set сделать с ним что угодно и отдать результат пользователю что угодно означает как угодно переставить строки как угодно переставить колонки полностью поменять схему resulted а все что угодно некая функция которая берет таблицу а точнее резал сет на вход и выдает обработанный переделанный резал сет на выход вот но к несчастью она значит в данный момент в дебри xi + + кода поэтому только одна только только одна встроенная функция есть которая пользуется обобщенным механизмом надо то ли скрипты добавлять то ли хотя бы у дев интерфейс будем делать 2 сильно более приятный для нормального человека функция но это вот улучшение группировки мы добавили функцию мульти группировки скажем так не в том смысле что по нескольким ключам на эту это тоже сделали а в том смысле что в отличие от из куриных нормальных баз данных мы теперь даем возможность возвращать от 1 до n записей на каждую группу при грубой вот давно просили мы наконец сделали вот ну и вдобавок добавили кстати хэвен все это появилось в по моему 22 ну то есть group in buy появился по-моему в 21 а вот heaven появился совсем недавно в 22 соответственно полное значит на фаршированная всем группировка теперь выглядит вот так можно сделать group in buy мы можно сделать можно вытащить от одного но если там больше вообще нет да там 10 грубо говоря строку по каждой группе группировку можно сделать по нескольким ключам внутри группы можно задать порядок теперь наконец стало ясно зачем там именно порядок задавать они именно в таком синтаксисе а не в каком-то там не какое-то условие не минимизации и поверх всего этого поверх всего этого после группировки можно применить хэвен и тем самым ну отфильтровать resulted по агрегат ную функциям несмотря на все эти значит с лари фарша все это до сих пор работает что меня не перестает удивлять вот выглядят примерно вот так если обратить внимание тут две группы с разными значениями ключей не очень хорошо что там ключи различаются в одном предпоследнем знаки но видно что в отличие от нормальной группировки которая дала бы 4 уникальных значение чинно лойди здесь у нас по две строчки с двумя значениями чана лойди мелочь приятный ну еще одна такая занятная функция которую рекламируя поскольку она как бы как это сказать-то регулярную полезная но мало кто знает это штука про скажем так предсказанное время исполнения запроса сделали ряд внутренних счетчиков сделали возможность моделировать время исполнения запроса при помощи этих внутренних счетчиков и это нам дает две вещи первое ради чего делали стабильную терме нацию запроса они так что мы ограничиваем время исполнения 100 миль и секундами процессора атом то ли пять матчей нашли за эти стали миллисекунд то ли 125 непонятно человек нажал и в 5 у него резал цвет поменялся человек опять нажал f 55 ре зация поменялся ну не клево вот если хочется чтобы если хочется чтобы поисковый запрос был ограничен каким-то вменяемым количеством ресурсов с одной стороны но при этом у человека от нажатия f5 выдачи не менялась с другой стороны вот макс predict a time это как бы ваш друг плюс внезапно сделав его для того чтобы отсекать время исполнения запросов поняли что его еще можно использовать для accounting ресурсов ну вот реально можно потому что мы считаем счетчики которые как-то вот коррелированы с объемом работы которые сервер проделал для собственно обработки запроса вот кое кто там сзади ходят волнуется и пытается отомстить ресурса я думаю про инструменти рование вот что такое инструменте рование это не совсем красиво и значит слово как калинин менеджер которая как бы вводится для рекламы чтобы все думали что к вам вот такая вот придет уборщица а на самом деле как обычно но это слово красивая но в нем немножко больше смысла чем просто реклама это не только инструменте рование это про исследования скажем так потрохов программы все подряд не только профилирования а еще масса всякого разнообразные счетчики логе возможность посмотреть что происходит внутри которая включает в себя возможность посмотреть на производительность но производительность не ограничивается добавили пачку штук ну добавили сет профайлинг равна единица чтобы все а скажем так чтобы в боевом режиме по умолчанию естественно выключены чтобы в боевом режиме все дополнительные инструменты инструменте ру и мои штуки не тормозили боевой build поначалу казалось что делаю это зря впоследствии выяснилось что делаю это не зря потому что как бы вот для большей части запросов которые исполняются там разумное время не удается углядеть и вверх ай-дат профайлер of но для самых уродских запросов которые там грубо говоря по минуте исполняется вот для них как раз как я сняла север хотят профайлер of существенные типа в бою запрос исполняется секунду с провайдером там сих 1.0 одну секунду этого так было на тестах естественно когда речь зашла когда дело дошло до боевого использования выяснилось что бывают например запросы которые исполняются 45 секунд а с провайдером две минуты поэтому все-таки решение не включать профайлинг всегда оказалось правильным ура ура profile выглядят примерно вот так понятное дело разглядеть тут ничего не возможно я немного за зум люси ну вот надо его включить надо жахнуть какой-то запрос надо жахнуть неожиданную команду шоу profile по-моему в москве ли она собственно точно такая же в тот момент когда можно мозг не греть пользователю и украсть в чистую мой спальный оператор мы это естественно мы это естественно дела и мы крадем в тот момент когда нужны собственно и расширение делаем их ну вот видно что на разные скажем так стадий вычисления запроса можно посмотреть посмотреть сколько оно жрало времени в секундах и сколько это было процентов от общего времени исполнения запроса мелочь приятного удается всякая диагностировать некоторые запросы внутри устроены совершенно не так как кажется снаружи в основном это относится к запросам которые расширяются за счет всяких wild card of exp аршинов и прочих радостей жизни для того чтобы смотреть что происходит на самом деле внутри таких запросов сделали штук ушел план которая показывает вот такой вот как его планчик исполнение запросов хочу приделать сюда статистику чтобы еще было понятно одновременно насколько часто и вот это слова но это сопряжено с легкими техническими трудностями внутри ну когда-нибудь приделаем добавили штуку для того чтобы смотреть на статус того или иного индекса понимать сколько в нем документов сколько он памяти живет спокойно диски живет и так далее ну мелочь а приятно для того чтобы смотреть и понимать сколько памяти сервер сожрал например довольно удобно и добавили всякие счетчики вот эти вот счетчики про как это сказать-то счетчики об считывающие запрос ну добавили в шоу мета чтоб можно было хоть как-то их посмотреть готовясь к докладу я осознал что название абсолютно уродские их надо переименовать потому что как бы они не отвечают нормам госта вот дело в том что prediction fitch от ля ля ля это оказывается локальные счетчики а просто фича ты так далее это оказывается распределенные счетчики то есть если у вас распределенные индекс то значение расходятся и можно посмотреть отдельно локальные щечки отдельно распределенные команду отдал переименуем последний седьмой пункт как бы из картинки понятно что значит он про оптимизации но понятно что оптимизации иногда приходится делать как бы вот-вот ним немного на коленке некоторые из них не на коленке некоторые из них вполне приличным оптимизации много разных интересных если совсем кратко стал вставьте новый билд если вам повезло запросы начнут летать если не повезло ну соответственно как бы у вас все таки вот второй случай вкратце про оптимизации ровно две из них надо включать все остальные автоматически песни которые надо в кавычках включать это вот skip листы и биграмм и что такое skip листы начиная по моему с версии 21 до начиная с версии 21 may наконец-то научились при обработке запросов с маленьким редким словом из гигантским частным словом по списку документов для частого слова скакать причем скакать достаточно эффективно реально третий подход делала в молодости два подхода все разы оказы оказывалось только хуже а тут наконец нормально написал настолько нормально что я честно говоря собирался эту штуку сделать под опции потому что она делалась для как раз того чтобы в худшем случае когда запрос с чудовищно частым словом и соответственно чудовищно редким ну хотелось этот запрос сильно оптимизировать он оптимизируется на синтетических тестах которые на самом деле по статистике с определенного продакшна снято там до 100 раз до 300 раз там чудовищной оптимизации но как ни странно в среднем случай на моей сказали скажем так и ежеминутной тестовой коллекции выяснилось что куб с тоже растет без затеи в 1 7 раза на 70 процентов то есть там где она миллионные коллекции я видел 400 запрос в секунду с ядра я начал видеть 700 запросов в секунду с кедра вот мелочь приятно поэтому фича в итоге не пошла ни под какие опции она вот безусловным образом включена достаточно просто взять новый билд и зари билде яндекс либо если у вас индекс настолько гигантские что rebuilding будет чуть менее чем два года то есть опция то ли в яндексе ритуале в яндекс tool скорее всего в яндекс ту минус минус build skips которая позволяет индекс проапгрейдить со старого формата без keep листов на новый формат соски please to me с ней мог бы быть определенные сложности и пляски с версиями но по идее должна работать и отдельной оптимизация для тех случаев когда у вас очень много поисков по фразам с частыми словами при этом от этих частых слов вы не можете оказаться но вот оптимизация под названием биграмм и которая складирует пары слов в яндекс они только единицы слов но и позволяет поиск по фразам люто бешено разогнать люто бешено это опять и в десятке местами даже сотни раз это две оптимизации как для которых надо хоть что то сделать чтобы они включились в случае с by граммами ну добавить 2 директивы в яндексе перестроить индекс в случае соски please to me просто проапгрейдить и либо перестроить либо проапгрейдить индекс со всеми остальными оптимизация my как бы все приятнее ничего не надо делать оптимизму ли такие знатоки не за тартак side effects стала местами существенно быстрее индексация и сниппеты оптимизировали фильтрацию добавили несколько спец случаев для наиболее частых видов фильтров ну вот насколько стала быстрее не помню но скажем так оптимизации по одному проценту я стараюсь не лить чтобы кот не загрязнять оптимизму ли обработку запросов с гигантскими схемами гигантскими это сотни и буквально тысячи атрибутов до 3000 по моему у нас самая дикая схема которую мы видели в бою вот на дикой схеме с тремя тысячами атрибутов стала быстрее до 3 раз но эти оптимизации дали смешное эффекту даже на крохотных spies схемах она слегка быстрее даже на совсем крохотной схеме можно увидеть там ускорение на 2 процента за счет оптимизации она больших схемах оптимизация прям взлет ракеты в версии 2 2 стала еще быстрее доступ жетончиком которые сделали в 21 там два ключевых интересных значит момента оптимизация про доступ ключ у по имени но напрашивалась сделать интересный момент начиная с 22 укладываем в яндексе jison значения по порядку и дышит это дойдёт чудовищный эффект просто без затей от того что переставили данные в правильном порядке херак 20 процентов производительность мелочь а приятно долл бы переписывали наконец-то переписались не пит и они теперь сильно быстрее жрут сильно меньше памяти насколько сильно вот видно на слайде там где была 970 то есть 30 раз от размера документа стало правильно половину от размера документа почему я делю 50 ма 32 и получаю половину это не специальная военная математика это как бы здравый смысл из этих 50-ти мегабайтов 32 живет сам документы а сниппеты жрут но еще 18 то есть примерно половину вот и наконец-то стал быстрее умнее точнее gea de ст вот добавили к нему мышки чтобы наконец-то указывать единицы измерения не только в радианах богом проклятых которые являются ошибкой молодости а еще там в градусах чем угодно еще и соответственно единицы измерения длины тоже там в милях футах километрах и так далее указывать и добавили и сделали его дефолтным метод раньше был метод небезызвестного товарищах аверсе на который вообще не товарища некая формула полу синусов который был умеренно точный но тормозной сделали значит адаб так называемый адаптивный метод который в себе собирает то ли пять то ли 7 разных фокусов про которые могу водным самым интересует самым стойким рассказать в кулуарах общий эффект от этих пяти или семи разных методов и фокусов собранных воедино такой что я диск мало того что работает всегда быстрее он еще сказать его точнее стал ну вот но как следствие результаты поменялись поэтому старый метод тоже доступен если там неохота чтобы ничего не поменялось надо вот метод равно х versin включить и будет счастье вот у меня есть 8 секретный пункт под названием а что еще понятное дело что каждый из этих пунктов можно отдельно обсуждать там полгода ну вот надеюсь читать имеют все поиск по маске кое-какие гиа функции поезд сложенные select и там оператор за у нс пантограф анк от insert и теперь теоретически без задержки но нам по меньшей мере на тестах не удалось налить достаточно загрузки нагрузки чтобы insert все-таки call он встал и это не весь очень блок это как бы основные скажем так хайлайты не знаю как по-русски сказать через блок он побольше но фичи которая в нем они вот как бы им еще меньше итоге ну вот примерно вот такие вот чуть обсудили новости 2013 года этот тупо ключевые слова из этой же самой презентации это не дополнительные слова ключевые слова еще из блога это отсюда много разных штук мы за это так вот доделали кое-что сделали праха его ил ability про качество про оптимизации процесса продажи сончик альтера тоже вставки или оля 3 рубля подробнее ну как бы нападайте на меня в кулуарах я до остатка дня скорее всего тут либо приходите минуту рекламы за которую меня нет в кои веки не выгонят потому что это реклама самого хайло да и мастер-классы который будет послезавтра вот если это если хотите подробно если хотите как бы дорого ну коротко тут надо по саморекламой как бы заняться и порекомендовать продать вам консультации вот как то так это в принципе все вот андрей спасибо коллеги к сожалению время вышло знать традиция такая что в этих случаев дают задать там два вопроса за 3 минуты а потом окей два вопроса или три вопроса за две минуты но уже три но две минуты меня очень быстро сбегаем сильно индекс вырос что прости от биграмм сильный индекс растет в зависимости от того сколько б гранта на пихаешь в яндекс понятное дело что если каждую пару слов реальных данных а на реальных данных реальной жизни у нас три режима в зависимости от того какой ты включишь он либо в два раза распухнет либо распухнет на 20-30 процентов я рекомендую топовые 35 слова положить в биграмм и в этих случаях рост индекса примерно 15-30 процентов и понятное дело это мёртвые данные ну то есть если ты их не используешь ты их не используешь они тебя не мешают если ты их используешь они дико ускоряют поисков раз давайте еще один вопрос ну транг мы вот этими выходными дописали чинить лоб наконец до полировали скажем так поэтому трамп в течение этой недели выложиться в релиз уже 22 и да все это есть в ложные select а если чего немного кастрированные потому что они грубо говоря грубо говоря для того чтобы пересортировать resort сеты более не для чего но синтаксически они есть группа и нба и естественно тоже есть да короче все в tranque в транг на этой неделе пойдет в product продакшне он давно стоит пойдет в released on 2 опять я а вот скажи пожалуйста табло на ранжирование реальные пользователи не консультанты настраивают у них получается до невероятно но факт спасибо андрей"
}