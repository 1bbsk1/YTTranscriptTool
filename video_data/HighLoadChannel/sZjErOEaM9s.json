{
  "video_id": "sZjErOEaM9s",
  "channel": "HighLoadChannel",
  "title": "Обзор решений для PostgreSQL High Availability / Алексей Лесовский (Data Egret)",
  "views": 10174,
  "duration": 3117,
  "published": "2020-04-27T13:27:36-07:00",
  "text": "всем привет всем доброе утро меня зовут алексей лисовский я рад вас всех видеть с утра потому что с утра обычно мало народу приходит но здесь полный зал я смотрю немного слов обо мне я долгое время работал системным администратором веб-разработки и у меня очень большой опыт работы с линуксом но какое-то время я начал работать с прогрессом и в какой-то момент работа с пользовались а у меня начала заниматься основное время и сейчас 2014 года по нынешнее время я уже под грецку или db и работаю с посольством каждый день и мой доклад будет посвящен тому что же выбрать для high availability для паз gresso в 2019 году почему такая тема а потому что мир меняется раньше были железные сервера сейчас у нас облака и а базы данных это всегда такая медленно движущаяся штука но тем ни менее базы данных тоже должны меняться и в 2012 году уже мы должны иметь какие-то средства какие-то решения которые дают нам high visibility и нам надо с этим как-то жить и что-то выбирать чего-нибудь в докладе в докладе не будет инструкции по установке потому что это можно найти в документации какие-то базовые вещи можно всё там посмотреть найти запустить и использовать и не будет всяких инструкцией по установке в инструкции по использованию и различных конфигов потому что тоже легко гуглиться там забиваем название инструмента конфигах simples у нас сразу два листа со всякими примерами и в этом докладе я буду рассказывать про high availability из моей точки зрения высокая доступность это такое такое состояние сервиса которая позволяет его переживать отказ узлом до при этом не прерывая работу и доступность сервиса и при этом в способность восстанавливать отказавшей узлы и чем быстрее тем лучше если мы говорим про базу данных он где-то в идеале хочется иметь какой-то multimaster чтобы мы могли писать несколько узлов одновременно чтобы автоматически разрулились какие-то конфликты при этом чтобы наши мастера были в разных дата-центрах конечно же и всегда хочется иметь низкие задержки особенно для уилки при нагрузке ну и конечно же хочется чтобы вся вот эта вот ручная работа связанная с переключением узлов в балансировке восстановление узлов чтобы это все работало где-то под капотом чтобы у нас была какая-то кнопка а лучше и без кнопки чтобы это все автоматически работала и конечный администратор этого ничего не знала хочется примерно чего-то такого но на деле мы имеем что имеющие muse тема multimaster если он есть то он имеет весьма ограниченное применение весьма ограниченное количество юз кейсов и его просто нельзя использовать во всех инсталляциях которых хотелось бы и имеем только репликацию в которой запись осуществляется в мастер в единую точку отказа скажем так реплики используются только для масштабирования чтения это классический сценарий использования подвеса и при этом если мы хотим как-то управлять всем этим кластером у нас масса ручной работы этот добавление новых нот это какая-то работа связана с переключением роли мастера между разными узлами все это какие-то скрипты какие-то инструменты и это как правило ручная работа и мы приходим тому что все это нужно регулярно проверять потому что если инструментом не пользовались полгода не факт что мы когда начнем пользу сон сработает как хочется и последнее следствие для работы со всем этим нужна экспертиза нужно не только знать адрес у нужно еще и знать всякие сетевые протоколы как они устроены как они работают как вообще в целом сеть работает да то есть но нужно быть подкованным сразу в нескольких областях если мы зайдем на подрисовываю вики открой там пару страниц связанные с ability to мы увидим несколько инструментов которые предлагаются там на данный момент первый вариант это букардо с ним можно даже делать multimaster и но сам по себе букардо он морально устарел потому что он использует триггерные репликации внутри себя под капотом и в подгрести уже реализован эти вещи которые достигались букардо на своем этапе развития то есть можно реплицировать не только отдельные солнцем и можно реплицировать уже отдельные наборы таблиц стилей таблицы юз кейсы есть для букардо но как говорится они встречаются редко и я на самом деле практически букардо в живом виде не встречал только в лабораторных установках pg пул эту штуку часто можно слышать гораздо чаще чем букардо но когда бы я не сталкиваться с пополам всегда получается что мы имеем какую-то просадку производительности от десяти до двадцати процентов потому что все клиентские подключения они идут через pg пул и на этом теряется время light если наших запросов и сам по себе pulling впг пули он не совсем оптимальный а если сравнивать с другими решениями типа pg балансира упа такая конце концепция установить все соединения к по адресу даже если они не нужны но как бы не очень оптимальное использование ресурсов ну и сам по себе попу довольно хрупкий я лично сталкивался со всякими неприятными ситуациями когда из пула моды просто выбрасываются ты смотришь пологом и что привело к инциденту непонятно другой вариант который есть в википедии кипарисовой это после секса после секса это такие монстры многокомпонентные в которых есть очень много разных компонентов тип odata ноды координаторы менеджер транзакции и эти штуки подходят если у вас данных очень много и они не влазят на отдельные хост вы хотите как-то раз родиться но эти штуки они довольно сложны в эксплуатации вы расстроили после секса excel получили кластер но помимо этого кластера вам еще нужно каждую ноту подпереть своей репликой и получается такая развесистая топология и никакой автоматики там в общем то не предусмотрено нужно так же как и обычный postgres администрировать и отслеживать все события которые там происходят связанные с падением not но даже если нам какие-то решения не подходят вы всегда можем на велосипеде свой мы можем взять какие-то баш скрипты напилить свою логику обернуть это в анси был и взять существующий компоненты типах a proxy keep-alive и на них уже на вертеть свою логику и получить хороший кастомизируемый продукт который нужно поддерживать и вот эта поддержка нас зачастую выливается довольно такие интересные кейсы когда нужно что то сделать запустить принято лидировать переключить и она ведёт себя не так как хотелось бы потому что из сменились версии баша каких-то еще там системных пакетов и перестает работать самый неожиданный момент очень неприятно что получается по итогу если мы берем какие-то старые инструменты которые перечислены у нас на вики по адресу то они как правило не совсем гибкие с ними очень тяжело они придут предлагают ограниченный кейс каких-то решений они плохо масштабируются и ими довольно сложно управлять ручная работа никуда не девается как правило что есть на данный момент учитывая что технологии развиваются и уровень абстракции связанных с управлением он смещается от железо к облаку и вот идет движение в облака они как бы говорят нам что они даже не говорят они дают нам возможность делать все быстро нам не нужно ждать заказы серверов мы можем заправить они единственны за пару кликов мыши за пару нажатий команд в консоли мы можем заде плавать приложение тоже довольно быстро то есть continues in ты грешен континиус delivery они позволяют нам закомитить код и этот код у нас уже протестируете разольется нас тренинги и все это сделается довольно быстро и вот это вот быстро она как бы говорит нам что с базами данных тоже нужно быстро и вот эти вот вызовы и они приводят тому что появляются новые продукты и сейчас есть несколько продуктов таких как хлеб мгр патроне столом пав и pg failover коротко про них репом gr сделан был 10 лет назад 9 лет назад 2010 году и сделала его компания second квадрант это компания вообще она работает честно спас крисом у них очень большая экспертиза поэтому они давным-давно озаботились этим вопросом и придумали реп mgr который был сначала написан на питоне потом они переписали его носим основная его задача это управление кластером да то есть мы можем уже управлять кластером с помощью репом г.р. следующий продукт патроне он гораздо моложе ему всего четыре года и патроне он придумал компании zalando это ритейлер одежды в европе написанным на питоне и его основная задача также управление кластером следующий инструмент это с полом он также ровесник патроне написан 2015 году ему 4 года компания sorento об я честно говоря не знаю что это за компания я знаю только ее продукт столом с самой компании не знаком но сам стал он написан нога ланге и его основная задача также управления кластером два оставшихся инструмента они обеспечивают только авто файла веры и они не предлагают управления кластером то есть вов он изначально построен на компонентах pacemaker а и к росинка и предоставляет только авто failover задачи управления кластер а остаются нерешенными и они остаются в наследство администратору то же самое с pdf to fail озером это довольно новая штука она появилась в этом месяце в начале мая я увидел ее релиз а написано компании сайту с дата которые тоже их деятельность ориентирована на пол gris они работают только с посольством предоставляют облачные пост для кого ночного хранения но недавно их купили microsoft и вот эта штука pg failover это по сути extension в подписи то есть он только предоставляет он также авто failover без каких-либо функций авто управление и мой доклад postgres quelle high availability он как раз таки рассматривает управление кластером и задачи управления высокой доступности как раз таки через контекст управления кластером если брать этого внимания то два последних инструмента у нас отваливаются и мы их рассматривать не будем потому что они по сути не предоставляют нам удобных инструментов для управления кластером нет возможности добавлять ноды обеспечивать как-то подключения старых узлов которые вышли из строя в качестве реплик и вот такие функции которые они в повседневной повседневной работе они просто необходимы поэтому сравнивать будем три инструмента и критерии сравнения рассмотрим архитектуры какие варианты есть установки этих решений потому что как правило база данных у нас кластер уже есть и нам нужно high availability как-то вот имплементировать существующие базу данных ну и управления кластером и само по себе хавела 9 и первый пункт это обзор архитектур любая архитектура любого средства ну инструменты для хавела бельке она под подразумевает что мы должны как-то нивелировать те угрозы с которыми можем столкнуться в процессе эксплуатации то есть у нас могут возникнуть сплит brain и кто сталкивался со спреями кто успешно решал проблемы возникшие при спреду рейнах согласование обратные данных это довольно сложная задача и она ложится как правило на разработчиков не на администраторов а сам простой вариант конечно же восстановиться из бэкапов но не суть поэтому архитектура должна как бы нивелировать угрозу сплит брейна да и другая угроза это когда узлы выходят из строя наш кластер баз данных должен продолжать работу должен предоставлять свой сервис и как правило все вот эти вот угрозы они реализуются через использование кворума то есть у нас есть некий кворум некий источник истины через который мы определяем состояние и топологию кластера которая должна как бы предоставлять быть работоспособный как выглядит репом gr в данном случае с рипом версию просто это довольно таки простой инструмент у нас изначально представим что есть какой-то кластер мастер пара реплик и чтобы начать использовать репом г.р. нам нужно только установить пакеты и больше ничего но там установить extension посуде и все и мы можем уже управлять нашими кластером через реку mgr мы можем делать switch over можем добавлять реплики это довольно простой инструмент но если мы захотим failover который автоматически будет там переключать руль мастер если старый но если текущий мастер вышел из строя то нужно уже запустить отдельный процесс rip мгд который будет мониторить состояние узлов и выполнять переключение если текущий мастер вышел из строя архитектура rip ангар она довольно таки проста я и это очень хорошо то есть нет компонентов с которыми нужно долго и усиленно разбираться при этом если вы поставили rib.png вы получаете switch over из коробки вы можете уже делать автоматически ну вы можете делать ручное переключение узлов роли мастера на другой узел и это все доступно плюс есть такая штука как видно сервер эта штука она позволяет достичь некого консенсуса когда выбираем нового мастера и такой псевдо postgres псевдо база которая также участвует является полноценным участником в кластере потоковой репликации но при этом там нету данных то есть основной основная мысль то что репом gr довольно таки просто им легко начать пользоваться что у нас патроне когда у нас когда мы хотим использовать патроне до нам нужно уже иметь распределенное хранилище конфигурации потому что патроне не используют концепции видно серверов для достижения кворума у него используется уже отдельно и внешнее хранилище это может быть консул это может быть эти седину кибер либо хранилище и 10 из самого кубер не tissot то есть вся конфигурация кластер а хранится там плюс там есть такая концепция мастер-ключа который нужно обновлять 1 30 секунд и этим занимается мастер если мастер вдруг мастер-ключ не обновил то остальные начинают уже выбирать и кто обновил мастер-ключ вот уже становится мастером так происходит выбор и то есть концепция заключается в том что должно быть распределено и хранилище и желательно должно быть в отказоустойчивой конфигурации потому что с ним тоже могут возникать проблемы и при этом патроне не должен страдать от того что в сервисе отказоустойчивого конфигурации что-то сломалось и когда мы используем патроне мы получаем авто failover из коробки есть возможность свечу вера но она как бы является второстепенной функций изначально патроне это именно про авто failover то есть если мы хотим of the failure мы хотим автоматики то патроне довольно таки хороший выбор однако недостатком ну и в другой степени это даже ну сложно считать недостатком это с одной стороны недостаток с одной стороны плюс это то что нам нужно здесь с компонент он обязателен но к счастью он довольно таки легковесно его довольно таки легко настроить и не нужно очень больших знаний чтобы себе в инфраструктуру завести de ses счастью если мы рассмотрим архитектуру стол на то здесь все идет уже гораздо посложнее я не стал рисовать этих схем просто взял картинку из документации стол она как выглядит стол он у нас есть узлы и keepers по сути это под грессы обыкновенная на нем запущен стол он теперь который как раз таки управляет уже по адресам которые запущены этом узле у нас есть компоненты прокси вся работа с базой данных с кластером базы данных а.с. осуществляется через прокси то есть все приложения они не подключаются к базе напрямую они подключаются только к прокси прокси осуществляет маршрутизацию на текущий мастер и этого мол это как бы очень важная особенность которую нужно помнить есть узлы sentinel и сентинеле они обеспечивают расчет оптимального представления кластера исходя из того что какие узлы сейчас здоровые а какие отсутствуют то есть если какой-то компонент вышел из строя сентинеле пересчитывают кластер view и уже отдельные компоненты они гипер и например они перенастраивай утп адрес и соответствии с этим глостер view то есть роль мастера ей какой-то другой сервер прокси в это время меняет маршрутизацию и перенаправляет трафик уже на новый выбранный мастер ну и соответственно опять же у нас появляется компонент de ses который необходим для хранения и работы самого стол она для хранения конфигурации и если мы посмотрим в целом на архитектуру стул он то он также ориентирован на авто failover если мы хотим каких-то ручных переключений роли мастера то это не просто lan и это не про патроне они про авто failover ну и конечно же de ses также как и в патроне нужен gcs для того чтобы стол он мог определять состояние кластер а его топологию и отдельный момент это то что все клиенты должны работать через компонент прокси и если посмотреть так вот на архитектуру патроне стол она может показаться что они довольно-таки похожи они используют ободе с они оба предоставляют failover и может показаться что они похожи друг на друга но на самом деле если рассматривать их детально в них довольно много отличий и эти отличия не иногда преподносит сюрпризы давайте сравнивать дальше посмотрим как какие есть варианты имплементации в этих решений в существующей существующую в структуру есть два варианта на самом деле это стендбай кластер и и установка на существующем кластере чем они отличаются с тобой кластер по сути это ситуация когда у вас есть какой-то продакшен кластер вы создаете второй кластер через каскадную репликацию и уже на втором глаз тире вы настраиваете вашу high availability эту систему rib.png патроне стол не важно в какой то момент вы решаете переключиться вы обрываете каскадную репликацию делаете на реплики про молот она становится мастером приложение при этом вы переключаете на новый кластер и вы получаете уже кластер потоковой репликации но уже под управлением high visibility инструмента в чем минус такой ситуации это то что нужны дополнительные железки иногда это бывает невозможно дорого либо нет ресурсов либо еще кита причины если мы посмотрим на поддержку такого варианта установки то все к счастью все инструменты предлагают такой вариант установки потому что это наиболее безопасный вариант миграции да у вас есть старый кластер на который вы можете потом откатиться если что-то пошло не так и новые данные которые вы налили там в новый кластер вы можете легко их найти и залить старый кластер то есть это наборе такой безопасный вариант ну есть конечно же хардовый deploy когда вы просто берете инструмент свой high visibility и ставите на существующий кластер назад дорога есть но может быть со всякими разными приключениями и стал он в данном случае он не поддерживает такую установку он поддерживает только либо инициализацию с нуля либо инициализацию через томбой кластер я сделал небольшую такую суммарную табличку когда будет смотреть так вот там в оффлайне может быть она может быть полезна и чтобы сравнить характеристики инструментов если посмотреть то все заявленные функции по установке не поддерживаться только в патроне то есть можно развернуть на существующем либо на пустом кластере можно через стендбай можно на существующем запущенном власти в общем варианты разные репом горы столом у них есть некоторые ограничения управления кластером управления кластером это довольно важная штука потому что мы часто конфигурируем по адресу нужно поменять конфигурацию самого пожгли 100 либо конфигурацию системы в результате которой postgres нужный перепад перезапустить либо могут быть какие-то аппаратные задачи связанных с обновлением firmware и прошивок обновлением железо еще что то то есть конфигурация поспи со подразумевается что он тоже как то может и должна управляться и конфигурацию можно разбить на несколько пунктов добавления новых узлов если у нас есть мозга рис мы хотим когда смасштабировать нагрузку нужно добавить новый узел классический вариант мы просто создаем новую реплику на основе мастера запускаем по gps backup он там тебя не данные разливает реплику мы запускаем ее она подключается к мастеру все реплика готова но иногда такой сценарий невозможен по каким-то причинам это может быть что мастер нагружен и дополнительной снятием реплики мы сделаем еще только хуже и возникают вопросы а можем ли мы снять реплику с другой реплики или поднять реплику с резервной копии на то есть наша high availability штука она должна поддерживать такие сценарии а должна уметь развертывать узлы из других источников и не только с мастера если мы посмотрим на репом gr the rib mgr предоставляет нам автоматику снятие новой перед новой реплики через отдельную команду мы запускаем эту команду и она делает всю магию уже где-то там внутри это очень круто может ли она снимать реплики с других реплик да может там отдельный параметр в этой команде айдишник ноды и залив наливка реплики начинается с той ноды плюс можно снимать можно делать реплики на основе резервных копий резервной копии поддерживаются только барменом можно указывать отдельные параметры конфигурации и указывать там настройки барабана узел где хранятся резервные копии значит снимать оттуда но самому этом гарри есть функция кастомного восстановления то есть мы можем реплику каким угодно способом сгенерировать там руками взять из бекапа взять с другой реплики еще как-то и есть отдельная команда которая позволяет просто вот этот узел подключить существующей кластер vip mgr а то есть по сути мы можем написать какой-то свой скрипт со своей логикой и уже в этом скрипте реализовывать свою логику подключение реплик если мы рассмотрим патроне то патроне является довольно гибким инструментом он позволяет делать реплики вообще как угодно снимать других реплик снимать резервных копий будь то это borman b крест вал jewel е неважно у него есть возможности для этого и кроме того есть кастомное восстановление мы можем опять же написать свой скрипт со своей логикой и он будет работать то есть это довольно удобно но опять же мы должны гарантировать что этот скрипт делает ту работу которую мы в него закладываем то есть ответственность на это на администраторе что-то стоило нам столб он к сожалению не предоставляет некоторых вариантов когда мы запускаем с полом он автоматически нам наливает реплики но у него нет возможности наливайте реплики с других реплик то есть вся нагрузка ложится на мастер и мастер будет страдать особенно если выйдем еще много клиентской нагрузки нет возможности снятия с резервных копий есть возможность инициализации из резервной копии но это только при инициализации кластер а когда мы делаем новый стенд бай кластер мы указываем просто наливаться его из резервной копии но такая ситуация она понадобится только один раз когда мы имплементировать он в нашу инфраструктуру в дальнейшей работе это уже не нужно ну и кастомного восстановления также нету то есть получается что стал он здесь наименее наименее гибок стол он подходит нам только в случае когда у нас нет высоких претензий кастомизации процесса развертывания новых узлов что с управлением конфигурации управление конфигурации когда возникает задача поменять какие-то настройки в полисе и здесь важно помнить такой такой момент что репом гарета надстройка над под гриссом то есть по сути реп мглы postgres они независимы друг от друга мы можем но четко провести линию между ними и не обнаружить там особых зависимостей а вот патрон не стал он это они выступают в своего рода и не системой для подвеса то здесь мы идем уже на сделку мы получаем авто failover плюс дополнительный набор фич но мы теряем в некоторый в некотором контроль над конфигурацией если мы рассматриваем rip mgr мы имеем полный контроль над конфигурации мы можем редактировать postgres сколько он с гришкой ли autoconf правило авторизации параметры репликации потому что они независимы и компоненты репом гарни зависит пузырится под здесь не зависит от требуемой все круто полный контроль мы можем на отдельных нотах отдельные настройки применить на других модах третье настройки ничем не ограничены патроне уже берет часть управления конфигурацией на себя и это параметры связанные с репликацией когда мы и устанавливаем по тронемся в инфраструктуру текущей существующей подогрев сколько он переписывается патроне и он записывая туда те параметры конфигурации которые ему необходимы вот те параметры в репликации все остальные настройки едут в подогрев сколь бы из клонов если мы хотим что-то там поменять мы можем уже редактировать только под грецку либо из клонов основной под грибком он как бы уже не доступен администратору и если мы что-то запишем то патроне просто его при каком-то событии перезапишет и наши настройки потеряются есть вариант хранения настроек в de ses тогда эти настройки позади совы и они будут централизовано хранится в de ses и они будут распадаться по всем серверам это довольно таки удобная штука что у нас a stone stone выступает ещё более жестко он берет всю конфигурацию под свой контроль если вы хотите поменять какие-то параметры конфигурации вы уже не можете поправить конфиге они будут перепить переписаны с тоном вы вынуждены будете через салон gtl через отдельную команду применяйте параметры конфигурации после со и они уже разъедутся на все узлы кластера это очень круто и очень удобно если нам хочется иметь унифицированную конфигурацию кластера на всех узлах чтобы конфигурации не отличались плюс есть такой момент что часть настроек она невозможна для изменения вообще например параметры вал keep сегмент кто с ним знаком условно говоря такая специальная крутилка у нее есть своя специальная задача но стал он например не дает ее менять не как у него прописано специальные параметры в исходниках специальное значение в исходниках и он всегда держит его в этом состоянии и интересный момент спуска леску или авто конов по идее у администратора как бы должна оставаться возможность понять конфигу через alter систем но стал он отнимает эту возможность и переписывает пожгли сколь autoconf на дохнул все что мы вносим через alt российским она пропадает синхронная репликация синхронная репликация нужно потому что если мы работаем с деньгами и не хотим терять транзакции то другого варианта нет то только через использование синхронной репликации либо через какое-то реализацию на уровне приложения что предоставляется инструментами 3.png он никак не контролирует конфигурацию после со поэтому настройка синхронной репликации полностью ложится на руки администратора администратор идет в рекавери канав комов правит его и смотрят что все запустилось патроне ктл патроне он берет часть у патроне и стал он они берут часть управления конфигурации на себя поэтому включение синхронной репликации уже осуществляется через патроне столом мы просто указываем определенную команду и она автоматически настраивает синхронную репликацию для нас это на самом деле удобно и очень круто но у стола на есть несколько ограничений например он не поддерживает короны и конфигурации через и не и first устала на вместо этого свои отдельные параметры количество синхронных реплик минимальная и максимальная и дальше он уже автоматически на основе своего представления выбирает какая из реплик будет синхронной и настраивает и и мы дебаг trouble shooting когда какой-то инцидент произошел роль мастера переехала на другой сервер нужно как бы быстро ориентироваться что произошло и быстро разбираться в причинах произошедшего к счастью все инструменты предоставляют более менее одинаковый уровень предоставления информации администратору плюсу репом горы патроне есть свои логе можно указать лог-файл куда они будут сохранять события и можно уже анализировать их плюс журнал д все можно смотреть через журнал д довольно таки хороший ну единый общий универсальный источник блогов ну и плюс локи под колеса они никуда не деваются учитывая что после социологии конфигурируются отдельно вы просто при каких-то инцидентах смотрим не только логе инструмент на патроне требуем гастона но еще и смотрим логи вас где сам ну и наверное основной момент основная как сказать основной топик это обеспечение high availability как реализуется это инструментами если мы смотрим of the file over the патроне стол он предоставляет авто файлов из коробки если вы выбираете средства для своего подрисовок кластер а то вы просто ориентируйтесь на это ну вот на этот пункт если вы хотите сохранить контроль над своим кластером и самостоятельно выполнять переключения роли мастера между узлами the rib mgr подойдет здесь больше потому что он изначально ориентирована именно на switch over если мы говорим про свечой р опять же to switch over поддерживается не всеми одинаково если гриппом gr он идет из коробки в патроне он идет как дополнительная опция то стол она вообще не ориентирован на switch over у него нет отдельной команды переключить узел но переключить роль мастера на другой узел есть коркоран через синхронную репликацию и пометку существующего мастера как сбой нова но это такой вариант который не гарантирует что новый мастер уйдет туда куда нам хочется стол он выберет вас а по своему усмотрению и когда происходит само переключение мастера хочется чтобы произошли какие-то дополнительные события например перебалансировка перенастройка каких-то других сервисов регистрация каких-то событий что-то еще и наши инструменты также должны поддерживать эту кастомизацию у репом вера есть такая штука иван таких и кришна их довольно много штук 10 или 12 по сути мы указываем в параметре event notification команд какой-то специально написанный скрипт который обрабатывает идет его matific вишен и и выполняет какие-то задачи когда notification пришел то есть по сути у нас такой uber супер скрипт который обслуживает сети именно 9 шины но важная особенность что этот скрипт работает и синхронно рифам гор запускает его и дальше что там произойдёт с этим скриптом его не интересует он не ждет его завершении он не проверяет его код возврата у патрон есть аналогичный механизм он называется call бейки их меньше 4 штуки если мне не изменяет память но по сути принцип тот же самый у нас есть набор каких-то скриптов которые срабатывают при наступлении определенного события там перезапуск моды мода стала мастером и они также работают асинхронно патроне запускает их и что там дальше они делают патроне уже не мониторит кастомизация стол она устроена нет никаких инструментов он не позволяет вам запускать какие-то кастомные события при изменении топологии кластера к сожалению у и другой момент это fencing по сути fencing это а течение сбойные ноды чтобы она не продолжала жить своей жизнью отсутствие фен синга это как раз таки хороший источник для скрип brain of если у нас старая но до продолжает работать то в эту старую моду могут продолжать все еще какие-то приложения писать данные в новый мастер какие-то приложения тоже могут писать данной мы получаем уже две две картины время мгер finding a как такового нету его нужно реализовывать самому своими средствами своими инструментами опять же это через какой-то баш скрипт который будет запускаться который будет там чуть за и темой например выключать ноду либо там гасить пузырь с как-то ну это все ложится на плечи администратора в патроне получше с этим и учитывать что патроне использует disease есть два варианта где может понадобиться fencing первый вариант это когда отвалился патроне агент представим себе ситуацию что мастер работает а он управляется патроне и пришел он киллер и убил патроне postgres продолжает работать в этот момент происходит failover выбирается новый мастер и у нас получилось два мастера потому что на старом мастере патроне не может выключить posts для этого используется механизм linux watch dog патроне запускает таймер обновляет у вас 5 секунд если патроне процесс завершил работу то срабатывает watch dog и машина либо перезагружается либо выключается в зависимости от настроек и это очень круто как только у нас но до ушла в перезагрузку выбрался новый мастер произошел failover нас и сбегается ситуация с придурью на другой вариант это когда у нас disease стал недоступен консул видите сиди они стали недоступны и патроне не может уже поддерживать свою работоспособность он просто перезапускает под grease и мастер в редон или и запись просто уже становится недоступна что со стула нам если какой-то компонент 100 ломовский становится недоступен то сентинеле они просто пересчитывают кластер view и оставшиеся компоненты живые они наберут этого внимания и перри настраивают себя например существующей мастер может перекинуть роль на другой узел либо прокси просто может уйти из обработки соединений если de ses стал недоступен то узлы прокси они просто перестают слушать интерфейс сетевой а существующие соединения обрывают то есть это как раз ты меня та причина по которой рекомендуется чтобы все клиенты базы данных работали через прокси если какие-то клиенты в обход прокси продолжают работать с базой то это может привести к непредсказуемым последствиям если исчез снова появился the proxy узел он просто поднимает снова интерфейс но слушают на интерфейсе и может снова принимать подключения ну и другой момент связанный с восстановлением сбойных узлов потому что файла веры то всегда ситуация когда мастер недоступен и роль мастера переезжает на другой сервер и старый узел нужно как-то восстановить включить дальше в работу и если мы рассматриваем rip mgr то репом гарета ручное восстановление мы запускаем отдельную команду для этого и пытаемся восстановить узел и чтобы не перенести визировать узел с нуля для этого используется по гривен отматывает журнал транзакций до определенной точки и подключает старый узел в качестве реплики по гарри винт это уже как бы такой устоявшийся механизм переподключения с сбойных узлов в качестве реплик у патроне стула на похожие механизмы для восстановления то есть если старый узел ушел ушел в down он снова поднялся по тропе пытается и стал он пытается его перри налить если есть возможность использовать по гривен то используется по горе винт но бывает такая ситуация что этот узел он уходит в так называемый crash клуб он пытается запуститься случается ошибка он падает и вот так вот бесконечно то в этом случае нужно уже востанавливать руками с полной переинициализация ну и когда мы настроили эту штуку ну high availability наш кластер наше приложение тоже должны быть к этому готовы потому что роль мастера может прыгать между узлами и приложение должно быть к этому тоже готова нам нужно уметь переустанавливать соединение на новый на новый мастер либо пересмотреть соединения к репликам и приложение должно быть к этому готова оно должно уметь самостоятельно искать кто сейчас мастер кто сейчас реплики потому что роли эти меняются и адреса адреса серверов которые поддержку беру взяли эти роли на себя они тоже меняются и приложение должно быть готовы к этому + приложение должно быть готово что соединение к базе данных пропадет приложение должно быть готово перезапустить транзакцию повторить свои действия потому что failover как бы не спрашивает эти транзакции сейчас выполняются и не ждет когда они закончатся и что предлагают хавел и bild инструменты для этого репом гор ничего не предоставляет то есть мы просто используем rip мглы уже самостоятельно пишем какую-то логику для приложения либо в приложении реализуем эти вещи патроне есть авторегистрация сервиса в консоли это довольно таки удобная штука приложение может через обыкновенный механизм гомеса опрашивать кто сейчас мастера кто реплики и на основе этих записей просто переустанавливать соединения стол они есть прокси то есть переключение роли мастера вообще происходит прозрачно то есть это вообще круто прокси внутри себя просто меняет маршрутизацию но новый мастер приложение не как об этом даже не узнает она продолжает работать но и + стол они появляется ручная регистрация сервиса в консоли с версии 014 который должна выйти в мае в конце мы вот поэтому тоже можно будет регистрировать сервисы в консоли и получать их через dns тоже будет удобно но эта ручная ручная задача в патроне это более-менее автоматически происходит ну и того что у нас от того если мы выбираем инструмент для high availability у нас есть на выбор две категории репом гры патроне стал он если мы хотим автоматику мы выбираем rib.png стал он если мы хотим сохранить контроль мы выбираем режим gr гриппом г.р. авто failover как опция нужно дополнительно настраивать но мы при этом сохраняем полную полный контроль и полную свободу над конфигурированием под грессов плюс нет фелтинга это очень важно это нужно помнить fencing реализовывать нужно будет самостоятельно в патроне как и в салоне авто failover из коробки если вы хотите какую-то штуку которая автоматически будет управлять вашим по адресам и вы не ходите туда лезть это на троне стул она не более менее для этого подходят патроне в какой-то степени предоставляет больше функционала но часть из этого функционала вполне может вам просто не понадобится патроне подходит как для бары металла так и для облачных установок столом его отдельной особенность как мне кажется из за того что он многокомпонентный он очень подходит для облачных окружений если на баре методы его развертывать то это нужно 6 до 12 узлов примерно при том что некоторые узлы будут совсем легковесные в облаке допустим разместить это будет гораздо дешевле и стол она очень хорошо подходит если у вас нет требований кастомизации под gresso если вы используйте пасту себя в проекте как то ну не сильно сдаетесь в его аспекты конфигурирования ту стал он подходит гораздо лучше он позволяет все это унифицировать и поддерживать одинаково ну и на этом все спасибо за внимание здравствуйте благодарю за доклад меня зовут николай им tst вопрос такой скажите пожалуйста вот используя эти инструменты которые вы сегодня рассказали они позволят допустим devops инженеру меньше погружаться в особенности ebay и насколько вот по вашей оценке то есть не нужно ему быть ebay администратором теперь вот при наличии таких инструментов спасибо хороший вопрос дырка dp и он занимается не только сервисами debate а еще и написании запросов оптимизация запросов в такую специфику погружаться не придется но если вас интересует сохранность данных то в специфику подлец и все равно придется погружаться в результате фолловеров часть транзакций может теряться но при использовании асинхронной репликации если потеря транзакции как бы вам не допустимо нужно рассчитывать с л о с алей то в этом нужно погружаться нужно смотреть соответствующие конфиге после со ну параметры пожгли со их настраивать то есть если отвечать на вас лоб на ваш вопрос то некоторая экспертиза все равно понадобится доброе утро от нашего классный доклад а какие из этих тузов вы использовали в продакшене какие там были объемы данных какие рпс то есть какие в бою обстреляны из этих но хороший вопрос но основам используем патроне repair у нас есть на удаленной поддержки мы пытаемся отниму избавиться но там клиент он веселье задал вопрос ждет ответ но чтобы его сподвигнуть на какое-то переключение это очень тяжело как репом г.р. объемы данных около 100 200 гигабайт но эти устаревшие данные возможность что-то поменялось патроне у нас на 3 4 проектах в одном проекте довольно таки он сильно распространен на многих квартирах баз данных и мы в управлении даже туда не лезем там патроне установлен давно эти базы как-то там живут и работают переключаются мы туда даже не заглядываем объемы данных там небольшие потому что это микро сервисы и у них довольно маленькие объемы данных интересные проекты которые мы обслуживаем и куда заглядываем больше всего как они работают объемы данных около двухсот трехсот гигабайт но по сути объем данных как бы он не сильно играет значение при выборе инструмента она может когда вот реплика поднимается что может быть команда допустим есть поднятия реплики а реально надо ее запустишь нам дано когда отчет гигабайтах и не дождешься да да это это хорошее замечание потому что иногда приходится перенести сделать реплику с нуля при отсутствии мониторинга и реплика вошла freshlook и через по гарри винты и восстановить уже невозможно вот это играет роль да но спасибо и здесь спасибо за доклад максим мальчик сбербанк вот в обзоре средств высокой доступности вы не упомянули crunchy чем вы можете сказать у него есть open source решит вариант кранчер кароч с crunchy это после сколь оператор для купер написала про него говорите да но это не совсем как бы ни у них есть продукт отдельный который называется high level will be all abilities youth сушите я не слышал про него не смотрите на гитхабе там есть я сталкивался с их споры леску или оператором вот но проходило величают не знаком ну я посмотрю спросила а еще вот касательно этих трех которого рассматривали вы не не упомянули очень важный плюс у патроне есть растопи rest api да это это очень богатыми механизм общения самих патроне между собой то есть патроне например через двух других насколько я знаю нет но у репом горда rest api нету потому что там нету вообще механизма disease как такового стол они сталлоне тоже нет раз т.п. ну не знаю мне растопи редко бывает нужен я как-то обхожусь без него растопив в основном я так понял он используется для взаимодействия патроне агентов между собой да он позволяет еще расширять себя там но я стиля не углублялся в 1 т.п. и в завершение хочу просто добавить что вы сказали что используйте патроне если там не хотите лезть руками руками лезть все равно придется да не надо радужных таких нет вы так они конечно красивая штука хайло и бились это дополнительная абстракция к вашей базе данных с ней придется разбираться да она будет иногда ломаться а иногда а иногда даже не иногда часто с этим до нужно разбираться то есть к сожалению серебряной пули здесь нет есть только одна свинцовая и с этим как-то нужно жить последний вопрос спасибо за доклад одними поднимите руку пожалуйста здесь вот про патроне вы не упомянули х прокси в proxy до луны как бы там вот-вот веков документация описывается он как бы ставится и он как раз таки решение задача проектирования и опять же вот дополнение по поводу rest api именно за используя rest api патроне он разделяет мастера и прокси руи ту же no matter хоррокс уже х прокси уже до используются для балансировки там есть два варианта использования либо мы используем h прокси либо используем сервис зарегистрированные в капсуле но это это уже нужно если мы сервисы в комплекс пользу им это уже нужно приложение учить опрашивать через dns переустанавливать соединения с их апраксии вариантов попроще да но это тоже имеет вариант на жизнь там еще keep-alive где используется для виртуального адреса 2-х прокси да я просто уже не укладываюсь я сейчас выгонят спасибо можно рассказывать на самом деле много да да лечение мы вас выведем но в дискуссионную зону не против она прямо на выходе из зала слева там можно обсудить спасибо большое"
}