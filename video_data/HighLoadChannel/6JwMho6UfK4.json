{
  "video_id": "6JwMho6UfK4",
  "channel": "HighLoadChannel",
  "title": "BigПочта: как мы строили DataLake в Почте России / Алексей Вовченко (Luxoft)",
  "views": 15348,
  "duration": 3593,
  "published": "2018-08-16T04:46:22-07:00",
  "text": "а вы самостоятельно поскольку тут не было никакого представления меня зовут алексей вовченко я более десяти лет занимаюсь с системами хранения обработки данных и последние пять лет в области big data и сегодня я расскажу вам про то как мы внедрили bigdata инфраструктуру в почта россии поднимите руки тех кто вообще пользуется почтой россии отлично и я такой же как вы я точно так же пользуюсь почтой россии и кейс из жизни в 2012 году за казался посылку тогда я впервые узнал что такое amazon накидал себе много прям крутых каких-то мелких товаров подарок друзей и youtube реально под новый год хотел все раздать вручить заказал в ноябре специально чтобы пришел к новому году вот наверняка 27 ноября посылка произошел экспорт из сша и дальше как канала в черную дыру вообще никакой информации ничего нету где что звоню в почту никто ничего не отвечал только 25 декабря посылка появилась у нас на таможенном контроле к счастью всего за 5 дней а но прошло до офиса м с позвонил туда сказал не надо отдавать курьером они ее потеряют сам приеду заберу приехал туда там я был такой не одинока краску это был завал в почте простоял 5 часов вмс и забрал наконец свою посылку к счастью она дошла целостная на самом деле теперь я знаю как такое могло произойти ответ очень простой мы приходим ну казалось бы что общего у матрешки и почты но в этом просто кроется корень всего зла который был когда-то с точки зрения данных в почте россии мы сдаем отправления в отделении его запаковывает мешок мешок запакуют в контейнер контейнер из пакует в емкость это в большой контейнер и это в вагон и отправляют и все бы ничего но когда этот большой контейнер идет где-то на сортировке операция над ним проводится ровно над самым верхней уровнем контейнером и в каждый конкретный момент ранее просто в почте никто не знал что за отправление лежат в этом контейнере сколько там каких понять что есть документы есть накладные в каких-то системах разрозненных эти данные были можно было в случае разбирательства все эти данные достать но это дни а так чтобы взять и в конкретный момент сказать где сейчас наше отправление просто никто не знал именно поэтому собственно происходило то что происходило когда у нас дикие разрывы между статусом еще вот пять лет назад а вспоминаю как шли мои посылки просто невозможно было отследить мне доставляет посылку а статус что она где-то вот прибыло в сортировочный центр что такое собственно сейчас почта с точки зрения организации все мы ходим в магазин за продуктами знаем что такое ритейл они решают классическую задачу взять товар и доставить в магазин в магазине продать людям почта это то же самое за одним маленьким исключением почте надо знать про каждый конкретный товар каждая конкретная бутылка масла должна поехать в какой конкретно город в какой конкретно магазин и конкретному человеку и когда мы таким образом ставим вопрос мы понимаем что с точки зрения данных с точки зрения самой организации помимо вот этой сети почтовых отделениях ритейла в почте очень мощная логистика поскольку все логистические центры нужно выстраивать таким образом чтобы мы могли сортировать каждое конкретное отправление ровно туда куда нужно что же такое почта с точки зрения данных на текущий момент это 47000 отделений по всей страны ну если кто-то хочет посмотреть вот на точке это реальные точки нарисованные на карте это очень много примерно каждый день у нас появляется два миллиона отправлений и над этими отправлениями постоянно производятся какие-то операции общий поток событий которые нам приходят в реал тайме порядка 200 400 миллионов событий причем это не легкий quick stream где несколько атрибутов и это реально тяжелые событие по 50 100 атрибутов который характеризует что же сейчас отправлением произошло на самом деле помимо вот событий именно операции есть еще поток данных финансовых но фактически то что происходит в отделениях транзакции продали открытку выдали пенсию это тоже все данные которые мы получаем поэтому поток данных получается очень большой соответственно была поставлена задача довольно классическая построить инфраструктуру отказа устойчивую инфраструктуру который бы решал классический с точки зрения data warehouse а задача и все бы ничего наверно многие могут спросить а в чем же проблемы берем базу данных загружаем туда данные берем бей настраиваем на базу данных строим отчеты и real-time и быстрый все хорошо но проблема заключается в том что в почте много данных как я сказал 200 400 миллионов событий в сутки и они постоянно растут и накапливаются и естественно обычной базы данных просто не справляется поэтому нужна какая-то другая система к и другое решение на самом деле в почте думали вот ровно точно так же как все кто видят впервые эту задачу берем необычный базу данных берем параллельную машину баз данных экзо дату хорошая база очень быстро главное параллели ца можно загрузить много данных в целом решать опять же классическую задачу bio и и база проблема заключается в том что когда этот пилот в почте сделали и начали масштабировать на страну решение стало не очень быстро работать поскольку фактически мы заставляли базу одновременно конвертировать наши данные одновременно фв решать нашу задачу матрешки это по сути графова я задача одновременно отдавать пользователям отчеты биой и все это вместе все это в реал тайме все это сразу в какой-то мент это привело к тому что в особо такие пик когда данных было много задержка по доступности данным составляла 5 дней что такое пять дней сегодня пятница я начальник логистики хочу узнать что у меня происходит сортировочный центр и а у меня данные на воскресенье 5 дней это просто дикая задержка поэтому к нам пришли и сказали надо сделать все то же самое что было сделано на раковые к задать и только лучше и один такой маленькая ремарка маленький может сказать комментарии что больше не хотим никаких windows ких решений хотим только opensource ноги и сказано сделано соответствии с задачи на релиз 0 который у нас были это получить данные построить модель данных фактически решить графа вую задачу по разворачиванию матрешки потому что когда у нас происходит событие над верхней емкости нам надо найти в графе связи все пути до всех отправлений чтобы понять где сейчас конкретно и отправление надо построить некоторый отчет мы его назвали остатки который показывает на состояние на вчера какие отправления где сейчас находятся где завалы на сортировка где выделениях не успевает обработать почту собственно вот такой чет у нас был первый пилотный отчет и наконец предоставить доступ пользователям чтобы они могли посмотреть этот отчет задать фильтров причем набор фильтров был довольно большой 20 30 40 разных фильтров критериев чтобы аналитики могли посмотреть где проблема найти ее позвонить сказать ребята вы работаете плохо соответствовать ска уровневое наше решение выглядит следующим образом все на самом деле очень просто есть некоторый фронт приема надо данные сохранить в ходу мы помним у нас open source и затем отдать в бей и мы тоже помним что у нас open source поэтому была выбрана пинтах а соответственно дальше рассмотрим чуть детальнее как это было сделано понятно что hadoop это не про real-time hadoop для ба чего хранения поэтому все данные которые нас поступали от фронта приема они поступают в шину данных кафка это нам во-первых позволяет балансировать нагрузку потому что данных могут быть какие-то пике кафка их сглаживает а вторых это позволяет нам потом рассудке грубо говоря 0 часов прошло мы выбираем данные за предыдущий день и обрабатываем собственно с точки зрения обработки мы как наверное многие кто пробует hadoop взяли хаев поскольку все из мира баз данных все знают sql решили что это будет такой самый первый простой способ взять и построить нашей тельно хайве ну через мы при deus и на самом деле вот тут кроется та ошибка которую вот судя по статьям в разных местах в том числе и на хабре совершает многие компании когда пробуют hadoop и от него в этот момент отказываются потому что не надо так делать хай в нам и previews не знаю зачем это было придумано не надо так делать потому что в современном мире уже придумали такую крутую штуку как т.с. она идёт по умолчанию собственно в дистрибутиве от hartan works для колдера тоже можно при желании прикрутить но это правда потребует некоторых дополнительных ручных действий но hive с движком выполнения т.с. в сотни раз быстрее чем хороши через мой при deus то есть не надо пользоваться hai lam через мой при deus наконец поскольку у нас pipeline обработки был в нелинейной взяли с конвертировали они который такой процесс обработки данных то это нужно было как-то оформить мы выбрали озе как естественный компонент который позволяет нам описывать потоки работ для выполнения и запускать по расписанию на нашем кластере наконец теперь нам нужно отдать данные и с точки зрения того как мы хотели отдавайте данные нам же нужно отдавать быстро мы подумали так ночью костер считает днем он стоит что можно делать днем взять запустить spork sql server за каши ровать все наши витрины данных в память настроить spin the хобби а и на sparkasse quelle отдать крутое решение работает очень быстро очень эффективно пользователи прям очень радовались и на самом деле на этом бы можно было закончить если бы это реально было крутым решением давайте подумаем что тут самого проблемного да вот я слышу из зала слова с парка на самом деле это абсолютно правда sparkasse quelle всем прекрасен пока к нам не пришли заказчики которые радовали своим отчётам и сказали ребят вот 20 аналитиков смотрели отчеты и было очень хорошо но теперь мы не хотим сами смотреть эти отчеты мы хотим отдать отчеты на всю сеть чтобы смотрели пользователи в сорока семи тысячах отделений сразу сопоставляем нагрузку 20 аналитиков и 47000 отделений и получилось так что sparkasse quelle когда на него идет большая нагрузка с park the java он вообще любит очень с памятью странно работать происходит м экзекутор падает адонай за кашированная экзекутор падает данный начинают тянуться с диска снова в память бэтмена нагрузка слишком большая на другой экзо кьютер падает следующий следующий так каскадно просто падает весь спаркс кори кластер не надо так делать свечи и задача которая нам сказали что на самом деле то что мы можем выразить в реляционной логике это мало поскольку нужны бизнесу были киты хитрые обработки алгоритмов что учесть skype там операция событиям произошла не вовремя но она на самом деле относится к предыдущему периоду потому что там какой-то эвристик а вот это очень тяжело описывать на иску или ну то есть если кто то пробовал по вере ну как бы знает о тех кто не провал поверьте не надо описывать сложную логику на иску или соответствует третья задача с которой нам пришли это собственно когда мы построили отчет остатки показались список отправлений который лежит в конкретном отделение нам сказали а почему но как бы логичный вопрос почему мы считаем что они там лежит и нам сказали а покажите нам по каждому отправлению все те события которые с ним происходили а что это значит это вот например есть нас коллекция 100 миллиардов записей давайте-ка выберем из них 100 ходу просто для таких задач неприменим поэтому мы собственно стали решишь сказать решение но вначале сконцентрировались с нашей самой больной темой то что у нас парку стиль стал нестабильной у нас задача была просто витрины уже посчитаны и есть в ходу пи нам все равно что это будет база данных либо какой-то движок нам важно что взять эти данные либо вот с из взять либо куда-то загрузить а если куда-то грузить это должно работать быстро дальше нам нужно чтобы этот инструмент позволял быстро отвечает на наши запросы ну и в том числе уметь отвечать на тяжелые лап запросы мы перепробовали вот тут перечислены те темы которые нам попались на глаза но довольно популярной системы в тот момент и пришли к следующему выводу что все движки которые работают над данными же dfs в сколь бы они крутые меня были тот же объем began сайт очень хорошее решение само по себе если у вас есть только класса нет больше ничего но в сравнение он медленный с точки зрения баз данных лучше всего работали колодочные базы ну в целом это логично потому что у нас распределенная коллекция нам нужно делать раз про зеленые join и нам нужно фильтровать по колонкам и очень эффективно работает именно колон ночной базы лидерами собственно были верте кай грин план мы сравнили их под нагрузкой и через g метр проверяли мы с лечим образом есть отчет в пинтах а есть данные в базе мы через джимми трс много раз открываем отчет смотрим как работает связка пинтах а база и на самом деле на нашем кейси мы получили что vertica примерно в 3 раза быстрее чем green план скорость загрузки при этом в данных тоже превышала примерно в два с половиной раза чем у вертите быстрее чем грим план просто потому что мы все считаем work формате это очень эффективный тоже колоночный формат для ходу по ал'вир текке есть просто нативный коннектор для war формата мы просто говорим вот тебе external ты был загрузи ко мне данные и это получалось очень быстро и нам настолько понравилось как работала vertica что вспоминаем первые слайды только opensource что мы вот мент решили что вот мы ради вертите просто нарушим в данное себе можно сказать этот такой критерий или данное себе обещание использовать только у пан source и таким образом у нас в нашей инфраструктуре получилось вертикально таскать с тех пор мы не знаем проблем с отчетами то есть эта связка работает очень хорошо теперь можно обратить внимание что также sparkasse quelle заменился на spork-и это в целом логично если вспомнить задач которые нам поставили про не реляционную логику я утверждаю буду утверждать если кто-то хочет потом подойти подробнее расскажу что hive через ted в каких-то случаях работает даже сейчас быстрее sparco но тем ни менее spark это прекрасный инструмент который позволяет выразить любую не реляционную логику таким образом мы внедрили spark мы научились чтобы он не падал потому что там часто бывают проблемы с переполнением памяти научились писать на нем ну словно хорошо программы и собственно таким образом наша стала выглядеть инфраструктуры теперь следующая задача доступ к данным по ключу когда нам нужно увидеть операции по конкретному отправлению на самом деле те кто последнее время например ну года два с половиной три call на сайте почту свою посылку вбивали там отправление видели список операций на самом деле это ровно та же самая задача которой решено на сайте pochta.ru только у нас данных больше поскольку у нас есть все промежуточные операции по сути для внутреннего пользователя и почта хочет их видеть при анализе и при разборе разных инцидентов собственно на тот момент нам были известны такие два лидера можно сказать в этой области 1 x-bass с ним наверно сталкиваются всех кто работает с ходу pump то что он естественно идет в поставке как cartoon wars the colder а так и других поставщиков и второе это кассандра с одной стороны во-первых знали что это хорошая база во вторых уже наши коллеги которые собственно делали сервис отслеживания вот на сайте pochta.ru они выбрали использовать кассандру мы сравнили как работает две эти базы и выбрали в кассандру в целом очевидно почему выбрали кассандру к то что она быстрее 10 тысяч записей на узел и 10000 синий в принципе это утверждаемый их такой можно сказать потолок который может выдавать и себя это базам его легко достигали то здесь тысяч записи чтений на узел это не какой-то миф это реальность то есть если кассандра у нас на ssd дисках она работает очень хорошо и очень быстро второй момент то что если посмотреть на те задачи которые мы хотим решать у нас есть spork-и нам нужно как-то данные в кассандру ну в базу ваш bass или в кассандры загружать и spork-и кассандра дружат очень хорошо есть такая контора дата stax и они разрабатывают коннектор от sparco кассандре и это пожалуй сейчас чуть ли не лучшее решение по работе с кассандрой когда мы говорим про наши распределенной системы таким образом наш release 1 стал выглядеть с таким образом у нас появилась vertica у нас появилась кассандра появился spark и в целом на самом деле это уже очень хорошее решение она позволяет получать данные обрабатывать данные пользователи полностью довольны все данные мы обрабатываем за вчерашний день которые в игры были из кафки и пользователи в целом тоже были довольны коллеги проходите здесь вот много места и пользователи тоже были довольны но как известно когда мы даем конфетку они хотят вторую к нам пришел бизнес и сказал ребят вот все круто работают а давайте теперь real-time и чтобы понять что такое real time he дупе мы данный пишем в кафку выгребаем ночью обрабатываем и у нас pipeline занимает там семь-восемь часов чтобы за ночь успеть это вот все построения разворачивания матрешки построения витрин куча куча разной обработки а нам говорят а давайте теперь real-time мы начали спрашивать что же реально нужно на говорят нет нужен именно real-time нокий сказано пошли работать задачи которые у нас стояли очень простые нам нужно из кафки писать в кафку нам нужно из кафки писать в кассандру и нам нужно ее сказки писать в hadoop почему именно такая постановка вопроса на самом деле для real-time а у нас все было готово в нашей инфраструктуры хотя мы считали все за вчера потому что в кафку данные пишутся в реал тайме кассандра очень быстро пишет и очень быстро отдаёт соответству нас есть все чтобы сделать полноценный real-time с точки зрения обработки данных мы рассмотрели популярные фреймворке ну и выбрали угадайте что spark streaming очевидно почему мы выбрали spark streaming во первых у нас уже есть код на спарке и очень удобно использовать одну и ту же кодовую базу на спарке а вторая причина как этот рассказал чуть раньше про кассандра это прекрасный коннектор кассандра spark тем самым мы остановились на этом решении остальные почти не рассматривали хотя сам за тоже используется в почте в другом проекте например офлинг мы сейчас пилотируем про него расскажу в самом конце таким образом наша инфраструктура стала выглядеть таким образом у нас появился spark streaming и все бы ничего но есть некоторая проблема в семантике если кто присутствует на предыдущем докладе там рассказывали про семантики потоковой обработки что коллегам нужен был именно y3 ланс нам не нужно было семантикой язык леланд чтобы ровно один элемент доходил нас вполне устраивало семантика spark streaming от лист ланс но проблема в том как спарк работает с этой семантикой spark свои чекпоинты при чтении сказки может хранить либо в зуке перри и это медленно либо можно использовать так называемые дайрект айпи по доступу кафки это очень быстро очень производительно но когда а в сет в каске сохраняется с самом приложении спарка в виде чекпоинта и тут проблема возникла сама вас парка то что для чекпоинта он использует хэш от нашего исходного кода мы выпустили новую версию check point ну досадно просто а кафку мы храним за две недели интервал поскольку если случится какая-то проблема мы хотели иметь возможность всегда перечитать данные поэтому было кафка на две недели и мы думали думали что с этим можно сделать решили оки если нам не подходят стандартные средства реализуем свой компонент назвали его love set менеджер который при чтении данных из кафки после каждого микро бача сохраняет для каждого пар тишина для каждого топика для каждого приложения офсет в базу соответствию нас вышла новая версия приложения если у нас приложение упало чтобы с ним не произошло мы всегда после сбоя поднимаемся ровно 100 волос эта который записан в базе таким образом у нас в нашей инфраструктуре появился под грейс quelle но еще один такой маленький момент вот мы рассказывали что данные сохраняем ночью их процессе real-time как-то отдельно процессе и у нас просто произошло некоторые иногда расхождение по данным между нашим бойцам между нашим стримингом где то чего то по другому подсчитано это на самом деле очень плохо не должно быть такого ни в какой системе поэтому у нас появился некоторый инструмент флю который позволяет нам из шины данных кафки выгребать данные либо в форматах но обычных бинарных сообщением их сохраняли как логе в боишься 4 либо видео про объектов весь наш pipeline у его им проводки был построен на avr объектов то есть мы прочитали записали и по сути каждый промежуточный этап нашей обработки в онлайне мы сохраняем виде флюма на диск и на диске уже работаем с тем что у нас конвертировалась в онлайне на самом деле позволило нам решить большинство проблем которые возникли как мы помним было вот так когда мы внесли streaming стало вот так это наш release 2 на самом деле вот опять же тут можно было бы закончить потому что это очень крутая архитектура для организации которых хочет решать подобные задачи мы можем тут и онлайн обрабатывать данные мы можем batch обрабатывать данным отдаем отчет и у нас есть кассандрой vertica все у нас есть чтобы ну пользователи были счастливы но как известно чем система становится популярнее тем больше у нее пользователей и естественно всплывает то что сделано изначально плохо изначально плохо тут сделано ну на самом деле четыре таких вещи ну вот много красных крестиков собственно 1 это все наши фронты когда стало больше пользователей на bio и пинтах а хороший bio инструмент но он написан на java java любит переполнять и позависать подоить ее поднимаешь снова это downtime понятно что есть engine x есть мастер slave тем не менее второй момент это фронты прием они были написаны изначально намного лучше нагрузку держали отлично тем не менее когда был очень большой всплеск на запись мы просто отдавали пятисотку не принимали данные нам потом по протоколу их пересылали но тем не менее это не приятно ну тоже не очень хорошо иметь вот такой один маленький фронт затем spark streaming возникла проблема высокой доступности все очень просто мы данный отдаем реально организации мы отдаем на сортировочной системой даем выделение отдаем в сервис отслеживания которые вот мы видим на сайте и когда например что то упало ночью аспаркам априори падает то чтобы подняться ему нужны ресурсы и ресурсы все заняты ночным обновлением данных и он просто ждет в очереди пока не займет ресурсы не очень хорошо получалось что иногда какие-то джо бы лежали два три часа потом им надо было обрабатывать всю порцию данных которые за это время накопилась ну то есть не очень хорошо так делать и наконец стал сбоить интерфейс про который мы вообще не думали что он будет сбоить потому что самим производителям кассандры рекомендуется как лучший из quelle доступ к данным это именно использовать sparkasse quelle 3вт сервер который запущен standalone отдельно но тем не менее они рекомендуют у себя и сделать именно так просто под нагрузкой opel vita ржавые the spark он начинал как то странно виснуть начинал падать мы его перезагружать и но опять же небольшой downtime неприятно на самом деле с точки зрения фронтов решение очень простое вот та но тут такой маленькой картинка изображена у нас как раз в команду пришел очень крутой devops который сказал ребята все мы делали неправильно давайте везде вводить контейнеризации что это нам дает это нам дает на нескольких серверах разворачивать абсолютно идентичные контейнеры которые выполняют одну и ту же задачи ну и микс для балансировки на самом деле это решение она очень круто повысило стабильность прежде всего пинта хобби и у которого реально были проблемы в тот момент сейчас у нас наверно порядка 12 контейнеров пинтах обеих и работает одновременно и если надо мы просто в любой момент масштабируем потому что всегда есть сервера чтобы запустить новые контейнеры вторая вещь которую можно обратить внимание тут появилась это некоторый рост out что это такое мы подумали искали если sparkasse quelle spark скальп 3вт не работает давайте напишем свой рост который читает данные из кассандры под типовые запросы отдает нам jison q и это будет работать и как ни странно это лучшее решение по доступу к кассандре то есть если вам нужен es que el до sparkasse quelle 3 в 1 а если вам нужно нагрузка пишите rest который будет отдавать по ключу ваши данные поскольку java api работает очень быстро но тут уже вопрос как напишите все с на этот раз мы тоже сделали виде образов и контейнеров таким образом по сути мы решили все наши проблемы вот на уровне доступа к данным на уровне стабильности пользователей на уровне приема на уровне экспорта к слову на текущий момент и тот же рез который отдает используется всей организации чтобы от нас получать данные если например на сортировке происходит там идет к это емкость они бархат сканером проверяет летит запрос к нам мы отдаем это работает очень хорошо это держит нагрузку то есть лучшее решение просто не могу предложить третья проблема это высоко доступность spark streaming как и сказал что просто джо бы не могут подняться когда занят кластер тут есть классическое решение которые у нас есть в ходу пи это очереди мы просто резервируем очередь который никто больше не может занять и тогда гарантированно наше приложение поднимется но тут возникает другая проблема нам жалко это делать потому что если мы отрезали скажем 20 процентов на очередь под римминг это значит что наша обработка ночная будет не 8 часов а 10 а у нас окно с нуля до девяти утра поэтому нам жалко резать эти ресурсы мы долго думали чтобы с этим можно сделать чтобы стримить бы более стабилен мы добились просто стабильности самих job of чтобы они почти никогда не падали ну скажем 1 месяц они все равно коник / x сваливался и на самом деле решение но на поверхности решение не использовать spark streaming на ходу кластере казалось бы абсолютно нелогично у нас есть hadoop у нас есть yarns парк запускается в ярни у нас есть hadoop у нас есть yarn запускаете spark streaming не надо так делать если вам нужен высоко доступный streaming и тут есть два варианта как это можно сделать во первых у spark streaming есть свои встроенные средства для того чтобы поднять спаркл астарта что называется и запускать в рамках не вот для этого нужно просто энное количество машин и память но нам это было не очень удобно то что иногда мы все же стрим джо бы запускали на основном кластеры иногда на другом нам удобно было оставаться в рамках ходу п орно поэтому мы просто рядом построили еще один маленький hadoop в котором не было дисков в котором по сути было память были циpкa но но диски используясь просто для метаданных дробов для каких-то логов как они работают и как вот это все у пихнул из в железо я расскажу чуть дальше пока про это не думаем но тем не менее у нас появился второй маленьких идут кластер и вот это уже можно сказать почти идеальное решение которое работает до сих пор spark streaming стабильный пинтах а стабильный прием стабильная и кафка отлично hadoop обрабатывает хай вам через t с парком у нас есть версия все работает было так стало так в казалось бы небольшие изменения мы просто чуть-чуть квадратик вот передвинули а на самом деле с точки зрения организации просто колоссальные изменения проблема заключается в том что мы у нас в команде не любим останавливаться на том что есть поэтому мы всегда пробуем что-то новое еще когда впервые появился индекс treehouse на хабре еще когда он не был в upon source мы уже писали ребятам в яндекса не можете ли дать попробовать мы любим все пробовать интересно и естественно мы про пилотировали индекс клик house ну основная цель была попробовать заменить вертик у что мы сделали во первых мы ну понятно индекс recalls хорошая быстрая базу про это много сейчас статей на хабре мы засунули и кликал в докер кажется клик хаос в докер на самом деле мы не потеряли в перформансе специально проводили тесты но это нам позволило на одних и тех же узлах держать у кассандры просто нету родного механизм репликации и нам позволил на одном и том же узле держать фактически основной рабочий узел и для него фактически реплику если надо он просто переключался фактически нагружен 1 2 простаивает но поскольку это на одном узле то все это работал хорошо второе что мы сделали это написали на спарке некоторый универсальный загрузчик данных поскольку если кто-то работал с кликал сам знает что там работает через раз ты там нельзя просто сказать прочитай в ходу педан either dfs а то есть вертите это работал из коробки тут пришлось чуть-чуть постараться причем мы добились перфоманса реально как для верте ки мы фактически создаем распределенную таблицу делим данной исходные на партиции и друзьям с парком в каждую локальную таблицу свою порцию данных это получается реально эффективно провели наши нагрузочные тесты и даже смогли добиться такого же перфоманса как ouverte к но есть один маленький момент когда мы нагружали клик house у нас циpкa сто процентов но в системе это выглядело 3 600 поскольку у нас тридцать шесть ядер но тем ни менее и вот этот окт он нас немножко расстроил расстроил в конце расскажу почему но просто у нас на серверах живет много всего и вот сказать что эти сервера полностью под клик хаусом мы просто не могли себе позволить вторая вещь которая нас расстроило это распределенный join больших таблиц он не очень эффективно тоже работает включалась и тем не менее нам очень понравился клип house потому что мы можем туда загрузить любой объем данных версии мы платим за каждый таро байт а здесь мы можем загрузить любой объем данных если ты уже готовая подготовленная витрина по которым можно сделать из quelle без каких-либо join of the пользователи счастливые у нас этот инструмент вошел так мы его называем свободной аналитика когда мы готовим витрины ну по сути наша промежуточного слоя не отчеты а то на чем строится отчеты и это загружается в кли house пользователей буквально 2050 аналитиков иску или пишут смотрят на те данные которые интересны разбираются что происходит с какими-то сортировочных центрами отправлениями следующий момент это пилотирование fling нам был интересно всегда пробовать что-то новое fling это streaming фреймворк которых soul обеспечивает как они утверждают экзо крилан семантику но нам она не нужна поэтому streaming мы пока не переводим но нам не очень нравится как работает фильм который из с dfs из кафки данный сохраняет ваш dfs бывает там такие хитрые пограничные случаи когда просто он может зависнуть при этом данный будет сохраняться в ваш dfs но будет сохраняться один и тот же объект просто очень много раз причем мониторинг пока мы это не заметили наш первый мониторинг на это не срабатывал то что дано это пишется вот собственно fling сейчас пилотируем чтобы заменить фильм таким образом вот у нас был release 3 а текущая наша инфраструктура вот может сказать релиз 35 выглядит следующим образом появился клик хаос и появился fling на самом деле я рассказывал вам про компоненты и может естественно возникнуть вопрос что мы делаем с данными поскольку hadoop hadoop им vertica вертикально непонятно как мы вообще строим процесс обработки данных поговорим немножко про него наши данные поступают в шину кафка и дальше у нас начинает работать spark streaming spark streaming он читает из кафки пишет обратно в кафку и на самом деле вот этот этап он может повторяться много раз сколько нам нужно отработать данных про процессе столько мы пишем из топика в топик из тупиков топика и делаем это все real-time также соответственно работает фильм который все этапы нашей обработки сохраняет бережная в ходу чтобы у нас эти данные были мы могли их использовать затем у нас появляется кассандра поскольку spark streaming не всегда может работать фактически с одним объектом например чтобы решить нашу задачу матрешки когда нам приходят к это событие нам надо залезть в кассандру и собственно решить графа вую задачу найти все отправления которые лежат внутри этой емкости и вот собственно это делает наши online job и с помощью кассандры естественно в кассандра мы как пишем сохраняем так читаем из нее и точно также наши джаббы онлайн могут отдавать куда-то вовне например в почте есть корпоративной шина который тоже сделан на кафки для обмена всех систем и мы собственно туда экспортируем данные поставляя другим системам теперь как работает batch обработка нам сохранились какие-то этапы обработки хайфы spark у нас много коды на хайве много коды на спарке обрабатывает причем это тоже итеративный процесс все описаны в виде узи потоков работ мы используем везде арк формат и мы фактически готовим в конце некоторые конечные витрины ну плюс промежуточные для выгрузки free calls после того как данные по фитны мы их выгружаем вертик у в клик хаос и в кассандра kassandra у нас данный попадает как от batch обработки так и и онлайн соответст почему так очень просто не все алгоритмы разрешимы когда мы говорим про онлайн то есть скажем у нас есть часть алгоритмов которые дают 98 процентов точности но не 100 который мы можем обеспечивать бача поэтому естественно изба чему все равно выгружаем в кассандру вертик увлекалась теперь естественно возникает вопрос как мы все эти компоненты помещаем на оборудование и решение которым мы пришли очень простое на каждые 6 узлов и дуб кластера data not надо взять ну тут все сервера это 36 физических ядер 2 по 18 256 или больше памяти так на каждые 6 data not нам надо взять 2 кассандра но ты при этом на этих же но ты где живет кассандра мы размещаем все мастер сервис ходу по данным not yarn все менеджеры которые есть все метрики которые собирают но кто ставил и пользоваться hadoop кострами знаешь там очень много мастеров вот все это живет на кассандра узлах и на каждое такие два кассандра узла должен быть один условно кафка узел луковка vertica и на этом узле одновременно живет кафка которая не требуется полу но ей нужен диск верте к которой нужно немного цикл и побольше диска клик house которым нужен много диском много циpкa spark streaming vostro которым почти не нужен циpкa не нужен диск но нужна память и на самом деле это прекрасно все уживается вместе на этих серверах и понятной еще есть примерно 0 5 x серверов от этого количества это наше фронты где размещаются виде докер-контейнер of все раз ты наш bio и все внутренние сервисы которые нам нужны таким образом мы легко масштабируемся когда у нас происходит там раз примерно в год происходит закупку оборудования мы как-то масштабируемся но всегда сохраняем вот эту пропорцию таким образом что же было показано сегодня показано единая инфраструктура в который решает совершенно разнообразный спектр задач и те компоненты которые мы посчитали лучшими подходит для этих задач самое интересно что если задумываться что же я рассказал только что я не рассказал про то как устроена почта россии от самого собой но я по сути дал вам конструктор из которого вы можете как угодно миксовать свою собственную систему по те задачи которые у вас возникают не нужно вам свободной аналитика убираем клик house ok нам не нужен streaming точнее наоборот нужен streaming не нужно batch обработка убираем hadoop и все то же самое нам не нужен streaming нужен hadoop все то же самое нас нет задачи доступа по ключу все то же самое не то бия и нам нужно считает только в ходу пи все то же самое берем пользуемся собственно берите пользуйтесь если мне кто-то три года назад показал вот эту картинку а еще объяснил про каждый квадратик зачем он на этой картинке наверное наш проект бы развивался чуть-чуть быстрее что собственно осталось нам сделать хотим fling довести до продакшена сейчас он на стадии такого активного тестирования больше данных поступает соответственно масштабируемся полностью автоматизировать соседи я вообще эту тему никак не за страна у нас управляется по пятам есть контейнеры много на это сделано это просто отдельный доклад может быть когда-то сделаем опять же мониторить хотим все и все у нас очень много всего мониторится используем zabbix еще у нас есть тела сиксерс куда этот логе откуда выгружается строится аналитика все это есть но естественно да с тем покрывать большие различном мониторинга и если это все сделать можно будет тогда вот сказать вот теперь да мы сделали законченный продукт хотя мы всегда хотим испробовать что-то новое всегда развиваемся поэтому что также хотим дальше у нас сейчас в планах построить так называемую дельта лаб внутри нашего продукта где нас парком или других машин миг алгоритмах будем уже решать более не линейные алгоритмы которые требуют заказчик у нас есть сервера где например свободная память поэтому нам интересно все in-memory решение одно из них вот отжимает его связка с ходу пам нам интересно попробовать сработает ли это вообще или не работает ну и джина и тот же great game нам очень интересно как развивается spark в частности в последних версиях там появился spark страх через streaming выглядит это прям очень круто поэтому хотим попробовать и если это будет хорошо работать то тоже внедрим но если кратко spark fracture стрим позволяет скажем за три строчки написать то что раньше было две страницы как выводы хочу просто как такой манифест написать что никогда не нужно останавливаться если вы что-то сделали всегда можно делать это лучше 2 манифест что каждую задачу должен решать свой инструмент мы помним первичный опыт проект за дату хорошая база и и никто не может ругается но тем не менее когда попытались все задачи на нее нагрузить инструмент стал работать не очень эффективно именно поэтому у нас есть crack house и vertica 2 идут кластера потому что под каждую задачу свой инструмент и наконец не нужно бояться вот по сути этого зоопарка внедрять какие-то новые инструменты в свою инфраструктуру если этот инструмент хороший crack house ведь хорошая база надо брать ипользовать просто под те задачи под которым подходят на этом спасибо за внимание если если остались какие то вопросы по деталям подойдите я либо вам успею рассказать либо выдам визитку можно мне всегда написать если интересно как это можно было в скажем у вас проконсультироваться тоже всегда готов ответить на вопросы но сейчас давайте вопросы в конкретно по докладу сейчас игре микрофон и у нас давайте поближе алексей огромное вам спасибо за потрясающий доклад такая концентрация опыта совершенно верно сказали если бы мне дали такое сразу я вот сделал сразу столько шишек можно было бы избежать просто преклоняюсь перед тем что вы сделали сейчас это потрясающе меня походу занесла сразу три вопроса я как раз тоже на этом пути сейчас но только на начале этого пути и вопрос первый и самый наверное главное когда вы начинаете почему вы остановились на хортон works вы сразу знали что это платформа с тест удобно работает или это просто было решение заказчика на самом деле тут получилось так я могу сказать что мы хотели выбрать хаев стрезам потому что это хорошо неправда мы выбрали хортон works потому что там был storm который мы в итоге не стали использовать но тоже там есть тсн то есть на текущий момент я не думаю что нужно выбирать что-то кроме хардин works если вдруг у вас хорошие отношения с колдера и и у вас есть уже решение откуда-то сверху что стоит колдера то надо тест прикручивать но hard in words по всем текущим нашим ожиданиям просто особенно нам нравится как он развивается то есть например сейчас по дефолту все компоненты в хортон ворксе выходит быстрее spark 2 там появился намного раньше чем в кальдере хотя потом они прикрутили и вот именно этот опыт по обновления мы стараемся всегда обновляться на свежую версию нам очень нравится да то есть я так и предполагал что система изначально выбрать сразу то что нужно это пролезть невозможно этот путь он в любом случае будет тернист в начале знать я так понимаю нереально второй вопрос связан вас появилась на картинке с релизом 3 скуп не появилась на первом-втором почему просто на самом деле такая маленькая часть просто нас появилась база прогретом появились данные нам надо было их в рфс тоже выгребать и мы это для этого использовали скуп и третий вопрос проверьте q vertical ведь можно использовать до 1 терабайта бесплатно чисто как быстрый доступ к данным которые хранятся можно мне мой что вам этого было недостаточно вот в чем здесь проблема я так понимаю что у них там есть рост контейнеры и это ответов одна из проблем которые здесь нет никакой проблемы если у вас данных меньше терабайта три узла справляется идеально если у вас данных больше одного терабайта вы думаете как купить vertica но данные же в данном случае в вашем случае не хранятся в вирте ки они хранятся до на нар шадаа на наших витрин больше 1 терабайт у нас сейчас порядка десяти терабайт именно витрин которым пользователи обращаются спасибо большое такого там алексей спасибо за доклад отдельный респект за паппет два вопроса первый чем мне фильм понравился и второй вопрос как этот зоопарк уживается с кем брусом kerberos у нас только в планах поэтому пока не уживается ну по и говорю в отдельный доклад можно делать про наших devops of any fi на самом деле интересный инструмент но мы пытались решить задачу сохранение ставки в dfs и он нам поладил много мелких мелких мелких файликов то есть нужен был еще какой-то этап который соберет и уже кучками по 100 200 мегабайт разложат ходу пи чтобы это обрабатывалась эффективно флюма это делает из коробки fling сейчас делает это из коробки только поэтому там затем не доходит алексея спасибо больше вопрос такой когда появился cliff house in the h заменился на некий cliff house фронт что это такое это вот это не пинтах он остался кликал фронт это алкан source разработка есть вот в git лобби на хабре была статья про это мы просто его прикрутили поставили чтобы пользователи могли писать es que el к данным включался в некотором в fronte еще вопрос такой сколько человек в команде был из секрет который лайк или сейчас было и сейчас было четыре разработчиков в начале пятнадцатого года сейчас нас 36 человек не все разработчики это аналитики тем лиды и архитекторы тестировщики ну то есть вся большая команда спасибо ну или маленькая команда поставить ими александра зовут найти от меня такой вопрос россия это самая большая страна в мире у вас отделение которого обслужите по всей стране на понимаете чему я клоню географическую доступно и сетевые разделение и вот как бы как удалённые клиенты работают системы все находится в одном да центре я так понимаю в каком-то в москве там или еще где то как быть с дальним востоком они передают нам данные какой ли пенсии идет речь полсекунды секунды а секунды секунды нам сам вот именно на данном этапе real-time не важен ты скажем задержкам минуты передачи это тоже окей самая прелесть то что основную задержку по передать сейчас обеспечивают производственные системы потому что наш фронт он принял записал в кафку ответил og нас это полностью устраивает поэтому просто мы не сталкивались конкретно с этой проблемой и второй вопрос вот в частых ранением в ходу пи количество объектов у вас ходу фидера это не фидера этот обычный необычный иметь очень честно не очень не можете чуть ну что ходу питом бы ограниченные ваши и начал с тем ограничен в общем случае объемом памяти 1 машинку штанов весь индекс ранит в памяти у нас выпада влезаете пока влезаем у нас основная коллекция 100 миллиардов записей правда она растет вот например 200 миллионов четыреста в сутки но есть много других коллекций примерно такого же объема но тем не менее 100 миллиардов файлов у вас нет 100 миллиардов объектов поскольку мы файлики раскладываем эффективно блоки по 100 200 300 мегабайт у нас именно количество файлов небольшая но ты про туда и именно что количество файлов ограниченной памятью подамажил у нас просто не возникло такой проблемой и даже близко то есть памяти очень мало на и много потребляет я понял спасибо алексей добрый день спасибо за доклад меня зовут юрий мы тоже что-то очень похожее делаем себе и вопрос в том что очень красиво действительно масштабируемой гибкой архитектуры а думали ли вы в сторону того как на не строить дальнейшую аналитику разработка сопровождения что у вас плане куда куда-то линович governance на самом деле это будет смежные проекта не совсем у нас но в почте поскольку в я рассказывал один проект все что последнее изменение трех-четырех лет это не только наш проект есть десятка два других проектов так называемые новые продукты там до задумывается править и задачи у нас пока просто не возникало нам не ставили мы именно проданный сейчас муки спасибо можно вопрос вроде спасибо за доклад его вопрос вот такой вы рассказывали про сохранение в сетов esports стриминга искали что вы используете пост греда вот насколько это быстрее чем за кипер то есть замер проводили и ну скажем так глазом видно ну то есть мы специально тестов не проводили но это в разы быстрее сам spark у них если почитать на коммунити они рекомендуют при доступе кафки использовать именно direct stream copy потому что он просто в разы быстрее выгребает данные и никак не завязаны пир у меня тогда вопрос если я правильно понял у вас на одной тачки совершенно разные системы стоят там кассандра sports тримминг но это же приводит и к проблемам из вы теряете тачку одну вы теряете прям в разные узлы в разных по system of the seas там отказывают практически ну разные совершенно несвязанные часть на самом деле все очень просто если откладывает до то надо мы потеряли дата но дано мне страшно если вы вы совмещаете на одну да да да если отказывает кассандра но да где какой-то мастер сервис к дупа мы это мастер сервис переносим на другой кластер блага эти операции все автоматизированы в хортон марксе и живем дальше радуемся то есть причем все мастер сервисе за дублированы всегда есть мастер всегда есть свои вкусы что они переключились то есть тут тоже проблема никакой не возникает в кафки чуть сложнее мы теряем кафку но доверьте кино дублик хауса и надо spark стриминга на тем не менее тоже проблем некой не возникает потому что все компоненты которые тут используются все за дублированный все отказоустойчивые потеряли часть экзекуторов spark стриминга поднял новые компьютеры пошел работать на других узлах то же самое cliff house отлично живет без узла у него просто на другом узле возникает к это реплика vertica отлично у нее есть свой встроенный механизм ребриков кафка вообще идеально живет поскольку мы когда создаем только говорим сколько реплик нам нужно да мы теряем сразу энное количество компонент берем восстанавливаем вопрос смотрите говорили то что у вас не получилось online streaming там а что им ничего не хватило на смысле не получился то есть вы дублируйте все равно потом через ходу по дополнительно что-то вообще the ticket витрины а но собственно задача матрешки наша любимая что такое задачки матрешки это развернуть ну задача поиска всех путей в графе вот какой-то вершины до всех детей но в данном случае отправлений и когда у нас есть этот граф нам приходит события это прекрасно мы задачу решили но когда нам пришел события о каких-то цепочек в графе нет нам по сути надо тогда отдельно обрабатывать когда пришел какая-то ребров графе смотреть а на какие события в прошлом это повлияло в батчата легко в стринги не надо так делать вопросу то что вы так вы собираете данные из всех отделений и почты на он приходилось решать проблемы то что там где-то общения в интернет и не знаю не там где то опять же эти проблемы не мы решаем есть отдельные продукты которые занимаются именно софтом выделение которое нам должно послать данные соответственно это их проблема ну оффлайн отделение работает просто через флешку взяться flash каску это задержка она идет ближайший там почтамта словно откуда уже посылается данные спасибо в 10 вопросы да добрый день спасибо за доклад но я здесь вот но уже на самом деле вот прям предыдущий товарищ за тут вопрос которые были интересны тогда немножко другие спрошу скажите пожалуйста как примерно мониторится вот такой вот шикарный зоопарк в самой инфраструктуре вы на своих средствах это на своих мощностях этот luxoft размер цели это в честь прочный вся почта с когда я говорю про это это все прочие эту всю дата-центре почты известно центры почта и есть zabbix соответственно есть агенты которые мониторят каждый компонент отдельно пишется подняла метрики скидывается в zabbix grafana для визуализации на самом деле все как везде и с учетом того что они все обрабатывают иногда одни и те же да мы каким-то образом данных вы имеете ту бизнес мониторинг именно данные или сами инфраструктуру ну да бизнес бизнес мониторинг мы просто в ходу мы уже строим у нас есть некоторый набор отчетов по бизнес мониторингу где мы проверяем что streaming на считал что бочки это корреляции например вот тот же самый streaming который у нас разворачивает матрешка у нас есть некоторый условный те job который считает разницу чтоб понять что мы не дослали streaming что надо еще им передать в tracking ну то есть все делается в ходу это спасибо еще один вопрос так вот в контексте того что обсуждали прямо предыдущем вопросе есть ли у вас предполагалось ли у вас на этапе начальной эксплуатацию там первого релиза какая-то сверка с системными источниками потому что но именно я просто немного участвовал в предыдущих проектов почты и там были проблемы его на связанные с тем что систему из время проблема просто то что в отделениях раньше стояло много разного софта сейчас идет общая такая замена на там один софт и оттуда мы напрямую например выгребаем данные и сверка будет но когда-то позже этого сильно этапе я имею доступ когда мимо на тестировалась это изначально говорит эксплуатации не было проблемой поэтому сверкать здорово хорошо спасибо вам закончилось время то что надо дать слово след чем и за клатч докладчику давайте если кому то интересно вот вопросом и сейчас вот туда в правую дверь я выйду ну и раздам визитки если кому интересно чтобы можно было мне написать спасибо от шоссе большая"
}