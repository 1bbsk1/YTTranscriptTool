{
  "video_id": "RoCRkSXEkl8",
  "channel": "HighLoadChannel",
  "title": "Искусственный интеллект в разработке ПО: современные технологии и перспективы / Егор Баранов",
  "views": 2192,
  "duration": 2781,
  "published": "2024-12-25T05:39:52-08:00",
  "text": "Всем привет как меня уже ранее представили Меня зовут Егор ранов я архитектор решений в продукте гига код Я ассистенте встроенном в среды разработки и помогающие ускорить разработку по ревью кода покрытие тестами и различные прочие возможности поговорим о том о чём в принципе у нас сегодня доклад А сегодня у нас доклад такой обзорный с погружением в архитектуру то есть мы по верхам пройдёмся в принципе по разработке при помощи искусственного интеллекта по ассистентам но при этом углубился в их устройство как бы можно сказать соберём по частям типа своего Ассистента в какой-то степени Вот то есть затрагивая технические аспекты архитектуру и так далее вот ну и основные моменты просто ки поинты типа какие у на О чём будет в докладе говориться как бы да Первое - это углубление в устройство и систем то есть там компоненты составляющие Ну понят архитектур диаграммы следующее сбор контекста раги прочие модные слова вроде Calling мо агностик следующее конечно про будущее Поговорить то есть когда там нас искусственный интеллект заменит всех разработчиков что будет дальше происходить какое будет развитие систем как одного от другого отличается вот тоже какие-то тут слова интересные и следующее это в принципе реальное причины стоит вообще искусственный интеллект в разработки использовать то есть зачем это вообще всё надо да давайте сначала познакомимся кто вообще использует ежедневно и в работе можете поднять руку То есть я думаю большинство Да а кто вообще не использует но хотел бы или не очень хотел бы то есть Вообще никогда не использовали не занимаетесь этим Да Окей А есть кто-то кто разрабатывает ассистента есть какие-то конкуренты Тут у наши Да понятно запомнил да Ну окей Давайте тогда думаю для всех из этих Груп будет что-то интересное в докладе по крайней мере постарался э чнм в принципе с того как у нас вообще разработка устроена то есть из чего Она состоит То есть тут разработки представлен то есть такой цикл условно каждый из которых в той или иной степени как бы на людей завязан то есть условно как мы погрузимся в проблематику задачи без человека вмешательство Да и там структуру спроектируем ревью пройдём и всё такое Для всего этого нужно много человеческого внимание ресу стамен будут ссылочки на разные перы на разные вещи их можно не фоткать потому что в конце будет QR на github куда я все эти ссылочки залил и презентации вообще все сосы оставил поэтому Это скорее для потом чтобы для ознакомления тех кто будет виде файла смотреть так вот Вот он Life cle по всей этой разработки все этой истории Ну и конечно же идея в том что можно все эти этапы и интегрировать и их как бы ускорить в той или иной степени тут конечно по написал тоже много модных слов которые мы чуть позже разберём сейчас там всё как бы засчитывать сходу не буду но грубо говоря там на примере просто разберём допустим Погружение в проблематику задачи да то есть что такое проблематика задачи глобальная её может и как бы разобрать потянуть нужные сарсы как бы погуглить чат гпт какой-то вызов условно сделать но только на уровне какой-то полноценной системы которую мы интегрируем наши процессы Ну само собой любое место Где написаны тесты там руками вместо того чтобы руками писать мы это яичко пишем отладка работы de Баг и так далее и так далее по всему этому мы конечно же пройдёмся на следующих слайдах вот начинаем немножечко разгон так как мы будем тут заниматься немножечко таким дизайном по дизайном Я имею в виду только архитектуру только проектирование систем никогда не имею в виду слайды с каким-то ЮА хотя их парочка будет просто для наглядности Да но когда я говорю дизайн Я имею в виду архитектуру так вот мы хотим допустим собрать своего Ассистента А какие у нас вообще критерии то есть на что мы ориентируемся Чтобы это сделать если мы хотим в принципе любую и систему да В особенности для разработчиков первое конечно скорость генерации то есть Нам нужны быстрые модели чтобы они быстро отвечали чтобы у нас минимальная задержка была и она нам в работе не мешало быст быстрый текст печатался и так далее быстро какие-то проверки проходили следующее само собой размер контекста Мы хотим подать все весь возможный контекст это и проект и github и Overflow какой-нибудь и всю нашу документацию всё что мы там сами по напишем а данные с компа нашего Ну если мы конечно хотим этим делиться Да следующая точность Ну чтобы мы спросили нам сразу нормально ответила нам не приходилось что-то уточнять как бы тоже связано с размером контекста и тем насколько много инфы даём всей этой истории Ну следующая Ну стабильность чтобы не падало Но это понятно генерации нормальные чтобы были Ну и масштабируемость это больше с точки зрения дизайна чтобы могли модельку подменить потому что каждые пару месяцев что-то новые выходит мы как бы чтобы могли их быстро заменять и чтобы наша система не была супер зависима от моделей то есть Может быть Какой формат низации может меняться Да но про это тоже чуть позже поговорим так вот начнём про и ассистенты на сегодня какие у нас в принципе эпохи есть да всё началось там с No Assistance Многие так до сих пор разрабатывают Ну в этом чате конечно меньшинство так но всё равно остаются как блюди которые разрабатывают без и это стандартная разработка там автодополнение той же идея какая-то ещё история То есть просто мануальный девелопмент такой А потом появились первые ассистенты тут как бы указаны модельки сколько параметров какой контекст А тогда был чисто автокомплит потом чатик ещё добавился то есть это можно там 3-5 лет назад там как таб его старой итерации когда он по-другому ещё назывался Капа это первая итерации там гига код когда он там прототипом только был Это был чисто код completion эта Эпоха как уже сменилась на новую А на C Creation Это история когда всё завязано на генерации кода на создани какого-то UE на генерации возможностей на генерацию инфраструктуры какой-то и тут тоже слова которые мы тоже разберём интересные примерно размеры моделей и эта Эпоха подходит к концу а что будет дальше поговорим чуть позже вот так вот из чего состоят у нас в принципе системы такие я выделил три компонента А тут Client Application может быть ещё Веба может быть любая другая ишка Я чисто для примера привёл это клиентское решение про все Сейчас подробнее поговорим разделы следующее - это так называемый retal pipeline То есть это по большей части работа с контекстом обогащение тонизация то есть вся такая логика и плюс вся бизнес логика находится примерно в этом месте интайм модели Но это сами мки железки exec какой-то выполнение их работы стабильность и так далее распределённые запросы И сейчас мы разберём каждый из этих компонентов По отдельности начнём с клиентского решения само собой тут такая диаграмм текст мелкий но не весь нужен Я всё текстом Ну как проговори можно прям супер не вчиться Это скорее опять же для тех кто будет са потом презентацию просматривать у нас как У нас есть Ашка у нас в неё там ставится Ну чаще всего плагин какой-нибудь Да если у нас не какое-то решение Да ну там примерно тоже самое просто кодс посложнее доступ происходит это кодовая база проекта наша пользовательская у нас там может быть локальная МКА поэтому она пунктир ком у нас могут может быть модуль работы с контекстом локальным какие-то индексы которые мы строим поверх этого контекста ну и обращение идёт в pel соответственно то есть соседний модуль в котором тоже разберём комне системы скорее ну и может быть семантический поиск тоже реализован в рамках проекта вот ну это из таких если супер поверха смотреть как примерно выглядит эта вся история Из каких компонентов состоит Ну и там плагин там ючи всякие подсказки и так далее тоже всё это разберём пройдёмся по этому чуть позже Да разберём парочку просто технологии которые можно реализовывать для того чтобы оно всё нормально работало начнём с того что такое рак вообще многие Я думаю знакомы А кто вообще знаком с понятием рак А кто писал ра пайплайн какие-то свои или какие-то возможности для этого ну ну короче Да примерно все те же люди Да ну то есть рак для тех кто не знает это retrial Generation то есть грубо говоря это кастомный провайдер доб контекста для нашей генерации если так можно сказать прямо супер-пупер абстрактно если мы про это говорим Да И вот мы сегодня будем много говорить тоже про контекст про то как с ним работать как его доставать Да тут примерно показан принцип того как у нас работает клиент сайт локальное доставание контекста То есть это мы берём cbase берём сорс проекта их там индексирует на чанке чтобы м было по нему было удобно ориентироваться сохраняем индекс локально в случае реализации Ну там стро динги всякую такую историю делаем Ну потом Можем по ним быстренько искать всю эту историю как бы мать и подавать уже расширенный контекст в retal pipeline Ну для выполнения запроса да ну либо реализация на сервере тут уже чуть поинтереснее тут мы это переносим на к для этого мы должны прогонять через него сарсы строить по ним индексы возвращать индексы на клиента и Клиент уже по ним там всё строит и сам уже поиск производит э либо ещё может быть Интересная история если у нас реализован будет менеджмент сессий то в таком случае мы можем в принципе на бке в рамках сессии эту историю рить если пользователь не против и там хранить в принципе индексы правда это на много памяти съест но я думаю не страшно Зато можно будет на блокноте запустить если блокнот умеет данные свои передавать файлики на индексацию да ну тут опять же это больше для такого изучения есть если кто-то будет смотреть сами сорс тут Нам просто надо понять что такое тоже есть из основного дальше перейдём к следующему модулю это pipeline а так водички pipeline то есть непосредственно слой между нашим клиентом буде то плагин Web там UI что-то ещё интайм моделей там обычно вся бизнес логика весь вся обработка контекста роутинг моделе по каким-то бизнес правилам нарезка токенов подстановка промто то есть вся вот эта вот история Ну и раги дополнительные про которые мы сейчас тоже про парочку поговорим про эту историю Ну и S Management который как бы уже чуть обсудили Да тут плюс-минус написано что где можно индексы там в кэше in Memory хранить А и всё такое ну идёт как бы обращение это так уже всё по верхам Да разберём пару примеров Generation что же можно тут добавить в наш контекст чтобы мы могли больше количество данных оперировать Ну первое - это рак над кодовой базой конкретно github потому что там нужно очень много даты чтобы это работало подробно объяснять не буду пепер прикрепил а тоже много информации в интернете грубо говоря на байты Режем дату с гитхаба потом по ней эластик запускаем с алгоритмом там хш Или какими-то другими Шами Главное чтобы были равномерные кэши и нормально нам как бы UE доки дылицы будут и так далее Ну примерно такая история то есть грубо говоря можно обогащать контекст трам И это не супер сложно делается идейно как бы да В такой реализации с ластиком Также можно не только над кодовым индексом Да над какими-то ещё произвольными документами строить Рак и подавать оттуда данные Ну тут пример как бы внешних документ confluence Overflow всякая история тоже стром Ром чанки нарезаем на них индексы по верхних сумарин ков проводим Когда нам это нужно в некоторых сценариях когда мы допустим код хотим в чатик прогнать эксплей Да ну и прочая другой стория и ран снив точно такой же примерно то же самое то есть мы можем как и документы так и github так и наши произвольные источники данных то есть многие говорят допустим типа а как нам дооб учить модель чтобы она как бы умело с нашим данным пользоваться А вам обучать вам нужно просто к ней нормальный провайдер данных сделать который выдаёте из которого можно доставать спеты если моделька хорошая про это тоже чуть позже будет она сама со всем этим будет работать и вам как бы вы можете просто чистую модельку взять какуб либо оную либо какую-нибудь гпку и она спокойно с этим всем справится без добу потому что до обучения это как бы Бинар туда Бинар сюда по итогу он разе и непонятно что с ним будет ну и последнее ранта моделей слой тут больше будет про выполнение про железки Ну так чуть-чуть пря угм парочку слайдов просто приме берём грубо говоря есть у нас ранта моделей это среда это железки тут у нас МКА она завёрнутые inference inference - это Процесс получения данных с модельки То есть как как Data extraction грубо говоря такой получается вот у нас там есть кэши про кэши тоже чуть-чуть поговорим прямо совсем по верхам ногу просто понимать есть МКА обёртки используется как кэш при генерации и мы туда ходим говорим типа чувак Дай нам пожалуйста данные от мке Мы хотим их получить Ну и он там его задача - это максимально как бы по ресурсам побыстрее всё чтобы отработала и по токенам корректно вернулось и так далее без артефактов Ну и разберём что тут можно интересно разобрать разберём просто парочку кейсов параллелизма как эту штуку можно скери Ну просто чтобы для интереса Как же оно скери интересно вот Первое - это ПАЗ на уровне запросов Да история Когда у нас есть несколько нот и мы по ним уже н распределяя нагрузку то есть размер Пула который процес Дай момент Ну лучше конечно Картинку показать Вот она Да тут как бы типа несколько Да я так нарисовал Чтобы не засорять сильно схемку Ну и роутер тоже как с репликами идея в том что мы подавая Нау этот мы уже как бы область Мом одного ти чаще всего просто по репликам деления происходит Ну и он представляет из себ типа как балансер такой который просто умеет с данными работать Типа такого уже более высокоуровневый тинг предоставляет Ну тут всё стандартные кши пайла модельки ГПУ то есть всё уже как налы слайдах сэто у нас прям супер большая моделька А в там видеокарте у нас 80 гигов видеопамяти либо нам нужно очень большую видеокарту взять Либо мы их несколько объединим и запустим модельку ну и плюс не на все модельки существуют видеокарты в которые они влезут если это не какие-то супер кастомные решения да то есть Нам нужно использовать технологию nvlink которая объединяет несколько пушек в одну среду Как как бы ну и как бы видим там unifi R environment условно мы там взяли несколько пушек Илин объединили на них распределён ноду сделали с объединёнными решаем пошана и запустили там 45Б допустим модельку то есть И хотя наше желез до этого не позволяло Мы конечно же потеряем потому что это виртуализация там какие-то потери будут Но мы её запустим то есть тоже как бы достижение определённого рода и может быть обратный сценарий Когда у нас наоборот очень маленькие модельки у нас только одна видеокарта больше мы купить пока не можем и нам нужно какой-то mvp запустить или где-то развернуться в контуре чём-то где не так много видеокарт тогда мы наоборот юзаем разрезаем её виртуально на несколько и там уже запускаем маленькие модельки допустим я тут полторашки по запускал на пу это тоже слой типа виртуализации тоже мы там что-то потеряем но зато во-первых мы получим отдельные ши на каждую ноду во-вторых мы сможем глобально их запустить по-нормальному В отдельной срет можно запустить самом без этого минус вот Итак вот что у нас было изначально Какие основные компоненты и мы их разобрали подробно вот мы Cent Application разобрали вот мы pel разобрали вот мы разобрали тоже самое только верхнеуровнево опять же в конце будет можно всё будет детально посмотреть почитать и изучить Да так вот вернёмся к нашему ближайшему будущему чуть заправлю так вот бли будущее вот у нас д четвёртый год кончается на схем Да а что дальше происходит где мы Мы во-первых здесь мы находимся между C Creation и supervise automation условно говоря это уже мультиагентные системы генерация проектов Это история когда мы переходим от того что у нас ассистент к тому что мы становимся ассистентом для Яшки и помогаем ей писать уши код и наводиться просто где что находится и резол её какие-то проблемы которые у него возникают то сейчас по крайней мере в в самых современных системах мы как бы ээ ищем какую-то г нас возникает проблема трудности мы к ней Обращаемся И всё идёт к тому что постепенно мы всё больше и больше задач на неё перекидываем в конце она уже какую-то задачу решает Здесь всё понятно потом становится сложновато и Мы уже идём ей помогать в какой-то момент Ну тут примерно Эй моделей уже контекст такой есть уже количество параметров есть уже как бы всё это реализуемо просто как бы нужно рынку время чтобы всё это качественно сделать и настроить тут не столько в модельке упирается история Ну и Full automation 2050 год чисто мой плюс Пепе плюс всего что я читал плюс-минус по графикам по крайней мере того как модели развиваются и скеля если говорить про параметры тут не столько параметры ляют сколько как уже ранее проговорили качество рага и ещё парочка интересных вещей но модель как бы тоже конечно роль играют тут как бы их параметры для этого и указаны вот ну я Super То есть это автоматизации Вообще супер крутой супер хорошо работающий Да к полной автоматизации переходим в эпоху aen develop то есть уже как бы у руля если можно так сказать Да мы уже ему помогаем и всем таким занимаемся Ну и что такое вообще aen Давайте разберём еще возможности ассистентов что затронуть хоть чуть-чуть эту историю и плавно подберём к тому как из этого произрастает пер сама стада вость это бы автодополнение кода с которым думаю все работали а кто кстати работал во-первых с автодополнение Я думаю большинство А с чатом допустим типа который в проект индексированные дополнение и потихонечку придём как раз UB спарку и прочей теме да пер дополнение Ну Я пример привёл потому что мне нравится как у них сделан ent Прикольно реализована вот это их то есть короче платная истории не прямо встроены вшку Как работает автодополнение ничего сложного делаем Запроси там определяем тип комна только из интересного тут од МЧ это когда мы в рамках одного файла несколько подсказок сразу даём в разных местах но позже мы придём к тому как делать это по всему проекту а не только в одном файле Ну запрос модель там ничего интересного и отображение в контексте Ну если у нас мультиком они нам могут как ди вернуться а не как продолжение строки тогда мы на клиенте должны будем эту штуку почить и отобразить вот следующее возможности дальше идм чатик Ну многи чати работали контекст проекта и там поговорим Что такое короткие команды обращение к агентам так чучуть по верхам прямом примерка пайта истории видим в поле ввода Type fors это как раз и короткие команды грубо говоря пром холдеры но под которые вы можете При желании любую бизнес логику засунуть если как продукт разрабатываете грубо говоря чатик с контекстом проек работающий обрабатывающий ваш код и прям хороший чатик он вс знает к нему можно контекстом там хорошо оперировать и так далее вот Ну и как он устроен схожая схема сильно в детали углубляться не стал два момента интересно пайном Первое - это если команда мы её протом заменяем можно конечно же и каким-то вызовом произвольного Агента и какой-то дополнительной логикой но так лучше не делать Ну то есть именно сния потому что для этого есть собачка мы чи Ну например собачка я допустим вообще люблю просто написал команду там оно само всё поняло Что делать Да написали собачку это Агент мы к нему обратились допустим там знаю идж да И говорим и команду и он сам понимает что нужно свать команду там какой-то моделька идёт в пешку какую-то логику выполняет то есть сам уже с этим разбирается Вот и тут Примерно как это всё выглядит то есть доставание контекста процессинг и ещё момент который я на схем не стал отображать э история с фш Конгом грубо говоря у вас есть набор заготовленных функций и при запросе моделька сама понимает к чему вы конкретно обращаетесь говоришь ему сгенерирует тесты используя фре такой там условно мокли буу такую и он понимает блин это же функция генерации тестов у неё такие параметры и она как бы парсит ве этот запрос и возвращает вам условно колб функцию которую вы там можете вызвать условно да либо через окошко либо он там сам вызовет Если захочет и как по мне это прико чем агенты и чем команды Но кому как короче То есть это всё-таки более такая надёжная штука и следующее генерация тестов да то есть выносится в окно с параметрами А как правило чем это отличается от то что просто в чатике тесты просить генерировать Ну во-первых в чатике вам просто моделька их выдаст То есть это как как бы текст респонс она их не проверяет Короче она за них ответственность не несёт она что-то там где-то сгенерировал и всё на этом а вот нормальный сделанный тест нормально сделанное окошко с ними оно уже ответственность непосредственно Нет это кодиум бывший Да сейчас кудо не путать с кадем да потому ведьмы Дин сделали на самом деле я посмотрел рынок думал почни Уго не реализовано на самом деле много у кого включай как бы наш продукт тоже реализовано окошко генерации тестов В чём отличие от просто попросить сгенерировать Ну во-первых там под капотом па полноценный есть мы сгенерирован кандидата типа тест То есть у нас есть много кандидатов один из которых станет реальным тестом если генерируется в конце концов мы его Валиди мы его компи либо на бке Если есть возможность либо о Ну скорее о потому что всё-таки там окружение определённое есть имы Так гоняем условно сгенерирован дата проваливались история в том что эта штука ей можно количество каких-то Раев поставить количество запусков каких-то проверок условно написали код хотим тестами покрыть перед Ром потому что иначе ВМР не даёт потому что каже нету мы нажимаем генерируем тест для всего проекта где их не хватает там сам разберись либо лучше конечно же когда это по фу то есть по изменениям вашим чтобы ничего лишнего не генерить помимо этого а то будет сложно ревю потом но всё же да пошли кофе петь пришли Ну в идеале всё сгенерировать тестами всё О'кей вы проверяете просто код лидирует Если вы конечно не доверяете решению которое используете в повседневной работе да А ну и потом у вас как бы каверы всё бесплатно сэкономили время отличная штука как бы чатик спросить тоже хорошо работает но всё-таки у вас же бывает такое что вы типа код сгенерировать он там ошибку выдаёт и вы подаётся там а условно там фикс а сарсы сами и ошибка и он там их фиксит это тоже Ну это оно само делает Оно ещё и понимает там Что за ошибка ну то есть за вас так по-хорошему вся генерация должна работать в идеале Да ну и последняя возможность композер которым как видели пару человек только пользовалось А да Это история типа курсоров ся но уже адаптированная рынком потому что многие уже это делают вкратце под композе подразумевать будем многофайловый редактирование То есть это когда мы попросили что-то сделать и он это реализует в рамках всего проекта то есть несколько как бы несколько файлов редачить везде изменения заносит то есть условно говорим ему там сделай там тёмную тему он там везде доработку такую делает доработку такую делает ещё что-то меняет или там переделай компоненты на новую версию там UI он там всё переделывает по какие-то дср делает ещё что-то ну выглядит так да первое чатик окошко с композе где мы с ним общаемся Как в общем чатике но приятно открывается кстати заметьте ила оно прямо в дито открывается прямо на в окошке с редактором и перейдя на сед вкладки можно посмотреть сами редактируемые файлы вот что в них поменялось там применить применить поправить и так далее Ну в целом нормальная история ну выглядит примерно так то есть сейчас будет похожая диаграмм на эту потому что там есть интересный момент перехода между эпохами тоже при помощи этой истории подаём инструкцию процеси сарсы проекта строим индексы эксплей то есть объяснял чтобы оно как типа вот код запроса ба он прямо пишет ти это запрос в базу и поэтому производит по этой истории находит файлы подходящие и потом уже там их Реда и понимает как нам по команде конкретный файл то есть главное сначала Первое это определить файлы которые мы редактируем А второе что мы с ними делаем непосредственно Ну и примерно про вот это вот ВС история Вот это заключается вот Ну и как выглядит у нас по итогу вот мы обсудили выт плюс-минус на самом-то деле то есть многофайловый редактирование мы подали команду отредачить несколько файлов в проекте желательно там всё что возможно и подали как можно больше контекста всей этой истории А ну пока таких систем Именно прям судл не так много потому что по-хорошему нужен не просто композер А ещё и генерация кода То есть это во-первых много файловое редактирование во-вторых генерация проекта по запросу это тоже отдельная история как бы которая типа похожа в какой-то степени но не совсем Это скорее какой-то пайплайн с валидации есть github Spark это превью истории от гитхаба в которой плюс-минус такой прототип есть но на сайди preview пока что даже у гитхаба но уже исследования на эту тему различные ведутся и поэтому думаю вскоре мы сможем такую ai историю перейти даже локально в ашках Ну и что у нас после aen девелопмента котом про котором поговорили идём А у нас идёт Ну само собой Да замена как бы Многие говорят разработчиков на самом деле только больше работы станет а потому что больше систем просто будем делать банально после этого как бы да какое-то такое развитие прогресса можно сказать в какой-то степени Да полностью онона система которая Сама решает задачи сама всё сделает мы ей сказали сделай мне сайт такой-то такой-то она делает Говорит нормально ты говоришь там типа блин я не это имел в виду я хотел что-то другое или там Я хочу ещё какие-то правки внести и вот про это э история чтобы в неё углубиться пробежимся прямо вообще по мульти системам Что такое мультиагентные системы кто с мультиагентной Но грубо говоря Агент это просто такие абстрактные сущности будь то МКА набор ЛК или просто какое-то поведение мки Если мы говорим типа веди себя Ну кто-то же пробовал типа сказать Типа можешь вести себя как там сеньор разработчик И я тебя обя МКА либо вообще что угодно то есть условно какие-то абстрактные сущности и мы их им уже там жонглирующий общались то есть типа Ты им говоришь задачу и они с друм обсуждают там этот Агент они в конце такие агенты договорились они короче шили что вот это вот происходит Ну примерно про то же самое только в рамках системы Да ну модула агностик - Это скорее подход такой Э где мы абстрагируйся от того какие у нас модели внутри находятся А вот и просто если у нас модель там качество 4о может быть чуть пониже можно использовать Да мы их уже туда Просто подставляем и можем от них в какой-то степени абстрагироваться и использовать их как бы в работе просто подменяя на какие-то более большие если она просто в принципе может там типа притвориться кем-то и в принципе она короче у не Cage как бы равномерно распределён а не какой-то прям специфик да то есть перешли от таких острых моделей которые просто доо обучили на счёта на такие которые в целом всё хорошо понимают и могут что-то просто по контексту сориентироваться на месте Ну и как у нас выглядит aet если кто-то Ну то есть сравним это просто с той диаграммой которая у нас была Да вот и iden вот и грубо говоря заменило только то что у нас Mod R Заменил на пайплайн оркестрация агентов то есть из разряда что мы в композере сказали моделька сделает то-то то-то и она такая ну я вернул ответ ничего не знаю там сами уже разбирайтесь дальше что ещё Спросите мы говорим агенты ребята выполните нашу задачу пожалуйста и они там уже сами по себе разобрались всё сделали и уже нам нормальный вариант вернули в идеале Вот чуть-чуть это заеду за время Ага и ну подведём итоги что есть что обще к чему Мы пришли О чём вообще доклад Да что такое A development это грубо говоря код дополнение кода и генерация кода Что такое aen develop это генерация кода плюс кор плю пром Ну это больше для разработчика истории а не для системы Да и что такое у нас devel как уже как бы можно догадаться Это плюс мультиагентной идём мы агентам делегирую ребята разберитесь и они уже там сами с генно разбираются этой историе Ну обзор решени на рынке вот можно тут ознакомиться со сравнением как бы разных продуктов в том числе моего с тем что представлено на рынке тут как бы есть фичи которые мы уже прошли там код comp Chat Test comper и ещё Custom R про который мы типа поговорили про Ну как подметили у нас уже внимательные ребята Что хорошо у нас всё с показателями с возможностями Да ну онлайн чатик лайн чатик грубо говоря чу-чуть не проговорили это как композер но только на текущий файл Вот то есть мы говорим что передачи он там уже сам делает но тоже полезная фишечка такая плюс-минус нуха только покажется то есть прям что-то прям супер композер у них Пока особо нету ну и ещё страничка просто тоже заслуживает внимания То есть я бы сказал пому что я удивился тот же км по фича обходит многих Ну конечно же не всех есть всё-таки среди нас более хорошие продукты да чем но в целом он как бы обходит многие рынка на самом деле много у него но в целом подбираете под свои задачи под иде которым пользуетесь везде обычно ещё может быть что-то иногда вот ну и плюс-минус обзор рыно такой небольшой ну и сейчас много ID устроенным и кто-то пользуется чем-то из этого вообще можете понять руку Кто пользуется Да я правильно понимаю курсором А кто не курсором из этого А типа этим литом ЗМ а нум прико шту только там он пока ещ такой сыроватый но нормально Ну и конечно же IDE тоже как бы можно сказать из коробки работает в Като степени Ну и ссылочки вот и зачем вообще и в разработке то есть Давайте ещё итоги то есть технические итоги подвели продуктовые подвели и просто в принципе вот е МТ вы хотите интегрировать и разработку А может недо может ну так его оставим ещё разработчиков наймём Да зачем надо первое вершина айсберга ну быстрее код генерировать быстрее задачи решать Ну очевидно на самом деле Да следующее уже под айсбергом Да у нас идёт снизить когнитивную нагрузку то есть меньше напрягаться на конкретных задачах которые вам Ну не сильно как бы ресурс требует там тесты пог нери там условно какой-то руды написать стандартные какую-то историю такую сделать и работать с большим количеством контекста потому что как бы всем людям мы всё не запомним в любом случае вместо там петабайт данных конечно же лучше чтобы нас моделька всю эту историю Решала избежать появления ошибок тоже хорошо потому что ну Лим не будет просто дополнительны код проверить убедиться что всё окей Если там конечно много лишнего не будет писать ревю хороший не будет много лишнего писать избежать появления ошибок и последнее это быстрее и проще изучать новые области то есть хотите с чем-то ознакомиться там будет тонн там ещё какая-то история и вы как бы их изучаете при помощи быстрее в Като минут сфоткать тут презентация на гитхабе фоткают смотри ве зал надо надо тут сорс все тут можно вообще можно было не сильно следить и потом прочитать просто всё это То есть можно вообще было не смотреть просто найти ссылочку Вот И там просто всё преза я там материалы закрепил а потом ещё такую чу-чуть факторную версию залью в большем разрешении и ещё там на английском будет версии может что-нибудь Дону пе кинить Вот и конечно же рекомендую крайне голосовать за мой доклад вот Как можно чем больше голосов тем больше вероятность что я ещё тут выступлю когда-нибудь вот и зал побольше дадут Да и зал Вот мои контакты Если что-то нужно будет Вот и отзывы там Жду вот и ещё напомню что доклад искуственный интеллект разработки по современно ногие перспективы чтобы ну не забыли за что голосовать вот ну это был я Егор Баранов архитект решения продукта гига код Всем спасибо большое за внимание а Ну и вопросы временные Да вопросы быстро времени мало дофига Давайте самый конец потом ещё разм после доклада Да спасибо за доклад Скажите сколько Командо Сбере сейчас недр вот этот гига код вообще большинством сбера там идёт там Практически 10 человек количество людей которые интегрируют и пользуются им Вот то есть много команд то есть сотни может команд даже то есть по крайней мере я со сбера откуда только людей не видел все говорили что пользовались А какие метрики вводили и как мерили пользу есть поняли что ускорилась разработка или просто на пальцах Ну не Ну само собой у нас метрики там есть мы замеряем сколько кода и написал сколько кода написал там пользователь какой-то у нас в принципе мы Human Мы в resch заводим То есть у нас прямо куча метрик подхода то есть про это как пепер есть у нас всё по таким рыночным решениям плюс мы там прямо сейчас вообще большую платформу метрик разрабатываем для того чтобы всё это качественно замерять поэтому Ну и оно определённо доки потому что как бы и он либо ноль либо бы какой-то Импакт даёт но даёт на самом деле хороший Импакт у многих задача до 90% если говорить про такую Ну В задачах типа 90% ускорение Ну блин Можно сказать до 100% словно Вы там не не помните как не хотите SQL quy писать Вы говорите с генерис зу генерирует вы как бы писали её 10 минут написали там за 10 секунд Ну получается 99% ну то есть как бы разброс есть главное чтобы максимально равномерное было распределение задач да А ты у дискуссия Давай в кулуарах понял хорошо Ещё у нас НД есть кти ва последний вопрос первый ряд ещё нас стенд есть Ну подойдёшь спросишь 10 ещё у нас прямо да Егор Спасибо за доклад классный и достаточно глубокий А вопрос такой вот в этапе Full automation у тебя было показано что наступает момент когда нужно просто контролировать работу модели когда она выполняет работу за программиста вот вопрос такой как на твой Какие на твой взгляд должны быть качества у того кто будет контролировать или скиллы потому что сейчас вот как разработчик Да я могу доверить э контроль Ну минимум медлу лучше Лиду и он должен обладать широкими знаниями например такими как sec Да чтобы код был безопасным вот какими должен обладать качествами человек который будет контролировать работу мки в будущем Ну если говорить про Спасибо большое за вопрос Если говорить про то там Чем дальше к тем проще должно быть тем ниже порог то есть сначала там какие-то лы Ну условно вообще хороший его должен просто делать заказчик продуктовый То есть как на лансе условно чувак правки какие-то заносит требования Като и так далее вот тоже самое должно происходить потом чем лучше тем на самом деле эта штука идёт ниже то есть смотря что мы и назовём как бы то есть какой-то како момента это будут какие-то учёные в лабе уметь делать потом чем дальше дальше тем больше как бы и как бы с любыми такими вещами едет поэтому Ну хороший Это просто продуктовый заказчик мог не углублять техническую сферу чисто требования это всё делать Вот так давайте вот В центр вы говорили о том что для использовать какую-то переобучения вставлять поэтому это такой рыночный то есть мы используем как бы доо обученый какие-то затюненый расширенный контекст то есть мы всё сразу используем Вот но этот доклад больше про в принципе модели то есть не конкретно про продукт а получается Если больше вопрос о том как именно определяете файлы для контекста внутри проекта и подтягивается ли какие-то дополнительные ветки из github репозитория или дополнительные истории того же самого проекта это уже не к вам а более к вашему стенду к стенду вашего проекта Ну лучше правда казать вопрос да лучше на стенд тут больше про докладу доклад такой абстрактный больше все вопросы можно То есть можно после доклада либо на стенде Да СТ Да после доклада Давайте вот сзади девушка ещё кто вы говорите Добрый день Спасибо большое за доклад Я тоже работаю в Сбере и мы регулярно пытаемся сейчас Заимка код гига чат и такой вопрос как всё-таки гига коду подложить в контекст весь проект потому что сейчас я наблюдаю ситуацию что он вот исключительно по открытой странице там в настройках есть настройка расширенный контекст проекта она по умолчанию выключена потому что пока она тестируется стабилизируется но уже она на финальной стадия стабилизации всё уже хорошо работает Просто нужно найти в настройки и включить Project контекст а ага хорошо работает Спасибо ещ Подскажите было написано что рак в бета-версии гига кода То есть это можно сейчас использовать или нет Ну как раз рак над проектом и сейчас ещё лизм по крайней мере на банк расска уже историю с кастомным рам на кастомную репозиторию но сейчас уже уже у нас хорошо в замерах работает интересно Я поняла спасибо опять же абстрактны вопрос не проду продук можно задать нанде это больше такой абстрактный доклад про И в чате за тоже можно зата Вот давайте вот там два молодых человека по очереди в этой ране кто-то хочет Спасибо за доклад скажите вот при внедрении таких решений обязательно возникает вопрос как ишни ков начинать убеждать в том что то что собирается для контекста из проекта и уходит куда-то наружу не является утеко исходного кодака внм ста и модели ВС на ваше железки ставится внутри у вас крутится без выхода внешний интернет Спасибо туда Спасибо Егор за доклад покрите пожалуйста вот для рага для того чтобы он был прям хорошо оптимизирован нужно нужна хорошая МКА вот как часто необходимо обновлять мку исходя из актуальных или каких-то там данных и насколько это релевантно для бизнеса потому что это довольно дорогостоящая история выставите посредственно какой-то PR с поставкой Или допустим B2B история сонно то у вас как бы ваш Ну продукт который вы ставите и там э проблема тех как бы кто вам поставляет продукт они сами всё заменят саму э сами всю эту историю делают если сами разрабатываете то всегда стоит мониторить рынок желательно каждый там полгода год делать подмены и строить инфраструктуру как ранее в докладе было так чтобы она была масштабируемая и компоненты были заменяемые мки то есть чтобы они в целом хорошо отрабатывали в разных задачах поэтому такая история Спасибо ещё вопросы Давайте вот сюда Добрый день Спасибо большое за доклад подскажите пожалуйста насколько я понимаю вот такие инструменты они позволяют генерировать и дописывать код не в рамках одного языка А в рамках ряда различных языков программирования Может ли при этом одна и та же модель одинаково хорошо отвечать и дописывать по как раз различным языкам или у неё всегда будет какая-то преференция Ну смотря как её как бы до обучите смотря какая модель смотря какие у него показатели может одинаково в принципе хорошо отвечать Каче она в полоне Ну на моих задачах отвечала хорошо одинаково и на Джаве там на питоне и на c+ + Поэтому да может онако может по-разному Смотря когда обучите смотря что какие у вас метрики как бы а так да униж метрик - это скор какой-то просто то есть скор может быть одинаковым там же числа просто Поэтому да может быть одинаковые могут быть Ну смотря когда обучить короче че так в первом ряду вот молодой человек тянул руку если вернуться немножко всё-таки в настоящее по поводу код кошена насколько он честный то есть ну условно говоря если сейчас там анализатор в каком-нибудь там c+ по-честному идёт там разворачивает шаблоны то есть и подсказка там полная честная То есть можно как документацией пользоваться то что с Нейрон ну вопервых технология чуть-чуть которую скоро заменят более но перспективно во-вторых там тоже конечно анализатор в нормальных системах есть которые синтетическое дерево смотрит и всё такое и протокол где под капотом есть Ну и синтаксические конструкции и так далее вся эта история но тут на важно также понимать что как бы время тоже ответа ограниченно то есть М надо типа за 200-300 миллисекунд ответить там ну максимум за 400 иначе там не успеете поэтому тоже всё про валидировать можно не успеть но по-хорошему просто lsp подключить Да и индекс и валидацию проводить но в большинстве случаев Всё окей генерируется Ну Есть какая-то гарантия того что Он не пропустит какие-то варианты полной гарантии нет Если вы именно запускаете как бы автодополнение если вы какой-то генерации запускаете где у него есть возможность ошибиться и исправится то уже будет история если у вас код comp гдето 230 миллисекунд то там идёт гарантия только из того как он на сервер протоколе отработал то есть какие-то ближайшие токены потому что вас может допустим там 100 строк подсказки сгенерировать такая Да допустим и вы её валидировать просто не успеете за маленькое время иначе Вам долго ждать придётся Вот либо валидация пап запускать и он там уже ну короче больше времени будет требуется тоже немножко генерация кода а не код комп последний вопрос вот молодой человек Спасибо большое не слышно не слышно А я слышу Да нене не подожди надо чтобы в трансляции было да Хорошо сейчас сейчас починим Спасибо большое Нет давайте я свой дам быстрее будет Спасибо большое замечательный доклад у меня такой вопрос при внедрении таких технологий мы ориентируемся на то что наши молодые специалисты джуны лы наверно да они будут использовать такой инструментарий мы вообще не боимся что мы отучим их делать ошибки и из них потом не получатся сеньоры мне каже что разви Если как бы то есть он он больше кодо всё равно увидит он больше сделает Он больше там интегрирует то есть его задача - это пройти в конце концов ревью и понять как бы свои ошибки понять код всё равно верх валидировать а там пишет что он руками или не руками а это уже другое немножко дело может быть Ну то есть скорее он просто от каких-то Ну будет немножко смещён в сторону от рутинных задач какого-то выполнения Да больше в сторону какой-то Верхне уровня аналитики верхнего понимание кода То есть у него он просто будет короче чуть-чуть по-другому развиваться короче вот ну Дайто Бог Спасибо в таком формате Можно я своё личное мнение выскажу не уже всё Мы не успеваем своё личное мнение кратко выскажу Мне кажется что такими инструментами по сути только сеньоры должны пользоваться Потому что если дать этот джуну то как бы там Ну мне кажется всем нормально дж во Ну учиться проще с помощью и поэтому тоже хорошая для Ну в общем да это дискуссия уже Ладно надо выбрать один лучший вопрос дофига было вопросов Поднимите руки кто задавал Вот про будущее и хороший вопрос На вот вы Да а вот всё пожалуйста подарок туда и тебе тоже подарок от онтика комплимент спасибо за доклад как ты понял ты отжёг полный зал даже я бы сказал полных три зала потому что в двух ещё ретранслировать надо побольше зал следующий раз что за Спасибо"
}