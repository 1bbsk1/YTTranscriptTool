{
  "video_id": "V53lsVO31XQ",
  "channel": "HighLoadChannel",
  "title": "Частичная модификация объектов в Yandex Object Storage: как мы улучшаем работу ФС / Александр Снопов",
  "views": 114,
  "duration": 2338,
  "published": "2024-10-29T03:07:37-07:00",
  "text": "Да Саш Привет Как тела Всем привет дела вообще отлично заряжен готов рассказывать да супер ты работаешь Яндекс infrastructure разработчиком Да всё правильно всё давай погнали Давайте начинать сейчас будем делать из буханок троллейбуса и набрасывать на S3 как я уже сказал как меня уже представили меня зовут Саша я занимаюсь разработкой систем хранения данных в Яндекс инфраструктуре Яндекс облаке и недавно в нашем S3 Появилась возможность модификации объектов напомню Что обычно у нас в S3 объекты неизменяемые теперь это не так мы это сделали в первую очередь для того чтобы улучшить сценарий когда мы хотим работать с S3 как файло и системой вот что это могут быть за сценарий как мы это всё поддержали что у нас получилось я бы и хотел рассказать а доклад я начну с того что расскажу что такое FS поверх S3 как и для чего она может быть нужна вообще вот в этом контек поговорим про недостатки интерфейса S3 и что с этим можно сделать расскажу непосредственно про наши решение object как мы его реализовали как тестировали что получилось и дам какие-то рекомендации к использованию и Пару слов про то куда мы всё это хотим развивать Ну вот FS поверх S3 дават сценарий когда хочется взять и работать с обетами в бате как-то примонтировать как директор и что-то с ними делать стандартными инструментами зачем это может быть нужно Но перед тем как ответить на этот вопрос Давайте сначала разберёмся А как вообще можно реализовать файловую систему какие у нас есть опции можем взять упороться и написать модуль для ядра будет быстро классно но непонятно как это всё потом распространять обновлять вообще как-то сложно можно взять и напи Вот Но тоже есть трудности нету готовых библиотек удобных и отчасти ограничены протоколом Вот но возможно есть что-то лучше и Да действительно есть это То есть syst uspace это модуль ядра и библиотека для разработки файловых систем в пространстве пользователя вот ну собственно все так и делают берут и реализуют какую-то свою FS это простое рение стандарт много библиотек В общем любого языка распространять обновлять вы залили клиент скача доволен есть вопросы к производительности будет там медленнее чем в ядре реализовывать но в целом хватает вот и таких на самом деле довольно много есть несколько популярных реализаций от Open sce сообщества это s3s вот хорошая пок совме Месть похуже есть это что-то среднее между предыдущими двумя вариантами и есть Да есть реализация непосредственно от провайдеров это M вот недавно у них появился в основном они чтение просто реализуют и оптимизируют есть от от А здесь не буду на них подробно останавливаться У всех свои особенности вот есть наша реализация фс вот насколько знаю среди российских облаков мы первую свою реализовали зачем мы это сделали мы посмотрели на реализации конкурентов И посчитали что они либо слишком медленные либо у них слабая поск совместимость либо просто какие-то баги они зависают и написали свою Но вот мне кажется Получилось неплохо на маленьких файлах Мы работаем там можем работать в десятки раз быстрее чем вот на больших файлах там сопоставимо с или быстрее и напилили вот хороший пок совместимость поддерживаем всякую даже экзотику в виде девайс файлов сокетов Ну как действительно звучит интересно поднимите руку кто использует FS здесь есть такие о а другие какие-нибудь s3s тоже есть переходите на рекомен ответи на вопрос Зачем Какие могут быть примеры использования вот у нас довольно много людей пишут бэкапы вче gsfs вот Oracle база данных чез не знаю в чём там проблема либо не умеет В3 либо медленно но вот пишут чез gsfs у нас есть CSI драйвер для кубернетес который позволяет сохранять данные подов V3 вот а Vol мы монтируем ФСО вот если посмотреть как люди используют то часто пишут логи потом можно использовать для упрощения интеграции всяких ML приложений С3 локально погоняли какое-то обучение на маленьких данных провели эксперимент хотим обучиться на Большом датасете В3 код переписывать Не надо при монтировали и собственно обучаемся у HPC приложений HPC приложения довольно часто заточены Именно под работу с файлами системами с люст там какой-нибудь вот ну и влом прослеживается бы нить такая что это влом уб много всего написано по dfs привычный интерфейс и для ускорения перехода в облоко можно использовать как адаптер такой есть ещё кейс можно э с помощью фса в том числе кэшировать объекты если требуется частое чтение Вот какие плюсы и минусы могут быть у такого решения вот Ну они во многом истекают Из плюсов и минусов S3 плюс - это ulz То есть если выпадает какая-то зона доступности у нас тож продолжает работать это хорошая масштабируемость по пропускной способности и объёму хранимых данных практически бесконечны масштабируется сколько хочешь и3 зачастую дешевле FS и дисков Какие минусы Ну вот - это всё ещё не распределённый FS то есть нету синхронизации между нодами например никакой и недостатки интерфейса дорогие переименования которые выливаются в копирование низкис при синхронной записи и ну S3 в целом не славится какой-то хорошей вот поэтому возможно какая-то мекона синхронная запись не стоит использовать для этого S3 Ну вот Какие недостатки есть интерфейс S3 Ну давайте сначала вспомним вообще свежим чуть знания Что такое S3 Ну во-первых это объектный ж то есть у нас данные хранятся в виде объектов у объекта есть данные метаданные сто подразумевают что очес рядом лежат и идентифицируются по ключу объекты хранятся в бате логический контейнер для объекта Вот и объекты в бате организован в виде плоского списка вот говорится что такое очень легко масштабировать Ну в целом Да а как мы работаем с объектами V3 это взаимодействие по репи можем загрузить объект за один запрос тогда мы такой объект симпл будем называть либо по частям Ну назовём такой объект мурт вот данные объектов После загрузки менять нельзя Понятно можно читать удалять и можно вот копировать объекты Но вот из этих пунктов Уже видно что файловую систему тяжеловато реализовать нету иерархии никакой у нас для объектов и перезаписывать нельзя модифицировать А в FS можно вот Но вот про первое не буду говорить про то как иерархию реализовывать А про второе как раз будет доклад Но вот используя загрузку по частям Она же она же можно бы эмулировать пробовать модификацию объектов вот как она вообще устроена Допустим мы хотим залить какой-то объект по ключу вот мы создаём объект загрузки получаем какой-то дишни льём туда часть объекта вот части идентифицируются тоже по ID порядковому номеру лить можем в любом порядке но потом при завершении надо весь список портов передать от одного до кае нчи зания То есть если мы уже что-то за какой-то парт залили из памяти допустим выкинули хотим почитать поменять но надо завершать загрузку можем перезаливать порты по ID и можно копировать частью другого объекта Но вот с помощью как раз этого пункта можно сделать такую модификацию своеобразную то есть мы берём заливаем мультипарк который хотим модифицировать копируем префикс сначала записываем потом какой-то кусочек в середину новый потом копируем конец Вот Но приходится весь объект копировать при этом и есть ограничения самое основное здесь это то что у нас есть минимальная Граница на размер порта это 5 Мб то есть мелко боч никакой записи нет и ограничение на суммарное число портов то есть автоматом получаем ограничение ещё и на размер файла вот что не очень-то удобно но с этим приходится жить Давайте посмотрим как мупа используется в gfs но представим что мы пишем допустим Давайте Log файл у нас как-то разбит на порты Будем считать что они все одинакового размера для простоты и каждому порту соответствует свой буфер в памяти один вот мы Пишем пишем файл сначала вся запись идёт в память потом в какой-то момент память начинает заканчиваться и мы данные хотим вытеснить слить в S3 вот создаём загрузку и пытаемся сбросить данные данные из памяти можем писать дальше Вот как с этими вытеснен буферами возникают проблемы Но вот мы писали Пишем пишем хотим что-то в нём погреть а не можем потому что данных у нас нет надо завершать загрузку завершили хотим писать дальше а надо тогда копировать уже всё что мы уже записали вот ну и похожи проб возникаю какието более сложные сри чтото и просто Каю часть модифицировать получается что весь обект надо копировать это весь обект вот за примером Далеко ходить не пришлось просто взял открыл график нагрузки какого-то Бакета который ремонтировал увидел такую пи Но вот можно догадаться что это такая синхронная запись файла последовательная вот каждый зубец это как раз фа сть графи пору портов новых и делает FS чтобы данные доехали до S3 Вот и дёргает compete mul upload вот а вот это сине - это всё копирование портов уже которые были записаны вот и получается как бы что пока мы файл пишем этих портов всё больше и больше становится вообще как бы сложность записи файла вообще до квадрата возрастает Вот и смешно и грустно потому что если посчитать деньги за всё вот это получается что Клиент платит практически только за копирование вот ну как-то это всё печально Можно ли с этим что-то сделать Делают ли там Может другие люди что-то в своих облаках Ну да делают Вот например в Гугле есть инструмент композитные объекты Ну там AP который позволяет вам несколько объектов в один склеить Ну так вот они Элит апен Например у ажура там вообще своя история у них он называется Есть блок лабы это типа мульти парв только в них можно ещ блоки доливать есть P страничный это диски как объекты объект интерфейс к дискам есть вот хуаве тоже есть есть бакеты там оптимизированные подработки с файло системы у них есть Аде ранке В общем Кто на что горазд какого-то Стандарта для модификации вот аманос Хет и вот немного про наш вот вчера Паша Лев подробно рассказывал если кто не видел можете потом посмотреть записи Но если кратко то в Яндексе уже на момент реализации было большое объектное хранилище вот стандартном своём понимании на кучу эба без своей там метаба вот и по сути на S3 это S3 к нему потому что по своему протоколу работает Иза для тот же состав список ртов из которых обект состоит надо где-то хранить базе у нас написан на называется гусь хранилище называется потом пригодится название и В качестве базы используем по рованный поддерживаем все основные фи S3 каких-то серьёзных там изменений расширений У нас вот до этого не было уме такой незамысловатый запрос простой передам в него Объект который хотим модифицировать стандартный заголовок и мы в него передаём диапазон изменения ВТО очень простой запрос можно выделить две логические операции это когда мы внутри объекта меняем какой-то диапазон но новые данные не пишем и ковы Дан в комбинация ко мы что-то пере записали и дописали одновременно а мы разрешаем параллельные запросы в один объект либо ключ Ну потому что как быстро работать с S3 надо эксплуатировать параллелизм иначе было бы слишком медленно Вот и где есть параллельные запросы Там могут быть и конфликты вот у нас есть механизм для их решения вот Ну вот возможно может возникнуть вопрос но вот Саш ты там рассказал про мультипарк может их просто надо было пофиксить и всё Ну такие мысли были вот попробую объяснить мотивацию Зачем нам именно расширение во-первых не хочется в принципе на эти порты завязывать потому что мы хотим уметь работать с любым видом объектов как с мультипарк и вот Сим который одним запросом загружены если мы вдруг тоже захотим вам зачем-то диски ставлять в виде объектов то готовьтесь па на них тоже будет работать вот вообще р объектов существует есть загрузка ЕС почитать докумен при е завершении ж должен собрать как бы в один объект цельные эти порты и больше их как бы быть не должно а они Есть они Потом везде всплывают и в запросах и Тулин Весь работает Так что парализует по портам там выгрузку объектов например вот если мы хотим как-то Ну и понятно тогда становится что пар это отдель КАТО на будут трудности потому что уже на это везде ВС завязано хотим чтобы интерфейс был расширяемый которые хотим поддержать во-первых частый кейс - это траке если мы хотим провоцировать место для записи уже спокойно писать Либо наоборот файл обрезать легко реализовать просто дописывай какие-то фиктивные порты потом при чтении на которые данные реально не содержит метаданные поним при реализовать это просто п по сути Вот это может быть нужно как раз для HPC приложений когда несколько воркеров могут писать в один файл по разным офсета Вот и таким образом пишут файл вот Ну понятно что там разные Осе поэтому надо уметь заграницу файла писать ба запрос - это такая своеобразная оптимизация чной записи если мы один какой-то парт малекит ви самое логичное это скачать его к себе модифицировать и залить обратно вот такой но вот можно не скачивая бач запросами Просто сразу менять получается такой швейцарский нож но в хорошем смысле не то что он ничего не то что он кучу всего умеет но ничего не имеет В итоге а просто удобно и существуют стандарты в принципе со схожими целями интерфейсом Вот есть такой Старт котором есть па для модификации объектов как раз очном реже и пока мы придумывали свой патч некий а придумывал загрузку патчами ренджа в целом для хттп документов вот там чтение более-менее стандартизированного есть попытки и загрузку для загрузки тоже стандарт сделать вот и получилось в общем-то практически Один в один Вот и что-то мы него тоже позаимствовали вот Давайте перейдём теперь к деталям реализации как это всё сделано для начала разберёмся как хранятся объекты Ну вот допустим у нас есть объект из четырёх портов а случай там симпл объектов я не буду разбирать потому что это по сути объект из одного порта неинтересно а данные в объекте по портам размазаны как-то по нашему мдсу сторедж по разным нодамэ вот и это очень удобная схема в том числе да для реализации нашего метода потому что с одной стороны мы можем легко масштабироваться по там пропускной способности при записи в объект потому что ну и при чтении тоже потому что данные размазаны с другой стороны у нас всегда есть консистентные Вид объекта вот что нам позволяет постгрес И мы можем какие-то несколько атомарных операций применять к нему перезапись данных мы не стали ничего сложного здесь придумывать и реализовывать и просто перезаписывать все попадающие в диапазон порты То есть если мы хотим в камни одном парте поменять пару батиков мы его целиком перепишем То есть это такой неделимый блок У нас вот но это лучше чем перезаписывать весь объект мы хотя бы один пар только перезаписывает объекта мы никак не изменяем нарезку объекта на порты как то есть нарв котон разме последнего порта записах портов потому что нам ВС е нужно влезать в ограничение на число портов в объекте если нужно писать большой файл нужно размер увеличить Ну вот иллюстрация ко всему тому что я писал допустим пришёл такой вот запрос на модификацию зата третий четвёртый парт тогда мы полностью перепишем третий запишем новый ключ пере Порто запишем е один новый порт и один будет короткий Но потому что просто диапазон закончился Вот и данные старых портов третий чет Надо будет потом асинхронно почистить вот все изменения применяются Амар то есть не может быть такого что часть мы перезаписать нет нам это позволяет сделать пое заж зарабо обк который он получает на старте запроса допустим есть запрос а и каждый что-то меняет вот у них есть начальное состояние мы просто выбираем текущий список ключей портов из и работаем с ними Они делают какие-то локальные изменения локально меняют данные и потом эти изменения пытаемся закоммитить уже в тот вид объекта который видит клиент то есть в реальный Вот и при коммите мы проверяем совпадает ли у нас вот те данные которые были на начало запроса и те что есть сейчас реальные то есть при Коми Измени мы с помощью оптимистичных блокировок делаем такую проверку вот если данные действительно совпадают то запросы проходят успешно мы данны пере записываем и всё хорошо но здесь можно заметить что запросы B иц по одному из портов конфликтуют они пересекаются и вот допустим запрос с здесь не проходит вот ну можно заметить что это всё напоминает там Snap is mvcc Ну примерно оно Наверно это и есть можно провести такое сравнение Вот и на этом можно было бы остановиться но всё конфликт получили отдали ошибку но мы решили пойти чуть дальше и попробовать эти конфликты решать во-первых их может быть двух видов Первое это когда виноваты мы как бы со своей реализацией потому что с точки зрения литов Т конф никакого перех пересекаются Зато по порту либо когда виноват клиент когда сам пользователь нам прислал пересекающиеся запросы пересекающиеся диапазоны но видимо он ожидает какой-то всё-таки консистентные получить Вот и с точки на стороне сервера такие конфликты сложно различать но Давайте какую-то общую схему тогда придумаем схема тоже достаточно простая по сути ЕС получили конфликт но теперь уже в качестве нашего снапшота начального мы используем текущее состояние объекта Вот и просто повторяем запрос с ним вот и получается что у нас выигрывает последняя запись То есть можно сказать что конфликты решаются по стратегии wins Но на самом деле мы делаем на стороне сервера несколько запросов таких в основном чтобы вот пользователь меньше замечал Первый вид конфликтов когда у него запросы как бы не пересекаются но пересечение по порту идт вот и это приводит к тому что Правильнее будет сказать что просто запросы сериали в некотором порядке вот но в итоге всё равно мы консистентной Като объект получаем Да оптимистичные блокировки были выбраны потому что мы вс-таки ожидаем что у нас не будет какая-то высоко конкурентная среда не бут не будет приходить много запросов в один и тот же диапазон Вот и чтобы не городить блокив приня всё тривиально на самом деле приходит запись перезапись запрос на запись каких-то данных файл и если как бы эта операция в итоге выливается вй то есть внутри объекта что-то перезаписывать то мы её можем легко по портам распараллелить Вот это будет быстрее чем одним запросом отправлять вот а пока нет реализации спарс файлов мы будем эти данные для нескольких портов отправлять в одном запросе вот и это будет медленно Понятно Потому что ограничены пропускной способностью одного соединения можем там в какую-то просю плохую попасть А вот Но вот как спар будет это мы тоже оптимизируем тестирование как мы наше решение тестировали но я думаю не будет думаю будет не очень интересно слушать как я несколько часов на листочке рисовал пересекающиеся прямоугольники и потом юниты на это писал поэтому расскажу как мы тестировали уже интеграцию Как вообще можно протестировать FS есть набор стандартных СВ которыми это можно сделать это xfs тесты pdfs тест и Linux Test Project там тоже есть набор тестов для файлов систем по сути это регресс и мы проверили что при переходе на пач у нас ничего не сломалось вот потом написали самос такую утилиту для фа тестирования она умеет писать факами ме е переключаться в процесе между разными паттернами последовательная запись случайная с пробелами там накладываю вот и она у себя в памяти хранит локальную копию файла и после сверяет что В3 действительно тот объект оказался который мы и пишем что данные совпадают но вот пару багов так получилось найти на самом деле вещь полезная оказалась Вот и бенчмарки тут всё стандартно синтетика покажу сравнение синхронной асинхронной записи сравнение с предыдущим решением sfs с мультипараметрическое 4D SSD для тестов и ой хранилище на SSD со стандартной квотой 512гб в FS порты использую 5 Мб и параллелизм 16 то есть параллельно грузим 16 портов Так ну вот такой бенчмарк Довольно простой но при этом показательный ДФА Следовательно размер Блока 5 Мб размер одного порта который использовался зелёненький - это пач оранжевый Up вот эти которые всякие синие фиолетовые это диски и NFS тёмно-синий HDD фиолетовый SSD синий Это NFS если кому-то плохо видно вот Первое - это синхронная запись файла размером в 1 Гб но тут огромный столб льдов файл у нас загружался 4 минуты 38 секунд Ну что довольно долго Ну тут сразу оговорюсь что для Что обычно Foo делает Кет перед тем как писать данные для мультипарк это не делалось А пач у нас записал файл за 40 секунд но в два раза дольше чем HDD получается пока но ну SSD там сильно быстрее потом запись файла размером 5 Гб и fsn каждые 25 записей Ну то есть 125 Мб сс3 догнали поч чуть отстал Ну потому что там стандартный кво он чуть урезанный если побольше объём взять Я думаю он как SSD будет Вот но мультипас ещё проигрывают потому что достаточно много копирования идёт Вот и последний график - это запись объекта размером 10 Гб И уже только на закрытии что копирования нет но вот патч отстал не сильно но всё-таки чуть помедленнее Вот Но если поднять параллелизм до 32 побольше сделать то результаты такие же будут вот Максимум у меня получалось выжать запись 900 Мб в секунду Примерно вот на своих бенчмарках вот Ну и это сопоставимо со скоростью записи на SSD Вот теперь синхронная запись то есть пишем сравнение записи разными боками синхронные вот Зелёная это ИОС оранжевая мегабайты в секунду для наглядности Ну вот первый Т графика первый - это 8 КБ бок мегабайт и 5 Мб ну вот видно что пока мы пишем блоками размером меньше одного порта как бы сильно ничего не меняется примерно всё те же пять ИОС но только при этом понятно что скорость записи если маленькими боками писать она запредельно низкая там Вот её даже не видно Вот а если Начинаем писать уже блоком больше чем один парт то в выливается в параллельный запрос это получается достаточно быстро общем мораль такая что лучше писать большими блоками Вот либо поже Сить Ну рекомендации к использованию отсюда да как я уже сказал пишите данные крупными блоками как минимум размером с один парт желательно ещё выравнивать чтобы несколько парв не пере запись не про gfs постс пытаться на НМ поднимать Наверно всё-таки не стоит если асинхронно то пожалуйста Там ляжет всё в кэш потом сбросится если нужна частая перезапись лучше использовать порты меньшего размера желательно вообще минимального Ну меньше будем перезаписывать Поэтому будет быстрее Да если нужна максимально быстрая загрузка именно через пач то можно попробовать сначала провоцировать место для записи это загрузить кучу нулей потом как их перезаписать ль Потом если что обрезать Вот это в любом случае получается лучше чем там синхронная загрузка мультипарк заливка пами вот можно попробовать вот как будут спарс файлы либо хотя бы просто поддержан в паче это уже делать Не нужно будет Вот такие рекомендации слайда нет Но скажу так просто устно вообще какие у нас дальше иде разви па и вообще влом на чём надеемся что либо у нас сроки дойдут либо кто-то может сделать поддержку Open Source проектах в фе либо в Min вот а FS дальше хотим развивать как полноценную кластерную FS поверх S3 есть вот такой проект J FS он довольно популярный там 99.000 звёзд на гитхабе это как раз распределённый FS S3 но там вот этого соответствие один к одному нету то что Файлик и объект в S3 она в свом в своём там формате хранит просто чанки в S3 у неё тоже своя метаба где она эти чанки потом файлы мат Вот то есть и тоже чез монтируется то есть во многом похоже на нашу архитектуру но у нас ещё и сохраняется вот соответствие файла объекта если мы как бы дальше разовьёт вам работать с S3 и интегрировать какие-то варды которые с S3 умеют хорошо работать и которым кластерная FS при этом нужна Вот на этом У меня всё Если вам понравилось голосуйте за мой доклад ставьте лайки Подписывайтесь жмите на колокольчик Спасибо Да всё спасибо поднимайте руки у кого вопросы при за лучший вопрос всё также всё работает Давайте вот начнём в конце Ага давайте а у меня такой вопрос я немножко не понял из доклада что вроде у нас оптимистичные блокировки но потом что они там повторяются и мы всегда успешны Да и Last wins То есть даже если пять параллельных запросов будет там байти менять то просто какой-то из них выиграет Правильно ли я понял И в ЧМ заключается очно блокировок Могу ли я получить отказ от записи моего нжа Да спасибо за вопрос отказ можно получить то есть идея в том что мы не берём блокировку объекта или каких-то портов на весь запрос потому что как бы в принципе не хочется раци паралельно данные тоже эти менять потому что ЕС мы допустим целиком переписали то там перезаписывать ничего не надо можно просто обновить что теперь вот этот парт он по новому ключу какому-то лежит вот перезапись данных реально нужна если у нас два пересекающихся запроса которого целиком не переписывали надо объединить как бы данные и Да если много запросов то там воз об Так давайте продолжаем Саш ты запоминаешь лучший вопрос Александ Мы тоже делаем Вопрос такой первый уточняющий у вас в тестах был тест на запись но патч используется как бы для перезаписи Как вы говорите ну для обновления какого-то кусочка объекта То есть это получается повтор бы запи с использованием патча и в этом случае па выигрывает по производительности Да спасибо за вопрос вот на Первом графике это последовательно синхронная запись просто андами блоками В конец вот потом Да это перезапись именно уже лоро как бы объекта Вот и да то есть это дальше уже перезапись ну то есть разница существенная при перезаписи вот тогда патч Уже показывает себя как бы в полный рост а я просто пачем же нельзя загрузить Новый объект целиком загрузить Новый объект нельзя Но вы можете Ну как бы создать объект стандартными инструментами а потом пачем делать он до запись конец вот и вот в таком случае после создания нулевого объекта патчем получается создать конечный объект быстрее чем РМ Да это уже получается быстрее чем РД если мы говорим про синхрон ную запись потому что у нас нету копирования всего объекта так при первичной загрузке вы просто загружаете параллельно все парты я не очень понимаю как может быть первичная загрузка Мурта плодом медленнее чем загрузка первичная патчем с увеличением длины объекта Если вы весь Файлик загружаете как мультидом допустим Вот пример понятный с логами Мне кажется вот мы грузим грузим грузим Допустим мы хотим их как-то всё-таки В3 стить периодически чтобы ключ появлялся у нас мы могли с ним-то работать объекта у которого динамически в процессе загрузки меняется длина Да не статического просто объек всё Простите я понял И у меня ещё маленький вопрос э действительно есть серьёзная проблема с Right амплификации про которую вы сказали Мы её у себя тоже видим Вот Но в амазоне например они насколько я понимаю я не знаю инсайтов но кажется что они пошли подругому пути они парты не по-честному копируют на стороне сервера когда делается Copy парт а как бы делают некую дедупликация ссылку что вот типа эта часть вот этого нового объекта ссылается на вот тот на самом деле как бы блок данных потому что у них ко парт он чрезвычайно быстрый и не думали ли вы сделать похожую дупликации вместо того чтобы привносить новый метод в спецификацию Да мы думали такое улучшение сделать Возможно мы его тоже сделаем чтобы улучшить жизнь клиентам которые там не могут по какой-то причине па использовать но с пам с пачем именно тели кайто более гибкий инструмент на основе которого Потом могли реализовывать фи тоже запись сфа спасибо да спасибо са я вот хотел спросить просто начал так с места в карьер можешь кейс рассказать вообще вот частичного изменения файлов это вот логи Да что ещ всё Пен Оли файлы видео стриминг наверное видео стриминг тоже можно Ну всё Где в принципе всё где есть посредственно запись можно использовать для этого патча Но вот для перезаписи сейчас так из главы с ходу не возьму Но если нужна тоже можно использовать но если например даже какой-то может на какую-то тестовую базу данных например запустить для тестов чисто и там каждую запись МКА бощ не сикать будет в кэше сдать но всё равно потом что-то будет Перси и вот тут пач тоже поможет Угу Всё окей ладно продолжаем Давайте по центру Привет Э Вопрос такой смотрели ли какая файловая система под ногами у фьюза будет работать лучше оптимальнее если а разница между Ну в производительности Если вы настраиваете скажем что у вас парт сайз равен там блок сайз у ну файловую системы которая под ногами и последний вопрос Ну просто такой сто нет Да давай по очереди нене не это просто и вот в дочку чуть-чуть прямо буквально Это по поводу вот девайс файлов да и соответственно зачем они нужны как они используются именно быст девайс файл не скажу они у нас просто есть Честно скажу про про use я не очень понял вопрос про FS под ногами что имеется в виду Да микрофон не работает плохо слышно трансляции же Ну как есть приложение да наши пользователь с он там хочет сделать й начинает идти по стеку линуса там через vfs запрос попадает в очередь Demon А дальше он эти сообщения переведёт просто в gfs наш gfs дальше делает запросы в S3 если ему надо Ну не А вот обратная цепочка когда из FS приходит значит попадает это в ьз в конечном итоге-то это же кладётся куда-то на диск а диск у нас не на диск это не попадает Ну обратно в память просто всё понятно файловая системы нету Так а у кого микрофон Вставайте задавайте вопросы так всё нету рук всё в целом разобрались С3 А да да всё онлайн У меня тоже Тоже ничего нету друзья тогда давайте Саше похлопаем Так у меня ещё есть подарок за лучший вопрос Давайте его передам вот человеку который много вопросов задал а просто просто взял форсо вопрос тея да и ещё один давай подарок выберем У нас есть ещё один от партнёров Ага А какой какой ещё запомнился тебе так Ну давайте Вот про девайс файл и про фьюз про девайс файл про который просто есть да который просто так а Подними руку Да ты ты задавал всё Вот тебе ещё один подарок Саш тебе тоже подарок всё ловите Сашу в кулуарах друзья Давайте ещё раз похлопаем а Y"
}