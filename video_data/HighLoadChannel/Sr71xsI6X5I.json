{
  "video_id": "Sr71xsI6X5I",
  "channel": "HighLoadChannel",
  "title": "Распределенное логирование и трассировка для микросервисов / Иван Летенко (Infobip)",
  "views": 6772,
  "duration": 2785,
  "published": "2019-12-05T12:57:33-08:00",
  "text": "всем привет да меня зовут иван для тнк я работаю в компании инфобиз и сегодня мы поговорим про логирования трассировку ну и в целом а про метрики и про мониторинг о том как мы это делаем как мы это делаем в наших масштабах и какие задачи есть какие как к кубку какой путь мы прошли для начала я хочу сказать чуть-чуть о нашей компании потому что чтобы понять вообще у space понять background понятие размеры и числа на с которыми мы работаем значит в чем суть нашего бизнеса мы помогаем клиентам организациям доставлять сообщение доставка коммуницировать с их клиентами то есть когда вы получаете сообщение какой службы такси о том что ваш водитель прибыл когда получаете смазку из банка что с вас писали денег о том или получаете одноразовый пароль когда лагер лагер уйти из вконтакте это все скорее всего проходит через нашу платформу мы работаем по всему миру у нас примерно в 190 странах мы работаем с нашими клиентами поэтому все это вместе происходит при 150 миллионов транзакций в день то есть это 350 миллионов сообщений которые мы принимаем обрабатываем белем рауте мы адаптируем если необходимо отсылаем оператором и про и в обратном направлении обрабатываем deliver отчеты о доставке формируем аналитику вообще еще очень много чего чтобы все это работало по всему миру в таких объемах у нас для этого есть 36 дата-центров 500000 виртуальных машин и 350 инженеров которые уже сейчас разработали более 700 30 различных микро сервисов то есть то есть понятно что эта система очень сложная и вряд ли один человек или группы хотя бы к любой гуру может пора понять весь масштаб при этом одна из целей основных целей нашей компании это высокая скорость доставки имеется ввиду что мы хотим на у новые фичи новые какие-то релизы доставлять как можно быстрее это этого хочет бизнес и при этом естественно все это должно работать и ни в коем случае не падать как я сказал у нас примерно 350 инженеров на 300 тепло и в день то есть получается что каждый инженер ежедневно что-то тепло it еще несколько лет назад такая скорость доставки такая производительность наверно было только у одного человека в нашей компании это крыша он наше principle инженер но мы хотим чтобы и в принципе добились того чтобы каждый инженер чувствовал себя так же уверенно к крыше когда он нажимает на кнопку тепло или запускает какой-нибудь скрипт что для этого нужно для этого прежде всего нужно уверенность уверенность в том что мы понимаем что происходит сейчас системе мы не понимаем в каком она состоянии находится и при разработке кода при или если что-то пошло не так если какой-то случился инцидент мы всегда могли задать вопрос системы и быстро сама она быстро выяснить в чем же проблема что же мы хотим сделать так или что мы должны сделать для того чтобы наш новый год работал правильно это придает уверенности и соответственно чтобы добиться этого уверенности мы инвестируем в обзор выбелить и наблюдаемость и традиционно этот термин объединяет три вещи это логирование метрики и трассировку прежде всего как я говорила ему будем сегодня я буду говорить о нашем решении для лакирования но также обязательно коснемся и также метрики и трассировки в целом давайте посмотрим какую эволюцию прошла наша система и вообще какая эволюций а метрика логирования часов через какой путь проходит практически любое приложение любая система ну что у нас сначала появляется наверное сначала первый шаг от какой-то вывод на консоль потом потом мы начинаем писать логе файл нас появляется какой-нибудь фреймворк для структурированного вывода файл мы используем лоб бег обычно то что мы живем java в java коде ну то есть появляется структурированное логирование файл чтобы понятно было что разные логии должны иметь разный уровень вардинге норы и тому подобное как только сер инстансов нашего сервиса становится уже несколько или разных сервиса становится несколько становится задача что к этим блогом должен быть доступ должен быть доступ не только у разработчиков должен быть доступ у поддержки и мы переходим к распределенном лоббированию то есть когда различные сервисы вместе объединяют пишут какой-то единый сервис логирования у нас в компании стандартным выбором является грейлок хотя также в наиболее известная это elastic все чисто лог стрижки bonay lk стек либо его вариации мы выбрали брелок потому что он именно для лакирования предоставляет классный интерфейс чуть более заточены на логирование плюс alert и также идут из коробки и даже уже в бесплатной версии в отличие там наверное атаки баны то есть ну в принципе если мы смотрим налоги того релог очень очень очень классный выбор для этого из кейса вот у нас появился брелок система росла в нем можно строить не только alert и как и говорил также можно сразу строить графики аналогичные там наверное ебаные я думаю многие знакомы каких какие какие-то метрики даже по коду пологом строить все это растет наша компания росла и в определённый момент мы начали понимать что у нас с этим крыло гам что-то идет не так во первых появились в проблемы с производительностью потому что многие разработчики стали использовать эти классные возможности игры логов и строить там метрики строить там даже борды которые делают агрегацию по данным которые с различных облигаций берут определенную там дельты и тому подобное конечно так подобной операции на кластеры elastico конечно на я уверен что это не самый лучший выбор для elastico который нас на трафике на котором идет мощная запись когда на нем делаются сложная аналитикой агрегации строятся ну и второе это коллизии игры лог надеется в частности настройки elastico по умолчанию хотя до в горы логе под капотом тоже elastic такое маленькое замечание да и ну я думаю вы уже поняли об этом вот и коллизии коллизии болею команд много единой схемы нету традиционно когда в один айтишник кто-то родишь ник попал в первый раз брелок в качестве лонга автоматически мафик произошел потом другая команда решила что туда нужно будет записать и это довольно сильно ломает систему поэтому какое у мы сделали первое решение ну во первых у разных логов есть разные юз кейсы здесь какие то просто логе приложений там лак info там или еще что-то которые в принципе к ним требования даст достаточно у разных команд во-первых разные требования во вторых у них требования к разным многом разные и пор attention у по тому времени сколько они хранятся в системе и по по возможности поиска и по разным параметрам поэтому мы разделили первое было что разделили логе приложения и коммуникационной логе парка про этот наш эскиз я экземы об этом мы сейчас поговорим это очень как бы важны для важные логе для нас важны для нас виски из принципе они хранят информацию взаимодействие нашей платформы с внешним миром и еще не ту информацию о взаимодействии внутри платформы и также это мы заменили часть логов на метрики ну у нас стандартный выбор в компании это prometheus фармить и и графа на какие-то команды используют и в том числе и другие решения но важно было момент что мы избавились от этого большого количества каких-то дашбордов которые с аппликациями внутри игры logo и перевелись все это на prometheus и графа ну и значительно облегчили работу нагрузку на серверы давайте в целом посмотрим вообще какие какие из кейсы есть и для этой триаду логии метрики и trace и во первых чем хорошо логе логии то события которые мало героем они для них может быть большая размерность то есть туда можно лакировать и request айди юзера идей то есть размерность то есть лейбл и какие-то данные размерность которых не ограничено и они также классные для отладки для исследования для каких-то чтобы задавать вопросы системе о том что было и что происходило и из и из искать причины и следствия при этом метрики отлично подходит для а делегации для мониторинга для построения каких-то alert of the что отметками от всеми системами сбора метрик в нем об этом уже на этой конференции в том числе вчера очень много говорилось там внутри под капотом time series база данных которых отлично справляются с агрегации но они очень чувствительны к размерности размерности данных если мы будем добавлять например какой то айдишники какие-то request айди которых размер значений не ограничен то мы очень быстро столкнемся с серьезными проблемами кэшем тоже выступали найти на эти грабли и для метрик размерность данных на этом не должна превышать какие-то тысячи не десятки не сотни тысяч и трассировка с корреляции чтобы мы могли удобно искать по блогам по каким-то данным нам необходимо чтобы ноги были коррелированы то есть не только структурированы где у нас есть поля с определенными значениями request идеи там юзера идеи какие то данные сервис из которого пришел но и также они даже быть короли раваны ну здесь традиционное решение естественно что призываю на входе в систему присваивается какой-то уникальный айди системы и затем этот айди этот контекст пробрасываем через всю систему по всей цепочке вызовов внутри сервиса либо уже также по цепочке вызовов между сервисами трассировка соответственно ну есть устоявшийся термин и то есть трассировка разбивается на span и и демонстрируется стек вызовов одного сервиса относительно другого одного метода относительно другого относительно временной шкалы то есть мы хорошо видим какие методы к-к-какого путь проходила сообщение а также где какие тайминги у нас были все это очень наглядно а также можно проследить мы у нас был опыт использования zip кино уже 2005 году у нас был прав об коку пруфов концепт этих решений тут в два важных момента что чтобы получить такую картину нам нужно код нужно инструмен тировать то есть нужно из если вас уже вы работайте работайте с какой-то кодовой базы которая существует конечно нужно ее по ней по всей праге сенатора будет изменений кроме того чтобы получить полную картину и действительно получать выгоду от этих рейсов необходимо чтобы этот соответственно инструменти равана был не один сервис какой-то на которому сейчас работаете а все сервисы вашей цепочки однако это это очень мощный инструмент мы сейчас правда перешли от zip кино другое решение но это я уверен что эта тема отдельного большого разговора и теперь давайте перейдем к интересному кейсу как я говорил что логии должны быть коррелированы trace и так же такая же идея стрессами trace и должна быть коллировал коррелированы и нам нужен единый единый айдишник единый контекст пробрасывать по всей цепочке вызовов но зачастую это невозможно то есть зачастую вот эта корреляция она происходит внутри системы впоследствии в результате ее работы и когда мы начинаем транзакции или несколько транзакций мы еще не знаем что это они на самом деле части единого большого целого ну давайте посмотрим наш пример клиент от отправил запрос на сообщение наши внутренние продукт платформы его обработала и дальше сервис который занимается за водителем с операторов отправил его этот это сообщение к оператору что происходит обратно затем через некоторое этапу появился запись в системе логов потом через некоторое время оператор нам присылает отчет о доставке и сервис который занимается процессингом он не знает что это на самом деле этот отчет о доставке он относится к этому сообщению и это взаимосвязь произойдет где-то потом внутри внутри нашей платформы то есть таким образом мы имеем две транзакции которые являются частью они связаны они имеются частью единой целых и единой целой транзакции и эта информация очень важна для инженеров поддержки для разработчиков которые занимаются этими интеграциями но это совершенно невозможно видеть исходя из какой-то от единого единой трассировки единого идиш ника и второй случай у нас похожи когда клиент посылает нам сообщение в едином балки в большой пачке и потом мы их разбирает разбираем они возвращаются тоже может быть даже количество ими количество меняться на тоже пачками и все это потом клиенту объединяется то есть точки зрения это клиентов на нам отправил получил ответ но внутри мы получили сразу несколько независимых транзакций которые необходимо объединять то есть нас получается связь один-ко-многим а с отчетом о доставке случается связь один к одному но это очень хорошо звучит как графе да то есть мы можем построить граф где у нас есть связь один-ко-многим и один к одному 1 раз мы видим граф то соответственно стандартный ну какой то адекватно выбор сейчас есть и графу базу данных давайте выберем какую-нибудь графу базу данных например на вафа джей потому что они на конференциях дарят классные футболки книжки бесплатные вот естественный выбор был абсолютно очевиден для нас мы реализовали пруфа в концепт хост на котором 16 ядер мог обрабатывать графа 100 миллионов ноты 150 миллионов связей они заняли всего 15 гигабайт диска на тот момент для нас это подходило то есть ответственно наше решение получилось вот таким то есть мы нас появился на его fuji и еще нас появился log viewer для того чтобы инженером которым нужно видеть эту картину не чисто лог а вот эту всю целую картину целиком пелоси появился log viewer который достаточно не сложный интерфейс предоставление инфора просмотра логов вот но довольно быстро мы столкнулись что на фиджи наверное не самый лучший выбор для нашей ситуации почему ну во первых это ротация данных у нас объем и как вы поняли довольно мощные и данные необходимо ротировать а при удалении ноды из на его fuji данные на диске не очищаются то есть при нужен был оградить какое-то достаточно сложное решение плюс все равно мы сталкивались с с потерей что необходимо перестраивать полностью графа 2 это производительность вообще все графом в базу данных они очень хорошо заточены на чтение но на запись они достаточно они их производители заметно меньше а в наш наш эскиз был абсолютно противоположным и много пишем но относительно редко читаем это единицы запросов в секунду ну и даже в минуту но и также в него джек аллаха и ловили teclast рынка не за деньги это может быть не сильно большая проблема наших масштабах это вылилось бы довольно приличные затраты поэтому мы пошли немножко другим путем мы решили что раз граф можно размыть читаем меткам этот граф можем строить на лету то есть таким образом мы хранить список смежности наших хищников в виде таблички достаточно простая это два лонга эндера по которым и по обоим индекс сохраним все это в реляционной базе в покер в полисе и при необходимости когда приходит запрос мы обходим этот граф связанности depressed глубину всем хорошо знакомы алгоритм и получаем все все рыл этот а идиш ники все свет наличники ну и ротация данных также в пол здесь решается легко мы под на каждый день за заводим новую табличку и соответственно через несколько дней ее когда приходит время мы ее просто дропаем и всем освобождаем данном в принципе решение достаточно простое вот и что это нам позволило сейчас в данный момент в этом плоскость у нас 850 миллионов связей которые занимают 150 гигабайт диска пишем туда на скорости 300 тысяч в секунду и вот это для для этого после со всего две машины 20 и 6 гигабайт романа в принципе что это его из доказать под клизму и если мы пишем ланге в посольство не сел он пишет она умеет делать быстро ну еще есть небольшие машины для самого сервиса которая гарантирует и управляет соответственно наша архитектура изменилось вот так следующая компания росла появлялись новые дата-центры нагрузка даже для этого решение с конвекционными лагами нагрузка заметно росла и мы опять у нас появилась мы начали задумываться что наверное все таки в данном случае брелок уже не идеально нам подходит во первых это единая схема и централизация то есть ну хотелось иметь все таки единою а я никогда у вас десять дата-центров 10-ю аиф плюсы еще инструмент связи с лагами нужно было какой-то централизация ну и также вопросы использования единой схемы и на схеме mapping of dune данных чтобы не было коллизий поскольку мы использовали наш log viewer и добавляю туда определенной fitch этого стандартного от игры logo тоже был его не всегда удобно поле из использовать карте нужно отобразить данные с разных дата-центров правильно их отсортировать правильно пометить стандартная гоханом хотелось иметь с усов возможность собственно менять api как нам больше нравится и производительность наш трафик данный момент этот литера байтов день флагов что достаточно прилично поэтому брелок не всегда стабильно работал и нужно было залезать в него во внутренности чтобы очень точно понять и пол то есть уже получалось что мы видим тут то есть уже используемого не как инструмента залезаем не слишком глубоко поэтому я и явно нам надо было что с этим делать и задет задержки очереди обработки появлялись нужно было смотреть как реализовано очередь нам она не очень нравилась их стандартная реализация поэтому в общем-то а еще нет естественно все это обслуживание всего этого хозяйства игры лог также еще и тащит за собой манга тебе приходилось еще администрировать mongo db в принципе мы поняли что на данном этапе мы хотим наше свое собственное решение которое нам больше подходит возможно там не меньше функции каких-то меньше классных функций по alert ингу который уже не использовали для падаешь бардом но нам нужно собственное решение поэтому мы разработали наш собственный logs сервис за основу мы взяли elastic search поскольку в тот момент у нас уже была экспертизы как работы с большими обслуживать и мы infinite круг крупные кластеры ластика сам сервис мы стали писать на код лине потому что мы любим колдун вообще на стандартный стек в компании это java стек и джеймс так ну вот линтон следует быть для бэг-энда мы классного используем но первый вопрос это как ротировать данные и что дело с момента мы используем фиксированный маппинг и ротируется данные по бог был вопрос кто есть естественно пластику лучше иметь индексы одинакового размера но если мы имеем индекс одинакого размера нам нужно как-то маппить данные на кафка в каком конкретно яндексе искать особенно когда у вас несколько дата-центров в распределенная система распределенных состоянии наверное были идеи прикрутить звуки пир но опять же это суке суке pir это обслуживание это усложнение кода поэтому мы на самом деле решили все просто мы пишем туда по времени то есть допустим один индекс на 1 час книг какие-то дата-центр там два индекс на час каком-то один индекс на три часа но все равно пишем по времени индексы получается немножко разного размера поскольку ночью трафик меньше чем днем но в целом это это работает и наш опыт показал что какие-то более усложнения здесь не нужны это достаточно хорошо работает выбор протокола была идея вписать наш сервис логирование в нашу инфраструктуру микро сервисов все сервис discovery чтобы все сервис автоматически могу и видеть его но для простоты миграции и для такого объема данных был выбран гель протокол это протокол elastic протокол игры logo он достаточно простой тесь на основе тисе пи я не буду в него вдаваться подробности можно об этом поговорить вот на это тогда у нас появляется гель сервер на найти декодер которые потом jason yang кодируется для записи вальсик сечь и мы используем java api официальная java 5 ластик сеча и используем болты пишем балками это важная оптимизация для если нам нужно добиться высокой скорости записи нужно писать балками api предоставляет балка процессор который автоматически накапливает запросы и потом flash от их либо пачкой либо по время или либо папа времени вроде все хорошо мы запустили и мы поняли в данный момент мы запустили и мы поняли что мы упираемся в бал процессор это было совершенно неожиданностью мы не можем добиться тех значений на которые мы рассчитывали и совершенно проблема пришло из ниоткуда в чем же проблема проблема болт процессором стандартной реализации блок процессора котла в том что он на самом деле однопоточный синхронный несмотря на то что там есть настройка конкор инси и это это было из это на самом деле потом покопались это оказывается была известная бага известная проблема которая на дон на тот момент было не решена я перед ну мы естественным ножка вы изменили сделали явную блокировку через went and look и что здесь важно что я сейчас посмотрел ровно месяц назад только похожие изменения были внесены в официальной репозитории elastic сеча и будут доступны свершить с версии 7 тыс сейчас текущая актуальная версия 71 то есть если вы также работаете с болг процессором или вам хотите разогнать запись власти кто вам желательно посмотреть эти изменения и обратно портировать под ту версию которую пользу и пользуетесь мы например пользуемся версии 63 изменения затрагивают только bulk процессор поэтому я думаю где здесь сложности не возникнет если вам нужны ехал обратно портировать на ней на более масла нижнюю версию дальше но все отлично бал процессор пошел скорость разогналась но естественный ластик работает не с как эти производительность elastic на записи она нестабильна во времени поскольку там происходят различные операции например merging индексов flash и тому подобное плюс во время обслуживания когда как допустим вы бывает часть not из кластера система тоже производительность на некоторое время замедляется и мы поняли что нам нужна некая и лизации внутри был не только буфера в памяти а все-таки некоторая реализация очереди как я говорил нас не устраивало задержка которую предоставляет грейлок поэтому мы решили что мы будем задерживать только те сообщения которые были отклонены то есть только те балки которые бал процессор не смог записать вы ластик со ответ на ну это реализация простая экзамен пишется j'avais и пьютера языке и скутер сервиса rejected хендлер хенли то те балки которые свалились мы их записываем файл и повторно одни в отдельном экзекьютора повторно отправляем и здесь что важно мы не задерживаем новый трафик то есть для инженеров для поддержки для разработчиков важно все-таки видел новый трафик который счастлив свежий пришел систему он заметно важнее тот который почему-то задержались во время кота спайка или проблему когда elastic замедлился ok он задержался он прибудет потом ничего страшного новый трафик мы сразу же процессе то есть так таким образом наша схема стала выглядеть вот таким вот образом и мы поменяли на нашему лук сервис окей теперь давайте немножко поговорим про ластик search как мы из как как мы его готовим какие параметры мы использовали все что как мы настроили то что следующий следующий проблемы с которым мы столкнулись что нужно разгар нужно разгонять elastic search оптимизировать его именно именно на запись поскольку опять же количество чтений замес заметно меньше первое это параметр который мы использовали он не совсем связан с производительностью это отбрасывать и гномы гномэйл форум отбрасывать поля с неверным типом они весь документ поскольку нам все-таки хочется хранить хранить данные даже если кто-то почему-то каким-то образом просочились туда поля с неправильным а пингом и вообще для ластик все еще для по железу хочу сказать что там очень важный момент когда мы начали просить большие кластеры нам дают вам нужно очень много дисков это жутко дорого но почему ну мы ж тут raid-массив ssd как бы все круто но важными том что для ластик сечас тесто не нужно никакие раид массивы и создать диск а потому что вся full толеранс и все-все порт портировал парте цианирование она уже встроена в самолете ключ поэтому там даже на официальном сайте в может рекомендациях есть что если есть возможность берите больше железо дешевого чем меньше дорогого хорошего это касается и дисков и количество процент количество ядер процессора то что в принципе весь у вас еще и он очень хорошо параллели ца следующая рекомендация это если все-таки вам не достались ssd-диски я просто обычный и где-то мерч thread каунт надо выставить единичкой пишется индексы пишется кусочками потом эти кусочки множится для это необходимо это чуть-чуть экономится диск но прежде всего это необходимо для поиска это ускоряет поиск соответствие также когда индекс перестали вы перестали записывать в яндекс вы можете сделать force мертв или когда там нагрузка на классно поменьше она автоматически мир жить с тогда следующий параметр это задержка при при пропадая задержка рио локации при пропадании ноды если какая-то но то допустим перезагрузилась или была выведена там происходит тепло и и была выведена для обслуживания это время через которое ластик search начнет реала тировать индексы и аллоцировать данные опять же если у вас мощная нагрузка особенно на диск на сеть это также это да операция дорогая по диску по сети соответственно чтоб них не перегрузить этот тайм аут лучше иметь под контролем и пыли при понимать какие задержки вам необходимо индекс refresh interval опять же если нет он может быть выставлен в там в секундах минутах так же если у вас нету вообще поисковых запросов у можно поставить минус 1 то есть тогда индекс будет обновляться только при появлении поискового запроса и еще хорошие это транс лок durability это как как часто выполнять f sing либо при каждом запросе либо по времени в принципе тоже дает прирост производительности опять же если диски не очень быстрые вот еще интересный у нас юз кейс появился естественно ребята все разработчики и поддержка не хотят полноценно полнотекстовый поиск причем не просто полнотекстовый поиск горячего аналог радикса по по всему телу сообщения на самом деле вы ластики это невозможно ластик может искать только потолке нам который уже есть его системе эры гексы и wildcard можно использовать но они не могут стены talkin' не может начинаться с какого-то радикса поэтому мы использовали добавили word диаметр фильтр который позволяет делать вот такие вот штуки автоматически разбивать на токены это как ну сами понимаете название класса по дому образом пишутся все возможно отладочная информация то есть это нам позволило закрыть и часть проблем и решить этот момент с полнотекстовым поиском советуют так также добавлять когда работаете с логином такие вот настройки ну и в целом правил про кластер количество shard должно быть должно равняться количеству дата носа для распределения нагрузки таким образом каждый каждый надо будет иметь 1 шард основной и одну реплику то есть если количество реплика минимум один выбрать эскадры как как каждый каждая нота будет иметь один основной шар ты одел эту реплику то есть случае пропадания но да если данные более ценные то есть поэтому данному на слоги как бы мы их очень любим но все таки это не финансовые транзакции поэтому мы можем добиться одной реплики если у вас данные более серьезные ту лучше 2 размер шарда реками также опять же рекомендации можно их найти это от нескольких гигабайт до десятков гигабайт и очень важный момент это не больше 20 шар дафна один гигабайт hippo гигабайт ластика естественно потому что дальше он начинает замедляться именно им и на это тоже наступали в тех дата-центрах 90 рафика немного данные не рати раваль есь по объему у нас появляясь тысячи индексов и системы по два облака ешь наверно опять же цена случаем intenso на случае обслуживания когда у вас выбывает какой-то гипервизор чтобы индексы и шарды были разбросаны по разным гипервизором и они не пересекались и создание индексов предварительно тоже очень хорошая практика чтобы особенно когда мы пишем по времени чтобы сразу но в яндекс уже был говорящим уже был готовым и не происходил каких-то задержек вот еще интересный момент мы с обслуживанием обнаружили как как себя ведет его stick это параметр это к максимальное количество нот одного шарда количество short- одна одного индекса на ноги то есть ну в идеальном случае их 2 мы ставим 4 на всякий случай что если у нас все таки саркофаг окажется интер то есть машина окажется меньше вот в чем же здесь была проблема даже несмотря на то что мы используем allocation коварность то есть elastic знает какие пока как правильно разбросать индексы по гипервизором мы выяснили что когда после толкнул и достаточно долгое время находилась была выключена потом она обратно приходит в кластер и elastic вид что на ней как бы формально меньше индексов они устанавливаются то есть пока они не выстраданные не синхронизируются формально на ней на этой ноте индексов мало и при необходимости аллоцировать но вы индексы он elastic старается как можно больше забить эту машину новыми индекс свежими индексами то есть таким образом это надо получает нагрузку не только от того что на нее реплицируются данные но еще плюс свежие трафик свежие индекс из также свежие данные попадают на эту ноту вот поэтому это тоже нужно контролировать и ограничивать ну и в целом рекомендации могут быть те кто работают с ластиком они знакомы то есть целый на коммендации как как как его обслуживать при плановом обслуживания нужно отключите а локацию shard например оставить только только возносила аллоцировать только прямыми это заметно помогает и lasik он туда не будет и аллоцировать какие-то данные которые вы вам не нужны допустим значит вас через полчаса это ну да поднимется зачем он перебрасывать все шарды с одной на другую можем полчаса пожить то желтым бластером когда только у нас доступны только прямые шарды выполнять singt флаш тогда класс так но до при появлении возвращение в кластеры она намного быстрее синхронизируются при очень сильной нагрузки на запись допустим если вы загружаете какой-то у вас балка сообщение идет как раз спайк нагрузки или допустим вы загружаете большой объем данных можно отключить шарды по и потом их создать дать команду пластиковых создал когда я нагрузка будет уже поменьше и несколько команд которыми я люблю пользоваться кроме стандартных который там plaster хелс а я думаю которая всем знакомо есть команда которая позволяет посмотреть red bull именно на каждой ноги что сейчас горячо как какие на запись на чтение какие сейчас очереди есть можно посмотреть какие индексы куда и лоцируется как где происходят recovery тоже очень полезно понимать картину какого что вас приходит в кластеры и в целом allocation explain позволяет понять какие индексы почему не или реплики не арадан не ассоциировались все в удобочитаемым человеческом виде мы используем графа ну для мониторинга есть прекрасный спорта и соответственно grafana тимплей то от этого разработчика который позволяет наглядно им смотреть состояние int кластера и все основные его параметры мы его просто добавили в в наш докер-образ на судеб ловится в докере просто добавили этот экспортер docker и сразу нас метки получаются из коробки приз и диплом так но основные выводы по логирования что логе должны быть централизованы чтобы была единая к эта точка входа чтобы разработчики все понимали это и это опять же к вопросу о скорости должна быть централизация ноги должны быть доступны должны быть кроме того структурированы чтобы данное что чтобы можно было извлекать и ни как можно лучше как можно быстрей куда ценную информацию и должны быть короли раваны например не только коррелированы то о чем я горжусь собой например коррелирована с какими-то другими метриками другими системами которые вы используете например недавно вот это шведский конкурс с таким вот тяжело-тяжело читаемым названием это аналог шведского евровидение то есть конкурс на котором к евровидению происходит в его выбор кандидатов представители от страны и перед этим конкурсом на вам на нашу службу поддержки обратилась мы знаем он сейчас швеции будет большая нагрузка очень трафик который достаточно чувствительный к и мы хотим коррелировать некоторые данные у вас в лугах есть какие то данные которых нам не хватает на даже бородина должна графа не у нас есть метрики мы можем исправить его взять у нас нам не хватает имя данных по конкретным тома идеи каким-то запросам и таким образом они при помощи графа не смогли добавили elastic свеча как источник графа не смогли коррелировать эти данные то есть по таким образом до разок закрыть проблемы опять же получить достаточно быстро очень хороший хороший результат и эксплуатация собственных решений заметно проще то есть сейчас вместо 10 кг даже больше кластеров крыло га которые работали для этого решения у нас и несколько сервисов они опять же это 10 дата-центров у нас например даже не специально выделенной командой специально выделенных людей которые их обслуживают то есть здесь несколько человек который над ними работали и какие то их необходимо делают изменение то они прекрасно и они прекрасно вписан и нашу структуру соответственно тепло и легче обслуживать легче это стоит конечном итоге стоит без или и в целом нужно разделять из кейсы нужно иметь инструменты нужно иметь инструменты для лакирования для трассировки для мониторинга этой серебряной пули нету за золотого инструмента нет который закроет все ваши из кейсы и а как понять какой именно инструмент нужен что именно мониторить какие где используют логе какие требования слугам это нужно обязательно связать с service level индикатор сервиса объектов то есть какие методы что важно для ваших клиентов что важно для вашего бизнеса как на какие индикаторы они смотрят и какие инструменты вам помогут их добиться то есть для нас это во-первых клиентам и оператором важно решать вопросы коммуникации поэтому для нас конвекционные логе так важны а также всем важно знать сколько системе чтобы наша система при не было доступно какую задержку мы делаем то есть сколько времени сообщения находится на нашей системе какую задержка мы добавляем processing ой а также в вопросы ошибок и неудачных там сабитов потому что например ошибки как известно очень часто приводят к маленьким задержкам мы ошиблись у нас задержит задерживающий маленьким и просто всем отвечаем с какой-нибудь ошибкой вот спасибо большое я буду рад вашим вопросам спасибо иван мы тебе очень благодарна за то что приехал пассивный рассказал вот тебе подарок и я хочу на правах ведущего задать тебе один вопрос ну вот если ты хочешь и туча если не хочет что не очень такой же конечно у вас тот человек который приехал сюда не один он приехал с дерилом вилка relation ship офиса это специальная такие люди которые помогают айтишником общаться друг с другом и иногда даже вот с обычным людьми дам вот если тебе есть что сказать о том как такие люди помогли тебе подготовиться для кладу то скажи или вы можете потом лично подойти спросить если вы сами не решаетесь подать доклад то как быть кому обратиться но я как и все эти штуки интроверт и соответственно такие люди прекрасно помогают и придают уверенности скажем так прежде всего но если как а конкретном кейсе давайте мы лучше да лично переговорил да да да есть дискуссия не у меня нет развернутого ответа на это хорошо да вот вопрос 1 ряда спасибо за доклад возможно я прослушал что-то я не совсем понял как вы связали там ну вы говорили что у вас там есть одна транзакция потом вы что-то прошло и как бы 2 транзакций и как бы эта одна транзакция и вы как-то потом их связываете соответственно сервис который узнает о том что это эти две транзакции связаны это происходит а внутри то есть и лаггер uid один сервис этой энергии транзакций начинается на одном сервисе о том что эти транзакции связаны мы узнаем где то в глубине процессинга за ответ на сервис который узнал понял что это 2 транзакции они связаны он это эти данные эти этот соотношение записывает в early action service это другая 2 идиш ника отправляет эти два яичника связаны соответственно мы потом можем получить все связанные техники построить этот граф связей то есть вы чуть позже потом да да да то есть основная правда я в в этом есть вся суть что мы об этом узнаем позже мы не можем сразу присвоить какой-то единый контекст и не можем связать их сразу мы ла-ла-ла гяру им пишем в trace разные разные контекста потом его связывая между собой на ссору и следующий вопрос и руки потом на заднем ряду есть придет и вам спасибо за доклад не на самом деле много вопросов я задам всего лишь 2 1 когда отказались от использовать граф в базы данных от не ухудшает ребят у вас отняли футболки нет моих до сих пор носим молодцы какие а как бы к лексике эти лаги с машин стачек и так далее выписали тоже свое решение использовать стандарт стал то просто и все нет приплела через луг backup and look back gave up in dir 100 либо стандартный какое-то используется либо на самом деле я об этом да немножко заказал у нас есть библиотека для теле для некоторые сервисы которые объединены вот именно вот в эту часть взаимодействия с например с операторами там где библиотека которая позволяет из из из кода легко логировать то есть как вот эту операцию сбора резал винга правильных локейшнах происходит на той библиотеке а так многие используют gave up in der а насыщаете логика дополнительного ч насыщаете ими там имя поводу там не знаю машины и тогда или все там же происходит в этом какие-то пензе у нас есть несколько небольших русские всегда когда мы насыщаем на стороне logs сервиса например там бывает из разных локейшнах приходит то есть и есть определенные кейсы когда нам нужно правильно к ecu кое-что подправить исходя из исходя из нашей системы на насыщаем но мало основной насыщение происходит именно в коде спасибо два человека в последнем ряду начнем пример с левой стороной даже микрофон уже есть у нас в правой стороны зала хорошо да а но далее вот у меня был в рукава открыты двери вонь да да я вижу а у меня был вопрос про выбор инструментов то есть когда вы отказались от горы logo можно было выбрать что угодно вы остановились на власти ксир чьи вопрос почему потому что если у вас там есть проблема с записью большого количества логов можно было взять ну например тот же клика usb or который уже очень много говорили вот вряд ли вам нужны все фичи полнотекстового поиска там streaming поиск по окончании логе всегда быть на имеют ну как строгий формат все-таки но смысле заранее захардкожены на самом деле нам действительно нужно было полнотекстовый поиск поэтому какие бы даже мы добавляли свой собственный варды лимитер толкине за добавляли определенные настройки а по цене но это все конечно не первая причина первопричина было то что это выбор был сделан два года назад даже может быть приплюснуть чуть больше когда я клык ли каас еще не был настолько когда он еще тормозил сейчас раздаем что он не тормозит вот и плюс экспертиза по обслуживанию кластеров власти все еще у нас компании уже было накоплено довольно приличное нам нам было так проще блок да нет да такой достаточно еще один вопрос галина первый ряд или да я вижу пример спасибо за доклад первые пять десять минут я думал что все идет такой штуки ой какой панд racing или о полноте lamie3 да нет нового мы к ней это на самом деле то что мы сейчас делаем с рейтингом мы действительно сейчас внедряем up and racing standard напомнил и десна не от nec открыто не открыто и решение light степ но просто я не знаю я может кто-то раскрываю но это еще не законченный проект поэтому я про этот рассказал мне очень много скажем так пояснение большой опыт телеметрии это об интересе ну плюс ещё одна часть и вот тот график где были изображены например span и по раскладке запросы через все микро сервисы и обратно они как раз от дают вроде как полный набор инструментов по ну вот и ваш асинхронной схеме в том числе не так это совсем свежий продукт а у пони телеметрии в данный а я кстати тут тоже проверял эту информацию и они очень понял насчет наполнителями я не помню точно сколько из какого на каком конкретно продукте или на каком каком конкретно о сайте в общем я тоже видел эту дискуссию о том что необходим похожая проблема что связи между trace omi возникают в результате бизнес-логике и опять же это сейчас я не знаю решение даже свет вижу что там более в дискуссии 10 дней назад последний пост и опять же то есть это на основе дискуссий о том что это нужно решать мы возможно тебе же чем поговорить да в дискуссии дорога лаки после вопросов привет спасибо очень интересный доклад я хотел простить ты говоришь ушел a leading из вашего сервиса да да а куда он перешел то есть параметр не знаю метрики они немножко задержкой до как бы иногда важно налогах понимать и ну что что-то идёт системах не так дают какие-то летнему мы взвесим не перебил нет в общем то хотел понять куда вошли alert alert и ушли в аллерс менеджер prometheus а в основном для критических сервисов мы скрепим в про митю все каждые пять секунд то есть у нас intervals и настраиваться на каких-то сервисах это в общем то от 30 секунд до 5 секунд для наиболее критических сервисов в принципе это достаточно до дата то есть по теме по теме про my party метрикам внутри prometheus alert manager высылает alert и таким образом в принципе мне кажется при 5 секунд достаточно потому что для самых критических вещей там люди сидели сидит человек и смотрит на экран на самый критический график еще вопросы поднимайте руки привет массива за так от вот вы бьете по словам да вот это генерируете по словам вы увеличиваете таким образом количество токенов и например тот же самый вид вы будете бить на несколько токенов вот вам это не мешает uid записывается в отдельное поле то есть мы под океаном бьем именно сама текст грубо говоря какая то текст сообщения а то есть у вас месяцем грубо говоря тот тот которым много слов он одним полем контекстные поля вы как и варды используете да да как какие варды ну либо если это какие-то виды the city longhi айдишники то соответственно никак числовые поля до совершенно верно и если у нас нет больше рук то они выбери пожалуйста тот вопрос который понравился больше всего мне кажется хороший вопрос про open tracing и про то-то они сюда пока идешь помни как тебя звать где-то работаешь и почему вот тебе важно было обозначить трава контроле sing плюс я и за кредит плюс я из софитов не видел лицо привет меня зовут руслан и я работаю в университете итмо у нас много мелких проектов и как раз скоро скорее всего станет проблема похожий от рейтинга поэтому я активно изучаю все эти темы и вот именно в этом контексте было было полезно послушать ее задавать вопрос спасибо отлично спасибо"
}