{
  "video_id": "0dyRrnIH32I",
  "channel": "HighLoadChannel",
  "title": "Клиентоцентричный подход к управлению данными / Александр Синицын (Сбер)",
  "views": 57,
  "duration": 2516,
  "published": "2023-10-06T07:15:31-07:00",
  "text": "микрофон работает что ж пару слов обо мне Я последние несколько лет работаю в Сбере на занимаю роль корпоративного архитектора и специализируясь на задачах связанных с управлением клиентскими данными Сегодня я расскажу о том как строится наши клиенты центричная архитектура Как строится клиентоцентричный подход по управлению данными Ну и наверное прежде чем приступить к этому подходу нужно погрузиться в небольшой контекст примерно 10 лет назад Сбер Как таковым клиентам не управлял существовало несколько систем с отдельными продуктами которые жили обособленно например когда клиент приходил в отделение одновременно пытаясь оформить вклад и кредитную карту его дважды идентифицировали его данные дважды заносили в систему при этом данные в этих системах друг с другом никак не синхронизировались очевидно что с ростом развития бизнеса с появлением новых бизнес продуктов такой подход как бы мешал развиваться а например невозможно было собрать информацию о всех продуктах которыми обладает клиент невозможно было строить кросс-продажи для того чтобы победить эту проблему появилась система класса МДМ от одного из российских вендоров которая работал по следующей лойке данные о клиентах существующих бэковых системах сливались в МДМ там происходило вычистка дублей и появлялась некая актуальная информация о клиентах после чего эти данные верно распространялись тем потребителям кому они были Нужны но было несколько но во-первых сбор Таких данных происходил в дикой задержкой как правило это случалось по ночам а иногда и даже с задержкой в сутки во-вторых далеко не все например фронтальная система обращались в mdm как следствие появлялись проблемы связанные с искажением данных которые имелись примерно с 18 года вместе с большой технологической трансформации начался скажем так этап клиентоцентричного проектирования что он себя включал Ну во-первых с точки зрения фронта все фронтальные системы которые работали с клиентскими данными направлялись в одно место в один источник данных То есть у нас появляется единственный источник самых актуальных достоверных данных при этом с точки зрения хранения бэковых системах из них практически полностью исключается дублирование этих самых данных и связь продуктов Согласие обращений с клиентом выполняется через общий идентификатор естественно этот идентификатор выдает мастер система а собственно это тот Dream которому мы идем наверное можно сказать что сейчас его достигли процентов на 70-80 так моё экспертное заключение Давайте теперь погрузимся во внутрь что же у нас находится в середине в середине находится Мастер система единый профиль и дайте разберемся как она работает что есть внутри а прежде надо отметить что процесс создания мастер-копия это длительный проблемный процесс как же мы его решали собственно были взяты Core системы карты вклады кредиты в которых на тот момент времени жили клиенты всех Этих клиентов пропустили через сито стандартизации и дедупликация очистки дублей В итоге на выходе из 600 миллионов запись у нас получилось около 100 миллионов клиентов понятно при этом что у нас осталось некой серой масса внизу влево она видна это те Клиенты у которых были недостаточные данные для того чтобы принять решение о том что конкретная запись принадлежит отдельному клиенту а давайте же разберемся что у нас посередине что представляют вот эти чудесные бублики стандартизации дедапликация процесс стандартизации исходя из названия очевидно предполагает создание неких стандартизированных данных приведенных к единому формату на примере адреса Или например номер телефона очевидно можно утверждать что их можно завести в систему различным способом для того чтобы с этими данными потом можно было как-то работать ими управлять строить индексы для поиска их Нужно привести к единому формату за это у нас отвечает отдельная выделенная система которая этот сервис предоставляет помимо приведения к правильному формату данные также обогащаются например по номеру телефона мы сразу определяем К какому сотовых операторов он принадлежит а у адресов тоже есть отдельное развесистая структура которая до обогащается но и к слову сказать практически все домены клиентских данных которые мы храним проходит через стандартизацию далее магической де дубликация что же это такое по сути это алгоритм определения дублирующих записей которые предполагает сравнение группы атрибутов у разных записей в случае равенства принимается решение о том что эти записи принадлежат одной сущности в случае с клиентом две записи схлопываются в единую дублирующие записи деактивируются Но основной профиль становится тем самым золотым и основным чуть-чуть нырнем внутрь как технически это самое дедупликация работает в нашей системе нужно отделить операции вставки то есть создание новых клиентов от существующих апдейтов как чем они отличаются 1 При появлении запроса на создание нового клиента дергается специально выделенный сервис который в Реал тайме в синхроне для вызывающей системе режиме пытается понять А если этой записи дубли по сути этот сервис обращается в хранилище делать поиск и пытается синхронном виде понять А если пересечение очевидно что ответов всего два клиент либо найден то есть пересечение уже найдены и это дубль Ну либо он не найден что происходит Дальше Так поспешил что происходит Дальше если клиент был заранее найден выполняется апдейт существующего Клиент уже существующим айтишником а Ну соответственно если он был не найден он создается заново что важно вне зависимости был найден дубль не найден дубль все события складываются в отдельную очередь для последующей обработки после того как сообщение сложились выполняется ответ источнику запросов что же происходит Вот в этой внутренней очереди с ней ситуация следующая те потребители которые приходят и приносят новых клиентов естественно работают с жестким slm и ожидают молниеносного ответа но сделать полноценную дедупликацию сравнить А если у нас дубли иногда невозможно для этих целей собственно есть отдельный оффлайн процесс который синхроний делают эту самую дедупликацию просто для понимания приведу пример почему это нельзя делать в реальном времени то есть Понятно сравнить две записи по трем двум атрибутам Понятно можно сделать в моменте но например когда требуется поднять несколько профилей Взглянуть на их историю изменения поднять понять например как менялся паспорт у клиента в течение жизни это в Реал тайме сделать невозможно поэтому есть механизм полный дедупликации которая работает в оффлайне а в случае если источник изменений приносит апдейт существующего клиента Здесь всё просто изменение сразу накатываются в основную базу потому что мы уже знаем Заранее с каким клиентом Мы работаем его где-то идентифицировали раньше но при этом после апдейта все равно запускается этот процесс дедупликации что важно с точки зрения системного взаимодействия в рамках де дубликации у нас происходит деактивация одних идентификаторов соответственно после того как мы объединили профили всегда идет уведомление множество потребителям о том что часть аишников деактивирована часть из них соответственно стала актуальной а тема де дубликации достаточно чувствительная с точки зрения клиентского опыта клиентского пути очевидно что если мы вдруг в своих алгоритмах ошибемся приведем ситуации как изображена на картинке Я думаю ни один из клиентов не будет счастлив если он попадет в один из Вот таких профилей что здесь можно сказать когда мы стартовали свою запускали свою систему для определения дублей были идеи использовать какой-то алгоритм из машинного обучения Но от этой идеи честно отказались потому что в случае с каким-то вероятностным вероятностной моделью всегда был риск того что непонятно А насколько вывод был верный и что делать если он был действительно неверный в связи с чем у нас работает жесткие правила жестко пересечение сочетание разных полей но и последнее что хочется сказать что процесс создания новых алгоритмов выявления дубли он на самом деле не прекращается несколько лет назад Мы начинали там примерно с 20 алгоритмов сейчас их около 100 понятно что любой алгоритм его можно заложить там в некую модель но как бы любая любой алгоритм может развиваться о реальность жизненно пример с Наталией Петровой мы однозначно знаем что есть некий некий клиент Наталья ее профиль были в нескольких системах у них точно у этих профилей точно совпадает дата рождения документ удостоверяющий личность Но вот имя написано двумя разными способами кейс кстати с Натальей вот такой прям самый жирный с ними было очень много проблем что же мы делали с такими кейсами если мы применим примем решение что какой-то из этих профилей правильный всегда есть того что мы не угадаем тем самым как бы навредим клиенту навредим своим процессам вывод очень простой для таких а-а неоднозначных ситуациях все наши профили имеют свою э статусную модель которая говорит о том насколько мы конкретному профилю можем доверять или не доверять вместе с введением этой статусной модели были доработаны все фронтальные системы которые могли эти клиентские данные изменять все системы которые так или иначе соприкасались с клиентом через сотрудника были доработаны следующим образом все эти системы научили работать с той статусной моделью которая хранилась мастер системе и соответственно при обращении такого клиента в отделение у операционистов на экране вводилось специальными подсказка которая мотивировала или должна сказать заставляло эти данные должным образом а сверить б занести в систему соответственно распространение этих данных по кучу потребителей Мы запускаем только после того как эти данные полноценно сертифицируем то есть мы можем им верить и доверять а разобрались с фронтами разобрались с источниками данных и то как мы собираем золотую запись Теперь давайте разберемся А что мы с ней делаем дальше условно всех потребителей можно разделить на четыре части первая группа самая многочисленная это системы процесса потребителя которые приходят за профилем клиента поштучно нам при звонке в колл-центр по номеру телефона нужно понять что за клиент чтобы сказать ему Добрый день и назвать его по имени при совершении например переводов по тому же номеру телефона нам также нужно подтянуть его фео Ну и таких процессов на самом-то деле у нас абсолютно большинство таких потребителей больше всего вторая часть потребителей это как правило б системы которые могут запускать свой внутренний процесс в случае если на клиенте установлен тот или иной маркер а ну в качестве примера если мы на клиенте поставили блокирующий маркер по информации от компании мы можем заблокировать клиенту доступ в мобильное приложение Сбербанк онлайн честно говоря блокирующих маркеров достаточно много и есть множество внутренних процессов которые на них зашиты третья группа потребителей это те потребители которые по особенностям своей специфики работают со своей собственной копией данных То есть им не для реализации процессов нельзя ходить всё время в сервис поиска им нельзя сидеть просто на событийной модели им нужно Что называется под ногами хранить копию данных пример фродомониторинга который хранит связи в виде графов между разными клиентами для того чтобы делать свои скажем так проверки четвертая группа потребителей это те системы те процессы которые оперируют обычно данными в пакетном режиме обычно это задача либо аналитика либо какой-то отчетность либо Эхо к аналитика разберемся как же всех этих потребителей получает доступ к клиентским данным наверно самый первое самый массовая это те кто приходят сервисы поиска в нашей системе реализовано множество сервисов наверное что важно отметить у нас нет одного большого мастер сервиса на все случаи жизни нет требованиям в том числе бизнеса по требованиям безопасности У нас под каждого потребителя Ну или подгруппу потребителей создаются свои выделенные сервисы Почему так тут есть несколько аспектов То есть первый Аспект который вытекает из требования безопасности Мы должны соблюдать принцип достаточности то есть потребитель должен выгребать тот объем данных который нужен ему для реализации бизнес-процессов грубо говоря мы по запросу должны дать только то множество которое ему множество атрибутов которые ему положено вторая часть это особенная реализация фильтров с теми статусами доверенности и актуальности профиля про которые я в самом начале разговаривал так как таких потребители У нас очень много есть своя специфика уже Техническая реализация данные которые хранятся в профиле лежат в слое данных которые представлены двумя решениями основная часть лежит в базе погреce рядом с ней поднят кэш с этими же клиентскими данными на базе Игната соответственно все запросы на поиск сразу направляются выгнать Что позволяет более быстро отвечать тем потребителям которые собственно за этими данными приходят и таким образом получаем вот тот самый хайлот который дает порядка 20000 TPS там в секунду в Пике по всем потребителям а важно отметить как только мы начали делать множество сервисов для разных потребителей мы сталкивались как бы с банальными такими проблемами Дело в том что при первых скажем так релизах наши сервисы работали по черным спискам то есть они работали серии Верни мне всех за какими-то исключениями к чему это приходило приводило приводил это к тому что как только у нас появлялись новые типы клиентов расширялась статусная модель нам приходилось постоянно дорабатывать старые сервисы вот такую жизненный прям пример с которым было очень так много проблем появилась такая бизнес задача с беркитс отдельный профиль детей очевидно что с детскими профилями у нас работает выделенные потребители соответственно всех прочих нужно было какой из этого простой вывод мы теперь все новые сервисы делаем Заранее с определенными списками чтобы потом не приходилось их дорабатывать Поехали дальше вспоминаем по тех потребителей на примере фродомониторинга которые внутри себя хранят длительную копию данных таких систем прямо сейчас наверное на самом-то деле все меньше и меньше но на том этапе времени пока мы мигрировали легасе когда мы переходили от 2 к третьему этапу это тема была архив для нас актуальна как же этим потребителям мы отдавали данных любая транзакция на изменение в базе приводило к тому что эти изменения отбрасывались в отдельную очередь на который был подписан специальный компонент Design Maker который по каждому из ивентов определял а кому же такой винт интересен очевидно наверное изменение Фил или там паспорта Нужно отдавать практически всем изменения контактов e-mail of телефонов нужно о каком-то ограниченному числу потребителей собственно discision Maker определял кому что распространять и по каждому потребителю готовил отдельно очередь Куда эти события складывал далее на выделенные события был подписан было подписано отдельное приложение которое из полученного события готовила сообщение для конкретного потребителя очевидно что систем много у всех свой API для каждой системы нужно было сделать свой собственный маппинг или сделать свое там не знаю учесть отдельную специфику Ну простой пример у нас была такая система которая для одного бизнеса операции когда мы изменяем паспорт и ФИО предполагала последовательный вызов нескольких сервисов собственно отдельное приложение отвечающее за распространение данных в эту систему эту задачу делал что важно после того как данные отдали систему потребитель в обязательном порядке Мы ждали и ждем ответную квитанцию если квитанции не получено или получено например ошибка стандартно запускается Несколько попыток переповторов и Если уж переповторы не помогли мы фиксируем инцидент специальные люди которые управляют занимаются сопровождением системы имеют свой dashboard где такие отклонения фиксируются соответственно если кто-то недоступен запускается Процесс формирования инцидента и разбирается почему же какая-то система не обрабатывает запросы что в таком подходе подкупает понятно что мы до бесконечности глубоко можем кастомизировать процессор распространения под конкретного потребителя мы обеспечиваем гарантию доставки эту гарантию контролирует источник При таком подходе у нас распространение в каждого потребителя работает полностью изолировано соответственно мы можем регулировать интенсивность распространения и в случае необходимости Если вдруг это потребитель упал Всегда есть возможность переповтора но очевидно платой за такие плюсы является стоимость и сложность разработки Я наверное уже чуть-чуть повторюсь Но от такой схемы распространения мы стараемся отходить она еще существует Но на самом-то деле еще раз и делать надо хорошенечко подумать если такой паттерн применять то нужно взвесить все плюсы и минусы насколько компания готовы инвестировать в такой способ распространения Я думаю наверное там ребята в середине сидят и задаются вопросом а зачем так сложно Почему так заморочено Почему бы единожды не выплюнуть сообщение в ту же кафку она у меня здесь фигурирует и не подписать на эти события всех потребителей мысль Абсолютно верно но мы в целом разделяем Но почему в лоб так задача не решаем тут есть два момента Первое это та же самая безопасность которая запрещает в общедоступном режиме выгружать данные если мы выгрузим это в какую-то публичный топик очевидно что управлять несанкционированным доступом к нему задача достаточно сложная особенно в условиях большой компании тем не менее и винтовой механизм и в Андрея архитекчи У нас тоже присутствует в данном паттерном мы распространяем так называемый типовые события То есть это те самые ивенты получив которые потребитель Может стартануть свой процесс Так извините а что-то у меня кликер перестал кликать раз раз и ничего не происходит о случилось спасибо а типовые события собственно типовые ивенты Мы кладем в публичную кафку при этом Под каждый типовой вент создан отдельно выделенный топик и любой потребитель Может к ним подписаться их обрабатывать мы как источник из системы единого профиля не проверяем Кто на них подписан и не контролируем что потребитель эти сообщения вычитал успешно обработал с помощью таких такого метода распространяется событий смены клиентской воде вследствие де дубликация объединения про которые я в самом начале говорил и с помощью него распространяются отдельно ивенты по установке или снятию различных признаков на самом профиле при этом изменения условного ФИО или там дата рождения или документы удостоверяющего личность там нет движемся дальше так опять кликер нас подводит так коллеги пока я продолжаю кликать о накликал расскажу про третий паттерн распространение которое у нас есть это комбинированный вариант представляет из себя наверное симбиоз механизма публикации типовых ивентов и Механизм запроса есть отдельное типовой вент который не содержит бизнес данных но при этом потребителю говорит о том что у клиента изменился тот или иной блок соответственно если потребителю это интересно он обращается в сервис поиска и получает то что ему положено но и запускает свое свою обработку в том режиме как требуется движемся дальше так мне опять Я дико извиняюсь но у меня подводит кликер к чему же мы приходим в конце какой же итоговое окружение появляется понятно что в центре есть система у которой есть большой движок на обеспечение большого числа запросов на поиск естественно и Процесс поиска и создания сопряжен сервисом стандартизация есть внутренний движок обеспечивающий дедупликацию для любых потребителей сделан механизм распространения будь то это распространение точка точка point-point либо это и винтовая модель каждый фронт который генерит изменения данных работают в единой логике по единым правилам которые позволяет собственно развивать этот процесс в Едином ключе напомню У нас есть еще 4 потребитель про которого я до конца не это те потребители у которых есть задача работать с данными в пакетном режиме любая аналитика любая отчетность она не делается на базе единого профиля не на базе скажем так опер системы все делается на реплике фабрики данных это наверное отдельный пластмар который наверное можно сделать отдельный доклад но ключевой момент что таких потребителей Мы тоже удовлетворяем Ну и последнее любые клиентские данные имеют способ устаревать более того есть требования предполагающие необходимость их регулярно актуализации вот для того чтобы поддерживать данные в актуальном состоянии естественно мы являемся активным потребителем сервисов госуслуг текущий момент есть множество скажем так государственных услуг есть разные сервисы от разных ведомств В общем в двух словах все эти сервисы позволяют поддерживать клиентские в более актуальном состоянии Или например помогают их просто проверять на актуальности валинность собственно без такого компонента мы не можем обеспечить актуальные данные о клиенте Я уже двигаюсь К последним слайдам чуть-чуть специфики сбера очевидно что Сбер это большая компания с большими внутренними процессами иногда их даже можно сказать бюрократии всем этим надо как-то управлять для того чтобы любые архитектурные изменения происходили в Едином ключе вот в той парадигме про который я рассказывал У нас существует специальная архитектурные стандарты которые на любом этапе жизненного цикла по контролирует корпоративный архитектор Будь это этап проектирования будь то это участие в прием-значных испытаниях или вообще некий результат аудита как же система работает прямо сейчас есть несколько требований которые сводятся к простым требованиям первое мы как бы запрещаем хранить клиентские данные где-то кроме мастер это система второе вытекающие отсюда Мы заставляем в каждой из бэковой системе хранить идентификатор клиента как связь с основным профилем и быть подписанными на события изменения этого идентификатора ну немножко как бы связанная Задачка это есть запрет на создание интеграции в которых в качестве идентификатора клиента используется что-то отличное от квайнта ID Как это работает по жизни собственно Если вдруг команда осознанно допускает отклонение от этих стандартов на неё заводится тех долг есть отдельная процедура как этот тик долг устраняется у него есть свой срок и идея в том что если команда в договоре срок этот тик долг не устраняет она получает запрет на дальнейшее развитие это такое внутреннее подспорье которое отдельным образом мотивирует команды к этой самой информация и помогает приблизиться к этой самой клиентоцентричной архитектуре мой финальная Зачем это все И что это нам дает очевидно агрегируя данные в одном месте так извиняюсь Спасибо очевидно агрегирую данные в одном месте У нас упрощается процесс ими управления за счет того что клиентские данные живут только в одном месте мы прекращаем использовать естественные ключи как идентификатор клиента у нас уменьшается число жалоб вспомним пример с Натальей Петровой вот несколько лет назад для того чтобы отобразить продукты в мобильном приложении Сбербанк онлайн Мы клиенты продукты клиента искали по связке филдр очевидно вот если мы по Наталье пробежались по всем системам Мы скорее бы всего не получили полный Спектр ее продуктов сейчас сбор продуктов работает по идее за счет этого собственно подобные жалобы не могу сказать что сходит на нет но они значительно уменьшается следующий момент за счет агрегации данных в одном месте клиентских данных нам проще реализовывать те требования которые накладывают законодательство за счет уменьшения числа копий клиентских данных естественно снижается риск их несанкционированной утечки со всеми вытекающими Ну и наверное последнее что хочется сказать при агрегации данных о клиенте в одном месте и выдаче эквайнт ID всем у нас реально упрощается развитие бизнеса с той точки зрения что нам проще собрать продуктовый профиль клиента нам проще собрать аналитику по нему вот до того момента времени пока подобный подход не использовался подобные задачи несли очень эти задачи было сделать очень сложно на этом У меня все Надеюсь было познавательно и опять кликер меня подводит Спасибо прошу если понравилось оценить доклад по соответствующему коду Если вдруг желаете пообщаться после можем пройти на стойку сбера жду ваших вопросов Александр спасибо большое сейчас добежим и зададим все вопросы держите ближе Добрый день меня зовут Илья Вот вы сказали что вот этот подход у вас где-то на 70 процентов внедрен В чем основные сложности у вас сейчас остались А И вот можно сразу второй вопрос Да вот у нас в стыке есть еще устаревшие систему у которых не помню Нет полноценного рэста если у вас похожие примеры как вот таким подходом с таким системами бороться Давайте Про первую часть почему это не происходит одномоментно Все очень просто есть Пласт систем Ну например старая система в которых жили вклады и счета или например старый процессинг очевидно что мы такие системы по щелчку пальцев изменить не можем и для того чтобы достигнуть 100 процентов трансформации этих систем как правило это либо полная замена либо полная перепись делается одновременно с изменением подхода по клиентам это вот как бы наша реальность часть систем Уже трансформировалась выведена из эксплуатации и так далее но отчасти еще в процессе поэтому сейчас еще не сто процентов А вот те самые 780 А вот насчет резца Я немножко не понял можете вот чуть-чуть да уточнить Это на каком этапе нестыковка это вот когда система вот у обращения То есть когда система нет национального рта но не происходит изменение клиентских данных она не может в Единый шлюз на шину отправить эти данные своевременно О слушайте Но я честно говоря такой наверное аналогии У нас вот в моменте честно не вспомню если было вопросы серия а что делать если потребитель не готов дёргать тресс-сервис может быть в этом был Ну это тоже есть вопросы как быстро обновить данные да что будет уменьшить количество дублей да то есть потому что в разных системах данные меняются я понял ответ очень простой делать это максимально быстро то есть вот когда роста нет полноценного получается вот эти вот оффлайновые шлюзы которые замедляют смотрите А у нас же естественно всё было постепенно э начиналось это тоже с теми же самыми задержками которые были актуальны для второго этапа то есть кто-то нам отдавал с какой-то тоже задержкой клиентов но мы просто Шаг за шагом с каждым из таких источников работали и ну какого-то одинакового решения нигде не было тут скорее смотрели на конкретную специфику конкретного источника Спасибо какого-то золотого рецепта К сожалению нет Здравствуйте Вопрос такой по поводу ошибок алгоритма вы сказали что у вас был второй между вторым и третьим этапом множество интеграций со старыми системами и вы их оповещали о изменении идентификатора Вопрос такой что был Что будет если уязвимость была в алгоритме и двух разных людей склеили в одного Ну то есть такая насущная проблема отлично вопрос жизненный смотрите сейчас количество вот этих вот ошибочных объединений по факту разбирается всегда в ручном порядке как мы с ними разбираемся это либо есть триггеры по внутренним процессам которые говорят вот здесь у меня что-то сломалось либо что самое негативно неприятное Для нас это жалобы для обращения от клиента что происходит Дальше есть специальная выделенная группа людей которые работают с подобными обращениями и В случае заключения о том что действительно было ошибочное выполняет обратную операцию он разъединяет клиентов естественно мы Без этого жить не можем учитывая что таких операций честно наверное в штуках очень мало под рукой меня так в моменте статистики нет но это реально вопрос штук в день или даже наверное в неделю Но это разбирается грубо говоря в полу ручном режиме раз раз Александр вопрос Следующий Мы же сейчас живем все уже в цифровую эпоху каждый практически пользователь который приходит с Беркут еще он оставляет много цифровых следов и вот тут есть два момента мастер система она должна с одной стороны объединять максимальное число данных о клиенте в себе с другой стороны она не может держать себе все данные каждого сервиса и вот по идее мастер система должна чисто персональные данные держать себе где сейчас проходит эта граница еще один отличный вопрос смотрите мы регулярно проходим дилемму А что же у нас в этот профиль входит понятно что там с каким-нибудь документами контактами вопросов не вызывает не возникает но на самом-то деле вот определение места что мы храним в одном системе А что не храним но эта задача корпоративного архитектора и здесь какого-то универсального ответа тоже нет по сути Ну общий алгоритм принятия решений сводится к тому что мы смотрим А что это за процесс А что как он будет развиваться дальше А вообще А что вокруг него а-а естественно у нас нет задачи затянуть всё в одну систему ну Иначе она просто лопнет Ну и так немножечко из внутренних моментов То есть например у нас очень регулярная тема А давайте-ка мы в Единый профиль положим признак наличия или отсутствие не знаю продукта согласен ещё чего бы то ни было а такой Соблазн всегда возникает э откуда он идёт Ну как бы все хойка такая О'кей у вас касание с клиентом начинается с поиска этого профиля давайте мы сразу поднимем эти признаки и будем строить свой процесс А где-то мы с этим соглашаемся в эту сторону идём мы часто принимаем решение эти признаки хранить в каких-то третьих системах которые более для этого подходят Надеюсь ответим Здравствуйте спасибо за доклад Александр Вопрос такой как вы избегаете эффекта гонки при изменении данных остались ли у вас какие-то локальные кэши в системах потребителях а может чуть-чуть расшифровать не очень улавливает Ну вот вы говорили что все данные хранятся в Мастер системе Да локальных шеи в потребителях вообще никаких стремимся их свести к нулю отдельные каши Все равно остается но Вот пример мониторингом И он останется Что называется навсегда в целевом виде Ну и вот в тех местах где эти каши остаются Как вы боретесь каким-то эффектом гонки Спасибо чуть-чуть не проснулся не ловил А я привел два паттерна вот на текущий момент основной из них это распространение по схеме точка точка и ну как бы текущая реализация нам предполагает что мы данные доносим задержкой в районе нескольких секунд как правило текущих потребителей это удовлетворяет соответственно если потребитель вдруг упал эти сообщения не принимает но здесь как бы вопрос потребителя наверное Вот таких вот прям живых кейсов у нас произошел какой-то рассинхрон и это как-то негативно отразилось на процессы к счастью у нас нет и Ну вот тот транспортный лак по времени пока мои сообщения доставим там в несколько миллисекунд или секунд но он текущую потребность устраивает друзья еще один вопросик и у нас время закончится но мы всегда сможем продолжить дискуссионной зоне так вижу скажите вот говорили про то когда у нас два клиента к одному ID прикрепились этого разрешаете вручную А что делаете ситуации когда у одного клиента несколько сгенерировалось один раз он заходил по одному документу другой по-другому в разные системы и несколько суть кейсы что одного физического лица есть несколько профилей это вариант допустимый простой жизненный пример клиент поменял паспорт пришел в отделение и операционист поленился посмотреть на 19 страниц Мы создали второй профиль собственно после того как мы клиенту оформили продукт не знаю от него могла пойти жалоба или он мог прийти в отделение еще раз добавив какие-то другие атрибуты мы можем понять что эти две записи принадлежат одному клиенту в результате выполняется воспаление дублей появляется мастер ID и кейса когда у одного физика есть несколько квантоиде он для нас не применим Он невозможен Так ну вроде все Александр Я думаю что на этом сессию вопросов и ответов мы потихонечку переместим в дискуссионную зону Спасибо за выступление и теперь самое важное Какой вопрос тебе больше всего понравился я точно запомнил вопрос кажется от Никиты про как мы действуем случае разъединения профилей так еще наверное Давайте последний вопрос отметим про кейс А как же быть что у клиента несколько один подарок тогда у меня первого первый вопрос тот подарок который у нас есть а второму задавшему вопрос будет мой личный персональный подарок он у меня тоже заготовлен друзья Спасибо вам за такие интересные вопросы не убегаете наши помощники вам дадут призы Александр спасибо большое от компании от конференции хайлот У нас тоже есть маленький Презент за такое шикарное выступление Спасибо большое Давайте еще раз поаплодируем и напоминаю голосуйте за доклад если оставить еще какие-то вопросы ловить Александра в дискуссионной зоне"
}