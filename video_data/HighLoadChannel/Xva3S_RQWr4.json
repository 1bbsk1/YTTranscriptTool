{
  "video_id": "Xva3S_RQWr4",
  "channel": "HighLoadChannel",
  "title": "Reindexer - очень быстрая in-memory БД с полнотекстовым поиском / Олег Герасимов (Рестрим)",
  "views": 4311,
  "duration": 3150,
  "published": "2018-10-30T02:14:58-07:00",
  "text": "меня я работаю в компании restream сегодня рассказал работали вот и перед тем как начать собственно рассказ про саму базу я бы хотел чучуть расказать про компанию restream собственно в рамках задать которой ты ваза была сделана компания restream она не очень известно на небосклоне нашей стороны но вместе с тем мы реализуем весьма сложные и масштабные и амбициозные проекты наверняка вы знать какой проект как видеотрансляция вырвав президента поэтому все видели смотрели этого собственно наш разработка также другой наш большой проект это система интерактивного телевидения то есть у компании ростелеком есть сервис контрактного телевидения у сервиса там порядка 50 миллионов абонентов так вот собственно саму платформу все приставки всего по разрабатывает наша компания то есть мы делаем масштабные высоконагруженные проекты вот собственно сегодня расскажу про базу данных или яндексе а значит так что такое render render это in memory документ ориентированная база данных общего назначения значит с одной стороны индексе ртс оставить себе скорость таких решений как тарантул редис и римом конечно то есть вот классический подход in america база данных которая работает очень очень быстро имеет отдавать там сотня или даже миллионы ответов в секунду но с другой стороны яндексе обладает богатой функциональностью по выборкам и позволяет делать должны запроса такие как join my sweet рад и полям массивом и прочее прочее сложно что обычно находится в арсенале уже более тяжелых там реляционных баз данных но перед тем как приступить к описанию свой индексирует чуть расскажу о том какую задачу мы решили решали для бизнеса и как мы пришли к разработке собственного баз данных линда ксир собственно мы разрабатывали платформу для интерактивного переведя нового поколения значит у нас уже была вегасе платформа запущенная 2011 году которая была рассчитана на клип толстый клиентов то есть это допустимость две приставки или мобильные телефоны которые приходили на платформу и одним запросом получали так сказать ведь доступны для да контента после чего процессе все это уже внутри себя без обращения к серверу вот но как говорится времена меняются 2016 году когда мы начали проектировать такой подход уже был неприемлем поэтому появилась задача на разработку новой платформы на цельный на api тонкого клиента то есть что капитан клиент думаю все знают это когда под каждую страницу приложения или веб-сайта происходит запрос на бэкенд по данные которые необходимо отразить на этой странице вот плюс у нас очень сложная бизнес-логика фильтрация контента на самом деле вот не знаю возможно кто-то был на докладе иви про то как они пережили с свингса на elastic одним собственно из аргументов было то что у них тоже очень сложная логика фильтрация контента с которой уже свинство каким-то причинам не справлялся если говорить предметно что такое сложная логика фильтрация контента content это фильмы сериалы телеканалы или телепередачи значит есть доступность телеканалов или фильмов или телепередачи по тарифным планом каких тарифных планах они доступны в каких-то нет также есть доступность по регионам запущен в одном регионе фильм доступен в другом недоступен скажем всего каких-то маркетинговых акций или ограничение правообладателей которые тоже на передаваемые на просмотр контент накладывать он ограничение как пример допустим этот контент можно воспроизводить только в таком регионе только на таких типах устройств а на других устройствах это воспроизводить нельзя вот плюс ну стандартный набор пользовательских фильмов когда пользователь на визируется по каталогу с фильмами он имеет возможность фильтровать фильма по годам по актерам по жанрам по признаку детский не детские или по поискать полна текстом по собственно всей базе там контента как фильмов так и телепередачи вот и в довершение к требования у нас еще есть требование это 5 кило рпс 1 серверов то есть 5 тыс и запросы в секунду с учетом всех вот этих правил фильтрации которые здесь собственно отражены вот я вот здесь нарисовал очень упрощенную схему данных который участвует запрос мвд по фильмам эта схема она очень сильно упрощена но чтобы она влезла на экран с таким довольным телек том naught ровно такая значит нас есть табличка фильмов и в ней есть целый ряд полей массивов то есть связь могут много практически везде значит фильмов есть связь таблицы ассетов ассеты это грубая сами файлы с видеоконтентом то есть и bts либо там mp4 вот одного фильма может много сетов в разном качестве например есть фильм в hd качестве фильм hd качестве или фильмы в 3d также ассеты доступны не во всех локациях то есть возможно кого ты фильма для одной локации сказал дивов только будет 1 урона видео сера который находится во владивостоке а уже в москве будет другой видеосервер а где-нибудь екатеринбурге асета почему то нет и этот фильм соответственно до исключить из выдачи так как у него нет возможности показать пользователю 2 табличка который делается здесь join это пакеты услуг ну фильма входит в пакеты услуг если пользователь не доступ пакета услуг в которой входит фильм то поле соответственно фильм показывать выдачи не надо с другой стороны есть покупки допустим представим у нас был пакет услуг по какой-то маркетинговую акцию например купить фильм терминатор за 50 рублей вот человек купила фильм по этому пакету услуг пакет закончил свое действие скажем там полгода назад но вместе с тем и чувака фильм уже куплен по этому фильму должен показать выдачи и соответственно еще есть join под табличкой покупок уже непосредственно связанные с покупками пользователей вот плюс есть фильтрация по массивам жанров ну например там могут поискать фильм терминатор у него и жанр фантастика боевик фильмыбоевик они должны выдачи 11 губы терминаторы значит запрос в эту схему попадают с по цельсию пользователь 3 пользователя содержит себя как раз тип устройства по которым производится фильтрация по всем этим табличкам локация которая также фильтруется по всем ним табличкам пакеты услуг которые подключены к пользователю ну и собственно самый пользователя эти данные дополняются запросами в запросе параметрами который передал сам пользователь в своем собственном обращение к базе данных вот такая схема данных ну собственно мы стали выбирать решение как рубином баз данных использовать чтобы организовать такую схему в ответах от нашего бэкенда нового собственно попробовали дисковые базы данных классический подход попробовали ластиков рубли манга попробовали позгалев запрос нас получился с тремя inner join me с кучей фильтров по полям мотивам вот она заработала удалось совершенно какой-то неприемлемый рпс порядка 300 500 то есть на наших планах получить 5000 rp с такой подход совершенно никаким образом не ложился ok едем дальше второй вариант который мы использовали опять же достаточно стандартно это взять какой-то готовый memory решения такой как редис или тарантул плюс использовать стенли полна текста вот и собственно разместить него наши данные но решение таких как тарантул или редис у них нет функционала join a и фильтрации по полям массивом ну грубо говоря вот если фильм терминатор находится в двух жанр там это боевик и фантастика то мы не можем сказать нам нади фильмыфантастика потому что в поиска по полям массивом нету но с другой стороны есть возможность развернуть каждую нишу контента по полям массивом на несколько строчек у например у нас была одна строчка записи фильм терминатор и двумя жанрами боевик и фантастика мы берем и в табличке делаем 2 записи 1 запись фильм терминатор жанр боевик вторая запись это фильм терминатор жанра фантастика и такой подход применить ко всем ко всем ко всем полям который у нас там являются массивами вот посчитали у нас примерно каждый ница контента доступна в 100 локациях среднему каждый нет с контент и есть александра я здесь пакетов услуг 5 актеров 5 ассетов в это средние данные вот ну собственно давайте заполним табличку вот с такими данными чем получим правильно табличка на полтора миллиарда строк в память не влезет и и редис и тарантул замза каспер на вот это тут увы и ах как бы подход лоб не заработал собственно что можно пробовать делать дальше было бы собственно можно сделать комбинаторный подход до фильтровать данные и зари до зари тарантула в приказ не то есть мы делаем запрос в регистре тарантул по всем функциям которая не умеет той запрос простым индексом после чего уже в голым приложение там написать свой движок фильтрации тем самым ну размазать бизнес-логику как между базой данных так и приложением как бы ну да мне кажется подход он не серьезно одно дело когда мы допустим 99 процентов функции бизнес-логики реализуем в одном слое и один процент тот который у нас там корнер кейс не лезем реализуем приложение это один подход но когда мы проектируем приложение видим что у нас там сто процентов кейсов и ложится на одну аккуратную схему то кажется так как и дальше не надо а те собственно после этого грустного собственно вывода мы решили еще раз переосмыслить требования к нагрузочной способности ну возможно 500р песни самая плохая цифры вполне устроит как у нас так и заказчиком ну что мы сделали мы посчитали примерную нагрузочную способность и спроецировали и на пользовательскую базу 5 миллионов абонентов по разным регионам посчитали примерные petite рассмотрения вот и посчитали сколько будет стоить бэкенд в случае имеет 500 рпс случаев имеет 5000 rp с посчитали оказалось разница на оборудование 23 миллиона долларов хватит достаточно большая цифра что будет в лоб решить задачу с использованием а ластика ну не готовы были платить лишние 3 миллион долларов за все удобства и красоты elastico вот собственно каким выводам пришли в итоге этого исследования мы пришли к выводу что нам нужна какая-то in memory база данных которые с одной стороны умеет и join и умеет и фильтрацию по полям мотивам без соответствовал такой некой локации строчек умеет полнотекстовый поиск и при этом работает со скоростью мимо рикошет вот в таких баз данных мы не нашли вроде старались искали все-все присмотрели но ничего подобного не нашли и собственно выбор либо делать свою б.д. или платить миллионы за железо теперь я наверно уже расскажу о том что умеет делать render который мы создали тут наряжаем нашу задачу и для решения нашей задачи значит он умеет делать выборки по нескольким индексом то есть можно там сделать условия в яндекс 12 индекс 3 так далее вот и сделать выборку по ним всем причем выборка будет происходить не по одному индексу это сканирование по остальным отель будет тесно сборка по каждому индексу с пересечением результат то есть и всегда будет очень быстро так же у нас появились join и join и как пиннер так или joiner скажем так если смотреть на elastic и проводить новый social малости к здесь join еще обладает функциями нефти dsquared то есть по сути можно взять данные из основной таблички и к ним присоединить сущностями данные 2 таблички то есть получить как бы объектом не возможны какие-то подобъекта вот так же у нас есть ну стандартный арсенал это сортировки как по одному полю так и по нескольким полям вот и плюс есть комплексные первичные ключи то есть можно закажем взять несколько полей сказать вот этот набор полей у меня праймари kay вот на самом деле они у нас появились тоже истребовании бизнес-логики потому что так исторически сложилось что предыдущее поколение систем имела 8 независимых с танцев у которых они сущности могли пересекаться например на дальнем востоке у канала аиде какой-то мог пересекаться и дикон алана там регионе москва в этом у нас практически этих табличках прайма реке это регион плюс сойди там данных который портировать того региона вот ну как бы если говорит двух словах по сути рендерер имеет весь арсенал по выборкам что умеет обычные реляционные базы данных такие как рис или elastic ну который не реляционная база тоже как быть позиционируется как поисковый движок отдельная вишенка на торт это полнотекстовый поиск на самом деле в яндексе очень классный полнотекстовый поиск он умеет поиск запечатка my то есть можно писать учи пятку на дисковой опечатка умеет поиск по суффиксами префиксом то есть можно задать ему часть слову найдет по части слова все документы которые входят в собственность для документов есть поиск пологи то есть это поиск по корням слов например издать запрос окна он найдет и окно и окна мы все слова которых там корня слова окно плюс дополнительно он умеет поиск по транслит у нас на месте окна латиница то есть также найдет даже позволяет искать с неверный раскладкой клавиатуры то есть там ввести на русской раз от клавиатуры слова по-английски он его все равно найдёт ну теперь рассказ о том как мы с рендером решаем задачу с нашей бизнес собственно задачи по реализации бэкенда вот мы в качестве основной б д с гарантированным хранением используем пузыри с то есть уже как принимать индексирует а база данных засылай то что ваши данные при выключении питания могут потеряться записи синхронная вот поэтому главный которые для нас тактичным и храним под грехе и сохрани зиру им в их вниз при индексе все методы эти типы rest api мы обрабатываем отправляя их в яндексе рга за обращение к склере базе данных то есть все вот собственно lil jon & все вот эти фильтрации они обрабатываются индексируемых ответов дается клиента и закрепить итоге такого решения мы достигли нашего собственного целевого показателя в 5 как fps а местами даже его и превысили вот собой машина я еще раз напоминаю собственно табличку тему табличек вот и вот на собственно запросах повод такой схеме данных мы собственно померили производительность вот собственно запрос базе данных содержит в себе три условия для к простым полям есть условия век полям массивом 4 inner join к трем табличкам если говорить про так сказать запросу сам запрос в чистом виде сквере занимает примерно 5 килобайт 5 with no white gel а вот и на таком запросе вот ездим начать врк стрелять в ranger мы получим 10 крп с на железе пятилетней давности более того я на выходных ради интереса провёл такой эксперимент взял рендерер взял разбери finder сельской rasberry pi да вот да это очень такая скотина дешевая и от плато на которой там можно обычно люди обычно моргать стадионом вот мы решили мест марганец стадионом загрузить на эту плату рендерер а вот и что он получили вот такой сложный запрос исполненной разбери с рин дак сером дает 3 ст рпс то есть маленькая ты от платка до 3 ст рпс для наглядности следующий слайд как получить 3 ст рпц таком запросе можно взять разбери пай последний индекс р это будет стоить 3000 рублей и получить 3 ст рпс можно взять неплохой зирвак за 300000 рублей поставить на нем мало stick и получить те же самые 300 рпс достаточно наглядна видна разница в производительности и стоимость оборудования для этой производительности вот как то так теперь возвращаясь вопрос потребляемой памяти ну вот сейчас я расскажу обо объем нашей базы данных она действительно не сильно большая но тем не менее там содержит себя 30 тысяч фильмов 100000 ассетов к ним 3 тыс телеканалов полтора миллиона записи в телепрограммах и 3000 пакетов услуг вот это bt влезает всего-навсего полтора гигабайта включая все индексы полнотекстовые там trine 3 все все все вместе занимает полтора гигабайта как вы видите здесь резерв по росту огромные то есть даже если база внезапно вырастет 20 раз мы легко месте мся в память любого даже самого дорогого серверов нашей базой вот так что вот таким получили показатели как по память так производительность и теперь про айпери индексировать и тут стоит отметить важный момент что яндексе а может работать то есть и коммуницировать приложением в двух режимах первое это standalone сервер режим это типовой режим работы с базой данных вы запускаете процесс базы данных и к нему приложение подключается через сетевой коннектор какой-то у него понятные плюсы и минусы у него с одной стороны есть возможность поработать и без нескольких сервисов у него есть возможность изучить нему ходит треба интерфейс вот установить запустить отдельно от приложения вот но у него есть большой минус это о вероятной сети то есть каждый свой запрос это как правило минимум 100 микросекунд ну то есть если у нас исполнении запроса клиента требует 10 походов базу данных разные таблички то в решении ставангера мы получим вернет примерно одну миллисекунду не так много не менее он есть значит есть второй вариант это как даррен миксера статически блинкова это приложение и тогда как будут все данные становятся под боком у приложение и все обращения из голы приложения в яндексе не несут с собой не повод кеды выполняется за микросекунды то есть можно набирать либо то либо иное решение вот по фактам и приключается там сменой dsn в конфиге приложения можно так можно взять теперь о том как можно подключить яндекс приложению с точки зрения уже программного интерфейса значит есть драйвер для грн грн подобным интерфейсом который позволяет там достаточно в простой форме строить запросы к базе данных вот так же в render есть теперь я стоит классический rest через который можно обращаться к табличкам к индексам базам данных добавлять удалять данные плюс хоть бытует мнение что в 2017 году все должно быть на базе теперь я степи мы все-таки сделали свой бинарный рпц протокол взаимодействия с яндексе рам потому что он несет честно меньше оверхед там уже таким далеким от степени был бы он все равно требует кого-то парсинга заголовков парсинга урала все дополнительное время доплат дополнительных ладные расхода рпц протоколу наш с полностью асинхронный то есть грубо говоря в один сотен приложение можно запихнуть много команд и потом спокойно дожидаться исполнении кожи на стороне арендатора также скоро ожидается выход драйвера индекса для поэтому и уже можно будет его использовать не только из голода приложение либо через теперь я степи но и через приложением и поэтому аренды xero есть веб-интерфейс из коробки то есть для того чтобы им удобнее было пользоваться мы разработали веб-интерфейс веб-интерфейс есть такие функции как работа с табличками просмотр данных редактирования данных редактирования это на самом деле очень хорошее подспорье для так скать отладки там того что происходит с базы данных и что важно сразу появляется из коробки без каких-либо телодвижений после установки пакета сри индексирован яндексе это кроссплатформенное решение она работает практически на всех современных ос архитектурах ну собственно картинки говорят сами себя вот возможно будет работать других лютик турах но мы не проверяли потому что не попадались под руку если кого-то будет возможность или желание или потребность пробуйте забрать не получится пишите мы попробуем помочь разобраться так теперь собственно наш любимый слайды по производительность сравнении с другими базами данных ну опять же верно и любые бич марки можно воспринимать так сказать буквально скептических говорит вас таком виде там получилось больше поэтому вы крутые остальные все нет на самом деле не всем так вы просто прогнали несколько часов на железе типа макбука и получили вот такие результаты которые естественно если используем prezi просто кататься колеруется вот значит первый день это получение объекты из базы данных по идее выдачи его клиенты видят жетончик а вот как видим решение яндексе рам который в ленкова ну в приложении как библиотека оказалось самым быстрым следующим идет решение с редактором вынесен сервер и как видите усопп здесь ровно тот самый overheat про которая говорил то есть одна и та же самая база данных 1 тонн самый движок вынесенный посетив дает сразу в полтора раза меньше рпс ну собственно дальше вот идут и решение тарантулы редис они работают почти с такой же скоростью как аренда ксир я думаю вполне себе здесь в которых они могут его и обогнать все-таки и тарантул радиста хорошее решение которое действительно люди делали оптимизирует мизер вали вот дальше идет решение steelite собственно почему успевает в этом тесте оказался быстрее чем все остальные ответ тоже на поверхности находится дело в том что и сбивает также компилируется в приложении какой библиотека у него нет оверхеды носить поэтому здесь он вот так собственно выделялся на фоне остальных ребят зонах решений вот и дальше мы видим манга москве elastic который примерно на порядок работают медленнее чем и memory решения вот дальше несколько слайдов с бич марками получения объектов по одному фильтра но это допустим запросы а там какое-то поле герб больше 2010 вот на нем получили вот такую картину ну то есть целом в остановка сил не поменялось плюс-минус все осталось так же было в предыдущем слайде получение объектов по двум фильтром ну плюс минус тоже самое получилось но и скрывает уже сильно под сдал и практически потенциал того что она им беда решение как библиотека растеряла вот дальше апдейта весь как видите на апдейтах яндексе проигрывает и тарантул редис это собственно связано с тем что яндексе вообще многопоточное приложение и у него все запросы конкурентный из разных поток тарантулы редис реализует все обращения на записи они идут в один поток как следствие здесь в яндексе получаются бутылочное горлышко в лоте на запись в табличку и вот собственного это мы видим в том что у нас производительность по записи так себя мы это уже поняли планируем точно так же зале заводь записи в табличке в один поток и надеемся здесь получить и почетное первое место но пока вот по записи мы чуть сливаем данные про реляционные решение и про мангас моэск верим думаю говорят сами сидеть у них все тоже не очень хорошо но возможно не сильны в том что гарантированно сохранять данные на диске собственно вот что касается бенчмарков и производить вместе теперь я хочу чуть рассказать про применение в проекта как можно рендерер применить в проекте вот разработчика на голым клипа разработчикам другом любом языке то есть если у вас есть задача написать rest api с выдачей кого-то контент и для этого rest api нужна какая-то б.д. или быстрый кэш вы можете взять рендерер используя в этом проект я думаю подойдет или идеальна ли в лигу близко к этому если у вас есть задача реализовать полнотекстовый поиск по сайту контента это тоже при индексе на самом деле я буквально месяц назад писал статью на хабр в которой запустила так сказать пилотный тестик проекта поиск с редактором по всему хопра этом проекте я скачался данные с хабра разместила в индексе яндекс эра вся эта конструкция в памяти 9 гигабайт всего навсего весе хабар вот и полна текст работу по всему кадру и комментариям то есть вы тоже можете использовать также render подходит для хранения валидации здесь еще одну типовой применение уже для простых киева илью bass но тем ни менее ринг чертова для этого хорошо подходит обеспечить нормальную производительность в целом если вы выбираете там какой такое же либо сданного решение смотрите на reddit на таран пыльный ластик вот то на самом деле я бы предложил вам смотрите на render потому что возможно он вам тоже хорошо подойдет и позволит сильно сэкономить на железе под сервис но вместе с тем как бриндак сирота не серебряная пуля есть такие места в которых он не силён и такие задачи вы жить не можете тоже вполне себе логично значит есть и у вас данных сильно больше чем лизать from сервера то увы и ах яндексе не про вас он работает тех пор пока данные помещаются память данная память не помещаются все работать не будет вот так же рендерер использовать электронную запись на диск поэтому если вы собираетесь хранить это критичные для бизнеса данные такие как там и ты банковские транзакции ли быть это важные для пользователя данные то все же не стоит их как минимум хранить в какой-то более надежные хранился вот ориентир можно максимум использовать как кошка более быстрый и более надежной хранился вот вот такой вот собственно в нашем представлении назначение рен декстера которой можно использовать дальше я чуть-чуть расскажу и покажу потом как можно пользовать ренди ксеры из голодом приложения значит вообще любая запись в яндексе лет а по сути дела произвольный джейсон документ но вместе с тем драйверы для голлинг можно описать структуру которая каких-то сущностей и к ней приложить и описать индексы которые будут использованы в яндексе а ну собственно здесь я написал в комментариях что вот допустим у нас есть в структуре поля едим это поле иди prime реке и вот собственно этого запись игорь индексирует обозначает это вот есть поле ним она также является индекс закажи индексом то есть по нему невозможно делать запросы больше меньше либо они будут дорогими но запросы николс будут отрабатывать быстро вот-вот поле массив articles эта типичная запись на гол nk массива вот оно здесь будет уезжать в яндекс мазепы articles вот и есть еще возможность индексов типы деревом по ним возможны и тарирования вперед назад потому что строится под яндекс bad trip которому удобные тренироваться и главное быстро теперь про квари builder то есть обращение к индексируем тоже строится примерно вот таким достаточно читаемым и удобным образом то есть создается объект квари вот и к нему уже навешиваются собственно атрибуты сортировка по поводу полю значения такого-то поля там равняется допустим значение вася вот и так далее также здесь задаются параметры прессинга лимитов сет вот и опциональный запрос посчитать сколько всего записи попала под данное условие вот ну естественно как бы документации к индексирует а все расписано существенно более подробно есть просто привел также как пример формирования чтобы понимали что достаточно простая штука не требующего каких-то сложных там dsl лежит сложного следующий слайд это формирование запроса с джоном что рассказывал то что редакторами joint собственных этим воспользоваться тоже достаточно наглядно сдается квари по основной таблицы создается квари по присоединяемый таблица с кем-то пред условиями пусть чего делается jojen акварион поле на котором делается и все это запрос будет выполнять join и присоединять к основной таблички данные магами таблички вот так же нас пойдет не написал но на самом деле в яндексе есть из квиллинг хейс для обращения к данным которые позволяют вам не пользоваться загребин таким билдом а просто написать select что-то from что-то во что-то и join туда же все это так же будет работать возможно это будет там привычный если вы уже привыкли использовать эсбель в яндексе есть встроенный профилировщика запросов который позволяет отобразить влоги плана выполнения запросов чтобы воспользоваться вот достаточно к объекту квари добавить свойство дебаг и он вроде выглядит trace исполнение запросов пока в яндекс использовались где была сканирование где были как индекса то есть это очень богат при отладке каких-то сложных запросов теперь уже наверно ближе к завершению рассказа несколько слов собственно почему же рендерер получилось таким быстрым здесь я буквально тезис не вдаваясь любовь глубина детали расскажу о том почему начнем во-первых винда ксир написан полностью на си плюс плюс 11 с минимум внешних тяжелых зависимости вот мы используем подход минимизации всех налогов где только возможно используем такие средства си плюс плюс как и string view как смол string optimizations вот и тем самым добиваемся так сказать оптимизации вот чисто в плане кода дальше все запросы исполняют ремне мэри то есть там любой запрос он обязательно будет исполненный мимо rebirth этих походов на диск поэтому всей memory все быстро дисковое хранилище она асинхронная использовала для бэкапа данных причем данные пишутся не как там скажем в одессе вообще там 1 часа пишется вала сэм на самом деле у нас для стоит же используется быть and play ltb от лдпм пишет не спам чатами опишет л с сэмом то есть по сути там появляется лоб которые синхронно спокойно пишется также широко используется методика copyright что это такое но это вот как пример к нам приходит запрос отдай мне из базы пожалуйста миллион записей то есть что можно сделать можно взять выделить память на миллион записей туда их радости реализовать скопировать этом потерять много много времени много много памяти а можно записей пометить флажок мол риф каунтер увеличился и отдать их прямо сохранили их того же само место я не хранятся в памяти то есть без дополнительного копирования а если в момент когда исполняется вот этот запрос прилетает апдейт то собственно таблички запись просто планируется только одна запись вот и остается в яндексе а клиенту который сделал запрос кажется уже копия которое собственно вы лидируете в момент завершения запроса также если говорить про структуру хранения внутри ринок сирота данные хранятся в эффективном бинарном формате чем на этим имеется чек но при этом все индексные поля охраняться некоторым типизированным типизированный структурой с фиксированными аптеку например если мы задали какой-то конкретный индексу типа там and the в этой структуры и он назначается конкретный офсет вот и собственно все запросы к этому поля будут происходить как бы там за один грубо говоря в отношение длины этой записи либо я всегда будет на четкий а вся где-то за здесь находится вот теперь уже расскажу про наш план на будущее то есть первое что мы сейчас планируем делать уже активно пилим это репликация данных то есть первом этого мы сделаем репликацию мастер slave репликация будет роу бейязид при этом мы планируем обеспечить гарантию целостности и одинаковости данных на мастере слейда ну то есть типовая проблема робы интерпретации в том что если у мастера и слева разъедутся один допустим не было долго связи там какой-то butter переполнился кольцевой кто сохраняет залог то слоев может оказаться в состоянии что вот мол данные не консистенции с данными на майские мы эту ситуацию планируем решать зеленый риндо xero то есть yandex.ru буря будет собирать их всех записей в табличке на мастере славе из ливии то что после репликации они не совпадают то он будет собственно говоря уже синхронизировать эти данные вручную построчно ну там из есть только те которые отличаются вот потому что мы считаем что задача обеспечения консистентной мастер оставим это первую очередь сдача базы данных они пользуются кого приложения которое в день и должного следить за только там база работает внутри дальше наши планы это уже репликация мастер мастер и работа власти реформированием это более отдалённые плана но такие тоже планы есть вот про них я пока детали разобрать не могу потому что мы ждем детально не приступали к проектированию сейчас как раз рассматриваем вариант а вот вчера буквально было прекрасный доклад ребята из таранто не рассказали про подходы мы тоже послушали пойдем думать как же нам лучше это сделать вот ещё один важный момент это мы планируем реализовать горит memory коннектор стоит такое упряжь вернусь к слайду с перформансом для понимания как вы видите решение которое кантри равана в приложении производительность с на выше чем можно блон сервера значит здесь основная потеря производительности на передача данных по сети между сервером и applications вот жарит на море коннектор красы призван ликвидировать это вроде за производительность и то есть коннектор будет подключаться к серверу но для передачи данных будет использоваться не сотен аша ритме и в итоге от коннектор будет давать все плюсы standalone решения то есть когда у вас есть отдельный процесс сервера универсальный которого можно подключать другие сервисы но при этом будет работать со скоростью либо почти такой же скоростью к-бет рентгене я вот то есть это вот собственно наш план на там ближайшие несколько месяцев что мы планируем сделать вот у меня на этом собственно с повествовательной частью все если у кого рескит вопрос задавайте с удовольствием отвечу да ну ну не но в яндексе residencial desert которые считают количество каких-то уникальных ключей по запросу то есть я думаю можно будет сделать нужно отсмотреть непосредственного схему так выглядит так чтобы он кажется до людей хотел знать как вы собирали данные из возле и смысле новых сказали что ваши проекте вы храните данные в игре и sync или просто рей миксер странный танец да совершенно верное средство голода в приложении голая приложение получало данные из по сгрыз обычными скверик с коннектором и синхронизировал их саре индексировали синхронизации для актуальность организации мы использовали ну там некий type g dm то есть просто на сковать греющиеся прошел с периодичностью плюс у нас есть механизм отправки нотификации об изменении данных допустим там произошел им проданных отправлять сертификация в мисочку и мы используем и но за к его она пролетает в апликэйшен который занимать страни зации и он по этому поводу еще раз за дёргать не ходить организаций по испытаем насколько это быстро работать внутри не нужно просто некоторые о том что изменение здание здесь допустим если очень часто и много писать вас греем насколько быстро он будет обновлять данные в миксере смотрите как на самом деле мы в этом решении к развитым слабое место тоже у нас экранизация между по сгрыз и редактором происходит средствами голы поэтому мы решили задач организации данных во всех модах переложить на яндексе то есть грубо говоря с плоскость будет синхронизироваться только один из нас аренда xero а остальные нас индексироваться будут экранизировать сегодня яндексе raw я про то что запись допустим там пользователь сделал какое-то изменение изменение записалась подогреть sql и как бы этих смене очень много за короткий период времени ставим то пишет и насколько быстро будут данные попадать в ринге я понял а просто здесь на самом деле используется за тему следующее у нас очень много не сильно критичных данных такие как пользовательские закладки но пользователь допустил смотрел фильм на пункт оппозиции сохранил эту закладку просто добавили в избранное у такие вещь нас объема первую очередь пишем в яндексе а потом уже не быстрой зинкой отгрызть вот такая мастер системой начала получается вступает render в случае быстро изменяемую данных которое нам не жалко потерять дарим мы понимаем что эти данные могут пропасть и как все к этому морально готова как какой-то способ для пуша не планируется делать ну как бы просто если есть бизнес личные данные которые тебе нужно сохранять обязательно при этом быстро писать при этом ты хочешь быстро к ним обращаться после этого сразу видно какой логичный придумать день что будет как бы отправить push-уведомления там что мне изменить данные обновить здесь как если решать сегодня голод приложения то голову приложением вот собственно 3 себя этот пушка ты справа родить той записать данные по сгрыз и одновременно отправить render там слева мол чуваки нити перечитайте данные использовались в туда делается на уровне приложения то есть самой базе механизмов пока такого не планируете в прямо в базе нет не позвали олег спасибо за доклад скрыть вас так как все это дело мониторить мониторить ну значит в яндексе есть же теперь с такой то есть но самый минимальный hell секции теперь посмотреть какие открыто namespace и все люди хорошо со статусом вот такой вариант также наших планах которые вы не озвучил в силу того что они вроде не сильно критично и сделай что-то типа поддержки про метался чтобы там у нас бромид с клиентом может был прокатилась вам получать из рендере от разные метки там по использованию памяти потом количество запись от дтп еще не вопрос у вас был слайдами тысяч марками удастся вот там где вы мерились с и ластиком для людей запросов или полнотекстовый поиск это для линейных запас быть полнотекстовый поиск я вот сожалению почему то решил стать говорит презентацию когда написали статью принтер на хабр такой слайд был ну примерно раз в 4 быстрее линдакса то есть редактор напал на текст и работает со скоростью плюс-минус пара жарки съемках спасибо здравствуйте спасибо за доклад послушал много работы сделали если это все так же работает вообще прекрасно не а значит маленькая ремарка и план маленьких опроса ну во-первых янамари база который понимает join и все прочее to work all time стены extreme baby поэтому если вы не знали как можете попробовать денег стоит очень много и второй момент но уже как бы заказе которого стали кому раз целиком из импортозамещения поэтому решить на урок для ней где приветствовать и но это был не вопрос а все хотел уточнить следующий момент а сколько вы потратили времени и ресурсов и денег на разработку или яндексе ра не проще ли было ему такими точными проще не дешевле ли было потратить то самый миллион долларов на супер сервер получить гарантированный работы решения чем потратить например работу низких разработчиков менеджеров тестировщиков развертки не контуров куча тестирования времени также вроде фон заработной платы есть как бы плюс риски проектов в дубы не взлетела а потратили бы много денег справедливый вопрос как бы такое просто задавали что вы хотите на самом деле индексирован настоящий обмен занимается пятеро человек на старте там скажем был вообще 1-я потому что призыв милость двое разработчиков потом трое то есть я думал потрати примерно 50 человек калеб на текущий момент уйти 50 55 просто просить 5 человека лет на текущий момент это по деньгам не сравнима со стоимостью там этого зоопарка серверов вот туристки добыли конец как говорится морис боли вроде получили решение которое всех устроило и значит последний вопрос вы сказали что существующие реляционные базы как бы не смогли обеспечить соответствующую скорость выборки данных сколько было оперативной памяти на этих серверах потому что я посмотрел как бы на вашу базу данных она вроде небольшая основной поток данных к ней это потоп на чтение то есть по идее то все данные начать даже либо заки шеронова оперативки и выдаваться сразу по запросу кажется да ну на самом деле по факту нет мы тестировали на сервер на котором был там 32 гигабайта озу то есть казалось бы вполне достаточно того что все это призвано ну естественно и смотреть на по зрительный ластик это у нас полтора гигабайта озу то по взгляд там и точнее ластик выжил тебе по моему наставнику типов озон не как то более менее там сделал вроде больше не просил то есть путем мог закодировать чертов хотел но тем не менее спасибо это же маленький вопрос я вот на слайдах не видел сравнении со сфинксом если делали с ластиком может быть где-то в кулуарах просто пробовали поднимали тестировали да конечно пировали вот попал на тексту по полнотекстовом поиску у нас с винсом примерно такое производительность каких-то случаях у нас чуть быстрее каких-то усинска фильм быстрее зависть большинстве случаев от конкретного запроса конкретного за это давно спасибо сказали что он многопоточный во всех тестах сравнивались 1 поточными но я веду тарантула или редис действительно вопрос хорошее но тем не менее что является бутылочным горлышком ну почему с одного сервера именно что мешает сделать больше 5000 давайте отвечу по порядку то есть первый вопрос если говорить про ножи бенчмарки то в большинстве случаев бутылочным горлышком является сеть то есть на самом деле здесь уже 1 по точности многопоточность решение не сильно так сказать играет как именно сетевой верных это вот она бенчмарки за герба иди очень хорошо видно как только появляется сеть мы теряем очень много всего поэтому вот таких запросов действительно разница между решениями она в основном связана не с производительность небрежение а с тем что просто обычный корнс к посетил отвечают на вторую часть вопроса почему бутылочное горлышко на 5000 rp не совсем понял про вопрос это вопрос про решение с редакторы почему 5000 rp с они больше com ну опять же на самом деле вот если говорить про бенчмарка который я показал на 5 fps на нем профиль нагрузки пьем посмотрел на следующий значит мы бомбили искали запросами примерно процентов 15-20 и уходил на парсинг из геля примерно 35 процентов сибири уходило на формирование джейсоне чиков с ответами но для понимания вот benchmark который давал 10к рпс который я показывал тарана раз бри питают 3 ст рпс он примерно выбирает 700 мегабайт секунду трафик по 700 мегабайт секунд получаем данные из баз данных такой скоростью то здесь опять же думать вот и по профилю загрузки zipper примерно на 30 35 процентов по дела только на поиск нужных элементов и значениях то есть по сути здесь большая часть времени уходила на обработку запроса именно на парк запроса и начать реализацию выходных датах то есть вот как то вот так вот и 3d ксир используется zero на которых 2 x от ядерных сыпью 20 периодических потока вот он использует все потоки да ну как бы если использовать решение типа elastico ii лимон где то есть также буду загружать все я трахал потому что бы по точно если использовать тарантул или рейде сложно сказать там уж не функционал такой не умеет поэтому помирит на них рпс join me или rss поиска поля массива много невозможно то есть можно написать кучу бизнес-логики приложения но тогда непонятно чем бич маркой наше приложение с нашей реализации или все мушки самым базу данных то есть поэтому здесь можно сравнивать стараться он radisson попутно простых там запрос с одним из двумя индексами больше уже получается сравнение не базы с базой сравнения базы в с база + имплементация для фильтрации в приложении ответил на ваш вопрос вы подобрали такую вы подобрали такую конфигурацию сервера что процессоры все загружены и то есть если добавить процессора то лучше не станет если убавить то уменьшится скорость отдачи на самом деле мне кажется такой вопрос весьма так сказать вариативный в зависимости от того какие мы делаем запросы какого размера ответ ну грубо говоря у нас там лежит часов в котором поле description там на мегабайт то есть 10 и запроса будет честно меньше поэтому ну кажется если не желает поговорить можно творить какой то более менее конкретных заданных и наверно уже более кулуарно как мне кажется спасибо спасибо спасибо за доклад хотел спросить при использовании выглядит режиме выстраиваться в приложении на коленке или на си плюс плюс нормально на си плюс плюс тоже можно вот но вместе с тем небольшой дисклеймер у нас боулинг и 5 уже достаточно давно стабилизированное моего так сказать без крайней крайней необходимости меняем по факту она уже где-то полгода не менялась вообще не как-то си плюс плюс ее 5 у нас периодически x53 factory завод и соответствующей версии можно что-то поменять но тем не менее можно пользоваться это работает спасибо за доклад вы упоминали про драйвер для python планируется ли его асинхронная версия и планируются ли коннекторы для других языков был собственно драйвер для python изначально делаем и синхронном коннекторами других языков планируется но так сказать по мере загрузчики загрузки разработчиков то есть надо понимать что все-таки мы решаем задачу разработки там broken до для этого активного телевидения поэтому там первую очередь решаем задачи которые необходимо для вот этого вот и других языков мы также планируем делать драйвера нужны как у нас дадут ни крути то есть там примерно ожидается том я запер нас есть ребята которые хотят сделать кто-то хочет ли она джесс на календаре так сказать формате скорее там свободного пинсер творчество разработчиков над зале у нас пока нет которые хотят сделать но в целом как бы так как решение open source is вам это хочется можете сделать на пузе крест с коннектором назовем мы скажем большое спасибо ну на этом наверно на этом все всем большое спасибо что пришли"
}