{
  "video_id": "7Oo2aPjbaCY",
  "channel": "HighLoadChannel",
  "title": "Чему мы научились, разрабатывая микросервисы? / Вадим Мадисон (М-Тех)",
  "views": 6621,
  "duration": 3562,
  "published": "2017-05-14T22:53:05-07:00",
  "text": "всем привет меня зовут maison вадим я работаю в компании им тех которая собственно вышла из той самой компании rutube и собственно пару слов про наш компаниям то есть мы являемся видео платформой для федерального канала масштабы мы обслуживаем нтв плюс с точки зрения именно интернет вещания и вот те циферки которые вы видите на слайде это вот примерно то нагрузку которую мы сейчас обслуживаем то есть это 300 тысяч одновременных пользователей это больше миллиона в сутки и это примерно там 300 терабайт который мы отдаем за час вот примерно такая история достаточно неплохой в общем-то показатель теперь давайте про микро сервисом то есть есть такое интересное слово mainstream это когда все прошутто говорят но у каждого какой-то свой вижу давайте попробуем вот про микро сервисы свести это все как-то к одному поднимите пожалуйста руки кто вот вообще не знаешь такой micro series и вот раз два три 4 понятно давайте я тогда буквально в двух словах скажу что в принципе микро сервисы это подход к разработке когда в большую систему пилите на какие-то отдельные сервисы и каждый сервис и реализуют свою конкретную задачу некий такой unix своей где каждая утилита отвечает за свою часть и делает ее хорошо но давайте начнем немножко про проблемы потому что вдруг вы испугаетесь и дальше слушать не будете а вот первые три проблемы которую вы видите на слайде во многом это прямое следствие именно того что микро сервисы это много юнитов это много маленьких юнитов которые вы должны будете обслуживать поддерживать развивать и так далее то есть это много проектов детей это много проектов в системе континенте гришин мы используем ten city и вот даже маленькую часть нашей системы мы в бесплатную версию то тем сити уже не можем сунуть это прямое следствие количество вот этих сервисов то есть у вас сложнее ца инфраструктуру у вас усложняется обслуживание все вот это вот кухня + усложняется работа с данными с потоками данных давайте на вот достаточно таком реальном примере это кусочек нашей реальной системы который занимается нарезкой видео и злых потока вот зеленым это собственно микро сервисы и по масштабу это где-то вот одна двадцатая наша система то есть так вот экстраполировать на систему целиком это где-то вот 340 350 микро сервисов когда вот эту всю кухню мы разворачиваем продакшене то там какие-то сервисы там в двух копиях для без отказоустойчивости какие-то там больше копиях для увеличения производительности в итоге там реальная развертка всей этой кухне это где-то там больше тысячи еще немножко про проблемы то есть во первых это вопросы верха до то есть у вас появляется дополнительный сетевой overhead то есть если раньше это были меж процесса раны и взаимодействия вы все делали достаточно быстро и легко там на одной машине то теперь у вас добавляется latency именно сетевого характера это дополнительные расходы на оси реализацию диси реализацию данных прогон из одного там формата сервиса к другому сервису и так далее это вопрос и дополнительно инфраструктуры там обнаружение сервисов это та штука которую в больших монолитных приложениях практически нет никто не делает она была по сути не нужно это вопросы касаемо непосредственно разработки вы должны постоянно в памяти держать что ваш сервис должен вписаться определенным образом иначе от гребете ну и собственно следующий важный момент это инструментарий то есть покажу такую картинку а всем там вот видно да ладно будем надеяться что хотя бы количество квадратиков видны то есть я немножко расскажу почему вот это в центре докер потому что если мы говорим микро сервисах то какая то вот система контейнеризации она становится действительно важно это там то неважно это докер от ркт там еще что то все дано для вас как инструмент так или иначе вот мы используем docker и это достаточно молодая технология то есть да ей уже несколько лет но она активно развивается у нее куча всего того что он это делает сообщество просто чтобы закрыть тот недостающий функционал чтобы вот полностью эта система взлетела вам нужно понимать что да вот не все квадратики из этого вам потребуется но достаточно приличная часть то есть вам нужно будет это поддерживать вам нужно будет это значит понимать уметь готовить и так далее то есть это та же те дополнительные расходы которым нужно быть готовым ну и собственно тогда вопрос если так много проблем то вообще а зачем это нужно для начала давайте скажу что на там и достаточно давно а вот с этой темы уже возимся и честно скажу что то что мы делаем нам нравится то есть это решает те задачи которые мы ставили перед микро сервисами и мы планируем в общем то дальше идти по этому пути один из бонусов это вот которого для нас достаточно торрента независимая разработка если вы можете выделить часть вашей системы сформировать отдельную команду именно из тех специалистов которые отвечают именно за эту часть которой понимают как ее делать готовить настраивать так далее и эта команда будет отвечать именно за а вот эту вот это микро сервис или там скопище микро сервисов и действительно распределенная разработка это хорошо это отсутствие или там это снижение какой-то завязки на технологиям то есть если раньше на старте приложения вам было очень важно выбрать там правильный язык правильную базу данных там еще что то и впоследствии там выходили кита новые альтернативы вам нужен сложно было на них переехать с микро сервисами все гораздо проще он достаточно небольшой вы каждый из сервисов можете построить на том решении которой для этого оптимален то есть там у вас есть сервис который занимается обслуживанием там связи пользователя пожалуйста возьмите графу базу у вас есть сервис который должен там держать там двести-триста тысяч открытых сокетов не вопрос пишите на go там-то вот эта вся кухня она становится легко японии понятный актуальный упрощается тестирование то есть если вы достаточно правильно пишете микро сервис это вам не нужно каждый раз тестировать систему целиком вы прогоняете тесты вашего этого маленького юнита это быстро и легко это можно делать очень часто это легкость масштабирования просто потому что либо у вас микро сервис в принципе масштабируются и тогда у вас все хорошо либо вы не сможете даже две копии адекватно запустить и тогда это в принципе не корректно написанный сервис по инфраструктуре с одной стороны у вас получается достаточно много юнитов это больше точек отказа это больше накладных расходов оказалась бы это минус но хорошая новость в том что это можно превратить в плюс просто за счет того что вы можете построить систему таким образом что падение какой-то вот ее маленькой части не повлияет на систему целиком в каких-то там ситуациях то есть у вас там когда есть упала вы клиенту все равно ответили то есть да там не будет какого-то счетчика не будет там еще какой-то части но в целом это даже может никто не заметит здесь как бы вот достаточно интересный вопрос это то насколько micro series должен быть маленький ведь я встречал достаточно много критериев там за последнее время кто-то предлагает считать по длительности разработки кто-то по объему кода который вы пишете кто-то идет от той системы менеджмента разработки на которой он там атома джейл там еще что то они важно то есть важно что он вот у нас есть такая эта команда у нее такая то производительность значит сервис должны написать там за столько-то спринтов проблема всех вот этих вот критерия в том что они относительные они относительны того языка на котором вы разрабатываете они относительно той методологии которые вы пользуетесь при разработке и не дают какого-то вот линейного критерия поэтому я для себя вывел один простой критерий который вот идет собственно от сущности самих и микро сервисов потому что если вы нарушите независимость то вы потеряете вот на большую часть тех бонусов о которых я говорил и собственно если вот эта независимость она настолько важно то становится также важным вопрос как же эту независимость проверить понять что у вас действительно оно есть здесь тоже зачастую выдвигают скита сложные критерии там предлагается там описательном целиком бизнес-модель выделить контекст и определить границы вот дико напрягшись вы получаете что вот у вас вот такой сервис на мой взгляд можно пойти более простым путем попробуйте вот взять ваш какой-то конкретный бизнес задачу и описать там простым предложением я не знаю это в нашей ситуации это сервис который подготавливает скриншоты для отдачи в таймлайне сервис который кэширует медиа сегменты для внутренней обработки это вот достаточно удобно также важным критерием здесь может именно вот такой подсказкой служить что сколько потребителей вашего сервиса где-то вот деление как бы в обратную сторону если у вас там сервис а сервис b и каждый раз вот к сервису выходит только сервис а и других потребителей нет то этот такой звоночек что возможно вы слишком разделили ваш сервис и стоит подумать объединить его обратно то есть да есть какие-то исключение что то может быть вы поделили там на вырост там на будущее вы видите какой то дальнейшее развитие но в целом критерий работе и заключительный очень важный критерий это та приводит ли deploy вот одного сервиса к некой такой вот циклической какой то такой вот на тунике цунами когда вы один сервис запустили пошли такие волны вы все вокруг должны сзади плоть то есть либо вы нарушили границы сервиса а либо у вас просто технологическая ошибка вы сделали завязку сервиса на как какое-то вот ядро другого сервиса они стали у вас уже зависимы чисто технически здесь вот достаточно такой коротенький перечень тех вещей которым вот если вы будете следовать то в принципе у вас должно быть все хорошо то есть это несложно это достаточно понятна и в общем-то это помогает теперь давайте надо попробуем перейти вот именно к тем вещам которые вот вышли вот из нашего опыта то есть внутри там где мы на велике это шишки давайте вот на некую такую воду что вот именно для меня среда исполнения micro series of то есть это какое-то количество хост машин на них у нас установлен docker и все это в целом это некий такой черный ящик то есть если у вас как бы вот именно нормально production system вы там то не раскатывайте по пятам все эти микро сервисы хотя многие из этого начинают и в общем-то для старта вполне себе вариант но как вот только вы чуть-чуть минуты переносить этот вариант то есть у вас там появляется там каберне то станут омаров он еще что то какая то система которая начинает воспринимать это вот как некий вот кластер в этом кластере вы выбрасываете ваш сервис и даже не знаете на какой конкретно машине он запустится на каком порту он будет бензин для вас это вот такой же черный ящик как вот там для всего остального и отсюда на то начинается вот к красоте проблемы о которых мы сейчас поговорим и я немножко расскажу как мы этой решали во-первых вопрос конфигурации здесь у вас получается много машин много юнитов неизвестно где запустится важно вот как то вот все это от конфигурировать что мы попробовали каким путем мы сходили во-первых мы на этапе тепло и пытались раскладывать файлы конфигурации по всем вот хост машинам этого кластера там по определенные нотации и потом уже выбрасываете собственный сервис на запуск в принципе рабочий нормальный вариант неплохо себя показал минуса по большому счету 2 то есть если вы хотите поменять конфигурацию для одной какой-то конкретной ноды ну будет не очень просто и второй момент если у вас там то количество машин и растет то и соответственно вам нужно будет на все большее и большее количество машин делать эту раскладку второй вариант это пытаться закатывать это прямо в контейнер в общем-то для какой-то части конфигурации это работает в целом не очень если у вас какой-то ключевой параметр вдруг поменяется вам нужно будет не просто переди плачу эта система вам нужно будет ее прям пересобрать с нуля все эти контейнеры их положить в реестр и срез то доставить на конечной машины в общем куча лишней работы и собственно вот третий вариант тоже достаточно интересным поднимите пожалуйста руки кто знает что такое 12 фактор на и приложение от heroku кто вот манифест видел ну в общем не то что много поэтому давайте немножко вот буквально два слова такая компания heroku которая какой-то момент вывела свой манифест 12 факторного приложения в котором описал а какие то вот ключевые best practice и как делать именно клауд applications достаточно интересная штука советую почитать тем кто не знаком узнаете много полезно и вот один из поинтов этого манифеста в том что облачные приложение стоит configure через переменное окружение в общем мы попробовали не очень взлетела потому что именно вот в этом черном ящике на этапе диплом у нас нет еще информации о том где у нас сопутствующей функционал на этапе запуска у нас уже нет как бы возможности абстрагироваться от системы запуска поэтому в итоге мы пришли следующей схеме то есть во первых мы используем консул я про него чуть позже расскажу у него есть консул агент который ставится на каждую хост машину с докером и вся работа с консулом идет через этого локального агента у нас докер демон всегда прибит на 1-ой печник и в итоге когда мы готовим именно образ нашего приложения с докера мы выставляем две переменные то есть мы выставляем в нем через переменное окружение и печник о котором мы договорились на котором будет докер через него мы имеем доступ собственно консул агенту и мы через эти же переменные сохраняем текущую версию это applications сие нам считает тем city дальше мы запускаем это приложение в нем вообще по сути нет конфигурации она просто знает я вот такое приложение у меня такая версия она идет консулу и вычитывает из него для себя конфигурацию получается достаточно легко поддерживаем удобная схема и здесь как бы вот мы используем вот такую систему нотации вот некая такая вот подобие директории где вот приоритет возрастает с верху вниз и вот нижняя строчка там где у нас уже конкретная но да она может переопределить вот ту глобальную конфигурацию которая была вот в принципе для этого сервиза как мы это делаем то есть мы на этапе теплом используем ту сумму гиту консул она собственно берет наш конфиг из репозитория нашего проекта и раскатывает его как раз в консул по вот той нотации которую мы соблюдаем получается достаточно удобно хотя вот ребята рекомендуют которую ты и написали держать конфигурацию в отдельных там-то репозиториях но в отдельных branch ах мы этого не делаем тогда становится сложно поддерживать именно вот схождение версии микро сервиса и именно его конфига но при этом мы не храним вот этих конфига какую-то секретную информацию то есть там сертификаты по ролик внешним сервисом там соль еще что то то есть это все мы выносим volt то отдельные туза и в основном конфиге просто указываем путь как вот из него это дело достать тем более что эта информация она достаточно редко меняется в общем то проблем никаких следующий достаточно специфичны для микро сервисов вопрос это мониторинг что такое классический мониторинг это в общем то zabbix это когти и по большому счету они из наших же структуры никуда не деваются они остаются они отвечают за мониторинг хостов там свободного места на этих оставь дополнительную структуру это все работает работает хорошо но давайте посмотрим вот на специфику микро сервисов у нас здесь есть пять микро сервисов они иерархичны нижнем уровне у нас что-то упало мы получим 5 allure там то есть у вас система она просто должна как бы идти от микро сервисов она должна понимать что для микро сервиса хорошо что для микро сервиса плохо а вот нам и за биг си это вот настроить достаточно сложно тем более сделать это наглядно вот давайте множко при проиллюстрируют эту вот то интересную ситуацию то есть что это то есть мы перед тепло или примерно две трети нашей системы система переехала штатном 0 downtime все хорошо у нас просто часть микро сервисов отмерла вот в ходе переезда но при этом мы получили немножко allure то что он тут у нас тут же упала собственно что вот из общих рекомендаций здесь можно предложить ну во-первых помнить что циклы разработки цикл жизни и микро сервиса он в принципе очень короткий то есть это частая система релизов это балансировщик нагрузки по кластеру у вас может там от ноту перевести с одной машины на другую там одна становится другая запустится это все достаточно статная ситуация это нормально поэтому если у вас там micro series 2 дня прожил и помер на конкретной машине это в общем-то не проблема но это нужно учитывать как это учитывать стройте даже борды собирайте метрики эти метрики сводите вот на даже борт и накладываете друг на друга это будет говорящим здесь нужно как бы также понимать что здесь уже вот не работает никоян то бинарная логика работает не работает здесь есть как бы нато куча факторов которые как раз вот говорят что вот это плохо но это работает а вот это плохо это вот плохо причину то там простой пример с тем же тепло им лишь грубо говоря мы берем там даже барду и накладываем там например степенью память на количество ошибок в логах вот такая сборная солянка но что она нам показывает при рестарте там куча микро сервисов у нас естественно будет всплеск poссию и по памяти у вас одни сервисы замещают другие там копии множится это нормально но при этом при штатном переезде в логах у вас не будет там дикого количества ошибок прошлая версия штатно завершилась новая версия штатно запустилась все хорошо соответственно вот там вы увидите что ну тогда всплеск был ошибок не было скорее всего это все хорошо и соответственно также становится вот очень важным сводить на 1 dvd те значения которые у вас идут сходств машины и то что вы видите внутри докер демона собственно как это делаем мы это вот наш тег мы используем для сборки метрик сходств машины это даймон для сборки с контейнера и to see драйвер потом мы все это дело собираем в influx биби и выводим это дело в grafana логе мы из контейнеров все логе собираем в syslog агрегирует и потом уже агрегированный через блок стаж загоняем власти ключ и опять же вот за счет того что граф она умеет работать с elastic всё чем мы какие-то метрики пологом загоняем в графа ну а общую работу слугами все-таки введен в киба не это оказалось чуть удобнее немножко про альтернативы то есть если говорить как альтернатива сие драйвер то особых вариантов и нет там influx дата сейчас вот пилит свой телеграф но такая вот сырая штука и и еще прям сильно рано использовать по хранению собственно альтернативой influx baby это может быть prometheus он себя хорошо показал быстро надежный стабильный что здесь нужно учитывать если вы планируете прям реально большую нагрузку то prometheus он не умеет горизонтально масштабироваться то есть это вот 1 но до в которую вы шлете там кучу метрик с хороших новостей вылезай туда прям ними influx baby горизонтально умеет масштабироваться но за деньги все версии 012 они именно вот эту функциональность вынесли в enterprise решения и хотят за него там какую-то денежку в принципе вот сборку метрик можно попытаться сделать власти косячил он по нодам масштабируется делает это легко но он несколько менее производительный чуть более прожорлив по ресурсам то есть это нужно просто учитывать из таких вот еще общих рекомендаций здесь стоит сказать что во первых если вы собираете данные то естественно их обрабатываете понимаете что есть зависимость какая ситуация вам действительно говорит о проблеме а какая должна быть штатно то есть вот работайте с моделями данных работайте с именно пониманием что вам эти данные приносят старайтесь эти данные собирать вот это слепки состоянии как можно чаще если вы собираете метрику раз в минуту то скорее всего какие-то вот всплески разовые именно вот реальных проблем вы будете пропускать стремитесь там 10 секунд одну секунду тому тот же netflix там кому-то и докладов пытался рассказывать про милисекундные метрики ну правда тяжеловато вот это та штука которую вот нужно просто стараться к чему идти теперь вот несколько слов про тестирования именно про то тестирование которое вот имеет специфические проблемы для микро сервисов я думаю что в целом как тестировать уже примерно все представляют одна из проблем это вот именно тестирование взаимодействия с другими сервисами у вас их становится много а вы не можете и не должны тестировать каждый раз систему целиком по двум простым причинам то есть первая причина это то что такие тесты будут не показательны вы не будете знать что у вас действительно развалилась то ли это ваш новый выкачанные сервис не взлетел а то ли где-то там по ходу дела что то сломалось и до вашего теста . они дошли правильные данные а второй это просто сложность поддержки вот такую инфраструктуру то есть на каждый микро сервис вы ещё должны будете миллион вокруг всего разворачивать собственно как в этой ситуации поступать правильно на именно внешний api каждого микро сервиса заводите некий контракт то есть пусть он там реализует какой-то api в этом api уже вот делайте некий фриз и говорите что вот все вот это api мы его должны поддерживать именно в таком виде на это api вы пишете тест и то есть как бы эмулирует и тестами обращения внешнего клиента если у вас контракт полностью соблюден тесто это подтвердили то скорее всего у вас все хорошо и 2 именно специфичная проблема для микро сервисов это именно вот проблема какой-то эпизодической доступности то есть у вас сервис может быть доступен то есть один micro series к другому обращается он у вас сам то вроде как доступен вроде как отвечает но он может отвечать медленно он может отвечать там эпизодически то он там перегружен то еще что то или там вообще там не корректно вы ожидаете джисона он вдруг с какого-то перепугу вам plain текст возвращает вот эту ситуацию именно тестами тестировать очень сложно то есть в принципе она вот достаточно специфично но здесь есть хороший такой момент что по-крайней мере от этой ситуации вы можете защититься и такой хороший паттон searched брейка по-русски это наверное не зная предохранитель вот который как раз вам позволяет реализовать такую схему то есть вы обращаясь к стороннему сервису смотрите что если он вам ответил там то как-то нехорошо то вы его помечаете как нерабочий и идете к следующему такому же то есть для этого у вас естественно должно быть больше 1 ноды каждого сервиса вы там то ко второму сходили он вам ответил все отлично и здесь из хороших практик советую посмотреть на такую штуку как хитрик от компании netflix она как с вот все эти блокировки в том числе регистрирует в общей системе и показывает вам что вот столько-то было от лупов только торнтон было обратно включений и как бы общее вот состояние вот этих вот систем достаточно наглядно вот так же вот обычно вот тестирование у нас вот первые два квадратика это вот какого то вот нагрузочного тестирования практически не бывает и как раз вот это вот наш ситуации эпизодической доступности она вот условно может быть протестирована вот вот в этом голубому квадратики то есть мы нагружаем наш сервис мы запускаем где-то там немножко сбоку интеграционные тесты и по ним вот смотрим именно нагруженном сервисе как у нас ведет себя система то есть что-то из этого можно попытаться выловить также вот для нас оказалось достаточно не плохой практикой с мы собрали такой вот супер производительный класс ti6 разбери и вот на нем как вот на кошках тренируемся то есть мы прямо выдергиваем питание выдергиваем сетевые интерфейсы пытаемся ставить сверх медленные карточки и вот он во всей этой кухне гоняем вот какие то вот под может на нашей системы достаточно наглядно следующий такой вот достаточно специфичный вопрос это вопрос хранения то есть это уже не напрямую микро сервисы это скорее вот инфраструктурные сопутствующие вещи что мы попробовали то есть в общем то стандартный для докера вариант это проброс файловой системы в внутрь контейнера но мы помним что у нас черный ящик у нас куча машин вы на одной машине про бросили на 2 это уже как бы этих данных нет то есть это такое половинчатое решение нужно пойти чуть дальше то есть мы пробовали делать собирающие контейнеры вот на монолите у нас прекрасно работала когда мы на бэг-энде ставим проектирующие индекс он через об trim пробрасываем уже на фронты и нато у себя как бы собирает некий такой кэшируются за несколько итераций всю статику все это работало на микро сервисах это не взлетает с версии по моему 19 или 1 день в докере появилась такая штука как же я доволен то есть вы заранее создаете до того ли им его потому-то именуете от именованный волю маточки к конкретному контейнер или там нескольким и вот этот контейнер потом везде таскаете в принципе достаточно рабочее решение а ему чуть-чуть нехватает мобильности а вот эту самую мобильность добавили ребята из кластеры чаю через свое решение flogger она достаточно себя хорошо показала но не в нашем случае то есть если у вас действительно много данных вы там то сохранили там на 20 гигабайт видео сегментов то вот каждый раз таскать это ввс из него это долго поэтому что взлетело у нас то есть во первых мы используем сев мы выделили отдельно сторож кластер мы подняли распределенную файловую систему и часть машин из докер кластера мы просто помечаем определенными метками и когда мы запускаем контейнер это какие-то микро сервисы которые требуют именно вот такого типа хранения они ориентируются на эти метки то есть мы вот именно это подмножество машин их разливаем в чем-то похожую схему мы сделали для баз данных то есть почему мы тоже это вынесли отдельно в принципе есть варианты как это целиком на контейнерах сделать но баз данных они требуют определенных ресурсов то есть они требовательны к их качеству то есть это скорость сети это скорость дисков это объем памяти sd они конечно дешевеют но они все еще достаточно дороги поэтому мы поднимаем отдельные кластеры мы вводим правила именования баз данных и каждый сервис просто знает как найти свою базу вот в этом кластере и наверное вот самый такой специфичный вопрос для именно микро сервисов это их обнаружения то есть здесь как бы ответ достаточно простой мы используем реестр вот каких то вот мы in стрим новых решений в общем-то 3 честно скажу мы использовали а это консул эти сиди и каждый из них достаточно стабилен удобен в работе выбрали мы в итоге консул по одной простой причине а он из коробки умеет работать с несколькими дата центрами поскольку у нас их три то для нас это важно вот а так в принципе смотрите какой вариант вам больше нравится но при этом тот же кубер нетто с которым перед google использует тот эти сиди собственно буквально несколько слов о системе регистрации это вот опять же ярые представители как взять ваш контейнер с приложением и вот в бросить в этот самый черный ящик как его потом поддерживать балансировать и так далее вот то что выделено полужирным это то что мы используем сейчас как бы очень простая система для разработчика это просто песня то есть вы буквально одной командой nomad минус дев запускаете у себя вот готовую штуку на которую можете тренироваться для старта прям хорошо но вот почему мы с не и вот сейчас как бы свяжем вот в сторону cabernet оса просто потому что штука достаточно молодая и становится уже слишком простой мы просто вот этот уровень переросли вот если говорить о там том же но моди то встает вопрос а как организовать роутинг то есть у вас есть много сервисов там каждый на свое мои печеньки каждый на своем борту заранее это все неизвестно а при этом это нужно как то вот собирать единую систему ведь мы используем достаточно простую связку простая надежная как молоток это вот яндекс и консул template то есть вот так вот это выглядит сборе сейчас покажу немножко поподробнее то есть мы обращаемся консул говорим дай нам список живых сервисов выбираем какой то их подмножество это вот в нашем случае эта тема и смотрим те сервисы у которых есть такая заявку что внутри этому сервису нужен роутинг этом мы смотрим по признаку url-префикса если вот эти все условия выполнены есть то мы просто вот генерим список апстримом затем уже в разделе сервер мы эти ops 3 мы просто подключаем на те работы которые заявлены то есть это опять же вот та же самая магия вот видите там то в комментариях так : вот так примерно выглядит метка для сервиса который вот требует роутинг потом мы вот этот url префикс тире обрезаем и вот все что правее это вот как раз тот ротен который хотел бы увидеть этот сервис вот примерно вот так это в результате начинает выглядеть то есть это вот up stream и использование этого up stream а то есть просто надежно не требует каких-то дополнительных вещей тем более что тот же индекс его в принципе сейчас уже все умеют готовить и каких-то особых проблем нету вот ну и чтобы он сильно не имущество то есть это дело выложено на google drive можно скачать поиграться посмотреть ну и в завершении это вот такой достаточно короткий чек-лист вот задайте себе вот эти вопросы и если вы видите что an't вы готовы на каждый из этих вопросов дать себе ответ то почти наверняка вы как минимум к старту разработки через микро сервисы готовы ну что ж всем спасибо короткий чек-лист вот задайте себе вот эти вопросы если вы видите что да добрый день и спасибо за доклад спасибо за доклад хотелось я одену очки хотел узнать у вас на схеме с базами данных микро сервисы были отдельно база данных отдельная и несколько микро сервисов обращались к одной базы данных хотел бы узнать это так вас реально работает потому что насколько я знаю обычно база данных впитывается внутренне к сервиса и микро сервис отдельно работа со своей базы данных и не имеет шерсть и это составит с другими к сервисами вы все правильно сказали но нет мы так не делаем то есть это были машины на которых установлены именно engine и а в рамках этого engine а уже может быть там грубо говоря манга 10 баз данных и 10 микро сервисов каждый пользовать свою то есть они не шарят базы данных между собой это как раз противоречит вот всей схеме а вот то что мы запускаем мангу на конкретной машине это потому что мы на этой конкретной машине нагнали там немерено памяти мы туда поставили ssd диски и это просто вот работа из той скоростью которой должно я понял то есть у вас демон губы к манге 1а логически базы разделены для каждого добрый день такой вопрос вот у вас вы говорили про circuit breaker паттерн в то же время вы говорите про яндекс так он технически заменяет отказ но у вас балансировка и отказов точность поддерживаться на уровне джайна x правильно не совсем то есть здесь мы говорим о именно ро тенге то есть у вас в об стрим уйдут а те сервисы которые живы но а если вот мы там вспомним предыдущий схемы то есть некая иерархия то есть у вас там грубо говоря верхний пласт сервисов он будет видим через яндекс на остальные сервисы вы к ним будете обращаться напрямую взяв информацию о них из реестра то есть вы пойдете в консул вы скажете мне нужен микро сервис который занимается вот этим вам дадут на выходе список айпишник и суппорт и портов там грубо говоря там 5 инстансов и вы потом уже через 40 брекер это дело для каждого сервиса уже обслуживаете а почему не сделать это не дженкс он лучше справляется это я ведь просто послу который но бесконечно будет такой загруженный в итоге ну во первых он не будет вот такой бесконечном нагружены то есть там буквально кеширование стэйта на одну-две секунды она полностью решает все вопросы нагрузкой и там буквально дикий поток он держится легко а во вторых это как бы дополнительное вверх от у вас тогда получится каждый раз у вас весь трафик будет ходить через яндекс и будет каждый раз делать вот это вот петлю то есть вы будете создавать от overhead который вы можете избежать при прямом обращении у вас и так этих сервисов кучу вас так там дикий трафик и еще вот его увеличилась в два раза через вот эту каждую петлю это просто сильно избыточно такой вопрос еще вот про клиентские библиотеки когда мы дело микро сервис у нас получается что есть сервис site and point есть какой-то клиентский код который умеет к ним обращаться правильно ну потому что обычно это не просто какой-то ктп запрос а что там диссертации детализация вот этот клиентский код вы храните вместе с серверным кодом или вы носите какой-то common который там где надо подтягивать то есть отдельным проектом разработка идет или и как вообще вас пакетирование вот эта часть не смотрите во первых мы вообще стараемся избегать каких-то команд частей просто потому что они как раз ведут к тому что у вас сервис теряет независимость то есть вы вынесли какую-то общую часть потом у вас каждый сервиса начинает на эту часть зависеть а вы что-то под один сервис должны поменять 2 из-за этого вы должны будете гарантированно тоже изменить здесь мы поэтому идем даже если у нас есть какая-то там часть которая там условно общее мы выделяем на нее соглашение вот это примерно должно быть вот так и потом то там буквально там чуть ли не копипастом выносим это в каждый отдельный сервис и кладем это vendor и потом уже ну вот эту общую часть используем как вот венгерскую да ну тогда получается что в случае изменения 585 миссионер из вообще до несомненно то вам нужно по всем проектам которые обращаются которыми к сервису пройти и пища в рубку копипаста сделку the past да это вот обратная сторона вот этой медали но здесь есть на то важный момент то есть даже вот если вы выпускаете новую версию то это по сути как новый сервис то есть в какой-то момент у вас вполне возможно что будет работать и версия 1 и версия 2 и те сервисы которые работали на версии 1 они обязаны остаться именно рабочими то есть вы должны обеспечить что у вас а вот deploy вашего от этого сервиса который но g2 уже переехал не должен сломать все остальное поэтому вы в какой-то момент поддерживаете две версии и потом постепенно до распространяете эти изменения со временем у вас потребители вот этой версии 1 вообще не останется в ее выключить останется хорошо понятно спасибо еще такой вопрос в сериализация что используется на просто написав тесто счастья освещенных докладе смотрите в качестве рабочего формата мы используем джейсон и внутренние наши микро сервисы они работают через gr5 который по сути тоже свои ты так джейсона окей понятно а еще вопрос про логику разбив кивают так кратко осветили можно подробно то есть вы просто сможете но вот у нас есть вот на примере подготовки скриншотов у нас есть кусок который просто ecu готовит и мы туда все теперь засунем как то тогда будет или лойко другая нет примерно так единственное здесь мы идем именно не от технической задачи как таковые хотя это тоже в принципе вариант а мы стараемся идти именно от бизнес-задачи чтобы у вас один юнит и реализовал именно одну бизнес-задач здесь бизнес-задач а потому с теми же скриншотами это показать картинки на таймлайне видеоредактора и вот эту задачу мы реализуем уже через сервис если вдруг окажется что вам нужно там эту картинку попутно там еще и не знаю вот армад наложить то скорее всего это будет в этом же сервисе то есть здесь нужно именно понимать что вот если вы будете именно чисто технически границы выставлять то тогда у вас вот это вот грануляция она может достичь каких-то космических высот дано плода в случае с этим же примером провал скриншот возникает проблема с зависимостями через данные потому что да на вас большие это какое-то видео и вас в то что зависим от базы данных вы убираете у вас получается зависит через хранилище нет между смежными сервисами смотря на то что здесь надо считать хранилищем то есть например вот файловую систему если вы не напрямую к ней обращаетесь а там то например через какой-нибудь там even бас да и говорите что ну вот этот сервис положил вот туда то там вот это вот видео сегмент а второй сервис а вот эту информацию вычитал и пошел его использовать то он здесь вы как раз на не делайте эту зависимость то есть это у вас изначально тот же это ресурс который для этого предназначен если вы и забот с ним правильно ими вот изначально строите работу то есть не напрямую между сервисами его гоняете не там каким-то образом еще шарить это в общем то все нормально спасибо вы с монолитной системы переходили на микро сервис или сразу на микро сервиса стали разрабатывать смотрите у нас есть и такой опыт и такой то есть в общем то сама система которая держала нтв плюс она изначально была монолитом и постепенно какие-то части мы от нее . вы и превращаем их в отдельные сервисы а вот то там где вот мы видим что на тогда это уже там оправдана мы к этому подошли то есть например а сервис которая обслуживает именно проверку платежей он у нас уже полностью от пачку или там сервис который там отвечает за mondeo проверку сервис который контролируют одновременные просмотры то есть это все мы постепенно пачку им и систему разделяем но так живут то есть опыт когда вот мы полностью новую часть нашей системы сделали вот с нуля на микро сервисах и то есть монолит выстраивайте работу с сервисами до кратера на самом деле здесь нет никакой проблемы здесь именно задача отделите от монолита именно тот кусок который можно считать независимо ведь если вы там какую-то часть отделили я часть нет делили то в общем то эта проблема если же вы выделили ту часть которую вот вы полностью можете обособить то все хорошо спасибо спасибо большое за доклад у меня есть парочка вопросиков народ список не такой будет длинной вот но все же мне очень интересно вы считали касты поскольку вам сейчас обходится со порт микро сервисов и монолита или это так у нас типа хипстерский проект запилим нет проект не хипстерский рону то очень даже реальный и здесь все что смотря на то что считать кастами то есть с точки зрения разработки мы выиграли достаточно много то есть это во-первых разработка которую мы смогли поделить там например часть задач который у нас там эпизодические которые не являются вот прямо ядром нашей системы мы смогли вот при таком подходе отдавать на аутсорс это снизило наши затраты это снизило те потребности в размере команды которые у нас были и которые вот команда постоянно вот там должна была уменьшаться то увеличиваться было неравномерная загрузка вот какие то там такие вот вещи вот они за счет вот этого достаточно так стабильно стали это хорошо но насколько цифры какие-нибудь есть или это так было мы отдадим ног на аутсорс это все когда-нибудь ближайшем будущем вы говорите о том сколько мы сэкономили в рублях но если такая цифра есть но это та цифра который я не могу озвучить но она есть то есть до сэкономили сэкономить до сложность саппорта системы то есть теперь есть у вас хотя бы один человек в команде который примерно представляет всю архитектуру этой системой который может сказать вот из 700 32 писем какое конкретное письмо надо бы прочитать чтобы понять какой из микро сервиса все-таки упал ну вот как раз вопрос в том чтобы сделать чтобы не было там 700 с чем-то писем вот это с одной стороны с другой стороны даны все равно есть чек который видит систему в целом и как бы в общем то даже не один и в принципе как бы с точки зрения поддержки тут все зависит от того как вот к этому относиться то есть на этапе внедрения было очень много каких то вот вещей которые были вот именно нетипичны которые были новые с которыми нужно было разбираться информация по ним большим ты немного но когда вот это более-менее стабилизировалась это вот вошло в некий такой конвейерный режим и это стало проще то есть с точки зрения там-то саппорта запуска поддержки то есть там с точки зрения админа там каждое приложение там грубо говоря материала свое лицо то есть они все стали вот одна легкими такими то есть это контейнер у которого есть внешний порт причем какой у него там внешний порт и контейнер знает сам то есть у него есть метка он сам про себя говорит в систему сбора метрик и в общем то это все достаточно правда точно то есть каждая часть вот этого надо всего сервиса она стала иметь свое имя то есть если раньше у вас в монолите что-то сломалось и хреново значу сломалась то он то здесь мы четко видим что вот из вот этого вот на the pipeline а обработки запросу у нас выпал вот этот конкретный сервис мы его видим мы быстрее локализуем проблему мы быстрее можем исправить сравнивайте монолит без мониторинга с системой с мониторингом и говорите что монолит нет-нет-нет как раз на монолит точно также есть мониторинг но здесь я говорю о том что а здесь мы видим как у нас запрос проходит между сервисами мы видим это наглядно в то время как в монолите у вас вот где-то вот в его кишках что-то развалилась то есть это уже не отдельная его часть которая не обработал и которая вам вернула статус там 500 условно да а это именно вот где то там в меж процессор ных взаимодействиях у вас где-то что-то не срослось сюда уже вас по цепочке начнут падать и сервисы которые пытались обратиться к сервису который сбой ну и соответственно 732 письма вперед нет вот здесь как раз у вас задача в том чтобы вот именно тот сервис который у вас стартанул он как рассказал что это вот я именно упал именно вот дальше эти сервисы они его отстрелили и либо про сказали да мы не можем обслужить но не можем обслужить уже ты не по нашей причине и вот на этом вы должны уже как бы ориентироваться окей спасибо большое всем спасибо за доклад такой вопрос такой was time to market вот допустим разработчики за к метели в репозитории код вот насколько скоро он окажется в продакшене в идеале он окажется в продакшене на следующий день то есть это четко тенистый гришин как-то успевать пройти тесты если вас ручное тестирование да у нас есть ручное тестирование но во первых она не на все во вторых мы стараемся увеличить количество авто тестов мы держим определенные метрики и руками мы прогоняем не все поэтому а если мы видим что какой-то сервис у нас возможно полностью закрыть авто тестами то есть там ну грубо говоря это вот полностью вот такая железяка которая там скриншот нарезает то посадить тестер and a чтобы вот он это глазами все это смотрел да это значит никому не упала такой вопрос а вот используете ли вы сплит и stermy то есть когда у вас код из репозитория с минимальными тестом вода это продакшен какие-то ноды да и сравниваются предыдущая версия с текущей если мониторинг метрики но и так далее скорее у нас называется хрен охранников production тем не менее есть да это контролируемый процесс это тот процесс которую мы периодически когда мы в каком-то функционале не уверены мы запускаем его на каком-то вот сегменте наших пользователей и именно вот эту вот часть мониторим в двойне дамы это догоняем до продакшен но мы-то не распространяем на всех пользователей чтобы вот все коллективно не отгребли спасибо пожалуйста спасибо за доклад вопрос высокую доступность микро сервиса которые распределены на разных а стах ну как бы горизонтально масштабированы но могут иметь в данный момент только один ip адрес то есть должен работать только один микро сервис то есть как это keepalive тх орбит только применительно к докером вот честно скажу что вот как раз если мы говорим о микро сервисной архитектуре у вас вдруг получается что там из десяти not должна быть только одна то тут скорее вам нужно подумать как все-таки этой ситуации избежать то есть у вас вот если вы помните я говорил про себя кит брейке то вот как раз этот то вещь от которой вы в принципе должны идти все у вас каждой из сервисов должен быть равнозначным а то как понять кто вот из этих вот там 5 инстансов должен сейчас обработать тут скорее вам должны помогать другой инструментарий там-то вы должны это класть в очередь кто надо 1 из очереди тот и молодец кто-то и отработает или там еще каким то образом то есть поднимать сервис блокировок когда у вас а там там через тот же редис вы через там settings говорите что я взял больше никому не трогать всегда у нас есть сервисы которые там должны в одном лице там исполнять какую-то задачу там грубо говоря отправить задачу на запись программы но он вот мы решаем это именно через блокировки то есть у нас есть отдельный нс с которой вот является менеджментом менеджером этих блокировок и через этому разруливал а так потенциально все равно все ноды они равнозначны то есть эти блокировки реализованы вашим кодом но не каким-то сторонним софтом ну смотря что это сторонним софтом ради сторонний софт нет ну значит нет озу кипер пробовали они за кибер мы не пробовали и вот честно скажу что вот на него посмотрели решили блин да я чертов монстр какой-то и и успокоились это да спасибо здравствуйте спасибо большое за доклад говорить пожалуйста микрофон не он включен прежде чем просто поближе а доработать такой вопрос вы сказали что сервисов есть какой-то внешней опять и я так понимаю что есть какое-то внутреннее взаимодействие между сервисами в отсюда возникает первый вопрос как то у вас поддерживаются контакты между взаимодействием что является средой обмена данными смотрите контрактом и собственно достаточно легко и прозрачно поддерживаем то есть он давайте я попытаюсь промотать на слайд где вы блин это будет долго самое начало так мотаем мотаем мотаем мотаем уже почти почти почти а вот вот вот вот смотрите видите вот самые левые 4 сервиса это вот там api то есть это вот те сервисы которые собственно выходят во внешний мир это вот те сервисы которые вот просто на тот же сон api обслуживают это как бы с одной стороны а все внутренние сервисы они работают то у нас через gr5 джерри писи это в принципе тот протокол который обязывает вас описать этот протокол поэтому у нас каждый сервис он говорит что я реализую джипси протокол вот такой версии вот такой и тот сервис который это хочет использовать он просто он так говорит о kia тогда вот по этому протоколу к тебе обращаюсь такой вопрос а как у вас тогда происходит связка допустим контент связка результаты работы с сервисов с конечной странице каста контента в браузер и ну положим странице мы вообще не формируем мы выплываем на джейсон и тот же сон уже потом на клиенте превращается в html но это по сути такой закрытой части страницы а так как бы здесь вы финтами механика на общая для всех то есть если у вас какой-то сервис для того чтобы построить ответ должен обратиться к нескольким сервисом тогда он точно также через живописи к ним ко всем асинхронно отправить запрос и в параллель на каждый из них он выставит свой тайм-аут и скажешь тонут и если мне вот там два ответили а третий не ответил то в зависимости от ценности этого ответа он может вообще без него ответить не успел свидание твои проблемы тасс по сути описание прослойками доллары для браузерами сердца правильно понимаю ну в какой-то степени можно и так сказать никаких сторонних решений вы использовали нет привет быстрый вопрос ты говорил вначале том что такая архитектура позволяют в том числе использовать какие-нибудь преимущества тех или иных языков или архитектур фреймворков в отдельных мика сервисах вас есть такие в принципе да то есть у нас есть сервисы которые работают на но джесс у нас есть сервисы которые работают на год у нас есть сервисы которые там базируются на майские ли которых базируются на манга деби у нас есть общение с векторными базами и все это в общем то вот то в рамках полиглот persistent вопрос как вы ее поддерживаете во-первых да и то на тот тот момент который является тому то определенной сложности во всем этом я на слайдах немножко это упоминал и здесь мы вот эту всю штуку делим на какие-то вот два основных вопроса то есть если у нас какие-то данные а не критично важных своей целостности то вот здесь вот есть такой квадратик называется транзактов то есть это та штука которая как раз помогает нам реализовать распределенные транзакции то есть мы делаем некое подобие двухфазного комета то есть мы кладем часть данных на эту часть данных кладем метку version насти и вот эту метку мы распространяем по всем частям и дальше в какой то момент мы используем поттер а венчала консистенции который нам как раз показывает что в итоге у нас все собралось или не собралась если на каком-то этапе у нас все развалилось то мы как раз в шину сборки вбрасываем что вот это как раз версия данных у нас а не прошла и нужно сделать вот такое-то действие проблем при этом не бывает проблем и здесь нет а скорее нато идут от каких-то вот именно багов реализации чем вот от общей схемы интерфейсные тесты они у нас как бы идут за рамками микро сервисов поэтому и скорее немножко про другое то есть у нас как бы многое базируется на сингл публикация поэтому там как бы вот именно интеграционные тесты мы запускаем при тепло и определенного класса сервисов то есть если мы диплом там что-то касаемо и а именно платежей то там то запускается именно цикл проверки вот всего целиком потому что это супер критично важно если же мы стартуем какой-то вот сервис который где-то в недрах моего авто тестами просто прогнали то мы считаем его независимым он должен работать сам себе рядом да в том же репозитории если ты интеграционные тесты у них там прям директория интеграционных тестов и там вот мы как раз эмулируем клиентское обращение да спасибо за доклад у меня тоже один вопрос по тестированию есть да допустим у нас какой то вот сервис вашем случае например контент api зависит от контент-менеджера то при написании тестов на контент api вы какие-то заглушки просто ли контент-менеджер делаете или его тоже нужно запускать нет нет нет то есть если мы говорим о тестировании то каждый сервис мы стараемся тестировать независимо то есть единственное где мы вот внешней зависимости оставляем это завязки на базы данных ведь иначе это важно все равно есть кейсы когда один сервис пользу другой сервис до несомненно вы это заглушки тогда заглушка на галстуке и второй вопрос из пользователей какой-нибудь механизм для трассировки запроса входящего ну и понять вообще как он распался дальше по системе до несомненно что свое что-то или нет нет нет мы пробовали начинаем на анализ апдеш вот получим то достаточно со работая штука и дальше в следующем как бы этапом развитие тазик кен это тоже ядреный монстр но как бы то это единственная вменяемая решение вот в этом вопросе есть и остановись на нем дается короткий чек-лист исход задайте себе вот эти вот"
}