{
  "video_id": "0fT9uMV8tr0",
  "channel": "HighLoadChannel",
  "title": "Векторный поиск в ClickHouse / Артур Филатенков",
  "views": 1764,
  "duration": 2194,
  "published": "2023-04-28T06:10:46-07:00",
  "text": "Добрый день Меня зовут филатников Артуру и Сегодня я расскажу про векторный поиск creehouse прежде чем рассказывать свой доклад Я бы хотел узнать сколько тут находится ярых поклонников кликхауса поэтому поднимите руку Кто смотрел вчера релиз что никто не смотрел вчера Лиза значит для всех будет новое то что я сегодня буду рассказывать потому что там был небольшой так сказать тизер вот ну то есть перейдем к презентации немного слов сначала себе и как вообще появилась идея реализации векторного поиска я студентов и четвертого курса и пару лет назад я стажировался в команде Клин Хаус Мне так понравилось работать над этим прекрасным проектом что я решил и дальше продолжать добавлять какие-нибудь интересные фичи и Именно поэтому в рамках Учебной практики Я объединился со своими одногруппниками единомышленниками и мы вместе решили найти что-то абсолютно новое что-то интересное что-то полезное для людей и именно такой задачей стал векторный поиск Я уже несколько раз сказал сочетание векторный поиск но до сих пор не определил о чем вообще идет речь рассмотрим следующий пример допустим мне очень сильно нравятся коты и я нашел какого-то очень классного кота и у меня есть dataset с большим количеством картинок и мне хочется посмотреть как можно точнее какое-то количество похожих картинок Я хочу найти в нем Что же мне делать на помощь приходит Клик Хаус мне достаточно взять мой датасет из картинок и с помощью какой-либо модели при добученный или может быть которую я сам обучу сопоставить картинки набор чисел этот набор чисел будет отвечать за те или иные признаки назовем набор чисел вектором признаков или ботингом и тогда Если сопоставлю каждому каждой картинки Вектор я смогу понимать насколько Они похожи да для человека эти значения которые показываются в признаках не сильно читаемые То есть мне например не говорит ни о чем число 1 запятая 23 но зато можно определять схожесть картинок потому что у похожих картинок будет меньше разница в признаках тогда если мы рассмотрим эти Вектора в например L2 пространстве то котики окажутся ближе друг к другу чем щеночек например Прежде чем идти дальше стоит сделать два очень важных замечания во-первых абсолютно все операции которых я говорил можно сделать не выходя из creehouse для этого достаточно сохранить в виде путей до картинок либо виде каких-нибудь ссылок все картинки которые есть в это сети и использовать vdf чтобы получить с помощью предыдущих моделей эти вектора второй интересный вывод который хотелось бы сделать это размер вектора ведь чем больше признаков мы выделяем то есть под чем больше количество признаков по которым мы будем сравнивать тем лучше мы передадим структуру всех этих картинок и с большей вероятностью найдем действительно похожие помня эту информацию Давайте посмотрим как зависит скорость выполнения запросов от размерности вектора вы видите Запрос который находит номера всех картинок которые близки к нашей исходной картинки И если мы посмотрим этот запрос для размерности 256 то он окажется в два раза быстрее чем для размеров и 512 почему же это происходит во-первых сами функции расстояния зависят от размерности во-вторых увеличивая количество признаков мы сохраняем большее количество информации А значит нам необходимо считывать диска в два раза больше информации в данном случае именно эти операции занимают большую часть времени но работать так долго с такими запросами не хочется поэтому хочется как-то оптимизировать их что же можно в этом случае сделать во-первых можно ускорять сами функции расстояния Но этим уже и так многие занимаются и в принципе они в оптимальном состоянии сейчас находится А во-вторых можно было бы придумать какой-нибудь способ чтобы экономить на чтениях то есть хотелось бы заранее угадать Какие данные стоит читать а какие нет и опытные пользователи House наверное догадываются что похожие логику как раз осуществляют индексы то есть хотелось бы наверное реализовать какой-нибудь индекс Но прежде посмотрим как решают эту проблему в принципе существует Очень актуальная задача приближенный поиск соседей и у этой задачи есть целые сайты с бенчмарками которые анализируют какое решение лучше Какое быстрее работает какой точнее работает и так далее и самое интересное что это задача актуальная и новые решения появляются до сих пор даже в процессе нашего разработки индексов появилась по моему 2 или 3 новых реализаций мы собственно говоря должны были из этого огромного-огромного множества индексов выбрать те которые были бы интересны которые бы были во-первых надежны потому что мы добавляем довольно новую фичу не хотелось бы еще и разбираться в ненадежности кода который лежит под ней во-вторых мы собственно говоря искали те которые работают быстро и качественно то есть показывают хорошие результаты на бенчмарках и третьим признаком стало стерилизация то есть индекс должен уметь записываться на диск потому что на данный момент так работают все индексы и это привело нас к пяти следующему алгоритмам рассмотрим каждый из них чуть-чуть подробнее первый алгоритм это hnsv или Hero navic был Smart World этот алгоритм довольно известное решение для этой задачи а именно задачи нахождения ближайших соседей Он участвует Практически во всех реализациях каких-либо проектов что я видел поэтому у нас не было Никаких сомнений о том чтобы взять его второе алгоритм был оно это библиотека Spotify она показывала неплохие результаты бенчмарках Но больше всего наше внимание привлекло размер индексов Ведь у а Ноя они были действительно очень-очень маленькими по сравнению с другими реализациями следующая библиотекой стал Face это библиотека Фейсбука она набрала порядка там 12 тысяч звездочек на гитхабе то есть этим решением актуальны пользоваться его поддерживают разработчики и довольно любопытным в этом ключе стало возможность комбинировать разные алгоритмы то есть там есть не только сами построения индексов но и возможно предопроводка какие-нибудь там повороты данных отображение в меньшие пространство и так далее Все это довольно актуально потому что более больше вариантов как можно обработать свои данные следующим стал диска НН как очевидно из названия он хорошо работает с дисками поэтому проблем стерилизацией и стерилизации у нас не могло возникнуть и также Эта библиотека была написана Microsoft поэтому хочется верить что код там надежный и последняя библиотека которую мы рассматривали был скан это алгоритм Google который показывался лучше всех себя на бенчмарках на тот момент когда мы их смотрели поэтому мы решили его попробовать тоже я перечислил алгоритмы но не совсем понятно как на их основе реализовать работающий индекс поэтому сначала обратим внимание как В целом устроены индексы все данные которые обрабатываются группируются в гранулы это такой набор который будет считываться писаться и обрабатываться как единое целое во время создания таблицы а именно во время создания индекса пользователь может выбрать На каком количестве гранул будет строиться индекс этот параметр называется грануляете и когда наши индексы построены мы с их помощью решаем Должен ли участвовать весь набор данных в запросе или нет Я обращу внимание что мы решаем сразу за весь набор данных чем это может обернуться в случае наших алгоритмов а именно вспомним что они выглядели что и графики выглядели так это означает что они неточные то есть есть некоторые взобношения между скоростью работы алгоритма и точностью А значит у нас из-за ложных срабатываний мы либо будем обрабатывать наоборот слишком много гранул поскольку мы все гранулы оставили либо можем случайно упустить очень актуальные данные и это не порядок К тому же индексы возвращают ближайших соседей и чтобы оптимизировать функции самого индекса мы должны отвечать либо да либо нет то есть либо вся весь набор гранул участвует в запросе либо нет а это означает нужно придумать какую-то ивристику по которой отбирать опять же это неудобно Именно поэтому у нас появилась идея создать совершенно индексов а проксимед нейроснейбер индексы в честь задачи которые собственно говоря они решают В чем отличие от предыдущей картинки можно заметить что вместо всего набора экранов будут участвовать лишь некоторые Как это работает когда нам приходит запрос на нахождение ближайшие соседей мы Передаем количество которое мы хотим найти в алгоритм алгоритм вернет нам строчки в которых находится эти ближайшие соседи и тогда мы пометим гранулы в которых Нашлись Эти строчки как нужные Таким образом мы избавляемся от всех ненужных строк и оставляем только нужные и при этом у нас нет необходимости придумывать какие-то оценки на весь набор гранул звучит здорово и выглядит Здорово потому что результаты которые мы получили были воодушевляющими слева вы видите запрос без индексов а справа все подряд индексы которые мы пробовали обращаю внимание еще раз на вид запроса которые можно увидеть снизу то есть мы находим ссылки на всех картинки которые находятся близко к нашему вектору X то есть мы ищем N картинок близких вектору X и все абсолютно индексы ускорили запрос от 2 до 4 раз но это замечательно кажется что тогда можно было бы уже бежать и выбирать себе алгоритм строить индексы и работать с ними но не тут то было в процессе интеграции случились некоторые проблемы например скан вообще не был добавлен с ним случилось некая драма ни за что не передайте какая самом деле довольно скучная драма Он просто не собрался также еще отдельный пункт который здесь не упомянут это прохождение всех тестов creehouse но Об этом можно было бы рассуждать еще на один доклад поэтому рассматривать этот пункт я не буду посмотрим подробнее на те пункты что я упомянул как я уже говорил Скан не собрался просто из-за зависимости от тензор Flow есть и другие библиотеки например фейс и дисконн которые зависели от openmp и интеграция оказалась тоже не самый простой задачей И поэтому они пока находятся лишь на стадии разработки следующие проблемы которые мы столкнулись это была структура для которой применяются индексы изначально все функции расстояния почему-то были реализованы для тату поскольку Table имеет фиксированный размер и соответственно удобно его считать Но именно для нашей задачи это структура является не самой оптимальной намного лучше подходит Рей почему так тапал хранит все свои данные как совокупность колонок то есть для каждого элемента строится отдельно колонка и соответственно из-за такой сложный структуры сама стерилизация работает долго и в принципе доставать элементы тоже сложно потому что они находятся в разных столбцах Поэтому такая структура оптимально какие-нибудь задач когда есть разные типы но наши задачи это звучит не очень хорошо и поэтому лучше работать с рэем Как вы видите результаты запросов на tapple in Ray отличаются кардинально буквально в 4 раза быстрее работают Рей и соответственно при переходе на новую структуру некоторые индексы перестали показывать столь воодушевляющие результаты еще одной особенностью стало менее тривиальная зависимость от гиперпараметров если посмотреть на сайте то можно увидеть соотношение там прикол скорости и делать вывод на том что хочется использовать именно такой или иной индекс Но в нашем случае еще есть такая вещь как стерилизация и здесь реализация нам нужно читать индекс соответственно размер индекса имеет огромное значение и например когда мы пробовали для НСВ мы взяли библиотеку в которой было Необходимо еще и частично записывать сами данные и из-за этого индекс в два раза превысил размер исходных данных ну как вы понимаете никакой оптимальности тут речи быть не может индекс просто читается дольше чем сами данные вот следующая проблемой оказался рекол он оказался всего 6 процентов Что такое рекол это полнота и в нашем случае она показывает долю найденных индексами значений среди истинных истинными я называю запрос без индекса то есть где нет никаких приближений и в лоб пересчитываются все расстояния сортируются и находятся ближайшие элементы но так ли это плохо что полнота такая маленькая Неужели индексы настолько приближенно работают что ими нельзя пользоваться для этого лучше на самом деле посмотреть Не на полноту а на точность и лучше всего точнее на моем сайте было удобнее всего посмотреть на это визуально Например я сделал запрос на котят рыси это те которые слева и Мне выдало следующие четыре картинки согласитесь Это довольно похожие картинки потому что Нашлись какие-то котята или рысята или взрослые особи рысь то есть в целом точность хорошая а но я перечислил много плохих ситуаций которые у нас возникали в процессе разработки но очевидно была и хорошая нотка а именно Анной он превзошел все наши ожидания потому что он прошел через все предыдущие недостатки и им уже можно пользоваться сейчас он буквально был анонсирован на вчерашнем релизе Прежде чем я перейду показывать результаты которые выдает этот индекс я немного опишу сам алгоритм чтобы было понятнее как он работает и почему все так работает он разбивает пространство из всех данных на отдельные части делает он это с помощью выбора вектора рандомным способом то есть случайным способом выбирается вектор и происходит разведение Итак происходит некое количество раз и можно построить несколько таких разбиений Ведь если мы построим несколько случайных разбиений то у нас есть больше шанс что мы более точно найдем объект посмотрим на результаты которые предоставил нам иной во-первых стоит обратить внимание на зависимость от гранулярности это тот самый параметр который отвечает за количество гранул в индексе очевидно что чем больше гранул у нас в индексе Тем больше мы будем ускорять запрос ведь у нас больше гранул будут опускаться и поэтому вообще в целом все запросы ускорили порядка 5-4 раз так что это здорово следующим важным пунктом является потребляемая память как я говорил некоторые индексы на этом пункте даже отсеялись просто потому что стали больше чем сами данные и оно и в этом плане оказался прекрасным примером Потому что его объем не превышает вот буквально 36 гигабайта уже хватало на получение довольно точных результатов в чем еще особенность по потребляемой памяти вспомним что мы строим какое-то количество разбиений и ведь это одинаковые с точки зрения структуры разбиения Да они отличаются самим разбиением то есть выбором векторов но при этом сама структура у них такая же а значит память которую мы выделять будем зависит буквально линейно от параметра то есть от количества построенных избиений и это удобно потому что можно примерно оценивать сколько будет индекс занимать по памяти и намного проще подбирать вот 3D of памяти и точности а еще одной важной Темой является лимит лимит в данном случае немного особенный он не просто отображает Отвечая за то сколько данных хочется получить и отображать но если мы вспомним реализацию он также отвечает Еще и за то сколько данных найдет наш алгоритм А это означает что с увеличением предела на самом деле увеличивается время значительно из-за того что мы дольше будем искать сами данные но при этом увеличивается И точность Однако Вот я сказал что точность увеличивается но почему-то recola опять не превышает 7 процентов Неужели у этого индекса все плохо вот Ну и как раньше проверяем глазами делаем запрос картинку рыси и мне выдалась рысь или коты которые похожи на рысь звучит как будто индексы работают хорошо у некоторых зрителей мог возникнуть вопрос что если эти индексы просто натренированы на котов Я вот все показываю примеры они все котах до котах вдруг она не работает на просто произвольных картинках для этого я взял еще раз случайную картинку и это оказалось сова нарисованная И как вы видите Нашлись действительно похожие картинки что важно отметить что Нашлись не просто совы а тоже нарисованные совы Так что Это говорит о хорошей точности но я говорил уже несколько раз про точность самих индексов Однако не стоит забывать что на их точность влияет и качество построенных имейдингов то есть векторов признаков ведь Если наша модель плохо передает структуру картинок то как мы можем надеяться что индекс справится с этим поэтому стоит разумно выбирать модели которыми вы предо обрабатываете свои картинки помимо этого стоит отметить что вставки они становятся значительно дольше И это не в 10 раз а порядка 100 или даже может быть тысячи раз почему это происходит на стадии вставки индекс обучается на данных И запоминает структуру на это требуется время соответственно ставки становятся дольше просто из-за того что приходится обрабатывать данные и записывать самый индекс И именно поэтому индекс вообще говоря рассчитаны на сценарий Когда у нас Селект запросов во много раз больше чем inserve то есть когда мы чаще смотрим Однако Раз уж отвечаю добавлено то ее уже наверное можно активно использовать и для того чтобы понять Как именно ее использовать можно просто подумать Где используется сам по себе векторный поиск это может быть и распознавание лиц которое делается в принципе Аналогично тому как мы сделали распознавание картин и это может быть какой-нибудь поиск плагиата ведь текстом тоже можно сопоставлять им ботинки которые будут передавать суть или какие-то определенные черты текста по которым можно было бы определять их всхожесть а значит можно использовать крихаус для решения этой проблемы а также можно еще удобно как-нибудь например парсить логи на схожесть и так далее помимо этого еще если обобщать применение можно сказать о рекомендательных системах ведь для всего то есть для аудио видео текстов можно найти какие-то модели которые будут отображать их в признаках пространства А значит мы снова вернулись к нашей задаче и находим просто N ближайших элементов и под конец Я хотел бы показать насколько хорошо работают индексы я подключаюсь к серверу и хочу сделать запрос это тот самый запрос о котором я говорил все это время то есть я нахожу ближайших четырех соседей по или 2 метрики при этом если вы Обратите внимание то название присутствует Ray 25 то есть размерность гранул У меня 25 специально чтобы работали быстрее Как вы видите запрос уже отработал и в качестве исходного элемента я искал котята рыси То есть это тот самый самый первый пример Как вы видите это действительно те самые картинки которые я показываю на что стоит обратить внимание во-первых сам запрос отработал всего за 1 и 3 секунды запрос без индексов занимает Порядка 70 секунд То есть у нас получилось огромное преимущество по времени и снова можно понаблюдать на милого котенка что еще стоит обратить внимание в запросе так это использование такой штуки как Таргет вообще говоря запросе должен быть написан сам массив но в клиенте есть такие удобные вещи как параметры и вы можете не писать постоянно какой-нибудь Вектор длины 512 а просто сохранить его в переменную Таргет и нехитрым образом делать запросы избегая длинных записей а так ну и вот последняя картинка как раз та которая была на слайдране что еще стоит отметить Хоть это и фича и Экспериментальная но над ней ведутся работы еще есть много идей по поводу оптимизации алгоритмы которые были они не заброшены мы просто чуть дольше делаем но так как у нас был добавлен уже один индекс дальше дело пойдет намного проще и моя презентация подходит концу Вы можете посмотреть код по qr-коду который я привел на самом деле после этой презентации вам будет легко разобраться в том что там написано и также можете оценивать доклад А сейчас я предлагаю задавать вопросы из-за лучшие вопросы будут выданы такие же классные футболочки хаосом как у меня потому что не тормозит Давайте допрашивать спикеры пока ему некуда сбежать со сцены благодаря сцены у него плюс 20 хитрости Коварство и красноречию минус 20 внимательностью но она здесь на сцене не нужна пока ты не пытаешься сделать Лайф демон ты не пытаешься очень удобно раз раз Артур Спасибо большое за доклад очень классно Вопрос такой вот у многих перечисленных решений по векторному поиску есть одна проблема что если хочется в этом векторном пространстве сделать какой-то фильтр Ну продуктовый часто возникают проблемы и потом уже после фильтра найти ближайших соседей это часто проблемно мало где реализовано приходится что-то выдумывать кликаус сам по себе такая базапросами где просто напрашивается то что можно как-то помимо поиска ближайших соседей еще как-то фильтровать Вот и вопрос в том делали ли вы какие-то бенчмарки где помимо векторного поиска например либо предварительно сделана фильтрация данных либо после уже векторного поиска делается какая-то фильтрация по данным по какой-то другой колонке Да спасибо за вопрос Это действительно интересно вопрос мы не делали на самом деле таких бенчмарков потому что мы просто пока решали саму задачу но гипотетически вам ничто не мешает сделать типа заранее View и на него потом применять вот эти запросы с индексами они будут ускоряться еще доп вопрос то есть и в рамках этих View будут строиться типа отдельные там иной индексы под каждую такую грубо говоря механику это будет как бы разные стадии фильтрации Поэтому просто запрос будет фильтроваться также это все те же будут использоваться индексы просто уже немножко фильтрованный предыдущем времени и так далее Спасибо большое а те кто задавал вопросы не расходитесь потому что спикер будет ходить по залу и раздавать призы так у спикера больше одного приза Поэтому включайтесь в игру добрый день такой вопрос больше из области хайлоу что от параметра гранула рати у вас это влияло на скорость поиска вот есть какие-нибудь рекомендации Вот как вот этим вот можно рулить и влиять на скорость поиска два вопроса это вот первый вопрос отвечать а вы можете из своих соображений понимать что вам лучше что вам важнее что если Вы увеличиваете грануляете на самом деле у вас больше шанс того что вы начнете пропускать больше гранулы это будет влиять на точность то есть Чем больше тем естественно будет быстрее работать запрос и можете увеличивать его сколько хотите Но чем больше вы также теряете точность Это скорее вопрос трейдов Какой вы выберете для себя что вам важнее скорость или точность вот эмпирическим путем да получается подбирать Ну можно частично ориентироваться на самом деле на бенчмарке которые есть вот на сайтах посвященных задач Маркс но опять же стоит делать поправку что возникают неточности именно из-за того что у нас еще индексы выбирают фильтруют отдельно и поэтому на самом деле чуть-чуть другая пока бенчмарков Наших нет но планируется их добавить потому что это действительно интересно было бы посмотреть как отличаются бенчмарк от исходных И второй вопрос что когда идет интенсивная вставка записей у вас идет обучение индекса можно про это подробнее То есть если мы допустим у нас ну скажем так один и тот же сэмпл данных постоянно вставляется вставляется идет обучение индекса он какой-то ограниченным во времени он обучился он понял что за данные и все и на этом больше не обучается ресурсы не ест или это постоянный процесс Тут даже наверное еще более интересный вопрос его стоит отметить что сами insert и то есть на каждый insert Независимо будет обучаться индекс и вот когда собственно говоря процесс самого insurta закончился то все индекс готов Но если у вас несколько несортов они же будут вставляться в разные порты то есть части и поэтому на самом деле когда мы мершим части данные начнут перемешиваться и тогда возникает еще раз процесс обучения индексов потому что гранулы уже немножко переформировались то есть сам процесс он обучение Точнее индексов он только на время несет но потом возможно еще повторное обучение индексов когда вот происходит мерч отдельных портов левая часть зала фронтенд Спасибо большое за доклад Интересно а вот это алгоритм оно относится вот прям к самым точным то есть он гарантированно выдаст ровно ближайшие самые вектора или может что-то потерять вот параметры как раз рекол он и показывает что находится не прям самые ближайшие то есть мы жертвуем самыми лучшими результатами но находим результаты которые действительно похожи жертвами полнотой время но при этом получаем преимущество по времени и сохраняем точность как-то так а вторая категория Вот они чисто математические дают точно абсолютно ближайшие по расстоянию Я немножко не понял ваш вопрос я имею ввиду что если как бы алгоритм который Ну там гарантированно выдает самый лучший как бы результат сверху потом Но вообще возможно такие алгоритмы есть но мы рассматривали именно приближенные потому что они как раз по времени занимают намного меньше обучения и все-таки довольно быстро Дают ответ вопрос из интернета Почему при увеличении гранолаете снижается точность результатов Это довольно просто объяснить Я даже лучше покажу картинку чтобы мы вернулись чем больше гранул мы используем тем больше гранул могут быть пропущены как я и говорил мы будем делать запрос с лимитом и вот то количество строк которые найдет наш индекс она будет аргументироваться лимитом и соответственно мы будем выбирать только некоторые из набора гранул поэтому больше пропускаем соответственно меньше точность центр зала фронтенд Спасибо за доклад был интересно ты рассказываешь что принесет их именно происходит обучение именно в момент всего это получается что сама вставка Вот она замедляется там на несколько порядков Да по-моему сто раз не рассматривали там такие варианты чтобы вот это обучение производить потом в отрыве уже от данных то есть да там это не консистентность будет фоне она там будет уже ну это консистенция становится Но если я правильно понял вопрос Вообще говоря inser ты никак не блокируют сами допуск самим данным то есть нельзя будет прочитать те данные которые вот вставляются несет на которых еще не обучен индекс но все предыдущие данные ведь можно прочитать с помощью селектов То есть я не совсем понимаю в чем именно заключается вопрос процессы которые раньше вставляли они теперь замедлится возможно в сто раз и для каких-то систем Возможно это будет критично Ну в общем мы пока не думали над изменением процесса обработки таким радикальным способом и пока мы только сделали что вот пока идет и обучение то есть они вместе выполняются и это упрощает собственно говоря всю логику как и селектор то есть нам не нужно смотреть на каких данных индекс есть каких нет так и в целом мы не нарушаем никак совместимость другие индекс работают также понятно И вот это вот картинка Intex intoses здесь получается что вот когда мы первую запись ставили то система обучается Да она каким-то образом определяет один Вектор или она определяет от как здесь нарисовано там 5 векторов А обучение происходит на всех данных которые вставляются то есть в данном случае вот здесь гранулярность 5 то есть на всех пяти гранулах будет построен индекс и для каждого вот отдельные сущности индекса это обучение происходит Независимо поскольку у нас могут быть данные как-то распределены неравномерные именно важно запоминать в пределах нашего индекса данный вот понятно"
}