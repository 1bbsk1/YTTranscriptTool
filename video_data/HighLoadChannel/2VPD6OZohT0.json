{
  "video_id": "2VPD6OZohT0",
  "channel": "HighLoadChannel",
  "title": "Тестирование ClickHouse, которого мы заслуживаем / Александр Сапин (Яндекс)",
  "views": 4449,
  "duration": 2815,
  "published": "2019-07-18T07:49:58-07:00",
  "text": "в этом году мой доклад оказался единственным секции тестирования но на самом деле я тоже не настоящий тестировщик я работаю в яндексе и разрабатываю клик house но сам клик house особенно в представлении не нуждаются этапа колоночный системы управления базами данных которое нацелено на обработку аналитических запросов в реальном времени она позволяет хранить петабайты данных и молотить их с помощью гибкого языка запросов позволяет линейно масштабироваться для увеличения скорости обработки запросов ну естественно как любая взрослая суда умеет работать нескольких tcm для обеспечения отказоустойчивости но с этой стороны клика узнают все но у него есть ещё и другая сторона это достаточно успешный open source проект который разрабатывается на языке си плюс плюс клик house полностью живет в экосистеме гитхаба и судя по всему это достаточно и удобный и эффективный способ мы принимаем все изменения через pull request и и в неделю в мир живым порядка 40 повре квестов и где-то 15-20 процентов из них приходит от внешних контрибьютором что особенно круто вот так выглядит график наших pull request of и видно что буквально за какие-то 8 месяцев последнее это число выросло в три раза это число в мер живым их pull request of они просто тех которые нам присылают причем что особенно приятно растет число не только наших собственных пури квестов создаваемых нашей командой но и растет число пол request of от внешних контрибьютором что тоже нас очень радует но это хороший график есть ещё вот такой график на этом графике показаны на же количество наших релизов в месяц тут конечно можно поспорить много это или мало но на самом деле как минимум как нестабильно но это еще полбеды you еще недавно достаточно короткое время назад топ наших ищу с на гитхабе после этих самых релизов регулярно выглядел вот так нам не портили достаточно серьезные баги там писали про поломки совместимости ну и прочие вещи ну вообще это немудрено потому что сломать в клик хаусе можно кучу всего так как это проект написан на си плюс плюс то здесь все ошибки про которые шутят всяких каламбур окрасе + + и ошибки работы с памятью и так как клик хаус это пытается утилизировать процессор целиком для выполнения запросов той ошибки многопоточном коде гонки ну или просто классические логические баги например в сложнейшей часть кли krause анализаторе выражений ну а можно даже и не че вообще не сломать можно просто как-то не совместимо поменять язык запросов что с чем пользователи тоже обязательно прибегут вот но я таки конечно богах как там поломки хранения данных на диске или поломки в механизме репликации вообще говорить не хочется это совсем ужас ужас но благо такой случалось нечасто ну как с этим всем бороться подход известной писать тесты для проекта на си плюс плюс на самом деле самый первый тест это сборка этот тест уже достаточно неплохой современный компиляторы они достаточно умны и особенно из по если использовать сразу несколько из них и если использовать свежие версии плюс еще хорошо их настроить выставить им достаточно строки флаги компиляции можно обнаруживать достаточно много проблем уже на этапе компиляции при этом если собирать и запускать программу в различных операционных хотя бы unix-подобных системах то можно тоже обнаружить различные баги который он прервусь производится только в апреле и не воспроизводится в линуксе ну и также естественно хочется чисто технических вещей чтобы у собранного бинарник а был минимум зависимости и которые необходимы для того чтобы его запустить чтобы сборка была воспроизводимый ну и несмотря на то что си плюс плюс известные своей медленной компиляции хочется чтобы это было быстро сборка у нас устроено следующим образом мы используем си плюс плюс 17 и это не только для того чтобы быстро теплее удобно распаковывать но и на самом деле для того что бы убирать из кода спина я переписываю его на кон стек спор выражения что сильно позволяет оптимизировать время сборки мы используем 2 наверно самых популярных компилятора си плюс плюс это колонки джи си си используемых об стараемся как можно более свежих версий и выставляем им достаточно строгие флаги и если во втором полете первые 4 флага еще большинству си плюс плюс программистов должны быть знакомы то вот флаг в его сын не является таким популярным этот флаг доступен только в компиляторе clang и при этом разработчики к ланга не рекомендуют его использовать он превращает компилятору настоящего паникёры в котором даже куча появляется противоречивых проверок на самом деле при достаточно тонкой настройки мы отключили порядка 30 из этих проверок он штука помогает реально находить баги ну и для сборки мы используем семей сочетании с ним дженин g это такой более современный чуть более удобный быстрый мейк с помощью которого мы собираем наш проект мы собираем один статический бинарник под все версии linux и делаем это в докере а чтобы это было воспроизводимо но когда не можем собрать в докере например для free bsd это собираем в гранте ну и естественно для того чтобы наш бинарник был статическим мы в нам приходится всей библиотеке класть в себе в репозитории у нас для этого папочка кантри бы там уже набралось не много не мало 6 миллионов строк ну еще своим и в плане сборок платим своеобразную плату за open source так как есть много различных контрибьютором клик house который не хотят компилировать 6 миллионов строк кантри бы хотят использовать библиотеки системы или хотят собрать клик house набор сошек и такие сборки нам тоже приходится поддерживать чтобы контрибьютором было удобно ну конечно же для сборки мы используем с анитой зиры это маст хэв для абсолютно любого си плюс плюс проекта будь то большой маленький их уже достаточно много здесь на самом деле не полный список текста не той зеров которые за разработанных углом но мы используем из них адрес стресс станет aether и антифа нет сани tighter и того в сумме у нас получается вот такая вот достаточно не маленькая табличка с сборки с анитой zero мы делаем с клан гам так как от код гораздо более хорошо работает с анитой zero мы с этим компилятором а для релиза мы собираем с помощью джи си си 8 так как код генерируемый джесси получается по нашим собственным бенчмарком процентов на 78 быстрее чем то что генерирует clang ну и также видно по последним двум столбцам что вот эти сборки для энтузиастов мы тоже используем тоже их поддерживаем но этого конечно немало так как одна такая сборка в среднем занимает 20 минут на достаточно мощном сервере при этом хочется поддерживать около десяти таких сборок на каждый коммент это вообще очень много ни одна пил ферма не захочет просто так сжигать железо тратить его поэтому хочется сборки как-то чуть-чуть ускорить мы попробовали несколько подходов для начала попробовали казалось бы то что должно сто процентов помочь распределенный кэш с помощью программы из сиси но несмотря на то что этот самый распределённый кэш находился прямо в дата центре рядом с москвой все равно накладные расходы на передачу данных по сети и дали полностью профит от компиляция вообще никакого профита не давала также мы пробовали использовать unity билды когда весь код собирается в несколько очень крупных translation юнитов которые компилируются но и это кстати можно очень удобно сделать если вы используете семейка с помощью модуля который вот находится по ссылке на гитхабе но нам это тоже дало совсем маленькое ускорение а вот памяти поедать сборка встал вопрос совершенно не приличное количество сработал у нас совершенно брутфорс ный вариант мы использовали нераспределенный кэша локальный кэш при этом счастлив сборки какого-то очередного комитас охраняли этот кэш и скачивали при сборке следующего несмотря на то что нужно качать выросли накладные расходы на скачивание посетите все равно в общем суммы сборки ускорилось примерно в два с половиной раза ну а кто еще но страдает сборкой программ на си плюс плюс вот по ссылке есть презентации с хорошего доклада си плюс плюс раша где человек кажется обозрел все возможные способы как можно сборки ускорить но окей я сказал что мы хотим один статический бинарник под все версии linux но на самом деле полностью статическим он быть не может в него есть зависимости от библиотеки или psy или находятся самой базовой функции причем зачастую эта зависимость даже не явно это протекает откуда-то из библиотек в кантри by которые используют lip session и и вызовы при этом символы в липси на самом деле и функции versio не руются и собраны бинарник с более версией с более новой версии липси на какой-то там свежий ubuntu или федоре он уже перестает запускаться на более старых системах ругаясь на то что версии символов repti не соответствует ну и естественно клик house зависит от ядра от этого никуда не деться чтобы с этим бороться у нас есть специальный тест для этого который называется тест совместимости мы смотрим все символы которые есть в бинарники смотрим те из них которые относятся к липси и смотрим версию этих символов если она превышает какой-то определённый порог мы считаем что наш тест провалился также заодно помимо этого чтобы уж точно быть уверенным запускаем плек house в старинном доки в старинных линуксах centos 5 и у будете 1204 но делаем от конечно докере ну а если тест не прошел мы делаем такой достаточно интересный трюк мы просто копируем куски функций которые nude сами функции которые нужны которые протекли от cut ice контри бы из библиотеки маслоу это такая альтернативная реализация липси и естественно если бы удивились какие-то сколы которых более старых играх нет их от них тоже избавляемся просто в коде но окей клик house мы собрали все таки хочется чтобы он что-то делал и делал как-то контролируемо ну у нас для этого есть самые обычные тесты мы используем статический анализатор кода который нам иногда находят такие не до баги но это однозначно полезно мы у нас есть unit тесты и есть простой фреймворк для функциональных тестов которым поддаются и скольки на входе какое-то ожидание в ожидании выхода теста и происходит просто запуска этих запросов также там можно не es que el que a написать более интересный скрипт запуска при запуске с анитой за раме с данными это все достаточно эффективен находит много багов но вообще эти тесты они какие-то скучные при у них недостатков куча ну во-первых их мало они покрывают порядка семидесяти процентов кода вот при этом при этом их вообще то писать еще тоже надо что тоже достаточно большой недостаток и проверять какие то параллельные запросы или там в одновременные какие-то запуск вещей тоже с ними достаточно неудобно но тесты уже есть и хочется из них еще какой-то максимум выжить какую-то пользу получить для этого мы запускаем функциональные тесты в режиме стресс-теста мы просто создаем м копий функциональных тестов запускаемых они все начинают долбится запросами в сервер клик хауса дополнительно создаем нагрузку из мусорных запросов но чтобы вообще жизнь медом не казалась и после этого конечно не какие там результаты работы запросы мы уже не проверяем там пол накажу получается но начинает выполняться такие участки кода которые в нормальном режиме никогда не выполняются и в сочетании с адресат рационе тайлером мы находим достаточно много неправильных обращений к памяти гонок и этот здорово помогает и при том что этом эти участки коды могут быть ну достаточно редкими в реальных сценариях но так как эти тесты получаются вообще бесплатно ничего не нужно добавлять никакой логики то это вообще очень здорово находим много багов как я уже говорил в клик хаусе очень гибкий язык запросов там больше 600 функций вообще на все случаи жизни тридцать восемь типов данных десятки различных операторов и понятно что из вот этого всего можно собрать совершенно там взрывное количество конструкций которые в клика us можно задать и к тому же еще и сам этот язык он достаточно далеко от стандартного иску или ну чтобы с этим многообразием бороться у нас есть fastest который представляет из себя скриптик на мягко говоря не рекомендуемом яндексе языке программирования он имеет словарь типов данных словарь выражение языка спрашивает функцию клик хаоса и после конструировать достаточно простые запросы но которые очень изощренным образом передают аргументы функции клик хауса из-за чего в сочетании с анти фаниться не тайлером или адреса не тайлером часто находится совсем страшный баги когда на каких-то элементарных запросах клик house пытается уделять экзабайт и памяти ну или откровенно падает отказать все три запросу на слайде несмотря на их бредовости они все приводили к падению сервера и были найдены именно этим fastest им но это были такие тесты клик хауса в вакууме как мы из предыдущего доклада как минимум узнали в реальном мире клика us вакууме не живет он взаимодействует системами и естественно кликал сможет взаимодействовать с различными субд м популярными ну а с тем для кого не написано нативные адаптеры можно взаимодействовать пол ди би си также наши пользователи очень любит соединять клик house со всякими распределенными системами типа как мы уже слышали hd эфесу но особенно любит кафку но и также клика у сможет взаимодействовать собственно с самим собой это как раз для обеспечения того самого линейного масштабирования и самый интересный случай это как раз репликация данных репликация данных клик хаусе является асинхронный мастер мастер при этом для ее работы требуется дополнительно не какой-то маленький кластер звуки пера при этом как и любая мастер мастер асинхронной репликации она и вентили consistent это чем мы собственно гордимся on a highly вы либо она переживает выпадение not переживает в от разрывы сети между ними между звуки пирам и это и это естественно хочется проверять что это действительно так таким образом мы хотим проверить плане взаимодействия как кликал с внешними системами общается как общается между собой и особенно нам важно моделировать разрывы между сети чтобы проверять ту самую репликацию чтобы она действительно была highly reliable ну и естественно хочется чисто технических вещей чтобы запуск этих самых интеграционных тестов был простым чтобы не требовалось устанавливать тысячи каких-то там пакетов ненужных чтоб был чтобы мусора после их запуска нахождение оставалось ну и понятно что тут сценарий тест ты уже вряд ли будет таким простым совсем декларативным тут хочется еще чтобы их на каком языке программирования писать чтобы моделировать ситуацию для этого у нас есть фреймворк построенный на базе докер ком пауза он достаточно общей он подходит не только для тестирования клик house его можно немного адаптировать и тестировать в принципе любые конфигурации распределенных систем сами тесты пишутся на питоне сочетании с по тестам что достаточно удобно и вся конфигурация распределенной системы которую мы будем тестировать полностью сдается в коде никаких я мулов дополнительных писать не нужно давайте посмотрим на ситуацию которую можно с этой штукой тестировать допустим ой извиняюсь за было то самое важное что забыл мы хотим проверять сеть естественно любой системный администратор скажет что сеть можно проверять с помощью iptables что сеть можно носить управлять можно с помощью айпи тибблз ну вот таким простым командами можно добавить какие правила чтобы разорвать сеть между узлами или чтобы восстановить ее естественно но не многие знают что с помощью модуля статистику можно внедрять вероятностные разрывы между узлами которые как раз лучшим образом им лидируют в лапы сети который репликации должна переживать но и питался есть минус для того чтобы он работал душ нас судов естественно никто в жизни не запустят тесты которым для запуска требуется судов для этого у нас используется снова хитрый трюк мы помимо всех основных нот в наш который поднимает докер кампус поднимаем еще один маленький контейнер самым маленьким линуксом в котором у нас естественно есть root если 5 balls при этом этот контейнер запущен в к 100 вай сити что уже позволяет внедрять правило вейпе тейлз и таким образом управлять сетью без суда что удобно а вот теперь давайте посмотрим на пример вот у нас есть простая конфигурация какая-то в которой у нас есть маленький кластер из трех зуки перов есть две ноты клик хауса на которых находится одна и та же реплицируется таблицу которые связаны между собой сетью ну и чисто в демонстрационных целях у нас еще есть одна нота с ходу poms которой связана одна из нот клик хаоса из неё мы попробуем взять данные и так же у нас есть тот самый alpine контейнер который будет управлять сетью и так какой сценарий мы хотим промоделировать мы хотим сначала разорвать сеть между узлами что делаем с помощью этого самого контейнера потом на одной из нот хотим взять данные из х tfsi положить какую-то локальную табличку после этого восстановим сеть и уже на другой ноте проверим что репликацию отработала и данные доехали на самом деле для описания таком сценарии требуется совсем немного кода мы создаем объект клик house кластер добавляем в него две ноты одна из нот связано с hd fsm и звуки пиром 2 только с у кипером тут для работы репликации после нужно написать какой-то совсем небольшой код в котором нужно создать таблички на нотах положить какие-то данные для тестов gdfs но это не так интересно и после этого код самого теста будет достаточно простым мы с помощью класса партий шин менеджеров которые как раз и управляет сетью за через вот это pine контейнер создаем контекст в этом контексте мы с помощью метода партизан instances разрываем сеть между двумя нотами на 9000 девятом порту на котором работает репликация после этого собираем данные из их и tfsi и вставляем их себе в локальную табличку после этого из контекста выходим сеть восстанавливается и дальше проверяем что данные до 2 ноты доехали ну и при этом конечно делаем с ретро ими потому что происходит это не мгновенно вот ну тест описать достаточно удобно но нам все равно нужны какие-то внешние библиотеки и а то и 5 был со вообще говоря может остаться мусор если кто-то тесты девятом сигналом будет убивать никакие менеджер контекста не спасут правило останутся в над фильтре и будут в следующий раз вызывать совершенно непредсказуемость при запусках для этого для решения этой проблемы у нас используются странное решение мы используем докер в докере у нас есть специальный образ в котором уже установлен докер демон в котором есть все внешние нужные библиотеки и которые запускаются в них основой сети при этом однозначно никакой мусор не остается никаких зависимости нет но если для тестов это еще более менее норм но в продакшен такой использовать никогда нельзя вот под этой ссылке можно посмотреть какие проблемы ждут пользователей докеров докере в продакшене окей но вообще все любят клик house не за то что в нем там багов нет на 100 процентов на самом деле за то что он работает быстро ты для этого он исполняет запросы достаточно специфическим но на самом деле для аналитических субетто этот способ типичен он на каждый процесс утилизирует весь пункт thread'ов на каждый запрос утилизирует весь пункт родов при этом thread'ы могут воровать какие-то куски задач друг у друга если какой-то один отработал быстрее 2 может было он может перехватить задачу другому труда при этом естественно используется умный локатор так как павел системный достаточно плохо подходит для сценариев аналитический суп это но умный выделяют память достаточно особым образом и при этом ли краусом не имеет никакого внутреннего кожа он и полагается полностью на кэш операционной системы вследствие всего этого запросы могут быть достаточно нестабильными вот что же влияет на перфоманс но на самом деле почти все железо главным образом это конечно диск начиная с кашей файловой системы и соответствующие организации рейда и вообще состоянием дисков в этих рейдах но даже если конфигурация системы вот абсолютно статичная она никак не меняется то просто положение данных на этой диске может изменять производительность ну примерно в два раза ну естественно performance влияет память и процессор чем больше я der чем больше памяти тем вообще лучше ну как таких условиях производительность замерять ну во первых с дисками кашами побороться все таки сложно их лучше исключить так как их многообразии крайне велико степенью и памятью дела получше их можно зафиксировать там вариантов гораздо меньше естественно нужно правильно выбирать условие по каким в какой момент мы решаем что вот данная какая-то характеристика выполнения запроса может считаться его реальной характеристикой может сравниваться с другими запросами правильно в общем то выбирать условия останова выполнения вот так же в аналитической суп это не стоит замерять performance каких крошечных запросов с работой в несколько миллисекунд так как там из-за того же воровства задач между трудами такие запросы могут сильно очень различаться по performance у ну и также для запросов стоит все-таки использовать реальные данные так как на синтетических очень легко за оптимизировать какие-то частные случаи при этом на реальных в таких вариантов таких случаях всегда почти получается просадка как же мы с этим боремся у нас для этого есть программа которая называется коли клаус perfomance test которая на самом деле входит в стандартную поставку у всех кому клика установлена на есть она фактически является альтернативным клиентам клик хаусу напрямую посылать ему запросам как она получает из входных файлов которых собственно описывается тест формате xml декларативным при этом в ней можно задавать различные режимы выполнения запросов которые он собственно будет посылать это бесконечно выполняет запрос или выполнить запрос цикле при этом можно снимать различные метрики запросов такие как минимальный максимально рпс такие как квантили времени ну и естественно можно задавать те самые условия останова на интервале как например то что рпс не превышает какого-то значения или то что для циклического запрос минимальное время достаточно остается низким достаточно долго окей как мы это запускаем для этого у нас есть куча perfomance test of который мы с помощью этой программке проверяем часть из них это синтетические запросы для проверки производительности и отдельных функций есть и часть из них естественно реальные данные мы используем запросы когда-то этом нью-йоркского такси грата set one time так как данные тасс это как правило используется для сравнения производительности различных баз данных ну и также коллег не обижаем используем данные яндекс метрики которые тоже доступны открыто при этом сохраняем лучший результат выполнения запроса так как случайно запрос ускориться не мог он мог только случайно замедлится ну и в результате реагируем на просадку по отдельным запросам семь процентов в целом по клик хаусу на 1 процент ну и кому то такие цифры могут показаться как бы не очень точными что клик house вообще можно там по чуть-чуть просадить простуда плохие pull request и дело но на самом деле для отслеживания таких ухудшающих трендов у нас есть графики с перфоманса запросов которые у нас гоняются performance тесте и вот пример такого графика но здесь на самом деле показано хорошая ситуация это минимальное время выполнение вот этих трех запросов и видно что 5 марта она резко упала так как приказ был оптимизирован в очередной раз но на самом деле видно что даже вот эти запросы это хороший запросы у них все равно grip performance достаточно скачет то есть есть флуктуации естественно наши performance тесты были давно но запускать регулярно на каждый коммент моих стали недавно естественно когда мы запустили мы увидели просто тонну шлапов буквально почти везде естественно часть запросов было про часть тестов было просто отстойно написано были указаны неправильные условия останова или использовались слишком короткие те самые запросы которые хлопали чтобы все-таки окончательно полностью исключить влияние дисков мы все данные для запросов стали класть мпф с еще у нас были в лапы из-за того что мы конкурировали с какими-то системными регулярными процессами при поэтому решили ограничивать полтора ду пульт родов на которых запросы выполняются чтобы никак не конкурировать ну и чтобы избегать каких-то совсем редких вещей как там тротлинг на процессоре или битая память мы запускаем тесты на нескольких постах но на самом деле даже вот эти чисто технические меры которые мы приняли они далеко не думаю ни для всех случаев помогли вот пример такого случая это запрос он достаточно простой он почте считает числа в то по системной таблицы системном берс она является бесконечной самой интересной частью нее находится в части vr где используется специальная функция not игнор который заставляет оптимизатор все что находится внутри этой функции не выкидывать а честно исполнять там мы выделяем достаточно короткую строку потомкам к тени ruim ее 10 раз а потом результат еще конкретизируем 10 раз ну очевидно автор этого запроса для теста хотел как-то проверять функцию concat условия останова для таком запрос написано достаточно разумны и либо три секунды средняя скорость выполнения не меняется 0-ем всего выполняется 10 секунд тем не менее этот запрос нещадно fla пол показывая нам красные кресты на гитхабе мы решили отладить этот запрос мы во первых его сделаны конечным ну чтоб там controls и не ловить какой-то мент ограничили пятью миллионами и по запускали как раз такой запрос пятью миллионами выполняется примерно три секунды и видно что разницу во времени почти в полтора раза причем это не какие-то там избранные запуске это вот в общем-то подряд то есть хороший результат получается быстро но порой результаты жутко тормозн и собственно тут можно наверное подумать что кликал сет какой черный ящик тест для него performance писать почти невозможно нужно использовать какие-то серьезные инструменты линуксовые для анализа производительности нов клика усь этого всего вообще не нужно у него есть системная таблицы говорит ритлок в которой хранятся все данные системы которые были получены во время выполнения запроса мы просто выбрали из этой таблицы все статьи характеристики по запросам которые выполнялись больше трех секунд и сравнили с теми которые выполняются меньше трех секунд при этом оказалось что в общем то проблема основная видно наибольшее различие видно в характеристике пейдж фолз который как раз те самые полтора раза которые могли отличаться между быстрыми запросами и медленными запросами ну что это значит значит то локатор как-то по-другому выделяет память при выполнении запроса и причем может это делать достаточно долго поэтому мы этот запрос переписали сделали его выполнение циклическим сделали его конечным ну и стали снимать метрику минимального времени и и он достигает достаточно быстро таким образом этот флаг победили но на самом деле тут увлекся и примером таких на самом деле плитка усе еще очень много и до сих пор у нас на мастере запросы похлопывают но мы с ними боремся но вообще все эти тесты совершенно бесполезный если их не запускать для того чтобы их запускать в клик хаусе был чай этот чай представлял из себя сочетание из железного дженкинса который работал на железных хостах и отдельные столе и отдельные штуки которые мой отдельным трэвисом который запускался на гитхабе у этой системы было много преимущественно долго служил верой правдой но в один момент ее недостатки перевешивали уже все ну как минимум то что ее делали ребята из соседнего отдела и fitch туда попадали очень медленно там не тестировались внешне пол request и тяжелые тесты такие как performance запустить был нельзя с этим так как инсталляция была маленькая ну и никакие там артефакты чтобы проверить что там собственно пошло не так не сохранялся и сохранялись но это были как бы наши личные претензии к дженкинс у это все можно было исправить но у дженкинс и есть и фундаментальные недостатки в первую очередь это его система плагинов и job dsl на котором то есть либо мы должны были использовать плагины и программировать на html если функциональности не хватало мы должны были писать джо бы надеюсь цели который взаимодействует с плагинами но зачастую при обновлении этих плагинов происходили различные проблемы совместимости и поддержка такого себя и остановилась еще отдельным челленджем мы разбираться с этим но не хотелось совершенно трэвис это замечательный проект для маленьких open source иных проектов на гитхабе это маст хэв им удобно пользоваться но для больших проектов он конечно не подходит даже за деньги он предоставляет очень маленькие мощности 10 параллельных драбов что было бы с это целиком одними нашими сборками ну и конфигурация драбов трэвис и описывается ямам что тоже не всегда локально удобно воспроизводить ну решили мы эту мертвеца не воскрешайте решили посмотреть как устроен себя и в других окон source сбт первую очередь мы посмотрели на манга деби это очень крупный open source ный проект который тоже живет полностью в экосистеме гитхаба манга тебе достаточно серьезно подошли к процессу вся я и для этого у них собственный отдельный проект который называется эвергрин он тоже живет на гитхабе в него то он тоже полностью open source на и в него можно кантри beauty интерфейс этого эвергрин однозначно выше всяких похвал им пользоваться удобно и все артефакты которые там во время сборки получается тоже для скачивания доступны но при этом весь процесс разработки в manga деби сильно завязан на внутреннюю джерон прямо людей в pull request их приглашают создавать какие-то ticket и и запуск сейф тоже с этой дыры связан то есть изменение то есть запуске привязаны к текке там что на мой взгляд какое-то лишние лишние палки в колеса для контрибьютором еще мы посмотрели на по сброс это такая достаточно консервативная система в плане разработки у них использует собственный git репозиторий а все изменения они принимают через mailing list и вообще у по сгрыз достаточно много сейф наверное штук пять различных но наиболее популярные из них называется build фарм правда на ставите страничке создатели build фарма как-то предостерегают насчет языка но я думаю это на самом деле зря этот билд фарм представляет собой такую клиент серверную модель то есть есть какой-то централизованный набор серверов на которых находится мастер это убьет фарма и на абсолютно любой сервер в интернете можно установить клиентскую часть после этого настроить в этом клиенте запуск тестов интересующих тестов на нужные branch и просто по крону и видеть результаты этих запусков в интерфейсе build фарма это здорово так как можно тестировать вообще очень редкие архитектуры моим тренер и собственно тестирует то что их интересует это здорово но с другой стороны если что-то пошло не так если какая-то сборка там или тест не прошел то уже узнать найти концы достаточно сложно так как где-то там на каком-то древнем power писи что-то не так работает так как скачать результаты ней сборки нельзя это большая проблема еще мы посмотрели на субботу я пачек night она тоже полностью живет в экосистеме гитхаба тоже изменение принимают через пол request и и для себя у них используются этим сити это достаточно известный проект бесяев при этом вот это очень понравилось в интерфейсе этого тем сити сразу на запуске на все пол request и на каждой паре квас можно запуск посмотреть можно посмотреть полностью граф выполнения это все очень удобно но там какая-то странная особенность на каждый буквально на каждый запуск сотни упавших тестов которые периодически проходят периодически нет непонятно из-за чего это с чем это связано и возможно из-за этого интерфейс это у себя дико тормозит то есть пользоваться им ну совершенно не удобно и не смотря на то что тем сити запущен но где-то на 80-х стах все равно большая очередь запуске проходят достаточно долго но посмотрев на внешние системы в итоге у нас получился такой список анти паттерн ученом в нашем вся и 1 значит не хотелось первое чего не хочется это иметь какую-то инструкцию для контрибьютором в какой там интерфейс пойти где там tickets создать чтобы на ее что-то найти это вообще не нужно этот как я сказал лишние палки в колеса еще не хотелось вот такого комбо из трех вот этих пунктов когда тесты хлопают артефакты скачать нельзя и при этом еще и и при ну и это вообще достаточно неудобно то есть contributor у начинает казаться у вас там что-то сломалось у меня все работает и я вообще никак результатах узнать new не могу и также особенно чего не хотелось это прогонять тесты по нескольку часов не хотелось чтобы запуск был для какой для каких-то элитарных пользователей на определенные branch и хотел чтобы запускалась абсолютно везде на все branch и мы выдвинули себе такие требования во-первых мы хотим чтобы интерфейс был для contributor очевиден чтобы никуда ходить не надо было чтобы все было прямо перед глазами чтобы артефакты сборки были доступны всем чтобы запуске были на все pull request и на все комменты в том числе и тяжелых тестов и же самое главное еще чтобы это все локально воспроизводилась и весь код этой штуки тестовый был открыт качестве интерфейса мы использовали но он совершенно очевидный вариант странно почему мало кто так делает мы прямо из-за использовали интерфейс гитхаба гитхабе достаточно мощный механизм статусов которые он позволяет создавать для каждого коммита в этом статусе позволяется указать собственно статус проверки это прошла выполняется или успешно и можно указать ссылку абсолютно на любую обсалютно любую ссылку на который в которой привести но какие-то дополнительные отчеты при этом ну как известно гид хоп стабильный у него и пи ай мощный и этим достаточно удобно пользоваться в качестве данных вот по вот этой ссылке мы используем простые html статические html-странички которые храним во внутреннем индексом с 3 лет с 3 открыт наружу то есть пользователи могут пройти но тут никаких шедевров дизайна но вроде бы все видно и все логе абсолютно приложена каждому запуску дополнительно мы вот с 3 заливаем все сборки причем сборка какого-то из комментов становится релизной дополнительно никакой никакой отдельного процесса релизы сборки у нас тоже нет ну и само собой где-то все надо запускать тут мы велосипед изобретать не стали мы просто используя использовали опыт коллег у них есть специальное хорошей инфраструктурной облака которая похожа на team сити но чуть попроще в нем можно запускать произвольный код на питоне которые такая единица называется задачами при этом фиксировать характеристики хростов на которых этот код выполняется конечно такая система устойчива там к выпадению not но это само собой куда без этого она сама в себе может хранить какие-то артефакты и указывать на них атрибуты но эти мы почти не пользуемся и все что она может это запускать задачи по таймеру никаких специальных внутренних графов у нее нет то есть это все приходится делать руками ну и вообще мы запускаем какой-то случайный код из интернета на собственных холстах внутри яндекса и это может приводить к пожарам для того чтобы с этим бороться мы в каждом pull request и запускаем тест и все-таки только после какого то хотя бы первичного просмотра ответственного контрибьютором при этом это заключается просто проставки лейбла на пол request при этом мы все запускаем в докере чтобы получить лишний уровень изоляции и дополнительно внутри этого базового облака этого поиска все изолирована по диску и сеть и вот в результате у нас получился вот такой вот граф сначала мы скачиваем код с гитхаба потом запускаем сборку дополнительно делаем там какой-то анализ кода и потом запускаем все наши тесты что в результате ну конечно хотелось бы сказать что в результате все вот так что иисус наш теперь выглядят только вот так то есть никаких там багов только люди фичи заказывают performance просит оптимизировать но на самом деле от конечно не правда у нам много еще чего не хватает например нам не хватает теста у покрытия так как убеждать контрибьютором писать тесты мы уже научились а вот убедить их что их тесты на самом деле ничего не проверяют уже гораздо сложнее также нам не хочется все-таки иметь какую-то отдельную страницу на которой мы сможем смотреть какие статистики по тестам ну как это примерно сделана в тем сити и самое главное что хочется это бэк-ту-бэк тестов так как кликал все-таки система очень разнообразны и никакими человеческими усилиями там все не покрыть тестами для этого нужно просто брать данные от пользователей нужно брать запросы и сравнивать результаты работы между различными версиями клик крауса на самом деле граф наш должен выглядеть вот так то есть мы еще и статический анализатор кода хотим добавить clang таити дополнительно и вот те самые бэкпэке и измерять ковры но есть и хорошие новости на самом деле мы стали чаще все-таки находить баги ну что очевидно мы мир жим больше pull request of теперь у нас просадки производительности но вообще почти не случаются даже несмотря на то что в лапы тестов все еще бывают мы смогли ввести релизный цикл при этом ti релиз клика усы от буквально несколько минут так как ничего пересобирать не надо ну и особенно радует что стали появляться контрибьютором который контрит летят в тесты и contribute вся и то есть теперь выставить контрибьютором клик хаоса не нужно там знать си плюс плюс можно просто тестовую про структуру улучшить или докер файлы поправить все спасибо за внимание вопросы нет вопрос благодарю за доклад николай мтс ты вопрос такой скажите пожалуйста получается вот этой себя и сети которую вы сделали это как продукты ну если брать даже на уровне команд яндекса то есть вы сделали что-то уникальное вот это получается такой специализированная штука именно для cliff house или допустим другие ваши коллеги из других продуктов команд тоже могут его использовать ну на самом деле многое зависит от репозитория в котором находится внешний код для продуктовых команд есть свой большой внутренний моно репозитории в котором уже там построен собственный с использованием того же облака базового поиска то есть эта вещь в принципе для клик house достаточно уникально это продукт который на гитхабе живет на внешнем для яндекса это такой случай но частный ну вот совершенно частные вопросы вот есть у вас еще замечательный продукт индекс танк вот вы из вас разные вот метод сесть и продукт для тестирования или ну я сдам странную это именно pro performance и но у нас для этого свой клиент он достаточно специфичный вон именно умеет знает протокол общения с клик хаусом индекс танки такой бы детализации вы не получил бы от него получить спасибо большое похлопаем от примет нас благодарность и я должен был попросить тебя назвать авторы лучше вопроса на продажу зазор очевидным а еще один есть окей так вот может уже в кулуарах но потому что уже приз от already уже отдали то но я думаю что андрей сыра давай задавай вопросы короче пока не забыл я java script разработчик недавно писал запуск программы случайно не столкнулся на наши внутренние железная инфраструктуре слабо нехитрой счетную задачки которая круг говорят m203 500 миллисекунд процессор греет что она на процесс лапает просто от души места именно виртуализованных контейнере до 20 процентов расхождение от запуска к запуску лучшее чего удается добиться это вот на таких носитель на микро тестах где-то наверное расхождение да там двух трех процентов на троне просто до пскова запуску но тест недолгий натурально там в пределах 200 500 миллисекунд ну и соответственно приходится дебильные танцы танцевать под названием делаем там сотню запуска вот он когда совсем коротенькое партнера совсем там nana beach март короткой продолжительностью мере там порядка 10 30 запусков когда продолжительность чуть побольше там выбирать либо средний либо там фильтровать либо минимум я вот люблю выбирать очень но в целом многие годы меня как java script разработчика преследует это залупа что невозможно на линуксе воспроизводимые результаты в рамках 3 тестовых забегов изобразить вот у вас такая же беда или у вас нормальный сервер она лимсе ганина особенные и вот где бы мне украсть об и сервер и сервера у нас абсолютно обычная с абсолютно стоками к сиону со стоковым а миссию в этом ничего особенного нет новые это действий да у нас там вроде тоже но вот как нигде не пробовал какие серверами ни одно и то же но тайны прямо на же не скосить достаточно сильное выражение местами ноу до для этого собственно вот я про все эти муки и рассказывал что мы во-первых все однозначно фиксируем во вторых перезапускаем в третьих еще и на многих картах сразу запускаем после этого считаемся средние но до мог ими этими страдаем это правда то есть тоже тоже дрожит и в спал полной воспроизводимости на крохотном на на запуске нет нет нет такого нет приходится сделано крупных на на запуска групп говорят и дернул 3 проход по 500-м всех подряд на одном и том же посте он который не делать ни хрена все в памяти все запишем но все всю огонь по всем канонам должна быть в из поразились грубо говоря 500 500 500 одна миллисекунда на самом деле ты видишь отчеты 497 520 503 такая же проблема или получите но как я уже говорил мы собственно совсем короткий не тестируем а для принцип миллисекунда бывает да именно так то есть приходится много перезапускать и на разных просто хочу это делать понятно счастья тоже нет по цвету на этой позитивной ноте видимость больше"
}