{
  "video_id": "g6mso3BiMuQ",
  "channel": "HighLoadChannel",
  "title": "Секретные технологии инвестиционных банков / Алексей Рагозин (Дойче Банк)",
  "views": 1081,
  "duration": 1840,
  "published": "2017-04-08T13:59:17-07:00",
  "text": "добрый день коллеги меня зовут алексей рагозин я работаю в банке и сегодня представляю вам доклад под заголовком секретные технологии инвестиционных банков хочу сразу оговориться их секретов раскрыта него есть то есть все вещи которых я буду рассказывать они так или иначе доступны мартель трех источников про что же я буду рассказывать в принципе в мире айти получается так что такие технологии как базы данных языки программирования они используются везде независимо от industry везде используются скаляр к java и так далее с одной стороны с другой стороны бывает так что вроде бы какой-то продукт там допустим похож на базу данных но получается так что используется он только в финансах за пределами финансов известен очень мало хотя прямого отношения к финансам он не имеет не какая-то там какой-нибудь sap не какая-то конкретная бизнес систему и соответственно вот сегодня я подготовил доклад по сути три таких blitz доклада которым мы которых в рамках которых я расскажу про три таких систем и первое это аналитическая база в памяти и т.п. второе это система обмена сообщениями информатик ultra mat angel и третье это больше рассказ про архитектуру фронтенда трейдинга приложений ну и соответственно ту специализированной системы обработки ивентов которые пришлось эта архитектура написать итак позвольте мне начать со продукта под названием tdp это база данных в памяти аналитическое и прежде всего она используется для финансовые аналитики пару слов что такое финансовый аналитик а вот на этом слайде придадут представлен так называемый рыночный стакан или стакан котировок то есть есть некоторый сток которые торгуются на бирже и в каждый момент времени у вас есть очередь заявок на покупку за продажу каждой есть своя цена размер заявки вот в таком виде она присутствует только на экран то есть на самом деле это все происходит в виде ивентов рынок информируют тех игроков которые подключен к нему напрямую новых заявках у совершенную сделку то есть из за этих ивентов можно в любой момент времени составить такую картину посчитать например какой общий объем заявок на продажу выставлен какая средневзвешенная цена и эти цифры соответственно соответственно дальше могут использоваться для вычисления еще каких-то факторов которые по-разному используются ходе торгов тот например более сложные примеров того же анализа глубины рынка в данном случае представлена иллюстрация попытки манипуляции рынком которая была в 2013 году что здесь можно на что он здесь надо обратить внимание то что очень много точек очень много цветов то что получить диаграмму пришлось вот просуммировать разделить и усреднить достаточно большое количество информации соответственно для того чтобы работать с этим а помимо того что такой график надо построить один раз его еще надо постоянно поддерживать в актуальном состоянии постоянно пересчитывать по какому-то окну а свежих данных нам нужна специализированная система которая умеет быстро принимать данные умеет обрабатывать данные теми методами которые нам нужны в том числе в виде окон и которая хорошо работает с тем большим количеством арифметики которая требуется киви как раз является продуктом который нацелен на решение подобных задач в названии продукта присутствует слово дебит что наталкивает на мысль что это база данных более того эта система позволяет хранить данные на диске то есть там есть таблица хранятся на диске туда можно записывать данные но 1 очередная задача этой системы это работать с языком пью это специальный язык функциональный который идти на работу а силами сами разработчики кей би би называют его в окна на лице ориентированным языком потому что основная его задача это перемалывать массивы данных в памяти сам по себе язык достаточно страшный то есть функциональные основные в древние времена существовал такой язык и перепрограммирован вич это он приблизительно в одно время с листком родился вот по синтаксису он был еще более страшной но идея основные остаются есть вариант с горки который вроде как похож на успел то есть мы видим слова select from но надо понимать что вот результатом такого селектор будет массив и если вы запросите несколько кого на то вы получите два массива то есть то что может для вас выглядеть как таблицы на самом деле такие тебе это всегда массивы вы можете использовать их вместе вы можете использовать их по отдельности эти массивы они лежат в памяти они лежат в памяти плотно то есть в этом смысле обработка она происходит как в колоночный базе данных потому что мы оперируем именно с массивами как с колонками несмотря на то что сам по себе язык и интерпретируемые если вы попытаетесь там строить ту же самую аналитику например на чистом ламповым все вам придется очень сильно попотеть чтобы гнаться за ним опыт производительности потому что практически все операции которые выполняют этот интерпретатор они выполняются над большими массивами данных эти алгоритмы которые заложены в самой базе данных по работе с этой мазями она они очень сильно оптимизированные не оптимизированные под процессоры они используют все доступные векторные инструкции которые есть в процессоре плюс несмотря на то что с логической точки зрения выполнения кода она одна поточная отдельные части могут раз параллельность если нам надо просканировать какую-то большую таблицу применить какой-то критерии сложить результаты в массив то под капотом будет использоваться несколько потоков будет использоваться параллельность это с точки зрения выполнения кода он 1 по . как я уже сказал основное применение подобные технологии это аналитика но помимо этого удается ее еще достаточно хорошо применять для совсем не финансовых проблем таких как анализ производительности и анализ сетевого трафика в первом случае у нас есть система которая кодирует различные бизнес события между различными системами и тебе используется для того чтобы потом коррелировать информацию и посчитать какие задержки были на между различными системами при прохождении сделки или какого-то другого ивента и в тех областях где задержки действительно важны в high frequency трейдинге там есть используется анализ сетевого трафика то есть трафик лакируется с помечается сталь темпами и потом в киеве пить делается анализ на с целью поиска каких-то аномалий которые добавляют нам лишние задержки с точки зрения сетевых коммуникаций несколько ссылок на официальном сайте кидди by вы можете стать важный момент который я пропустил сам по себе интерпретатор и деби он очень маленького размера причем от релиза к релизу он становится меньше и одна из причин почему он остается таким маленьким чтобы помещаться в кэш процессора чтобы максимально быстро исполнять вот это вот ядро кода которая собственно занимается обработкой ваших данных соответственно скачать совершенно бесплатно 32-битной версии тебе можно с официального сайта она полностью функциональна но как сами понимаете 32 битная версия для решения каких какого-либо рода масштабных задач не очень интересно в связи с ограничением памяти если знаете лицензии и лицензионные ограничения на некоммерческое использование также есть ссылка на еще один так уот полки и деби на русском языке тоже от сотрудник удачу банка и наконец организаторы попросили по возможности делать ссылки на какие-то open source аналоги существует а нова реализация аналога языка кий который является предтечей языка пью которая доступна под теперь версии 3 рецензии честно говоря не работал с не могу ничего сказать не плохого не хорошего так для информации привожу эту ссылку на этом заканчиваем ски тебе следующая следующий мне нам мини так вот это системы обмена сообщениями информатику ультра messenger ну немножко в двух словах основные принципы систем работы обмена сообщениями у нас есть очень распространенный паттерн сторону форвард или хопкинс полк в котором у нас есть источник сообщение есть брокер который отвечает за хранение сообщений то есть обеспечивает гарантированную доставку и есть потребители который подписан на очередь на какой-то топик по которому передаются сообщения соответственно коммуникация выглядит она следующим образом источник пишет сообщение получает подтверждение о том что оно записано брокер имеет некоторое надежное как его дисковое хранилище в котором эти сообщения лежат потребители получают сообщение по одному и также подтверждают при этом разные потребители могут находиться в разных точках этой очереди то есть кто-то уходит вперед кто то тормозит получает более старые сообщения брокер отслеживает позицию какое следующее сообщение послать для каждого из потребителей и в случае если это дергал подписка то при перед подсоединении потребителя по некоторым его идентификатор он будет продолжать ему передавать те сообщения которые он еще не успел получить такая модель позволяет строить цепочки традиционной обработки данных достаточно просто и с хорошими гарантиями то есть если допустим у нас есть компонент который должен гарантированно записать сообщение в реляционную базу данных то схема будет выглядеть следующим образом этот компонент подписывается на топик в брокере получается общения делает запись в базу данных подтверждает получение этого сообщения причем запись в базу данных и подтверждение сообщений это часть 1 распределенной транзакции то есть как правило реализации брокеров сообщения они понимают двухфазный комет могут участвовать в двухфазном к мите и у нас как по его присутствуют некоторые координатор транзакции которая все это координирует то есть благодаря двухфазном у комету мы независимо какая из частей этой системы упадет все равно можем восстановить сообщение и гарантия однократной обработки сообщения она будет строго выполнена однако двухфазный комет штука такая тяжелая и даже вот а java enterprise милях где такой паттерн является хрестоматийным далеко не всегда используется на практике есть более простая альтернатива двухфазном у комету которая позволяет обеспечить гарантированную обработку сообщений она строится на следующих принципов в в потоке сообщений сквозная нумерация то есть все сообщения нумеруются по порядку бруки охранит некоторую глубину сообщения то есть допустим сообщение за последнюю неделю и потребитель подключаясь к брокеру он может запросить сообщение с нужного ему номера если этот номер не слишком в прошлом то brokers своего хранилище перри проиграет историю и соответственно потребитель получит все сообщения которые ему нужны чем хороша эта модель тем что брокер больше не отвечает за хранение позиции чтение клиента за позицию чтения клиента отвечает сам played то есть если он пишет в базу данных и например наш процесс упал восстановился прочитал данные из базы данных нашел номер последнего сообщения которые он записал запросил следующее сообщение у брокера брокеру про него знать ничего не надо он просто хранит некоторую очередь сообщение с некоторым лимитом по времени по объему хранили но если нас волнует не только просто the system но еще и время отклика можно пойти дальше в классической модели брокер является посредником то есть отправитель передает сообщение брокеру получатель получает сообщение его брокера можно брокер или его аналог поставить сбоку это есть в этой модели у нас источник напрямую пруд кастит сообщение всем потребителям включая брокер случай если нам нужно восстановить историю то есть мы пропустили какие сообщения или у нас произошло перезапуск процесса ему надо догнать текущее состояние событий он описывает отдельный запрос аналогу брокеру в этой схеме рипа и серверу которые соответственно хранит историю сообщений на диске и может этот запрос для этого потребителя удовлетворить здесь немножко сложнее потому что то что сообщение не должно быть обработано дважды это уже задача самого потребителя но за счет того что у сообщение есть уникальный монотонно возрастающей до индификатор эту задачу решить довольно просто в целом вот такая модель управления не через двухфазной транзакции а через сквозную нумерацию она существенно упрощает построение системы и вот в области ит рейтинговых приложений является доминирующей моделью построения архитектур что такое информатику ultra mat sin gent & что этот коммерческий продукт предлагает чего не предлагают другие брокеры сообщения прежде всего он реализует оба этих принципа то есть и multicast и хранение сообщения то есть гарантированную доставку мультик показ протокол базируется на спецификации прагматик general multicast достаточно старый протокол в самом этом протоколе достаточно много дыр которые информатика закрывает своими какими-то про паразитарными решениями которые позволяют всей этой схеме работает помимо multicast и могут использоваться юге unicast tcp транспорт есть еще и писи транспорт но это для другой схемы взаимодействия но с практической точки зрения как правило используются именно и эдипе multicast который позволяет получить оба преимущество из этой схемы следующий вопрос как в этой схеме работает отказоустойчивость работает надежность те кто копался в области построения распределенных систем знакомы с алгоритмами консенсус of они могут обратить внимание что такие простые стрелочки что один этому послал тот получил все поехали дальше она достаточно слабая и да действительно как правило практические решения они имеют дырки но тут надо понимать что надежность это всегда вопрос выбора вы можете построить абсолютно надежную систему она будет слишком медленно когда мы делаем выбор между надежностью и производительностью мы опираемся на некоторые факты первый факт это то что отказывала калины и сетевой инфраструктуре они очень маловероятно потому что стива инфраструктуру вокально контролированное и на уровне самую инфраструктуру продублировано сервера ненадёжный элемент они падают более того могу могут падать с вами сервера могут подать отдельно процесса по каким-то причинам там 1 на сервере какой-нибудь процесса съел всю память и сервер завалился то есть даже не железные причины могут быть у таких боев против этого надо действительно защищаться резервный дата-центр он всегда есть но как правило используется модель холодного стенда поэтому переключение на резервный дата-центр это все равно операция не автоматическая помимо самого messenger нга надо переключить и еще много всего поэтому ожидать что это будет работать мгновенной из коробки все равно руке и даже если у нас messenger мгновенно переключится есть еще базы данных из чего другие системы которые все равно этот процесс будут тормозить поэтому торопиться тут некуда поэтому обычно используется следующий баланс между надежности производительностью используются три реплики хранилище сообщения в каждом из дата-центров и для как критерии успешного справки используется иерархический corum причем как правило иерархии иерархически это сильно сказано потому что от удаленного дата-центр подтверждению и дожидаться долго обычно полагаются на то что есть два подтверждения от хранилищ сообщение доступных на вокальном дата центре есть нюанс то что в такой модели потребитель тоже должен дожидаться кворума от двух хранилищ это делается далеко не всегда потому что иногда как бы по специфике обработки данных нет ничего страшного если мы обработаем какое-то сообщение потом окажется что она нигде не сохранилась потому что мы либо можем гарантировать что сообщение которое придет с тем же номером она будет там что такое же сообщение все равно придет может быть другим номером просто либо в принципе то ошибка которая внесет отличная обработка она не так критична она все равно будет выловлена на других уровнях и не принесет больших потерь если такой верность нет тогда на стороне получателя тоже надо использовать корм это естественно увеличивает твой пенсии между источником и потребителем механизм кворума между тремя хранилищами он позволяет нам гарантировать что в случае если в системе в каждый момент времени продолжают работать два хранилища мы гарантируем доставку сообщений то есть ничто не теряется в случае реализации ооп информатика синхронизации между хранилищем не происходит то есть если какое-то хранилище не получила копию сообщения то в его история останется дырка но поскольку мы получаем твору 2 сообщений даже если произойдет так что один из одной хронич подтвердивших поучение выйдет из строя другое хранилище не получил это сообщение все равно у нас останется минимум одно живое хранилище которая сможет это сообщение из истории восстановить несколько слов про аналоги прямых аналогов тут нет но идея с секвенированием сообщений она достаточно активно используется в частности есть два продукта от apache которые предоставляют нечто похожее а пачиков к это система обмена сообщениями она позволяет работать в двух режимах и в классическом когда брокер отслеживает сообщение которое клиента прочитал но внутри как бы механизм хранения сообщений и механизм отслеживания позиции чтение клиентов они разделены по этому вы можете при желании использовать низкий низкий уровень где происходит именно монотонное секвенирование сообщений работать через него второй проект это apache ибуки пир который реализует распределенный журнал распределена транзакционных жил но в это по сути очередь с пронумерованными сообщениями то есть разница функциональный никакой нет и в том и в другом случае у нас есть последовательность сообщений которые мы с какой-то точки из какого-то номеру последовательности имеем возможность зачитать а пачиков к достаточно активно развивается probook теперь такого сказать нельзя хотя в принципе как продукт он у нас используется в некоторых случаях как заменой информатики там где нагрузка не очень велика оба эти продукты они не используют мультикаста есть там идет коммуникации клиент брокер есть реализация пейджем в зиру и mpio но там нету инфраструктуры восстановления сообщений то есть нету компонентов которые отвечают за хранение и перри посылку сообщения что делает ее а для задачи надежного мясом дженга бесполезной а на этом заканчиваем с манджинга мы переходим к последней части этого доклада это архитектура frontend для трейдинга здесь речь пойдет не о коммерческом продукте наши внутренние разработки потому что коммерческих продуктов с нужными характер мы не нашли на какие-то такие характеристики нужны для того чтобы обеспечивать работу frontend для трейдинга 2-ого что такое фронт-энд для трейдинга как правило это тяжелая толстый клиент как правило на сишарпе само по себе в саму сам себе обмен данных трейдинге он весь построен на сообщениях есть у вас происходит торговый день у вас есть несколько подсистем которые посылают сообщение о том что сделку ушу заявка ушла сделка произведено и так далее то есть все состояние системы она летает в воздухе виде сообщений в виде went off поэтому чтобы нарисовать табличку на экране вам надо в каком-то месте зафиксировать the state of the world чтобы можно было бы в визуализировать поэтому за толстым клиентам практически всегда стоит какой-то вариант каша который слушает все эти сообщения и в памяти строят картину мира которую дальше отображает на экране при этом особенность систем такая что первых все построено на ивентах постоянно на экране все тикает двигается изменяется много источников данных причем все динамические то есть даже справочнике то что мы называем статическими данными они все равно могут меняться то что может быть ситуация что в статических данных была ошибка tanzen trade не проходит через систему человека support a побежала в базу данных из правил вот это вот исправление тут же пролетела через все системы информация обновилась трэйд пошел дальше это исправить и исправления они делаются на лету в ходе рабочего дня поэтому ожидать того что с утра загрузили данные больше они не поменялись такого не приходит помимо этого есть котировки которые сыплются с рынка есть различные системы аналитики там в том числе такие тебе которые нам постоянно какие-то будет информацию предоставляют и еще одной особенностью все это является то что основной способ представления информации это таблица то есть мы видим таблица таблица таблицы если вы посмотрите на дисках трейдера то это вот 6 мониторов забитых таблицы как-то раскрашенных в разные цвета мука и где есть графики график и тоже попадаются суть в том что как бы вот во всей этой системы таблица на входе таблицы на выходе на входе мы имеем реляционной базы данных там какие-то уже в принципе достаточно фиксированные модели которые укладываются формат таблицы а вы хотя мы тоже имеем таблицы это наталкивает на мысль а почему бы нам не использовать формализм ле ле ле цион алгебра чтобы описывать всю логику представление информации то все что нам надо сделать взять trade из одного источника с женить их с справочниками из другого источника женить x марки данными которые там текут через подписку поучить 200 колонок отобразить эти 200 колонных на экране соответственно переход к такой реляционной модели он позволяет существенно сократить необходимость написания доменных объектов они не нужны они нужны в некоторых местах там где от действительно нужно например выполнить какое-то действие то есть пава отправить заявку но для визуализации информации они не нужны и отсутствие доменных объектов она существенно упрощает жизнь то что вам нужна новая колонка которая там получается расчетам из пяти источников вы добавили эту колонку в запрос все она появилась на экране то есть у нас есть мета-данные которые позволяют исходя из фактического запроса понять как эту колонку отобразить какие действия на ней можно использовать там как какую контроль чик показать интерфейс фильтрации так далее но поскольку данные у нас динамически нам для этого нужно система которая вот на лету может делать всю эту обработку методы мир лицом на алгебры принципе есть такое понятие как как continue силён processing system которые делает почти то же самое они реагируют на ивенты они позволяют использовать революционное преобразование все здорово есть один нюанс они не достаточно динамично то есть обычно традиционной кантине своем процесс процесс и система предполагает что вы несколько запросов заранее на configure ти и вот они так и будут работать в случае тренинговая пользователям создал еще одно окошко подключил его там к такому-то источнику данных задал на нем свои нужный исключительно ему параметры фильтрации и по сути он получил новый запрос которая вот надо выполнять данные должны тикать этот этот запрос он сейчас создал руками он ожидает что данные там начнут тикать и мгновенно в традиционных цеп вот именно инициализация запроса достаточно тяжеловесно поэтому нам пришлось придумать свое решение которое является таким гибридом между классическим цепь и некоторыми элементами обычных баз данных данные все обрабатываются в памяти при этом используется арсенал подходов в типичных для комплекса when processing а то есть случая агрегации это различные алгоритмы которые позволяют агрегата считать инкрементальные поддерживается весь диапазон лицо он алгебры с другой стороны есть несколько механизмов которые позволяют решить именно бы странице инициализацию запросов первый механизм это перри использование операторов то есть нам пришел новый запрос это некоторый граф реляционных преобразования мы смотрим какие у нас реляционные преобразования уже в памяти живут и если мы видим что у нас есть какая-то часть этого графа эквивалентная она уже выдает данные то мы просто подсоединяем к уже существующему оператору вместо того чтобы инициализировать копию это помогает не только для производительности это помогает также для экономии памяти потому что памяти такая модель обработки потребляет достаточно много блюз есть механизм поисковых индексов то есть если все таки запрос новой то сначала он отрабатывается приблизительно так как он отработал супы в традиционной базе данных строится изначально снабжу потом у дальше продолжает работать уже по ивентом используя инкрементальный алгоритмы на этом а мой сборник из 3 blizz докладов закончен готов ответить на ваши вопросы"
}