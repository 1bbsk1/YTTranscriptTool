{
  "video_id": "X_v4oTxBDpg",
  "channel": "HighLoadChannel",
  "title": "Решение проблем высоконагруженной балансировки / Алексей Бурылов (Qiwi)",
  "views": 1077,
  "duration": 2091,
  "published": "2019-05-15T04:09:05-07:00",
  "text": "здравствуйте меня зовут алексей бурлоф я более 6 лет работы в компании киви и сегодня я расскажу с какими проблемами балансировки стал для волос наша компания но некоторые из них конечно и варианты возможны их решения сначала я кратко расскажу о нашей инфраструктуре у нас около 2200 20 миллионов активных кошельков у нас тысячи партнеров у нас порядка 100 тысяч терминалов сожалению данные я искал в интернете поскольку приватные данные компании разглашать не могу но порядка 100 тысяч у нас точно есть терминал и очень плохие клиенты в том смысле что многие из них подключены через gsm сеть то есть они могут отвалиться на длительное время а потом все одновременно выйти в сеть и поэтому балансировку у нас испытывает очень сильные пиковые нагрузки и с ней было очень много проблем все это подключено двум крупным процессингом и около 500 микро сервисов между которыми тоже осуществляется соответственно балансировка в общем у нас true структура достаточно сложная я начну с самого простого алгоритма балансировки он самый популярный он очень простой он очень скоростной это round robin суть его проста мы по очереди отправляем запрос и на каждую из нот в нашем списке но там просто по очереди это очень просто надежно у него есть один недостаток этот алгоритм не работает на практике проблема в чем мы ожидаем что у нас будет как то так то есть есть балансировщик он равномерно раскидывает задачи по нашим сервисом какой там запущенный на гипервизорах каберне tissot но к сожалению в реальности дело обстоит примерно так нагрузка на гипервизор и сервисы каберне this и так далее крайне неравномерно и в связи с этим когда проходит какой-нибудь пик нагрузки у нас у нас может накапливаться большая очередь запросов это очень печально мы шкиве длительное время просто у нас была практика нагрузка на но да не больше 50 процентов от ее производительности но это тоже не проходит поскольку терминала создавали пики нагрузки выходом из этой ситуации мы применили алгоритм лес connection это очень клево алгоритм суть в чем балансировщик ищет сервис на какой сейчас открыто меньше всего ктп соединений когда клиент посылает новый клиент посылает соединение на балансировщик он его туда отправляет этот алгоритм работал совершенно замечательно он полностью решил проблему с пиками нагрузки но у него выяснилось еще один факап при падении одной ноты одной ноты из всего нашего кластера у нас внезапно отвалились почти все клиенты 90 процентов запросов обрабатывалась некорректно проблем было элементарно и совершенно балансировщик посылает запрос на этот сервис сервер ему возвращал это tb-500 них это та 500 он возвращал нашу внутреннюю ошибку нас достаточно плохой был протокол раньше к сожалению и он велик и возвращал ошибка мгновенно блендер отвечал клиенту когда приходил следующих лет балансер смотрел что на этот сервер не тут подключений он отправлял запрос туда естественно тоже не получал ответ а 90 процентов клиентов получали ошибку при отказе всего 1 но до из кластера соответственно лес connection может работать только с очень хорошим циркус брекером другим способом решения проблемы нашей с таким неравномерным распределением является весовая балансировка это тот же round robin но балансировщик распределяет задачи неравномерно она какие-то но до отправляют больше на какие-то меньше к сожалению этот способ тоже не работает по той простой причине что никто не будет настраивать динамические по мере создания удаления новых там виртуалок нотки верните с и так далее простите у меня тут странные сообщения но нотка вернитесь и так далее эти параметры существует единственное ну две возможности мы можем отслеживать пропорционально нагрузке на сервер то есть балансировщик может как-то ходить на серваке мониторить загрузку степи и соответствии с ней выставлять этих коэффициенты второй способ это мы можем отслеживать сколько времени занимает выполнение среднего запроса если все запросы у нас системе более-менее одинаковые то тоже хороший способ если надо сильно загружен на время обработки запросов на ней вырасти к сожалению это но этот подход называется перерегулирование то есть мы пропорционально дифференциально то есть следим за той с каким скоростью это изменяется и интегрирующей регулятор мы смотрим за длительный интервал и соответствии с этим определяем балансировку к сожалению этот способ тоже плохо работает поскольку на рацион ность вычислительных систем крайне мало поэтому даже в идеальные ситуации работа пид-регулятора выглядят вот так поскольку коэффициенты подобрать корректно ли пид-регулятор практически нереально они изменяются на лету и все они очень-очень ну очень баллы и очень велики соответственны зависимости от расположения в реальности мы от моделирования дает вот такую картину то есть очень резко и пике потому что стоит чуть превысить нагрузку на сервер у него сразу растет время отклика но поскольку загрузка секу так далее поскольку сервер сразу уходит перегрузку у него накапливается очередь и идут такие автоколебания как видите это от единицы до нуля то есть нагрузка на сервер подскакивает до 50 процентов на реальной с реальной ноды снятые вот показания выглядит вот так то есть у нас на реальной ноги следствие вот этих колебаний нагрузка подскакивала до 0 7 единиц то есть до семидесяти процентов это тоже очень печально ну это как-то работает так как подход то есть он стабилен следующая типовая проблема балансировки это слишком большие пулы программисты привыкли что чем больше цепью чем больше памяти чем больше жесткого диска тем лучше работает приложение когда программист настраивает балансировку какие титулы и так далее он в первую очередь добавляет всего побольше то есть побольше connect of play к сожалению это тоже это неправильно совершенно подход с точки зрения плов наоборот надо стараться добавлять как можно меньше рассмотрим такой пример то есть у нас классическая входная какая-то очереди есть и задачи из нее распределяются от клиентов по двум потоком от первого клиента там ушла в поток один от 2 в поток 2 и что-то у нас в этот момент произошло систему поступило там у нас пришло много запросов поскольку чуть большая не все встали в очередь естественно балансировщик все эти запросы раскидал вы учились они там обрабатываются ну клиенту у клиентов есть такое понятие как тайма ты через некоторое время когда наша очередь очень длинное будет обрабатывать свою одного из клиентов произойдет time at что сделает при этом клиент конечно за пошлет запрос повторно предложение не знает что клиент уже отсоединился и послал запрос повторно он он она закончит обработку первого запроса попытается вернуть его там клиенту но это невозможно connect до клиента закрыт приложение возьмет следующие запросы из очереди у этих коней клиентов тоже сработает time at поскольку и у всех у них она примерно одинаковый и мы окажемся ситуации lifelog то есть приложение работает она обрабатывает запросы но ничего не проводится никаких эффектов для пользователей сервиса на выбор это очень печальная ситуация мы скидки веток легли на 3 кажется часа и не в больше не могли не как подняться у нас ситуация еще усугубилась тем что у нас цепочки ни один запрос о несколько запросов и если любой из них отвалился по таймауту приложение начинала цепочку сначала это очень печально это вообще прямо паника паника и это разваливается только хороший настройкой в данном случае нам надо уменьшить очередь запросов банально и когда нам придет эта вспышка да мы части клиентов ответим сервису на выебал но мы их физически уже не могли а служить поскольку у них выйдет тайм-аут банально поэтому лучше сразу вернуть сервисом на вы обл и когда у нас появятся ресурсы мы все-таки обработаем пусть некоторое время сервис будет недоступен но хотя бы он поднимется в случае когда у нас несколько запросов цепочки надо ограничивать входной поток именно для первого запроса как же подобрать этот размер пул потоков пула коннектор так далее то есть у нас пул потоков вулкан актов и так далее он с чисто математической точки зрения должен быть равен числу себе он ядерно сервере то есть если у нас на сервере два ядра то мы должны выделить всего два потока но тут все несколько более сложен но поскольку большинство наших сервисов она имеет синхронных характер когда эти токи вызывают другой сервер с они блокируются на нем то есть потоки у нас есть аэдра ничего не делают поскольку они ждут другого сервиса соответственно мы должны просто пропорционально добавить число потоков в реальная структура очень сложно у нас много разных сервисов которые взаимодействуют между собой поэтому строгий математический подход на самом деле не очень работает можно просто посмотреть сколько у нас используется обычно и добавить 20 процентов на всякие пике очень распространенной проблемой балансировки является каскадной блокировка как я уже говорил в большинство сервисов в мире синхронные то есть мы вызываем сервиса ждем от него ответа поток на этом блокируется в киеве работает с большим количеством поставщиков услуг то есть это внешние по отношению к нам сервисы которые работают очень но не очень плохо но поскольку их много мы время от времени хотите из них обязательно падают начинает тормозить когда у нас приходит запрос processing и посылает его его потоки блокируется на этом поставщики услуг и ждут от него ответа но поставщик услуг лежит и не может дать ответ в разумное время то есть потоки вернуться по connection таймауту все потоки процессинга платежей оказываются заблокированы на таком сервисе соответственно процессинг платежей лежит веб-сайт начинает вызывать процессинг платежей поскольку все потоки его заблокированы он не может принимать входящие запросы тоже ложится это очень печальная ситуация поэтому в любой сложной системе в которой есть micro сервисы обязательно должен присутствовать некий циркус брекер который отследи такие сервисы которые упали в данный момент и если они не ходить критичны то она просто отключит ну ничего не сделаешь если сервис удержит мы его просто должны отключить тогда система будет работать совершенно корректно проблема циркус брекера в том что они тоже не работают и они могут совершенно исправный сервисных по тем или иным причинам отключать к сожалению хорошую балансировку создать практически невозможно еще серьезные наши проблемы являются накладные расходы то есть реальность так компания киви выглядит как то так и у нас куча микро сервисов которые вызывают друг друга у нас очень сложный процесс обработки запроса поскольку это платеж он должен совершить много разных стадий на разных сервисах и проблема в том что если мы используем в дтп то это подойдет если мы используем стандартную связку наши компании джей ти плюс прыг около 600 рпс когда мы делаем это для когда мы делаем это для для внешних запросов которых сравнительно мало по количеству это еще ничего но поскольку у нас достаточно много микро сервисов и когда мы переходили на архитектура микро сервисов была оценка дана что у нас будет в одной вызове участвовать 1020 микро сервисов 600 рпс значит надо делить на 10 20 фактически у нас половина всей инфраструктуры обслуживала бы только протоколах это т.п. то есть чистая реализацию детализацию за вопросиков джейсон или там xml дополнительной проблемой что латентность всего это процесс составляет около четырех миллисекунд я в мерил не знаю почему так получилось по логике должно быть 2 но измерение показывали 4 если у нас будет хотя бы 10 микро сервисов это уже 40 миллисекунд а-20 например у нас уже есть стеки с таким количеством вызову это 80 милисекунд то есть фактически половина времени обработки запроса еще недостатком что для had a top of blue приходится создавать api для каждого языка мы в связи с этим использовали бинарный протокол 3вт бинарный протокол имеет гораздо лучшие показатели то есть восемь тысяч fps на ядро латентность 1 10 миллисекунд или даже меньше он автоматически генерирует топить то есть мы на его языке пишем api а потом может генерировать его для любого языка и он будет из коробки это очень удобно mouth риф то есть свои недостатки связи с тем что он бинарный протокол и когда мы выбирали выяснилось что утрехта нет хорошего балансировщика странно другой серьезной проблемой является нет хорошего балансировщика связи с этим компания киви разработала свой балансировщик 3 вп ул и 3 full она содержит все методы балансировки то есть это робин вещь визит балансировщик носков со встроенным режимом киркук брекер киви выложил его в конкурс вы можете скачать и использовать его для своих микро сервисов это серьезно облегчит вам написание микро сервисных и рыцарь архитектур а важным вопросом балансировки является сервис discovery то есть мы использовали хотя внешне вопи у меня слайд перепутался простите и для внутреннего про портал внутри сервисное общения 3 вп ул наш 3 вп у можно скачать вот по этому адресу гид хоп киви . 3 вп ул кому интересно он будет на заключительном слайде можете сейчас не спешить важным аспектом балансировки является сервис discovery то есть если у нас действительно высоконагруженные положи приложение что собственно highload у нас то у нас число нот в любом кластере достаточно высоко то есть не менее трех-четырех и соответственно эти ноты часто уходят на обслуживание на какие-то работы добавляются новые ноты удаляются старые и каждый раз обновлять список серверов на всех но до которые используют этот сервис это просто нереально поэтому нам нужен какой-то третий сервис на которой ноты будут сообщать где они есть и соответственно балансировщик смотрит на этот сервис discovery и получает оттуда новую моду и может отправлять на нее запросы если мы говорим о высоконагруженные балансировки то это в первую очередь балансировка по ключу то есть банальный sharding это хорошо всем известный механизм надеюсь на холоде используется балансировка прикручу приколю при кэширование она удобна при rolling релиз когда мы можем выкатить только для некоторых клиентов нашу новую версию они будут себу этих все запросы этих клиентов будут балансира ваться по ключу на одно и то же но ду и соответственно клиент будет уже видеть новую версию sharding обычно работает так сервис называет некий балансер балансер если мы говорим о холдинге обычно встроен внутри кода сервиса и он соответственно пойдешь нику клиента вызывая выбирает базу данных ну например для классических серверов мам кэш то есть сервис ходит в базу данных получает какие-то данные потом сохраняет их мам кэш там полку ли чон а выбирается хорошая но до балансер строим прямо в клиенту в каша это все работает хорошо ключевым недостатком такого подхода является то что у нас работа с моим корешом встроена прямо в бизнес-логику это крайне неудобно но не некоторых видов приложения с этим надо жить мы можем все приложение полностью балансировать по ключу тогда прямо запросы клиентов отправляются на балансир берется там хэш от айтишника клиента поэтому хочу находится сервис проблемы такого подхода является то что если у нас какая-то но до упадет то куда отправятся наши запросы если мы используем какую примитивную балансировку то у нас если но запросы отправиться на один сервис он естественно упадет на него нагрузка резко выросло вдвое мы можем делить этот хэш по остатку и выбирать ноду зеленом помечены диапазон их и шейка коры при таком подходе изменится то есть как мы видим при исключении одной ноты с балансировки у нас изменились почти все уши это соответственно неприемлемо для решения такой проблемы используется балансировка под так называемого алгоритму консистенции хеш кратко объясню его мы берем отрезок на числовой прямой но я условно взял от 0 до 256 и обычно используют 128 бит кашель 64 бита мы берем этот отрезок числовой прямой замыкаем в кольцо на этом отрезке сохранилась вот меточка потом берем ноды и призываем к каждую ноту к определенному участку этого кольца числовой прямой когда у нас приходит запрос мы вычисляем его хэш вот он какой то получился мы берем следующую ноту в кольце и отправляем запрос и на неё недостаток такого линейного подхода в том что если надо упадет то все запросы пойдут на следующую ноту у нас на надо опять придёт удвоенная нагрузка чтобы решить эту проблему мы берем и в кольцо добавляем ноду множество раз поскольку у нас электронно вычислительная система он может добавлять но ты очень много раз никаких проблем это не вызывает при падении ноды соответственно уже происходит перебалансировка всех ее диапазонов на другие ноды но как мы видим на одно надо уже пришлось всего две трети запросов она оставшуюся одна треть чем больше раз мы добавляем кольцо ноды тем равномернее выходит распределение при 250 6 там например родах она в районе процента получается что вполне устраивает что-то я быстро заключение любая балансировкой имеет скрытые проблемы больше не значит лучше то есть если вы поставите больше но там больше обул и особенно пулы это вообще критично притом важны не только входящие и исходящие пулы то есть основное именно накопление вот эти очереди это исходящую пулу подключений ваших если вы их поставите большими у вас может упасть циркус брекер он у вас должен быть должен работать поскольку без иркут брекер и вы можете на самых неожиданных местах падать и ни в коем случае не пишите балансировку самостоятельно возьмите готовый там f5 какой и джинс мы сейчас вот используем или можете взять наш 3 full в нем все основные проблемы балансировки исключены всем спасибо с вами был алексей бурулов наш 3 вп а можно скачать вот по этому адресу кому интересно можете задавать вопросы добрый день илья банк x правильно понимаю если у вас все пришли на дно году она упала у вас это стоит сессии не сохраняется и когда клиент нужно это в печи он в это состояние не попадет до счастья сохраняется на клиенте у нас основная часть сервисов имеют рост то есть они не хранят собственный state state сохраняется на клиенте некоторые данные анти фикации а так далее клиента сохраняются с централизованным каши то есть используется как без а вот тут то что вы рассказывали это имеет отношение к липким сессиям когда на носу залипает конкретный клиент или это немного другое липкий сессии частный случай балансировки по ключу когда в качестве включая используется техник сесть и собственно или айпишник или же что то такое у нас насколько знаю кто ты такой используется вот еще вопросу я увидел вы сказали упоминали про синхронное а я вот и увидел на картинке вы используете но джейсон как не блокирующие осинкой о ну то есть как бы вы его используете он как бы она она у нас есть взяла сервиса голова куда-то насколько я знаю в них достаточно активно и синхронные вызовы используется но новыми не везде используете нет у нас основной стек это java + spring но у нас есть например полностью асинхронный овен driven сервисы на скалы там соответственно все овощи асинхронно у нас есть асинхронные базы данных например кассандра там тоже мы в синхронной манере с ними работаем вот просто почему бы например всю сервисную архитектуру на асинхронный построить ну грубо говоря некоторая шина типа нация или еще чего-то где будут ну собственно там асинхронный долги вызов и он к через сколько травлению обрабатывается в то же время клиент может получить ну понимаете ночами то есть синхронность хочет поток асинхронность его как бы не хочет на самом деле но с точки зрения вычислительной нагрузки и синхронный и асинхронный способ выполнения они примерно одинаковые синхронные даже больше нагружают систему асинхронный эффективен с точки зрения того что он позволяет снизить латентность то есть мы можем асинхронно послать вызовы сразу на несколько разных сервисов а потом собрать их результат одновременно то есть они будут работать параллельно поэтому асинхронность это не про увеличить увеличения пропускной способности то при снижении латентности в первую очередь то есть нужно гармонично как бы использовать этот этот подход до синхронный код банально проще писать поэтому лучше писать синхронный код если есть такая возможность спасибо насте спасибо за доклад посмотрите налево собственно я хотел спросить про то же самое то есть у меня возник вопрос про асинхронность закономерный вы уже все описали мне интересно ну понятно что синхронность писать проще какой процент кода у вас теперь синхронно и асинхронно используется и где васин хронику применяете больше ну трудно так сразу оценить у нас где-то 95 процентов куда наверное синхронные и только 5 синхронный и асинхронный код это всякие в первую очередь алгоритма балансировки у нас есть отдельные сервисы вы синхронной манере у нас асинхронные очереди используется для оповещений то есть ну есть часть кода синхронного но это не очень большая часть асинхронного кода не используете каких-нибудь вот типа рапирой бита что-нибудь или кафки для обмена всем этим где мы используем буковку для обмена сообщениями вот васин хроники именно да да именно васин хроники спасибо большое здравствуйте я справа от вас справа тут если раз ты меня два вопроса первый вопрос я так понял что у вас индексы и как вы на них и реализовали сервис discovery не были там с ним какие-то проблемы используем в качестве сервис discovery концу консул достаточно хороший сервис discovery то есть это автономная апликационная система у него и много достоинств то есть в случае развала основного кластера консула его отдельные ноты продолжит функционировать то есть сохраняет кашированные состоянии сервис discovery очень надежная система сама по себе архитектурно спасибо и второй вопрос такой такой синхронной моделей pipe лайнинга обработки запроса когда у вас много серверов подряд идущих очень важно иметь какие-то ограничения то есть вот вы рассказали про дно ограничения на балансировщик и что у вас там очередь она как-то зажата а какие еще и используя еще какие-то ограничителей во всем этом процессе какие может быть такой вопрос от вы ограничиваете очередь нам балансировки а дальше где то есть какие то еще ограничения там зажимаете среды еще чего-то но большинство программистов полагаются на дефолтные настройки нашего 3 пула которые достаточно строгие и в тупую режут все что подозрительно это достаточно хороший подход по факту пробоя в балансировке по 3 полу у нас за два года его эксплуатации не было насколько знаю мы ловили глюк внутри самого 300 правда но пробой в балансировке не было это хорошая модель в engine насколько я знаю у нас сейчас ограничением нормальных нету но местами что-то мы там пытались сделать ну я не совсем знаю как это у нас компании очень большая у нас 250 программистов что ли работает я не могу уследить за всем что у нас происходит физически ну то есть я про не понимаешь что главное ограничители это вот это взаимодействие между сервисами то есть вот допрос главное 9 лет а именно между сервисами вызовы к пулу коннекта в базу в connect и в бат до базы это тоже рпц вызовы там тоже может происходить накоплению очередь запросов в частности вот в процессинге терминалов но очень сильно ограничен именно полых коннектов до базы это очень стабилизировала его работу в пиковых нагрузках спасибо мирасти да простим спасибо за доклад чем осуществляется доставка приложений продакшн и по стретчингу а также чем в джетте стоит самих серверов и конфигурацию балансиру а у нас используется два подхода в данный момент старый подход основан на виртуальных машинах виртуальной машины там стоит тебя и классическим deviant пакетом у нас разработана система континиус integrations которое позволяет графическим способом устанавливать пакеты с новыми версиями приложений и более продвинутую сейчас систему активно внедряем на основе кубер не тесс то есть обернитесь эта в разворачиваются под и то есть фактически докер контейнеры а по серверам конфигурацию по серверам и раскатываем конфигурацию по пятам ну пока верните су особой раскатка конфигурации не требуется нападение александра гасс там нефть у вас сам будет балансировщик он за балансировать то есть если подохнет сама машина с балансировщика а мы центральные балансировщик и естественно катетер пышной входные они за балансировали на сколько я знаю а внутри сервисная балансировка у нас используется три в пул который является build им балансировщик омон находится прямо внутри коде приложение это клиент сайт балансировка то есть внутри каждого было приложение работает естественно свой полностью независимый автономный балансировщик это естественно сильно повышает надежность системы еще есть рекомендованный подход ставить рядом с каждым приложением приложения балансировщик так работает например консул но мы решили что это несколько избыточно ну перри усложненная структура получается спасибо спасибо за доклад у меня такой вопрос вы упомянули circuit breaker вы его в итоге используйте и как он у вас работает есть работает на уровне джинсы у нас используется отслеживание их это тпк тов ошибок то есть это сервис возвращает к ттп коды ошибок и хотя tb-500 какие-либо тон циркус брейки отца а на уровне 3 в пула используется отслеживание бросаем их сервисом action of this a service начал бросать какие-то недокументированных экшена рвать connect и и так далее то он тоже церковь brackets а также у нас на уровне этот и балансировщик 3 пула используется циркус breaker по среднему времени выполнения запроса если запрос выполняется слишком длительное время сервис начинает тормозить чтобы избежать каскадного падения следствие блокировки потоков описанного мной мы осуществляем тоже циркуль breaking такого сервиса а возвращаете ноду при каких условиях обратно а я точно не помню как происходит возвращение в риджентс в 3 пули у нас происходит сначала несколько пробных запросов балансируется на эту ноту если надо корректных обрабатывает сначала включается на минимальную нагрузку а потом под регулятором нагрузка стабилизируется да ну распределение всего кластера в течение где-то двух трех часов это позволяет осуществлять плавный старт нос то есть нагрузка растет плавно чтобы предотвратить каскадное падение not следствие пика нагрузки спасибо здравствуйте собственно такой вопрос вы говорили про консулу cabernet почему в купюрницы вы не используйте нативные средства сервиз discovery и если у вас есть консул почему вы не взяли инструмент такой как нам от к сожалению нам от я не совсем знаю что это такое консул скин нативный сервис discovery скажем так нам не удалось его хорошо крутится нашим приложением были какие-то значительные проблемы к сожалению этим занимался не я не я не могу точно ответить какие но были реально проблемы с получением списка входов корректного и его корректной обработки кроме того консулу работает гораздо стабильнее чем встроенный каберне тиски сервис discovery соответственно это просто очень надежная схема понял спасибо"
}