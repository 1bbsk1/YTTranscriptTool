{
  "video_id": "RxWVxr4uUpI",
  "channel": "HighLoadChannel",
  "title": "Хьюстон, у нас проблема. Дизайн систем на отказ / Василий Пантюхин (Amazon Web Services)",
  "views": 8605,
  "duration": 2973,
  "published": "2020-02-26T12:03:11-08:00",
  "text": "естественным свойствам окружающего нас мира является неизбежная деградация вообще всего то есть мы стареем код сбоит компьютеры ломается и даже казалось бы ну наверное самые надежные системы которые мы например запускаем в космос это периодически ломается в семидесятом году американские инженеры запустили очередной аппарат аполлон 13 клуни и казалось бы они все уже там предусмотрели там было целых три батарея топливных элементов и никто даже не мог предположить что в результате взрыва кислородного баллона две из них выйдут устроен на самом деле я думаю что многие из вас знают историю они вернулись домой все было хорошо про это даже сняли художественный фильм с томом хэнксом в главной роли но фраза хьюстон у нас проблемы вошла в историю 1939 году на одной из баз ввс в калифорнии проводили расследование аварии самолетов и одним из инженером которые этим занимался был майор эдвард мёрфи и он характеризуя работу местных техников сказал если существует два способа сделать что-то и один из этих способов ведет катастрофе то почему-то всегда выбирает именно этот способ позже эта фраза там под пером писателя артура плохо вошла в историю как законы мёрфи ну а по-русски это называется законы подлости то есть у нас получается какая ситуация нам никак не избежать каких-то поломок человеческих ошибок закона в подлости и нам как-то с этим надо жить и именно поэтому когда мы проектируем свои системы мы изначально закладываем в эти системы свойства того что отдельные компоненты этих систем будут ломаться постоянно и этого никак не избежать какие характеристики мы пытаемся улучшить как-то изменить когда мы говорим о дизайне на отказ design for ever ну естественно это доступность те самые девятки это надежность то есть свойство системы предоставлять необходимый уровень сервиса и это отказоустойчивость то есть свойства системы препятствует возникновению каких-то проблем либо быстро после них восстанавливаться есть еще один момент когда мы говорим про отказоустойчивость и надежность надежность еще и должна обладать свойством то что по-английски называется но он announce то есть известные и неизвестные мы защищаем себя от тех проблем и которых знаем но не знаем когда они произойдут а в отказоустойчивость еще добавляется штука которая называется она un an ounce это проблемой сюрпризы о которых мы вообще ничего не знаем вы скажете василия как можно не знать о проблемах которые могут возникать да запросто особенно в облаке потому что очень многие проблемы они являются эффектом масштаба то есть система разрастается до такого размера когда начинает проявляться очень удивительные эффекты которые мы вообще не ожидаем никогда и отсюда получается очень много проблем неожиданных вообще для всех когда мы говорим о сбое сбой обычно это вещь не бинарная у сбой есть никаких уровень деградации сервисы либо радиус поражения сами ли радиус поражения он какой-то такую военный термин мне честно говоря не очень нравится поэтому я буду использовать некрас уже устоявшийся в кругах термин blast radius то есть наша задача уменьшать blast radius наших систем правильно и ещё одна вещь если мы честно признаемся себе что проблем не избежать то мы должны к этим проблемам превентивно готовится то есть мы должны проактивно что то делать то есть мы должны сделать наши сервисы делать таким образом чтобы в случае возникновения проблем и они обязательно будут мы контролировали эти проблемы они наоборот когда мы просто реагируем на проблемой и уже проблема контролирует нас и вот как раз сегодня я буду рассказывать о восьми паттернах который мы используем в облаке это был с именно при помощи которых мы пытаемся контролировать проблемы которые у нас возникает у каждого из нас есть дома электроника которая управляется с пульта судака пульт пульт по сути своей это пользовательский интерфейс сущности который называется control plain control play on я думаю все знают используются для управления либо настройки наших сервисов ну-ка любых сервисов да ну а да это play на то что непосредственно выполняет функцию ради которого сервис создаете то есть control plain это часть control a plain и это пульт ну а телевизор которым вы управляете экран вернее то вы телевизор и today the plain естественно в облаке мы стараемся у себя разделять эти две функции с точки зрения тестирования с точки зрения разработки и так далее есть очень важный момент который для вас как для потребителю облака он скрыт control plain чаще всего это очень сложная штука эта сложность вы ее не видите но на самом деле там за сцены крутятся очень много чего и ошибки в проектировании control play на ошибки в реализации какие-то баги являются наиболее частыми причинами действительному массовых очень серьезных сбоев и именно поэтому сегодня я буду как расфокусировать вот мои советы которых я буду говорить они будут сфокусированы на control plain и иногда я буду говорить об этом явно иногда как-то неявно подразумевать ну вот мы сегодня больше про control play давайте-ка конкретики и хочу я вам рассказать об одной неприятности которая случилась у нас в июле двенадцатого года в северной вирджинии был очень сильный шторм и несмотря на то что естественно защита дизель-генераторы все дела но так получилось что один из дата-центров одной из его любили сезон региона северной вирджинии пропало питание соответственно нужно было как-то реагировать мы питание быстренько восстановили там минут 20 это заняло все таки но как бы то ни было но мы столкнулись с массой проблем восстановление сервисов им некоторые сервисы мы к сожалению восстанавливали целых несколько часов здесь я расскажу в чем была причина на примере а сервиса очень простого сервиса это первый балансировщик который мы сделали это 7б классе колода winter suit очень простая у нас есть каждый вал ability зоне по instance у балансировщика который торчит наружу и бишь никами но и для нас эти а печники нарисованных запросы от клиентов отдает если у нас происходит сбой одного из инстансов ну есть специальная база куда попадает event о том что произошел сбой и соответственно как реакция на этот ивент запускается специальные процедуры на самом деле все что я говорю это вот было в прошлом многие вещи они уже сейчас мне так до запускается процедуры в частности вычеркивания записи из dns а запуска нового инстанса и его он айпишник обратно в dns вставляется ну казалось бы ну чего тут все просто ломать здесь ничего но когда у вас происходит действительно массовый сбой когда у вас сломается одновременно тысячи инстансов происходит следующее во-первых вы получаете огромный backlog вашим мы получаем огромный boklok в базе данных более того control plain эта система распределенная и она так быть не должно но так случилось мы получили дубликаты то есть у нас эти тысячи ивентов разбухли вообще до сотен тысяч ивентов с этим стало очень тяжело работать еще один момент когда у нас происходит сбой в на одном из инстансов весь трафик практически мгновенно переключается на выживший instance то есть трафик удваивается и естественная реакция этого инстанса какая от масштабируется начинается масштабирование это занимает достаточно много времени а еще это приводит к нехватке ресурсов потому что этапе кого вдруг им одновременно начинается массивно все захотели от масштабируются и начинается доказал ресурсы и так далее в общем ничего хорошего в этом не было и автоматика не справилась вот именно с таким массовым сбоем поэтому наши инженеры вручную ну-ка скриптами понятно ну прям пришлось восстанавливать эти системы разбор полетов ребята так не годится так бывает очень редко но так не годится нужно переделывать соответственно стали задавать вопросы что мы должны изменить в нашей системе и 1 за вопросов которые задали это как нам случае возникновения сбоя и восстановление после него уменьшить количество пользователей которые затронуты этим сбоем либо по другому даже так как сделать так чтобы пользователи которые понятия не имеют что сбой произошел что что-то было вот они не знали что сбу и дальше живут счастливо здесь я расскажу вам первым паттерне который называется изоляция и регулирование смотрите обратно к нашей картинки огромный у нас backlog но этот backlog туда попадает не только ивенты о сбое но дальше попадает многие другие венты например ивенты о масштабировании ивенты о том когда кто-то попросил себе новый балансировщик создается и так далее так далее эти и ленты мы изолируем друг от друга группируем их особым образом отдельная будет группы например ивентов восстановления после сбоя отдельно например то же самое запуск нового балансировщика смотрите какая ситуация у нас есть 10 предположим пользователей которые почувствовали что что то не так да у них одна одна из ног например балансировщика упала естественно сервис ира как-то работают но они почувствовали у нас есть 10 расстроенных пользователей и у нас есть 11 лишь который ничего не знает о сбое он просто хочет себя новый балансировщик и если мы его запрос на создание балансировщика просто поставим вниз очереди то скорее всего он не дождется своего времени то все развалится по тайм аут и пока все другие ивенты например элементы восстановления после сбоя наконец-то завершатся что мы должны сделать мы должны приоритизировать некоторые ивенты поставив их наверх от этой очереди то есть некоторые запросы например запросы от людей которые ничего не знает об этом сбоя мы должны приоритизировать тем самым сократив количество пользователей которые вообще узнает о том что что то произошло следующий вопрос как сделать так чтобы наш control plain был предсказуем и стабилен здесь я расскажу о следующем поттер нет номер два который называется констант word постоянная работа обратно к нашей картинке у нас происходит сбой event реакция на этот ивент определенные процедуры в частности работы с денисом это огромные пиковые нагрузки случаи массовых сбоев как на control plain так и на другие сервисы на dns можно ли этого избежать когда у вас вдруг все нормально нормально а потом как надо много много работы сделать можно и мы используем подход который называется постоянно работаем например dns можно сделать чуть умнее и он будет просто постоянных в чекать наши ноты балансировщика живой не живой а результатом будет каждый раз я упрощаю bitmap живое instant единичка неживая нолик и тогда у нас получается что независимо от того наша система восстанавливается после мас-о сбоя или работает штатном режиме у нас dns всегда делает регулярно проверяя хавчик энгри раз там 10 секунд 30 секунд там зависимости до делает всегда одну и ту же работу никаких пиков всегда предсказуемо и стабильно другой пример тоже такой вы рождены упрощенный мы хотим поменять конфигурацию на большом флоте инстансов флот в нашей терминологии то просто много каких-то виртуалок которые чем-то занимается да мы кладем конфигурационные файлы в пакет и потом делаем две вещи мы например каждые 10 секунд просто пушим всю эту конфигурацию на на наши на наш флот на наши инстанции мы бат два важных момента мы это делаем регулярные никогда это регулярность не нарушаем не быстрее немедленно раз десять секунд и второе мы пушем всегда всю конфигурацию не дельту которая поменял потому что может дельта больше быть меньше быть а всю конфигурацию независимо от того изменилась она или нет ну а соответственно да это планшете ноды они уже при не сами принимают решение что с этим делать вот вы скажете но если вы какую-то работу делаем постоянно означает ли это что мы должны за это больше заплатить ну разумный вопрос да означает только если прикинуть сколько вот такой подход будет стоить то мы увидим что например 100 not каждую секунду запрашивают конфигурацию это увеличит стоимость но это такая понятно что приблизительно но это где-то будет 1200 долларов в год 100 not каждую секунду в год это принципиально больше чем зарплата разработчика который будет вам пилить стабильную работу control plain а вот с дельтами с вот со всякими такой реакции с классической не который не используется констант вор так что это разумно еще один момент если мы каждые 10 секунд меняем конфигурацию это означает что наша конфигурация меняется медленно оно поменяется только через 10 секунд верно-верно плохо это ну здесь два момента 1 во первых в во многих случаях чтобы само изменение конфигурации или например запуск каких-то сервисов нужны под этим он занимает минуты десять секунд ничего не сделает погоды а второй момент действительно существуют сервисы где это очень важно например ли писин записи конфигурация должна меняться мгновенно что это значит это значит что это potter то просто не применим это паттерн и это не какое-то там мудрость которую надо применять везде паттерн и где-то применяется где-то не применяется опять же вам рекомендую это делать осмысленным что нам делать с масштабированием как его контролировать и здесь я расскажу о следующем паттерне который очень простой когда называется предварительное масштабирование приемки с кейлин в чем здесь суть помните у нас сбой на инстансе 2 выживший in сразу получает удвоение нагрузки и начинает масштабируются сразу этого много получается нехватка ресурсов но не круто что мы можем сделать самое простое потому что берутся заранее в случае если это 2 в label эти зоны то от масштабируется при утилизации меньше 50 процентов и соответственно если у нас происходит сбой нас уже надо уже готовы принять удвоенный трафик ну окей это работает но опять же вопрос василий это что получается у нас наша конфигурация вообще не до утилизировано стоит мы раньше при 80 процентов масштабировались а сейчас ты нам 45 предлагаешь то есть мы просто я вам большую часть времени так ли это да это так совершенно верно мы простоим и немножко наша конфигурация с этой точки зрения становится дороже но поверьте мне мы очень активно используем этот паттерн потому что относимся к нему как страховки за страховку да действительно приходится платить но зато когда у тебя случается что-то действительно серьезная неприятность какая то а тот как бы benefit который она вам приносит он покрывает все расходы поэтому мы сознательно идем на эту но конечно вам если вы решите использовать вам нужно тоже сесть и посчитать риски и сколько вы должны за это заплатить как нам уменьшать blast radius как нам изолировать нашим сбоем здесь я вам расскажу про бешено популярный он используется очень очень много где в облаке это был с подходе который называется ячеистой архитектура смотрите и существуют два по сути основных способа строить сервис и масштабировать их существует некий монолит до которой вы просто накладываете накладываете накладываете ресурсы когда нужно они пухнут и здесь мы очень быстро сталкиваемся с кучей проблем во первых мы упираемся в разные элементы во вторых мы через какое-то время из зоны линейности важных нас нам характеристик выходим сначала вне линии собачьим потом вообще в насыщении в полку можем уйти blast radius нашей такой системы это вся система целиком и еще один момент как может быть даже самый важный когда мы говорим о действительно крупных системах ну например и вы убили сезона и ws да это много дата-центров а нам просто не протестируете и да еще это дорого это там нужно нагрузку как-то создать который будет похожим на настоящем и того раз мы не можем полноценно тестирует такие системы у нас повышается вероятность века на возникновение проблем сюрпризов то о чем я говорил anon анонс не надо этого нам поэтому в большинстве случаев мы используем конфигурацию в которой наша система состоит из ячеек фиксированного размера и масштабируемые тоже добавляете чеки тем самым мы лучше масштабируемся потому что внутри ячейки нужные нам характеристики а нелинейные мы получаем blast radius нашей системы один или несколько всего лишь ячеек и мы ее можем тестировать полноценно что соответственно понижает многие риски и это мне напоминает подход который используется в современном судостроением уже на самом деле более ста лет он используется у вас есть корпус корабля судно вы ставите перегородки ну и соответственно получается такие отсеки и если будет пробоина в корабле то затапливается один или несколько отсеков но а корабль соответственно плавучести не теряет вот презид на такой подход к сожалению вот привести вру сейчас примеры где у нас используются и честь архитектуры на деле я не могу то есть некоторые вещи индии я так и не нашел как бы разрешение чтобы о чем-то конкретном рассказать зато я придумал свой сервис для того чтобы вам проиллюстрировать как это работает значит сервис который я назвал 7 планшет ship service этот сервис который создают объекты геометрические фигуры это набор api ну например там под треугольник вы получаете объект треугольник снег ним айден вы можете запросить тип геометрической фигуры по идее либо например посчитать все круги у такие простые совершенные api запросы и естественно сделаем это ещё похожим на облака сделала ему мультики нанкин то есть у нас есть некое количество пользователей которые будут пользоваться этим сервисом соответственно нам нужно придумать способ здесь я скажу на слово парте цианирования сделать вот по этим ячейкам наши объекты как это можно делать по какой характеристики мы какаем портишь линьки здесь выберем но самое простое просто по геометрической фигуре то есть все тромбы в первую все круги во вторую и так далее здесь у нас получается несколько плюсов и минусов например если кругов а это скорее всего так и будет кругов например больше то это будет не до утилизированы ячейка да то есть неравномерное распределение некоторые запросы делать очень легко например посчитать все круги нужно просто посчитать все объекты внутри 2 ячейки и все и больше ничего не надо делать а некоторые делать сложнее нужны какие-то хитрости придумать например найти по айди геометрическую фигуру нужно пройтись по всем ячейкам и поискать ее то есть это чуть больше затрат на этом другой параметр которые мы можем здесь использовать это ради наших объектов просто мы диапазоны первые 1000 объектов первую ячейку 2 во вторую и так далее здесь мы получаем лучшее распределение но зато например для того чтобы считать наши все треугольники нам нужно как раз тот самый метод scatter gopher то есть мы распределяем запросы в каждую ячейку она считает внутри себя треугольники потом мы собираем ответы суммируем их и получаем ответ на это упрощенный конечно примерно в общем больше геморроя третий способ это по финансам по пользователям и здесь мы сталкиваемся вообще с классической для облака особенностью проблемы она заключается в том что у нас много очень пользователи которые малюсенькие они пробуют что-то там они практически не использует сервис и есть какое-то количество огромных мастодонтов которые никогда ни в какую ячейку не влезут и нужно придумывать какие-то хитрые способы чтобы их распределять между ячейками и так далее в общем идеальном случае не бывает если вы спросите василия как нам то бы быть я скажу но каждый случай индивидуален но ну то есть надо подумать посмотреть но хорошей новостью является то что во многих случаях вот эти параметры по которым вы разбирать разбиваете свои сервисы на вот эти ячейки позиционирование они ну более менее явные такие здесь этот принцип который называется по английски котлы за grain то есть колоть дрова лучше по волокнам они рубить поперек ну вот соответственно эти волокна очень часто их видно и дальше уже можно поэкспериментировать что-то найти следующий вопрос ячейки то между собой конечно слабо связанные но связаны и соответственно кто-то их должен связывать а еще он должен быть уровень маршрутизации или маппинга если хотите который будет правильный прокидывать в эти ячейки нужные запросы и здесь по сути подход должен быть следующий подход который мы используем делать этот уровень мажьте зации максимально тоненьким то есть нужно чтобы он был максимально простым и избегать туда закладывать какую-то бизнес-логику вопрос как делать какого размера делать эти ячейки маленькие плохо большие плохо опять универсального ответа нету я могу сказать что в облаке это было с мы используем логические и физические ячейки совершенно разных размеров то есть есть у нас сервисы которые там региональные не размер ее щеки реально большой есть зональные сервисы где ячейки и поменьше и другие варианты поэтому даже у нас размер ячейки это та же вещь вариативная следующий вопрос как там уменьшить blast radius как нам уменьшить зависимость от каких-то пиковых нагрузок и естественно утих улучшить утилизации потому что утилизация это вот всегда больная тема для любого облака и здесь мы подход используем который называется мультики нэнси помните когда я говорил про селби classical от баланса 1 до который мы создали облаке я говорил о том что для каждого пользователя под каждый балансировщик мы делаем отдельные инстанций и независимо от того как используется или не используются они они принадлежат ресурсы выделены они принадлежат вот этому tennant облака соответственно утилизацию вместе с другими негативными вещами которых мы поговорим часть мы из них пофиксили но как бы есть определенные вещи связаны именно с тем что это решение 1 tennant на и а есть решение мульти tennant не в частности другой тип балансировщика которые у нас есть это нлп не только дансер так вот он живет на сервисы на нашу внутреннюю сервисе вы его никогда не увидите но внутри он соответственно живет облака и предоставляет услуги другим нашим сервисом от называется хенге про плен и гипер plain это огромный флот нот на которых живут многие сервисы в частности нлп которыми он сказал некоторым живут разные tennant и что мы получаем multiman там подходе во-первых мы получаем принципиально лучшую отказоустойчивость гипер plain эта штука которая сделана они уже стоят огромное количество нот под парами который знает состоянии друг друга поэтому выход из строя одной ноты практически мгновенно переходит переводит трафик на другую ноду отказоустойчивость принципиально повышается мы получаем принципиально лучше утилизацию то есть сервис становит просто дешевле и мы получаем еще и а некую такую защиту от пиковых нагрузок потому что нагрузки между разными then on to me они обычно не коррелируют друг с другом соответственно какая-то сглаженная получится суммирующий а кривая ok давайте распределим наших then on the food до ромбики кружочки и треугольники их обозначу по всем нодом и здесь мы встретимся с ещё одной проблемой эта проблема достаточно тоже классический которую называется проблема шумного соседа но зина ибо она заключается в том что если какой-то мы готовимся к худшему да если какой-то из tenant of начиная генерить какой сверх могучий трафик либо неправильный трафик там используя какую не багу не не знаю еще чего-то его вот такой деструктивное действие повлияет на всех tenant of blast radius это все tennant и давайте уже использует тому чему мы научились это не чистый подход соответственно мы поделим на шиноды на ячейки здесь мы просто их назовем шар даме шарды партийцы это одно и то же соответственно ромб как шумный сосед он повлияет всего лишь но вот на моем этом примере влияет всего лишь на 1 tennant и треугольника но зато реально очень сильно треугольнику будет очень больно как нам сделать чтобы хоть как-то сгладить от эффекта лучше избежать здесь я вам расскажу о шестом паттерне который называется перемешивающие шарди рование что мы делаем мы распределяем совершенно случайным образом наших tenant of по вот этим надо мульти tennant ным ну например ромб на вторую-третью шестую ноду высаживается треугольник на вторую шестую 8 и так далее вот перемешали и здесь начинает работать простая комбинаторика то есть можно просто посчитать что в этом случае с 50 4 процентной вероятностью у нас будет всего лишь одно пересечение между нашими then on to me то есть наш шумный сосед повлияет всего лишь на 1 tennant и это не всей нагрузка а только одной третью этот q вы рождены случай если мы возьмем хотя бы чуть-чуть более похожую конфигурацию на реальность со 100 нодами и shorts разом 5 то он получаем 77 процентной вероятностью у нас вообще пересечении не будет то есть мы принципиально уменьшаем глаз радиус shuffle шарин перемешиваешь сортирование используется очень во многих сервисов и даже есть об этом статьи в каких смотрите когда мы останавливаемся после массированного сбоя мы должны облетит огромным количеством лететь конфигурацию да вот у нас например обратно поднимается очень много нот огромное изменение конфигурации мы как-то должны ее то менять это путь очень частый вопрос хочу нам делать-то с этими апдейтами надо кушать или пулить самом деле вопрос неправильно а правильный вопрос с моей точки зрения звучит следующим образом какой флот больше я говорил уже что такое флот да и здесь я вам расскажу о следующем о седьмом паттерне которая называется маленький флот вызывает большой они наоборот сейчас я расскажу что это смотрите очень простая конфигурация у нас есть огромный флот фронтэнда в их инстансов у нас есть какое-то количество брендов инстансов но естественно мы их позиционируем как-то у нас фронтэнда вы in soci разговаривает с определенными брендовые инстансами то есть мы как-то должны их смотреть какой то сделать маршрутизацию статическая маршрутизация обычно не очень хорошо работает ну когда например мы используем крышках какие-то алгоритм хэширования она не очень хорошо масштабируется ведь в случае сбоя когда нужно там и им все менять поэтому лучше динамическую маршрутизацию делать то есть мы рядом с этими двумя огромными флота me instead of rune тентовых и бэкон дав мы ставим маленький плотик моники сервис который будет заниматься чисто матированием он будет знать кто кому должен ходить морите происходит неприятность происходит большой сбой огромное количество наших not падает мы предполагаем такие ситуации а потом они начинают восстанавливаться что они делают они массово практически одна момента начинают запрашивает наш маффин сервис дай мне конфигурацию и что произойдет с этим маленьким сервисом в лучшем случае он деградирует об худшем случае скорее он вообще умрет как правильно делать правильно делать это инициировать изменение конфигурации с маленького сервиса в сторону большого сервиса то есть если наш маленький сервис например используя известны нам уже паттерн постоянной работы будет просто роста в 10 секунд рассылать конфигурацию просто всем и все и тогда маленький сервис никогда не сможет забить большие сервиса вот вы скажете василий вот и все рассказываешь как улучшились отказоустойчивость масштабируемость отказоустойчивости надежность а бывает ли такие случаи когда нам нужно пожертвовать чем-то например доступностью добывает здесь у нас уже 8 последний паттерн который называется отбрасывание нагрузки давайте вспоминать классический график зависимости задержки от нагрузки все наверное даже и в реальные жизни видели это поведение то что называется колена до у вас при сверхвысоких нагрузка в правой части графика вы получаете маленькое увеличении нагрузки приводит к очень значительным повышением лет инси задержек естественно в нормальный в штатном режиме мы никогда не вводим чтобы в правую сторону наши сервисы ну надо добавить просто ресурсов но бывают такие ситуации мы готовимся к худшему например мы восстанавливаемся после массового сбоя и мы так получается что уходим вот в эту часть графика давайте на это часть на это график еще наложим одну вещь это клиентский тайм-аут клиента может быть ну просто другой компонент вашего же сервиса внутри и для простоты опять же light если мы нарисуем 50-ым перцентилями чтобы проще было понимать это и мы здесь получаем неприятность которая называется браун out мы наверное все знаете термин английский black-out black а вот это когда в городе в большом происходит массовое отключение электричества электричества нет ничего не работает brown вот это когда что-то работает но работает настолько плохо и медленно что особой разницы нет что мы здесь получаем вот в этой коричневой зоне мы получаем половина запросов которые мы получили от клиента мы их обрабатываем мы возвращаем результат a time at уже кончился и никто уже наш результат не ждет а другая половина она также обрабатывается возвращается быстрее чем тайм-аут но настолько долго что польза уже нивелируется и мы получаем 2 иную проблему потому что нам уже очень плохо мы уже перегружены а еще мы греем воздух мы делаем кучу бесполезной работы которая никому не нужна нужно что то сделать для того чтобы когда в таких нештатных ситуациях мы попадаем в эту правую область мы хотя бы не занимались ерундой мы делали вся работа была полезной что мы должны сделать первое мы должны найти то самое колено ту самую точку перегиба не бывает фантастики никакой вам нужно это померить или как-то теоретически хотя бы оценить но вы должны найти где вот начинается вот эта точка перегиба и после этого вы делаете очень простую вещь вы начинаете отбрасывать все что заставляет вам уйти в правую правее чем точка перегиба то есть вы на часть запросов возвращаете клиенту сразу же ошибку вы ничего не делаете о возвращайте ошибку это очень дешевая операция мы можем себе это позволить ну а часть запросов они обрабатываются в итоге что мы получаем мы получаем что в таких нештатных ситуациях мы наши доступность сервиса она начинает падать мы не обрабатываем часть запросов ну правда клиенты могут при трою например по ретро и джиттером снова запросите все таки получить сервис то есть и был ability падает но при этом тот кто те запросы которые обработаны мы обрабатываем гарантированно низкой лет инси то есть с одной стороны мы не делаем бесполезной работы и с другой стороны если мы что-то делаем то делаем хорошо опять же я говорю против правую часть графика туда как бы это нештатная ситуация окей я так понимаю что время уже подходит концу мы поговорили с вами о 8 патронов то есть это изолирование и регуляция регулирования когда с моей точки зрения в некоторых случаях имеет смысл нам приоритизировать определенные типы запросов для того чтобы пользователей который не знает неприятности так об этом и не узнали это постоянная работа я категорически я вам предлагаю уменьшить либо вообще исключить какие-либо переключения режимов ваших сервисов частности то это прежде всего очень важно именно для контроля play на тем самым мы получаем более стабильный более предсказуемый control plain это предварительное масштабирование случае например 2 и выловили сезон давайте от масштабируемся чуть раньше например при утилизации менее 50 процентов ну а стоимость сами конечно прикидывайте окупится это или не окупится это очень мощный принцип который называется и честь архитектура мы получаем одновременно кучу с этим бонусов получаем меньше blast radius уменьшая вероятность возникновения ошибок сюрпризов она на нос и так далее мульти tennant ный подход позволяет нам значительно улучшить утилизацию значительно уменьшить blast radius при этом еще и как то сглаживать пике нагрузок shuffle sharding перемешивают шарди рование это подход на самом деле который относится к мульти tennant насти и здесь мы еще меньше делаем blast radius это 7 паттерн который мне самому нравится это название маленький флот вызывает большой они наоборот как и такое американское название с моей точки зрения это мы стараемся делать так чтобы маленькие сервисы маленькие флот и являлись инициаторами изменений больших конфигураций и последний патрон который называется отбрасывание нагрузки где мы стараемся в таких нештатных ситуациях делать только полезную работу и делать ее хорошо коллеги ну вот сегодняшнюю сессию я начал с того что даже самые надежные технологии в космические технологии иногда ломается но на самом деле мы учимся на своих ошибках на чужих ошибках применяем подход дизайн на отказ и естественно не только это позволяет нам не только развивайте существующие сервисы но и ставит перед собой по-настоящему новые амбициозные такие проекты но и в заключение хочется пожелать вам достижения космических целей в проектах которые вы сами себе ставите удачи друзьям спасибо большое друзья вопросы есть вот уже первые смотрите вот он 1 2 3 антон ленок java разработчик и сбербанком василий большое спасибо за доклад за то что во первых очень насыщенные во вторых то что очень понятный в вашем докладе вы сказали очень хорошую вещь о том что можно подготовиться к вещам которые мы знаем и к вещам который мы не знаем меня сложилось ощущение что большая часть доклада как раз таки рассказывается рассказывает о том как защититься от того что мы знаем что в принципе можно сделать чтобы наперед подготовиться к тем вещам когда будет то что мы не знаем но на самом деле если говорить про последний паттерн это больше про то что мы не знаем то есть мы посылаем солонку там мы не знаем в результате чего мы можем зайти вот в эту часть и стать перегруженными но мы строим систему таким образом что если такое случиться то уже к мы как то более менее в безопасности вот но это один из примеров хотя конечно вы совершенно правы очень изначальная версия моего доклада была на два часа состояла из по моему 16 паттернов в общем там разные есть варианты например например это тоже кстати о наверное о не знаем есть такой подход который называется active актив то есть ну если примитивно говорить у нас есть но до активной который обрабатывает трафик и но до пассивное которое ждет если что-то случится она перехватит этот трафик так вот если наш наш подход заключается в том что если что-то не работает даже не работает какой-то маленький промежуток времени это все равно не работает и мы не знаем им как это как какая-то ситуация определенная повлияет на вот эту пассивную ноду поэтому например актив актив паттерн он как раз закладывают в себя что все должно всегда работать до это немножко усложняет нашу систему зато мы сто процентов готовы даже к неожиданностям ну вот это как пример еще 2 наверно что умная версия правильно понимаешь что в африке если про полную версию доклада то будет естественно опубликовано потом на ютюбе а вот если есть какие то еще кстати вопросы коллеги pro 6 в смысле в этом полную версию я думаю что нет это надо culoare над слышит . вот кстати коллеги забегая вперед если будут какие то вопросы именно по это был я сани по докладу у нас есть в африке в африке стенд такой скромник и маленькие притулился под грибком iwsc там есть наши инженеры которые можно задавать инженер который отвечает именно за работу с россией и можно задавать вообще любые вопросы не только по докладу так что ходите дорогие junior его фрак в африку гулять до следующий раз пожалуйста всем привет алексей участник показывает me up василий спасибо большое за доклад действительно очень доступно и очень полезно а вопрос такой вот вы говорили что в с тоже в какой-то степени этим паттерном следует у меня надеюсь по крайней мере и вот первый такой проблему словить еще в далеком 2012 году год 2017 если не ошибаюсь а вот эти веса когда мониторинг был зеленый просто потому что красные кружочки были на другом пакете который не был доступен вот это проблема большой системы когда нельзя уследить за там за всем или это там в каких-то случаях вы жертвуете этими этими покерными там в угоду не знаю бизнесу или чего-нибудь еще ну скажем так всегда ответ простой и так и так то есть в каких-то случаях действительно есть всегда стоимость решения и понятно что существуя я не комментирую конкретную вот это я чесно гря и там сбоев была масса да и какой из них чего там означает я уже естественно не помню наизусть но в некоторых случаях то есть есть приоритеты всегда есть приоритеты отказоустойчивость надежность например это важно но что еще важнее например да это это невозможность потери данных то есть когда бреда это короб шин это самый высокий приоритет то есть если окей сервис недоступен это плохо да но если у вас данные за корабть или сто никто уже вот те кто были они уж точно обратно не вернутся никогда и поэтому иногда нам приходится ресурса все равно ограниченной к лисе на конечно приоритеты ставить иногда ну мы все тоже не можем то есть это первая часть вопроса иногда вы совершенно правы мы просто не успеваем не находим или там это просто эффект роста системы и так далее сейчас вопрос из новосибирска потом вернемся в москву сибирь жгите они внимание на экран да привет меня зовут артем я технический директор а вот и вопрос у меня будет соответствующий вопрос буду я задавать василий привет привет а ты меня видишь я я смотрю на тебя я сзади да не все хорошо с электро слушай у меня такой на самом деле 222 иной вопрос первый вопрос такой вот программисты очень часто хотят и говорят так фразу ребят я хочу просто писать фичу дайте мне писать фичу вот а вот это вот все вот это вот все это как бы какой-то оверхед с их точки зрения очень часто то есть как бороться с тем чтобы было прям на генетическом уровне что блин это надо закладывать на все уровни по его продукта и следом за ним вопрос естественный вот по твоей оценки мне свой оценка да то есть но как бы я ее умолчу на пивной вечеринки скажу вот по твоей оценки вот если разработка всего продукта сто процентов то из этих 100 процентов сколько рационально тратить усилия на вот те вещи о которых ты сейчас своем докладе говорил спасибо да отвечая на первую часть вопроса как нам убедить разработчиков следовать каким-то правилам они просто ходят там что получится ну понятно что есть роль архитектора который его не все любят он уходит и всем как дятел напоминает о том что делай правильно на самом деле все равно все равно зависит от команды но хочу сказать что у нас в и ws например некоторые из этих паттернов они я их читал и смотрел на внутренних ресурсов и у нас например проводятся регулярно именно внутренние какие-то конференции и семинары для разработчиков где люди которые с этим столкнулись популярной форме на примере уже конкретных проблем с которыми они сталкиваются вот помните вот тогда-то у нас чем там жахнуло заказчики это не увидели но зато мы все посидели чуть-чуть вот и то есть как бы еще популяризации этого это тоже важно с моей точки зрения какой процент то есть процент чего ты спрашивал я уже забыл я забыл я помню процента время процентов процентов это вот ну да вот но вот эта вещь то есть sq сколько от 100 процентов рационально тратить на вот эти истории слушай ну мое личное мнение опять же наверное зависит от много чего я бы сказал что архитектура это как минимум половина успеха проекта потому что это же еще закладки на будущее и если ты сейчас делаешь отход по факту какую-то архитектуру а в облаке растет все совершенно бешено быть об через не зная там полгода те нужно переделать потому что все разрослось ты потратишь принципиально большее количество денег и времени и ресурсов то есть лучше сейчас заложить 50 процентов на архитектуру чем потом вообще все переделывать то есть у меня вот такая оценка не зная насколько она совпадает с твоей ильинская с оценками коллег но вести пересдавать еще один вопрос потом вернемся в москву 50 50 процентов я хочу чтобы все слышали да и не говорите потом что не слышали я передаю следующий вопрос добрый день иван серверный разработчик центра финансовых технологий у меня вопрос по поводу паттерна вот малый флот вызывает большой да я так понимаю если возникает необходимость хранить вот эти конфигурационные файлы в одном месте значит как минимум они зависят от того какие ноты сейчас активны и если каждый язык секунд мы отправляем актуальную конфигурацию как вот в этом случае учитывать какая должна быть конфигурация и не получится ли так что если мы будем опрашивать ноты на доступность то в случае падения большого количества нот мы все равно получим очень большую нагрузку на этот сервис за счет перестройки конфигурации и вот как в этом случае работает вот этот паттерн небольшая нагрузка именно на перестройку этот сервис он на самом деле не живет естественно в вакууме вот и опять же это некий такой сферический конь в идеальном мире вот но в реальности такие сервисы они как-то еще и общаются с другими какие-то системы мониторе не и так далее очень часто опять же говорю это вот так больше теоретически разговоры но то есть я не могу просто конкретные примеры но часто еще есть как а какие то мозге у этих сервисов они тоже как отдельный маленький сервис рядом живут они собирают какую-то статистику и так далее начинает предсказывать какие-то вещи и пытается заблаговременно например какие-то альтернативы посчитать но это на самом деле очень важная проблема серьезная котором вы иван сказали вот универсального метода решения конечно нет приходится томи надо костылями это делать иногда еще как-то но и теперь спасибо мы в вас то можно еще от того что вы здесь с нами это прекрасно возвращаемся в москву пожалуйста 1 раз носили спасибо за доклад можно отвечать сначала на вопрос все-таки коллеги технического директора из новосибирска чего не отвечу на его оба я сам разработчики знаю ответ как заставлять своих разработчику делать более качественно садись сюда чтобы они вас видели поднимаясь над центром не стесняясь ставить минутку потратив на это помощь зала остановили бочеков на давайте и они слушали как улучшать качество ну и все-таки плате побольше денег тогда и качество соответственно будет от разработчиков наступать больше спасибо доклад превратился в дискуссионную площадку теперь меня права просто собственной серии вопрос-ответ еще раз спасибо за доклад да конечно вопрос простой даже два на самом деле ты говорил что если есть очередь сообщение который нужно обрабатывать ее нужно приоритизировать иначе мы можем начать просто отбрасывать хвост не да как никогда до него не набираясь но если мы приоритизирует какие-то запрос это вот как раз failure когда нужно было обрабатывать мы их получается вообще не будем обрабатывать или меня не но вы же понимаете что когда мы говорим о массовом сбоя да у нас ну предположим у нас 1000 стоит запросов на в восстановление системы и например просто так получается что в этот момент у вас там один два запроса на на там создание например новых ресурсов во первых эти запросы обрабатываются control play нам и уходят на какие-то разные движки и во-вторых вот эти два два запроса к этой тысячи они особо не не дадут вам принципиального изменения то есть мы не говорим если бы 1000 человек иди на момент на хотели бы запустить эти балансировщик и у нас 1000 одновременно вот этих восстановительных работ тогда да вы правы то тогда бы уже непонятно кого вы больше любим тех кто пострадал или тех кому не хотим мы сказали что каждый кто пострадали они уже пользуются что второй вопрос у нас не так много времени пусть старые ну и второй вопрос короткий вы сказали что с одной стороны нужно большим флотом не ходить на маленький а наоборот с маленького кушать с другой стороны самом начале наоборот сказали что у вас до the plain загружает конфигурация скан трамплина там наоборот большой вот идет на маленький тут какая-то не консистентной селия что здесь между паттернами коснись ценностей не должно быть потому что это разные какие-то методы которые можете в каких-то местах применять то есть я говорю как бывает например когда мы говорим то есть можно так можно так например когда мы говорим о том что постоянная работа это тоже не консистентной паттерн потому что иногда как казалось бы потому что иногда у вас например изменения конфигурации слишком большой если вы будете до лба хоть каждый там секунду огромное изменение конфигурации вы тоже ничего хорошего не получите в таких случаях нужно делать дельту просто дельту надо правильно делать надо тогда дельту делать versio не рваную например не просто перетирать там изменении какого-то параметра делает это с версии например делать какой-то рыбы то есть я хотел сказать что здесь и не должно между ними какой-то консистентной sti и такой великой мудрости каждый паттерн он применяется в какой-то конкретной конфигурацию здесь он может просто не применяться спасибо василю кому подарим мне на самом деле василий понравился за смелость упал выжил таскать на сцену рассказал свою позицию ну и на самом деле это хороший вопрос про консистентной и так далее отлично серию трейдеры для тебя у нас тоже есть памятные призы спасибо за выступление"
}