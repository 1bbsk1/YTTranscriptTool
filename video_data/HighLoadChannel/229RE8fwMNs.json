{
  "video_id": "229RE8fwMNs",
  "channel": "HighLoadChannel",
  "title": "Как мы ускорили Яндекс Go на несколько секунд / Денис Исаев (Яндекс Go)",
  "views": 4141,
  "duration": 2148,
  "published": "2023-01-19T06:59:52-08:00",
  "text": "всем привет трансляция видно все нормально я хочу как мы ускорили индекс go на несколько секунд и это реальная история ускорение она может быть обращено и местами для облегчения восприятия и еще важно что это выкачать всех ускорений то есть мы постоянно ускоряем регулярно тоже не и я расскажу лишь про определенный промежуток времени в конце доклада поговорим про паттерны и принципы чем вообще руководствовались и что еще важно весь захват он будет идти как по бы конца так вот так и по клиентскому книгу и четкого разделения мы поговорим про то как мы research или как мы ускоряли p50 p99 как мы вообще избегать дальнейшего замедления и в целом прокатит паттерн и в конце немножко обомне я руковожу продуктовым бы кантом индекс г у меня 9 лет опыта войти я я видел данный проект по ускорению индекс гол в определённый промежуток времени и в целом виде меня есть опыт проекта связанных с оптимизацией например в почте mail.ru или день торгов wang searing который там тоже немножко про скорость можно спросить зачем вообще что-то ускоряли одно из конкурентных преимуществ индекс go и это качество приложения и все чаще стали появляться жалобы пользователя о том что приложение немножко подтормаживает и конечно команда тоже видео что приложение с каждой печей по чуть-чуть замедляется и мы по сути на капельку perfomax долг если бы если продолжить эту тенденцию то было даже немножко страшно чтобы быть через 5 лет если бы тренд сохранился поэтому мы решили сфокусироваться на качестве и за не заняться системной проблем перфоманса и кроме того мы понимали что попутным бонусом может быть рост продуктовых метрики или бизнесов метр лишь итак давайте поговорим про то как мы research или research и это вообще ну ты продюсер чем я называют процесс которым пытались понять что вообще ускорять в каком порядке и по моему авто проектов связанных с перфомансом один из самых больших челленджей вообще всех проектов это как-нибудь его анализа пора ли здесь то есть как избежать ситуации когда мы рисе о чем так долго что за это время можно было бы жить чуть не ускорять вот и особенно сложно в нашем случае было потому что у нас системой сотен микро сервисов и просто чтобы их понять осознать мог могут уйти месяцы если пытаться еще и как то ранжировать то обще годы и помогал нам не уйти такой анализа paradise например снифер банальный туза мне нравится чарльз мне нравится прокси мент под макось в эфире можно быстро увидеть каким поинты дергаются и не нужно пересечь всю систему целиком кроме того нам помогал дистрибьютор racing у нас собственная админка для визуализации span of можно быстро посмотреть какие span и какие части под запрос подтормаживают еще круче к дайк можно агрегировать чтобы в голове это не делайте смотреть статистику какие части системно медленнее чем остальные и в противовес анализа по радость есть и обратная проблема как вообще говоря избежать преждевременной оптимизация например мы на старте проекта в шторм или командой какие идеи у кого есть вообще что можно по ускорять и вот здесь вот реальные выводы про и штормы здесь можно заметить куча интересных идей и технологий я в конце доклада расскажу а вот ретроспективно насколько они вообще классные на самом деле оказались и вот если бы мы бросились сразу их реализовывать вот это я называю преждевременной оптимизации мы понимали что на самом деле так делать не надо что скорее для нас брейншторм от способ генерации идей и полагаться стоит только на метрики и поэтому мы решили построить dash горды по клиентским метрикам то есть метрик которые шлют с мобильных устройств и сделали их в разных разрезах на пример на слайде разрезы по платформу ios и android и это кстати нужная штука потому что у нас были тельца когда общий суммарный тайминг падает вниз а на одной из платформ он растет при этом и кроме того мы сделали разрезы papers interim по регионам странам и другие и в целом я не рекомендую вам начинать какие-либо оптимизации пока у вас нету клинских метрик и пока у вас нет разрезов хотя бы по перцентиль им и такой мы пытались избежать анализ фара лизис пытались избежать преждевременных оптимизацией полагались на клиентские метрики и вообще выбрали оптимизации порядок которым их делать от ран жираф их по эффекту деленному на сложность реализации дальше мы бросились ускорять 51 см я буду называть p50 медиана и это по сути пользователи на 4g или вайфай и которые не слишком далеко от наших датацентров а наши дети около москвы если что еще няшка терминологии по реке чем я буду называть перед загрузку например на используется в браузерах если вы бро вводите в браузере какой-то url то до того как вы нажали enter он уже может начать загружаться чтобы когда вы нажали enter он уже быстрее загрузился trust мы в команды посмотрели как вообще приложение грузится и там увидеть четыре основных шага 1 шаг какая-то подготовительная работа интеле зация второй шаг делаем н запросов на сервер загружаем standpoint of серверных просто какие-то информацию которую нужно для рендеринга экрана следующим шагом делаем синхронный prefetch контента бокового меню она нужна для того чтобы если user кликнет на боковое меню то она открылась моментально без перезагрузки и дальше рендерим все что получили сервера и нам стало интересно что ты запер печи такой зачем вообще нужен и вот у меня есть что это в целом такой вот список пунктов типа настройки истории способ оплаты и так далее и у нас возникла гипотеза с командой а что если это меню вообще говоря мало кому нужна мы посмотрели аналитику и получилось что она используется открывается вообще всего в одном проценте случаев а при этом печь занимает 400 миллисекунд медиа не и как вы понимаете она используется на каждое открытие приложения то есть мы лет сто процент пользователей замедляем чтобы ускорить один процент пользователей мы конечно сразу это отрубили получили минус 400 миллисекунд и можно спросить но вот как так ребят как вообще-то вроде могу оказаться здесь все довольно типично во-первых предтечи редко именной с профессиями то есть нашем случае он именовался просто просто сервисный запрос во вторых пресечь и часто еще внутри печи находится в нашем случае у нас был запрос печи критических данных для рендера экрана и внутри него внутри ответы были просто дополнительные поля которые нужны только для последующих экранов но в данном случае для меню кроме того бывает что предплечье когда к делают они работают моментально и проблемы нет и в целом и редизайне периодически случаются и они могут менять вот это вот один процент на порядке после этого мы решили посмотреть похожие кейсы наткнулись на другой экран там похожие логика но с одной разницы пресечь здесь сен асинхронной то есть мы не блокируем ся на нем и не ждём его ответа и сразу начинаем рендерить мы попробовали в качестве эксперимента его отключить как думаете какой был эффект поднимите пожалуйста руки те кто думает что ничего не изменилось окей спасибо кто считает что мы могли ускориться этим например до 100 миллисекунд окей спасибо уже больше а кто считает что могли ускориться больше чем на 100 миллисекунд так окей спасибо очень интересно результаты нас удивили мы ускорились в медиа не на 150 миллисекунд на обоих платформах и еще больше чем на секунду в 1с девятом приз на теле и как так дело в том что ответ этого хоть и асинхронного на prefetch и занимал больше 100 терабайт сжатым и конечно же это во-первых долг дорого на мобильном типу который стала бы обрабатывать партии сети джейсон и как-то потом еще процессить и соломона забивать мобильную сеть ну и кроме того такие особенности спи как увеличение ри transmit of забивание this pic отжившие выйду они тоже конечно же скорее всего сказываются и так как мы по сути отключили 2 пресечь я и получили сердцам -500 50 миллисекунд в миде они еще и попутно бонусом по 99 optimizely и это был вышел не бесплатно то есть мы ускорили основной сценарий но замедлили побочный сценарий который нужен там до 20 процентов случаев это км от причин предплечья получили ускорение дальше мы решили посмотрите как вообще устроен граф вызовов в нашем приложении на нас воде от отражен граф и отражены только критичные поинты только те in point и который блокирует загрузку экрана со стороны я скрыл назвав именами и как его читать сначала вызывается из приложение на старте aimpoint ланч и только когда он ответит вызывает следующий поезде а позициями и так далее какие-то вызываются параллельно и можно заметить что их общая длина 1000 миллисекунд и мы ведь намеренно игнорируем сетевые задержки то здесь чисто серверное время в медиа ним и мы решением ну давайте ускорим все эти импланты тоже как мы это делали ну мы разбили работу по командам раз параллели и каждой команды отвечать за свой сервис который соответствующий point и начали в каких-то сервисах мыс optimizely просто около алгоритмический части который superbounce где-то мы переписали с пяточком на себя с плюс где там и ри фактор диодик у которой они очень оптимально написано мы отказывайся от свечей как отвечай который просто не используются давно так и отвечай которые используются но может быть несут мало профита и сильно замедляют нас самым эффективным оказалось распараллеливание бы банальные вещи но чуть-чуть становлюсь на ней у нас некрас сервисная фактуру с сотнями микро сервисов поэтому на ней не тривиальна и значительно сложнее чем на монолите что-либо распараллеливание 0 сложно даже понятие вообще как оно устроено вот пример как может выглядеть 1 in point кроме того можно ожидать что если нам нужны какие-то например н видов данных на экране то их все можно запечь от параллельно но в реальности почти всегда у них есть кросс зависимости друг от друга и для того чтобы с этим бороться нам приходилось например разбивать какие-то in point и на 2 чтобы одну из этих частей можно было делать параллельно вторую последовательно кроме того мы иногда отказывались от распараллеливание специально так как часто бывает трейдов что если мы раз пролезли такой заметный усложню ну и просто у нас есть фреймворке стропилами и там само собой дополнительные запросы не бесплатны и вот мы бросились на эту проблему командами и смогли таким образом перечисленные оптимизация my сэкономить 350 миллисекунд в медиа ним что все вам тоже классный результат мы ускорили медиану сразу у ряды карточных in point of и после этого решились команды посмотреть вообще вот визуально она как как выглядит мы смотрим и не видим не очень каких изменений в этом что-то на ускоряли по графикам есть вот таких ступеньки визуально кто-то говорит что мы быстрее ставок того что медленнее вы что говорит вообще нет незаметно перед тем как обсудите это немножко терминологией мы называем вот такую красненькую штучку пином и внутри pin находится время которое мы называем это estimated time of arrival это время до прибытия машины и вот это вот время это она получается сервера и она грузится самым последним элементом с сервера и пока нагрузиться мы проигрываем анимацию анимация выглядит вот так то есть моргает белый кружочек внутри pin как только данные пришли сервера этом органе останавливается и мы решили посмотреть детальный на эту анимацию вот и и раскадровка можно заметить что 12 кого это анимация штатные секунды это означает что если мы заодно миллисекунды получили данные то еще 599 или секунд мы просто ждем и анимация крутятся хотя мы могли бы уже отрисовать и но на практике за ч-что за 150 миллисекунд мы данные получили еще 550 на секунд просто ждем мы вместе с дизайнерами серий и подрезали интервал анимации до 150 миллисекунд но и сразу ускорились все визуально стали замечать все наше ускорение вот такой тег ускорили анимацию все наши связаться стали видимыми и после этого мы планово и решили еще под ускорять мобильник вот мы оптимизировали память мы подгрузку зависимости оптимизировали много инвестировали в работу сетью и в целом даже легковесный дизайн специально сделали под медные устройство я не буду углубляться скажу лишь что результат хорошие мы сэкономили сотни миллисекунд и заметьте что результаты как это часто бывает в темизация my отвечают основа по платформам и суммарно мы провели четыре оптимизации для медианы и получили общее ускорение больше 1000 миллисекунд и еще как бонус p99 по ускорили на этом мы достигли своей цели по медиане и перешли дальше к ускорению по 99 19 этот тоже самое по аналогии делать 9 перцентиль это пользователи которой находится скорее на сети 2g или 3g и который еще скорее всего далеко от наших датацентров которые около москвы и мы конечно же подхватите сначала посмотрели на наши медиа файлы что вообще с ними поднимите пожалуйста руки те кто видеть разницу между двумя этими картинками так примерно пять человек видеть разницу интересным мы верхней картинка она весит 450 это наше оригинальное исходное изображение которое было приложение нижней картинка это тоже самое но с оптимальное более агрессивные сжатие она висит в три раза меньше мы проводить такое же упражнение с командой мы садились с менеджерами с разработкой и просто сравнивали стоит бойца две картинки пока не на что такой коэффициент которым практически никто не видит изменений но при этом он дает хороший выигрыш по по размер изображения и мы решили просто разово пожать все наши медиа файлы и получили аж минус 8 секунд по 99 говорю примерно потому что мы не делали оба тест лет скорее по графикам падения кроме того довольно сильно сократили жалобы от пользователей еще и трафик мы уменьшили что тоже крут и конечно же чтобы не полагаться на человеческий фактор мы настроили автоматику store при обходе проверяйте размерах ширине например больше 3 3 байта мы запрещаем грузить мы за optimizely картинки получили хорошее ускорение дальше перешли больше к сетевым проблемам что такое т т т т т я буду называть round trip time или pink это время путешествия сетевого пакета от клиента до сервера и обратно или можно смотреть как на клиентское время между запросом ответом если на сервер обработка занимает 0 времени ртт зависит от расстояния во первых чем ближе клиент-сервер у тем меньше rtti вторых от скоростью передачи данных по сети например для москвы на вай фай поэтому это будет около нуля а в африке где-то бюджета будет 250 миллисекунд примерно я кстати рекомендую вот такую книжку она нас много 2 навля love в процессе ускорения hopeful из браузерный clothing она бесплатна и если помните мы смотрели вот на такой вера вызовов и в нем мы рисовали последовательности вызов игнорируют сеть и это на самом деле крыла нет на тому что мы грузимся на вай фай в москве потому что там задержка около нуля но если мы сделаем более реалистичную картину например 4g москва то видите что граф растянулся 150 до 850 миллисекунд что уже заметно а если мой на 3g в новосибирск пойдем то вообще практически удвоились по времени это говорит нам о том что а вот здесь довольно важен в каких-то случаях далеких далеких от это центров нами более медленных сетях и возникает также на этом по-хорошему надо длину этого графа которая сейчас 4 максимально сокращать то есть до единички сокращать и мы решили пойти вот сторону думаю давайте вот отрежем игра ментально сначала первый on point ланч и потом подумали ну можно наверное объединить его со следующим оппонентом дело позициями и тогда у нас будет минус 1 round trip но потом все-таки решили что он возвращает у нас редко изменяемые данные эксперименты настройки пользователей и мы можем вообще за кэшировать и не нужно объединять ни с чем и мы разыгрывали при первом запуске приложения мы к шером сохраняем ответ на последующих запусках мы берем прошлого ответ и в фоне обновляем кэш то есть запрос стал асинхронным и только для обновления каша мы это выкатили медианы практически без изменений а по 99 нашими на две секунды возникает вопрос как так почему ты целых две секунды вот мы говорить про tt и например даже в москве на 2g ртт будет примерно 500 миллисекунд что довольно много но все еще не не две секунды но кроме того можно обратить внимание на скорость скачивания например 10 терабайтный файл скачивается на 2g 800 миллионов размер нашего ответа 15-го байт ну и в общем-то примерно так оно и получается что две секунды кажется садись og и мы подумали помните вот мы пресечь асинхронные убрали из который был таким жирным по ответу и мы сэкономили там тоже неплохо и в меня не в по 99 подумали может и здесь тоже самое про вернуть хоть он и асинхронный ну давайте размеров это гонщицу заодно подрежем мы сократили вдвое до 7 килобайт получили еще дополнительно 2 секунды экономия в по 99 это к вам и суммарно сделали watch асинхронным еще и сократить размеры ответы получили минус 4 секунды в по 99 и вместе с первой оптимизации медиафайлов суммарной эффекты минус 12 секунд может сказать что какие-то огромные значения на p99 он обычную сочетается в 10 секунд все-таки это тот самый кейс когда на 2g далеко до это больно на этом мы закончили ускорение по 99 и может показаться что самое сложное в таких проектах это ускорить но на самом деле примерно равноценны charge the как избежать дальнейшего замедления потому что в моменте сотни разработчиков перед новой фичи и каждая свеча имеет потенциал что-то по чуть чуть замедлить поэтому мы договорились с командами о таком принципе важным ни замедляться при разработке новых фич и для того чтобы это упростить мы обеспечили команды то лингам то есть все те dashboard и графики метрики добавили в бтс ты метрики перфоманса и выработан технические рекомендации например одна из рекомендаций не добавлять новые запросы приложение даже если эти запросы фоновые если все-таки хочется добавить то мер этих с какими существующими то есть применять паттерна и 5 идей твой таймаутов до критичных имплантов мы рекомендовали делать не более 300 миллисекунд и как вы уже поняли размер ответы имеет значение и поэтому мы рекомендовали вы не более 10-ти в байты мы были другие рекомендации давайте рассмотрим на примере почему это челлендж есть сервис который ходит параллельно в 3 зависимость от 0 д 12 представим что все эти зависимости критичные если хотя бы одна из них не доступна то весь сервис недоступен у каждой зависимостей м 99 99 процентов тайм-аут мы используем 300 миллисекунд как в рекомендации и это гарантирует нам хороший аптайм всего сервиса 99999 8 процента и гарантирует чтобы по 99 не более 300 миллисекунд и вот мы хотим сделать новую пищу для которой нужно добавить поход в новый сервис назовем их сервис slaughter потому что он спойлер медленный и вот мы используем там а у 300 миллисекунд но у успешных ответов в таком случае всего девяносто восемь процентов что автоматом понижает аптайм всего сервиса до тех же 98 процентов у нас есть решение мы можем просто повысить тайм-аут и вот тут мы сталкиваемся с тем самым челленджем что проще всего повысьте тайм-аут но при этом мы замедлим приложение получается так как понизим гарантии на по 99 мы решили здесь применить паттерн и хочет request то есть параллельно с основным запросам в сервиса удоб мы пускаем точно такой же дублирующий запрос который может вернуться быстрее а может позже мы берем из этих 2 ответов первый который пришел второй отбрасываем почему она может помочь потому что например один если запрос может пойти на какой-то подтормаживая сервер где накопились его очередь где всплеск циpкa и за фоновых job и тогда тот который даже позже был выпущен может прийти раньше это помогло нам получить целевые любой успешный рейд ответов при хорошем то налоги 300 миллисекунд мы вы провели ситуацию при этом применимом далеко не всегда в нашем случае мы готовы будет дополнительно выделить железо то есть кого то запросов у нас был внешне неконтролируемый сервис который сложно править но и она еще может быть применима если у вас сервис и залипают часто например вот там часто фоновые джо бы происходит но и мы столкнулись конечно с рядом тонкостей например когда запускать второй запрос мы пробовали сразу пробовали через x миллисекунд и это все влияет на трейдов между кастами на хардкор и получаем в отнести и так я показал например у что далеко не тривиально бывает выполнять рекомендацию ни замедляться второй пример похоже другой сервис снова 3 зависимости сна выходим параллельно снова хороший тайм-аут и хороший аптайм и нам снова нужно добавить для новых фич и поход в какой то еще один сервис снова на заменил ствол гэп и опять нам нужно использовать высокий тайм-аут 400 миллисекунд чтобы иметь хороший аптайм казалось бы нам остается только одно принятие смириться что аптайм будет 98 процентов но в этот раз мы решили применить паттерн грейс а degradation то есть я сказал что зависим от 10 до 12 блокирующие но в данном случае столбик был довольно минорной зависимости мы могли просто выкинуть его ответы не использовать если если он не был получен подробнее про этот паттерн мы рассказывали на других наших выступлениях но конечно это в целом идеальной картины потому что хоть мы и получили хороший аптайм 98 процентов из деградации но все равно у нас 2 процента случаев частично не доступны данные ответа и хотелось как-то поумнее сделать поэтому давайте посмотрим на суды по глубже внутрь он тоже ходит в н зависимости параллельно назовем их сам гипс и на самом деле там точно также можно применить многоуровнего деградацию греться degradation и у нас получается такой от двух уровнях деградация если совдеп какой-то недоступен то все равно столбик может ответить но для того чтобы это корректно работала тайм-аут экс аптек должны быть 300 миллисекунд если тайм-аут коса у дев те же 300 миллисекунд иначе она не согласованы мы ждем просто так и оно не будет работать а для этого сервиса у д получается должен знать тайм-аут к себе и из каких-то более оффлайновых контекстов тайм-аут может быть больше например 600 миллисекунд и для того чтобы дать следует это знание мы применили паттерн d2 непогрешим то есть мы стали передавать в запросик сервисов значение тайм-аута к нему параметрам тайм-аут м с и тогда это тайм-аут сервис audi уже выставляют где своих зависимости и все работает корректно при этом есть сервис есть смысл распространять это тайм-аут и дальше по стыку вызовов потому что sardor сервисов ситуации может быть аналогичной они точно также могут делать грейс пул degradation и он будет уже трехуровневый как и сам сервис ему тоже есть смысл принимать на вход тайм-аут к нему и если в данном примере он 285 то он должен использовать именно это тайм-аут для своих зависимостей но на самом деле нам нужно не тайм-аут нам нужно остатка тайм-аута если сервис 15 миллисекунд что-то делают в начале своей работы подготовительные какие какие-то последние вызовы делают то их нужно вычитать из исходного тайм-аута и аналогичные stories дальше сосуды таким образом мы добавили поход в сауну и смогли сохранить гарантий на по 99 и хороший аптайм многоуровневость градаций x на данном слайде это время которое мы в начале потратили на инициализацию те самые 15 миллисекунд например мы применили для этого доннер погашен который позволил нам разменять таймаут на качество под ответа при этом мы сделали это плавно и с помощью многоуровневость градации вот ещё один пример того что далеко не тривиально может быть следовать принципу ни замедляться новыми фичами я хотел вообще cheers подвести все это ради наших ускорений мы сделали 4 оптимизации медианы и ускорились на более чем секунду еще попутно по 99 ускорили и потом мы нацелена били в p99 и вскоре ли его на 12 секунд в целом хороший результат моим довольным и поговорим немножко про паттерн и чем мы руководствовались когда ускоряли 1 потому что оптимизировать стоит под основной сценарий то есть вы могли заметить что открытие бокового меню убрав которые мы ускорились это некоторый побочный сценарий который нужен 1 процент пользователей и такой часто бывает при пресечь их я призываю обратить ваше внимание на пресечь и в ваших приложениях насколько они вредят основному сценарию следующий паттерн что есть смысл работать в нескольких разрезах например разрезы по платформам айос и android можете заметить что результаты у них чуть чуть отличаются или разрезы по перцентиль им здесь это часть вообще все то есть как с вами оптимизация отличаются под разные перцентиле так отличаются эти результаты конечно же еще один паттерн что доверять той только данным и графиком бывает такое что есть соблазн применить какую-то модную технологию известно что какое-то место уже плохо написана и поэтому хочется его по optimized вот и вообще очень долго строить графики за зачем это делается давайте сразу бросились в бой мы вначале говорили вот провод бренд шторм который мы делали командой так вот если посмотреть как вот при распитии вно мы на него сейчас смотрим то только 3 из 9 оптимизации на мне сейчас кажутся живыми остальные оптимизации скорее не стоило делать и даже если мы смогли бы вычленить ровно три вот эти оптимизации на самом старте после бри шторма то все равно мы могли бы упустить другие оптимизации которые не фигурировали в штурме например две жирные оптимизации это сделать раньше синхронным и отключить prefetch и вообще не обсуждались и и не понятно как они могли обсуждать какие-то вещи которые до которых можно докопаться только смотря на графике анализируя и похоже паттерна что бывает так что нужно все-таки применить какую-то крутую технологию например есть современные форматы картинок в.п. авив и они могут дать много профита но при этом если внедрять их дорого часто бывает такое что можно получить восемь процентов результата значительно дешевле в нашем случае мы просто намного сильнее пожали jpeg и png и получили примерно похожий результат чтобы чем-то полезна выйти из этого доклада я призываю вас запустить свой сайт отражения под с эфиром поднять пожалуйста руки те кто за последний год хотя бы раз вы запускали снифер путей пасибо пример примерно треть запускала я призываю запустить снифер и посмотреть выводите нефера на возможные проблемы например не слишком ли много ваше приложение сетевой запросов нет я вообще избыточных запросов которые не нужно делать если ответы который более 10 тема байт джад и даже если это фоновые запрос и нед ленд поинтов которые отвечают более 400 миллисекунд нет лиц слишком больших картинок я когда готовилась к докладу взял 10 популярных приложений из appstore а и запустил под с кефиром у 8 из 10 приложений была хотя бы одна из вот этих проблем на слайде как его индекс гор конечно же как вы поняли из этого доклада поэтому я призываю это очень простое действие сникеры есть даже на телефоне у меня даете 20 нефера стоит на компьютер тем более итак мы проговорили про ускорение как мы избегали замедление поговорили итоге паттерны у нас есть еще время и немножко бонусного контента еще один из чем ниже в таких вот проектов ускорения это как продавать командам может показаться что просто пришел попросил они сделают но часто бывает так что вот у нас сотни разработчиков в 10 команд и у команд свои цели свои приоритеты где-то может не хватать людей и не вся команда согласятся 0 ускорение которые мы можем предложить например нам помогало донесения важности ценности для пользователя когда оптимизации занимает месяц мы порой делали какие-то прототипу шутках остальные просто за день которые ни в коем случае не захотите пород но они демонстрируют визуально насколько станет лучше и мы сравнивали сайд бай сайд просто видео сравнения старая новое это очень сильно помогало мотивировал команды что что-то срочно делать также помогали сравнении с конкурентами когда видно что говоришь приложение работает быстрее газеты например и и в салон всегда полезно транслировать далекую стратегию на 35 лет вперед к чему мы придем за чему что это что-то делаем здесь также мы надем команда был важно понимать как это отразится на продуктовых метриках на их продуктовых целях и днем с одним помогали замедляющий тесты ведь нельзя до того как ты его оптимизацию понять какой-нибудь эффект а если ты сделал того какой уже смысл понимать поэтому мы как делали мы берем как one thing point вставляем там стрип на 200 миллисекунд например катим в оба тесте на маленький процент юзеров из смотрим насколько просели метрики просели по те и фиксируем результат и считаем что примерно также вырастут когда ускоримся на это значение ну и конечно же мы ссылались на какие-то прошлые результаты по метрикам кроме того ук для команд обычно довольно важно удобство планирования сравните две ситуации первая ситуация мы просим команду перейти на коне совершенно новый например на готовку ведь какую-то новую технологию и команда оцениваешь что это в месяц работы другое дело мы просим команду подмерзших пару ручек и сократить размер ответа и конечно же 2 быть сделано намного более вероятно а результат может быть примерно похожее и аналогично сравните два кейса первый кейс мы просим команду ускорить сервис который два года не трогался и мы просим команду ускорить сервис который планируется ли факторы на этой неделе конечно же второе узи он намного вероятнее и вот этих энергий тоже полезно искать у меня на это все осиба можем прийти к опросам отлично давайте поблагодарим денисом и а пока в зале задаются вопросы а девушки идут к людям у кого подняты руки у меня вопрос из чата я напоминаю что можно задавать в чате конференции вопросы вопрос звучит так и похоже ты на него ответил самом конце во время бонусов но я на всякий случай его повторю а ты подтвердишь или нет вопрос как вычислялось ускорение после каждого изменения на бэг-энде на ком-нибудь стоит же при пародии или прямо в прозе и как выглядел сам процесс изменения измерения просто смотрели разницу на графиках было несколько птиц там первый этап когда у нас небо вообще ничего не кати графика в какие-то ускорение все равно делались это просто чуть ли не пологом мы читали статистически там перцентиле вероятность и так далее вот второй этап когда у нас уже появились метрики мы по клиентским метрикам смотреть и ступеньки на графиках на третьем этапе мы встроили в бтс ты метрики performance и уже час на более читал статистически смотрели в пытаетесь но какие-то вещи мы делали без збт став специальную например сжатие картинок так просто сильно проще спасибо и вот молодчик пожалуйста встаньте микропластик поближе спасибо за доклад у меня вопрос про дедлайн про повешен у тебя на примере на слайдах вы прокиды вали именно тайм-аут и здесь просто хотелось узнать было то почему было такое решение потому что там необходимо собственную работу точно вымерять до чтобы не на махаться с дальнейшим прокиды ванием как вы считали собственную работу сервиса вот насколько надо уменьшить следующий тайм-аут и почему не прокиды вали именно сам дедлайну может быть проблемы там синхронизации часов на сервер от и так далее когда можно конечную точку времени прокинуть ждали все сервера просто у него вписываются спасибо за вопрос да классно подмечено эту часть я специально вырезал то есть тут кажется день доклад что мы выбирали прокидывать абсолютное время или относительные в абсолютно времени нас смущалась не красятся часов мы не готовы будет углубляться спасителем были аппаратные проблемы что где-то задержки в очередях нужно аккуратно учитывать ртт между дата центрами но все же своей сложностью в этом запас на сетевые запросы оставляли просто вот мы на самом деле в этой сильно так не углублялись скорее для целями для целей оптимизации мы сделали вот так и дальше мы уже параллельным треком начале все это вылизывать и делать именно для полноценного prada production ради решения насколько я помню сейчас там все-таки относить сейчас там именно остаток тайм-аута передается но измерять он просто берем ну просто таймер на у в начале в конце да и задержку на кровь но между вот этот типичный у нас к книге есть пример так спасибо и вот девушка будьте добры привет вопрос следующий ты сказал что убеждали команды с помощью альфа и бета-тестирования где на конкретных пользователей что-то замедляли вы строили процесс взаимодействия со службой поддержки которые вот на этих альфа бы это пользователях собственно наверняка наблюдали рост жалоб там не знаешь на не такое спасибо за вопрос мы специальные не делали большие замедления то есть 200 миллисекунд это обычно практически не заметно на глаз - когда будет ускорить на 1000 миллисекунд медиана 200 миллисекунд страниц летием ну вот то есть больше двухсот мы специально не делали"
}