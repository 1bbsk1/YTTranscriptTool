{
  "video_id": "Cpkhp9Ip18E",
  "channel": "HighLoadChannel",
  "title": "Мониторинг быстродействия web-проекта / Владимир Буянов (Ultimate Guitar)",
  "views": 1253,
  "duration": 2356,
  "published": "2018-01-16T12:36:00-08:00",
  "text": "приветствую меня зовут владимир и я работаю сам министр оторвать гитлер пару слов о нашей компании мы работаем на рынке уже 18 лет in текущий момент и являемся крупнейшим треть каталогом гитарных табулатур у нас так же самое большое сообщество гитаристов ежемесячно аудитория составляет 60 миллионов человек а наши мобильные приложения входит 100 платных приложений категории музыка в работе мы используем достаточно стандартный так технологий этапах апэйн джинкс и майский если тут есть люди и спирко нато привет мы вас любим как видите ники космических технологий раз вы пришли сюда то думал вас есть какое-то мониторинг серверов метрик на основе zabbix она deuce или про метался снова экспортером поэтому я не буду касаться этой темы итак поехали я вам нужно мониторинг особенность работы нашей компании часто диплом очень часты в сутки разработчики могут выкатить до 50 ревизий которые сразу ходят в продакшн мы работаем быстро иногда что-то ломаем и должны быстро об этом узнавать ошибки могут быть вызваны также не только нашими действиями но и старание факторами например проблема в центре ошибки вообще может не быть многими все плохо например выход новых версий ос браузеров или змейки хд политик безопасности явные ошибки которые явно шаги которые легко находить блогах не интересно поэтому я буду говорить про не явные ошибки которые вызывают падение производительности производитель на нашем сайте занимает особое место потому что на быстром сайте выше конверсия по данным исследований с остатком увеличение времени загрузки с 3 до 4 секунд снижает конверсию примерно 20 процентов наши данный город примерно о том же поисковики игры пользователь тоже любят быстрые сайты а мы естественно хотим быть сплаве поиска быстро узнать о снижении производитель мы можем только от наших мониторингов когда давно мы узнавали об этом по сообщению на форуме обращение в support или снижению продуктовых метрик но такой подход работает плохо потому что пользователи редко сообщают о проблемах а чаще просто закрывают сайт снижение продуктов метре говорит о том что все уже плохо хочется узнавать об этом заранее и так я расскажу о наших мониторингах на примере реального кейса у нас есть два домена prepaid которые работают пояса цели на пай домен большинство после приходится среда мена в один из дней наш мониторинг на основе performance api который мониторит производить через пользовательский браузер я которыми расскажу чуть позднее заметил рост времени дтп бдм ссср напои домене примерно 30 процентов на остальных доменах работающих на тоже инфраструктуре изменений замечены dvb это время от нажатия пользу кнопки enter и браузере до получения первого байта ответа от сервера в основном зависит от задержек сети и скорости вашего бренда на заметьте что мы заметили проблему это значит что пол дела уже сделано осталось только ее найти и исправить это какие у этого изменим могут быть причины где будем проверять сначала вопрос к залу еще варианты да начнем с бэг-энда так как его легче мониторить мониторинга быстрый понятно результаты и мы его полностью контролируем стандарт мониторинга стандартных серных метрик таких нагрузка на капу диск и подобные часто недостаточно для детектирования проблем в приложении например медленно отвечает внешней сервис или база данных медленный код или катит специфичной body раньше у нас был бинарный мониторинг который показывает показывал работает приложение или нет и вместе с мониторингом как он часто пропускал проблемы хотелось также мониторит насколько хорошо работает приложение я думаю их пишет факта слуги почему бы не использовать их мы их собираем и храним в связке ластик щечки брелок визуализируем данные с помощью grafana с помощью данной связки удобно мониторить response time серверов с разбивкой по страницам количество запросов и их статус и можно производить произвольную агрегацию по vr по углу страницы девайс у пользователей ли его стране на графике вы видите время ответа нашего сервера с разбивкой по страницам как хорошо видно все страницы кучкуется где-то снизу и только одна выбивается из общей картины кроме мониторинга эти данные используются для аналитики автоматического явления ибо набор ибо на ботов или для того чтобы ходить некоторые специфичные body например недавно мы заметили рост количества запросов к одному из методов api после исследования выяснилось что при обновлении adios разработчики случайно сбросили каско клиентского приложения нарезана все а боишься клиенты кинулись всего перекачивать сделать конечно уже было ничего нельзя но мы хотя бы это увидели и предприняли меры что следующий раз такого не было поскольку храни длительную историю власти все так ладно так она занимает очень много места мы храним данные за здесь 14 дней исторические данные у нас хранятся в москве агрегированном виде естественно по агрегирует данным dead а также гибко искать что их можно хранить бесконечно возвращаясь к нашей исходной задаче response time брендов не изменился то есть проблема у нас не на серверах хорошо но если мы заметили что вырост response time какой-то странице как понять почему можно научить самом приложении записывать метрики своей работы например время выполнения запроса кбд или внешнему сервису тяжелой функции подсчитывать хиты мисс и каша в общем все что вы сможете находите написали базу данных обычно для этого используется time series b dm например про metals или графит над заметить что полезно такого мониторинга прямо по официальное количество собираемых им данных при запуске подобного проекта у нас мы попали в замкнутый круг никто не пользуется мониторе ну потому что у немало счетчиков и никто не добавляет новые счетчики в код потому что мы итогам никто не пользуется через некоторое время проекту мир поэтому если решите внедрялись подобную себя-то не повторяясь нашу ошибку и заставляете разработчиков сразу обвешивать максимальному навешать максимального счетчиков так вот идем дальше мы имеем представление 100 происходит сервере значит ли это что то можно закончить ну к сожалению нет возможно ситуаций когда на сервер на хорошо попользовали все плохо например кто-то блокирует загрузку страницы частенько этим грешит рекламу блокируя события вот еще пример это не оптимизированные картинки то есть картин который можно нажать или корзин который использую неправильному разрешению то есть на сайте нужна картинка стала 100 использовать 1000 на 1000 это генерит на пользу дополнительный трафик и ненужное время загрузки еще проблема которую мы не сбежим несмотря на то что все очень умна это человеческий фактор например недавно с nintendo разработчики добавили в джесс которые используем почти на всех страницах сайта тяжелую либо это заметно замедлила загрузку страниц у пользователей и наконец после могут быть проблемы сеть чего например крупную dos атаки или локальные проблемы у провайдера или регионов конечно сделать с этим играть лишь за сможем узнать об этом хочется в этой части доклада я постараюсь вас дети что необходимо мониторить frontend если вы этого еще не делаете мы мониторим и змея в рестлинг google по себе для того чтобы находить некоторые из них отклонений делается это очень просто у нас был написан скриптик на но с который собирает данные и запер угла и скрытых в майский по сложности настройки и поддержки против красивым профита это отличный мониторинг так как он нитка 8 к ресурсам все работу выполняю сервера гугла и запускать его можно хоть на разбери пай инициатива также очень просто благодаря бензин гамаке от гугла большинство популярных языков программирования некоторые примеры программ который умеет них или данный мониторинг это не оптимизированные картинки или выпущенный за zip на серверах восстановить им тоже грешат рекламодатели который не умеет настраивать свои сервера и с большинством удается договориться о исправление возвращаясь к нашей исходной задаче google pagespeed проблему не видит то есть по его данным все хорошо хорошо раз посетит проблему не вид надо копать глубже можно собирать такие данные как размер страницы количество запросов который выполняется при ее загрузке их размер они плохо будет также измерять такое время как дом вроде лот этот fb если кто заблокировал загрузку страниц мы хотим знать кто это для мониторинга таких изменений мы используем проекция спида и он представляет из себя chrome или firefox и обвязку на но джесс с помощью него мы отслеживаем полный размер страницы и количество запросов которые необходимы для ее полной загрузке можем сегментировать запросы по запросам крассом и старанием сервером и по типу контента например джесс к с картинки так далее измерим так же время загрузки такой как дом ради и лот мы не смотрим в данном мониторинге на метрику that of a bad так как наш тестовый сервер расположен в центре там тесно все хорошо с интернетом и метрика тот особо не сильно полезно детальные отчеты сохраняется в виде хтмл файлов метрики записываются в графит визуализация листинг реализовано с помощью графа на данный мониторе хорошо позволяет видеть изменения тяжести тяжести странице что изменилось например стали тяжелее картинки мы также сохраним хоре порты на экране вы сейчас видите часть такого отчета на нем в наглядном виде представлены все запросы которые выполнялись при загрузке страницы их порядок и время выполнения кроме этого для каждого запроса можно посмотреть заголовки хорошо помогает выяснять что же собственно сломалась и как это исправить а еще маска про плюшки сайт спит он может эмулировать несколько скоростную сеть например мобильную может работа удаленным браузером на android устройстве здесь может тестировать сразу на живых девайсах прикольно фича персонаж бюджет можно задать ограничение например например количество запросов глубина дом количество дом элементов количество фреймов количество редиректов размер контента и так далее после этого вы запускаете test is a spear говорит удалось ли ему загрузить страницу с указанными ограничениями или нет он является полностью окон собственным решением так что любой может его себя скачать for кнут сделать пузыри глаз ты так далее благодаря официальному блогеры уже попробовать его все будет очень просто достаточно сделать docker пул иран и возвращаясь опять к нашей задаче даже такой мониторинг который максимально приближен к реальности не видит проблемы то есть наш материк настолько формат сопи говорит что все плохо синтетическими интернет говорит что хорошо проблема может быть только у части пользователей например в каком-то регионе неожиданно стало плохо с интернетом или вы запустили об это стадное сварятся сломано вашему интервью я не входят проблема также может появляться на некоторых браузерах и девайсов например на десктопе тяжелая в скрипт выполняется нормально на мобильниках нечетный тормозит для мониторами таких изменений мы используем мониторе через пользовательский браузер как это работает большинство современных браузеров предоставляет performance shoppe с помощью него javascript может узнать о скорости загрузки страницы на всех страницах нашего сайта подключается джесс которая после загрузки страницы собирает эти данные из браузера а формировать проект get запрос на сервер уставлены джинс который полученные данные записывает в access логе мы используем газ формат для записях со слов как наиболее компактные и удобные для парсинга обрабатываем данные с помощью связки питон и pandas так как при богатая функциональность она обеспечивает достаточно высокую скорость работы собранные и обработанные данные мы храним в мой стиль мы собираем следующие метрики dns это время рисового домена принимает значение 0 если результат взят из кэш браузера redirect это время редиректов внутри домена хочется конечно мониторить и время redirects домены домены тут есть две новости хорошая и плохая хорошая в том что существует специальный заголовок тайминг голова риджент который позволяет разрешить браузер это делать плохая новость том что разный браузер работать с ним немного по-разному конечно можно было написать код под каждый браузер и но мы решили пока не заморачиваться с этим коннект это время установки соединения между клиентом и вашим сервером пустом зависит от задержек сети и скорость вашего балансировщика принимать значение 0 если используется существующей тепла и в соединения в это время также входит с цель хансик но если хозяйка мы дополнительно измеряем отдельно для того чтобы находить возможные проблемы с целью нас в нашей реализации принимает значения 0 если используется keep-alive соединения или если за цель не используется дом ради это время до загрузки страницы и всех синхронных скриптов и он лот это время полной загрузке страницы мы также записываем тип соединения то есть вай-фай ethernet мобильная сеть и его поколение для мобильных сетей то есть 2g 3g 4g это не все собираем иного метрики но самые полезные кроме этого например можно запускать оба тесты скорости загрузки важный нюанс мы не используем сэмплирование при сборе данных сэмплирование когда мы записываем не каждый винт а каждый второй ли каждые 10 а потом экстраполируем данные благодаря этому при сегментации у нас остается достаточное количество event-ов а если сильно увлечься циркуляции то может получиться как то вот так при обработке при обработке каждая метрика группируются по каждый тип по каждому типу группировки то есть мы берем все данные за последний час разбиваем их по url страницы считаем перцентиле для каждой метрики и записываем результат а потом опять берем все данные разбиваем их по типу устройства считаем перцентиле записываем и так и для каждого типа группировки результаты сохраняются в базу данных raw данные удаляются плюс такого подхода в том что требуется хранить очень мало данных минус в том что мы можем добавить новую группировку только для новых данных соответственно сейчас нас квант время 1 час если мы захотим изменить это то сможем сделать тоже только для новых данных на картинке увидите два графика времени ответа нашего сервера за 48 часов разница между желтым и зеленым графиком составляет от 5 до 10 раз как думаете какой то сне показывает ситуацию желтый это среднее время ответа а зеленый это 95 перцентиль на зеленом графики хорошо заметны дивные ночные колебания как видите вычисления среднего значения отлично маскирует изменения поэтому мы для всех метрик считаем только перцентиле обычном обычно мы оперируем 70 и 90 перцентиль им но считаем также для каждой метрики 50-ый и 95 и техника что такое перцентиль 99 перцентиле означает что 90 что 99 процентов запросов а выполнялись быстрее чем указано на зеленом графики . а теперь вернемся к нашей исходной задаче напомню что было известно из то мы выяснили и так у нас есть два домена free ipad который работает пояса цель момент пользуюсь пользовали приходит кликай по ссылке на средами ни в один из дней нас мы только настолько фома сопи заметила рост времени tfb dns я за цель примерно 30 процентов на остальных доменах работающих на той же инфраструктуре никаких изменений не замечено response time серверов не изменился и я google pagespeed и , проблему не визит после детального анализа данных из performance shoppe выяснилось что затронуты все пользователи то есть все страны все девайсы и так далее а теперь я предлагаю вам сыграть небольшую игру и просто догадаться что собственно произошло тот кто угадает или будет максимально близок к этому унесется собой вот эту замечательную бутылку джека мне с мониторингом все было хорошо мы это проверили в первую очередь и как паза канал дальнейшее расследование дела было ни с ним нет мы проверили мы проверили пользу пользуюсь такой же без редиректов и так далее так нас немножко по очереди нет sd на сам не было никаких изменений не затронуты все пользователи то есть все стороны равномерно все девайсы также равномерно мнение это именно время тот fb то есть получает этого бренда нет у нас не было ни в то время не было таких изменений на серверах то есть это могут рассказать что это не сертификаты это не те кипит так и так далее то есть садим все было хорошо и не менялось да эти два доме находятся на одном и том же оборудовании на одном и том же канале и так далее dns у них тоже 1 сейчас образования что время tfb это время ответа ответа получения клиентом 1 байт ответа от бэг-энда то есть либо стал медленнее работать backend либо стала медленно ставлю соединение нет это было уже после нет это не связано с версии google chrome и мы проверили то опять же все равномерно по версии браузеров то есть пострадали как старой версии так и новые нет у нас как бы мы безопасность админы сами поэтому мы знаем что крутим дойдет уметь ответ да конечно дали как видите время 2 то бэг-энда не изменилось то есть backend дает на балансировщик страницу также быстро всем до сможешь даже все хорошо нет я уже говорил даст целям все хорошо и он не менялся и проблема не в нем нет проблемы с этим до блокировщик работает хорошо еще раз можно или или в микрофон нет но хорошая попытка нет опять же как я говорил уже все пользу то есть и те которые сидят прямо под боком за центра и за которым на другом конце земли да какие запросы не пользователи переходят на другую страницу кликнуть по ссылке их отправят на другую страницу вот нет все без изменений могут дать небольшую подсказку у нас на серверах включён keep-alive и он как-то у часто задача keep-alive нет ни буферы не менялась конфигурация не как-то еще раз очень близко да ну пожалуй я все-таки там у человека есть у кого нет вариантов лучше отдам бутылка нет ну это уже сказали ответ то что использовалась heep live поэтому давайте я расскажу что собственно случилось и так что у нас было на сначала на free домене был старый код который после загрузки страницы аяксом посылает запрос на предмет соответственно момент в плане запроса производился резал в dns установка цпс цель сидения после выполнения запроса она оставалась висеть фоне благодаря включенному keep-alive когда поиски нажимал на ссылку он быстро переходил так как использовал уже существующие соединение то есть это был такой случайный реализованный prefetch который устанавливал сиденье ещё до того как она понадобилась пользователю потом этот выпили стало как то вот так теперь пользователь был вынужден проходить процедуру с нуля это естественно замедлил на загрузку страницы интересно ведущим в том что вот этот код который работал на среда менее внедрялся для увеличения конверсии там какие-то предпочтения пользователей вот и для этого проводился apts теперь ясно что бы тасс был проведён некорректно и возможно вся пользу этого года было увеличение скорости загрузки страниц и так я думаю многие как бы интересуются как как мы находили естественно при возникновении проблемы мы про люблю или изменение в те но данное изменение пропустили так его связь с увеличением времени загрузки было очень очевидно уже после анализа данных всех мониторингов мы поняли что случилось и зная что искать нашли это изменение в гите примерно неделю заседает это был это было не очень не быстрый процесс потому что сначала была первой мысли в атф что произошла так сейчас да хочу заметить что несмотря на то что большинство мониторных проблему не видели это не значит что они были бесполезны то есть отсутствие информации тоже дает подсказки где искать и собственно выводы только многогранный мониторинг поможет вам находить и исправить проблемы то есть нужно мониторить весь так они какую-то его небольшую часть но данный мы только не очень полезно без их правильной обработки и в данном вопросе вам советую поймать clown грамотного аналитика привязать его к батарее и расспрашивать его медных обработки данных он вам расскажет гораздо больше чем частного который успел затронуть все инструменты которых я рассказывал кроме google pagespeed являются открытыми бесплатными google pagespeed бесплатный но закрытой соответственно любой может легко и все поставить попробовать если понравится использовать продакшене я рассказал только о нескольких инструментах но на самом деле их гораздо больше используйте и другие инструменты тоже спасибо за внимание вопросы ни у кого нет вопросов знаете покажу график собстна это одна и та же метрика среднее время ответа как видите из-за большого количества страниц из мы с очень маленьким времени ответа метрика средние почти не подвержена колебаниям в то время как 99 перцентиль очень да очень красноречив спасибо за подсказку поэтому среднее время довольно бесполезно для нахождения проблем что на такой оправляем может быть именно для этого мы измеряем не записываем ни один перста деля несколько окажет кола мы записываем 4 5 лет и 50 и 70 90 и 95 как раз если проблема будет только 10 процентов пользователя то это можно будет легко увидеть просто поселка спирта на теле нет своем и не писали потому что разработка свое решение всех много проблем много кораблей гораздо проще использовать чей-то чужой опыт завтрака же скала у нас есть мониторинг на основе как со слов которые используйте ластик и игры и log is so написанная джесс к которая собирает данные из сифона сопи браузера мы пока обходимся одним инсам в принципе него проблемы с пастеризация нет когда мы переезжали с 1 инстанции на другом по собрали кластер перегнали все данных новый совсем другой и погасили 1 х ст то есть технические проблемы никакой ластик отлично работает в кластере и если хочется то можно использовать без проблем на самом деле насколько я знаю мы не собираем метрики с мобильных приложений то есть по крамер и технически мы собираем там какие-то ивенты то есть нажатии кнопки польским купите что-то подобное то есть чисто маркетинговый они собираются с помощью все того же tracker на яндексе то есть работа и tanks а он записывает полученные данные в access лак и потом он такса слог парсится чем-то обычным павшим питоном это с пандусом доступно просто из в консоли chrome и там в консоли просто игра типом windows performance допам windows . performance и он выдает все эти метрики по большинству события лета приходят сначала админом то есть админ уже инициализируют какую-то какое-то разбирательства если нужно подключать разработчиков аналитиков и так далее часть другая часть артов приходят аналитиком которые тоже смотрят какие-то данные и вот вам интересно аналитиком снова интересно всякие продуктов и метрики ну то что ближе к продуктовым админом теста ближе к техническим то есть на прямо увеличение времени загрузки это частот минская штука до как я уже сказал собрать данные по performance api можно просто набрав в консоли window . performance то же самое вы делаете в javascript и то есть просто вызываете нам вара равно винду performance там т т т т т т т б потом это все все метрики собраны группируйте в один url и дёргаете его аяксом данные по сети предоставляют насколько помню в методе not working тоже браузерного open it working и там что то там сейчас просто так не вспомню да да именно так мы сначала пробовали с jinbei это сми не изменяет память решение от доход буду потом собственно потихоньку пиво периферию и так что теперь фактически просто я джесс к пока таких инцидентов не было то есть сложно представить ситуацию когда кому-то понадобится массированное служить такими данными то есть если нам придет 12 такие значения ну крайне кривых то они просто не попадут в перста теле и все чтобы это как-то серьезно повлияло на картину то нужно спамить ну представь уж много сообщений и ну пока это некому было не нужно да найдем мы забаним сейчас скажу за час собирается примерно 1 2 гигабайта на бетонных обрабатывает что-то в районе 10-15 минут то есть примерно сорок восемь гигов да то есть это как css в таком стиле метро мне , а каким-то другим ну фактически css там у нас использую вертикальной чёрточкой тут как кому нравится да они удобнее для парсинга но тут есть 2 проблемы с которыми мы уже столкнулись когда ты стиле access логе формате json во первых во первых они снимают гораздо больше места ну то есть там фактически два раза пишется там название метрики и и значения а во вторых джонса дает данные в очень странно формате например он может записать вместо например такой метре как response ставим он можно записать туда какое-то число а можно записать туда черточку дефис соответственно джейсон очень нравится когда вы в дабл поле пишите какую то фигню телефон говорит типа я не валидный то есть мне можно конечно писать это в виде строки но это ужалить это очень не нет я говорю том что инженер можно давать как допустимым даже за значение так и черточку и если вы хотите использовать тип integer для этого поля то в него нельзя записывать эту черточку брелок брелок это штуковина которая логе принимает и записывает в ластик партию plague этот агент смысле это все же practice логе не разварить и тогда агент парсит лак и все запись отправляет в игре лоб брелоках индексируют и записывают в ластик потом эти данные выводятся ужас с помощью grafana или того же крыла которая тоже умеет строить графики и водить сообщение нет ещё у нас есть от этого все слуги которые пишутся целиком в elastic есть метрики которые приходят от пользователей то вот да мы считаем 1 час и выводим уже обработанные данные последний вопрос касательно elastico делали ли вы горячие данные на ssd их или ли хватает их и т.д. они производительность производитель хода не хватает мы решили эту проблему глобальные перенесли все на ssd мы очень любим делать выборки там например по недели две по всем логом ну иногда это просто полезно что понять там что как было и что стало поэтому перенесли все на ssd и теперь все хорошо объем суточных суточного и декса власти китай суточный вот не скажу там примерно 100 гигабайт сзади набегает мы тратим почти все запросы но почти запросы которые уходят на backend то есть тазику мы не лагерным потому что ее очень много будет записей и они довольно бесполезны и все ну точно данных не скажу но допустим запрос сзади граф она выполняет примерно за 10 15 секунд запросы за неделю примерно до минуты то есть принципе время терпимые но похоже вопросов больше нет спасибо за внимание"
}