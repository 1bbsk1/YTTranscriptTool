{
  "video_id": "5hWdlg_S07U",
  "channel": "HighLoadChannel",
  "title": "Проблемы измерения производительности Erlang-приложения / Ренат Идрисов (MachineZone)",
  "views": 339,
  "duration": 2044,
  "published": "2017-04-10T03:40:46-07:00",
  "text": "большое спасибо тем кто остался значит мой доклад про проблемы измерения правительстве талант приложения я как уже сказали из компании машин зон и у нас ну одни из самых крупнейших игровых миров но то о чем я сегодня расскажу будет относиться к опыту создание open source нова бенчмарка который мы пилим тоже вот и пусть вас не пугает слово ярланд название потому что большая часть доклада скорее всего будет относиться ну ко многим языкам не только карла нгу вот а контексте то есть какие у нас цифры что мы измеряем что мониторе то есть попробую объяснить и цифры снизу 10 квадрате рабочей станции это довольно таки просто я думаю все такую цифру себе легко могут представить миллион потоков это немножко сложнее то есть тут нужно вспоминать что ограничения 64000 портов в айпи и вы уже просто с одного ip адреса такое количество потоков не сможете создать не сможете использовать нужно навешивать дополнительное количество ip-адресов благо обычно там amazon это умеет добавляет айпи адреса и у вас получается создать такое количество допустим сложнее продемонстрировать цифру 100 миллионов ну можно сравнить например с населением москвы если считать что в москве 15 миллионов то каждый москвич должен кликнуть примерно 7 1 секунду что получилось такое количество запрос это довольно много вот и доклад как раз о том как адекватно мониторить такую систему вот проблемы с измерениями которых я бы хотел поговорить я разделил на две части то есть это адекватность самих измерений то есть есть такие измерения которые просто портят систему то классический пример допустим импульс квантовой механики когда вы берете измеряете его на систему уже не такая как была раньше ну и для тех кто пустим кто далек от квантовой механике это например масса частей здорового человека то есть как только вы разделяете человека на части он перед дай быть здоровым и непонятно какой какого веса у него были отдельные части вот и другу другой класс проблем это адекватность от обработки допустим вы измерили температуру у людей очень хорошо и измерили очень правильно но затем взяли усреднение например и вы потеряли ну собственно говоря всю информацию но возможно и это именно то что вам было нужно то есть зависит конечно от ситуации вот и первая часть доклада про измерения времени но это время естественно не такое как абсолютная дата там день недели там или что-то еще это измерение каких-то временных промежутков то есть например система получила запрос как-то она на него отреагировала вот и вы даже когда речь не идет о колоде а когда допустим там сотни две сотни событий каких то вы их не можете вот так вот просто просмотреть и все решить но это довольно сложно то есть когда человек анализирует данные ему хочется иметь одну там но может быть пять цифр каких-то ну и понятно что первое приходит в голову это средняя средняя плохой классический плохой пример как бы на нем сильно не будем задерживаться есть минимум и максимум то есть узнав какая у вас там температура где-то в больнице максимально вы тоже что-то получаете но вы не узнаете сколько например там больных людей или там еще какие-то детали распределения вот ну есть такая штука которая уже много говорили здесь на конференции это пирсинг или квантили грубо говоря это такой уровень который не превышается заданном проценте выборки ну и я решил это продемонстрировать чтобы показать что происходит когда берем пирсинг или например то есть вот такая выборка с несколькими выбросами и есть среднее тут можно увидеть что средняя на самом деле не относятся ни к какому из результатов то есть она больше чем большинство результатов но меньше чем вот эти выбросы последнего вы естественно не узнаете что они вообще есть но я не говорю что средние нельзя совершенно использовать то есть его нужно использовать иногда но нужно при этом знать как что она дает 50 проценты пирсинг или это то значение которое не превышается в половине вашей выборки то есть видно что половина выборки где-то легла под панетта значение обычная еще измеряют 75-процентный пирсе тилль он также может съесть ваши выбросы ну и 95 процентный пирсинг или например 99 процентный персен теле и большие компании любят бороться за 999 персен тилль это ну собственно значение которое не превышается на 99,9 процентов вашей выборки то есть amazon например борется за него дальше если добавлять девятки кто то считает что но это оправданно экономически кто то считает что нет вот плюс ко всему когда у вас данных становится действительно много ну там миллионы какие-то там не миллиарды вам довольно сложно их адекватно посчитать ну то есть даже даже вычислить пирсинг или нужно пробежаться по всем данным каким-то алгоритмом там может быть параллельным это все довольно сложно поэтому в большинстве случаев используют simply рование сэмплирования это просто выделение подвыборки какой-то по которой значит вы вычисляете вот значение которое вам интересно как работает сэмплирование я как раз сейчас продемонстрировать то есть есть например какие то события которые но неравномерно распределены по времени то есть вот здесь на девятой секунде больше всего событий на 8 поменьше но и в первых секундах довольно мало то есть если посмотреть распределение по времени это будет примерно так ну и первый способ такой самый простой который я бы хотел показать это кольцевой буфер то есть первое что приходит на ум берем какое-то количество событий запихиваем буфер как только приходит новое то убираем оттуда самая старая и тут у нас примере например 15 событий вот это на 4 секунды это на 8 секунды то есть мы конечно не потеряли там минимум максимум они вроде где-то близко на относится к нашим событиям но тем не менее мы потеряли очень много информации о данных которые были на между собственно 8 секунды и 4 вот что мы видим на двенадцатой секунде тут мы теряем минимум максимум тоже как бы плохо вот и на последней секунде мы еще и забираем события которые ну которые собственно не относится к тому временному промежутку который нам интересен то есть мы как какие-то данные берем из предыдущих секунд потому что просто в это время не было нужных событий вот собственно это происходит когда пользуются сэмплирование плюс можно конечно использовать окно в секундах то есть это примерно такой же способ новый например берете мониторить и каждые 4 секунды и события храните за последние четыре секунды вроде бы у вас данные все становятся правильными но можно очень легко получить переполнение то есть если у вас начинает приходить очень очень много информации то у вас вот происходит такое то есть вы можете запросто превысить отведенную вам память ну и следующие секунды понятно как выглядит ну и на 16 секунде одно событие то есть самые адекватные но тем не менее опасный то есть вы когда возникает реальная нагрузка просто получаете там нехватку памяти какую-то кроме того что можно придумать можно случайно выбрасывать числа из выборки то есть то же самое количество событий например но выбрасывать не самая последняя а случайным образом тут для некоторых случаев этот способ дает выигрыш то есть в данном примере не очевидно чем он лучше то есть для 4 секунды мы также потеряли максимум не вам и для 12 секунды тоже но тем не менее у нас есть какой-то дополнительный случайный фактор который нам позволяет некоторых случаях не терять данные вот еще есть такой способ когда добавляется время то есть мы не просто используем случайная а мы еще учитываем время когда приходят это событие добавляем вот такую формулу есть такие можете почитать о том почему этот способ лучше он действительно лучше на некоторых данных и вот на этих данных он оказывается лучше вот здесь мы конечно тоже потеряли минимум максимум но тем ни менее данные более распределены по секунде и вот эта формула которую вы видите в правом верхнем углу слайда это вот как раз число которое считается ранд это случайное число от нуля до единицы для каждого события вычисляется вот эта величина и они по у порядок упорядочиваются по ней и соответственно выкидывается самое меньшее ну как бы вот что мы видим на двенадцатой секунде например и на 16 естественно из-за того что событий мало мы захватываем все предыдущие как бы ну это довольно ожидаемо проблема вот в принципе любое сэмплирования какое бы вы ни придумали не будет работать на универсальных данных то есть всегда можно придумать будет выборку данных для которых будут включены ложные события неправильным образом почитается статистика и так далее то есть как бы проблема вот и самая известная библиотека это уже ланговая специфика фолсом которая собственно реализует большинство из от указанных видов сэмплирования базируется на етс2 синтез для людей которые не знакомы с эрланга мы это такая in memory база данных в ирландию хорошая штука по поводу неё это то что она поддерживает параллельную запись вот параллельно и чтение если вы задаете поддерживает там множество упорядоченное множество и все такое то есть по хорошему это то чего не должно быть функциональных языках это как раз таки мутабельные состояния то которые не любят функциональные программисты но тем не менее вот в ирландии большинство способов которыми люди пользуются завязаны так или иначе на этот и ds от фолсом поддерживает счетчики о которых мы поговорим дальше поддерживает истории одиночные значение и гистограммы гистограммы это вот как раз такая штука которая говорил время допустим какой-то набор значений с сэмплирования история это просто куча значений которые вы храните как они есть ну и одиночные значение это когда вам нужно что-то измерить и у вас ну например нету неравномерности в этих событиях то есть например вы измеряете загрузку циpкa и она приходит каждые 4 секунды каждые 4 секунды вы ее мониторить и и вам естественно не нужно там не пирсинг или не квантили просто нужно одно значение тогда вы используете просто одиночные значение все вот ну и он достаточно простой если будете пользоваться эрланга мы вам понадобится какой-то простой мониторинг то берете фолсом говорите создать метрику записать метрику все очень просто то есть получаете все так скажем из коробки вот но вы не получаете экспорта метрик это вот проблема то что вы не можете их отправитесь фолсом а сразу в графит или куда-нибудь стас д вам придется писать экспорт собственными руками но и я тут для того чтобы показать что библиотека доступно я привел ссылку на git хоп вот есть проблемы о которых может быть большинство не подозревает то есть есть ограничение во первых на количество это из таблиц если вы создаете фол сами метрики вам кажется что сколько бы у вас не было их пока они влезают память например все должно быть хорошо но нет вы выходите за 1400 такое магическое число которая задана в ирландии по умолчанию и у вас все падает как бы конечно это исправляется но в первый раз когда вы это находите но обычно люди не радуются вот есть потока опасность вот странная штука до в нашем современном мире до сих пор пишут потока опасные программу то есть я не говорю о том чтобы просто из нескольких потоков добавлять какие-то значения гистограмму если вы будете активно ее создавать и удалять то в конце концов вы попадете в такую ситуацию когда у вас она не создалось но процесс уже пытается в нее писать собственном и на это нарвались от тоже очень неприятная штука пришлось писать обертки вокруг фолз у морских и гистограмм для того чтобы он стал потока безопасный вот и такая странная штука блокирующая запись то есть если вы посмотрите исходники фол сумма там везде написано когда он создает это из таблицы right hand right bank ourense то есть по идее должна быть запись конкурентное но в исходниках в документации орландо написано что корда рецепт райт kong оренсе просто не применим то есть может быть они и описали еще в какие-то стародавние времена когда был старый long который это поддерживал но в современном эрланге это не дает ничего то есть они просто используют несовместимые опции может быть просто библиотека star а вот следующий библиотека это их за метр то есть у него гораздо больше вид видов гистограмм разных сэмплирование там под ваши данные и это вроде бы хорошо вы можете использовать также фалсо мужские все виды гистограмм все метрики то есть он просто включает фолсом вы можете все используют что там есть и вы можете просто задать свою метрику то есть если вы придумали какое-то там но дублирование например хитрая или у вас есть backend для метрики который очень-очень быстро эти числа запоминают то вы можете его прикрутить к экзамен торы и будете иметь накладные расходы в виде там вызовы методов не так много как бы вроде не такая проблема ой и он в отличии от фолсом поддерживает отправку в другие во внешней среды то есть графит стас д куда вы захотите вы можете это отправить этот как бы очень удобно вот но о проблемах немножко позже да то есть есть такая штука сейчас популярное hd гистограмм как раз это библиотека которая не использует сэмплирование о котором я говорил плохое то есть там используется пакетирования просто данные разделяются на диапазоны и запоминается для какого-то ну диапазона сколько было срабатывание то есть такая стандартная штука артель гистограмм хорош тем что он использует то что вы как бы использую тот факт что вы измеряете временные задержки то есть все остальные средства фолз он там их за метр ему не важно какие вы числа складывайте там отрицательные какие-то большие маленькие здесь учитывается то что есть разница между одной сотой и двумя сотами секунды например но нет разницы между 100 секундами плюс одна сотая 100 секунды 100 секунд плюс две сотых например то есть эти промежутки временные bucket и увеличиваются чем дальше от нуля тем больше но и нету отрицательных естественно времен за счет этого получается создать такое компактное представление для временной задержки в виде вектора и уже не терять какие-то пирсинг или но конечно округлять данные но тут как бы понятно что именно такой поправкой что во мне должно быть важно статам или 101 10 вот реализовано наноси для ерванд программистов это обычно плохая штука потому что когда вы используете какой-то сильный кот у себя в проекте он может уронить просто всю вашу ноду как бы но зато быстро работает и есть вторая проблема это то что планировщик с ним не очень хорошо работать то есть эрланга есть планировщик которые переключаются между задачами у него есть количество редукции которая может сделать процесс это количество операций грубо говоря вот и если вы вызываете какой-то сильный кот естественно он его по операциям не бьет он него идет как единая такой операции и в документации написано что ваш личный код должен быть очень очень быстрым иначе or long будет с ним плохо обращаться ну как бы есть такая проблема и вот ещё одна проблема нет потоковой безопасности вот странная штука прям вы если откроете документацию ордере гистограмм то написано не пробуйте использовать низких поток это вот в нашем многопоточное время очень странно но забегая вперед и хочу сказать что мы сделали свой форк который собственно использую этот атоме каунтер и добавили там несколько строчек немножко поменяли функции и стал работать несколько потоков но наверное стала работать медленнее вот какие я хотел показать числа эксперимент это складывание чисел разные гистограммы вот которые до этого перечислил это экзаменатор фолсом и hdr гистограмм в один и 300 потоков почему 300 но для того чтобы это число было просто гораздо больше чем количество ядер чтобы не влияли вот эти вот эффекты всякие два типа нот это c48 x-large есть такой тип на амазоне 36 ядерный и лаптоп ну просто мой ноутбук который на мокасин вот 20 запусков с последующим усилением и в принципе можете вот я думаю что после конференции будут доступны материала то есть можно скачать этот репозитории там есть ток который отмечает кот именно на момент холода 2015 но пока он никуда не ушел вот поэтому можете скачать допустим набрать мейк и посмотреть какие там получается у вас допустим цифры или просто посмотреть как я это измерял например вот результаты для одного потока здесь ничего такого сильно-сильно страшного нет то есть цифры довольно близкие 5 секунд на три миллиона операций там или шесть секунд это не так важно или 7 но ваш деньги 100 грамм существенно быстрее это как раз показывает то что будет если вы сделаете каунтер все например ну то есть будете вызывать ерлан галльским мифом вот интереснее становится когда 300 потоков то есть вот эта вот пунктирная линия которая здесь есть это примерно в районе пяти секунд я обозначил такое среднее между вот значениями которые были на предыдущем графике для того чтобы увидеть что некоторые в 300 потоков становится гораздо медленнее чем в однопоточный а некоторые быстрее то есть по-хорошему конечно мы ожидаем что она стала больше потоков все станет быстрее но вот оказывается что не всегда и очень любопытная разница между операционными системами потому что ну разные вызовы и ланга трансформируются в разные вызовы операционной системы за счет этого получается по-разному на макось ее на линуксе то есть вы допустим если что-то тестируете у себя на ноутбуке она может совершенно по-другому себя повести потом на линуксе это видно вот с дефолтным и экзамен русскими счетчиками то есть они стали быстрее на лаптопе но чудовищно медленнее просто на линуксе то есть тут как бы нет нет для этого какого-то красивого объяснения сейчас у меня это нужно копаться разбираться во что уж там превращаются эти вызовы но здесь видно что нужно использовать hdr гистограмм если у вас есть такой выбор он получается гораздо быстрее ну и я еще построил такой график как он деградирует с увеличением количества потоков то есть по оси x количество потоков и по оси y это время ну видно что на линуксе на самом деле вы когда увеличиваете количество потоков несмотря на то что ядерного почему то лучше не становится ну хотя бы не становится хуже это хорошо на macos и становится лучше но потом это все ну как бы потом главное не деградирует дальше я строить не стал больше пятнадцати до до 300 потому что там график примерно так же так же себя ведет уже не сильно интересно становится вот вторая часть то есть это это было про временные задержки еще можно измерять счетчики вам не всегда важно какие значения приходят иногда вам просто нужно знать что они пришли то есть у вас есть какие-то срабатывание вы считаете например вот самый такой straightforward способ который приходит на ум в ирландии вы знаете что есть именованные процессы с состоянием и можно к нему обращаться можно сделать процесс который у вас будет считать и обращаться к нему через день сервер кол это плохо потому что процессы которые будут его вызывать будут блокироваться и ну вы получите просто испортите просто то что измеряете вот есть другой способ без блокирования не блокирующий ся вызов сделать это еще хуже потому что вы переносите проблемы в другое место то есть у вас вы делаете кучу вызовов действительно с большого количества потоков логин сервер работает на одном ядре и у него просто переполняется mail box то есть это ген сервер каст это просто письма и серверу вот и если у вас много данных идет то вы их конечно посчитаете потом если допустим данные перестанут идти вы там на герреро миллион событий каких-то но если данные прибывают и прибывают вы просто упадете по нехватке памяти поэтому это очень плохо вот кроме того есть в и т с о которой я говорил встроенная функция счетчиков и она довольно хорошо работает на самом деле если считать через и теста вы можете писать с нескольких потоков он там как-то это внутри все обрабатывает и хорошая штука по поводу и теста что он поддерживает транзакции то есть вы можете сказать увидеть счетчик на 0 например а потом там уменьшена какое-то еще число и он вам будет выдавать какие значения были после увеличения например на ноль и это все производить итамар на то есть вы можете сбрасывать счетчики узнавать за одну операцию как бы хорошо вот кроме того есть соблазн если вы допустим часто хотите что-то считать очень много есть соблазн считать не все например а считать все с какой-то вероятностью то есть вероятности например одна сотая производить эти инкременты и тогда увеличив вот это число которое вы получили в конце на нас то вы как бы получаете результат но проблема возникает тогда когда у вас мало данных закон больших чисел конечно не работает увеличиваете настой получается к это чепуха вот какая разница то есть между библиотеками о которых я говорил то есть можно посмотреть что у экзо метр счетчики уже как бы гораздо быстрее приближается в принципе каждый гистограмм и здесь я еще привел результаты для хвостовой рекурсии это если вы просто увеличиваете но счетчик и рекурсивно вызываете допустим функцию то есть это так скажем такой предел которого но не получается достигнуть здесь следующее это длится 4 x large можно увидеть что для 300 потоков ничего плохого не происходит то есть как бы можно считать фолсом запросто там можно считать их за метром не обязательно для этого заморачиваться вставить hdr гистограмм или что-то еще и считать через них и как бы это не проблема вот для того чтобы реализовать сэмплирование наката про которые он говорил перед этим нужны случайные числа но и довольно часто у человека есть соблазн какой-нибудь рандом чик куда не запихать чтобы что не посчитать допустим как быстро работает гистограмма там складывать случайные числа но это потенциальная проблема потому что она до сказал про сэмплирование потенциальная проблема потому что случайные числа иногда приносит дополнительный лог сейчас покажу это на графиках и есть такое решение когда вы можете просто использовать время как случайное число если у вас много параллельных процессов вы например можете тут добавлять какой-то соль в брать хэш и число будет уже относительно случайно поэтому следующие графике я сравнивал кара случайные числа с ставим с темпами здесь в ирландии есть одна такая штука на которой бы я хотел обратить внимание ладно там вот рэндом ладно цельный рандом очень медленный на 30 на 300 потоках то есть он даже в идеальном случае если вот распределение между задачами так скажем хорошие он должен был быть такой же то есть тут объемы данных никак не поменялись вот и вы должны как бы теоретически получить те же самые числа но нет то есть цель нам рандоме вы получаете все гораздо хуже вот есть в ирландии такая функция этой лонг на у которая выдает упорядоченные таймс темпы то есть когда вы к ней обращаетесь вы вроде бы получаете просто время но на самом деле процесс сбора блокируется пока не перещёлкнет timestream до следующего то есть там не про и не пройдет 1 миллисекунду и поэтому как ни странно многие не знают и даже вот в известных библиотеках с vip сокетами часто используется этот эрланд на у который создает лог вы запускаете процесс на многоядерной машине и не получаете никакого ускорения то есть такая вот вроде бы очевидная но странная штука и здесь логарифмическая шкала поэтому пусть вас не пугает то что как-то данные вправо влево уходит вот еще одна тема это когда вы измеряете временную задержку вам иногда хочется посчитать разницу то есть разницу на разных состав но тут возникает в принципе тема довольно большая я так очень-очень поверхностно коснусь возникает ряд проблем то есть во первых у нас облака на docker их если у вас тоже докеры то вы знаете что вы не сможете поменять внутри докера время потому что время такой же как на хост машине нужно останавливать докер менять время на хвост машине запускать докер если вы начинаете обращаться conti перед мы тогда как то так сделали решили посчитать задержки и посмотреть какие у нас они получаются вроде бы все хорошо но каждый сервер допустим 330 серверов запустили эту команду каждый сервер случайным образом выбирает случайные сервер из пула и с ним сравнивает свое время то есть вы получаете разницу между каждым из ваших серверов с каким-то случайным сервером то есть это ничего не даёт кроме того если вы начинаете общаться с одним сервером в очень быстро получаете отказ от обслуживания он просто вам не говорить не какое время он говорит что у вас лимит и исчерпались вот и выход конечно собственный интерес сервера то есть мы в итоге подняли себе для того чтобы уменьшить задержки но лучше всего просто не считать не не сравнивать таймс темп с разных ростов это как бы железный способ и ну просто полностью синхронизовать времени получится там все равно будет какая-то погрешность вот кроме того даже если вы вы выбрали такое решение виде экзаменатора какого-нибудь фол самом которая вам считает пирсинг или на каждой ноги то есть вам хочется посчитать то что будет в кластере и отправлять сырые данные совершенно не вариант потому что данных очень много ну как бы если хайло то очень много данных и просто даже надо которые их обрабатывает загнется загнется сеть все будет плохо а если вы будете отправлять пирсинг или то вы просто потеряете информацию вот например что будет я привел пример есть две выборки вы берете пирсинг или вроде бы хорошо да сложение пирсе теле поделили пополам вроде бы тоже четверка получается но меняем вторую выборку вот таким образом например пирсинг или остается тем же самым но пирсинг итоговые выборки меняется потому что ну действительно как бы вы не считали как бы вы ни хитри ли там не учитывали вес то есть здесь даже просто одинаковое количество чисел в выборках самый простой способ самый простой случай то есть пирсинг или без характера распределения смержи но просто не получится то есть если вы будете это делать вы получите какие-то странные данные но и будет зависеть от того как ну как вы это реализовали если вы будете считать что у вас все ноды в кластере одинаковые то они станут неодинаковой но то есть будет какая-то больная но до который будет давать выбросы вы будете соответственно считать что все в порядке то есть эта проблема но сажде гистограмм которая использует как раз вектор вот такой собаки там такой проблемы нет ну что данные не теряются они уже сгруппированы и вот эти вектора можно отправлять и как бы суммировать но проблема в том что данные в дефолтные hdr гистограмме нельзя объединять ну как бы тоже почему-то не подумали как про многопоточность но мы сделали свой форк его можно тоже посмотрите вот собственно мораль такая да если у вас есть какое-то средство для измерения там засекание времени там или просто для счета нужно сначала проверить это само средство подходит ли она вашей системе не портит ли она вашу систему вот и потом уже измерять потому что иначе очень просто допустим измерить что то нет а вот собственно у меня все если есть вопросы буду рад ответить да да чем что может быть у амазона есть свои интеко сервера который можно использовать и может быть они лучше чем pull and bear да они скорее всего лучше но мы подняли свои как бы свои сервера еще лучше я думаю но как бы мы в итоге все таки не измеряем просто на на разных has так но на всякий случай потому что как бы есть сложности с учетом этих задержек и так далее ну да да скорее всего на зоновский луч спасибо за доклад а вы говорили что в итоге свою пилить и прочее не услышали вот это что for клюнули ордер киста графики 100 грамм до этого собственно но есть та ну то есть hdr гистограмму нас есть свой форк которые поддерживают во-первых многопоточную запись во вторых он поддерживает суммирование то есть можно взять вектор и сложить то что в оригинальном нет то есть это можно найти очень просто если надо набрать на на гитхабе слышь машин зон то там будет вот эти все репозитории с нашим бич марком и спортом hdr гистограммы там еще с другими штуками ну да то есть она доступна спасибо у нас как бы немного еще добавлю что такая вообще философия что быть марки должны быть открытыми для того чтобы люди ну как бы понимали откуда мы берем эти цифры вот поэтому быть парке мы open source то есть у нас есть свои технологии там передачи сообщений которые скрыты для того чтобы их люди не взломали но benchmark считается что если даже человек взломает то непонятно что с этого будет здравствуйте такой дурацкой просто не на может пропустила на какой версии эрланга все beach park делалось сейчас 17.5 ну да кстати это это не то что дурацкий вопрос на самом деле это хороший вопрос потому что я long now выкинули из 18 версии эрланга да там сделали другие функции да это действительно так есть потому что я с ним много проблем от он блокирует и 18 ирландии в гатчине да и то с семнадцатым эрланга вот ну там в 18 новой функции есть ну что ну если нет больше вопросов да большое спасибо что пришли"
}