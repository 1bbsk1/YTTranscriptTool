{
  "video_id": "mRUpfLxmo40",
  "channel": "HighLoadChannel",
  "title": "Тестирование производительности с нуля / Руслан Зиганшин (РНКО «Платежный Центр»)",
  "views": 1635,
  "duration": 2698,
  "published": "2019-01-14T00:13:25-08:00",
  "text": "меня зовут руслан и я занимаюсь поиском и устранением тофу инфраструктуры а также и оптимизации развития развитием в расчетной небанковской кредитной организации платежные центах моя организация является оператором и расчетным центром платежной системы золотая корона и выполняют функции межбанковского расчетного центра для федеральная система город в своем докладе я расскажу вам несколько историй о том каким образом развивалась зови сдалась наша такая маленькая сага о том как мы начинали тестировать производительность в целом в современном же мире ничего не стоит на месте у нас каждый день тысяча десятки тысяч изменений не только в нашей жизни но и в тех приложениях которые мы с вами разрабатываем сопровождаем эксплуатируем производим мы упускаем далеке светлый путь и соответственно они не являются тому исключением и есть масса вопросов которые наряду с тем насколько правильно корректно работает этот код который мы произвели появляются на передний план выходят вопросы связанные с производительностью этого кода почему первый аспект первый аспект самый главный когда мы что-то пишем что-то меняем в коде один из самых важных вопросов это вопрос связанный с тем как наши изменения повлияют на на приложение мы на самом деле когда все начиналось об этом не думали вообще пока один маленький такой нехороший пример нас не заставил встрепенуться и начать уже как-то копать ребята делали бизнес попросил сделали вставку на мне небольшую три строчки кода сделали добавили библиотеку которая занимается постингом документов которые приходят на мы у нас просто центр постинга большое количество интеграции документы приходят у нас перевариваются и уходит соответственных результат ребят оставили буквально там небольшой малюсенькую ставочку и так потихоньку я смотрю у меня только тесты попал только чуть не то смотрим время увеличилось то есть вот это вот маленькая вставочка номинальное время было где-то около трех мире секунд ну ребята советует ставочка добавили 0 8 миллисекунд ставочка занималась тем что готовила там такой же маленький небольшой отчет для бизнеса которые они попросили ну так как вы и меня небу они вставили у библиотеку и соответственно не протестировали а протестировать как ну обычно разработка ведется жена в базах которые далеки от продакшена и по объему данных и собственно по составу этих данных и соответственно протестировать это никак невозможно соответственно этот вопрос мы стали себе задавать второй вопрос а что будет если вдруг наши клиенты все разом начнут выполнять какие-то большие тяжелые мощные операции как наша система отреагируют на это как долго она проживет это второй вопрос который ну наверно каждый кто занимается он даже не то что highload система вообще любыми системами себе задает третий вопрос третий вопрос он вытекает из 2 это насколько наши аппаратная платформа хватит чтобы сопровождать наши потребности то есть на сколько ее можно масштабировать по текущей конфигурации а после того как мы получаем ответ на этот вопрос возникает четвертый вопрос в каком объеме и сколько нам что покупать то есть бюджетом в любом случае не безграничны деньги нам никто просто так не дает их надо в любом случае ну нам имеется ввиду не только нам но и всем наверное не редко встречал организации где деньги тратят на право и налево бездумно ну не только найти его собственно как раз на этот вопрос ответить мы получаем некий ника и обоснование каким образом можно нам и что наращивать как соответственно руководство это принимает или не принимает там затаиться начинаются переговоры ну собственно теперь к самой теме ближе к самому топику расскажу вам четыре истории как я уже говорил первая история она довольно-таки ставя связано нас одним нашим дружественным процессингом это дистанционное банковское обслуживание в эта система вы наверно про неё слышали факту gaga проблема у нас называется по-разному называлось это она суть бывающие в 12-м и 13-м году он достаточно давно вот я как раз пришел работать woven кого это была проблема номер один с которой кто-то нас просто вот в таком мандраж водилам этом ночами не спали думали что делать как соответственно было непонятно на народ народу было мало собирали эти методики думали как а собственно в чем сама проблема то проблема в том что когда наступает новый год и заканчиваются новогодние праздники клиенты начинают хотеть выписку и хотят они эту выписку там за очень большой промежуток времени и очень большое количество клиентов это приводило к коллапсу почему этот коллапс был не только в том что выписка долго отдавалась еще полбеды беда была в том что она оказывала грубо говоря негативное влияние на водке на остальной функционал соответственно такой расклад никого не устраивал у нас было чуть меньше года и мы начали думать чё нам делать соответственно для того чтобы понять что нам делать надо поесть и какую-то тестирование чтобы понять насколько вот какую максимальную нагрузку мы сможем обработать если где-то есть какой-то затык его каким-то образом там отыскать соответственно локализовать и устранить первый момент из искали я уже говорил приложение различные опыта малая тестирование производительности ну занимался там немножко в основном там больше на базах которые там никакого у нас используется священнику системы цветы банк на базе oracle и у нас в общем ничего не получилось мы ничего не нашли это был какой-то казус наступил сентябрь месяц учитывая то что ребята которые нам могли помочь они не входят в нашу разработку они где-то рядом и соответственно год а делается заранее мы долго думали и вспомнили замечательный предмет там несколько предметов то чему нас учили ванию сетей те решили сделать ну чем совсем ничего сделали такой грубо говоря расчет на бумажке то есть в чем заключалась этот чем заключалась эта расчет мы решили узнать какое время сейчас а система голая ничего нету то есть как вот понять вот сколько у нас сейчас документы обрабатываются вот эти отдам его путем документов там несколько типов различных приходит время обработки них соответственно разная для разных типов и могут быть еще несколько состояний ну там понятно ошибка там какие-нибудь еще промежуточные и соответственно из них нужно как то сделать эти выборки чем сделали в общем взяли изучили приложение приложение было ну для меня очень много богатом коллеги мне помогли мы нашли где что хранится какие даты и нам повезло там хранилась зато на тему обработки каждого экземпляра это окончание чем мы сделали мы сделали выборки разрезе типов и в разрезе аж в состоянии и взяли этом среднее время по экземпляру вот это все согревали собрали получилась большая толстая excel к ну на самом деле можно было mathcad matlab заре тёщи куда угодно ну вот мы нам надо было быстро мы завели в excel но тем более там откат matlab они денег стоят нас с этим строго все с лицензированием нельзя был пустяк поставить и соответственно в следующим шагом было получение очень глупо очень неотесанной функциональной зависимости на основе этих данных и а на основании того функциональная зависимость количества вот для каждого типа экземпляров естественно то есть любых к напомним было в разрезе них получили функциональную зависимость функциональная зависимость времени обработки от количества это очень глупо неотёсанное мы подставили там большое пиковое значение даже больше но тем ожидали получили время средняя но у нас устраивающие и на основании этого там мы сделали пару доработок ну фактически как бы наверное почти не почти не ошиблись нам повезло то есть там полиномиальная зависимость получилось танку то там многочлен там в восьмой степени что ли не буду делать и соответственно вот папа учили пике все хорошо ну в целом руководство это устроила мы показали за счет обосновали его сказали что вот для того чтобы трудозатраты такие вот нужны мод не много времени потратили такой результат получили это первая история подведем ее маленький итоги достоинство этого метода вот он называется в excel кино своди ну там на бумажке он назывался в первой версии достоинства безусловно быстрый результат нам написали можно написать там запросы доставить данные каким угодно способом как хотите там она все это легко изымается агрегируются и получается там какая-то цифра ну трудозатраты там при быстром результате они просто минимальные то есть метод ну наверно там кажется изначально ну достаточно простым наверно можно им пользоваться когда-то но есть нюанс все достоинства перекрывает низкая точность то есть мы получили мы полиномы что я потом исследовал более сложной зависимости например есть такой объект как расшифровка выписки и и время формирования зависит от количества движения по счету движения по счету то количество операций по счету и вот там нифига не получилось вывести соответственно метод он ушел в утиль собственно из этого ограничения в применении ну и такой вывод что профит от методики ну там чуть больше там чем никакой на самом деле как бы скрепя сердцем чтобы не лукавить использовали мы его один раз у нас было решение технологическая которая там подписывает документы документы там выгружаются в конце подписываются накладываются подпись бухгалтера и коллеги нам предложили альтернативный вариант могут также на бумажке посчитали поняли что профитом одинаковые сказали не ребят у нас вот на внедрение уйдет столько датчика часов и она там ну чуть чуть лучше где-то чуть хуже там в целом там плюс минус также вторая история вторая история уже была более интересная у нас начало расти база коллеги начали бить тревогу чё делать решили разделить таблицы на секция но как бы неправильно что ещё можно сделать из доступные способы фактически вот то что нам досталось и закрались смутные сомнения а как оно будет работать мы подумали поняли что нам нужно получить какой-то более точно результате им на бумажке на бумажке как бы такие процесс не считаются расстроились подумали поняли что надо как то что более серьезное придумать я пошел к разработчикам мы сели посидели я уже упоминал коллегу андрей если ты сейчас меня смотрит сам 2 гады сапожков привет спасибо тебе это очень тоже помог мне в этом вопросе мы посидели подумали и решили что нам надо брать какую-то нагрузку какую-то с продакшена каким-то образом или захватывать проигрывать делать изменения и еще раз проигрывать результаты сравнивать то есть был больше до всего не додумались то сделать стоит поправку на то что мы опыта у нас было мало но вот это вот где-то прочитали где-то что-то кто-то подсказал им и больше ли пустить это дело в продакшен но тут опять же есть такой момент чтобы что-то с чем-то сравнивать нужно понять насколько эффективно вот цвета синтетическая нагрузка собрано а для этого для этого должны быть какие-то значения номинальные с которыми можно будет потом сравнить первый прогон первый прогон это прогон допустим ne nuzno продакшне же никто не будет прогонять будут прогонять на какой-то бдсм где там какие-то данные есть может быть синтетически может быть там это будет копия продакшена несет есть такая возможность позволить но не все могут к сожалению и нам пришлось заниматься расчетом внедрением этих показателей тут вот с показателями случилась такая беда что но не все можно было там посчитать участь мы посчитали запросами у нас слава богу есть функционал который также пишет то есть мы по аналогии сделали у нас выходит документ есть время начала его обработки есть история его состояния это вот очень интересная и есть там завершение в обработке на основе этого мы там почитали сказали вот у нас там для проводки время например там опять миллисекунд ну там 05 микросекунд например для там проверки там шесть микросекунд там для проводки и для еще каких-то там процессов столько то это зафиксировать сказали вот мы с этим живем и здесь параллельно я должен был выступать с одним докладом он ушел на осенью там мы внедрили измерения если хотите я сейчас их затрагивать не буду то есть фактически двух словах скажу мы откладывали код вот процесс и есть которые у нас выполняются до в системе то есть они в виде кода реализованы этот несет определенно там cut шаг мы их обкладывали фиксировали в таблицы таблицы журнал измерения то есть там тоже высчитывали сравнивали наши силы с этим вот всё дальше сделали коллеги мне буквально за пару дней гарри завали операцию которая захватывала какой-то объем документов там за определенное количество дней с продакшена то есть фактически у нас система устроена так что работаем мы на интеграцию нас данные приходят обрабатываются и уходит соответственно вот нагрузка исходная она ну опять же она до неполная то здесь не надо завиваться это плохо мы взяли вот и и залили там сделали две копии базы там на которых данных не было тоже каких-то там в тесте просто быстро там на скорую руку обработали это все получили какие-то цифры сравнили время обработки и потерпели фиаско почему так случилось почему потерпели фиаско во первых когда мы собирали эту нагрузку никто не задумывался но опять же поправка на неопытность о чем мы будем тестировать от какой вид тестирование мы будем проводить то есть чем будем тестировать просто что-то да какое-то направление ветку функционала тестировать нагрузку вот или тестировать нагрузка либо тестировать доступна система сколько она продержится либо проводить какой-то стресс тестирование соответственно написали такую операцию что-то там собрали что ты обработали что-то по утере вот для того чтобы нагрузка была оправе ну как бы чтобы результат получился корректном нужно понимать что вы будете делать то есть какой то от этого зависит первую очередь полнота нагрузки вот второй такой аспект нужно понимать что объят на объять нельзя если вы будете выгружать вообще все подряд то есть все тут синтетическую нагрузку либо и и генерировать это это может быть что это может быть какие-то данные которые у вас приходят в систему то есть вы ее вы вы вы вы берете заливаете там с одной базу на другой вы кушаете либо это может быть например вы берете запускаете какие-то операции заранее знаю там время их работы и запускаете их там на разных базах там автоматически или вручную то есть как получится и здесь вот надо отдать должность что нужно не брать все подряд определяться только с важным критическим функционалом недавно иван шагов и выступал там вчера буквально он сказал очень такую хорошую вещь мне она понравилась что вот есть пользовательские какие то есть критические операции есть операции некритически то здесь уже это все решается индивидуально там на уровне либо силуэтом с бизнесом вы договариваетесь либо сами там определяете потом согласовываете но любом случае лишние вы отсеиваете объем должен быть такой зависит именно от тестирования то есть вы хотите проводить стресс то берите все понятно если вам на какой-то кусочек протестировать например функционала то вы берете только вот эту часть потому что ну чтобы не будет у даем к и не ждать долго третий аспект это интенсивность опять же зависит то есть как погонять нагрузка либо вы прогоняете и один к одному соответственно у вас он запускается она отрабатывает так же как на продакшен если вам нужны результаты которые примерно там коррелируют пропорционально но при условии что у вас там это следующий будет аспект либо вы берете и нагрузку масштабируете там в меньшую ну обычно нагрузку никто не растягивает по что он зачем это делает но как нам бессмысленно вот сжимать ее для того чтобы получить там какой-то резкий удар там всплеск это дает пожалуйста это можно делать это хорошо получается вот их али важный аспект холивар на с которым мы долго спорили там постоянно это вечный спор какая должна быть площадка под тестирования производительности у нас мы долго очень думали в итоге что сделали первоначально для синтетики но и вообще для тестирования производительности у на железо разница то есть для продакшена и для теста железо оно там никакими коэффициентами то есть в умных книжках пишут 5 но мне там приносили да ты чего вот же написано там коэффициенты гу ребята хотите коэффициент как я вы чувствуют допустим два массива hitachi g800 и hitachi g 1500 там какой у них коэффициент да бог его знает я не знаю там никогда не вычислить его что потом как-то вот эти данные томск увиливать сказать ага что 2 микросекунды на мои стендовой б.д. это в 5 раз больше чем на продакшене соответственно продавшие но будет где-то также то есть ну вот здесь в идеале наверно конечно чтобы железо но как-то было более или менее одинаковое либо либо как вы можете сделать либо не сравнивать с продакшеном то есть стоит какой-то комплекс с одинаковым железом поднимать 2gd например с одинаковой конфигурации для виртуальной машины то есть у вас есть 2 таких площадке первая площадка этого все что ваша для тестирования да да изменений то есть вы туда заливаете база там создаете нагрузку какую-то вот все что делать авторов после изменения она должна быть такая же потом туда нагрузку подаете уже сравниваете их можно там автоматизировать обвинить этом базы под былинку вот и соответственно уже и поменять хоть и вот кстати по синтетическую нагрузку хотя речь идет там про авакова на самом деле синтетическую нагрузку можно генерить и для других субд этом мы не только для сободы этом вот как вот получится то есть пользоваться этими же аспектами подведем итоги каковы достоинства но при условии что это все собрано правильно то есть выполняется то что говорили там о чем на предыдущем слайде то есть это все у вас продумано понимаете что делаете это достаточно высокая точность результата то есть у нас мы сравнивали с продакшеном до результата не коррелируют то есть вот по и тестирование версии мы на самом деле были удивлены до 100 было внезапно когда вот мы собрали то есть ну наверное глупо звучит со специалиста но мы удивились то есть что правда то правда безусловно очень хороший плюс это масштабирование нагрузки нагрузка мы можем масштабировать в большую сторону для того чтобы проводить там какие-то стресс тестирования проводить там тестирование доступности но для нас это будет прям замечательно то есть хороший момент одну того затраты при условии что у вас уже механизм реализованы отлажен они тоже не великие в принципе то есть не туда страты какие на то чтобы разворачивать этот стенд но не вопрос есть всякие средства continuous integration которые можно там подвязать взять тот же там ansi был там дженкинс объединить это все и таскать эту нагрузку туда-сюда там в том числе из продакшена зависит от вашей женской структура теперь о недостатках ну на пилонах для того чтобы синтетическая нагрузка работала то чтобы можно было пользоваться нужны какие-то начальные стартовые затраты достаток он один ну нужно просто ложиться маленько реализовать вот этот вот механизм ну и соответственно продумать какие у вас будут временная силы на самом деле это не так страшно то есть можно взять какие то времена вычисли вычислить аналитическими методами и взять их за основу то есть это нормальная практика в этом нет ничего такого то есть это потом все согласовывается вот и поэтому как резюме ну методика наиболее точно нам нравится мы эту методику очень любим на самом деле нам дает наибольший профит у нас 3 стоя на несколько большая она связана с инструментом который интегрирован в дтп с этого кого апликэйшен testing и в первую очередь там то что называется tbs реплей ну с учётом опыта да что мы внедрили синтетическую нагрузку на вот приходит и говорит ребята ну и же дабы play давайте вот мы эту нагрузку будем там не какой-то операции мифическое собиратель разрабатывать и животном хорошая замечательная вещь мы эту вещь возьмем развернем нагрузку с соберем прогоне мы все и будь счастья сказано сделано познакомились том почитали прогнали эту нагрузку собрали ее там sampo путем собрали там какой-то день вообще то что там какую попало там ну лишь бы это все посчитать пригрели эту нагрузку откалибровали там получается запускается в чем-то но мне понравилось надо брать эти в акции клиенты выход клиент который бегут эти файлы запускают и соответственно работали сгенерировали отчеты получили и вообще очень могучий и связано это с тем что у нас инструмент использовался для системы цветы банк подсыпьте банк тоже уже рассказывали напомню маленько там есть технологическое двое вот такая беда что когда вот эти в акции клиенты запускаются начиная тут нагрузку проигрывать должна регистрироваться сессия в технологическом и 2 там и вот это вот не произошло если там сессия не регистрируются то все отваливается здесь у нас вся вот это все пошло прахом мы расстроились клавиши w пой она мне подходит второй инструмент нас привлёк больше это искали performance on a loser секунд и хёнсына возник прошу прощения вкратце не буду на самом деле кстати если говорить про апликэйшен testing можно наверно попробуйте реализовать подобный механизм но вырисовывать его надо так для других субд e чтобы эта нагрузка собиралась независимо то есть чтобы не было там как бы там есть фильтр с этим фильтром и тяжело работает достаточно то есть там его надо настраивать он только трехэтажный вот по недостатки чуть там попозже расскажу вот теперь по и скрытых о максе культов антоновой за все клипы фон снова замечательная вещь вот вы собираете культа нагрузку но виде запросов эти запроса там либо прогоняете на продакшене говорите что это до изменения там делаете копию продакшена применяйте эти изменения берете еще раз прогоняете эти запросы получаете отчеты которые там сравнивают вам либо планы выполнения то есть там видите ага вот такой план был долго такое план состава после и уже потом если что-то расходится есть там такое как бы эмуляция выполнение то есть она вроде как запускается что-то делает и в эти характеристики там и лап считаем там буфер get сама все высчитывается тоже сравнивается мы это все повторили все это дело с генерировали ну на самом деле все пошло гораздо более гладко этот инструмент нам помог когда мы у нас было два апгрейда 1 апгрейт это с1 с2 03 дпс ставили пасу 1204 там был один маленький момент который мы поймали поведение с битве нам то есть там есть такая конструкция интересная там когда больше либо равно меньше либо равно интервал и у нас ребята сказали там уж прогрессивные люди давайте between напишем between написали он деградировал почему почему я не знал бога на cайт вот собственно тут он пошел более гладко нам понравился этот инструмент мы успешно задействовали по миграции на 12 сил у нас сейчас эксплуатируется 12 102 спасу в 1701 17 наиболее там удачен которым шел вот тут опять же когда вы будете готовить тут есть аспекты есть эти аспекты не выполняют то путь будь фиаско в общем и эта связка моноколесе на самом деле изначально когда заклад готов и хотела сказать как у нас все хорошо получилось чтобы там народ не пугать не как-то не отлаживать от этого дела тут какой момент есть план выполнения запросов зависит от двух вещей это системная статистика и эта статистика оптимизатора вот статистика оптимизатора может быть и системная статистика собрано с продакшна то есть мобильном маленькая так обманываем базу то есть у нас вот есть такая пустая маленькая база вот на которую мы тащим вот эти наборы для того чтобы прогнать у нас всегда не позволяет до возможность мы эту статистику переносим и у нас получается вроде как что данных в таблицах столько же там сколько на годовщину такой вот небольшой find и соответственно когда эти планы генерации они опираются на тут статистику но иногда не пока ты это не прокатывает когда уст активные fete включенного с адаптивная сетями вот тут-то на лису но все просто я сейчас занимаюсь тоже у меня там куча отчетов мы с акционерным там еще одну систему и богато по таблице у меня чистому такая свистопляска с адаптивными фичами у меня вот все эти отчеты поехали потому что он видит что база меньше и соответственно уже начинает там не все пути он был давать когда вы отчеты получаете в первую очередь опирайтесь на плана запросов при прогоне то есть планы запросов самое важное сети на плоскости например или на москву можно тоже реализовать такую методику когда у вас вы вы собираете какие-то там запросы с продакшена там их эмулируется выполнять их генерить и планы сравнивать ага вот у меня был план такой довод он такой букву после вот после того как плана вы посмотрели есть у вас идет какое-то расхождение дикая вам непонятно то уже надо запускать и поверять как она получается ну что сказать достоинства да тоже высокая точность но при условии выполнения вот этих вот обхода вот этих грабли на которых мы наступили то есть это все то что мы там собрали и вот старался так немножко объединить ну это грехом волков это и плюс и минус другой стороны потому что интер посидишь а денежку стоит то есть но опять же можно там схитрить и с тем же о как он там на standard edition тоже делали там такие вот кита приблуды не только трудозатраты да тоже низкие она всё легко собирается легко запускается все огонь все нравится вот нагрузка тоже собирается в 315 там главное только чтобы она была осмысленна это нагрузка нагрузка берется из курсов каша из отчетов и может собираться там течение какого-то периода там делается с и уже потом агрегируются ну из недостатков понятно что если у вас есть какие-то обстоятельства то есть например и те которые причислял то чет становится анализировать сложно вот самое главное если текст запроса поменяла сеть не работает то есть если вы версию обновили вот так вот его пытается проверить это не прокатит то есть это не для этого инструмент вот соответственно очень хорошо такую методику использовать при апгрейде базы или если вы хотите параметры какие-то субботы поменять там палочку или 1 и проверить как оно там будет вот 4 истории это маленькое оправдание дата близки по я тут все то же самое то есть нагрузка собранно прогнан а и применено вот очень хорошо этот метод пошел но на второй системе где прослойки нету технологической и здесь мы уже стресс тестирования нового железа проводили у нас ребята очень устали им купили новый сервер вот решили то цели сразу испытать сколько он там выдержит вот использовали как раз data base happy когда вот эта нагрузка была не синтетическая какая-то собранно апостол пока вот сама отдавая у нас мы вычисляли кстати смотрели по профилю нагрузка у нас она ну как бы ежедневно глаз наносим гель у повторяется сам адовый день это вторник вот взяли вторникова натравили сутки прогнали есть правда такой момент ну достоинств понятная интеграция нагрузка там легко получается есть масштабирования но нюанс чтобы нагрузку за грабить над базой стартануть а базовый стартануть никто не даст особо-то а если базу не стартовать можно попасть на незавершенную транзакцию вам полетит там куча ошибок когда вы будете посетят эти отчеты соответственно там может фигня поучиться по что уже было такое там народ да нафиг ты не будем и стартовать то вот все взяли там запустили готовит носишь просто но ограничение в применении понятно что не все приложения есть еще до высокие трудозатраты спору нет есть еще такой нюанс гадки немножко мы с ним сталкивались то ли это глюк я писал волок он у меня там что ответили тоже не помню уже когда в том что когда вы нагрузку начинаете прогонять 11 в 1 она у меня зависала несколько раз вот у меня день прошел второй день прошел третий день прошел мне приход год ну чё когда нагрузка про гонится я посмотрел гун учета вот гонится могут они прервали запустили заново опять у нас все отвалилась мы запустились масштабированием там с небольшим с коэффициентом 1 и 1 примерно там она прошла нормально почему там у слава богу там мы получили какие-то цифры вот очень такой вот единственная ситуация в которой рекомендую применять этот надо стресс-тестирование провести все вот больше наверное особо не подойдет вот эту только для стресса давайте теперь подведем небольшие итоги у зимы всего того что было сказано и так если вы хотите обновить или изменить конфигурацию базы данных вам подойдет либо синтетическая нагрузка либо и скрипов секунд приходится на вазе то есть когда вот тот инструмент когда вы собираете планы собираетесь запросы прогоняете их там на до и после сравнивайте плана два плана смотрите например сравнивать их стоимость вот можно там по стоимости сравнивать тут это ну где-то 9 тоже там это другие написать там по xix свой вот если вот там не урока у вас обновление приложение но синтетическая нагрузка безусловно это лучший вариант лучше мы пока ничего не нашли мы ее потихоньку расширяем эту синтетическую нагрузку объемы исследуем то есть у нас сам процесс не стоит на месте мы не считаем что закончили вот и соответственно до стресс тестирования синтетическая нагрузка безусловно однозначно лучший вариант ну иди the bass & play то есть не какой-то его аналог который вы хотите получить огромное вам еще раз спасибо за внимание я готов выслушать ваши вопросы а и да кстати у меня тоже будет два президента за самые лучшие вопросы из аудитории все и спасибо суши вас руслан спасибо за доклад у меня такой вопрос а может этот отмотать на один слайд назад а вот у меня вопрос по и сколь performance on a loser тут более менее понятно он записывает тексты запросов там запоминает иску или планы как работает дтп с реплей как он записывает эту нагрузку которая возникает смотрите дтп скп работают следующим образом то есть вы запускаете сбор и тайно гавайскому процесс капча она собирается файл и потом эти файлы вы должны куда-то загрузить а что представляет это записываемой нагрузка это изменение блоков не смотрите то есть у вас вот идет фактически но можно провести такую глупую аналогию с ну с завода журналами даже новыми транзакцию это очень грубо это не точно там самом деле идет бина xeno то есть смотреть вот эти файлы и в них идут все эти все все все что происходит последовательно а еще забыл нюанс там есть такой нюанс там есть такое когда вы воспроизводите там хоть и включается синхронный режим до что допустим вот у вас есть запись в эту запись начал atompub деятель а потом и за делитель и вот она в отличие там например журналов транзакции которые там аккумулируется она выполняется соответственно ну папа попал поможет может сместиться и это масштабирование не всегда работает то есть то взрывает на воспроизводить нагрузку с той позиции журнала транзакций откуда началась запись нагрузки на исходной да поэтому местах нужен то есть урока он говорит типа ребята не надо we start i чтобы у нас было фактически там база с нуля то есть мы включили процесс сбора нагрузки подняли базу то есть у нас взлетели наши нашу активность и началось все это писаться то есть прям вот как есть все что происходит сейчас говорит пишется на каме вот это в таком виде она отображается вот потом мы получаем файлы эти файлы они сливаются куда-то там на клиенты клиенты колебаются то есть надо поучить какое количество и запускается уже калибровка у него странно достаточно умет например был профиль в 20-25 активных сессий он нигде там бы те 4 клиента надо его как так ну как 4 то но я 4 запустил у меня четыре сессии получилось запустил 20 клиентов у меня профиль нагрузки пошел это же подмой я не знаю на самом деле понятно большое спасибо спасибо папа вёл в их нет кто-кто-кто кто кто еще раз спасибо за доклад вот я правильно потому что да это бы из реплеи тоже вот кто про что вы говорите что бинарные the right ahead лоб по сути вот или нет а не поняла то есть это это лак и каких-то высокоуровневых операция вот ну просто вот что что происходит базе вот что вижу то пишу вот вы его выбыл вот она в таком виде все записывается то есть все что происходит пользователь запускает там не знаю какой он там ерунду ну понятно фильтруется то ясно есть вот зависимость ну во-первых подготовки вот этого реплея ну то есть время подготовки вот время подготовки и но по месту как как зависит от размера базы от числа операции объем там достаточно небольшой получается вот этих файлов которые есть то есть мод сутки собирали сутки 400 мегабайт было ну у нас вторая база там она более высоко транзакционные там ну сколько полос людей ну наверно около так пытаюсь посчитать там на кого дах дах и доходило там до терабайта просто но соответственно 300 мегабайт висели вот эти файлы они немного на самом деле весят то есть как то она хитро записывается как то это аффект этот эффект на производительность особо не влияет а ну как бы ты мешать наводки который это наводок нету то есть она потребляет там около 1 2 процента ты колокол заявляет у себя говори что ребята там она очень мало кстати секунд пахомом снова зик тоже там почти не видно вот а быть это вы микрофон спасибо за club вопрос такой а по поводу синтетической нагрузки не совсем понятно в чем разница грубо говоря это что-то подобное своей реализации скелет прав у мастера или что другое а поподробнее какова методика сбора синтетики и прогоны в чем разница между перфомансом лазерами а сейчас расскажу то есть тут получается преимущество то того что делали локально но в том что мы собираем там все что хотим то есть вот то что нам надо без всяких без фильтров без ничего то есть у нас там лишнего нету эту нагрузку уже фильтровать не нужно то есть она уже готова это первый плюс во вторых она идет в нативном виде то есть нативном виде это как вот понимать допустим у вас есть документ есть система то есть ноутбук папа просто в другой теме на банковской системе документов там цыгана банковская система документ выходит обрабатывается и уходит и соответственно вот такую нагрузку и эпохи подогнать под бизнес процесс какое-то потому что она же как правило силуэтом бизнес говорит хочу чтобы документ системе там был ну максимум там вот есть бы fps показателей бесперебойности функционирования платежная система вот мы найти показатель бы в суд как раз ориентируемся тоже соответственно пони не превышали и этим она хороша эта нагрузка потому что мы вытаскиваем именно той скармливаем системе что в реале получается а когда собирается дтп если play там собирается вовсе все то есть и у и очень тяжко мусор оттуда доставать тут правда во первых доставать муса во вторых это все прогонять масштабировать это гораздо сложнее потому что мы документы масштабируем на правых документа как это можно хитро вот масштабе быть я загрузил 100 документов я могу обработать 1 минуту 1 документ допустим вы ставите время по уму время обработки реквизит а здесь я могу только коэффициент поставить сказать вот там коэффициент 2 там в два раза быстрее поганить а здесь я могу выставить уже эту нагрузку отмасштабировать так как мне надо то есть как она в реале обрабатывается от это бы с реплеев скую которую я вот так не смогу подогнать тонко мне сложнее будет потому что там реквизиты уже не задашь вот то что я собрал например то что то то то что я собрал то я и воспроизвел все то есть не больше не меньше к сожалению то что кинетическая груз как грубо говоря на уровне приложения работают на уровне до укрепив эмоционален это чистая и сквере без привязки к плите сельских бизнес-логика грубо говоря да а вас получается все таки это но фактически бутово приложение запустили на нее просто запыленной промежутке да это приложение которое эмулирует фактической нагрузку которая приходит то есть как будто у нас тут получается в системе работает ну вот мы и штатную работу система то есть не приносят туда какую-то доббин овчину там и и переваривает приносит он настоящий документ я сразу вижу что вот у меня документ я могу остановить то есть этот документ сделать с ним все что угодно то есть синтетическое нагрузки я ничего менять не могу то есть вот вот в этом и гибкость that нашего локального решения спасибо будьте добры микрофон добрый день такой вопрос ну я так понимаю генератор синтетической нагрузки вы сделали вот для компании это дорого или дешево на самом деле для нас для нас там ну сколько мы часов наверное 8 потратили генератор на самом деле простой вот если говорить честно то есть у нас есть там куча документов могу рассказать как это работает то есть есть документы есть определенные состояния да вот когда документ приходит систему ее состояние новые то есть и дальше он уже обрабатывать сама чуть сделали мы взяли эти документы написали операцию которой бегать документы меняет выгружают их файл загружен а загружая в систему меняют у них состояние на новые соответственно не обрабатывают с нуля но здесь в этом настройки должны быть соответствующие чтобы там дата а фигня попадала то есть деньги должны быть на счетах натянутом все прахом пойдет то есть вот в этом-то и беда то есть должны быть какие-то определенные на нас настройки системы еще вот вопрос относительно стоимости основного продукта вносятся изменения в основной продукт вот нужно изменение генераторе особо нет это у нас основная нагрузка то есть он так система спроектирована но наверное в некоторых случаях возможно придется допиливать генератор и очень даже возможно не вопрос именно вот в том оценка экспертная оценка вот там нас на изменение продукта требуется столько-то процентов если но один процент спасибо коллеги какие-то вопросы есть у готов на них ответить а кстати 222 президента это вам календарь спасибо большое вот и вам держите замечательный ежедневник каком от компании cvt пользуйтесь с удовольствием еще во всем спасибо большое за внимание мы благодарим вас за участие и за ваш интересный доклад"
}