{
  "video_id": "dm_oid1HVfQ",
  "channel": "HighLoadChannel",
  "title": "PostgreSQL: практические примеры оптимизации SQL-запросов /  Иван Фролков (Postgres Professional)",
  "views": 68370,
  "duration": 3057,
  "published": "2017-04-22T14:48:16-07:00",
  "text": "мы переходим так сказать к основному акту нашего морализм балета мы начинаем погрею секцию на которой я вас Рад всех приветствовать на правах рекламы Приходите на наш прогревы стенд мы раздаём пряники и разные всякие другие ништяки Ну а сегодня нас наше мероприятие открывает Иван обп и я как человек уже не первый год организующий конференции Мета с его участием могу вам совершенно чётко доложить что люди всегда в восторге и просто безмерно рады послушать тот материал который он предлагает Сегодня мы будем говорить про оптимизацию запросов Давайте поприветствуем Ивана коллеги добрый демео ком профессиональный и я в этой компании занимаюсь собственно говоря не разработкой базы данных а скажем так её применением то есть непосредственно пишу запросы и помогаю клиентам соответственно эти запросы оптимизировать смотреть что у них получается Какие проблемы надо сказать по большей части клиенты в общем-то достаточно однотипными достаточно простыми проблемами сталкиваются в то же время правда бывают такие люди у которых у самих не грех поучиться так там вывели мою презентацию развернуть вот сейчас м развернут Значит так развернули у которых самих не грех поучиться обычно у клиентов Ну по крайней мере то что до меня доходит проблема встаёт достаточно однотипная запрос работает плохо но на самом деле т другой вопрос Что значит Плохо что такое эффективный запрос это быстрый нуно какой быстрый время получения первой строки или время получения всего результата если немножко подумать то можно понять что для того чтобы обработать весь получить весь результат может потребоваться значительно больше времени чем для получения первой строки не всегда В некоторых случаях время достаточно Сравни Например если у нас есть сортировка и нету подходящего скажем так индекса или у нас есть группировка какая-то э ну там тоже в зависимости от группировка может выполняться по-разному К сожалению времени на выступления У меня очень мало мне задали значит тайминг 45 минут я честно говоря готов 45 минут рассказывать про просто сканирование таблиц Table Scan э тут сейчас придётся покрыть большой очень объём вопросов и в общем-то прошу понять извинить что достаточно глубоко вдаваться в каждый пункт У меня просто нет времени Итак значит что у нас быстрый быстрый Но как это оценить а нередко может оказаться Так что запросы работают примерно одинаково по времени но по результатам э скажем так массо ну параллельного выполнения результат может получиться разный Почему э ну в общем-то если мы будем оценивать не столько по времени выполнения хотя и По времени тоже но обратим внимание на накладные расходы которые возникают при выполнении запроса как то ну во-первых у нас как вы наверное знаете я повторю всё-таки на всякий случай Запрос который поступает на вход базе данных текстом сначала должен быть синтаксически разобран раз убедиться что все объекты на которые ссылаются этот запрос существует надо убедиться что права доступа У пользователя на эти объекты есть нужно построить оптимальный план и наконец его выполнить а каждый из этих этапов может носить некоторые задержки в большинстве случаев вот предварительный Вот соответственно все эти этапы то есть синтаксический разбор убеди в том что есть обекты и оптимизация в большинстве случаев Ну как большинстве процентов 80 наверное занимает относительно небольшое время большая часть занимает выполнение но надо сказать что есть случаи когда как раз первый этап занимает больше времени чем собственно само выполнение запроса это заст очень много тут есть такая небольшой така такая особенность что если вы пишете функцию в пост SQ на SQ и пишете эту функцию на psq и она собственно выполняет запрос возвращает результат так вот функция на окажется быстрее Ну естественно это будет иметь значение это будет заметно только в том случае если вы очень активно соответственно посылаете вызывайте эту функцию посылайте запрос нужный вот у меня тут есть небой приме чтобы уж совсем голословным не быть пример выполнения запроса по чем интересен тем что ну интересен например Oracle Да если попросить он даст не тот план который будет реально выполняться который он предполагает что будет чтобы реально посмотреть ну там можно конечно залезть сервер Посмотреть реальные планы пос Вам всегда вернёт тот именно план который будет выполняться более того можно его выполнить посмотреть резуль которые получились есть куда расти в плане мониторинга заправ в общем-то работы Что называется ведутся но на текущий момент ещё конечно не так хорошо как хотелось бы тем не менее Вот у меня здесь небольшой пример совсем простенько запроса который выбирает из журнала в общем-то бухгалтерских транзакций там транзакции определённого типа ну я не знаю кто-нибудь explain Anal в постс пускал о очень много Ну много-то много много И кто и не пускал Ну давайте для тех говорится кто не пускал попробую немножечко рассказать Итак У нас тут видно что идёт сканирование индекса по первичному ключу значит цена запроса начинается 0,56 - это время это цена получения одной строки стоимость в постгрес определяется таких странных попугаях вообще говоря это стоимость доступа к странице в памяти насколько я помню значит 858 - это ожидаемая стоимость получения последней строки всего ожидает он получить столько-то строк и ширина строки в байтах нередко ширину строки как-то пропускает Но вообще стоит обратить внимание если у вас много строк и вы их передаёте по сети куда-то вообще говоря это тоже не бесплатно и на это тоже уходит в общем-то вполне заметное время значит дальше в скобах в скобочках идёт актуальное время выполнения действительное это в миллисекундах задаётся Вот первая строчка была получена через 52 микросекунды Ну в реальности вы конечно это не увидите потому что 52 микросекунды - это то что получил экзектор когда первую строку когда он дое до клиента это в общем-то вопрос достаточно интересный Может конечно и очень долго ехать Ну и всего ушло Значит на всё это дело 2 С5 секунды 2000 миллисекунд значит дальше идёт у нас условие как преобразовал к можно посмотреть и очень интересный момент я просил expl Anal можно попросить и попросить статистику по обращению к буфера к буфера к памяти и к диску Ну в данном случае запрос честно говоря когда готовил презентацию пускал не первый раз всё уже прокисло и можно посмотреть что Ну кстати не всё прокисло я вас обманываю можно посмотреть что в шарит Hit - это то что было было получено из кэша столько-то просчитано столько-то буферов соответственно такое вот время выполнения это чисто для иллюстрации чтобы можно было понять о чём я буду говорить дальше общий принцип при выполнении запросов Когда вы хотите оптимизировать это Чем меньше данных тем лучше Чем меньше всего лучше вообще конечно оптимальнее всего будет работать база данных с одной колонкой с одной строкой в оди байт Вот она вот будет моментально работать Это конечно случай вырожденный но тем не менее стоит на это обратить внимание чем меньше данных тем тем у вас будет работать быстрее Почему будет работать быстрее у вас во-первых будет больше умеа в кэш Возможно у вас целиком база влезет в кэш обычно любит рассказывать про огромные базы данных но 90% баз данных небольшие Я думаю что тут у большинства честно говоря базы в общем-то не грандиозные более того за последнее время Ну как последнее за последние лет 10-20 очень скать выросли вычислительные мощности я хорошо помню когда таблица в 60 Мб считалась очень большой сейчас Эта таблица в общем-то просто никакая по размерам совсем маленькая Ну тогда как-то управлялись может быть и сейчас можно сейчас правда есть тенденция у людей раздувать объём данных что нужно что не нужно не очень хорошие типы данных подбирать об этом попозже чуть-чуть поговорю Ну вот Постарайтесь пожалуйста когда будете проектировать базу данных уменьшите её как можно больше база данных по-хорошему это не хранилище всё-таки Это для оперативной более-менее обработки для конкурентного доступа Ну и для более-менее удобного доступа из языка это не Big Data всё-таки это база данных э дальше Вторая проблема у людей возникает что они делают индексы на все случаи жизни которые есть и которые им кажутся учтите индексы тоже вещь не бесплат Когда вы обновляет которая меняет индекс у вас даже в общем случае без относительно постгрес Нужно обновить страницу с данными страницу в индекса и записать страницу в журнал причём ещё возможно две про индекс и про и про собственно таблицу с данными Чем больше индексов тем хуже индексы у вас сильно снижают время обновления Ну и в случае аварии время восстановления индексы должны быть только те которые нужны они на все случаи жизни которые вам возможно привидится много индексов Это всё-таки не очень хорошо инде долж быть только такие какие нужны ввод-вывод Чем меньше ввода-вывода опять же чем меньше данных тем у вас меньше проблем Чем меньше страниц имею в виду страниц которые получают доступ во время выполнения тем соответственно тоже лучше чем меньше блокировок тем лучше типовой случай запросы работают еле-еле сервер не нагружен нулевой Ну значит всё понятно у нас что-то чего-то блокируется надо сго блокируется есть два варианта по-хорошему говоря это кратковременные это не долговременные блокировки не которые возникают в процессе ирта или апдейта А который сервер берёт во время выполнения для того чтобы взять страницу на ней что-то там поправить найти и отдать её другим Чем меньше таких вещей тем тоже лучше опять же тоже стоит смотреть если у вас предположим база работает какие-то аналитические запросы раз в сутки приходят мы это наверное не так критично если у вас она какая-то активно онлайна обновляемая запрашиваемая это уже может быть проблемой надо сказать что в постгрес начиная с версии 9.2 вот по текущую 9.6 в плане борьбы с внутренними этими блокировками в общем-то заметный Прогресс был сделан дальше Вот ещё у меня случай был недавно были Клиенты у клиентов был тип уид вот мне тут сбили с панталыку честно говоря при подготовке презентации Ну 32 байта У меня написано они хранили уид в тексте у них было около колонок удов на таблиц получалось около 5 Гб Ну 5 Гб вроде бы немного но в тоже время люди обычно хотят за грош пятаков и денег вообще-то оплатить тоже не намерено с дополнительные возможности просто путём превращения из текстового уи в обычный погрей тип уи получилось уть в два раза Что стало с таблице таблица стал помещаться в кэш в результ запрос койни работа 4 секунды работать 400с п такая вот ве соответственно общий принцип когда вы будете рисовать таблицу проектировать базу данных жадничай Делайте как можно меньше Выбирайте типы поаккуратнее Ну смотрите конечно чтобы помещалось но как можно меньше другое дело что следует иметь в виду что у постгрес на каждую строчку 24 или 32 байта в зависимости архитектуры уходит скажем так служебных данных в общем в этом есть смысл подумать над тем чтобы иметь достаточно широкие строки Ну не совсем уж безумно широкие но достаточно К сожалению есть такие накладные расходы в тоже время даже если у вас там есть предположим 100 Милн строк и вы на байт меньше сделаете у вас будет на 100 МБА меньше в общем-то неплохо так один тип поменять и получается хорошо Так что вот очень рекомендую на это обращать внимание од условие поэто бы и сечас есть в принципе система резервирования отелей для курортов для туристов И к сожалению она была трёхуровневая страна регион отель И к сожалению в общем Тип тип курорта был указан на на всех трх уровнях они натыкались на такую проблему что когда Возникала задача найти подходящий соответственно подобрать тур они вынуждены были смотреть сразу в трх таблицах результат к сожалению это получалось сделать только после джоина в результате получалась достаточно грустная история у них полу выходило что-то около миллиона вариантов и под конкретные условия попадало буквально несколько штук обычно значит что получалось мы соединяли миллион строк и из них выбирали только две что тут можно было бы сделать тут опять же с запросами честно говоря не очень разбежимся конкретные признаки тогда можно было получить доступ по индексу и выбирать очень быстро соответственно при проектировании базы данных обращайте внимание на то как она будет использоваться с индексами у нас принцип в общем-то получается всё тот же чем меньше индексов и чем меньше индексы тем лучше у поса накладные расходы на на строку индекса по-моему 14 бай имейте в виду опять же не забывайте про выравнивание постгрес выравнивается это можно посмотреть в PG Type есть такая таблица служебная значит можно посмотреть на Границы выравнивания это в документации написано но в принципе там вполне ожидаемое выравнивание то есть инт который 32 бита выравнивается на границе 4 байта выравнивается на границу 8 байт dou тоже 8 байт Нарик по-моему на 4 байта выравнивается Вот кстати тоже надо быть очень аккуратным с нариком Если вы делаете таблицу с намери всегда указывайте точность можно налететь на такой случай что у вас там окажется очень большое значение к счастью или не к счастью в по имеет общем-то очень большую точность и вы легко можете сделать какие-то значения по килобайт размерам это в общем-то наверно не то что вы хотите обычно там деньги находятся в намери и вряд ли вам нужно с такой точностью с ещ хочу обратить внимание что иногда можно и без индексов В каких случаях это Можно например у вас есть не очень большая таблица Ну там наверное десятки миллионов строк максимум И вы по ней там раз в сутки пускаете какой-то агрегирующие запрос в принципе по ней можно можно гонять без индексов они вам не особо потребуются потому что время запроса не так критично и лишние вкладные расходы тоже никому не нужны я не буду говорить о всех вариантах индексов которые есть постгрес я в общем-то хотел бы остановиться на наиболее популярном который B3 значит следующий по популярности индекс наверное дн но уже сильно меньше сильно меньше дополнительно есть индексы гист сст они используются в основном в достаточно специфичных вещах это какие-либо географические базы данных что-то там ну вот у нас есть Клиенты они там ищут Кто поблизости находится что-то такое найти Но по большей части естественно везде используются индексы B3 Ну и у индексов B3 в постгрес есть возможность которые нет у других их можно перестраивать во время выполнения К сожалению другие индексы нельзя Надеюсь в дальнейшем конечно это будет исправлено Типовая совершенно ошибка это есть практически в каждой базе данных Когда у нас есть индекс по одной колонке и есть индекс по этой же колонке ещё одной колонки почему это ошибка ну скажем так это я может быть несколько привели в 90% случаев это почти наверняка ошибка Почему Потому что у нас вот в данном случае второй индекс может быть использован вместо первого Мы прекрасно можем искать по ID Ну там единственно ограничение что у нас вопрос с уникальностью встаёт тут тоже следует рассматривать Но обычно меня тут указано два их может быть и до десятка следует также иметь в виду что когда у нас оптимизатор ба данных пытается найти оптимальный пла ОНТ оптимальны для всего приложения а для этого конкретного запроса было бы конечно хорошо Если бы оптимизатор мог учитывать то что происходит Кроме того кроме запроса смотреть на что-то другое тут в общем-то два варианта есть либо смотреть во время выполнения запроса либо смотреть скажем так между запросами в течение сессии это очень такая перспективная тема сейчас развивается толком она к сожалению нигде ещё насколько я знаю по крайней мере в популярных базах не реализована называется и в этом зале Завра Олег Иванов будет из нашей компание рассказывать о тех работах которые у нас ведутся по этим вещам Конечно я не могу сказать клиентам что деть Подождите годика два может быть мы вам чего-нибудь предложим вот так что пока что следует исходить из такого простого принципа что у нас все объекты которые будут обеспечен доступ долж быть извест во время выполнения во время синтаксического анализа запроса некоторые исключения здесь встаёт с секционирования же о секцио таблицах будут рассказывать здесь же Дима Иванов где-то он тут был вон Дима Иванов сидит вот я в общем-то если кому-то интересно тоже очень рекомендую послушать для больших объёмов данных это достаточно важная вещь и у наших компании в общем-то достигли Мне кажется определённых результатов в этом плане так вотр ещ хотел бы упомянуть что тоже часто встречаются некоторые недопонимание со стороны скажем так клиентов которые ВС это используют они не вполне понимают как будет использоваться индекс возможно кому-то здесь это покажется очевидным но Уверяю вас надеюсь присутствую тут нено для некоторых это может быть отсортирован таблицу в уза с указанными значениями То есть у нас например по и потом уже отсортировано по колоночки понятно что искать можно только по отсортированной последованности в данном случае поэтому поиск по скажем так в большинстве случаев будет неэффективен Почему я говорю что в большинстве случаев может оказа например US ID и эти только эти две колонки и в то же время условие задано поедет и в то же время объём чтения который ожидает сервер получить при выполнении при чтении индекса будет меньше чем при чтении всей таблицы тогда он может выбрать индекс то есть иногда поиск по индексу возможен даже не для скажем так лидирующих колонок но тем не менее в общем-то необходимо себе чётко Представлять что и как тут происходит нечто похожее представляет собой индексы like с ними тоже есть проблема они работают в случае того если у нас указан константный префикс и указано там произвольное окончание Ну можно после процентив Ещё что-то проценти что-то ещё добавить но он не работает с использованием индекса для случая когда процент указан в начале впрочем Если вы будете это использовать в постгрес А наверняка у всех у вас стоит русская локаль у8 ре то вы с интересом обнаружите что у вас даже в случае префикс по не будет использовать индекс никто такое не натыкался А натыкался с чем это связано связано Это с тем что у нас есть такая Замечательная вещь как унид в унико многие символы могут быть представлены по-разному у меня вот лся т у не при копировании манто преобразовал ма и краткое из символа и краткое в символ и плюс дополнительная для таких строчек потное сравнение Ну тогда вы натыкается в общем с кратким с можете наткнуться на проблему либо в в нашей сборке по используется icu которые нормально работает с унидом в принципе тоже можете по будет нормально ильва ме того сча включили поиск по лидирующим байтам по сравнению Это здорово ус производительность но к сожалению с унидом тоже возникли проблемы Вот в нашей сборке по это из использования это работает корректно тоже В общем достаточно важный момент ещё есть такой важный случай как покрытие таблицы индексом Это тот случай когда у нас все колонки которые нужны в запросе находятся в индексе в общем-то это работает Очень неплохо я чуть дальше покажу как Почему Потому что когда мы Обращаемся к индексу нам нет необходимости обращаться к странице базы данных чтобы получить Дополните Ну получить собственно дополнительные строчки дополнительные данные у нас всё есть в индексе в постгрес правда в данном случае возникает некоторая особенность постгрес всё-таки может обратиться к странице базы данных За тем чтобы определить собственно говоря видна эта пото что по данные о видимости строки другим транзакциям находятся именно в странице базы данных за управление этим отвечает такая структура данных как если Посмотрите в директорию где у находятся файлы база данных там можно обнаружить файлики число то кото указывает видна к чему это приводит собственно говоря к тому что если вы сделаете таблицу и в неё ставите данные там Table такая-то insert таблица куда-то и будете выбирать у вас ещё не построен и у вас Бут обращение идти к этой странице на самом деле там ещё будут идти запись но это уже несколько выходит за предел нашего рассказа вот таким образом Если вы сделали такую таблицу Вам необходимо следить за тем чтобы Ну либо вы сами руками опустили вакуум и он построил visibility Map либо у вас нормально отработал штатный процесс автовакуум Скажите пожалуйста кто-нибудь автовакуум выключал А зачем вы это делали А вы на проблему Не натыкались аваком а что же такое было расскажите пожалуйста как-то У вас что вы смотрели параметры автовакуум его агрессивности лет назад могу точно сказать Ну на самом деле у аввакума можно настроить С какой агрессивностью он все эти операции делает и причём можно настроить конкретно для каждой таблицы эти вещи в общем-то в ряде случаев это имеет смыс и даже оче имеет по-хорошему Если вы очень не знаете хорошо Что вы делаете автовакуум лучше не выключать потому что у Вас могут быть очень большие проблемы с этим с с нео отработавший вакуумом так вот если вернуться к покрытию индексам у нас Кроме того меньши ввод вывод Кроме того мы меньше Обращаемся к страницам конкретно базы данных у нас меньше получается Чей у нас меньше получается пинов пинов по это когда страница просят не выгружать на диск то есть чтобы она оставалась непосредственно ну правда есть минусы это дополнительный индекс и индекс сам по себе распухает соответственно становится больше что тут ещё можно сказать по этому поводу Ну надо конечно смотреть в случае чего обычно это возникает в том случае когда у нас есть Запрос который кровь из носа нужно быстро а быстро уже по-другому не получается Это можно сказать я чуть позже скажу Это буквально предпоследний способ сделать быстро вот у меня тут сейчас будет небольшой пример я создал таблицу из двух колонок из ID и из вала вставил туда значени Ну достаточно таких бестолковых и выполнил два запроса вот обращаю внимание если в первом случае я выбираю колоно которая не находится в индексе то во втором случае выбираю колоно которая в индексе есть и возможен индекс покрытие индексом какие результаты смотрим запрос номер один Итак что у нас получилось выполнение 22 миску первая строка вторая там одна строка выбра всё хороо получа ИК всего у нас 816 было буферов затронули время выполнения Как видите 22 миску на самом деле я это делал F5 нажимал и смотрел что получалось там оно вообще варьировала от до 30 А взял наиболее типичный случай просто разрешения таймера толком не хватает План Б доступ иние но у нас получилось 277 страниц в общем-то если это выполнять вручную и смотреть результаты оно и то и другое выполняется молниеносно и поэтому в общем-то не очень показательно кто-нибудь такую утилиту знает один человек два так три вот вообще говоря если остальные интересуется очень рекомендую с ней разобраться возможность вообще о зна для тения производительно тест поре но в частности Она позволяет погонять свои тесты параллельно посмотреть что получится то есть пишем запрос и начинаем его соответственно в несколько потоков гонять вот я пом и погонял то что получилось получилось вот что сравнение при параллельном выполнении во клиентов у меня в общем-то четыре ядра на машине было что получилось значит в случае первого обычный доступ есть у на по индексу услу 22 за в секун случае Как видите в полтора раза больше на большем объёме данных например Когда у нас может индекс умеа в память А всё индекс таблицы нет выигрыш может быть просто радикальным но это в общем-то тоже Когда у вас всё стало Ну всё почти некуда способ как можно сделать ещё лучше - это делать materialized View К сожалению опять же я про постгрес что-то гадости говорю к сожалению в постгрес с Марий View не всё так хорошо как хотелось бы и их делать надо всё-таки чтобы они были более-менее актуальны делать надо руками на триггерах Или там Если вы напишете на процедурах как-то там с процедурами в принципе это не сложно В принципе это не сложно другое дело что на кажд ме того е успеть не забыть если вы написали И через года предположим обратно вернулись в этот код Вы можете в общем несколько путаться лучше с такими вещами наверное не увлекаться хотя да как вариант это можно использовать должен ещё сказать что у нас вот тут Насти нету Настя лубенников для индексов какп есть можно вни с индексом они просто там будут для покрытия индексом в общем-то это работает это есть у нас в ппро сборке в общем-то сейчас несколько при тормозилось работа но были идеи на то такие чтобы включать туда не только колоночки но и выражения сражениями уже там можно даже Довольно интересно развернуться интересные вещи делать Вот такая вот значит ситуация с ними перем к сду Извините что Янь поверхно равам смун тиво Сай ходовой метод соединения это по равенству Наверно все знают а кто другие метод соединения использовал по неравенству предположим больше меньше один человек два человека ри там ещё есть вижу Ну вот есть самые типовый случай соединение по равенству больше всего применяется соединение через Exist Ну там могут быть другие вещи Может быть какая-то Функция может быть что-то ещё Это частично подпадает под Joint фильтр про который я раньше упоминал в общем-то случае по частоте если первый случай встречается сплош рядом второй довольно редко третий Ну ещё более редко правда вот например третий случай хорошо у меня работат для задачи выбрать 10 последних постов друзей пользователя вот если вы попробовать по-другому написать то у вас получится Нет в принципе они будут работать но конструкция Бут довольно неэффективная с 95 когда 94 по-моему появилось ключевое слово уже забыл там стало Можно поаккуратнее писать более Ясно но до этого можно было только вот через третий вариант такую вещь делать достаточно интересная конструкция ну можете посмотреть Медине дило Носта один цикл другой цикл Значит первое мы предположим можем сканировать таблицу можем просто сканировать Можем по индексу сканировать второй вариант внутренним Ну наверное только по индексу по индексу получили строчку проверили условия вып всё хорошо следующий у нас вариант соединения хэширования соединение хеширования оно вообще говоря для небольших таблиц работает великолепно для больших таблиц там начинаются Особые случаи когда у нас таблицы не умещаются в память Что с этим у нас может сначала одна таблица память потом обе не умещаются в память и опять же по распределени ключей опять же у нас к сожалению мало времени про про соединение хеширование можно рассказывать тоже весьма долго и интересно Ну конечно кому как я не знаю кому-то может не интересно вот но тем не менее хишир есть и следующее у нас в общем-то один из моих любимых методов соединения merch Join Mer Join у нас едет по двум отсортированы спискам другое дело как они получаются и выдают результаты что про эти соединения методу соединения можно сказать ложные циклы вообще говоря для многих случаев немногих для наиболее распространённых случаев это самый лучший метод соединения просто Великолепный когда он хороший это когда вы выбираете буквально несколько строк или вам Ну или вам нужно получить быстро первую строку Когда вы соответственно думаете над запросом тоже надо понимать что я хочу получить ВС сразу или Мне нужно быстро первое отдать в интерактивных приложениях Обычно нужно отдать первое значение как можно быстрее а никак не соответственно Всё потому что если у вас там предположим 100.000 строк пользователь их точно просматривать все не будет ему нужно отдать первые 10 или там 20 чтобы он их посмотрел то он и 20 смотреть толком не будет Поэтому он очень хороший Он дешёвый у него дешёвое время запуска То есть ему никаких памяти не надо ничего не надо единственное что он не очень хорошо работает для больших объёмов данных Тут у него наступает грусть тоска почему Ну например если у нас нет индексов то у нас это о и плю по соседней таблице Сколько строк есть в первой дальше Ну соединять понятно он может только по две таблицы Сразу говорю в по все соединения происходят по двум таблицам в принципе для для это достаточно очевидно теоретически вложенными циклами получается что хотя бы по одной таблице должен быть индекс доступ по индексу ко всем строчкам В общем достаточно дорогая операция то есть мы каждый раз должны пройти от корня до каждой страницы Да есть какие-то методы оптимизации этого дела Но тем не менее достаточно дорогой на больших количестве данных это в общем-то не очень здорово плохо работает как я уже написал Вот с большими объёмами данных для не очень больших обв данных работает очень хост во-первых он конечно да более скажем так интенсивно использует цпу достаточно жаден для памяти но в то же время он хэш таблицу строит в памяти процесса это прекрасно параллели ничего никому не мешает кишини сбивается вообще всё хорошо другое дело что он любит память потому что ему нужно построить одну хш таблицу тут оптимизатор Может наткнуться на проблему потому что постгрес Смотрит сколько ожидаемо уникальное число ключей по статистике и если у вас не актуальная статистика или резко что-то поменялось могут начаться в общем-то проблемы вот скажем так ко мне если клиент обращаются с вопросом как сделать запрос быстрее Вот мои коллеги иногда обращаются с запросом как с вопросом как сделать запрос медленнее Вот например у них был случай нужно было симулировать падение бэнда прогрессо сервера который обслуживается клиента по нехватке памяти Ну вот я что иму предложил сделать это сделать таблицу с колоной с двумя значениями потом резко сделать для этой таблицы много значений и чтобы статистика оставалась старой и попробовать что-то подсоединять чтобы получился ш Join и оптимизатор резко промахнулся с оценкой получившейся хэш таблицы вот так что ш хороший но надо иметь адекватную статистику и в общем-то он любит память Да он любит память Кроме того если вы соединяли которые в память не умещаются у вас всё это может происходить несколько проходов если соответственно памяти дадите побольше вы всё уместить в один дальше Joint который я люблю Он в общем-то практически для ряда задач как N он хорошо отдаёт первые строки у него достаточно Девы старта То есть ему нето распределять табли как для есть чтото делать быстро даёт строки ноно у него есть недостаток такой что ему требуется отсортированный списки строк на входе это либо индекс либо сортировка соответственно с этим могут быть соответственно связаны проблемы ещё маленькое уточнение по всем трём вещам это внешние соединение айны ned Loops у нас умеет Left Join умеет Right Join не умеет у нас соответственно умеет и любые и и и и тоже умеет Но одна проблема то что с не по равенству у нас умеет работать только Loops и тут есть очень интересная вещь что в pog не умеет Full Jo делать не по равенству Ну правда я никогда не слышал чтобы на это кто-то жаловался Скажите пожалуйста кто-нибудь жаловался а что вы делали мне интересно и при переходе вам потребовался такой интересный запрос Мне нужно было много джоновна были аналитические воркфлоу по для которого постс мне к сожалению во всех его ипостасях про не погоди пришлось переходить на Ну вот вот челове неравенством Ну да мы там считали всякие разные рои Модели там по кастомным системам атрибуции трафика в общем по-дурацки немножко выходило то есть решали задачу не очень эффективно в лоб Ну я не знаю я не могу ничего сказать но Кстати надо сказать что в планах нашей компании есть задача научить Full Joint в неравенстве работать Я правда не думаю что правильно поть не думаю что это будет большой сильно востребовано но как-то чтобы было значит для выполнения запроса опять же эффективного необходимо чтобы у поса была нормальная статистика о том какие значения есть в таблицах статистику собирает между прочим автовакуум которую кое-кто выключает Да если соответственно его выключить и долго не включать у вас статистика может перекоси а может не перекоси кстати но вообще вот статистикой вот нередко бывает что после того как статистику соберут всё начинает работать хорошо вообще очень удобно Вот такие вещи Ну не всегда к сожалению так бывает тем не менее по статистику собирает статистику Он держит в системной таблице ПГ ST такое название она честно говоря не очень читаемая есть представление ПГ stats вотт опять же нет времени расписать это полочкам что какая гистограмма и прочее прочее Ну по крайней мере хочу сказать что он там учитывает количество уникальных значений насколько соответствует какому индексу первичному ключу распределения и гистограммы где как Что расположено есть проблема у постгрес постгрес собирает статистику только к сожалению по одной колонке штатно постгрес по двум колонкам например статистику собирать не умеет это в общем-то ведёт Не такой уж редкий случай Хотя не особо часто я вот обычно приме что Предста что у нас есть таблица в которой находится мужчины и женщины Прим бульдозерист и нянечки И если мы будем Значит отправить запрос выберем мне всех пожалуйста бульдозеристов таких-то нянечек всё будет работать хорошо с индексами Да но мы можем нарваться на проблему Когда мы будем искать женщин бульдозеристов или мужчин Яник пото что статистика будет говорить что это навалом в общем-то Исходя из этого к сожалею таких строк может быть вообще не оказа постгрес будет выбирать вместо индекса доступ по э тейбл сну и будет достаточно грустно вот это в общем-то тоже поля скажем так для улучшений хотя бы по Двойка по тройка колонок в ряде случаев это конечно очень надо Oracle Это умеет надо сказать покс не умеет К сожалению э захн това к сожалению погз не получится а может и к счастью э воскреси хинтон когда я был разработчиком собственно вот непосредственно писал Код Да я тоже очень хотел хинты А сейчас вот вам микрофон А сейчас когда я посмотрел Что делают люди Я думаю что не надо хинты Нет случаях когда статистика неправильно считается неправильно считается Ну бульдозерист чки здесь если вы знаете как бы что у вас будет такой кейсу правильно то да по-хорошему было лучше конечно Ну даже знаете в том случае если я буду знать что мне есть такие вот странные комбинации такие запросы Хотя бы по-хорошему даже если я буду собирать отдельно статистику по этой паре колонок это уже вроде хинт получается я должен знать какие у меня данные да я согласен в ряде случаев с хинта было бы лучше и это иногда единственный выход Ну мне кажется что вреда от них всё-таки будет больше Потому что люди расхн ют так ну в принципе с другой стороны заработаю больше тоже конечно вариант Ну мы же тоже люди как бы мы же сами должны как-то Да я понимаю на самом деле если вы хотите расхн това Вы можете обратить внимание на Функции там достаточно много чего интересного можно сделать с функциями то есть штатный способ вот такого подсказок для оптимизатора постгрес - это что вы имеете глядите вы в постгрес можете штатно задать порядок соединения таблиц например Это я не буду рассказывать но это можно заставить использовать конкретный индекс Ну с этим сложнее да в принципе Вы можете сделать функцию в которой конкретно всё прописать что надо и вызвать эту функцию Ну то есть стандартный способ - это функция Да ну можно Можно сказать и так это в общем-то с функциями там тоже на самом деле можно развернуться по-разному опять же к сожалению сколько у нас закругляться пора Так ладно переходим к типовым проблемам которые возникают у клиентов на самом деле 90% клиентов проблемы достаточно схожие во-первых это плохая схема БД плохая в том плане что во-первых она они обычно очень большие какие-то кладбище данных вот лежит непонятно что никто толком сказать не может Откуда это взялось Ну так и исторически сложилось и мне досталась такая уже База Я с другой стороны сам был таким разработчиком я всё это прекрасно понимаю та дали Крутись как хочешь но тем не менее даже если оказалось такой ситуации это собственно схему данных никак не улучшает это лишние данные ненужные данные дублируются данные они кстати ещё и противоречить могут чтобы жизнь мёдом не казалась лишние индексы значит лишние индексы есть нужных нет неверные типы как я уже упоминал и вот ещ маленькая подсказка Если вы всё время пишите хитрые какие-то запросы Это не потому что вы такой молодец а скорее всего потому что у вас структура данных не соответствует тому что вам нужно запросы должны вообще-то в идеале быть как можно более простыми если у вас всё время простый запрос получается Вы скорее всего делаете то что надо ну с другой стороны Может конечно нарваться что у вас схема Не вполне адекватно и наконец бездумное использование РМ я РМ естественно не люблю Но мало ли что я не люблю Многие люди его любят и с этим жить как-то надо вот совершенно типовой Запрос который генерирует РМ Я в данном случае даже не могу ничего сказать плохого про РМ РМ что ему дали то и генерируют в данном случае это в общем-то не очень хорошо прописана рамная модель Итак у нас запрос начинается с того что первая строчка стоит стинт если у вас запрос не вида примерно скажи пожалуйста какие типы там у нас чего-то бывают в этой табли или в этом запросе вы выбираете Поль они вас почему-то дублируются а вы в избежание этого написали сти они дублируются перестали то вы что-то не то сделали потому что у вас что-то откуда-то не то лезет Ну во-первых вы видимо не ошибаетесь с чем с тем что вам нужно хо тоже не факт но зато у вас его оказывается больше почему стинт плохо это ВМ выполнени запроса который должен сделать можно сделать двумя путями либо сортировкой либо агрегирование хеширования в большинстве случаев он выбирает сортировку почему выбирает сортировку используется в тех случаях когда ожидаемое количество скажем так уникальных строк велико то есть почти Не повторяется тогда он будет сортировать если у вас посмотрите пожалуйста на запрос внизу у нас стоит большой о у нас будет сдела ором выборка возможно в несколько проходов отсортировано для того чтобы стинт сработал и уже будет получен результат уже сразу грустно получается Обратите внимание то есть выбрали отсортировать А почему Потому что у нас стинт следующий Left Join Все мы если им не очень аккуратно прописать не очень внимательно я конкретно говорю я конкретно разбирался с ги бернем там это можно нормально сделать в гибер Можно даже сделать конкретные модели под конкретные запросы ВМ возможности насколько это хорошо Я не знаю Но этим можно пользоваться но тем не менее если так вот В тупую то у нас получаются замечательные вещи как Left Join Если вы используете Jo и не знаете почему вы используете у вас в общем-то та же история что с дитом у вас скорее всего что-то не то почему Потому что во-первых если вы не знаете вы что-то делаете не знаете почему это уже как-то наводит на мысли вовторых у на выполняется всегда слева направо сначала левая таблица по ней выбираются и ищет всё по правой если например у нас в Вере есть условие для колонки из правой таблицы которая равна какому-то значению К сожалению пос не умеет это дело обрабатывать нужным образом и преобразовывать а Joint он это делает Как Joint К сожалению я подходил с этой идеей у меня был скажем так внутренний когнитивный диссонанс потому что с одной стороны такие вещи лечить Это наш хлеб с другой стороны как-то нехорошо вот Ну по крайней мере пока это не вылечили то есть тоже вот Обратите внимание на такую штуку на Left Jo аккуратно прописывать схему и limit Off почти всегда плохо а тут опять же у постгрес была проблемка и она скорее всего у вас осталась что для выполнения лимит ота он вас сначала выполнит всю выборку а уже потом по ней и будет делать вырезать нужные значения у вас возможно будет очень много вычислений того что не надо я иногда спрашивал клиентов зачем вы выбираете Вот вот смотрю запросы там со позиции они почему-то объяснить не могут Я тоже не знаю что они делают Вот такая штука получается есть да хорошо сорочная страница регулярно регулярно сотую страницу смотрит мало ли Да но тем не менее листать постарайтесь сначала выбрать первичные ключи результата И уже потом по ним строить результирующую выборку это по крайней мере будет дешевле почти Наверняка ещё замечу что есть патч от нашей компании который убирает вычисление ненужных значений для вот этих вещей Вот что я правда не знаю когда он пойдёт в люди в народ Что с этим можно делать тут вообще-то вопрос начинается организационно политический Потому что часто на вопрос Скажите пожалуйста а какова бизнес задача этого запроса клиент мнётся мнётся потом говорит А может всё-таки хеширование будем соединять вот ээ То есть получается Запрос который делает Неизвестно что но очень нужен Не исключено что он просто не нужен или нужен какой-то другой лучше всего работает по моему опыту по крайней мере по личному то что я делал это хорошо подумать что тебе надо И уже потом всё это выполнять скорее всего это Ну конечно не во всех случаях но очень часто это радикально повышает производительность лучше всего подумать что тебе требуется или не делать да вот и наконец значит что нужно с ремом делать разобраться с ним прописать схему не выбирать все колонки которые получаются потому что бывают огромные простыни по сот сотни колонок это в общем-то тоже ширина таблицы резу реве это тоже требует времени тоже требует ресурсов ну до Кон и Прим по-моему почти уложился Итак выводы это Чем меньше тем лучше чем меньше данных Меньше индексов меньше обращений к страницам и наконец Как правильно сказали знайте ваши данные что вы выбираете что у вас может быть есть мужчины нянечки спасибо вопросы коллеги поэтому бой"
}