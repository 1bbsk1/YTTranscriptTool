{
  "video_id": "ChR38RJznEA",
  "channel": "HighLoadChannel",
  "title": "Возможности ClickHouse для продвинутых разработчиков / Алексей Миловидов (Яндекс)",
  "views": 9412,
  "duration": 3191,
  "published": "2018-11-20T12:12:16-08:00",
  "text": "всем привет меня зовут аксай я делал crack house и сегодня я хочу спасибо сегодня хочу вам рассказать про некоторые возможности которые я сам считаю интересными но про которые не все знают вот например сэмплирование и соответственно колючкам полированием пожалуйста меня интересно кто знает про то что такая возможность существует возможность выполнения приближенных запросов вот пара человек уже хорошо рассмотрим типичную вообще задачу для krakow со именно ту задачу для которой он предназначался изначально есть у вас какой-то коллег stream ну не знаю рекламная сеть система веб-аналитики допустим есть вас яндекс метрика мало ли вдруг вот и вас есть куча событий вы хотите хранить в не агрегированном виде то есть без какой-либо потери информации и генерировать отчеты на лету в режиме онлайн и вы хотите генерировать отчеты для разных клиентов и среди клиентов есть некоторые маленькие скажем маленькие сайты типа пупкин . narod.ru все прекрасно работает для них есть средняя но есть и действительно крупная скажем непосредственно yandex.ru на нашем сайте тоже стоит метрика и вы хотите даже для таких крупных отчетов получать таких крупных клиентов получают отчеты мгновенно ну что значит мгновенно пусть хотя бы за секунду и для этого есть отличное решение можно выполнять запросы не целиком а пони которому sample для этого нужно просто объявить вашей таблице типами арчи 3 ключ сэмплирования вот как это делается great people дальше ордер buy это первичный ключ тут у нас кстати структура точно такая как у нас в яндекс метрике для таблиц просмотра событий номер счетчика то есть один секатор сайта потом дата идет а потом неких ешь от этим тифе катара пользователям дальше позиционирование а вот самом низу ключ sampler о нем и в качестве ключа сэмплирования как раз именно этот хэш от идентификатора пользователя рассмотрим что это дает сначала возьмем какой запрос и выполнен его просто так таблица хитов данные за месяц считаем количество уникальных посетителей по одному сайту вроде нормально выполнился за четыре с половиной секунды и скорости прилично то есть три с половиной гигабайта секунда это между прочим на одном сервере но четыре с половиной секунды ждать не хочется не могу просто терпеть давайте добавим простую секцию запросе sample 1 10 правом после frome пишем такой синтаксис есть теперь тот же самый запрос выполняется за 0,6 секунды ясно посмотреть скорость гигабайтах секунду стало почему-то меньше всего лишь два с половиной гигабайта в секунду но нас это не волнует главное не скорость а главное это чтобы запрос выполнялся за маленькое время а с какой скоростью в байтах чё он там читают обрабатывает это уже его дело правда количество уникальных посетителей получилось в 10 раз меньше и меньше надо будет домножить по 10 чтобы получить приблизительный результат что нужно что все это работало во первых ключ сам беру не должен входить в первичный ключ вот как в нашем примере скажем последний компонент первичного ключа после него уже ничего другое не имеет смысла он должен быть равномерно распределенным в своем типе данных ну типичная ошибка я самый в качестве ключа сэмплирования возьмем timestream unix timestamp ясно нарисовать график количества событий зависимости от роста потом будет вот такая какая штука все кто работал админом я не знаю где вам сам да и вообще все люди знают видели такой график это просто графика активности по времени суток так нельзя потому что неравномерно то что нибудь за хэшировать вот если захочу рут индификатор пользователя все будет прекрасно ключ sampler вина должен быть легким как для чтения из таблицы так и для вычисления скажем тоже плохой пример берем url фишером его и этот хэш используем в качестве включаться моделирование очень плохо потому что ясно просто выполняется запрос все нормально теперь добавляется сам пол и запрос может работать дольше потому что вам нужно будет этот url из таблицы прочитать а потом еще и хэшировать какой-то сложной функцией возьмите в качестве ключа сэмплирование что-нибудь маленькое и дальше вот этот гораздо более распространенная ошибка надо чтобы ключ сам прерывания не находился после мелко гранулированной части первичного ключа ну например первичного ключа у вас есть время с точностью до секунд допустимого слоги какие-то и это естественно потом вы добавляете еще какой-то фишек и это будет работать плохо потому что ключ сэмплирование позволяет именно с диска читать мало данных и почему это работает потому что данные на диске упорядочены по первичному ключу и соответственно ясно есть какие диапазоны префикса первичного ключа ту из них можно читать меньшую под диапазоны ключа сэмплирование hayastan это диапазона маленький для каждой секунды то из них уже нет возможности вставить эффективно какой кусочек прочитать придется читать все так что вот в нашем примере из яндекс метрики первичный ключ это счетчик дата и только затем затем ключицам природе и для больших счетчиков есть много данных за каждую дату и из этих данных можно выбрать уже меньше данных достаточно эффективно посмотрим какие свойства на которые можно полагаться во первых сэмплирование она работает детерминированного потому что у нас там не рандом у нас нормально хэш-функция то есть выполняется запрос один раз выполняется другой раз результат одинаковый отчеты прыгать не будут и он работает консультантом до разных таблиц то есть если вас таблица с просмотра страниц я столица с осями в них объявляйте один и тот же ключ сэмплирования и вы можете эти данные джо нет то есть мы выбираем подмножество там одну десятую всех возможных хорошей от посетителей и это подмножество будет одинаковым и он реально позволяет читать миша данных с диска если все сделать правильно а в качестве бонуса применять его можно самыми разными способами первый способ самый частый это выбираем одну десятую всевозможных данных другой способ мы можно написать sample какает вашего число направо 1 миллион и в этом случае подмножество выбираться динамически относительно концерт подбираться динамически чтобы выбрать не менее чем 1 миллион строк но и не сильно больше правда в этом случае будет трудности с тем чтобы узнать о какой относительный коэффициент сэмплирование выбрался какая-то доля данных то есть это 1 миллион строк из 10 миллионов или из миллиарда и для этого есть такая никому не известная возможность это виртуальный стал гнаться подчеркивая sample подчеркиваем фактор а поднимите руку кто знает про эту возможность в а знаете почему потому что я вчера про него рассказывал на нашем этапе покликал сон и теперь вы можете написать там скажем сумма и там x умножить на подчеркиваем сам был подчеркиваем фактор получится все что нужно еще одна интересная возможность это sample of set это очень просто вот вы выбрали одну десятую данных а теперь вы можете сказать а дайте мне пожалуйста вторую одну десятую данных до этого просто напишите сам полотна 10 в сад 1 10 и так можно все эти данные перебрать и еще один бонус это если у вас в таблице есть ключ сам прерывания вы можете теперь распараллелить ваш вопрос не только пожар дам но и по репликам каждого сорта на разных репликах будет выбираться разный sample данных так чтобы покрыть все множество и соответственно запрос будет выполняться быстрее или не будет будет количеством прерывания выбран так что его легко читать вычислять и это сама сэмплирование добавленный запрос не потребует существенного верха до теперь перейдем к следующей интересные возможности это комбинатор и агрегатных функций заезда а там обычно агрегатная функция сумма на средний адамов каунт distinct который у нас можно записать с помощью просто uniq и этих линек еще есть четыре разных варианта или даже больше но каждый агрегатных функций можно сейчас право прописать такой вот комбинатор записываться права во имя скажем их мы вместо сун пишем сумму их и теперь у нас эта агрегатная функция принимает ни один аргумент а сразу два первый аргумент это том что мы суммируем а второй это условие которая возвращает как он число типа uint8 i там где не 0 и мы это будем суммировать так тянули все будем пропускать рассмотрю например а для чего это нужно типичное применение это сравнение разных сегментов мы этот бесстыдный использован для сравнения сегментов яндекс метрики вот данном вопросе мы за один проход считаем количество уникальных посетителей для яндекса и количество уникальных посетителей для гугла очень удобно другой пример комбинатор агрегата функции это эрой было вас обычная агрегатная функция вы прописали прописали к ней рай и теперь у вас получилось агрегата функция которая принимает массив из тех типов данных которые раньше в качестве аргумента надо было передавать я она просто применяет эту функцию для всех элементов массива рассмотрим пример значит есть у нас массивы два массива разных и мы сначала считаем количество разных массивов потом количество разных элементов объединения этих массивов потом интересно агрегатная функция группой но это немножко другое это агрегатная функция которая все города назначения собирают массив то есть теперь у нас в результате будет многомерный массив из двух массивов потом групп ли у не коры она собирает все разные значения в массивы еще мы можем к этим функциям прописать комбинатор и рэй и получится что то что сначала выглядит несколько необычно но и даже неудобно и даже за это неудобство может быть немножко стыдно разработчикам коли хауса тем не менее к этому можно привыкнуть и так груб и рэй рэй что это такое это значит взять массивы взять все элементы этих массивов а потом собрать их в один массив получится один массив из всех элементов а группы unicorn эрой это тоже самое только для разных элементов посмотрим что получилось кажется получилось все верно всем видно ну и замечательно то есть в одном случае количество разных масел в другом количество разных элементов в третьем массивы собрали многомерный массив четвертом разные мотивы собрали многомерный массив а потом собрали все элемент в один массив а потом все размеры надавать яна sef эй' мне надоело пойдем дальше кстати комбинатор агрегатных функций можно комбинировать друг с другом то есть делать игрока там функций sum выписали к ней а потом еще можно их приписать а можно наоборот то есть сумма и ray ev и суммы и эрой а в чем разница позвольте у меня задать этот вопрос уважаемой аудитории кто знает ни в порядке аргументов в порядке применения да значит будут функций с двумя аргументами и что функция дает как объект но это механизмом действия кто знает никто нет абсолютно верно то есть рассмотрим значит в одном случае у нас будет два аргумента массива мы возьмем элементы этих массивов соответствующие а массивы должна быть одинаковых длин и один элемента то что суммировать а другой это условие надо ли сформировать от элементами не надо это у нас будет сумм и в рай то есть карбюратор эры проявляется к функции sum не free превратит оба аргумента в массивы другом случае сумм р.ф. первый аргумент будет массивом а второй это условие нужно ли применять функцию sum рнк массивы целиком или не нужно абсолютно верно вы выиграли а еще они могут комбинироваться так тут очень много разных комбинатор of soul for each type for each и врыв state я не знаю что это делает но я написал функционально то на этот случай чтобы она работала оно должно работать я сам ваша задача это нужно она будет работать давайте дальше кстати агрегатная функция можно вычислять не только до конца то есть есть вас агрегатная функция скажем сумма ну вы часто вы получили сумму все просто если есть агрегатная функция средняя то вы чисто вы получили среднее но в процессе вы часто не мы будем накапливать некоторые состояния и очевидно что это будет 2 числа это будет сумма и количество а потом мы просто делаем одно на другое если это количество уникальных посетителей то там тоже будет какое то состояние которое может быть довольно сложным кто скажет какое нужно состоянием чтобы посчитать каун distinct абсолютно верно хочется вчера был замечать на доклад как раз про хэш-таблицы как раз на эту тему и это нужно да сразу многих применений например для распределенной обработки запроса случае распределенной обработки запроса мы отправляем некоторые маленькие запрос на каждый сервер и говорим вычислим это агрегатные функции но не до конца до промежуточного состояния а потом эти промежуточное состояние будут переданы на все рубенса то запроса и объединены вместе это внутренний механизм но он увлекался доступен и для пользователя ясно вы возьмете агрегата функция добавьте к не комбинатор стоит твой получите непосредственно это промежуточное состояние и она вернет нам значение которого типа которые в других базах данных и не встретить типа агрегат fangs он и там какие параметры и значение этого типа можно сохранить в таблицах то есть вы можете создать таблицу а там будет сталкиваться типа агрегат фанкшн вы там сохраните производственное это состояние и можете потом их до агрегировать новые и есть комбинатор мертв он делает игрока то функцию который в качестве аргумента принимает эти самые состояния объединяет их вместе и возвращает готовый результат давайте рассмотрим что получится сначала просто вычислим средние июне ки из двух чисел ну ничего интересного а теперь вы чистом состоянии выписали комбинатор стоит и он навернул какую-то вещь который пользоваться невозможно какие-то бинарные данные да они еще нам вырастут экранированием половина байта не выводится в терминал потому что терминала в кодировке utf-8 эти бинарные данные это естественно ньюта f8 ну ладно давайте дальше а какого типа эти значения типа агрегат фанкшн с аргументами типа у нас могут параметризовано первый параметр это имя агрегатные функции остальные параметры это типы аргументов агрегатор функций и мы можем создать таблицу с такими типами а потом мы можем зад и таблицы выбрать значение промежуточное состояние все их вместе объединить и получить готовый результат но зачем же это все нужно типичные сценарии использования это и nakara ментальная агрегация данных вообще вы наверно слышали наверно даже от меня потому что я все время говорю что treehouse это такая система для которой самый лучший сценарий работы это работа с не ограде ровными данными есть у вас к alex3 он там логе транзакции всякие события мониторинга сохраняйте все что есть клика us нужен для того чтобы можно было на лету выполнять все агрегацию максимально эффективно но все не так просто иногда агрегирует данные все таки полезно ведь их становится меньше запрос работает быстрее и да мы поддерживаем этот сценарии работы достаточно просто создать таблицу типа агрегат in north 3 это такая таблица которую будет данный до агрегировать фоне вы вне определили некоторые столбцы с промежуточными состояниями агрегатных функций когда вы записывать в эту таблицу вас там какие-то куски на диске и эти куски фоне мерзавца и для одного значения первичного ключа все эти состояния грамотно функции будут объединены в одно более толстые состоянии то есть вы можете и на кри ментально около реального времени добавляя данные обновлять ваши статистике все эти каунт инстинкты квантили пожалуйста и более того этот движок таблицы таблицы очень удобно использовать в качестве движка для мате реализованных представлений еще одна супер-возможность при хауса о которой я рассказывать не буду потому что оно есть в документации но есть некоторые ограничения и что могли бы сделать бутса скажем сейчас хотел составе агрегатные функции до бинарные данные которые не аверсе они руются и мы попали в ловушку потому что мы не можем их поменять я ведь уже рассказал про это возможность вы будете ее использовать и было бы очень плохо я собой обновили кликал сервер и она сломалась бы поэтому нам придется добавить туда versio нирования как можно скорее и надо принять ваш случаев когда состояние казалось бы разных играх на функции на самом деле одно и то же скажем состоянии кратный функции sum и сумма их это одно и то же но сейчас они несовместимы так тут еще детского пунктов написано типа можно должно быть возможно получать это состояния с помощью обычной функции сейчас это тоже можно места например функция рей радиус берем массив указываем какая на макро кратная функция нужно и она все эти данные pierdas мазь в агрегата функции все элементы массива и мы получаем состояние этой агрегатный не означает регата а если в качестве агрегатных функций указать агрегатные функции с комбинатор of state мы получим состоянием ведь очень просто правда же ладно давайте дальше посмотрим еще одна интересная возможность cry хауса это настраиваемый режим консистенции вот умолчанию вы знаете краха вас это система типа и начал консистенция но и соболя точно система какую репликацию она вообще реализует репликация асинхронная то есть сделаем сорт получили подтверждение когда данные записаны на одну рубрику и данный баттер питера на фоне ответ на черт успешно его все еще не значит что данные на нескольких репликах вовсе не значит что данные реплицировали репликация конфликт фри без конфликтов по причине того что у нас не атоллов дай то есть сенсор ты то есть все ок антон для прекрасно коммутирует брукс друг с другом конфликтов просто быть не может и за счет этого она работает multimaster пишется на любую реплику ясно реплика недоступна вы можете тот же самый блок данных повторить на другую реплику даже если на самом деле был записан я следом понятность то есть данные будут для дуплицирование и таким образом вы можете добиться записи на должны записи с экзо клеманс семантикой тем не менее основная проблема и которая для многих сценариев является серьезным ограничением это то что после подтверждения успеха то сорта если реплика на которой записана единственное внезапно исчезла навсегда и данные не успели до этого от реплицируются данные будут потеряны и большинство людей когда читаешь документацию они читают . а потом и дамы будут потеряны недавно записанной все можно закрывать и вот специально для таких случаев у нас есть магическая замечательная настройка теперь можно включить строгую consistent ность а точнее до шаолиня ризу имость in short of на самом деле у нас даже две настройки 1 до insert подруга это селектор естественно потому что они обязательно должны идти с двух сторон первая настройка это включить кого ровную запись для insert of минимальное количество реплик на которой данные должны быть записаны перед тем как клиент получит успешное подтверждение о записи ставите хардкором скажем 2 и будет записана на две реплики и более того им сорта линия рисуется в том смысле что они будут записаны на две реплики которые при этом содержат все предыдущие в шорт и которые тоже были записаны скоро вам со стороны select of есть такая вот настройка селекция каша в конце снасти может быть ее имя даже не совсем точно надо было ее назвать селекции меня раза был но переименовывать уже потом в этом случае если вы отправите select the будет сделан запрос занята данных звуки пир и этот соляк будет разрешен только на репликах которые consistent а то есть содержат все ранее подтвержденное и шорты записаны с кормом если вы обратились к другой реплики то вы получите x описан и клиент должен составить на обратиться к какой другой реплики консистентная которая будет существовать это нисколько не удобная настройка но все это до тех случаев когда это вам действительно нужно я включать эти настройки не рекомендую тем не менее для многих станнеров полезно и например мы в компании это включили чтобы записывать данные рекламных кликах теперь рассмотрим еще одну интересную возможность это агрегация во внешней памяти вот в документации почти все время было был такой пункт что промежуточные данные формирующейся при выполнении грубой должны помещаться в оперативку на каждом шарди участвующим выполнении запроса а так же на сервере инициатор запроса так вот это больше не верна и вовсе не обязана рассмотрим простой запрос считаем разные поисковые фразы и до каждой поисковой фразы количество просмотров страниц и количество разных посетителей попробуем это посчитать тут все очевидно на экране вот он считает считает кстати красивый прогресс барр мне очень нравится игры хавас клиента тоже замечательная штука я его очень люблю к сожалению он ничего не посчитал потому что не хватило оперативки он пишет что для обработки этого запроса не хватило 9.31 что ли gebo оперативки но это 10 миллиардов байт и первый вопрос который стоит задача а почему именно 10 миллиарда байт это просто по умолчанию такое ограничение вы можете его увеличить спокойно давайте сначала рассмотрим почему не хотела оперативки посчитаем сколько у нас тут данных было и сколько разных поисковых фраз я не вижу сколько на полный горда что ли ну мы можем даже посмотреть на эти данные подумать что да ведь действительно много оперативки надо так и должно всё работать яно-сан давай самый простой способ я оставался есть какой-то сервер там бывает наверняка больше 10 гигабайт оперативки и допустим вы с этим сервером сейчас работаете один потому что вы сидите ночью выходные и вам очень рад почитать какую-то аналитику ну почему бы просто не сказать давайте я увеличу макс номер явился для себя я использовал всю память на этом серве на всех остальных пользователей можно не обращать внимание ну посмотрим выполнится не выполнится да вроде все нормально но это не тот способ который можно использовать на продакшене все время правильный способ это включить группой во внешней памяти что это значит это значит что накладываются какие данные в оперативке когда их становится многом их сбрасываем натиском потом снова накапливал снова сбрасывал на диск снова на кадрах сбрасываем а потом возьмем это все и будем мерить причем мерз будем как-нибудь так с использованием маленького количества оперативки то есть какие-то кусочки брать из каждого этого куска довольно сложно употреблять слова кусочки для разных вещей в одном предложения и вот так вот их не ржите отдавать росстат клиенты уже потока есть две настройки которые для этого предназначена первое максимальная объем оперативки когда данные сбрасываются на дисками и второе это использовать эффективной по памяти мерч то есть этот самый мяч по кусочкам при распределенной обработки запроса обычно распределенная обработка запроса устроено так мы с каждого сервера весь datasat скачиваем по сети на сервер запроса все объединяем и для этого нужна оперативка а тут он будет скачивать эти datasat и по каким-то кусочком по баки там и объединять их потоково давайте проверим выставляем максим родился 10 гигабайт сбрасывать будем чё там 8 написано гигабайт да вот у нас прогрессбар завис на какой-то момент а потом дальше проложите что это значит это значит что именно в этот момент времени данные сбрасывали с натиском и как ни странно запрос обработался даже не слишком не сильно дольше чем запрос без этих настроек тут есть некоторые забавные фокусы например когда данное сбрасывается на диск они на самом деле сбрасываться файловую систему а когда данные записываться файловой системы они вовсе не обязательно записываются на диск то есть тут как бы тоже из полости оперативка но но не всегда и еще интересно что данная при этом жмутся то есть данные сбрасываться в сжатом виде вполне возможно что у вас там 10 гигов оперативки использовалась для грубая а потом вы это жалит получился всего один гигабайт и быстренько его там в поисках куда и записать и в общем на практике это обычно проводят тому что запрос работать не более чем несколько раз медленнее а в этом случае даже чё там в полтора раза шторы давайте перейдем к следующей возможности это работа с географическими координатами честно сказать что как раз это не какая-то гилас прошел система там нету никакой штуки типа пост гис но наши пользователи очень хотят складывать туда всякие координаты вот у нас есть в компании сервис такой метрика мобильных приложений она собирается какие лаги и естественно там есть координаты а что мы хотим с этими координатами делать конечно же мы хотим показывать рекламу например вы прошли мимо магазина как вот ну ничего там не купили а вы покажем вам объявления что а зря ничего не купили вернитесь назад вот этого нужно скажем просто отфильтровать пользователи у которых координата в некотором полигоне вот пример функция python полигон первый аргумент от carthage land а дальше идет и массив координат полигона этот массив должны константам вы какую-то область этим полигоном зачеркивается кстати там есть еще следующий аргумент с помощью которого можно из этого полигона еще дырки выразить даже поломка аргументов в общем такая продвинутая функция и работает эффективно рекомендую есть еще парочка функций которая честно говоря я рекомендую вместо них просто point полигонов сама такая продвинутая сам оптимизированное функции но есть и другие point in groups as позволяет вам задать несколько эллипсов на координатах как ни странно нина нина землянина сфера просто на плоскости то есть будьте осторожны если у вас пользователи на чукотке там и есть этот разрыв координат просто вернет нолик единичку если единичку и 100 пользователь попова телимся и другая функция это расстояние на сфера две точки и считаем сколько на сферы будет great circle distance ещё одна интересная вещь экспериментальная это интеграция к хаус с моделями машинного обучения это не значит машинное обучение внутри крауса это значит машина обычные модели который вы там обучили где-то еще заранее теперь вы можете их загрузить в crack house и они будут доступны для выполнения объявляется этим модель машинного обучения лектором конца на файле конфигурационные файлы можно обновить налету без перезагрузки сервера объявляете имя некоторые данные и теперь они доступны в виде одной функции модель является первым аргументом просто передавать ее на остальным передаете факторы фичи для модели скажем вам нужно предсказать сетях или предсказать вероятность покупки про эту тему я подробно рассказывать не буду ясно интересует вот замечательно ссылка там прям доклад именно про эту возможность как пользоваться сейчас у нас единственный метод машинного обучения доступны на такой август вопроса почему ему акад boost потому что яндекс нет потому что он лучше слова могли бы сделать чтобы это возможно стала еще лучше скажем часто нужно применять какие-то простые модели но применять их много на правда каждого сайта какую-то маленькую модели чтобы она быстро выполнялось до этого можно добавлять сам простыми адеры грязь и типа логистической регрессии по крайней чтобы это соответствовало нашим принципам что работа должна быстро тормозить не должно если какой-то сложный там градиентный пусть он катался из куча деревьев она конечно будет работать быстро она может быть будет тормозить нам это не надо представьте как было бы удобная своего можно было обучить модели хаусе с помощью агрегатной функции вот я показывал пример промежуточное состояние агрегатной функции а представьте что у вас будет игра кратная функция создать модель какой-то там логистическая регрессия вы передаете туда данные получается состоянии записывать в какую-то блюдца а теперь можете взять из этой таблицы позориться и примените это состояние видео обычной модели это не то что доступно в хаусе это мои фантазии но было бы круто продажа и конечно важно онлайн-обучения то есть чтобы модель сама адаптировалась к постоянно поступающим данным следущая возможность очень интересна эта обработка данных с помощью клика usb-диск rehau с сервера есть у вас какая-то машина вы не хотите на не оставить crack house но у вас на ней есть какие-то логе и вы админ что вы обычно делаете его обычно у вас есть куча средств от огреб set of или даже pearl но если у вас есть какой то опыт работы скатался например вы через плечо хотя бы увидели как круто обрабатывать данные как это удобно можно написать правом запросы не надо гре пути сидеть был очень заманчиво обрабатывать браманте файлы с помощью коли house of без какой-либо загрузки без преобразования и такой возможности есть это утилита cliff house vocal вы указываете некоторые параметры самое важное это пир дать структуру то есть имена и типы столбцов это важно потому что краха все-таки строго типизированные система указываете формат в котором ваша данный лежат на примерочный logo удобно если у вас логин джейсоне того указывать формат тайсон вечеров указывайте запрос и промо-поста дэн передавать ваши данные и пожалуйста ваши данные обработаны конечно это будет не так быстро как если вы сначала все-таки загрузится данный в house потому что эти данные надо будет распарсить и все с ними сделать но я вас выбираю работать будет быстрее чем афк первый сет в некоторых случаях даже быстрее чем грех смотря с какими параметрами но если вам данные нужно обработать не один раз а хотя бы два запроса выполнить то пожалуйста не нужно мелочиться поставьте себе крякал сервер много ресурсов не отнимет и будет удобно работать и что интересно скажем если у вас уже установлен сервер где нибудь вы можете его выключить зачем-то для монтана с какого-нибудь и затем с помощью программы crack house vocal вы можете подключить данные которые в нем находятся в локальной файловой системе и обработать запросы прямо над ними не поднимая греха усеру для обслуживания клиентов что сейчас это возможность ограничивает что нам нужно сделать чтобы стало удобнее скажем мы сейчас весьма строги к форматам даты и даты с времени со временем вот да ты у нас например формате iso 89 могу оговориться дата сравним не совсем то есть там нет не поддерживается что можно было указать там плюс минус смещение или суффикс или дробные секунды вот естественно было бы очень удобно чтобы такая возможность появилась и сейчас она у нас уже появилось много видео отдельной функции есть отдельная функция называется порождает time best of art и она без всяких аргументов парсит дату сравним в любом формате кроме американского потому что американский формат где там сначала месяца по а потом число вам такой слова и не отличишь так что если в американском то пожалуйста можно это функции использовать еще очень удобная сам мы добавили такие форматы которые поддержка форматов которые более свойственно для hadoop инфраструктуры что вы могли бы скажем запустить cliff house vocal в качестве родился job и прям ходу пим скажем мы могли бы добавить хотя это и так можно в режиме streaming а если нет то как-нибудь по-другому но был бы очень хорошо я сам и добавили скажем паркет и сейчас эта возможность уже появилась в этой паре квеста наверно скоро по мертвым еще интересный вариант если бы мы добавили такой формат данных который я про себя называю трэша sql представьте если вы могли бы данное разделить каким-то лекарством на столбцы а потом подать на вход кликал соколу конечно можно это сначала сделать с помощью того же авка но иногда был бы удобная такая возможность была прямо внутри к хауса пожалуй поставите интересный пункт о котором я хотел бы рассказать это недавно появившегося возможность наш кластерного копирования суть в чём конфигурация кластер в хаусе довольно жесткая то есть вы должны указать сколько у вас там шар дав сколько яблок на каждом шарден и все прекрасно будет работать пока вам не надо будет это пересортировать как это пир сортировать ну можно поднять еще один кластер родам создать там такую же таблицу а потом сделать insert select is distributed таблицы в другую distribute таблицы и она поначалу будет работать я сам повязал то нас работает проблема в том что во первых она работает в один поток будет передавать данные через один сервер по сети и я снова одна нога достаточно вы запустите например поработать недельку а потом раз сетевая ошибка и вам придется смотрите какие данные скопируют какие данные не скопировались или разделять это как то вручную по парте цену неудобно же и поэтому у нас есть специальная специальный инструмент называется какого скотт мир это такая программа которую вы можете в любом количестве экземпляров запускать на любых серверах она автоматически будет выбирать себя задачей и координируется через booking a задачей это partition на портится одной таблицы на одном шарди того кластера который вам нужно будет создать путем копирования можно настроить ограничения по сетевой полосе можно настроить ограничение по количеству одновременных задачи и работать это будет отказываться . то есть серверы с этими программе они могут там падать восстанавливаться ясно какая-то портится частично скопировано нарезать хороший сервер попытка выйти из которых будет повторяться то есть какие-то частично с как ерунда на удаляются и копируется заново и самое главное это возможность про верно в продакшене мы недавно завершили операцию наш кластер на копирование contex метрики у нас был один кластер на 538 серверов и мы взяли другой кластер на 240 сероваров меньше потому что сервер более современные и туда больше помещается мы изменили наших таблицах все схема формирования поменяли было шарди рования по сайтам сделали шарди ранее по пользователям изменили алгоритм сжатия на старом кластер было z4 на новых звезд иди и запустили это все и она начинает копировать и у нас были проблемы потом еще были проблемы еще были проблемы дорабатывали их каскадёр серьёзно задача из 1 раза конечно что не работает и где-то через месяцок все скопировалась когда мы копировали уже таблицу с просмотрами просто с просмотрами то у нас было где-то 15 за неделю скопировался и теперь можно запускать и прямо забыть и она свою задачу выполнит так что если это воспользовались мы наверное вы тоже сможете этим воспользоваться пожалуй все спасибо ваши вопросы спасибо за доклад копира интересна возможность в реал тайме поддерживает дописывая данных которые прилетели на сара кластер нет копирует нужно именно портится которую не изменяются то есть соответственно когда вы копировали вы уже читали с какого дистрибьютора между старым и новым кластером или читали только снова кластера как это происходило так сначала в нашей программе который данный записывает мы сделали чтобы она записывала на оба кластера у нас на новом кластеры создалась какая-то портится за какой-то неделю или месяц кстати схему порционирования тоже поменяли оно создалось неполной потом следующая портится уже были с полными данными мы запустили копирования вплоть до этой последней неполной партии цель и этот копировальщик эти данные неполной партиции заменил на те данные которые были на старом кластер то есть теперь у нас есть бесшовные данные и мы можем отключить запись на старый кластер но мы это делать не будем потому что на самом деле мы создали новый кластер для других задач мы найдем будем обрабатывать тяжелые аналитические запросы то есть как раз кликал спустить почему то есть как раз ты тестировать лихо вас получается 4 между что ну хотя бы шутить по поводу что новый класс app для тестирования rehau создавали неё нет до тестирования cliff house а у нас для разных сценариев нагрузки то есть с наведут запрос от внутренних аналитиков тяжелая они будут идти на новый кластеры это очень удобно потому что там данные не по точкам разбитая по пользователям и это запроса смогут использовать ресурсы всего а кластер а если скажем обрабатываются запроса для рунета за день смотрите на есть какие-то наработки чтобы запускать да такие планы есть на с ними есть одна очень серьезная проблема которая именно для вас серьезное дело в том что яндекс и есть не используется ходу есть своя рога затем определился под названием выйти и люди сделали чтобы crack house запускался внутри витя сама обработал данные в его формате передавала друг друг с другом для распределенных запросов сделать это кто-нибудь до боли распространенных так скажем система то это еще вопрос понятно то есть уже как бы внутри яндекс и такие наработки по поводу применения на идти и вот этого запуска под конкретный мы листов с менеджером на кластере она уже есть это динамическое есть то что уже не конкретно на каждом ноги установлен treehouse да вот это уже как бы как как tool как вот это для обработки csv и он уже распространяется в виде джуба для у нас внутри компании это задач находится сейчас стадии экспериментов на так скажем последней стадии разработки и там сейчас сделано так что какая то часть кластер и выделяется и на этой части кластера запускаются не кликал сервер а какая то какой другой бинарник который содержит tackle house и части хотя и она все это читают и обрабатывает спасибо спасибо за доклад вопрос немного не просто шел вопрос коллеги по поводу тихо ушла к лампам спрашивал он существует только в виде бинарник а или есть еще какие-то модули для каких-нибудь языков курантила встраивать можно например встраивать нет только как standalone приложение единственный бонус он встроен прямо в культ house бинарник то здесь вообще такой бинарных основной сервер и клиент и около и все что угодно спасибо я просто не пользовался еще и там unique рай а район не ордер делает он их в рандомном порядке берёт просто как-то странно были разбиты слова на слайде дал мне тут организованном порядке зависимости от того в каком порядке данные обрабатываются на разных фронтах и разных потоках спасибо хочу спасибо за доклад а вот у меня такая практическая проблема была с клик хаусмана немножко надуманная на самом деле на в общем данное до этого лежали вертите чуваки там пытались писать запрос на это все и шедший тормозило что я сделал я просто выгрузил их csv я загрузил клика usb ли хаусе за joy нил уже в другую таблицу в которой все было как бы уже в один организована в виде но уже по ней запросы шли быстро проблема была только в том что если ты хочешь вот эти все за joy и те нужно очень много памяти чтобы тебя весь запрос память в лес и я но я ничего лучше не придумал кроме как просто памяти докинуть на этот момент и все но можно ли это как то было решить другим путем если возможность при house and join так чтобы не обязательно правая таблица или по крамер результат права под запроса помещался в оперативку пока нет пока какого сервиза он хозяин то есть правый результат право часть должна помещаться в эту самую хэш-таблицу оперативки но у нас есть плана это изменить эти планы весьма серьезно и правда их серьезность в том числе связанные с тем что это будет не так-то просто сделать до этого придется серьезно менять conver выполнения запросов чтобы реализовать мертв join и чтобы он работал нормальной и в том числе в распределенном случае спасибо спасибо хотел спросить если или когда появятся апдейты то будет ли еще мастер мастер репликации если да то как или если нет то что он будет делать чтобы она работала по этому вопросу можно сказать ура потому что сейчас овда это находится в поверхность и мы их планируем замерзать мастер на этой неделе смотрите вот я здесь стою а другие люди сейчас в офисе и мир тот мастер мастер и публикация продолжат работать на сколько я понимаю во-первых все операции в хомсе они реализуются с помощью звуки пара то есть там есть полный порядок этих операций яз вы будете угадать это конкурент нас на разных репликах то соответственно в каком порядке они дойдут и в каком-то порядке выполняться здравствуй спасибо за доклад насчет клик house копир поможет ли он решить задачу когда необходимо вывести вывести из чарда реплику и на новую реплику итворда скопировать данные например для проведение работы для этой задачи каховского пер не нужен потому что это очень простая задача и типичная operations вещь вы просто создаете новую реплику и у вас допустим была дверь apple киева создать новую теперь три реплики старую теперь можно удалять ну или там одна реплика была создать снова она наливает данные сама самое главное если у вас сервис репликой с концами исчез куда-то ну его больше нет надо удалить мета-данные это и сейчас нашего реплики звуки пера иначе там я способность накапливаться логе репликации вот проблемы спасибо"
}