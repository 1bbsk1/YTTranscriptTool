{
  "video_id": "CvT1v7xiRS0",
  "channel": "HighLoadChannel",
  "title": "Принципы и приёмы обработки очередей / Константин Осипов (tarantool.org)",
  "views": 10440,
  "duration": 2924,
  "published": "2017-07-29T12:57:50-07:00",
  "text": "практика из реальной жизни это сейчас я попробовал ася чуть чуть потише потому что такое вещание это наверное вопрос к залу вот как вы считаете таковы стоимости очереди с приоритетами то есть она кто-то допустим лезет в не очереди как посчитать стоимость для всей системы в целом эта ситуация чему она пропорциональна допустим времени обслуживание клиента или чему такому фактором допустим у нас нам но пять минут стоит его обсудить то есть она пропорциональное количество ожидающих а почему потому что время ожидания для каждого из них и вещи смотрите вы даже знаете уже факт практически половина доклада можно вас всегда вытаскивать значит но я тут цену времени потому что оно еще не началось формально говоря но я так понимаю что вы все не хотите выходить входить давайте начнем сначала о себе я занимаюсь разработкой sugoi тарантул mail.ru вот и этот доклад просто ну одна из интересующих лично меня частей это вот обработка очередей потому что мы много актуальным мы много очередями внутри системы фактически вся база данных построена как система массового обслуживания вот я свое время учился на в мкм был но математику особо не осилил поэтому стал программистом а сейчас меня мучает совесть что я плохой математику я пытаюсь как-то вернуться к истокам и немножко посмотреть сторону математики значит так clicker а куда нужно направлять clicker чтобы он вот сюда да нет пока нет может быть ее надо включить аналогично значит еще один christ газа лак для затравки то есть на самом деле вот я просто дают дам превью во всей презентации основном мы будем рассказывать про всякие проблемы балансировки нагрузки вот но прежде чем мы к этому придем я бы хотел дать некоторые некоторые затравку и поговорить о том зачем вообще нужна очереди как они появились у меня в компьютерных системах то есть что они по за чего не позволит добиться и 1 1 в моих любимых таких мисс концепций например по поводу баз данных это то что транзакции достаточно для всего например для того чтобы перевести деньги из одного банка в другой нужно просто сделать распределенной транзакцию между двумя банками и все будет хорошо то есть мы берем лучшим аккаунт в одном банке потом лучшим аккаунт другом банке делом и списанию начисления потом разворачиваем у нас все консистентной надежно вот или допустим взять такую же проблему и связано с банкоматом да то есть мы пытаемся снять деньги в банкомате ну что нам нужно сделать нам нужно распределенную транзакцию между банкоматом и соответственно одну автоматизированной банковской системы бы контента и все у нас тоже будет хорошо вот но есть одна маленькая проблема в этой всей истории а именно а что делать с принтером он может быть участником распределенной транзакции или нет но тем что чеки печатает или диспенсером банкнот как вы считаете что что ни одна вы выучите вы все знаете ли мне ответить на конкретный вопрос может ли диспенсер банкнот быть участником распределенный транзакции он поддерживает rollback нет то есть в общем то традиционная теория на хороша но и пользоваться для сегодня возможно поэтому есть в первую очередь участники в реальной жизни который их нельзя откатить да если дым патентные участники то есть какую-то операцию можно и безопасно повторить еще раз и а есть ней дым потерян участники то есть фарш невозможно провернуть назад и с такими участниками нужно как-то жить и общаться и вот один из приемов работы с такими участниками то очередь потому что если мы фиксируем статус любой задачей в очереди то мы фактически ней дым патентного участника превращаем вот импотент мы всегда можем обратиться к очереди и посмотреть состояние да то есть мы нас очередь выступают что-то вроде журнала она отслеживает текущее состояние задач мы в первую очередь ставим задачу в очередь например на печать или на диспенсер на то чтобы отдать банкноты потом мы собственно выполняем эту задачу обновляем состояние и так далее то есть любой момент мы можем понять на каком шаге мы находились относительно задачи и в этом смысле именно транзакционные система а не в каком-то были пионерами систем с очередями есть всякий enterprise transaction менеджеры и так далее они тоже управляю транзакции с очередями ну и паттерна архитектуры связано с сериями типичны что же как можно просуммировать вот то что я сейчас сказал в каких-то плюсах минусах ну вот элементарно то есть какой у нас получается преимущество что нам это дает очередью одно из не очевидных преимуществ это то что мы можем развязать в принципе и клиента и сервера да то есть у нас выполнение задачи она не зависит от того доступен ли в данный момент клиент или доступны в данный момент сервер клиент ставит задачу в очередь после этого его роль в каком в каком-то смысле заканчивается сервер в этот момент не обязан быть доступен сервис какой-то момент когда у него есть возможность берёт задачи из очереди выполняет ее изменяют ее статусе так далее всегда клиент может проверить обратиться и за проверить статус задачи состоянии задачи всегда известно мы можем иметь несколько серверов одного клиента несколько клиентов одного сервера они все работают через единую очередь значит таким образом можем балансировать нагрузку когда речь и блокировки нагрузку сразу речь заходит о приоритетах направить их я сказал уже в начале да что с приоритетами все не так просто если кто-то прыгает в очередь без называется в начало очереди то стоимость такого действия она не на самом деле не очевидна и зависит от загрузки системы какие минусы данного подхода то что нас появляется дополнительная сущность фактически у нас на одну и ту же задачу если раньше мы обращались напрямую к серверу да без какой-то предварительного буфера виде очередью там и сразу и выполняли сейчас у нас получается поставить задача сервер обращаются изменяет статус у нас больше запрос и одна из моих таких вот любимых а тем это то что люди склоняются к не persistent нам очередям потому что ну им кажется что долевых конкретной задачи не президента очереди достаточно скажем раббит но хотя раббит может быть президентом там все равно persistent ность да там связано с опять же с традиционностью до речь идет о надежной persistent насти то есть как только у вас появляется очередь ее состояние фактически это состояния вашей системы если вы теряете это состояние то у вас могут быть всякого рода аномалия связаны с повторной обработки задач да то есть кому то в рассылка пришло два раза кого-то фотография добавилось два раза у кого-то вообще не добавилось потому что потерял и задачи да то есть клиент который поставил задачу в очередь он считает что все хорошо сервер задача потерял потому что очередь не persistent поэтому в принципе очередь это на самом деле не какая-то отдельная компонента на мой взгляд эта база данных которые выступают в роли очередь то есть она выполняет этот сценарий это традиционная система который выполняет роль чуть лет самой правильной очереди и соответственно такого рода очередь они конечно стоит дороже теперь для чего можно это использовать ну здесь какие-то очевидные тезисы но значит опять же когда мы говорим о паттернах то надо в первую очередь вспомнить ситуацию с тем что у нас одна задача она может порождать множество задач такая вот типичная история допустим вас зарегистрировался пользователь что нужно сделать там послать уведомление его друзьям допустим загрузить какие-то его картинки что угодно то есть множество ему эсэмэс там послать или ему рассылку послать то есть у вас множество разнородных задач связанные с одним действием и очередь может выступать в виде мультиплексор и за счет ип именно поэтому ну помимо вот лот balancing часто очень используются очереди как паттерн именно для того чтобы просто выполнить кучу задача пользователь пришел сделал какое-то действие на веб-сайте и мы тут же отдали ok вот после этого уже системам потихонечку шуршит разгребает и делается задача связаны с этим действием за счет этого у нас получается как бы рек уже реакции более реактивной интерфейса в частности одна из неочевидных историй которые запилена исключительно но очередях вот в mail.ru это я не знаю вы знаете мне такая фишка сборка почтой то есть вы можете подключать удаленные ящики а ну-ка mail.ru можешь подключить же mail там что угодно да и у вас в вашем ящике оказывается почты из всех этих адресов из-за всех этих ящиков или допустим когда вам приходит почта вам автоматически высвечивается фотка человека и социальной сети откуда угодно да откуда mail.ru берут эту фотку какой-то момент еще до того как вы зашли в свой почтовый ящик и mail должен сформировать эту страничку которую нам показывает фронтальную уже вашу почту созываются по рачительно и аватар того кто послал почты он ставится задача на то чтобы получить и сохранить локальном кэше чтобы так тот момент когда вы заходите на фронтальную страничку вам и быстро показать до чтобы тот момент когда вы зайдёте не обращаться по всяким и пей там социальных сетей gravatar а для того чтобы получать этот картинка все это не тормозил вот так и так такой принцип применения при этом если мы говорим о практике применения то тут появляется множество таких же также специфичных кораблей которых тоже следует помнить в первую очередь это связано с всякими плохими задачами то есть типичные и вообще здесь все идет рука об руку есть такой сейчас популярный метод досада это когда доз осуществляется после поиска уязвимостей в пропускной способности веб-сайта то есть нет уподобиться потом по сетевой нагрузки до какой-то из веб-сайтов а ну на уровне сетевого стека а именно выяснять какие-то уязвимости связанные с с тонкими местами в архитектуре то есть допустим предположим что у нас в момент регистрации нового пользователя есть большой объем работы связанные там с чем-то всем угодно что мы можем сделать мы можем загрузить этот веб-сайт большим количеством пустых регистраций просто для того чтобы его зову его система завалились от этой работой да он не смог отвечать уже по своим типичным сценарием допустим показанной странице так далее и в этом смысле очередь может содержать плохие задачи да то есть если говорить о картинках то допустим у вас есть задача ри сайдинга картинок и какие-то картинки в очереди биты и есть такие типичные анти паторны когда кто-то загружают битую картинку worker ее берет красятся да за счет этого очередь считает что задача не выполнена отдает и другому worker он ее снова берет красться задача постоянно возвращается в очередь и соответственно результат понятный да то есть маркеры делают пустую работу полезно работать никто не делает значит то похожая история связана с приоритетами то есть у вас типичная история что если вам как о каком смысле не получилось выполнить задачу паритета my time ago to me вас может быть желание вернуть задачу в очередь и но выполните не немедленно то что вы постоянно будете то есть причина по которой задач не может быть выполнено может быть 1 дано находится во внешнем мире и у вас может возникнуть желание вернуть задачу очередь с каким-то тайм-аутом чтобы потом ее взять назад каким-то тайм-аут он после по истечении этого тайм-аут возможно внешний мир изменится через это тайм-аут и задачи удастся выполнить ну или в конце концов из дальше не удалось выполнить в течение долгого время это вам имеет смысл просто избавиться от этой задачи пометить ее как невыполнимую и так далее то есть все это надо учитывать еще интересная такая же идея о применимости в этом смысле очередей и том как очередь должна работать найдет из всяких задач искусственного интеллекта дата поиск ближайшего пути и так далее когда мы берем у нас есть какой-то граф связи и мы пытаемся найти в этом графика на и на кратчайший путь из точки а в точку б но один из способов это прям полный перебор условно говоря ну или какой-то более осмысленный перебор что мы делаем мы берем ближайших соседей ставим для этих соседей задача в очередь найти кратчайший путь потом выбираем кратчайший путь из из найденных но может так получиться что граф то может быть сильно связана и вы одни и те же путей фактически будете проходить многократно счет того что вы просто у вас поиск допустим в первую очередь связан в глубину идет глубину либо какие-то пути вам нет смысла проходить потому что вам уже заранее известно что они не оптимальны их нужно отбросить в этом смысле тоже когда очередь используется на им надо типичный пример это краулер кровли на веб-сайт вы заходите на веб-сайт печки из него front of range вы выбираете из этого фронта и за все линки на последующие страницы ставите задачу в очередь у вас дальше происходит все то же самое значит на все эти задачи распорки ваются worker и ставятся задачи в очередь и в итоге у вас сайт просто-напросто например можно за доносится потому что огромное количество ордеров начинают вдруг на него ломиться либо одни и те же странице если на них идет куча ссылок вы этого можете не увидеть при таком способе и вы будете одни и те же ссылки траверсе несколько раз тоже бессмысленная задача то есть в этом смысле появляется вложенной в очереди зависимой задачи очередь авто есть у вас может иметь смысл допустим организовывает организовывать под очереди в очередях да то есть у вас есть общая очередь задач и в контексте каждой из очередей у вас есть по дочери задача с которой не могут быть про мультиплексирования ну я говорю какие то абстрактные вещи но если на практике если вы возьмете любой сервер очередей то там все эти проблемы так или иначе будут учтены возможности как-то отражены в интерфейсе так далее до их обсуждать конкретный сервер очередей ну я здесь как бы не хотел единственное пожелание он должен быть pure system теперь я хотел бы перейти ко второй части доклада она связана уже с другим аспектам обработки очередей а именно так вот таким вот максимально эффективными очередями стране максимально эффективных сергей и то есть взглядом на проблемы с точки зрения балансировки нагрузки до что такое балансировку нагрузки вот определение из википедии налоги распределения запросов которая позволяет достичь что здесь важно вот у меня есть такой график которая назвала диаграммы насыщения да ну график абстрактный и на этом графике у меня с одной стороны запрос количество запросов в секунду а с другой стороны lighten7 то есть я дальше докладе буду постоянного наверное заметили меня постоянно держит англицизмы я использую слово лейкерс и хотя это достаточно это именно для вот этого вот вот в данном контексте я его использую под этим для этого определения время обработки одного запроса тебя вообще она может означать там что угодно какие-то скрытые задержки и так далее так вот какая наша задача когда мы организуем очередь или организуем обработку очередь это сделать так чтобы у нас с одной стороны была высокая утилизация ресурсов да с другой стороны мы максимально качественно обслуживали всех клиентов что такое качественно в первую очередь качество это время обработки до время ожидания результата и если посмотреть на типичную диаграмму системы которая обслуживает очередь она выглядит именно вот так to him мы можем можно строить гистограммы по instagram огласит график можно строить полностью график можно строить prps в этом смысле рпс мы можем либо заметить либо не заметить снижение рпс но даже есть большое количество систему которых количество запросов в секунду снижается с увеличением нагрузки кстати кто может сказать за счет чего это происходит так и вас я не спрашиваю вам не нужно на highload junior как минимум но почему почему у нас при повышении но вышла в метро никогда на у нас меня спросили будет ли примерно из реальной жизни может ли в снизится пропускная способность метро если повысится нагрузка но тоже простой вопрос кто здесь пользовался метро ну давайте пример из метро из-за чего может тормозить метро когда там толпы двери держат ну кстати вопросы можно задавать по ходу доклады вот вот если как-то более ну обобщить и ты поешь на такой двери держит что это значит перегрузка но перегрузка это сюда для связанной с лифтом да это прикольно да кстати слить и то же качество снижается до 100 заходит никто не хочет выходить за этого никто не едет все пытается значит смотрите что с точки зрения системы масса обслуживаем происходит она выполняет бесполезную работу да то есть в момент перегрузки происходит что-то что не направлена на выполнив непосредственно обслуживания клиентов так или иначе направлена на борьбу с перегрузкой а вот например если взять базу данных типичным примером базе данных это является как раз снижение нагрузки снижение производительности при увеличении количества одновременно присутствующих базе данных транзакции за счет чего это происходит за счет того что появляется ожидания на блокировка хэды блоки до ожидании на блокировках это бесполезное дело до драки вообще приводит того что транзакции ри стартуют их нужно выполнять повторно вот в пример из из компьютерной системы но что нас данной ситуации интересует наверно нас интересует как бы построение такой системы которая будет находиться в оптимальной части кривой да то есть она будет выполнять максимально возможное количество запросов при этом сохраняя свои какие-то тактико-технические характеристики и в этом смысле на самом деле часто еще осознаешь что многие не до конца понимают что их реально интересует потому что вообще-то latency и рпс это несвязанные вещи да то есть наше желание максимизировать производительность системы и наших желания максимизировать качество обслуживание то противоречивость желание да то есть вот на графике качественно видно что если мы хотим ограничить именно latency до в допустим вот вот вот этим вот вот эта величина да то мы можем максимум допустить вот такую нагрузку буду дальше мы уже заходить не можем то есть наши требования к качеству обслуживания они ограничивают фактически пропавшую способна сейчас я попробую показать теорию почему это так математического хотя я еще раз сказал я недоучившийся студент внк значит 2 второй критерий который мы можем оптимизировать систему эта максимизация рпс и в этом смысле нам полезно дойти до какого-то насыщение системы при этом сохранив качество но скажем так удовлетворительное удовлетворительный уровень обслуживания и не выйти в перегрузку в область перегрузки чтобы понять почему собственно это взаимосвязанные вещи я сейчас попробую в грызться чуть-чуть в теории очередей и но максимум что я смог осилить эту модель с одним сервером поэтому сейчас мы это увидим но тут уже тоже достаточно показать какие то вещи из теорий очередей они показатель вообще есть два способа в принципе смотреть на ну каким то образом понять как работает система масса обсуждать 1 господство это построить модель второе ну может быть есть больше на второй способ от симуляцию да то есть буду бенчмаркинг когда вы тестируете попытаюсь сдать живую нагрузку а симуляция кстати тоже поговорим о бенчмаркинга и всяких опасностях которые ждут на этом пути если пытаться не чуть-чуть у меня буквально пару слайдов и рыться в теорию массового обслуживания то первую очередь осознаешь что моделей может быть очень много есть такая вот нотация кен кендалла или кендалла kindle наверное оно классифицирует всей системы вот по этим 6 показать первое это распределение времени между прибытиями задачи то есть мы должны понимать что живая система оно не идеально это не метроном и вам раз в секунду никто задача стать не будет живой системы есть какой-то скорее всего пуассона цска и распределение то есть количество задач в определенном от времени она следует по способностям закон то есть она случайно я когда-то больше когда-то меньше также распределение времени обслуживание но в компьютерных системах часто все-таки время обслуживания она более-менее фиксировали часто мы когда делаем наши beach park ли симуляцию мы чаще всего проверяем какие-то типичные проблемы или однотипные задачи но в целом можно говорить что это тоже случайная величина s это количество серверов то есть вас может быть система с одним сервером со множеством есть еще такая штука в модели называется емкость система обслуживания емкость системы обслуживания это вот о чем смотрите у вас может быть очередь фиксированного размера и все кто извините не полу не успел тот опоздал да то есть они вообще не получают уксус следующая вещь из модели это популяции источника то есть или популяция или общий объем то есть понятно что на распределение на все остальные показатели будет влиять то сколько у вас вообще потенциальных клиентов и конкретно в эту комментарии меня потенциально но и принципы обслуживания это всякие приоритеты там подобные штуки значит простейшая модель которая теорий очередей дает эта модель а для одного сервера 100 здесь что здесь дается степень утилизации это соотношение производительности к темпу поступления задач по скорости поступления за дальше то есть допустим у нас один сервер может обслуживать 10 задач в секунду а поступает 9 задать в секунд ну наверно он справится с нагрузкой среднему день этого степени цивилизация причем что здесь как бы сразу польской отдать если количество задача секунду превышает пропускные способны сервер ну в принципе уже все пиши пропало ничего особенного тут не поделаешь очередь будет неизбежно расти пика ты это модели вероятность к задач в очереди но вы собственно уже все прочитали что здесь интересно смотрите вы допустим у вас 10 задач в очереди 10 скорость поступления даже 10 в секунду а сервер может обслужить допустим 12 в секунду какова вероятность того что в тот момент когда придет следующий потребитель очередь будет пустота есть он сможет получить обслуживание немедленно ну наверное эта вероятность того что до этого никто не пришел да это вернется того вот это ну 2 12 скажем так да то есть почему с большой вероятности уже к тому моменту когда приходит следую задача а сервер обслуживает какую-то предыдущую с вероятностью десять-двенадцать а с обратно вероятности он никого не обслуживает вот это нам говорит модель из теорий массово то есть смотрите что это значит что если мы хотим максимизировать утилизацию то у нас неизбежно будет расти очередь потому что в тот момент когда кто-то под новая задача поступает уже сервер занят обслуживание какой-то задач и чем выше утилизация тем тем выше это вероятность это как бы базовый inside теория теория масса обслужи есть еще собственно собственно вот выводы которые я хотел бы и затем здесь я не привожу модели для нескольких серверов но опять же идея которую которая у нас есть базовые это то что если у нас есть единую очередь множество серверов там и вот эту вот дисперсию в распределение участников можем гасить именно тем что у нас все сервера в каком-то в каком смысле получает равномерную нагрузку вот результат например симуляции когда у нас есть 80 процентная загрузка на кластер и синий график это у нас задача поступает в произвольный сервер по случайному закону а красный график это когда у нас есть и глобальную очередь и каждый сервер он берет задача зато очередь когда у него появляется такая возможность то есть мы видим что с увеличением количества серверов у нас сладости снижается это реальность реальную симуляция то есть смотрите здесь конкретно у нас получается вот что такое один этот это длина очередь да то есть когда у нас при 80 процентной загрузки каждый сервер работает независимо в среднем у него есть какая-то очередь когда он работает из глобального очереди вероятность того что в момент поступления нет доступного для выполнения задачи сервер и она вот такая она близится там меньше ну в пределах 0 1 на графике нож всех то есть но интуитивно понятно у нас есть 10 worker of и 8 задач на worker и каждый момент времени вероятность того что нас пришло задачей у нас нет свободного worker она маленькая в то время если у нас есть 10 worker of и на каждого своя задача то вероятность повышается что еще какие еще и сайты из-за теория массово служение можно взять есть такой закон little а он я вот эти люди с очень простой и общую его идеи то такая что количество одновременно обслуживаемых обслуживающихся задач пропорционально времени обслуживания и темпу поступления что что 100 данном случае важно что смотрите если у вас вот например если у вас допустим система получает 1000 запросов в секунду время обслуживание одного запрос 1 миллисекунду средняя длина очереди такой схеме будет 10 то есть фактически время обслуживание одной задачи в такой системе будет но на самом деле тут не среди для учит здесь количество одновременно задач системе будет были про миска вот но целом если это разные очереди то у вас средний для очереди может достигать 10 то есть если у вас у каждого брокера свою очередь на очереди будет постигнуть с точки зрения масштабирования вывод из этого следующий для того чтобы как то увеличиваем пропорционально расти до нам нужно масштабировать работу ну более-менее линейно и увеличивает число серверов увеличивать число одновременно обслуживаемых обслуживающихся задач то есть если у нас задача большая мы чаще всего увеличения числа серверов и и никак что сможем так сказать увеличь нашу производительность и за счет того что нам приходится увеличивать число серверов у нас общее количество задач в работе растет соответственно растет время всяких прогревов стоимость простое и так далее и тому подобное ну и собственно вывод который я бы хотелось который более-менее уже очевиден из того что я говорю что у нас есть конфликт требований для того чтобы его удовлетворить нам нужно так или иначе снижать нагрузку на систему это основной вывод который нам дает теория теперь я хотел бы перейти к бенчмаркинга и поговорить о каких-то практических аспектах именно бенчмаркинг меня немножко смущает эта тишина гробовая вы понимаете что я говорю окей это интересно мне увеличить темп уменьшить темп все нормально послушаем сделаем выводы можно задавать вопросы вы могли бы писать элементарную постановку задачи вот там давно столько-то серверов там благодаря и теннисом густую да как они были как раз задача решать я хотел бы чтобы вы решали выпить до дна вот в целом но смотрите установка задача у нас есть 10 серверов время обслуживание одного клиента допустим равно 1 задач выполнение одной задачи равно 10 миллисекундам и мы хотим чтобы наш средний lite версии при такой-то такой-то нагрузки был равен 20 миллисекундах я но опять же среднее то один одна из мы хотим чтобы 99 процентов задача сейчас об этом надо говорить обрабатывались пределы 20 миллисекунд вот такую задачу мы данный момент решает хорошо а вот судя по определениями которые вывели вывели вы решаете задачи в области теории вероятностей да как я понимаю вот в области линейного личного программирования вот методов оптимизации для поиска оптимального значения показатель насыщение минимум вот оптимальное значение я вас понимаю то есть вы говорите что давайте ударимся в модели и попробуем линейном программировании найти это оптимальное значение и так далее есть там даже я пока готовился успел прочитать про дрифт липу новые всякие такие умные вещи но знаете я вовсе не проекта я рассказываю про то что тот практически уровень который может понадобиться разработчику интернет-проектов то есть мне не в меньшей степени интересуют теория теорию я попытаюсь поддаться ровно настолько насколько это применимо для для этой для этой задачи то есть максимум что меня интересует почему я обвёл вел эти вещи да вот выводы которые можем сделать практически для масштабирую необходимо пропорционально если число задач обработки это имеет последствия для в качестве обслуживания потому что если у вас допустим отключили питания то вы навредили большому количеству людей или то что как бы наивное предположение которое делают разработчики о том что очередь у них в среднем пусто если у них сервера сары справляются с нагрузкой она неверная и нельзя говорить о лейкерс и в принципе я вот большой большая часть этого доклада на посвящена тому какие представления у людей появляется латексе давайте я воспользуюсь этим и продолжим доклад то есть к чему к чему мы вообще почему я вообще веду большинство людей насколько мне известно имеет очень смутное представление о том как какое время обработки одной задачи их система имеет есть практика измерения этого мониторинга и так далее но даже это практике они часто неверные вот мы сейчас попробуем этом поговорить с просто не правильная реализация но собственно что мы можем исследовать что мы можем верить и как мы можем типичным образом верить в том что мы обычно делаем мы пишем benchmark в котором наш скрипт оон создает какую-то случайную задачу до посылает ее на сервер получает результат измеряет время пишите во влог если мы хотим так сказать увеличить производительность этой системы или нагрузить нагрузить проверить каталог насыщение наши вот в этой light in circles как-то выйти выйти в сторону насыщение мы увеличиваем количество клиентов хотя часто даже это людей не оценивают и они пытаются нагружать один сервер с той же машины что и допустим и то есть нагрузку давайте той же машина на которой то ставите тестируемой системы но что нас стоит что в этой ситуации я нас интересует что людей в первую очередь интересует чаще интересует рпс первую очередь значит количество запросов в секунду чем больше тем лучше я бы хотел поговорить чему это неправильно в первую очередь нас должно интересовать качество обслуживания и в заданном качестве обслуживания нужно добиваться максимального рпс да а качество обслуживания определяется именно временем которое тратится на обслуживание какой-то парад какого-то процента клиентов то есть предположим что ваша пьеса 10 тысяч запросов в секунду может быть такое что какая-то часть клиентов получают сервис там допустим за но пять процентов клиентов получают сервис за 2 секунды ты допустим или нет тем не менее можно иметь высокий фпс но часть клиентов будет иметь очень плохое качество обслуживания и с чем это связано особенно вот в базах данных какой-то периодической работы которая больше больше больше больше часть без порока не просто не мере то есть если база данных у вас раз в секунду засыпают и что-то делает то вы этого можете даже нас вами ведь марки не увидеть собственно почему сейчас я попытаюсь показать как обычно у людей выглядит график нагрузки у меня здесь нету но идею обычно такая что здесь по этой оси у нас количество запросов время количество количество клиентов по этой оси у нас производительность допустим десять тысяч 20 тысяч тридцать тысяч запросов секунды что что нам это говорит о качестве обслуживание ничего в первую очередь для того чтобы получить распределение времени percerin то есть у нас 90 процентов запрос обслуживается с такой-то производительностью от там 10 процентов пределов такой вот здесь у меня нарисованы такие отбой обивочные линии и допустим какой-то маленький процессор процент запросов он вообще уходит каталог и для него время обслуживания очень высокая и часто для того чтобы нарисовать так и гистограммы стандартным да пожалуйста да это разные системы здесь 10 тестируется то есть это кривые для разных систем и но на самом деле это более-менее рандомной картинкой но нет не совсем рандомно из из интернета значит то есть в первую очередь когда мы строим такой всем нам нужно определить и целей да мы говорим что мы готовы нам необходимо чтобы 90 процентов за запрос обслуживать за одну допустим миллисекунд или микросекунду неважно 10 процентов большая часть запросов в 9010 99 оставшихся в пределах пяти миллисекунд но для остальных у нас и допустимо 10 миллисекунд определив василий нам нужно это василий добиться и часто я не знаю кто вот слышал про такую проблему корней туда мишин вот у меня в скоординированная ошибка измерения это наверно будет так правильно русский перевести они незнакомом это термин да значит смотрите как мы обычно меряем производительность нашей системы до по 7 рублей трассе типичный пример кода мы говорим star time этой запоминаем систем запоминаем время выполняем запрос и запоминаем время в конце вот я потом мы как три дня и мы суммируем результат давайте посмотрим проблемы такого подхода в случае одного клиента она станет более менее очевидной предположим привет производительность нашей системы 10 тысяч запросов в секунду для одного клиента мы написали вот такой benchmark и меряем собственно эта производительность а теперь я зашел на серверную консоль и послал стоп-сигнал серверу и он остановился допустим на 20 секунд после этого я послал сигнал continue сервер продолжил работу в общей сложности у меня benchmark работал одну минуту сколько запросов результирующий гистограмме будет иметь время исполнение там 15 секунд я сказал я ждал сколько 1 до а в реальности сколько должно быть 150 тысяч что да то есть то количество запросов которые сервер не обслужил и эта проблема большинства бенчмарков ну допустим возьмись more гоняется в там 40 потоков да вы все равно имеете эту системную ошибку измерения и чаще всего это системно ошибку просто не видит минимум и максимум как-то людей не смущает то что минимум максимум там не укладываются там какие три сигма от нормального и так далее от среднего их тоже не смущают просто система меряет не та и это некая важная проблема которую надо решать каким его можно решили вкусовым решать ее можно экстраполировать можно догоняться до доставлять добавлять нагрузку если мы видим что у нас количество запросов в данный момент снизилась то есть мы говорим что нам нужно было выполнить еще эти эти эти эти увеличивать количество запросов то есть есть какие-то способы которые мы можем это решать и часто если строить опять же гистограмму распределения то на не скорректированных данных у нас выглядит это как то так то есть у нас есть маленькое количество запросов который имеет очень большой 2 тыс а в реальной жизни у нас light носи растет с увеличением нагрузки или или даже не с увеличением нагрузки это я не совсем это имел ввиду насладитесь и более равномерно распределена по всему множество запросов что мы таким образом можем увидеть значит какой-то переди периодическую работу которая выполняет система то есть допустим она чепуху вот lsm дерево lldp но может очень быстро обрабатывать запросы потом в какой-то момент начать произойдет пройти процесс мир дженга деревьев и на какой-то момент время выполнения запроса снизится вас естественный в конечной системы интересует худшее время и последняя тема которую я хотел бы сегодня обсудить у меня уже кончаются время если не кончилась эта борьба с перегрузкой и здесь буквально несколько простых вещей почему перегрузка возникает мы обсудили вот сюда сюда ну да да да да да возможно график не слишком удачные согласен наверное правильнее было бы все-таки измерять это вот так и графику развернуть и корпусом у него сгибался вниз да ты прав а значит давай у меня остался 0,0 секунд я расскажу про последнюю тему и мы на этом завершим значит какие способы почему возникает перегрузка мы проговорили какие способы борьбы простой способ это просто ограничить размер очереди все кто не успел тот они получают сервис значит но не всегда это допустимо но на практике вот есть например симуляция если у нас размер очереди ограничен там двадцатью то у нас всего лишь там какой-то процент за повод задачи он не получает абсолютно какой-то конкретной систем то есть конкретных случаях это возможно второй способ который вы которые можете воспользоваться эта типичную историю в баре до вас не факт что пустит в бар если он переполнен для того чтобы люди которые присутствуют баре получаю нормальный сервис кто-то должен подождать снаружи это второй паттерн который вы можете использовать с ним вопросов нет это системой билетов любых тикетов раздача билет люди которые требуют ресурсов они ждут снаружи они ждут не с ресурсами то есть люди в баре они уже какие-то ресурсы используют что студия там и так далее время бармен поэтому давайте ограничим их здания снаружи и более общая идея которую необходимо реализовать для борьбы с нагрузкой это какой-то способ обратной связи обратного давления в гидравлике да здесь я привожу пример клапан ограничения давления но творить как он устроен есть какая-то пружина которая увеличивает ну за счет механическая энергия она не дает давление превысит определённый размер да то есть есть обратное давление на средой и так или иначе вы в свою систему нагруженные должны так такой такой механизм строить если вы хотите бороться с перегрузкой дальше уже идут как раз всякие интересные теории по моделированию нахождение оптимального состояния когда мы программируем линейный коэффициент и вычисляем и так далее но базовый идея такая просто на практике конечно вы не будете использовать эти теории управления для этого корее все выглядите какой-то простой способ дат это тоже возможно но на самом деле что значит мало некие некое количество слайдов про колебания производительности я бы на этом прекратил и перешел к вопросу местами время german насколько мне известно он первый щит предназначен для выполняет таких более тяжелых задач тяжеловесно rabbit бенз толк более легковесное причем его ребята гораздо больше фич на сколько я могу судить если говорить именно о гарантии выполнения один раз та ну насколько опять же мне известно ни у без толка не ребята не транзакционный база как бы кэндо german множество используемой аскольда как бы к вот но дело даже не в этом дело в том что вы можете сами не понять что вы уже поставили задачей поставить задачу еще раз то есть для того чтобы два раза не выполнить задача в первую очередь мне должен быть какой то естественно уникальный идентификатор по которым вы можете проверить статус выполнения то есть даже если у вас есть супер надежное хранилище в котором всегда можешь посмотреть статус задача выполнится нагнет вы должны каким-то образом прежде чем и выполнять проверить что она уже не была выполнить допустим ведь есть же ещё такой момент что между вами и базы и серым очередей находится сеть и сеть может потерять пакет ответ вам просто не придет спасибо за доклад хотел узнать в tarantul и если уже встроены средства для получения вот этих цифр мониторинга но там не знаю там средний light in sexy мальной период и тогда нет нет понятно спасибо ну что давайте прекратим спасибо вам большое я буду в коридоре"
}