{
  "video_id": "794G1A3ybO0",
  "channel": "HighLoadChannel",
  "title": "Columnstore - \"старый\" новый движок для аналитики от MariaDB / Роман Ноздрин (MariaDB Corporation)",
  "views": 698,
  "duration": 2657,
  "published": "2020-04-27T12:08:56-07:00",
  "text": "так вот ночь с истории почему движок старый в далеком 2000 в америке появилась компания coal пункт которая решила делать и планете для все это больших данных и они сказали давайте мы сделаем большой шкаф или несколько которые можно поставить клиенту и после этого он как-то будет считать аналитическую нагрузку середине своего пути в середине двухтысячных они сменили бренд назвавшись infinite be это видимо было такое поэтому все называли себя как-то макс baby пытаясь показать производительность которую вы можете получить купив и продукт в общем это смена названием не помогла и где-то в четырнадцатом году в середине 14-го года они объявили себя банкротом но перед этим приняли решения выложить свои наработки в open source pdp и льва-2 и после этого объявили банкротом скоропостижно скончавшейся команда разбежалась стороны в это же время примерно мария baby оценивая свои возможности приняла решение о разработке или doubt какого-либо движка который позволит эффективно обсчитывать аналитическую нагрузку посмотрев вокруг они обратили внимание на этот заброшенный проект и подобрали его таким образом появился проект мария дебетовым star который унаследовал от infinite be всю их кодовую базу это примерно 400 тысяч строк кода и появился каллум star это просто схема поможет мне рассказать о том как устроен каллум star вверх внутри он схема покажет достаточно высокоуровневое описание кластера и на том что мы видим слой на слой который мы видим потребители в качестве потребителей может выступать любое приложение которое умеет клиентский протокол мой сиквел или мария baby таких достаточно много в частности мы являемся сертифицированным источником данных для табло следующий уровень это уровень фекального фронта и конечной агрегации по архитектуре они объединены вместе и после этого идет распределенный слой исполнителей за про частей запроса который поставляет свои промежуточные данные вверх на уровень агрегации после этого отдают в результаты клиента и последний уровень это уровень хранения данных которые отличаются большим разнообразием здесь вы можете использовать либо локальные диски или группы их какие-то распределенные блочные устройства и отдельно хочу выделить кластеров с который к в истории используется для организации резервирования данных на уровне блочного устройства и поэтому слайды у меня к вам вопрос скажите пожалуйста а почему для чего могут использоваться вот эти вот 3 сервера которые стоят на уровне фронта и уровня конечной агрегации результатов есть идеи ну на самом деле balancing запроса в данном случае не происходит и мы используем несколько серверов для отказывай устойчивости я хотел рассказать о списке свечей который cola нестор поддерживается но подумал что это будет не очень интересно если будет оторван от реальности поэтому я расскажу о двух клиентах к сожалению под индии поэтому не могу называть имена и цифры если захотите подойдет после доклада я что-нибудь расскажу поэтому представляю вашему вниманию американский финн тех ну жизнь этого фильм тех а достаточно типично они собирают данные из различных источников таких как новостные ленты данные о котировках на фондовых рынках и после этого они их как-то обогащают анализируют и отдают клиенту по одному из доступных каналов и какое-то время назад они вполне себе справлялись с помощью кластера состоящего из нескольких мая секундных серверов все было хорошо тогда приземлялась как и аналитическая так и транзакционные нагрузка но время идёт нагрузки растут количество клиентов увеличивается и они уткнулись в потолок и начали рассматривать варианты замены такой схемы в том числе они обратились к нам а потому что в первую очередь они хотели увидеть у нового решения у нового старриджа совместимость с их имеющимися приложениями то есть ему нужен был нужна была поддержка клиентского мои сиквел протокола и морей тебе поддерживает и no debe поддерживает мой сиквел вплоть до файлов данных на диске до 8 версии я думаю что через какое-то время пути разойдутся и я бинарное будут несовместимы эти два продукта но пока это еще так и при такой связке они могут использовать как и no debe для транзакционные нагрузки так и калом star кроме этих двух движков мария де 50 есть несколько других интересных такие как rox baby с регулярным подтягиванием новых вещей из версии facebook а и спайдер спайдер это движок позволяющие сортировать транзакционный у нагрузку прямо из коробки эти товарищи они хотели кроме всего прочего переиспользовать словаре имеющиеся у них в таблицах с движком и на дибир то есть регулярно приземляется нагрузка в эти таблицы и хотелось бы не сохранять еще одну копию данных поэтому следующим их запросам была необходимость поддерживать join между таблицами из разных движков что собственно каллум створ умеет и выполняет достаточно эффективно после того как они провели внутренние стрельбы их удовлетворила производительность этого решения они задали вопрос про отказоустойчивость нашей схемы и мы предложили им реализовать отказоустойчивой с помощью использование вот этих как раз нескольких инстансов марии db которые в то же время держит несколько дублирующих агрегаторов работающих по схеме calls then buy на слое движка и исполнения запросов не нужно ничего резервировать потому что они распределены и если один из них вышел из строя его можно заменить на уровне столь же они используют кластеров с который позволяет им как раз таки решить вопрос резервирование данных на хранилищах таким образом они закрыли этот вопрос эмигрировав в течение трех месяцев на решение предложенные им они сейчас прекрасно живут и и проблемы с масштабированием у них не возникает здесь перечислены фичи которые они использовали следующие клиента которым хочется рассказать это биотех технология биотех компании из америки который занимается исследованием генома крупного рогатого скота как вы видите на картинке и вот если это видимо вариантах виде не будущий коровы эта компания занимается исследованием генома и сохраняют промежуточные данные в таблицах которые они в дальнейшем используют для получи создания викторов об считываемых в их pipeline ах и если раньше они использовали колумб top в качестве хранилища из которых с помощью функции агрегатных они строили вектор координаты которого хранятся в колонке джин пи и после этого они передавали эти данные на элементы на степа pipeline а собрав необходимое количество викторов где-то месяцев шесть назад я встретился с их ведущим разработчиком и он мне вдохновенно рассказал о том что они делают в том числе и про эту схему и я упомянул ему про фичу который есть колонн стар и которая называется юзер define the грига it functions что это такое наверняка вы слышали про юзер define fonts and в современных движках баз данных и эта функция которая может быть написано на каком либо из поддерживаемых языков и она позволяет создать пользовательскую логику исполнить ее на движке агрегацию дав позволяет делать то же самое но распределена то есть его исполнении можно задействовать в если смотреть с точки зрения секундного сердца сервиса сигнального сик вольного statement а вы можете использовать удав в оконных функциях и в агрегатных функциях и исполняется запрос в на слое движка исполнение запросов то есть он будет исполняться параллельно не централизовано таким образом что у них получилось по сравнению с тем что у них было до этого они смогли выбросить один из pipe is степов своего pipeline а и ускорили время обработки что самое любопытное от выбросили они микро сервис на фортране это я видел первые впервые них там многое такого вот список вещей которые они использовали я хочу сказать что в некоторых ситуациях этим товарищам у которых достаточно небольшой 20 терабайтный набор данных в одной из таблицы 2 тысячи меньше 10 периодически им нужно было перезаливать данные и по какой-то причине перезалив к занимало до трех дней я уж не знаю как они его заливали поэтому иногда им приходилось использовать стандартный statement и сиквела апдейты дэвид и что позволило не перезаливать данные в случае если нужно поменять там три строчки которые расположены в разных временных интервалах когда несколько раз за время их существования и эксплуатации к амстор им понадобилось поджо нить эти две благодаря бледные таблицы им пришлось использовать диск by joy о котором я не сказал но он поддерживается каллум створ то есть если данные в память не влезают вы можете по j нить его с выбросом промежуточных данных на диск это конечно будет медленнее чем in диск join in memory джойана распределенных узлах но тем не менее он выполняется параллельно и сойдется на следующих нескольких слайдах я перечисляю типы данных поддерживаемых ну тут стандартно int i chase dsm lw строчные бинарные типы отличаются особенностью вы можете там хранить до двух гигабайт данных но я не рекомендую конечно к вам скоро использовать в качестве блок хранилища картинки там хранить можно но больше не стоит и поддерживаются кодировке utf-8 временные данные обладают при сезон до микросекунд вы можете их использовать и следующая секция это рассказ о об особенностях использования граблях которые могут встретиться на пути администратора или программисты использующего к вам старт и тут я буду использовать двух персонажей вася и петя вася у нас человек импульсивный поэтому он старается всегда реализовать первое правильное по его мнению решение которое пришло ему в голову не всегда это приходит приводит хорошим результатом а петя принимать взвешенные решения и кроме этого у него есть некое знание некоторые знания об архитектуре внутренней каллум стара и оба персонажа будут исполнять несколько сценариев и мы посмотрим на то что они получили в результате как это можно сделать лучше и какие особенности объясняют поведение пятен по и поведения каллум створа в случае исполнения петей или уазик первый сценарий ну как и в большинстве аналитических движков отдельно взятые insert и в базу это не про это нагрузка которая обрабатывается но она имеют некоторые пенальти и как следствие отдельный invert может занимать значительное количество времени по сравнению с вставками данных пачками в этом сценарии обоим персонажам нужно вставить по 100 строк и вася запустив скрипт начинает вставлять и в результате он получает 100 секунд ну 100 секунд для 100 строк это недопустимая производительность петя знаю об особенности работы аналитических движков в целом и к вам стр в частности использует один из методов пакетной ставки самый быстрый это консольная утилита happy импорт и он получает результат менее 1 секунды но если бы он вставлял скажем пачку в 500 тысяч значений то он бы получил ту же самую секунду методы вставки пачками различаются и по скорости и по удобству использования поэтому давайте посмотрим на то что есть колонн store самый первый метод который который мне приходит на ум это сипим порт отличается он тем что это консольная утилита которая взаимодействует с кластером поэтому а она запускается из linux из одного из узлов кластера но работает быстрее всех потому что пишут минуя все промежуточные слои напрямую в демона которые дальнейшем пишут на сто раз эти два statement а которые можно использовать в сеуле позволяют использовать они используют под капотом тот же сипим порт но у них есть некоторое ограничение в частности insert select он требует для вставки данных по какой-то промежуточную таблицу который в которой данные уже должны быть на мария baby и это занимает время и место loaded in file это другой statement и вы наверняка про это знаете он позволяет ставить данные в том числе с локального файла который расположен на клей на компьютере подключающийся клиента на прошлой конференции в нью-йорке ко мне подошли ребята из d бивер и спросили каким образом можно быстро вставлять данные скалам створ ну мы с ними поговорили и вот они как раз решили использовать loaded in file хотя я думаю что можно посоветовать им сейчас и другой метод о котором я расскажу на этом слайде эмси из импорт это еще одна утилита сторонняя которая является попыткой переписать сипим порт для того чтобы позволить его использовать на большем количестве операционных систем частности он может быть запущен из под windows пока он уступает в производительности сети импорт но ведутся работы по ускорению под капотом mcs импорт используют специально написанный для программного доступа к каллум star walk right и pr пока это только rai 3 и то есть вы можете из плюсов java и python и от других языков которые поддерживаются писать напрямую в каллум stor минуя секундный интерфейс интерес импорт как раз использует версию для си плюс плюс последний вариант это использование все-таки inserto но вставка ни одной строкой вам множеством поправив определенный параметр на мария ди би сервере который ограничивает количество данных которые вы единоразово можете сдавив ставить мы можем получить быструю ставку но то есть по сравнению с happy импортом это будет все таки медленное но тем не менее а если сравнивать по времени те же 300 тысяч вставка 300 тысяч значений занимает 2 секунды насыпем партии то 1 1 и 2 секунды и при увеличении количества строк который мы одновременно вставляем разницы будет расти соответственно я бы посоветовал для начальной загрузке большого объема данных использовать типе импорт который максимально проанализирует и чтение и запись а для какой-то периодической вставки данной последующем в последующем можно использовать insert с множеством строк часто возникающий сценарий перенос данных и shoes iu из уже существующих лтп таблиц в к вам stor это задача часто возникает в и теле допустим у нашего финте карского клиента есть необходимость периодического переноса данных извел типе таблицы в колун стар и вася ничтоже сумняшеся создает таблицу с идентичной схемой и после этого исполняет insert select и время исполнения этого запроса к сожалению может варьироваться есть запросы которые исполняются максимально эффективно и как следствие время которое он потратит на вставку будет минимальна потому что первое insert select использует тот самый тип импорт под капотом и запрос на получение на выборку данных исполняется эффективно но есть такие запросы заковыристые которые работают не так быстро как ожидается например но не quick join когда у вас включи что-то отличное от равенства и петя зная об этом использует простое решение это выборка selecta с последующей передачи по pipeline но все импорт что позволяет ускорить процесс вставки все значительно почему так происходит почему что это работает быстрее что-то медленнее ответ на это режима исполнения запросов каллум старт есть родной режим запроса хорошо родной режим исполнения запросов в котором каллум star обрабатывает все данные внутри есть режим совместимости различаются они набором поддерживаемого сик вольного интерфейса работа набор совместимости на самом деле обсчитывает данные в марии деби сервере и вы можете выполнить запрос произвольной сложности в этом режиме но это будет происходить медленнее потому что открыл им stora в этом случае мы получаем только либо fulham либо скан отфильтрованный предварительно по предикатов и есть ещё третий режим гибридный который позволяет сначала попытаться использовали исполнить запрос в родном режиме после этого переключиться в режим совместимости если первый не сработал сценарий при котором мы хотим вставить максимальное значение из доступного диапазона значений для in the запросу нас сверху под названием слайда василий вставляет и мы видим что на выходе в таблице будет значение на 2 единицы меньше и у меня вопрос к вам как вы думаете почему так произошло куда куда делись эти 2 2 единицы почему вставленное значение отличается от полученного ну на самом деле подсказка для ответы находятся в названии слайда и петя знаю об особенности он для того чтобы обойти это ограничение которое заключается в необходимости сохранить два значения 2 и этого значения с диапазоны для ну love & м ти значений он использует один из двух методов либо он создает колонку более широкого и туда сохраняет то что ему надо либо он использует танцы антип и отдельная колонка несет значение знака вставляя данные он получает ожидаемое значение этот слайд еще одна боль для всех аналитических движков которые могут хранить таблицы произвольной ширины но в частности к вам сторону из-за ограничений на мария де пье не в нем может сейчас содержать примерно 3900 950 колонок можно и больше но для этого требуется изменения в коде марии де беф и это будет скоро сделано поэтому когда вася хочет получить по привычке звездочку из таблицы в которой 500 колонок ему нужно прочитать данные для этих всех 500 колонок петя зная об этом он так не делает он выбирает только то что ему надо и в частности он прочитает данные только для вот этих пяти колонны которые используются запросит еще одна особенность к вам stora это так как делать какие типы данные использовать для эффективной фильтрации эффективная фильтрация предусматривает отбрасывание большого количества значений блоками по 8 миллионов еще до начала исполнения запроса и зная об этом петя по сравнению с васей принимает решение использовать более короткий тип данных в частности для названия страны по которой он фильтрует он прячет в чар 2 после этого его запрос исполняются на порядки быстрее тему увози объяснение этому тому что у нас во первых я расскажу про типы файлов которые используются для хранения данных для того чтобы подвести плавно к механизму предварительного отбрасывания данных файлы существует двух типов сегментные иди ksunory файлов сегментных данных мы храним данные которые ширина которых составляет 8 бань в dictionary мы храним тексты было бы волчары шириной больше восьми этот процесс отбрасывания называется в комстар extend illuminations и он позволяет как раз таки и резко снизить количество данных участвующих в исполнении запроса и тем самым уменьшить нагрузку на дисковую подсистему и ускорить запои исполнения запроса как я говорил уже мы поддерживаем строки в ю т ф но есть ограничение для каждого hotpoint iii tf используется два байта поэтому ширина колонок которые могут быть задействованы в extend или myon & shane уменьшаются два раза это надо учитывать и как в других движках строковые функции возвращают фактическое длину в байтах они в символах ордер buy вколол штор бывает двух видов он бывает родной исполняемой на стороне каллум створ и более более фирса тайл более разнообразны по поддерживаемым функциям но исполняемой на стороне мария baby сервера и в данном случае два наших персонажа получат разную производительность казалось бы одинаковых идентичных запросов а причина в том что режим ордер buy предоставляемой им самим морей тебе сервером он медленный для того чтобы передать мария baby серверу для начала нужно данные материализовать в строки передать на сервер исполнить сортировку и отправить клиенту много мест где производитель насильно просаживается кроме этого сортировка идет в один поток на стороне сервера исторически так получилось что каллум star предполагался для использования в запросах с агрегации и как следствие большое количество данных сводилась до небольшого количества соответствующего количества групп и мы использовали только агрегаты ну то есть возвращались десятки тысяч строк но не миллионы случае если вам нужно отсортировать миллионы строк мария baby просядет но разработчики в свое время приняли такое решение поэтому существует два этих режимов и самым простым способом обойти использовать родной режим это обернуть ваш запрос в под запрос таким образом будет использоваться эффективная сортировка join и join и в каллум створ исполняются в общем виде распределена и это хозяин и но есть одна особенность которая который нужно учитывать это ограничение на размер таблицы передаваемой по сети для запуска этого распределенного join a есть параметр который указывает сколько данных мы можем передать на на второй слой на третий слой на слой движков исполнителей и тем самым запустить этот бродкаст join и этот параметр по умолчанию составляет всего 64 мегабайта поэтому если вы хотите по joy нить таблицы десяток размер которых составляет десятки гигабайт то вам нужно поднять этот параметр и это можно сделать как в конфиге прибив это значение гвоздями такта и в рамках одной секунды и сессии к сожалению каллум star не может предоставить высокой производительности на запросах вида приведенного здесь то есть выбирать какое-то одно значение одну строку колонн star умеет сделает это параллельно но индексов в нем на данный момент нету поэтому не стоит рассчитывать на высокую производительность и я бы рекомендовал избежать подобных подобного вида запросов а если еще вместо конкретных колодок поставить звездочку и запустить это на таблицы из 500 из 500 колонок то вы порадуетесь за производительность как я говорил уже каллум штор поддерживает дэвид и но если вам нужно быстро удалить большое количество данных и они находятся в каких-то диапазонах вы можете использовать простые файловые операции которые сойдутся намного быстрее причиной этому то что дэвид на самом деле это апдейт и он перезаписывает во всех колонках специальные магики empty значений в то же время использование функций которые применена петей позволит вам свести это все файловым операции некоторое время назад ко мне пришел клиент и задал вопрос почему его запрос который достаточно тривиален и возвращает набор данных составляющих несколько миллионов работает очень медленно и после небольшого анализа я понял что производительность упирается в одно ядро на стороне морей тебе сервера поискав причину я обнаружил с удивлением что мария baby сервер умеет предварительно кэшировать данные отправляемые клиенту по клиентскому протокола и в случае если это миллионы строк то он делает это очень медленно и если вам нужно выбрать набор данных составляющей миллионы строк отключайте пожалуйста это кэширование по сравнению если сравнить 16 миллиардов строк в 16 миллиардов фунтов выбираются искал амстор за с включенным кэшированием за 50 секунд без включенного кэширования данных начинает возвращаться сразу и запрос сходится за если не ошибаюсь 10 секунд но это измерение на моем лаптопе но то есть есть разница и это порядке на этом я заканчиваю свой доклад если у вас есть вопросы то я готов на них ответить да я думаю что это займет у меня генерация этих данных займет у меня какое-то время но вы можете подойти за пределами и я вам продемонстрирую но я думаю что и так могу я думаю что можно без него я вас прекрасно слышу я повторю да нет не так это видимо микрофон включился немного не так если вы хотите закончить вопросы задавайте я просто ответь иную понятно в каллум star используется другой подход позволяющий сократить дисковую нагрузку и этот подход называется extend и liberation мы храним определенные метаданные о пачках 8 миллионов значений то есть у нас мин-макс по из этого из этой пачки и мы можем отбрасывать эти данные эти блоки по 8 миллионов зная запрос и знает предикаты запроса то есть если у нас есть определенные фильтрации которая говорит что нам нужно значение больше определенного мы выбираем только те блоки по 8 миллионов которые нам нужны которые действительно попадут в этот разум вы кино нет вопрос в том какой метод обработки запроса используют наш оптимизатор на самом деле у нас есть достаточно рудиментарный оптимизатор который из методов оптимизации может себе позволить только поиск таблицы фактов и это связано с особенностью модели данных используемых на аналитических хранилищах то есть в основном используется звезда и на текущий момент этот оптимизатор может только использовать extend элемент шин и поиск таблицы фактов для того чтобы не таскать ее вот в этом братка с джо и не то есть мы знаем что это таблице фактов поэтому с ней будут жениться это будет big says backside м.л. но в следующей стабильной версии мы серьезно перерабатываем этот подход и мы будем предоставлять мария baby сервера статистику в виде гистограмму о распределении данных о количестве индиви и на основе этого мы будем использовать функционал самого сервера то есть они будут для нас перезаписывать запросы и оптимизировать под наши нужны запрос то есть все что существует в оптимизаторе мария baby все хаки мы будем их применять на колу mstar вопрос заключался в том есть ли в планах поддержка джейсон у меня встречный вопрос а какие функции работы с джейсон вам нужны почему вас не устроит использование текста в качестве хранилища для джейсен то есть вы хотите иметь быстрый доступ каким-то частям джейсона каким-то полям джейсона известную структура внутри поля и в нее нужно залезть и по значению поискать понятно пока таких планов нет и мы останемся с вар чарам ускорив собираемся мы очень сильно ускорить работу с строками произвольной длины и это единственный метод который наверное можно применить для джейсона потому что я поясню почему в самом мария baby сервер внутреннее представление джейсона эта строка то есть у них нет джейсон где формата и если не ошибаюсь стандарт сиквел который описывает поддержку джейсон он также говорит о том что храните джейсен строках но планов каких-то по поводу джейсона не было потому что в первую очередь не было запроса поэтому если вы придете в наших жиру и напишите фичи request будет чем апеллировать при диалоге с продакт-менеджер почему подскажите вы упоминали для множественных insert of можно использовать нужно подстраивать иногда параметр mat spy kids а я почему-то размер с размером суммой размером 7 байт всех колонок который вставляется как его оптимально вдаль на вычисление вы можете описать пример на основе которого вы вот такое утверждение делаете что не совпадает то есть вы вы вы померили размер самого запроса и размер заводных данных сумм от суммы размеры всех вставляем их данных она получается реально больше чем минимальный необходимый макс пакет says обращение что данные сжимаются ну на самом деле чтобы ответить на этот вопрос наверное тут нужен специалист из морей db на но если вы подойдите ко мне после моего доклада я залезу просто в код и посмотрю каким образом они считают ограничения спасибо еще один вопрос если можно если данные находится в и на дпс сын к деньгам допустим гтф mp4 здесь в ю т ф два байта их можно будет колом стоит перевести как то до их можно перевести но насколько мне известно юта фм4 он как раз использует два байта не он использует два потому что используется доступен только сосед не то есть какое-то ограничение на количество доступных код поинтов понятно да точно можно потому что не так давно у нас был переезд 1 банка южная азиатского крупного сингапурского и вот они как раз переносили данные в том числе и у них данные были в ютов и поэтому я точно могу сказать что да это можно сделать спасибо за доклад хотелось задать вопрос по поводу апдейтов далитов полноценные ли они или ситуация аналогична как ли хаусе то есть там alter апдейт alter делит и еще второй вопрос и сразу по поводу baci ставки нужно копить вот эти бочки на уровне приложения или есть какие-то будущие планы по поводу интеграцию с кафкой сделать чтобы это все бросать и грубо говоря не заморачиваться они комп лением бачи бачи вот этих памяти ну ответ на первый вопрос это полноценный апдейты дэвид который в том числе умеет мульти апдейта есть с джой нами в запросе далит деле поддерживает такой же функционал фактически это является апдейтом как я говорил составляющим специальные мти медики по поводу второго вопроса вы можете использовать промежуточную таблицу и на тебе которая позволяет делать одиночные вставки и это занимает десятки миллисекунды он сам какой-то полинг есть этой таблице то есть по какому критерию будет грубо говоря бачу формироваться в данном случае вы можете формировать его самостоятельно то есть схема который вы можете применить может содержать это поле которое может говорить о том что вот данные именно этого бача нужно перенести спасибо подскажите пожалуйста лучшая защита от дурака на мария де беф той ситуации когда кто-то ошибочно удаляет данные ну допустим деле там несколько тысяч строк ограничить в правах дурака нет но если это нельзя сделать поскольку репликация в этой ситуации не спасает бэкапом до моста достаточно старый что-то еще можно сделать вы знаете в голову мне вот так ничего не приходит но если вы подойдете ко мне то мы можем кроме того что посмотреть как работает возврат энтов так и посмотреть что какие из методов кода какие из методов в коде позволит вам сделать достичь и 2 результата спасибо вы сказали что данные не удаляются просто помечаются в начале можно ли их нет польза это вот проблема в том что не вначале простите что перебила это не вначале они перри записываются значениях перезаписано то же место на то же место спасибо у нас в планах есть заменить апдейт делите на bitmap операцию что выглядит более логичным и как следствие тогда данные будут оставаться и можно будет получить из коробки вот тот функционала которым вы говорите данные остаются на месте но в bitmap ах просто помечаются строки"
}