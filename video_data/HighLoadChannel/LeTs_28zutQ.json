{
  "video_id": "LeTs_28zutQ",
  "channel": "HighLoadChannel",
  "title": "История создания системы потоковой аналитики в реальном времени / Ренат Идрисов (MZ)",
  "views": 1238,
  "duration": 2302,
  "published": "2019-06-03T08:57:35-07:00",
  "text": "от я приехал из паспортного берлина рассказать о он как разрабатывалась система потоковые видео аналитики для начала какую задачу мы решали с точки зрения бизнеса есть город есть камеры в городе и они генерируют какую-то информацию у нас есть какая-то система которая выдает например оповещение какие-то оповещения это например оповещение о пробках оповещения каких-то ну чрезвычайных например ситуациях о том что большое количество людей скопилось где это ну то есть пробки можем могут быть пробки автомобилей пробки людей просто загруженных дорогах ну например даже плохой погоде в общем какие угодно должны быть оповещения кроме того каждый месяц им хотелось видеть как используются дороге какая у них способность на тот случай например если дороги и близки к своей максимальной пропускной способности чтобы как-то оптимизировать сеть что-то с ней делать то же самое там для пешеходов и интроспекция интересный такой момент сейчас я покажу как это выглядит то есть это скриншот не нашей системы к сожалению наша система пока еще не выложено open source поэтому я решил для безопасности использовать скриншот другой системой что вы случая не нарушить ничьи права от и это сын стоим разрабатываются китайцами из серии что всегда есть взят который сделает что-то лучше тебя но это не такая же система как у нас такая же она с точки зрения интроспекции но у них все эти алгоритмы прибиты гвоздями а у нас грубо говоря и pr и туда можно внедрять любые алгоритмы любой анализ который грубо говоря инженеры по компьютерам зрения напишет что здесь видно я думаю что на слайде сложно разглядеть но там очерченные машины написано что это красная машина очерченный люди написано что этот человек носит штаны этот человек носит рубашку с коротким рукавом это взрослый вот это велосипедист и так далее и все они движутся то есть эта штука во первых конечно производит такой вау эффект на инвесторов на потенциальных заказчиков и так далее но кроме того она служит подтверждением того что система действительно работает потому что если бы мы видели только статистику вот из предыдущего кадра то в конце месяца грубо говоря или там в конце недели в конскую в конце дня мы бы могли посчитать сколько у нас помаши машин прошло по дороге и сравнить например с правда который мы знаем там это либо человек либо устанавливается специальный такой как металлоискатель под дорогу который фиксирует нахождение большого металлического объекта то есть он очень точно считает и мы можем сравнить наши алгоритмы с ним но может так быть что наш алгоритм выдает все правильно но на самом деле он детектирует немножко не то по какой причине например он детектирует легковые машины полтора раза грузовые машины там 0 3 раза например при каких-то соотношениях это может давать правильный результат а при каких-то других соотношениях это начинает ломаться поэтому интроспекция очень важно тоже с точки зрения понимания того что все действительно очень точно и очень правильно работает вот какие цифры один видеопоток из 10 4 с таким разрешением это 8 мегабит примерно это уже 86 гигабайт данных день если у вас 100 камирта это примерно 8 терабайт данных день я могу сказать что камеры которые мы используем имеют больше разрешения естественно и стока мир это ну это наверное какой-нибудь маленький город и не знаю деревня какая-нибудь для москвы конечно это цифра скорее всего возможно даже на пару порядков больше но для городов вообще как бы 1000 это более характерно но тем не менее стоит уже 8 терабайт вот какой был соблазн когда значит мы разрабатывали систему мы думали о том что можно например попозже посчитать статистику более точную то есть мы например выдаем какую-то интроспекцией у которая не совсем точное но для человека выглядит очень хорошо а потом например в конце дня мы считаем статистику таким образом у нас есть вот этот поток данных мы находимся в каком-то его положение днем например появляется очень много объектов за которыми нужно следить это вычислительная сложность и мы начинаем постепенно отставать по времени то есть мы отстаём отстаём устаем здесь на графике может быть слишком мелко я написал цифры но здесь отставания примерно 600 секунд пунктиры различают день-ночь день и днем и например уходим немножко назад ночью мы нагоняем когда никого нет у нас на камере ничего не происходит и вроде бы хорошо живем но проблема в том что естественно камерой не хранит эти данные мы не можем так вот попросить камеру выдавать нам например по-разному не потому что такой технической возможности нету потому что все алгоритм еще немножко с разной скоростью работают вот и в любом случае нужно эту проблему хранения где-то решать то есть эти данные куда-то скидывать и потом как я еще скажу восстанавливаться после сбоев если что-то произошло и еще как показала практика когда рэнди инженеры начинают работать в таком режиме что и можно немножко отставать они начинают отставать немножко сильнее чем возможность нагонять то есть они допустим посчитали у себя что мы отстаём на 5 процентов за день мы уходим назад ровно на столько сколько мы можем заносит догнать потом код релизиться оказывается что процессоры немножко хуже чем они думали и вся эта система начинает отставать оставать оставать и в конце концов естественно все крыши цапа out of memory потому что данных никогда не становится меньше то есть если не сломается камера у нас не появляются возможности это все дома обработать то есть наступает время бесконечных данных это отсылка естественно ко времени приключений и здесь я попытался изобразить и usb провод пересекающей слова время вот если посмотреть википедию есть такая парадигма как событий на и программирование и когда тает ощущала считалось даже без practice то есть завести цикл и начать все обрабатывать получить обработать ответить но это в нашем случае да мы считаем что обработка какая бы она ни была сложная скрывается за обработать но и как бы получить вот эта идиома вот известно идиома как бы и использовать идем и конечно очень хорошо вот но с этой идеи возникают некоторые проблемы именно проблемы возникают когда у вас следующий шаг например дольше чем предыдущий и все это начинает затыкаться вот а где начинает затыкаться начинает затыкаться на уровне тисе пи скорее всего если вы останавливаете получатель то он перестает разгребаться с данными которые ему поступают забивается его буфер и начинается начинает забиваться буфер отправителя то есть на самом деле некоторые скажут ничего плохого об этом уже очень много людей подумали есть can женщин control flow control там много-много всего в тисе пи чтобы работать вот с такими ситуациями чтобы обрабатывать ппш но это очень хорошо работает когда у нас данные все-таки заканчиваются когда-нибудь а когда они не заканчиваются эта ситуация приводит к тому что данные начинают копиться дал буфера у отправителя то есть соответственно на камере еще где-то то есть камера должна их как-то хранить и кроме того должна быть какая-то уверенность что наступит все-таки момент когда вы их обработаете наконец потому что иначе но бесконечно копить никто не может быть будет крошиться камера и будут крошиться все соответственно алгоритмы вот естественно их нужно дропать и естественно если алгоритм медленно и дроп они в любом случае где это будет происходить проблема этого подхода в том что дропа не будет происходить на отправителе рэнди инженером и вообще тем кто разрабатывает алгоритмы всегда хочется контролировать как-то как дропать то есть можно например дропать каждый пятый можно ну какие-то другие стратегии применять мы не хотели ограничивать пользователей системы той стратегии которая мы например написали на камере вот есть такой вариант обрабатывать многопоточную на же много ядерно вычислительной системе мы можем допустим когда получаем новое сообщение создавать новый поток его обрабатывать новом потоке и допустим завершать новый поток когда вся обработка завершается но это плохо с той точки зрения что если алгоритм действительно медленные мы все равно где-то уткнешься в количество потоков и еще проблема в том что вот это все многопоточную часть мы пишем на си плюс плюс и код обработки мы отдаем обрабатывать нашим написать нашим рэнди инженером который как бы с трудом пишет си плюс плюс код многопоточности + + код это очень сложная штука и тем более если им хочется иметь какой-то стоит им приходится городить локи и это все конечно очень хорошо забивается и этот подход просто не работает как а есть вариант есть вариант для того чтобы получить какой-то более осознанный дроп кадров завести буфер между получателем и обработкой то есть получать и складывает в буфер обработка берет из буфера и соответственно обрабатывает но тут есть ряд проблем более или менее серьезные но в целом решаемый какой размер буфера брать то есть для каких-то алгоритмов например этот буфер можно оставить маленьким для каких-то алгоритмов его хочется сделать очень большим на примере для таких которые собираются отставать на на час или как то еще есть проблема того что это должно быть конфигурируем и кроме того если например у вас система с маленьким буфером упала докер-контейнер перри запустился вот подхватил опять поток и пошел работать вроде бы ничего страшного но увидели какое-то мигание там подумали может быть алгоритм как-то плохо сработало ли что то еще произошло но если если этот буфер успел напиться очень сильно то вы теряете ну какое-то время необработанных данных и нужно думать о том как его делать мир системным например и как его восстанавливать при сбоях кроме того когда возникает буфер то есть если его сделать маленьким например если считать что мы ну как в основном успеваем да даже вот сделали простой анализ там просто убираем фон и что-нибудь считаем мы успеваем например все хорошо мы сделали маленький буфер там три кадра оказывается что операционная система периодически делает какие-то вещи которые не совсем от нас зависит и у нас происходит фрейм drop и то есть такая ситуация была вроде бы все хорошо вроде бы алгоритм быстрый и вроде бы циpкa не сильно загружены но периодически происходят потери кадров и для рэнди инженеров это например большая проблема вот они говорят ну как же так мы теряем целых два кадров в час мы не можем построить алгоритм ну то есть есть люди которые просто будут на вас всегда сваливать свои проблемы говорить но как же так но вот не работает система ну теряет кадры на нельзя развита написать так чтоб не терял но решается это конечно увеличением буфера в данной схеме да но тем не менее опять же возникает вопрос насколько его увеличивать вот и кроме того для разных алгоритмов как я говорил хочется иметь различную различные варианты управления этим буфером то есть кому то нужна самый свежий кадр кому-то нужно самый старый кадр кому-то нужно чтобы расстояние между кадрами там не превышала какой-то как как какое-то количество вот и соответственно нужно давать и интерфейс для управления этим буфером мы даже в какой-то момент начали обдумывать этот интерфейс и получилось что ну короче такая сложная штука то есть если например алгоритм хочет обрабатывать самый свежий кадр он у знает сколько кадров буфере и потом например берет самый последний все остальные drop it но в это время другой поток может положить что-то в этот буфер естественно ему нужно этот буфер блокировать блокировки пользователям этого буфера приводят ну плохим ситуациям когда опять же начинает блокироваться получаете начинается начинаются круговые сети блокировки и все работает очень плохо кроме того есть в процессе разработки выяснилось еще такая интересная штука то есть я начну с того что покажу как все работает нормальном случае то есть у нас например есть декодирование мы получаем в этой схеме кадры по сети и либо из файла как только мы показали кадр мы начинаем декорировать следующие потом начинаем обрабатывать следующий то есть все довольно просто если кто-то не может прочитать там сверху декодирование потом обработка потом пок пока эскадра все происходит по порядку если вдруг у нас в одном месте обработка затянулось ну что происходит мы не видим аннотации на кадре номер 3 и либо видимых на каком-то другом кадре кадр просто теряется и вроде бы ничего плохого но этой ситуации как я говорил плохо для повторяемости выяснилось это когда начали тестировать алгоритмы то есть написали какое-то условно говоря алгоритм для продакшена и решили написать другой алгоритм который работает например медленно но очень хорошо и работает непредсказуемое количество времени но как бы там 100 там в тысячу раз медленнее как а есть вариант просто можно было замедлить замедлить видео и тогда получить чудовищно большую обработку то есть замедлить его до самого медленного кадра и все это обрабатывать но хотелось иметь вот что то такое то есть хотелось чтобы вне зависимости от количества кадров где зависимости от времени работы алгоритма каждый кадр полностью обрабатывался но в такой схеме с буфером это естественно решается очень просто делаем бесконечный буфер к чему это приводит это приводит к тому что все это огромное количество кадров как только вы запускаете тест на двух гигабайт нам файле сразу всех кадры декодируются складываются в буфер и потом может быть этот докер-контейнер выживет после ну скорее всего упадет конечно по out of memory вот но возможно тесты пройдут и соответственно промежуточное решение которое было сделано этот двойной буфер это буфер перед получателем и 2 буфер маленький который нарисован только маленьким буфером которым уже управляет внутри алгоритм плюс специальный флажок для этого особого режима когда нужно получать получать данные в пакетном режиме то есть решение написано в кавычках потому что это на самом деле совсем не решение да как я думаю все понимают просто добавили еще один буфер то есть сначала тисе пи буфер идет потом после получения буфер потом внутри алгоритма удобных буфер который с которым он делает что угодно это как бы и известная штука известный приём как бы велосипед на велосипедах но какие проблемы более конкретно то есть я говорил уже что многопоточный код для research инженеров это какая-то сложная штука и вроде как здесь не слишком сложным многопоточный код просто один поток складывает в буфер 2 берет какой-то там небольшой лаг чтобы избежать проблем и вроде бы ничего но так как этот код под контролем research инженеров то они его естественно сломали в какой-то момент то есть внесли во первых своих дополнительно всяких штук которые позволили очень гибко управлять буфером ну и конечно от гибкости код загнулся для пакетного режима как я уже говорил уже потребовалось дополнительный флажок протаскивать через все и кроме того год стал вот этот алгоритм обработки стал знать что его запускают пакетном режиме что-то довольно плохо то есть как бы если он допустим не знает то у него точно также внутри этот буфер переполнялся решение ужасное вот и проблемы с повторяемостью не ушли потому что какой-то из буферов маленький либо кааба буфера бесконечные но решается это на самом деле все не так сложно то есть есть такая штука реактивные потоки которые собственно появилась из паттерна подписчик то есть есть наблюдаемая есть наблюдатель и наблюдатель подписывается на наблюдаемое получают какие-то события то есть есть различные модификации то есть вот это вот самая понятная да это же жадная так называемая модификация почему именно жадная будет понятно последовал как я расскажу про ленивую но если кто-то знаком с этой терминологии то как бы это должно быть вполне очевидно то есть обычные языки программирования которым мы привыкли если мы не хаскеле программисты это все жадные языки если мы пишем вызов функции то при передачи аргументов туда они вычисляются то есть если мы написали какую-то функцию анала если пейдж даже если функция ничего не делает то веб-страницы все равно загрузится если мы написали взять пять чисел из чисел от 1 до 1000 то эти числа все равно все вычисляться вот и это собственно называется push потому что аргументы грубо говоря отдаются в поток тем кто и ими владеет да то есть сначала скачивается потом туда отправляется но противовес есть ленивый метод это пол метод и собственно в этом случае страницы уже не загружается то есть может загрузиться может не загрузится может как-то частичного и числится это знакомо я думаю всем по конвейерной обработки которые есть unix системах когда вы результат допустим выхлоп одной команды отдаете в другую не факт что ваша первая команда сразу же весь свой файл прочитает не будет остановлено в какой-то момент вот и это также реализуется в ленивых языках программирования то есть грубо говоря здесь отдается не результат функции fitch которым является уже допустим текст этой странице а такая ручка за которую функция in a lazy пейдж может потянуть а может не потянуть то есть на самом деле это очень привлекательна тем кто впервые открывает для себя ленивую схему начинаю думать что они получили просто сверх способности можно оперировать бесконечными потоками можно взять первые пять чисел натуральных чисел потому что они будут все вычислены они будут вычисляться только когда их попросят но тут конечно вопрос да можно реализовать лиги вую схему неправильно и можно этот аргумент начать вычислять полностью но как бы в любом нормальном языке этого не происходит то есть вычисляются только первые пять и это происходит потому что когда потому что в этой схеме в обычные наблюдаемый наблюдатель появляется дополнительный запрос на данные то есть мало того что наблюдатель оформил за подписку он еще и отправляет запрос как только он готов получить дополнительные данные как только они ему нужны то есть возвращаясь к вопросу о странице да они могут но данные со страницы могут не понадобится либо могут понадобиться как-то частично и пакетная обработка которая говорил это как раз таки ленивый режим который отлично вписывается как только вот алгоритм анализа готов принять следующий кадр он запрашивает его и запускается чтение декодирования и обработка но как я говорил да сверхспособностей не появляется на самом деле почему все языки до сих пор не ленивые это потому что сливом режимом гораздо сложнее как бы сказать о и он гораздо сложнее отлаживать потому что не всегда понятно что и когда вычисляется и ну многие говорят что он не эффективный потому что когда нам понадобился показывать кадр грубо говоря когда мы его хотим показать мы только запросили чтение из файла и нам нужно вот эти вот все этапы пройти либо как в некоторых языках программирования делают гибридную систему грубо говоря запрашивают немножко данных которые скорее всего понадобится до того как их попросят и таким образом пытаются минимизировать накладные расходы но тем не менее это приводит к еще большей сложности при отладке вот как реализуется вся эта схема с велосипедами в велосипедах грубо говоря по нормальному то есть есть источник кадров есть приемник этих кадров и источник других я написал одних других здесь имеется ввиду кодированные декодирование просто слова получились бы довольно сложные и не влезли бы на слайд вот здесь соответственно источником является файл камера или сеть декодер тоже как бы hd с 4 века на энтом что угодно подключается дальше стоит накопить группировать который осуществляет вот как раз буферную функцию и отдает накопившийся куски в нутрь видео алгоритма внутри видео алгоритмы находится отбрасывать которые уже сам решают то есть грубо говоря в отличие от предыдущей схемы где у нас был век а где у нас был буфер ручки которому мы отдавали и давали возможности как-то этим буфером управлять здесь появляется вместо кадров виктора кадров которые отдаются полностью и по которым алгоритм уже решает как их отбрасывать то есть брать 1 брать последний брать каждый третий или что-то еще делать кроме того мы реализовали встроенной отбрасывать или для того чтобы ну research инженера мне приходилось думать слишком много об этом вот и встроенные имеют естественно функцию самых новых самых старых кадров все такое вот и есть приемник аналитики которые уже получает информацию которую мы экспортируем из видео вот когда рекомендуется вообще использовать такой подход рекомендуется всегда когда не получается предсказать размер входных данных то есть если вы знаете что у вас данные ну грубо говоря опять мегабайт не не то чтобы ваш один видеофайл 5 мегабайт а то что вы всегда будете использовать данные например лимитированного это размера то скорее всего потоки не нужны кроме конечно этого случая они обеспечивают гораздо более слабую связываю масть то есть компоненты не так сильно зависят друг от друга и по коду и по интерфейсам они просто получают объекты одного типа порождают объекты другого типа то есть вам не нужно ну думать о дополнительных зависимостях и такие штуки есть естественно во всех более менее развитых языках программирования то есть у нас весь этот проект на плюсах есть пустая streams есть а к streams истерик джесси реактив поджал везде вот но и собственно это все что я хотел рассказать спасибо за доклад слева слева а я хотел спросить по поводу механизмов отбрасывать или и в частности отбрасывать или и встроенных а если какие-то встроены они просто глупы то есть какой-то пятый кадр седьмой кадр отбрасывает или они вычисляют какие-то там smart алгоритмы типа похожие кадры отбрасывать еще что-нибудь подобное но нет то есть умных по дефолту умного отбрасывания нету и ну как там интересно вообще вопрос то есть у нас естественно вот эту часть разрабатывают грубо говоря инженеры типа меня прогнал обеспечивания часть алгоритмов разрабатывают и рэнди инженеры и мы смотрим что им нужно и пытаемся какие-то штуки реализовать и вот таких у них идей не было как ни странно то есть если бы это сильно нужно было может быть мы реализовали но вопрос да как это там ведь допустим в качестве алгоритма может быть какой-то код который написан там на о гансе вина tensorflow там какая-то определенная модель то есть мы должны как-то ну определенным образом установить критерий похожести ну как бы я не знаю звучит на самом деле разумно для некоторых случаев но у нас такого нет то есть либо самые старые либо самые новые либо там три равномерно что-нибудь такое но один добрый у меня вопрос такой у вас задача ставится но видео принципе полная оставить или у вас есть возможность в принципе не снимать или частота кадра может быть там губы 10 кадров секунду 5 кадров секунду либо вообще не быть ни и второй вопрос если можно не снимать не думали вы о том что можно это не обрабатывать то есть саму картинку использовать губы датчики там лазерный и то есть чтобы уже была команда камере снимать и снимать снимать не снимать то есть не брать видео изначально за как обработку чтобы понимать сколько часто такая какая должна быть ну насчет разной частоты кадров ну допустим камера генерирует 25 кадров в секунду на примерно мне не нужны эти кадры нам нужно только 10 кадров в секунду но это мы можем узнать только вот от research инженеров то есть у нас система как бы не чувствительно к тому что в ней пишут грубо говоря то можно какой-то vision алгоритм делать к которому важно что 10 кадров которому не важно и мы тогда начинаем но допустим если нам кажется что трафик большой мы начинаем research in der спрашивать не подойдет ли вам 10 кадров в секунду они говорят извините нам нужно там месяц для того чтобы все это про benchmark эти для того чтобы понять ее нужно ли нам 10 кадров тогда мы поднимаем дополнительный стрим чтобы они бенчмарка ли и они это проверяют можно ли снимать можно ли не снимать интересный вопрос но этот камень камеры наблюдения они стоят на улице то есть грубо говоря каждой алгоритму может определять какой-то каким-то способом что кадр не интересны заранее да и экономики ну я имею тунис картинки эту информацию выискивать с помощью каких-то других инструментах ну ну вот какие камеры например бывают то есть камера снимает сверху площадь ну которая там наполняется людьми или не наполняется то есть можно поставить и к датчики какие-то которые будут фиксировать что люди пошли на площадь но это сложно во первых потому что камеры уже стоят и но не понятно как это все нужно делать то есть это можно в каких-то случаях но у нас была идея что вот есть уже город есть уже камеры и просто мы получаем из того что уже имеется какую-то интересную информацию то есть алгоритм сам допустим может по но осуществлять какие-нибудь там в вырезании этого фона и смотреть что ничего не меняется и дальше ничего не запускать но как бы внешних других дополнительных источников мы не спали спасибо за доклад на такой вопрос то есть получается при достаточно интенсивном количестве кадров и когда вот там основные алгоритмы они такие сложные могут меняться то есть без отбрасывания кадров то есть получается вообще никогда то есть не удается с материка ну есть просто что такие тяжелый алгоритмы что не получается обрабатывать все или известно медленный эти кадры чтобы вся система не затыкалась да да да конечно ну и плюс чтобы можно было например взять с другой моделью там запустить очень медленные алгоритм который прям там на один кадр может там час например тратите когда-то получить результат да ну то есть чтобы все это не все это конечно решается при помощи там костылей велосипедах там и так далее но вот получился на что там буфер переполняется мы можем там и всегда писать да еще и но это все как бы некрасиво красивее все просто завернуть потоки и как бы там уже имеете возможность переключаться между ленивым и жадным режимом и как бы иметь грубо говоря все что нам нужно было спасибо спасибо за доклад такой вопрос когда вы писали реактивные потоки вы не рассматривали готовые системы по доставке данных скажем брокер вечеринке у рыбе тонкую так далее у нас своя система в смысле имеется система доставки сообщений да я об этом не упомянул в докладе но эту проблему мы не решали потому что у нас своя система передачи сообщений но как бы сложно сравнить с чем-то ну как бы можно сравнить на старт но короче вот проблема штука проблема по части передачи сообщения уже решено то есть от камеры все эффективно мультиплексе руется на эти боты в смысле получатели и поэтому мы уже смотрели проблему вот внутри получателя то есть как бы проблема передачи самих кадров с камеры на на получателей и не было то есть понятно что если например у нас будет стол готов вот этих вот 100 алгоритмов и они все будут каждый отдельно тянуть с камеры поток то у нас сеть клиента перегрузится и все и ничего не будет работать но у нас от камеры грубо говоря один одно соединение в публично вскроет наш сервис который мы подписываемся сами уже и дальше все это получаем от него вы свой сыр и списали потому что он получился быстрее или это как исторически сложилось идея была как обычно захватить весь мир вот если вы посмотрите наш сайт sata редут ком-то наши маркетологи хотели это все продать как twitter для для компьютеров вот и ну грубо говоря мы уникальны в каких-то характеристиках вот и но судя потому что вы не знаете то систему мира вы не захватили да но как бы пытались конкурировать с существующим решениями если так сказать по поводу существующих решения как вы видя не занимался там последние годы 4 следующая берем черный поток не но вы в этом случае управляете отбросам на стороне грубо говоря где порождаете потоки вы не можете но как-то то есть для одного алгоритма так отдать а для другого как-то по-другому дропнуть ну в каких-то пределах то есть вообще на самом деле но почему нет спасибо"
}