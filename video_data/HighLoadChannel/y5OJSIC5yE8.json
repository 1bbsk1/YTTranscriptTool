{
  "video_id": "y5OJSIC5yE8",
  "channel": "HighLoadChannel",
  "title": "Почему ivi перешел со Sphinx на Elasticsearch / Евгений Россинский (ivi)",
  "views": 27353,
  "duration": 3133,
  "published": "2017-12-11T01:34:18-08:00",
  "text": "меня зовут евгений росинский я являюсь техническим директором компании или тут были вопросы или или away на самом деле пофигу потому что название выбирались относительно свободного 3 буквенного домена в котором было что-то связаны созвучно с видео поэтому честно когда мы сами не знаю как она называется вновь привыкли уже иви киви сегодня хочу вам рассказать о том как мы ушли со сфинксы на самом деле это не рассказ про то что сфинкс плохой elastic все очень хороший это рассказ про то что разные инструменты немножко для разного insert инженерные инструменты вот и в двух словах чтобы вас погрузить в проблематику я расскажу собственно где мы использовали сфинкс и куда мы включили elastic search собственно у нас есть и 5 которая позволяет нам работать с клиентскими приложениями клиентские приложения наши призваны для того что для одной цели показывайте видосики через защитить ее лично tps и вот для того чтобы навигировать а по клиентским приложением до делать полнотекстовый поиск делать такие запросы дай мне фильмы тридцатого года с таким-то режиссером нам собственно и нужна была система которая бы позволяла все эти выборки делать казалось бы на первый взгляд идеально в эту структуру вписывается реляционные базы данных и вроде как все просто замечательно и где-то 10 лет назад когда все это начиналось действительно так и было у нас был под гараж какой-то backend каши и все общем стандартная и без выпендрёжа однако наши реалии заключается в том что у нам приходится тесно взаимодействовать с ребятами которые называются правообладатели и поскольку мы легальный сервисы пока нам кто-то что-то не разрешит мы ничего не публикуем и вот эти самые веселые правообладатель придумывают различные очень сложные иногда шизофренических для нас требования например а давайте весь наш контент мы будем показывать именно этого правообладателя hd1080i нам неважно что есть устройство которое то не подтянут ну вот у нас политика компании такая только из 2008 и никак по-другому и вот подобных требований там эти требование могут быть там по территориям там еще где-то их довольно много они вносят большой сумбур и нам приходится параллельно жить точнее одновременно жить в большом количестве вселенных как в общем us была устроена наша и 5 то есть вот есть клиентские приложения которые обращаются через кристовский протокольчик джейсон внутри отправляются на и пей дальше есть сфинкс в котором хранятся по сути все эти шнеки информации для того чтобы осуществлять навигацию по каталогу и редис regis появился тогда когда в сфинксов понять всю перестал помещаться вот мы это вытеснили в редис и заставили эту волшебную конструкцию быть консистентной да то есть вытягиваем айтишники и потом лезем за более подробной информацией в в radice все было бы хорошо вот однако зачем в принципе использовать движок полнотекстовым поиском и потому что мы что сфинкс что elastic search это не только движки полнотекстовый поиск а ну и в общем-то прекрасные движки для обычных простых запросов с простых простой фильтрации с простой выборкой и как это ни парадоксально но работают они оба очень шустро и вот на протяжении там трех четырех лет у нас решение работала на сфинкс м и горя не знали имели очень хорошее время ответа значит а дальше началась чем старше мы становились чем больше у нас появлялась бизнес-логики вот тем сложнее нам было управлять всем этим добром значит во первых с одной стороны у нас есть правообладатели которые накладывают на нас ограничение что как и где мы можем показывать с другой стороны у нас есть технические ограничение платформы которые говорят что эта платформа умеет воспроизводить умеет показывать дает начиная от контейнеров там мечела сдашь mp4 и прочие заканчивая там системами защиты как-то там различные д-р m white wine плеер иди и прочее вот слава богу многие сидящие здесь даже не знают что это такое это страшная паре приторная штука с которой приходится жить легальным сервисом так вот и он получается что у нас сейчас продакшене больше пяти тысяч различных вариаций или почему потому что по сути площадка на которой мы демонстрируем контент определяется тем самым контентом который на ней демонстрирует и вот у нас например есть площадка android под площадка таблетка да это планшет территории германии такая эта версия она умеет вот делать вот это контент на ней будет существенно отличаться от аналогичного версии приложения например в россии должен быть немножко другой поиск должен быть должна быть другая навигация в принципе приложений внешне могут выглядеть по разному и вот таких вот различных конфигураций у нас около 5000 и значит что по ним нужно уметь быстро искать проблема заключается в том что количество этих версий растет стремительно каждая новая версия привносит нам новый геморрой почему но вот смотрите я тут точность схематично изобразил как мы живем с версиями почему вечно храним всю информацию о доступности для всех выпущенных когда я бы то ни было нами приложениях вот мы например зарелизили aerys приложения на момент релиза для этого приложения был доступно к примеру 70 тысяч единиц контента прошло какое-то время мы чуть-чуть под напряглись и скажем реализовали поддержку fair play fair play это система защиты контента вот и план и значит тот контент который по мнению права правообладателей может быть защищен только этим гримом на этой площадке стал доступен и поэтому у нас получается версия 1 0 которая умеет воспроизводить там в данном случае 80 тысяч единиц контента следующая версия которая умеет воспроизводить на 2000 больше мы не имеем право вернуть старой версии предложения более новую версию каталога потому что это будет очень сильно раздражать и напрягать нашего пользователь а это значит что мы должны сохранить все настройки предыдущего каталога они должны высчитываться вот так чтобы в любой момент времени пользователи которые такие не обновились и продолжают активно пользоваться нашим приложением старой версии чтобы они получили актуальную работающую систему в среднем жизнь каждого приложения около двух лет в каждой версии понятно что за первые две-три недели обновляются 70 процентов но вот оставшиеся 30 на протяжении двух лет плавненько утекают кто-то обновляется кто-то уходит в отток это не так уж важно но по сути это те самые преданные пользователи которые считают что каждое новое обновление разработчиками привносится какое-то говнище вот и никогда не буду обновляться вы меня сейчас явно расстроить и вот таких много это самые лояльные люди которые платят тебе деньги поэтому нам приходится вот этим прекрасным людям оставлять слепо чик системы доступности этого контента и вот таких вот слепков у нас сейчас около 5000 с учетом того что мы интенсивно обновляемся нас примерно релизы приложений происходит два раза в месяц по основным платформам вот перед представь себе что тут вам нужно умножить это все на количеству территорий и стран который мы поддерживаем сядет подержим если там четыре года назад мы доработали только в россии три года назад мы работали там в россии в снг два года назад на стали работать там во всем мире то получается что для каждой страны у вас должны быть индивидуальные настройки потому что по сути контракта вания контента под каждую страну происходит ну или подгруппу регионов происходит отдельно как у нас все было устроено год назад все что нужно для навигации быстро у нас хранится хранилась в сфинксе дальше вытягиваете о технике мы добываем дополнительно информацию из редиса обогащая их вот при этом делаем вот это вот обновление собственно консистентных сфинкса и редиса мы должны гарантировать да то есть мы обновляем i had a more на что для этого было сделано для этого было сделано очень простое решение нас была просто два типа кластеров основные бы копны и пока основные обновляют индексы на буквы весь трафик обслуживаются бы копнами полное резервирование как только основные обновились на них возвращается трафик и они вытягивают дампы индексов редиса и дампы свингса наоборот они все продам дампы индекса свинца и дампир одисов вот значит это все работало и работала более-менее неплохо почему же вот штуку которую даже сидящие здесь люди потратили какое-то время на разработку мы решили спалить вот и станцевать на костях старого решения вот а проблем были следующие мы несколько лет назад довольно сильно ускорились относительно релизного менеджмента и выкатываем как приложение довольно шустро так и собственно версии бэг-энда значит и количество версий которые у нас стало появляться она перестала укладываться мы посчитали что и через примерно через полгода мы вынесем за пределы оперативной памяти serv очков где жил сфинкс как у нас был устроен по сути у нас было три типа машин на одних машинках у нас крутил скрутились буквенные serv очки на питоне на других там у нас крутился сфинкс и там на третьих у нас крутился редис это что есть и таких вот троек у нас было энное количество соответственно если ты вылезаешь за пределы одного сервера у тебя горизонтального масштабирования в принципе тут вот как бы быть не очень может вот это было действительно проблема который мы методом простой арифметики пришли к выводу что подберемся через год гарантированно вот каждый месяц у нас добавляется 100-200 версий с индивидуальным но по сути да у нас вот каждая версия это декарт он то есть все множество декартово произведение всех возможных викторов да то есть это территория эта платформа это индивидуальные настройки платформы и собственно возможности технические возможности конкретного приложения мы добавили новые геолокации и самая большая проблема что мы примерно полное время то есть не инкрементальные полное время обновления индексов сфинкса у нас стало занимать около 40 минут это в общем-то не допустимо то есть когда у тебя нужно все пересчитать за 40 минут это как бы долго вот и также были редкие случаи нарушения консистентной sti 2 хранилищ редиса и сфинкса как правило это был связан с человеческим фактором во время релиза кто-то забывал что у нас оказаться два разных хранилище человек забывает что он как бы есть вещи которые когда то мы договорились и их не надо трогать вот и например опачки выкатили новый индексы на сфинкс а вот в редис выкатить забыли или не успели или вот в плане релиза не предусмотрели от омар ность этого действия и получаем на 10 15 минут рассинхрон то есть в сфинксы есть о технике которых нет в рисе или наоборот это собственно влияет на качество сервиса таких такие случаи были примерно два раза в год это этого уже достаточно чтобы с этим что то сделать вот ну и как я сказал собственно мы начали разрабатывать или где-то 10 лет назад с тех пор итерационным и на хреначить да столько говна палок скотча клея вд-40 и прочих различных полезных разработчику инструментов что остановило сюжет тошнотворное потому что выходит новый разработчик такой радостный пришел в компанию работать им такую вот смотри он такой начала мне на собеседование сказали об этом нормально же сидели вот и так давайте все перепишем вот соответственно ну и как я уже сказал с венцы по умолчанию не очень-то распределенной вот и нужны дополнительной магии для того чтобы сделать его распределенным вот ну субъективный фактор это то что действительно каждый разработчик хочет посмотреть на что-то новое потому что у соседа как бы и жена симпатичнее вот и коровы молока больше дают вот ну и это было одним из поводов для того чтоб все к чертям переписать вот что мы сделали мы с калле ok недовольные разработчики вот вам лопата грабельки совочек творите что хотите выбирать любые технологии и сделайте себе счастье но как это есть один момент нужно удовлетворять следующим требованиям значит соответственно создание прототипа мы отводили месяц должен быть контроль от омар насти обновления если будет несколько хранились вот скорость нужно увеличить на порядок а то и больше и нужно однозначно поддерживает инкрементальные обновление потому что у нас часто бывают ситуации когда прибегает правообладатель качать так ребята да у нас вами договор все хорошо снимаете этот контент мы возместим во все неустойки ну вот сейчас нужно снять такие случаи бывают когда например оффлайновые кинотеатра наезжают на правообладателя провал дать и просит у нас снять контент вот всякие ситуации бывают мы должны очень быстро уметь прореагировать на подобные ситуации вот значит как я сказал мы несколько лет назад мы пришли к хорошей скорости в релизах и примерно 20 релизов в день у нас происходит и вот отходить от этой уже классной завоеванной высоты очень не хотелось это значит новая система должна просто релизиться и этого мы посвятили довольно большое количество времени время ответа сервиса должно быть не больше существующего то есть мы посмотрели на 95 процентный пир sentir и на средние по всем командам отказоустойчивость у нас вся бизнес-логика располагается в 3 дата центрах соединенных кольцом и если выход одного из дата-центров должен не приводить ни к чему потеря двух дата-центров должна привести к тому что время ответа должно несколько возрасти но мы ферон должны иметь возможность функционировать вот соответственно нам нужно было горизонтальное масштабирование им очень любим свою службу эксплуатации админов который дежурит и не спят начальный когда чет происходит и вот этих прекрасных людей нужно было сделать счастливыми потому что паз по сути ему должен быть один рубильник что-то не работает дернул обиняков всё работает на классно расходимся вот ну и собственно не не надо было про долбать то хорошее что у нас было в сфинксе а хороший у нас был действительно классной полнотекстовый поиск который работал быстро и отвечал всем потребностям которые у нас были на тот момент итак после в варения собственно в чанах мы оставили ты только два жизнеспособных решений соответственно этому модернизации текущей архитектуры и допиливание сфинкса точнее все всего что вокруг свинца связано для до его масштабируемости вот и история с elastic search победил в частности за счет того что админы очень сильно топили за elastic search победила ластик search почему потому что черт возьми и он прекрасен и отказы устойчив мы пытались сломать его разными способами мы ломали сеть мы ломали железо вот мы оставляли всего одну ноту вот она продолжала там чучел ему ли тушкой продолжала выкарабкиваются горит на тебе вот как оно существовало вот и админ сказали но вот она вот она вот вот наша мечта выбрав победителя мы решились nokia теперь как бы самых-самых самое интересное позади да то есть все что интересно разработчикам прототип построен я свою работу выполнил я ухожу нет начинается самый триша чок-чок начинается с того что по-хорошему нужно полностью копировать скопировать существующую систему которая функционирует уже больше энного количества лет и тут были выданы следующий критерий благодаря классному быстрому релизом у менеджменту у нас хорошее покрытие и не тестами и функциональными тестами это позволило в принципе задуматься о том что мы можем подойти к вопросу рефакторинг а хотя бы просто задуматься об этом вот нужно прохождение нагрузочных тестов передо мной выступал коллега и завита который много рассказывал про там нагрузочное тестирование чуть позже я расскажу о том как мы тестере вот соответственно и самые важные это продуктовые метрики потому что мы берем одно сердце вынимаем вставляем другое и мы не должны просить по конверсиям если следующий конверсии мы себе обозначили как базовый это конверсия из поисков просмотр видео время загрузки страниц на клиентских приложениях время ответа по каждой из команд и пьяни должно увеличиваться то есть как 95 процентный пирсинг или так и средние и время обновления индексов нужно уменьшить несколько раз уж 40 минут это овер дофига вот соответственно и важная история с точки зрения партнеров что больше ста клиентских приложений которых мы там в глаза иногда некоторых никогда не видели должны не почувствовать какое-то каких-то изменений вот и тут нас на самом деле ждали очень большие сюрпризы соответственно прошло четыре месяца через четыре месяца один процент нашей аудитории получил новый и перин и вот тут началась мы думали что вот такие часто основная стадия позади вон уже свет в конце туннеля но свет в конце тунеля оказался 2 дырки в задницу вот еще большего туннеля значит за первые два месяца тестовой эксплуатации вот мы сделали больше ста фиксов вот которые были связаны как с бизнес логикой так из как истории с отказоустойчивостью и нагрузками отдел эксплуатации начал плакать кровавыми слезами потому что одно дело провести несколько пестиков и посмотреть а черт возьми ну классно да все так как по хипстерский все работает замечательно вот а другой делать вот эти системы эти plati.ru и начались тут слезы сопли а как хорошо было раньше вот атом мы все умели а тут мы ничего не умеем вот два месяца значит для мониторинга мы используем zabbix вот у нас на самом деле так скажем 10 системы для админов мониторинга это zabbix а вот разработчики льют всю интересную для них info они льют в 100 т.д. и граф она вот собственно админ из пытались настраивать свои триггеры триггеров оказалось много их больше 150 штук на новую систему мы навесили вот дальше выяснил что хваленые нами и юнит-тесты несмотря на то что мы считали что мы покрыли то и у нас катка в ристайл как о какой вот выяснил что есть части системы которых там мы уже 5-6 лет не вспоминали и думали что там вот эти вот люди которые этим пользуются давно вымерли но нет они существуют они тут же написали в саппорт потому что они конечно же попали в один процент и вы в этом на самом деле большое счастье что они попали в один процент вот показалось что одного процента достаточно для того чтобы собрать нам 99 и 9 шишек пациентов шишек которые могли бы быть вот дальше еще веселее мы узнали о партнерах о которых не знали вот то есть они когда-то с нами за комплектовались вот они даже платили нам деньги но технический департамент как бы ему был на это фиолетово ну как бы песенки пишутся бабло качается да вот люди пользуются и пиаре отчетность строят бизнес-аналитики деньги нам приходит все хорошо для нас эта штука не существовало выяснил что в 2016 году еще есть люди которые парся джейсон руками и от того в какой последовательности они переставляют параметры не сломается парсов часть из них нам удалось наставить на путь добра справедливости и сериализации и 10 реализации однако часть и не скальной ребят смотрите на этой платформе уже давно никто не пишет резные циклы закрыты ну вы либо чините либо мы перестаем работать ну собственно первый костыль в но в новой системе давайте подправим немножко стерилизацию объектов для того чтобы последовательность параметров было и как бы вот такой вот окей там программисты написав прекрасный новый чистый код поплакали скажи ну ладно но это будет последний раз да как как как они ошибались вот значит следующая проблема у нас существенно просела конверсия из поиска что мы сделали сначала мы какие у нас есть вот списочек правил для сфинкса для того как у нас и что должно искать нокий мы берем доку пойло sexy о чем берем список переписываем профит нет это не так есть куча тонкостей и нюансов о которых мы не знали которые работают там в интересных случаях там связанных с там числительными там с пробиотиками много тех вещей которые по хорошему вроде как на синтетических тестах проходят прекрасно но наши пользователи они же прекрасны они где-то пишут там латинскими буквами половину латинской половины русскими если в старой системе мы как-то это уже прошли и запомнили то в новый муж мы несколько облажались в написании этих правил и около двух месяцев мы доводили конверсию из поиска хотя бы до того уровня я не говорю про новые волшебные шаги до того уровня чтобы добиться прежних результатов мы просили по всем продуктовым показателем тут как раз был синергетический эффект и он был очень неожиданный он появлялся периодически связан был с тем что у нас есть такие классные устройства которые называются smart tv многие из вас не знают о том как как и что там пишется потому что на самом деле это там тонкие клиенты большинстве случаев они пишутся либо на всех либо на что имели на там javascript html 5 вот и вот когда вы пишете приложение на html5 выясняется что у вас по каким-то причинам время ответа каких-то команд в нашем случае практически всех почек среднее почему-то стала достигать иногда 20 секунд тому же как такой может быть ну то есть как люди еще после этого после этого пользуется вообще откроем сервисом копали очень долго и выяснили на самом деле там был целый клубок проблем проблема оказалась в том что те лики очень хреново делают хан шейки что тебе соединения то есть если там есть какие-то протоколы обмена собственно шифрованной информации о которых они не знают они впадают в эйфорию и думают несколько секунд с твоим сервисом ничего не происходит просто телек вступил вот и проблема была в том что как бы перед всем нашим трафиком бизнес-логики стоит система которое ссылается куратор вот и периодически переключаюсь там один процент в наса было там 100 обслуживался с куратором тобиас куратор мы никак не могли поймать поймать а где черт возьми нам нужно подкрутить настройки на какой входной точки чтобы определить где проблема вот искали это тоже около 2 месяцев вот включая куратор выключая куратор возвращаю трафик на один этот процент на старый api переводя на новое то есть на самом деле к сфинксу и classic все еще не иметь никакого отношения но когда ты меняешь гидросистемы ты получаешь кучу синергетических эффектов которые ты причисляешь к тому что да ты наверное что-то в коде сделаны только на самом деле нет есть какая-то маленькая хрень которая убивает два месяца твоей жизни вот но жизнь боль вот пять шесть раз мы снимали трафик потому что экспериментами ломали кен системности ластик сеча вот там чуть чуть не до обновили там kontrol цен и выполнение скрипта вот это вот все вот соответственно дальше начались серьезной истории мы подключили наш сетевой отдела подключили отдел эксплуатации для того чтобы они поломали нам все на хрен вырубали дата-центры вырубали сетевую связанность и вот эти тесты мы прошли прямо таки на ура да то есть нам нужно было немножко подпилить историю с нашими питания чьими сервака my опять таки это не имело отношения к истории из elastic всего чем вот поработать там с коннекторами но отказоустойчивость оказалась на довольно хорошем уровне вот и дальше начали продуктивно догонять по продуктовым метрикам по всем и тут нас ждало пренеприятное разочарования скорость работы elastico по определённым командам оказалась существенно медленнее если ничего не делать из коробки мы получали там 600 миллисекунд против 50 и вот начали копать там привлекали консультантов читали доки нам удалось как бы снизить эту штуку довольно существенно но по некоторым командам этого сделать оказалось невозможно это была плата за распределенность это была плата за надежность и отказоустойчивость и дальше мы оказались перед не очень хорошим выбором то есть у нас есть штука которая работает быстро но мы пока не придумали как ее развивать и штука которая работает нормально вот это нам понятно как ее развивать и дальше мы пошли кланяться в ножки к продукту бизнес вами ребята давайте как-нибудь договоримся вот и слава богу мы нашли этот консенсус например в таких вопросах как ну то есть например swings развращал нам без проблем там за там четное количество миллисекунд список из полутора тысяч сайтов вот вот эти же самые полторы тысячи the youth of elastic возвращал там там в районе секунды мы каким слушать ним зачем вам полторы тысячи 200 до лезть на самом деле тут нам очень помогу помогла аналитика что да там полутора тысяч до скроле вал только очень человек с сильным пальцем вот ведь людей сильными пальцами слава богу который пользуется нашим сервисом не так много поэтому мы вы торговали для себя послабления в количестве возврата объеме информации вот ради того чтобы у нас было масштабируемость консистентной стикеры что нам нужно было делать меньше и хорошему не хотим ни о чем думать не о консистенции о чем мы хотим там писать код и папочку вот собственно это на самом деле очень большая проблема я об этом как раз я и хотел поговорить что смотрите фильм действительно быстрее но просто эксплуатировать его на задачах подобный нашей оказалось непросто вот и про проведенные нами эксперименты показали что черт возьми мою полем свою теплота цию или напишем вокруг этого энное количество костылей и подпорок а вот там где все из коробки она черт возьми работает медленнее все что могли сфинксы мы уже забрали мы уже вытащили это в редис и вот у нас на чистые фланга пересечении адэшников контента уже уже оптимизировать там никуда там вот соответственно дальше началась самая веселая в море как переходим к арцаху carhartt кода в моем докладе значит мы помнишь talkie у нас работает наша новая система мы построили на отдельных железках вот более того мы после первого места месяца эксплуатации помимо того что мы лили туда один процент трафика и пользователи получали ответы мы с наших проксей клонировали туда весь остальной трафик вот чтобы по-хорошему на длительном периоде то есть синтетические тесты мы прогнали там танк apache бенчмарки проще всякие веселые штуки вот но они не дают в принципе никакого никакой информации о том как она будет жить в продакшен потому что комбинации запросов они очень нетривиальный сильно зависит еще от активности людей которые управляют контентом и в принципе от куча внешних факторов так вот мы довольно долго жили с полностью построенной системой в которой просто ли литров он лили клонированный трафик ну всего один процент этого трафика был ответы от обработки отдал процент от рафиков возвращались пользователь все остальное просто перемалывал ась в холостую и дальше случилась штука которая позволила нам за релизиться за три минуты вместо того чтобы два месяца готовишь следующий два месяца готовить плавный переход с плавные раскладкой опять пресловутый человеческий фактор 5 часов вечера мы сидим работаем работу думаем о прекрасном и тут и саппорта прилетает что один из популярных тайтлов почему-то перестал быть доступен на такой платформе лезем в админку ну да он перестал доступен его убрали оттуда черт возьми и ведь все остальные тайтлы этого контракта тоже ушли и оказалось что наши коллеги которые управляют контентом ошиблись то есть все мы люди и все мы ошибаемся они примерно с периодичностью там в час или в пол часика случайно убирали методично контракт за контрактом мы разделились на две части наша команда экстренного реагирует от рассказа происходит примерно в течение 5 минут вот админы начинают экстренно поднимать с шагом полчаса дампы сфинкса и редиса чтобы найти то самое консистентной состояние когда мы еще не просрали все полимеры поднимают не то поднимают тут этого не тогда тут этого нет черт все плохо вот вторая команда начинает пологом административного интерфейса смотреть а что у нас тысячи правил если не десятки тысяч и просто так вы грузите все и посмотреть на суд на человеческий мозг не в состоянии это оценить поэтому мы начали делать реверс мерз да то есть мы начали раскручивать назад пологом админке то каким образом мы дошли до жизни такой и пришли к выводу что ok мы сейчас ты провела применим но нам не у потратить те самые пресловутые 40 минут на пересчет полного инкрементальные истории тут не помогут изменений были настолько существенны что мы там день все равно что на гангрену пластырь наклеить вот и собственно вот у нас есть система которая полностью восстановится через 40 минут как обычно все проблемы случаются в члены на частные больше нагрузки в нашем случае это с шести вечера до 22 часов по москве и вот у тебя уже 5 часов вот и вот уже вот сейчас пипец стучит тебе в дверь вот и а у нас тут рядом построены ровно там бы кластер который работает и вроде как все все хорошо и мы принимаем решение что ok прием сто процентов трав он оттуда а этот пусть пока обновляется в случае чего потом переключимся и эта хрень заработала причем и вот это наверное один из немногих случаев разработчик ского и административного оргазма который я испытал своей жизни когда то что ты делал несколько месяцев подряд вот не думал стану у меня еще есть время впереди я я заряжу это потом вот мы вроде как уже все готово ты просто ещё боишься и тут опачки стучится к тебе пока поговорит пара дружище пойдем вот и ты запускаешь и on и вот все те мероприятия который ты проводил на протяжении нескольких месяцев они оправдали себя мы не увидели да градации по производительности мы не увидели каких-то изменений в продуктовых метриках все заработало заработала хорошо но мы немножко пересрали и добавили туда еще железо на всякий случай вот ну ну есть же пусть будет вот соответственно добавили железо оно всё окей хорошо до завтрашнего утра вот у нас пожалуйста у нас есть переключить трафик там несколько секунда у нас вот есть вот тут вот запасной аэродром если будет плохо там отслеживали фон обращение в саппорт отслеживали все метрики админ прям буквально вот так вот сидел с занесенным пальчиком над кнопочки если что сразу вернуть трафик туда вот но прошли сутки она работает мы подождали ещё месяц и потом разобрали старый классно вот и закопали стюардессам домбре им и закопали стюардесса вот соответственно чем мы получили в итоге в итоге мы получили сервис с кодом которым приятно работать как минимум еще год будет вот прошел уже почти год нам все еще приятно с ним работать пока еще не подано солидно много интересных бизнес логики вот мы получили отказ устойчивую топологию мы на практике проверили обработка аварийных ситуаций сначала на собственно до релиза потом и после релиза мы регулярно проводим тесты потому что вы что-нибудь сломать вот мы ушли от в принципе необходимости иметь два хранилище и поддерживать их ассистент в сторону 1 то есть лень победила a consistent насти думает самый ластик вот мы не выиграли в скорости действительно не выиграю скорости от печально вот однако мы довели время ответа elastico до такого компромисса не настройками до такого состояния что продуктовые метрики не пострадали и теперь там мы довольно а увеличить скорость обновления индексов там сделали классную админку для интер ментальных обновлений вот и это все позволяет сейчас по сути продолжает штамповать релизы интенсивно и не думать о том что вот сейчас сейчас у меня кончился память в синг се и что я тогда буду делать нам надо давайте тут чуть выкинем сделаем какую-нибудь какой-нибудь sharding какой-нибудь странную репликацию вот то есть для нас это оказалось довольно хорошим и удобным решением мы перешли на elastic в апреле вот и с тех пор вот именно с этой подсистемы пока проблем не знали но то ли ещё будет вот поэтому в основную мысль которая хотел до вас донести что сфинкс это хороший инструмент это быстрый инструментом быстрее чем elastic но это инструмент который накладывает на вас определенные ограничения в плане масштабирования и там 99 случаях когда вам нужен полнотекстовый поиск сфинкс будет работать быстрее но когда вы делаете вот такой толпе графический гашиш с декартом произведение всех вариаций тут как бы нужны немножко другие решения если вы хотите эти решения получить на нагруженном сервисе а у нас нагруженный сервис вам придется искать компромисс между скоростью и между собственно удобством в эксплуатации и масштабирование друзья на этом все спасибо за внимание оставил пару минут на вопросы ну конечно ровно 10-15 друзья не стесняйтесь если есть вопрос который хотите задать публично поднимите руку вот на первом ряду есть таковы прямо хранить все до картаго произведения всех этих прав ну не совсем еще немножко пересекаем on demand и 2 самую любимую бой с поиском как там с полным совпадением сейчас сильный лучше чем то когда то это разрабатывал здравствуйте а какое решение не вижу здесь ни здесь извините а все-таки какое решение предложила команды со сфинксом команда саспенсом предложила поэкспериментировать с шарда мин то есть настроить свои шарды ну то есть условно для побить по регионам пусть по какому-то признаку выделить вы хотите продолжить ну хорошо я правильно понимаю что вы на скин связали в общем-то тройку то есть у вас под каждой observer фактически ставился нет у нас один сфинкс на ну то есть смотрите значит было там энное количество одинаковых свинцов вот да он он был один на все задачи и полна текста поиска и фильтрации насколько я вас просто понял из доклада на сбор то есть у вас сказать там что называется applications серые принимающие какие-то за просеки рядом обслуживающий и варить из которого лежат искать там все что не поместишься и рядом стоит тоже svenska по которому аптека там стучится в поиск да вот такой горизонтальный масштабе четко она и была горизонтально вопрос о том что у вас есть либо вы используете сортирование да потому что смотрите вариативность того что нам нужно хранить она большая и она потихонечку перестала помещаться в памяти какой горизонте на горизонтальное масштабирование когда вы не вмещаете сь в память одного сервера они не предложили перед этим поставить регулировщик который скажет так вот эти зоны пошли налево ну собственно третях это и назвал сортируем да нет о нет они это предложили вот но написали такую обвязку который не понравилось эксплуатации то есть вот именно вот эта штука то есть еще раз это не история про сфинкс эта история про просто разговором там уже хватит вот именно вот эту штуку мы попробовали и именно маршрутизация всего этого дела и поддержание этого товарища в consistent нам состоянии она ложится на наши плечи случае с и ластиком это делать кто там и ним и сортирование в том числе кровавый будет следующий доклад кстати здравствуйте спасибо за интересный доклад а вы говорите что нужно поддерживать много разных приложений и потому что пользователи не хотят обновляться а разве нельзя со стороны бэкенда просто ограничивать для разных пользователей я получается backend обновляете вы а приложение уже так не раз ты так собственные происходит то есть наш backend возвращает то или иное множество контента у вас есть там множество и множество бы одно для одной версию другой для другого не пересекаются между собой но они неэквивалентны и вот задача как раз в этом и состоит чтобы опиат плевала консистентной множество по которым можно было навигировать как полнотекстовым поиском так и фильтрация my понимаете то есть мы не мы не обновляли приложениям и собственно предоставляли данные просто данные для приложения они уникальны по сути своей совокупностью спасибо отличный доклад есть вопрос если не секрет а на каких собственных сценариях у нас ластик проигрывает сфинксу ну вот как раз там где нужно было вываливать большое количество инстансов то есть когда результатом запроса оказывалось большое количество элементов то есть вот вот примерно там в районе 200 проигрывает не сильно все что больше мы уходили в потолок еще маленький опрос вот у вас то есть миллион версии и как вы ищете поэтому всем просто есть теги для каждой версии ну да там wpad по сути там у каждого каждой единицы контента есть кортеж в котором вы знаете на каких версиях она доступна вот есть это если очень образно есть технические возможности есть настройка контракт дальше они происходят пересечении что там и пред рассчитываем что то мы рассчитываем on demand спасибо спасибо за доклад можете уточнить к вас размер индексов и количество запросов на чтение вас профиль нагрузки часто чтения я правильно понимаю да большая часть нагрузки и это чтение значит что касается сфинксом мы перестали помещаться там примерно в 96 гигабайт вот соответственно рпс китам я думаю что около 15000 секунду на эластики в это держали таком железе ух вот это если вы после доклада камни подойдете я быстренько админы мы пишу и они тут же расскажет не помню спасибо здравствуйте спасибо за доклад подскажите пожалуйста просто насколько я понял из из доклада у вас вот есть полторы тысячи вот этих вот конфигурации и условно насколько приняв пользователи он использует лишь одну из них то есть он делает select и только в 1с конфигурации в какую-то для него как для них навыками в таком случае нельзя было условно побить вот эти полторы тысячи на 750 конфигурации на одном свинок сервере 750 нм другом можно просто вот вот вот это вот логика ее нужно реализовывать ее нужно поддерживать собственно мы это и сделали просто нам это не понравилось то есть вот смотрите так тебе приходится писать код и поддерживать его консистенции это не только история про то что одно или другой инженерное решение лучше просто я как технический директор должен принимать решения а что мне будет еще проще саппортить и куда мне нужно будет тратить ресурсы куда не нужно будет тратить и вот это тоже не последняя история то есть можно сделать в абсолютно правы дал собственно этот вопрос очень напоминает вопрос вашего коллеги вот можно было сделать мы именно это и попробовать решение в лоб мы просто зачем этим заниматься когда все сделали за тебя да ты платишь производительностью за это ну то есть ничего не бывает бесплатно добрый день и собственно говоря привет а вы не пробовали немножко ограничивать количество вот этих конфигураций за счет форсирования обновлений приложений пробовали это собственно первая идея которые нам пришло в голову и собственно с помощью этой идеи мы немножко отсрочили смерть предыдущего инженерного решения вот однако есть уперты партнеры которые и в принципе не форсируют например вы не можете обновить приложение samsung двенадцатого года но в принципе не можете потому что samsung уже перестал принимать свои админ очки приложение для этой этой платформе и вот оно то есть у вас есть непрерывный рост вот да вы можете потерять старичков это мы сделали мы заработали себе там год жизни вот но дальше черт возьми местам сегодня например мы занялись и приложений для windows тора она тоже будет релизиться раз два дня ой 1 2 1 1 1 2 раза в месяц вот и дальше мы выпустим еще что-то и у нас большой то есть как бы то что вы видите на в наших приложениях и только верхушка айсберга у нас очень много партнерских би ту би взаимоотношений где мы просто предоставляем свой сервис и вот если своим пользователям и еще что то можем объяснить туда говорится сотни партнеров очень нетривиально штука поверьте дешевле все переписать понятно спасибо большая где девушка стоит здравствуйте спасибо за интересный доклад я сразу скажу что я любитель сфинкса поэтому от тела меня подгорело немножко вот у меня три вопроса пробовали ли вы получите крестную третью версию сфинкса с real-time индексами второй вопрос как получилось так что swings все данные атрибутика не влезала пластик стал вылезать и третье зачем вы поменяв по сути внутренние там условно говоря систему поиска поменяли публичный 5 мы не применять публичный ну вы же говорили что были люди которые партия ли джейсон руками и там от порядка полей что-то зависело ну да но в как бы в моей системе координат от порядка полей не должно ничего за как это зависит от реализации поиска от поиска никак ну то есть это просто поскольку для новый поиск это пишешь новый сервачок ну собственно написать новый сервачок идентична сторон бессмысленно потому что у него другая плоскость ok понял тогда ответьте пожалуйста по поводу полу секрет на третью версию сфинкса и real-time индекс с обновлениями нормальными значит вот когда мы начинали вот эту всю работу это был год назад соответственно тогда вот эта штука еще не было настолько известный как сейчас и мы этого не пробовали так хорошо как получилось так что в сфинкс в памяти данные не вылезали овала из текстолита конечно не на одну машину влезают она разгар зимы макс астру а сфинксе она сдала на 1 одной машине в этом то и проблема хорошо я понял в принципе если хочешь подраться можно сейчас мы я просто могу проконтролируешь себе никто больше не увязывался потому что та часть ребята из базу полезут опять-таки был ребят из году они в принципе любят подраться или им там пусть музыка утопить их просто здесь многое их оставляет качаться за растление спасибо большое за так вот у меня такой вопрос ano sora вы не смотрели вместо ластика search один раз меня уже об этом спрашивали нет не смотрели потому что уточнить как на уровне холиваров и вопрос о давайте посмотрим это же так похоже вот но мы не нашли ни одного адепта который хотел бы этим заняться это смотрите когда вы выбираете новые архитектурные решения вы отталкиваюсь от нескольких факторов 1 возможен быть энтузиаст который потянет на себе всю эту историю второе не должно быть жесткого антагонизма со стороны команды и это ваше решение должно удовлетворять вашим бизнес требованию вот бизнес стремным да там салону можно более того там один раз не так давно меня спросили опробовали ли мы такого зверя как элла сандра этот поместилось sexy очень и кассандр собств в этот момент я узнала его существование теперь все знают спаси большие вот у меня такой вопрос есть вы говорили что была проблема с тем что индексация занимало примерно 40 минут а почему это вы делали всегда полную индексацию да я когда говорю по полной 2 то есть на кри ментальный да там она она была быстрее вопрос том что яндекс не не всегда очень сложные у нас взаимоотношения между объектами и ты не всегда не можешь выстроить какое событие должно привести к переиндексации перестроение каких индексов понимаете да то есть вот иногда проще пересчитать все сначала вот как раз история с нашим внезапным релизом она это и показала что мы сходу не смогли понять то есть перестройки частички частичные перестройки некоторых индусы оказалось недостаточно мы это попробуем а не сработало этапа это полный да то есть мы берем и выполняем полную счетную задачу если менять какие-то спасибо так он еще есть много человек да пожалуйста скажите пожалуйста что случилось бы если у вас не было резервная система контент и продолжали бы накатывать конфете каждые 15 минут мы бы из говна и палок слепили бы он во-первых мы бы и качали бы над от положили бы админку для комп . это очевидно но вот соответственно а дальше мы бы я думаю что мы бы дошли бы методом половинного деления до того корректно тут мы начали бы расчет а дальше с помощью место половину делением нашли бы те самые дампы которые нам нужны когда они не начали еще за свою зловредную деятельность той базы не полегли бы а база бы ни были грея mi vida нет нет ну то есть смотрите мы мы же не легли мы потеряли часть контента и в этом случае то есть в сервис продолжал функционер просто человек выпивал в поиске там где человек паук паутина из рук и получал хрен вот вместо того чтобы начать восхищаться творением голливудских мастеров спасибо"
}