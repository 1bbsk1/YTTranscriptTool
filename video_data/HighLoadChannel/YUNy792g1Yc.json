{
  "video_id": "YUNy792g1Yc",
  "channel": "HighLoadChannel",
  "title": "Как построить кластер для расчета сотен тысяч high-CPU/high-MEM-задач / Александр Кириллов (Evrone)",
  "views": 738,
  "duration": 1768,
  "published": "2018-08-16T04:45:32-07:00",
  "text": "меня зовут александр и я работаю в компании в рон сегодня вам буду рассказывать довольно интересную тему как она в проекте может быть сэкономить довольно таки мог денег маленькие накладочки пока нас накладочки скажите но в принципе это наверно вопросы странные для такой легкой ференци и ребят кто из вас в компании используют тестирование автоматизацию тепло и всего остального а кто нет понятно мы делаем довольно таки много различных проектов и один из наших проектов это канте news интернешнл сервис как ни странно все мог подумать зачем еще один себя и сиди если их и так довольно таки много на просторах интернета мы решили сделать для разработчиков его то есть сами являемся в основном разработчиками и нам необходимы некоторые фичи которых нет в остальных кантине смотрю лишь на сервисах наш сервис позволяет проводить вам тест и автоматизацию deployment и все остального и мы не ограничиваем наших пользователей на количество одновременно запущенных задач параллельных и одной из специфика нашего сервиса является то что у нас постоплатной системы и тарификация поминутная соответственно получается pay as u go то есть сколько вы наработали насколько насколько вы заняли наши ресурсы за столько вы не платите вы не платите за ресурсы который простаивают более того то есть нас практически нет ограничений как и все большие этой крупные сервисы уже мастодонты мы должны и позволяем нашим пользователей запускать различные среды различные языки программирования производить с помощь них какие-то действия компиляции билды подготовка различных артефактов тогда и так далее также мы поддерживаем практически все сервисы которые вы можете пройти найти на просторах docker hub подключить их к себе в проект и использовать их как внешние сервисы с которым работают ваши продукты то есть запускать на разных версиях на разных продуктах на и ваши тесты и окружения одной из задач которая перед нами стоит это быстро освободить ресурсы занимаемой машины для того чтобы запустить там новую задачу и время между запуском ваших задач клиентских либо между билдами должно быть минимальным то есть конечно же согласитесь что не приятно сидеть и ждать пока ваша задача из очереди попадет в бан начнет выполняться и ждать там пять или десять минут пока эта очередь дойдет до вас и конечно же как я говорил это неограниченный параллельный запуск ваших задач вы можете разбить ваши большой кейс на несколько маленьких и одновременно их все запустить и это сократит и время ожидания между коментами дипломантом время ожидания разработчиков целом для того чтобы как-то среагировать исходя из результатов проведенных тестов как поступают обычно все остальные continues to грешные сервисы скажите было ли такое что вы запускаете одну и ту же задачу на одном и том же сервисе подряд но первый раз она выполняется допустим 5 минут а второй раз это же задача выполняется уже 10 не замечали такое бывает провели research почему такое случается большинство из сервисов предоставляет своим клиентам одну большую машину с огромным количеством ресурсов там 16-я dirt на 64 гигабайта оперативы делит ее на какие-то кванты и запускают на этом большом шарат окружении задача различных пользователей бывает такое что приходит задача которой выедает большую часть этих ресурсов а всем остальным остается какой то маленький процент свободных ресурсов и они пытаются их как-то использовать из-за этого время запуска вашей задачи увеличивается мы подумали и решили не идти таким путём мы решили предоставить каждому пользователю на каждую задачу честные ресурсы полностью виртуальную машину все что она недоступна отдается конкретной задаче нет шаринга ресурсов какие еще с каким еще проблемно столкнулись когда начали разрабатывать от сервис у нас стал постоянный наплыв задача то есть практически нет время простой системы постоянно кто-то приходит что-то запускает тестируется deep ловится и так далее и проблема в том что это практически невозможно планировать как-то на будущее то есть сейчас может прийти 10 клиентов через минуту придет еще 20 и загрузит ваши ресурсы по полной и это как-то не коррелирует обычно с промежутками довольно небольшими промежутками времени конечно же вы не хотите чтобы ваша задача запускалась на машинке и какие то другие пользователи мили к ней доступ задача должна быть полностью изолирована в каком-то окружении от всего остального мира для того чтобы запустится и отработать не цепляй какие другие задачи запущенные на этой же машине частично мы это сделали как раз изолировав одной задачи всего лишь на машине бывает так что не зависеть от по независящим от нас причинам либо это канал паника либо еще что то но да просто схлопывается и нам необходимо мониторить каждую виртуальную машину что с ней происходит насколько она загружена жива она вообще или нет и по результатам если вдруг надо упала перезапустить задачу на новой машине мы же не можем дать пользователям такой функционал что задача схлопнулась вместе с машиной как обычно решают проблем масштабирования все мы наверно вам известно два возможных пути 1 это вертикальное масштабирование большинство сервисов предоставляет вам ползуночки или как-то это автоматизирует и вы можете их таскать туда-сюда увеличивая количество процессор на во времени или ресурсов понять и все это замечательно работает но в этом в этом есть некоторые минусы тоже скорее всего вам всем известные то есть это ограничение какой-то верхний предел у сервера и серверов выступает как бутылочное горлышко в этом случае если вдруг задач нет у вас получается простой ресурсов в огромный сервер стоит на нем ничего не выполняется вы скажете ну есть же горизонтальное масштабирование давайте добавим еще ресурсов и у нас это решит проблему до эта проблема решается большинство проблем решается именно горизонтальные масштабированием и мы все знаем ее плюсы и минусы что это сложно управляется это нужно как-то менеджере и вообще с этим как-то взаимодействовать с обратной связью ну что же мы делаем сервис давайте масштабироваться для наших клиентов самым простым наверное способом и большинство его используют это взять того хостинг-провайдера на котором вы запустились и использовать их какие-то инструменты которые практически у всех они есть то of the spelling у amazon такие же подобные вещи есть о гугла и уложила на чем базируется обычный авто скиллинг который идет из коробки на каких-то метриках эти метрики довольно таки простые это нагруженность процессора потреблением андрюша парка по сети и количество пакетов которые в нем со времени к вам приходит зависимости от этих метрик вы можете создать некоторые правила для того чтобы добавить количество машин of в группу или уменьшить количество машину группу либо многие провайдеры предоставляют какие-то расширенные метрики которые например это класс watch у amazon они добавляют какие-то некоторые ресурсы из мониторинга на которых может базироваться правило авто скиллинга и угла недавно появилась довольно интересную вещь это масштабирование на основе очередей пока что мы глубоко туда не копали но интересуемся интересно что они там сделаю она пока еще в альфе и она такая не всем доступна вопрос подойдет ли нам подобное решение для того чтобы мы могли масштабироваться под запросы наших клиентов как оказалось тех метрик которые предоставляют предоставлять из коробки нам недостаточно у нас довольно таки специфичная лойко приложения из-за того что мы не можем прогнозировать по количеству задач которые к нам приходят в единицу времени мы не можем настроить авто скиллинг по тем метрикам которые представляют провайдеры у нас бывает так что приходит задача с пиком активности под сапу а потом 80 процентов времени например там происходят какие-то действия с файловой системой эти метрики естественно падают также очень часто все задачи нагружают систему неравномерно то есть например происходит установка зависимости пакетов и там нагрузкам маленькая а когда пошли все основные тесты загрузка цп повышается до максимума ну потому что мы хотим чтобы все проходило быстрые тесты были быстрые и мы стараемся по возможности максимально использовать все рисую все предоставляемые нами ресурсы также там обычно в таких решениях практически нет обратной связи то есть мы как-то можем регулировать вот эти правила но в динамике это получается со скрипом и не очень удобно и как я говорил не все метрики нам подходят мы не на все метрики можем положиться для того чтобы предсказать нужно нам большего ресурсов или нет и бывает пики нагрузки которые вообще адекватно воспринимать там невозможно потому что они не показывают состояние системы в целом ну и к чему пришли конечно же нам нужно нужно писать свою систему авто закупки давайте ее писать для начала давайте рассмотрим какая архитектура проекта у нас было раньше и какая стала сейчас когда проект только-только вышел в публично в общем плавание публичные интернет и начали пользоваться клиенты у нас было довольно таки простая архитектура у нас было закуплено несколько больших машин на жюри на который ну то есть вот стандартные методы которые используют и ясно и все остальные сервис подобные сервисы были закуплены машины все это deep ловилась ручками через он сел если вдруг у нас появлялись какие-то дополнительные задачи мы просто увеличили к увеличивали количество закупленных машин они будут встретились на них поднимались агенты и они были готовы к работе с пользователями но тут встает довольно-таки большая проблема опять же пиковые нагрузки когда приходит много пользователей происходит закупка много задач происходит закупка большого количества машин машины обычно закупаются на определенный промежуток времени и обычно это время имеет какое-то минимальное значение например час все задачки пробежались пиковая нагрузка спал и ресурсы остаются простаивать что делать с этим правильно нужно использовать не одни мало больших машин много маленьких с виду некоторых некоторые достатка функциональности в ажуре мы и других причин на которых я расскажу чуть позже мы сменили ажур на amazon и там стали закупать маленькие машинки под задачи клиента мы убрали полностью ручной deployment ручную конфигурацию перешли в контейнер и кубер нэйт но те машины которые запускают у нас задачи клиентов мы вынесли из под кластер а в свободное плавание почему это было сделано одна из причин во-первых это изолированность для того чтобы рабочие машины вообще не участвовали никак не прикасались к внутренностям нашу нашего кластера и во вторых у amazon есть довольно интересная специфика весь трафик который идет изнутри приватной сети проходит через интернет литвой internet gateway тарифицируются он берется за время и количество трафика который через него проходит а наши клиенты ну практически все любят устанавливать много зависимости для прогона тестов это установка пакетов это клонирование каких-то или скачивания каких-то артефактов для их тестов это использование докера и выкачивания множество множество образов докера которые сами по себе тоже не очень маленькие поэтому трафик получается довольно таки большой плюс ко всему мы для каждой ноты сделали публичное и и весь трафик перенаправили через него в итоге у нас получилось что трафик ходит нет через интернет где твоя на прямой но я сегодня расскажу подробнее именно нашей системе авто закупки она немножко рядом стоит с основной системой то есть оно не является незаменимой ее частью а находится рядом как бы наблюдает и делает какие-то действия как она работает логика работы довольно таки просто к нам приходит новая задача мы проверяем есть ли свободные но до в пуле если она есть то все замечательно мы назначаем задачу и она падает под мониторинг она мониторится получается обратная связь и как с ней происходит взаимодействие но если вдруг такой но ты не нашлось пули у нас был переполнен то мы делаем запрос нас одна закупку новой ноды запрос отправляется в хранилище дальше он отправляется в хостинг-провайдер этом случае в amazon и происходит закупка закупка в амазоне происходит некоторое определенное время это примерно 60 секунд от 60 до 90 в этот момент мы не оставляем задачу ждать закупка когда закупиться новая но да мы опять делаем запрос если свободная машина специфика таковая что задачи заканчиваются она ты остаются и вот эти 90 секунд которые проходят от момента создания запроса на закупку да во время bootstrap аноды на накатки нее образов и подготовки к работе может освободиться какая-то уже свободная но 2 в амазоне более того почему мы делаем сразу за вас сразу поиск новых нот еще одна специфика амазона в том что после запуска виртуальной машины если вдруг вы стартуете из какой-то ами образа на базе и bs то у вас ограничивается первые был чтение первых блоков из файловой системы скорость чтения 50 процентов вот так у них сделан мы пытались с этим как-то бороться но пока не получается то есть первая задача первое чтение с файловой системы ограничено ровно на 50 процентов следующие чтение следующей задаче запускаются на 100 процентной мощности это обходится только подключением ssd но и но ssd instance они создаются и сами образов к сожалению с вы меня спросите но что у вас получилось как-то сэкономить на всю этом деле да вот я буквально недавно решил подытожить сколько же у нас в среднем мы экономим на переходе от закупки больших сервиса серверов на закупку в маленьких и по чуть-чуть если мы берем примерно одинаковые ресурсы это количество циpкa и памяти из того сколов которые представляют хостинг-провайдеры то мы видим довольно большую разницу чем она обусловлена почему так дешево мы перешли на amazon из-за того что пока не единственные кто представляет очень дешевые испытываю ноды вы можете сказать но спорт он же может в любой момент его аренда закончится или у него повысится его стоимость да это так но так как мы запускаем все в контейнерах и получается и мутабельные системы то мы можем с легкостью просто перенаправить задачу на другую ноду перезапустите и эту часть времени не учитывать в биллинге а учитывать только oberyn к той задаче которая полностью прошла от старта до за до окончания не важно с каким результатом в принципе она закончилась спотовый ноду нас очень спасли я рекомендую всем их использовать или хотя бы подумать как их можно использовать вашем проекте чем еще хорош вот этот метод закупки по чуть-чуть я как и говорил если бы у нас пришла еще одна задача литре задача да например на большой на старую архитектуру мы бы закупили еще один большой сервер из него использовали меньше там 30 процентов мощности а все остальное у нас простая и не как не использовалась при закупке на закупки виртуальных машин на каждую задачу мы можем по полной использовать ресурсы которые нам нужны и не оставлять ресурсы которые простаивают среднем где-то вот кратно получается у нас уменьшить стоимость наших ресурсов и затраты на них буквально за месяц до того я уже начал готовиться к выступлению в сети появляется просто от амазона новость о том что ребята все круто мы вели по секундную тарификацию спотовые но ты тоже мы оплачиваем теперь посекундно мы подумали может ли это нам как-то помочь в этом и решили попробовать вот буквально за этот месяц мы немножко переделаю нашу систему и теперь мы мониторим на к у каждой ноты никто еще дополнительные метрики какие это время на которой происходит пролонгация закупки ноды в пуле то есть она остается в пуля это как раз из соображений того чтобы не словить время ожидания boost папа и соответственно и соответственно дать реакцию и меньше pending при запуске задач мы мониторим ноду ее количества и времени пролонгации и количество ее нагруженность то есть количество задач на не запущенных за этот промежуток на базе этих цифр мы происходит аппроксимация по времени и мы можем теперь примерно предсказывать насколько нам увеличить пролонгацию еще даже купить эту ноту то есть не сразу и и гасите опять на час закупать насколько мы можем пролонгировать ее в рабочем режиме пока что это нововведение вот только только тестируется и мы пытаемся идти в ногу со временем и немножко добавить туда нейронных сетей для того чтобы по получше аппроксимировать вот эту функцию который нам позволит вычислять время пролонгации попробуем посмотрим что из этого получится так вот хочу вернуться к оптимизации именно финансовой как я вам говорила о том что спад его я ноды с потовые машинки амазоне гораздо дешевле и вы действительно можете видеть наверху идет как раз и за цена закупки по запросу машинки внизу идет средняя цена на аукционе при закупке с платова ресурса в чем может быть проблема проблема тут может быть в том что цены на спотовые ресурсы очень сильно скачет иногда и такие пики бывают давайте часто но все основное время средняя цена которое считается за определённый промежуток времени в среднем она остается постоянной и вот эти скачки сильно не влияют на конечную стоимость сколько в итоге мы заплатим за каждый ресурс отдельно но бывает такое что эти скачки довольно непродолжительное время происходит то есть а цена может повыситься допустим целые сутки держаться довольно таки высокой или она вообще может повышаться даже выше чем рекомендую она но чем цена закупки ноты по запросу и тогда мы просто перед переключаемся на другую зону и обычно так получается что скачки происходит только в одной зоне в другой зоне они остаются более-менее стабильными так мы можем немножко варьировать там то где мы закупаем определенные ноды если возвращаясь и подведя резюме мы как я говорил то есть мы выявили все ноды из-под виртуальной сети сделал в изоляцию и сократив себя затраты на обеспечение трафика который мы потребляем и потребляем много потому что это в основном идут как я говорил какие-то артефакты а у нас остается только трафика видел logo флагов мы тоже не медное количество собираем и все это оставшихся цена строится только из вот этого количества логов так вот подводя итог я хочу еще раз сказать чем мы добились такой оптимизации это подготовленные инстанциями образов в амазоне мы держим instance в пуле моего не бросаем то есть не отдаем обратного аукцион держим его постоянно пока на нем пока есть потребность в нотах и соответственно делаем пролонгацию инстанса спасибо большое если у вас есть вопросы сразу на них отвечу раз спасибо за доклад у меня два вопроса первый в чем проблема была использовать маленький инстанции на ажуре там тоже есть пол ведра ядро этого мало ну хорошо два ядра маленький ну т.е. мы там тоже есть маленький до 1 а потом второе учит и ли вы разницу в производительности амазонских машин и я журавский потому что жор дает настоящие дрого amazon дает виртуальная вот и третье это то с чем мы сталкиваемся ну у нас похожая ситуация поводу скачивание интернетов задумывались ли вы а каширование каком-то локальном хранение тех же докер образов но артефактов которые юзеры перекачивают постоянно чтобы не гонять посиди спасибо за вопрос да мы делали сравнительный анализ производительности в самом начале до того как мы начали полностью использовать спад вы из нас и мы провели анализ хожу русских машин то есть то что у нас была уже запущен на жюри те кванты мы взяли держит ул а уж он и amazon и в итоге amazon овский машины как ни странно показали большую производительность по сравнению с digital оушн абажуре тогда были довольно-таки высокие цены на вот такие маленькие машины но где вы найдете машинку на два ядра и 8 гигабайт оперативки за два цента в час поэтому выбор был сделан в сторону ажура автор знал амазона это не в коем случае не реклама просто так получилось и это стало очень выгодной для нас но тем не менее наша система авто закупки я не зря сказал что она немножко отдельно от бизнес слойки все приложения лежит она позволяет себе решено мы можем ее расширить практически до любого хостинг провайдера и закупать данные у этого хостинг-провайдера к слова каширования мы используем кэширование для того чтобы уменьшить трафик но мы копируем наши образы которые мы предоставляем для того чтобы не ходить за нашими же образами мы используем amazon registry мы пируем эти артефакты которые пользователи ставят к себе то есть от одного запуска до другого происходит там сначала происходит установка пакетов обычно эти артефакты виде зависимости и виде пакетов установлен для разных языков не меняются они меняются только когда происходит смена языка или какая-то схема зависимостей мы крашером эти пакеты и так же сохраняем именно в локальной сети и уже их вытаскиваем но трафик все-таки строится больше из новых задач которые плюс это скачивание артефактов которые им необходимы для запуска задач то есть от иногда могут быть дамп иногда может быть еще что-то очень часто это большие репозитории которые то есть клонирование репозитория происходит на каждую задачу и тут мы за каширование просто не имеем права кэшировать not поэтому трафика строится из многих таких вещей но вот установку большинства пакетов это debian of ski и пакеты мы коллируем локально установку зависимости мы копируем то есть уже установлен даже не ко мне перекомпилировать в будущем они используются уже готовые то есть вот эти вещи мы кашира плюс мы представляем возможность вам кэшировать любые ассеты которые вы хотите 10 вопроса деду мысли нет вопросов можно интересный вопрос касательно контейнеров прочее ногу вас обернитесь получается инфраструктура вот как вы защищаете контейнеры в которой хранится польский код от воздействия на внешних от машины чтобы они не воздействий на другие контейнеры которые на этой же машине потому что как бы ну с контейнер на самом деле можно повлиять разными способами там через а и о например через семь и так далее да вы как ты то учитывайте спасибо сейчас я верну этот слайд мы изолируем контейнер одной машиной да то есть у нас изоляция и с помощью виртуализации происходит и с помощью контейнеризации в итоге то есть одна машина только одна задача после окончания задачи докер сам заботится о том чтобы почистить все ресурсы которые там были получается мутабельные структуры каждый раз он стартует на чистой машине но мои сделал еще небольшую оптимизацию мы прибуду strappy машины не выкачиваем заново докер-образ мы подготовили ами с базовым образом где вот сам само хранилище докера лежит уже в образе это накладывает тоже никто и ограничения с которым дальнейшем столкнулись этот как раз в то что машина невозможно забудь вступить на ssd только то есть эфемерное хранилище туда не подходит только и без gps спасибо я думаю мы закончили"
}