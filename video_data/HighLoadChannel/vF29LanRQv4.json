{
  "video_id": "vF29LanRQv4",
  "channel": "HighLoadChannel",
  "title": "Производительность PHP: планируем, профилируем, оптимизируем / Павел Мурзаков (Badoo)",
  "views": 17501,
  "duration": 3003,
  "published": "2019-06-06T12:21:33-07:00",
  "text": "всем привет меня зовут павел бурлаков а последние 5 лет а ты в аду руковожу одной из команды разработки бэкенда также последний год яркого я отвечаю за производительность нашего бренда в целом году растет за последние два года нагрузка наш backend выросла достойный раза и мы не смогли пережить этот рост без добавления железа тем самым сэкономив достаточно много денег сегодня расскажу о том как мы подходим к вопросам производительности бэг-энда мой доклад в целом надеюсь будет полезен всем разработчикам потому что все мы с этим так или иначе сталкиваемся и так о чем говорить сегодня будем во первых поговорим о том что такое производительность что мы будем подразумевать под ней что в ней важно что неважно с чего начать и как ее измерить во вторых я расскажу какие инструменты профилирования мы используем и в-третьих немного расскажу о то как мы решаем проблемы с производительностью мой доклад надеюсь поможет разобраться в этой области и последствий эффективнее решать задачи подобные сначала немного нас водой это семейство приложений и сервисов знакомств у нас их и на самом деле несколько буду хорошо известен всем наверное здесь есть например еще бомбил который очень здесь на штатах но в россии не так популярен только на бодуна зарегистрировано 420 миллионов пользователей в пике на наши бренды приходится 120 тысяч запросов в секунду и они обрабатываются наше тесто серверах спички vpn нас наш сервис достаточно нагружен поэтому его производительностью нам очень важно итак начнем с того что определимся что такое производительности с чего начать я когда готовился к докладу решил начать с того что просто посмотреть в уголья как этому подходит другие люди когда я это пытался сделать то увидел на все первой странице всем до боли наверно известные рецепты типа замены постиг снова инкременты на прекрасные двойных кавычек на одинарные и это конечно мой самый любимый рецепт и не использовать вещи вообще на самом деле применение подобных рецептов обычно бесполезно часто и вредное по нескольким причинам во первых они учат читаемость в первом случае девелопера явно опусти рвал код во втором случае понятно что тут появляется длина строки они теряют актуальность обычно с выходом но в новых версий печки например если раньше интерполяции переменных двойных кавычек двойных кавычках было возможно медленнее чем конкатенация сейчас все с точностью до наоборот двойные кавычки и переменные в них это самый быстрый способ формировать строчку а вообще двойные кавычки одинарные кавычки производит на выходе один и тот же код если в строке нет никаких переменных и так вместо из всех рецептов которые я честно признаюсь и тщательно отбирал как ты еще работает замены постиг снова инкременты на префикс ный ну я навряд ли вы вам поможет потому что для этого ваш бэкон должен только и делать что инкремента постоянно но скорее всего все таки делает путь полезную работу надеюсь 6 пункта рассматривать сегодня не будем потому что конференции протечки как ты грешна ваты на самом деле хорошо рецепты не работают ну что что то делать я предлагаю сделать шаг назад и подумать целях и проблемах которые мы имеем связи с производительностью у нас есть на самом деле две цели первая цель это если мы почему-то хотим сэкономить потребляемые ресурсы жилищные или вдруг их нас нам стало не хватать или если нас не устраивает качество нашего сервиса возможно мы медленно отвечаем клиенты например и на самом деле все если нас устраивают оба этих пункта то нет смысла что-то делать и менять применять какие-то рецепты менять инкременты нет никакого смысла на самом деле и я не призываю конечно нарочно писать код который не оптимальный но на это не стоит давать тратить дополнительное какое-то время хорошо мы определились с целями проблемами но как понять что у нас все хорошо что у нас все хорошо с потребляем ресурсами что качество сервиса нас устраивает ну для этого у нас есть инструмент измерения с первым пунктом на самом деле все очень понятно для этого есть систему мониторинга это очень обширная тема я вывел на слайде просто несколько из них сегодня не будем вдаваться сильным в подробности кто вообще использует какой-то инструмент не только поднимись рост руки до использует отлично а есть кто-то кто использует сразу два о круто на самом деле 1 даже достаточно cтoит вы будете использовать но если вдруг кто-то использует сразу все то он точно фундаментально оградился от всего эти систему мониторинга позволяет следить за всеми важными ресурсами циpкa сетью просто берите ставьте в конце слайда в конце доклада у меня будет ссылочка на материалы можно будет посмотреть фотографировать том что не нужно хотя эти средства позволяют следить за всем за всеми ресурсами для нас наиболее актуальным является все-таки циpкa обычный это бутылок у нас поэтому мы для циpкa строим отдельные графики на которых видим как равномерно ли распределяется например нагрузка по нашему классу как загружен классный в целом какая средняя нагрузка максимально минимальной перцентиле и тут мы просто выбрали какую-то для себя планку здесь на слайде 70 процентов но на самом деле сейчас она даже у нас ниже после которые мы понимаем что возможно ближайшее время нас будут какие-то проблемы нам надо что то делать тут есть много нюансов как выбрать такую планку для себя я сейчас остановлюсь только на одном это гипертрейдинг hyperthreading это возможность процессор на одном ядре выполнить одновременно два процесса процессора так может сделать далеко не всегда и поэтому изменение циpкa use ja в зависимости от нагрузки до планки 50 процентов не такой же как после планки 50 процентов поэтому как как вы перешагнули нужно быть особо внимательным потому что возможно юрию здесь будет расти не так как вы предполагаете а быстрее хорошо разобрались систему мониторинга и теперь что делать с качественным services временем ответа мы используем pingu но на самом деле пин бы есть различные аналоги типа new relic или об дайнэмикс но на самом деле она ее аналоги в основом все обычные и платные пин бы кажется что это единственная такая штука с подобной функциональностью чтобы оно было слов hosted pink бы клиент пин бы работает в контексте физики процесса и хотя он и позволяет его как также и мониторить как систему мониторинга делают вроде как посмотреть на илью зашла память на сеть но что самое главное то что тут можно следить в при помощи pink by за временем ответа от скрипта и делать это в разрезе не просто какое-то средне время ответа в разрезе роботов прилла приложение либо каких-то других интересных нам разрезов со временем ответы на самом деле штука такая же нужно выбрать для себя какую-то планку мы ее тоже для себя выбрали и если как бы какой-то приемлемое время ответы тут ключевое слово приемлемой потому что на самом деле оптимизировать можно бесконечно но это уже может не давать какой-то профит кстати pink бы активно развивается совсем недавно вышла king 2 которой была переписана с нуля она супер производительная так что обязательно посмотрите опять же в конце презентации будет ссылочка так подводя итог этого раздела я хочу сказать что но обязательно следите за каким-то метриками и что самое главное если результаты вас удовлетворяют не надо ничего делать если и так все хорошо чем что-то делать что сделать если что-то не удовлетворяет на самом деле можно использовать ту же pingu пину позволяет расставлять таймер и внутри кода и таким образом мы можем локализовывать проблему сужая область поиска и понимаешь что что у нас тормозит но лучше с этим справляются профайлер и профайлер и я условно делю на два типа сейчас я расскажу о каждом типе и в каждом типе у меня будет два провайдера первый тип это трассирующие суть их работы заключается в том что вызов каждой функции оборачивается в такие скажем так таймер и до вызова функции делается какая-то логика производится и после вызова функции тоже производят какая-то логика измерения таким образом такие профайлер и могут получить точное точное значение например сколько конкретный метод выжрал памяти либо сколько он работал на циpкa это плюс таких профайлер of но с другой стороны эти профайлер и работают в контексте самого профилированного процесса это значит что если у вас есть какие-то функции которые достаточно мелкие то логика измерения она может быть даже тяжелее чем логика этих функций если это будет делаться в цикле то результат изменения внешней функции будет сильно искажён ну и само собой очевидно что если эти профайлер а работы в контексте самого профилированного процесса то они дают какой-то вертеп наверное самый известный профайлер для psp это xh прав у него есть на самом деле аналоги такие как black fire 32 из и многие другие но принципиальной разницы между ними нет иксов прав позволяет получить данные по конкретному выполнению конкретного запроса но не позволяет видеть какую-то картину в целом по группе запросов по роботу приложения поэтому если мы хотим от профилировать у нас есть какой-то конкретный запрос который тормозит и мы хотим разобраться как он работает то xh прав это наверное лучшее решение потому что мы можем увидеть что там происходит но с другой стороны если мы ищем ботаники в нашей системе то это не самое лучшее решение потому что мы хотим сразу же видеть что у нас выполняется чаще всего что нас выполняется дольше всего автопрофи мы видим только отдельные клетки и нам прив придется как бы самим вручную ходить по этим слепком смотреть и разбираться для того чтобы избавиться от этой проблемы мы сделали свой инструмент поверх xh прав о который называется life прав like прав может агрегировать множество профилей xh прав а и строить какие-то усредненные значения по ним и даже строить графики изменения этих значений по времени и что наверное самое главное то что он может детектировать резкие изменения этих значений например если вдруг вы тепло или новый код и вас там оказалось к тяжелой функции the life прав наверное лучше всего поможет разобраться в этом и найти и вторая группа profile of про фидеров этой sampler ищи профайлер и они лишены недостатков трассирующих профайлер of обычно их суть сводится к тому что есть какой-то процесс параллельный то есть это нет ни тоже процесс который профилируется параллельный процесс он пытается получить как-то стектрейсы основного процесса разобрать их и понять что сейчас выполняется на профилированным процессе когда stack trace of набрано достаточное количество сэмплер ищи profiles в профайлер смотрит сколько конкретный stack trace занимает в общей кучей таким образом мы можем видеть самые тяжелые места нашего приложения наверное самым известным надежным и проверенным времени с им прежде чем провайдером является перс он получает данные о stack trace их при помощи ядра linux это очень эффективная но таким образом можно получить данные только скомпилированных программах и нельзя видеть то что делает то что делать интерпретированы языки то что делает их а виртуальные машины поэтому сам нами написанные пить pequod в них увидеть нельзя но зато можно видеть что делает виртуальная машина что делает код виртуальной машины и можно видеть вызовы extension of хотя с одной стороны казалось бы это нам ничего не дает потому что мы пишем печь пекут они вот этот какой-то там сильный находит в с другой стороны по нашему опыту мы в результате анализа profile of the perv нашли наиболее такие результативные оптимизации и сделали вот такой пример у нас был однажды посмотрев перф мы увидели что мы как будто бы постоянно что-то сжимаем режима им используя и не используя при этом за клип это занимало в восемь процентов процессы она времени кластера когда мы посмотрели впервые увидели родительские функции кто это вызывает само собой и мы поняли что это делать обертка монтаж а когда значение какого-то ключа превышает порог обертка вам каша начинает сжимать и это занимало восемь процентов кластеры мы побить марк или другие алгоритмы сжатия и в итоге выбрали для себя за std который оказался в 15 раз быстрее и что в итоге дало нам восемь процентов прироста к типу usa же нашего гастере на одном из наших кластеров и и это в совокупности примерно равной равно 45 сервером конечно же не нужно просто так брать менять , за из т.д. потому что на ваших данных картины может быть обратная и вообще возможно за клип или сжатие какой то это не ваш bootleg но по крайней мере при помощи 1 вы сможете такое если что найти и сделать какие-то выводы в итоге может быть что-то поменять или вообще отказаться от чего-то если вы никогда не пользовались perform то можно просто выполнить вот такие строчки опять же в конце презентации у меня будет ссылка на этот год если вы пользовались когда-то то для того чтобы видеть символы и старшинов важно включить двор и выделить достаточное количество памяти под стектрейсы значит они не очень быстро вот я говорю что в перси не увидеть письме кода но в письме 8 возможно эта изменится и даже скорее всего это изменится потому что jit уже официально приняли в печке 8 если вы перейдёте на него и включите jit то скорее всего в 1 вы увидите в вывод ваших что что делать ваши функции кстати как ты уже компилируем ведь 8 ставил там и поднимите руки пожалуйста такая же мы тоже нет но возможно когда-то попробуем да и никто не никто это не делала но хочется попробовать какие-то сам следующий профайлер и да посмотреть что как они показывают и на самом деле год назад это стало возможно потому что появился проект который называется пить и спать это сэмплер ищи profile with для psp он копирует это также другой процесс запускается он копирует память печки процесса и пытается разобрать ее и понять что же сейчас делает виртуальные машины на самом деле кроме того этот профайлер помогает записывать значения различных переменных и таким образом на выходе мы можем в переменной что-то записать изначально и на выходе мы можем как-то этот отфильтровывать или сгруппировать и в том числе мы можем сгруппировать выходные данные по например животу приложения опять же пить и спать на самом деле очень молодой проект и вокруг него не хватает туринга и у него с ним сложно сейчас работать всякие визуализации приходится делать самому но если он будет развиваться то возможно когда-то станет вообще лучшим про полируем для выпечки вполне может быть сейчас я говорил про профайлер и и последняя часть этого раздела это инструмент который помогает вообще всем профайлер ом до этого мы видели какие-то скучные таково искусны интерфейс и наконец то есть красивый и с разными цветами на который называется flame граф flame граф очень нагляден каждый блок у него это вызов какого-то метода и эти блоки они идут снизу вверх по глубине то есть снизу это самый верхний уровень любые методы по стыку а сверху это самые верхние уровни наоборот снизу это самый верхний уровень его я и а сверху и самые глубокие вызовы по стыку и таким образом мы сразу же попытка так как по ширине это время которые затратила метод мы можем видеть сразу же какие участки кода наиболее горячие несмотря на то что это супер классный и красивый и разноцветный интерфейс но цвета в него на самом деле ничего не значит они просто где он и так заканчиваю раздел при профайлер и и суммировав все это если у вас есть конкретный запрос скорее всего xh прав вам лучше всего поможет если вы хотите детектировать какие-то изменения с дипломами the life прав это самый лучший они если хотите понять как их старшина работает как работает печка и виртуальный машина это перс найти bootleg возможно когда-то поможет печки спай лучше всего но ведь пока что я не могу его назвать лучшим решением поэтому на спинку и life прав есть визуализировать все поможет венгров и так это где-то примерно половина моего доклада и переходим к последнему разделу допустим мы поняли что у нас есть какой-то узкое место теперь что мы можем с ними сделать я сейчас в этом разделе сначала расскажу немного абстракции к такой небольшой а потом вернемся к миру печки и заново допустим представим что у нас вот есть такая команда который состоит из двух человек это наш кластер мы узнали что у вас есть какое-то узкое место и решили почему бы его не не оптимизировать но оптимизации это время разработчика и возможно они будут достаточно не быстрыми там иногда нужно применять архитектуру ну или что-то переписать с нуля этому могут быть в месяц и с другой стороны мы можем просто добавить серверов наш кластер и получите гарантированно дополнительную нагрузку и в таком случае важно взвесить стоимость разработки стоимость оптимизацией и стоимость железа особенно если у вас облака то тут даже перевез еще больше в сторону железо получается также нужно обратить внимание на то что пока что вы оптимизируете что-то вас по сути ресурсы сработки уменьшится в два раза вас только один из рабочих останется который может что-то делать другое полезное для компании какие-то фичи разрабатываете прорывные кроме того возможно вы можете получить такие дополнительные мощности даже вообще бесплатно допустим у вас есть какие то другие сервера которые раздают статику картинки диска тогда вы можете просто запустить на них также пить пиво особенно в эпоху докера если вас спички в контейнере то запускайте печки все у вас сразу же бесплатно увеличился кластеры кроме того если вас на разных кластерах разные паттерна нагрузки например вас на кластер печки пик нагрузки приходится на вечер есть какой-то другой кластер где строится отчетах это ночью либо в рабочее время этот рецепт такой же просто запускаем печки и радуемся мы такую штуку использовали когда у нас была рекламная кампания на супербоуле супербол смотрят сотни миллионов человек и до того чтобы перестраховаться и по единовременно увеличить мощность нашей системы чтобы пережить этот пик мы подняли печки на разных других местах где это было целесообразно и в итоге спокойно это пережили если у нас такая команда и такой кластер то ситуации возможно будет обратно ресурс одного разработчика это какой то маленький процент от команды разработки с другой стороны если он оптимизирует что-то вдруг в два раза то этому может быть совокупно равно десятком сотням и даже может быть тысячи серверов мы в какое-то время для себя собрались посчитали и поняли что мы можем потратить человека месяца даже человека годы на оптимизации это все равно будет выгоднее чем добавление железа вывод из этого маленького подраздела это то что конечно надо взвесить разные подходы к решению проблем с производительностью и если можно их решить просто почему бы их не решить просто зачем давайте перейдем теперь к печке это последняя часть моего доклада на самом деле чаще всего все оптимизации которые вы найдете профилирует они скорее всего будут завязаны на бизнес-логику и не применимы для других тоже самое у нас но тем не менее мы смогли найти много оптимизации которые связаны с тем как вообще работает пить из его архитектурой и поэтому они в целом могут помочь вам не стану также надо конечно всегда смотреть и действительно ли это так и действительно ли они у вас вам помогут профилировать я сейчас расскажу немного о том что это за архитектура а потом расскажу какие решения можно принять соответствии с этим архитектура наверное всем вам известно я сейчас в первую очередь говорю про печь плевка ямой promod пить и подобные но и немного коснусь я сейчас демонов тоже это то что каждый раз мы выполняем запрос по сути с нуля то есть мы не можем между двумя запросами пошалить какое-то состояние процесса сохранить что-то инициализирована и сохранить какую-то переменную это у этого есть огромные плюсы проще 50 писать код и сразу же исчезает целый класс ошибок которые можно допустить если бы мы такой архитектуры не было так же как я говорил раньше мы можем линейно масштабировать систему за счет железа и это в первую очередь благодаря тому что каждый процесс никак не связано с другим потому что если бы они были связаны так просто это бы сделать не удалось но конечно минус это производительность потому что на каждый запрос нам нужно сделать кучу повторяющихся действий это подключить файлы наших с кодом то конечно укажу помогает но тут тоже есть нюанс я не расскажу тоже потом инициализируете фреймворк для контейнера библиотеки что-то еще сделать ну и конечно запросить данные скорее всего ваше приложение запрашивает откую то данные из внешних хранилищ но суть в том что даже если эти данные вообще никогда не меняются в их не можете просто так взять и сохранить между процессами на будущее сейчас я пройдусь по каждому из как по каждой из этих областей и расскажу то есть можно сделать начнем с последней с данными давайте представим вот такую ситуацию который наверное часто бывает на сайте просит ввести город либо определяют его автоматически этом сохраняются лишних города в cookies да и потом на каждой страничке этот город выводится для того чтобы его вывести скорее всего нам нужно поешь нику получить его имя самое простое решение взять и поэтому а девчонку сходить какой-то внешней сторож типа базы данных вам каша или подобного и выбрать имя но это достаточно тяжело потому что скорее всего это сведется к сетевому взаимодействию опять же нужно подключить библиотеку опять же нужно выделить память под данные и и прочее прочее прочее в пехоте нельзя что ты пошалить между процессами но все равно это сделать на самом деле можно благодаря их старшину который называется опцию например и это ходе сделайте можно но это далеко не самый лёгкий extension потому что доступ к переменной значительно быстрее чем что-то сохранить его в опцию и для редко изменяющихся данных решения напрашивается наверное само собой мы просто можем такой справочник городов сохранить какой-то файлик и подключать его казалось бы мы подключаем кучу лишних данных до нам нужно вытащить всего лишь один город поедишь нику но мы каждый раз в процессе берем этот массив создаем каждый город добавляем в память и это должно быть тяжело но на самом деле это не так потому что пить и начиная с версии 70 применяют оптимизацию и я вот здесь вот сравнил по бенчмаркам массив на 10000 элементов и подключения такого массива из файлика занимает примерно одну микросекунду а пиццу в 800 раз медленнее эта оптимизация называется из рэйми юта был и трюк заключается в том что если ваш массив статический и его значение полностью можно определить во время компиляции то пить и сохраняет его однажды в shared память и все скрипты просто ссылаются на эту память не создавая ничего заново таким образом это происходит очень быстро можно сохранить огромный так таким образом справочник он во первых будет храниться один раз во вторых когда к нему будут какой-то доступ происходить из других скриптов ничего не копируется не будет пока что вы его конечно если не захват не не захотите изменить в них но самой собой если файл очень большой то ресурсы все-таки тратится на его компиляцию и когда только письме впрям стартанул либо если вы этот файлик изменили само собой видно во время компиляции может быть это это происходить чуть медленнее эти запросы так что это необходимо иметь в виду мы такую оптимизацию применяем очень давно и сложно сказать сколько она нам дала но последний раз совсем недавно мы перевели один из конфигов конфиг абэ тестов на такую штуку это дало часть процентов густо на одном из наших костров принципу что примерно на 5 сервером тут возникает вопрос а что такое вообще ну статическая штука да то есть а если мы напишем какой-то константу классов оно казалось бы статической для нас но она статическое для нас но не статическая для печки потому что вещь и применяет оптимизации в разрезе одного файла потому что тот файл в котором содержится этот класс он может измениться независимо и печки придется пересобирать это все заново и поэтому сохранить однажды это нельзя это изменен изменится в природе который появился спички 74 потому что при лот логически объединяет множество файлов в один и тогда письки может применить эту оптимизацию разреза life эту константу однажды как же нам понять применилась оптимизации лет очень просто мы можем вызвать дебаггер оп оп кодов и увидеть что в таком случае у нас происходит поэлементно и формирование массива если зимой возьмем изначальный наш файл то у него обходы будут просто возвратить ссылку на мотив и все хорошо мы много говорили про то что мы подключаем to make the файлики но сколько вообще стоит нам подключить файлик перейдем ко второй части последнего раздела я тут говорил что include такого статического массива на 100 мегабайт занимает одну микросекунду да но если мы подключим чернил клипе например и symfony то это будет 150 микросекунд что в 50 раз медленнее хотя казалось бы key arena . значительно меньше чем это мегабайт на самом деле все зависит от того сколько сигнатуру методов и классов находится в таком файле и кроме того иногда нужно иерархические по цепочке подключить другие классы например если мы создадим инстинкт класса а то нам придется подключить здесь все семь классов a b c d e f и g таким образом если мы возьмем пример кант symfony 41 то до выполнения первые строчки кода у нас будет подключен 310 файлов и это занимает до нескольких миллисекунд даже если вы не используете фреймворке то зависимости composer и могут что-то подключать о чем вы можете и не догадываться это в первую очередь касается объявление функций вне классов если какая-то зависимость объявляет функцию то единственный способ гарантировать что она будет вам доступна в вашем коде это подключить ее вообще на каждый запрос потому что в принципе нет of the law 1 га функций ведь вынужден подключать такой файлик постоянно мы нашли у себя одну из таких библиотек которые объявляла много функций переписали чуть код чтобы ее перестать использовать и в итоге это дало 2 процента экономии одного из наших мастеров что в совокупности примерно равно 12 сервером хорошо мы не можем полностью избавиться как that include a да но нам должен помочь appcache если у вас не включён appcache я надеюсь включен белка у кого у кого не включена package is постройки отлично тогда не буду давать рекомендации включить его покажи хорошего говорили об каша есть куча различных настроек и они многократно описаны и многие статьи по этому поводу я хочу сейчас рассказать о тех настройках о которых какие то есть спорные штуки и не всегда очевидны и либо советы противоречат тому что на самом деле происходит в первую очередь я говорю а о настройке rewarded пас а ее все советуют включать в первую очередь из-за такого известного способа тепло и кода который предложил расмус когда ты давно и мне кажется многие пользуются до сих пор это способ переключения 7 ленка когда у вас web-сервер ссылается на самом деле не на папку на simulink assembling ссылается на реальную папку с кодом когда вы деплоить и новый код вы его кладете в новую папку и когда этот кот готов полностью выложен просто переключайтесь им линк и тем самым у вас все а то можно переключается на новую ветку когда эта опция включена она сильно упрощает тепло и то есть вам не надо ни о чем париться вы просто переключаетесь в link все работает из коробки но эта опция довольно-таки сильно сказывается на перфомансе когда мы ее выключили мы получили 9 процентов экономии циpкa что примерно равно эквиваленту 50 серверов после того как и если вы вдруг решите и выключить то для вас немного жизнь усложнится вам придется для include a free zone вечеринки руками через ряд link ну либо постоянно вело водить пички при деплоя и обязательно web-сервер это же указать чтобы он резал вел землянке сам для engine.exe the real truth in директива вторая штука который все говорят это то что appcache для com онлайн скриптов никогда не актуален и он по дефолту выключен и типа ну тупо включать его зачем нет ну каждый раз скрипт создается с нуля зачем там appcache какой то на самом деле это не всегда так в большинстве случаев да это так но если у вас печь работает например как демон и for каяться африке подключают какие-то файлы или просто это не демону скрипт который там подключает the file you for cats и то у таких зависимых скриптов образуются общее участки памяти куда может быть помещены to the top код сохраненный и тогда форте не будут заново разбирать файл они возьмут код и зуб каша мы просто включив appcache для cum on line скриптов на одном из кустов сэкономили 60 серверов ну и конечно сейчас если кто еще не перешел на 74 конечно избавиться от и пенальти я за include меня не получится никак но в 74 появился при лот и его включение теоретически собирают все файлы в один и тогда мы полностью избавляемся от того что include может быть как ты медленно но тут конечно начинать свои проблемы с диплом но как я уже говорил обязательно взвешиваете возможно для вас это будет лучше чем то есть выгода от привода будет больше чем сложность тепло и и последний вообще самый наверное маленький мой раздел моего доклада уже скоро закончится скоро можно будет пойти наступать и сам жду этого этапа инициализацию то есть много про говорили про данные поговорили про то что делать с подключаемыми файлами но даже если все это у нас работает хорошо все равно я нам нужно на каждый запрос инициализировать наши танки для контейнеры китай библиотеки создавать iso 100 какие-то на каких-то нам нужных сервисов что с этим делать на самом деле с этим сделать можно немного ты всего и больше всего это инициализации на самом деле она может быть и не так не так сильно заметно на скриптах которые сложные но на сильно заметно на скриптах которые просты и потому что таких случаях сложности интеле зации может быть равна ли даже больше чем полезная нагрузка скрипта тут принципе очевидное решение это попытаться как-то объединять эти запросы в пачке чтобы выполнять не маленькую части логике сразу же много таких маленьких частей что в совокупности большая часть логики и в первую очередь если вдруг клиенты как-то клиентская команда там если у вас клиенты это часть вашей компании то если они вашей власти то они должны быть вашими друзьями вообще и помогать вам всячески если они могут как то группу запросов объединить в в один то почему бы не попросить их это сделать если это даже даст вам какой-то выигрыш но если это сделать нельзя то возможно у вас есть какие-то запросы которые не требуют ответа сразу же и это можно ответить и синхронно либо они вообще не знаю какая статистика который не требует ответа в таком случае вы можете написать какой-то простенький скрипт собирать все это отправлять всю эту в очередь и потом очередь разбирать опять же пачками чтобы уменьшить этот пенальти на интеле за цию мы свое время когда собачий различные запросы на клиентах и начали делать такой на сервере сэкономили пять процентов циpкa одного из кустов что равно эквиваленту в 30 серверов ну и конечно сегодня были докладе демонизации письме сейчас прямо идет в параллельном залив доклад the road runner и может быть кто-то успеть если кому-то стало скучно и добежать и посмотреть в этом сраном происходит это вообще отдельную область и как я уже говорила в самом начале она сильно меняет архитектуру то есть здесь уже не написать такой же код его надо написать по другому возникает новый класс и ошибок которые можно допустить это делать сложнее новый класс проблем а если у вас уже есть существующий код то возможно переписать его очень сложно как какая-то например для нас и мы хоть и не используем сейчас полностью вот эти штуки наверное никогда не будем использовать полностью но мы все-таки экспериментирую у нас есть места где их как-то можно применить пока еще у нас нет каких-то результатов которые можно пожарить так что следите возможно не к это будет все мой доклад подходит концу и пока что мы здесь говорили обо всем все оптимизации которых я сказал сэкономим studios два сервера неплохо за 30 минут в целом а давайте еще раз пройдемся по основным моментам который я сегодня сказал во-первых обязательно мониторьте профилируйте потому что противном случае не понятно что происходит системой и вы не можете знать есть ли проблемы у вас или нет и где они обязательно если вы нашли какие-то проблемы 200 разные способы их решения возможно какой то не очевидный способ будет более эффективным или может быть какой то наоборот очевидный не применяйте рецепты какие то просто так даже все что я сказал не верьте даже мне обязательно перепроверьте если соберетесь что-то делать и обязательно обновляйтесь на новые версии пить пиво но здесь у доклады были никиты попова дмитрий стогова которые очень много вкладываются для того чтобы сделать спички быстрее и особенно это заметно при переходе с ветки пятую и на седьмую все материалы доступны по этой ссылке кир код все на этом все спасибо ваши вопросы понял спасибо за доклад мы хотели бы поблагодарить и вручу тебе сертификат и его спасибо покажи круто спасибо глядя на твое стикеры на ноуте я вдруг понял что у меня футболку под цвет бонус круто это чем-то это значит мы не договорились работодатель не будем говорить ниже итак сейчас у нас будет секция вопросов не забудь что тебе нужно будет выбрать природа самый сложный момент они будут стараться кажется нет вопроса все хотят наступать и добрый вечер вопрос такой странной просто там в презентации было написано про php4 7.4 что вы уже используете нет мы не используем нас 72 пока что мы еще и даже не переходим на 73 и скорее всего 7 пока еще это не решена но скорее всего 73 мы пропустим и передем к возносим 4 по 5 спасибо здравствуйте спасибо за доклад вопрос такой вы вынесли справочник городов в отдельный массив пока пышный допустим а раньше он был базе допустим есть такой же страшен ну не городов чего-либо другого и он базе потому что нужно какое-то его управления там из админки допустим этого этого самого списка естественно сейчас добавление нового элемента в этом массив это будет отдельный камер и это будет деле задач на разработчика они управления допустим из какого-то веб-интерфейса или этот как-то файл генерится у вас отдельно там по крону там забирает из базы где из справочника генерит статический массив ага да я поняла вопрос смотрите на самом деле у нас сделано так что у нас есть репозиторий и у нас есть папки которые не кладутся в репозитории то есть они просто папки и в них находится сгенерированные файлики то есть отдельно происходит выкладка кода отдельно происходит выкладка таких сгенерированных файликов то есть мы можем просто верну конкретно если это интерфейс не знаю если у нас прям такая что да есть у нас такая штука даже много где применяется то есть в интерфейсе мы что-то меняем и мы перерабатываем только вот эта вот папочку с сгенерированным кодом это никак не комиссии в претории то есть ну как бы анализируется старый файл они перегенерируем и должен сбросить стоп кажется там этот новый массив ура подтягивался новый справочник а на самом деле appcache как раз вот тут я рассказывал про тепло сим линком да тут зависит очень сильно как это все настроено то есть у нас сделано так что у нас все файлики versio не руются как бы имена файликов то есть они мне кажется я видел ваших до дадим dk можно посмотреть доклад но истории в том что у нас это будет новый файл на самом деле и просто вся система узнает что надо подключать уже новый файл ему пасибо но это также можно сделать например всем линком если у вас эта опция включена и например всем венки на новый подписываться спасибо за доклад вот про профилирование вопрос такой быстрый ты говорил что можно например обложиться начали там start и end перед выполнив функции посмотреть с процессором временем но со временем выполнение сколько занимает скрипт понятно с процессором понятно какой на какую память вы смотрите hop уснут мама ремуса какой вы смотрите ага смотри я сейчас отвечу сначала немного не совсем наверное я может быть правильно рассказал про вот эти вот таймер и мы их сами не расставляем это делает профайлер то есть xh прав ты включаешь простых сахаров он перехватывает вызовы и это что я написал это не реальный код это просто как бы как логически это происходит то есть кот остается таким же ноги к запрос добавляет что-то до вызова и после вызова вот по поводу памяти как бы это правильно сказать мы не не то что не смотрим на нее но она нам уже последне время настолько неактуально то есть когда мы перешли на печке 7 у нас потребление памяти скриптами настолько упала что она никогда не становился нас bootleg вам последние фиг знает сколько на то есть мы следим за не за нее но специально как-то глубоко не не смотрим и даже по методам я не смотрим мы смотрим в пинге в целом по скрипту то есть пинг посылает в конце выполнения скрипта сколько он память выделил вот и у нас никогда и она не выходил последнее время за какие-то границы и поэтому мы не смотрели на память методов а еще вот вопрос вы сказали что память у вас с ним проблем не к не бывает наверняка же у вас есть задача по обработке изображений этого загружаем и пользования не прочее это все происходит на печке или нет если на печь питу как кто-то из памяти все таки справляетесь у нас наверное много как происходит в том числе что-то происходит на печке но это происходит скриптах то есть это не онлайн и там обычно есть есть разные решений у нас наверное много чего предсказать изображениями но обычно это просто кайта очередь очередь разбирается скрипт что-то делает с изображением этом 10 элементами очереди из там со 100 с тысячу что чтобы что подходит нам сейчас до и после этого мира it как всегда ну то есть все все нормально работин спасибо ну и наверное я понимаю вопросы к такие проблемы как это могут быть но мы с такими проблемами не сталкивались просто у меня три вопроса в одном вопросе первый вопрос это про масштабируемость x h прав а насколько знаю он нативно плохо масштабируется возможно но мы на самом деле собираем профайлы то есть мы собираемся продакшена но они собираются не на каждый reckless потому что у него достаточно большой мир но скажем так он гораздо ниже чем у и где бага этот overhead он достаточно большой и поэтому мы собираем profile и там один из там допустим 1000 request of да то есть мы сильно их проживаем поэтому у нас принципе проблем с масштабированием его не было ну я имел ввиду тут сборы и результатов то есть это нужно писать утилита которые будут брать файл и потом агрегировать их запихивать а брать файлы озу и агрегировать да да prolife прав этим еще до их xh прав экспонирует да я имею дом файлы помещают у него же нет у натурального какого-то решения чтобы собирать связанных серверов файлы и как агрегирует результат насколько я знаю я я точно не знаю написать это сами или нет но по-моему xor крупная сам может писать в маске и у него есть веб-интерфейс найти смотреться хорошо потом еще я хотел спросить про такие важные мне кажется моменты для оптимизации это как у вас выставлен php-fpm то есть статические процессы фиксированное число до статический процесс в кино что там где-то обычно по 100 и 120 5000 эвристические рассчитали можно с лицами рассчитывали вручную смотрели и выбрали какое-то число да вы используете кэшированные соединения с базой данных с редисом и так далее редисом вообще не используем с базой данных навскидку не скажу я бы наверное нет нет не используем используем потом я хотел еще ну как бы это не вопрос а просто такое уточнение тоже про каширование путей к файлам то есть покупая еще есть такая настройка как rail pass кэш и если проект довольно большой то есть большое число файлов то дефолтная установка она может не вмещать всех каширования всех путей то есть на это тоже имеет смысл обратить внимание гасят окна и вот ещё одна очень каверзная как бы настройка это open бэйс гель для вас это скорее всего не актуально но для тех у кого там ширины серверы или допустим старая какая-нибудь установка если стоит настройка open до из дерпта путине кэшируются до полон я измерял у меня в три раза я там работал на старом проекте как бы оптимизировал его и одна эта настройка в три раза меняла производительность долго на самом деле много настроек и много раз они в них говорилось дай ссылочку кстати это ссылка на agestar если у тебя есть какие-то мысли и ты можешь их записать туда и все остальные видеть если кто-то хорошо и последнее то что я хотел спросить это каким образом вы сравниваете производительность то есть у вас есть какие-то тестовые стенды и вы сравниваете на той же самой нагрузки производительность как бы до изменений и после изменений тестовые стенды у нас есть но мы так наверное это зависит от ситуации скажем да то есть допустим мы поняли что виктор профи увидели что там какой-то метод очень долго выполняется да и мы вы оптимизировали мы следуем снова мусор профи посмотрели если все стало окей мы дипломат код смотрим как на продакшене то есть у вас фреймворка такого сравнительного тестирования прямо как автоматизированный нет ну то есть у нас собираются все метрики строится пинга все это происходит с разных серверов том числе so stay джинга и можно получить там шо ты у нас такая штука как типа своя ветка кода на продакшене вас любом да но это не автоматизирована происходит спасибо page давай остальные вопросы передвинем в кулуары и тебе нужно выбрать самый лучший а давайте вот последний человек он может быть они качество но количеством точно взял то есть"
}