{
  "video_id": "0q9UyUlYPos",
  "channel": "HighLoadChannel",
  "title": "Обзор архитектуры быстрого сборщика логов на Go / Владимир Витковский (Ozon)",
  "views": 5562,
  "duration": 2609,
  "published": "2023-01-19T07:03:35-08:00",
  "text": "руководитель об сервами лети соответственно в зоне это при павлина первое логирование мониторинг и tracing так как сервисов много больше двух с половиной тысяч рпс of много 120000 это в секунду самый нагружены сервис соответственно вот этих всех вещей логов метрик трессов очень много сегодня нас интересует больше история именно с лагами прилетает их 300000 в секунду примерно у нас в зоне поэтому мы как бы решили сделать некое свое решение дальше я буду объяснять почему мы решили его делать и чем она там лучше или хуже других решений по плану вот этот обзор будет начали потом посмотрим на архитектуру какое-то внутреннее устройство нашего инструмента какие он дает гарантия доставки рассмотрим как сделан плагин для чтения из файлов и соответственно отправки этих данных куда-то дальше плюсы-минусы расскажу такой тизер что мы будем делать дальше в будущем и посмотрим на результаты внедрения и на что повлияло вот внедрение нашего инструмента обзор ну во первых нам нужно понять что что такое вообще сборщик логов да это какая-то вещь которая читает данные обрабатывает и записывают в другое место сразу скажу что вот все что я рассказываю это можно самим посмотреть на гитхабе уже все выложено то есть можно с этим как-то экспериментировать самим пробовать у нас были изначально особые требования да так объем данных больших большие поэтому мы сформировали ну такой список требований во-первых нам важно сбор и запись в разные системы при этом они не обязательно какие-то общедоступные то есть в озоне есть какие-то системы для которых нет уже там готовых каких-то вещей нам важно было быстрота и надежность кроме того вот этот инструмент должен работать на различном железе вот сейчас армада допустим достаточно актуальная штука поэтому не только там до 64 но и армии тоже нужно чтобы это работало есть кубер есть железная сервера есть виртуальные машины кроме того так как озон и большая большая компания нам у нас есть определенные требования безопасности не какие пароли нигде в конфигурации не должны находиться поэтому все секреты к хранятся в lte и вот это одно и то же таких важных требований к этому инструменту есть уже готовые решения все наверное знают там есть файл beetle axt снг flow in beat здесь есть наверное сейчас наиболее популярный инструмент это вектор от компании do the dog ну еще есть графа налоги и сейчас следующий слайд чтобы не томить да вроде заявляется что быстрый инструмент немножко запутался вот то есть результаты у нас получились такие это я проводил у себя на ноутбуке да но здесь хочется порассуждать не о том насколько там большие или маленькие цифры у меня есть следующая мысль у нас есть процессоры до которые там на одном ядре могут несколько гигабайт данных обрабатывать секунду есть сеть которая тоже там гигабитные интерфейс и есть ssd-накопители которые тоже могут гигабайты данных отдавать в секунду но при этом цифры для сборки логов обработки их так далее там можно разные бенчмарки смотреть и они как бы не четырёхзначное да там допустим 1500 мегабайт в секунду они почему-то двухзначное обычно бывают там если взять файл бит до 64 мегабайта в секунду как то возможно как когда железо у нас вот такой вот топовый и мы как бы уже в двадцать втором году поэтому в какой-то момент вот для нас это было ну так такие сомнения до вызывало почему инструменты не так быстро работают как могли бы и на самом деле вот даже если взять вот второй кейс когда не идет чтение ssd джейсон и потом просто вдохнул сбрасывается до полтора гигабайта в секунду в принципе мне тоже не понятно хотя вроде как мы сделали быстрый инструмент но можно больше но почему то вот над этим можно работать но общее доступные инструменты почему-то даже и такой скорости не по мне показывают вот почему мы решили все таки делать во первых вот эти все общедоступные вещи мы пытались адаптировать каким-то образом исправляли баги file by те пытались там заставить френды работать надежно чтоб он все доставлял ну то есть копались именно вот в кишках у нас ну так как мы копались да мы поняли что в код немножко сомнительного качества вот надежность не устраивало не устраивали то сколько ресурсов потребляют эти все вещи кроме того вот фичей например как волк до таких из коробки не поддерживаются то есть нужно что-то там придумывать кроме того озон большая компания быстро растет ку ку чи всего нового появляется и конечно же нам нужно будет этот инструмент какой-то момент дорабатывать допиливать еще что то делать поэтому важно было легкость доработки если это какое-то чужое решение да ну его сложнее про плагины я уже сказал да нужно что-то будет допиливать например у нас есть такой плагин дистрибьютор apple называется он позволяет имитировать количество считываемых лагов не по сервису даг не по одному instance у сервиса она весь на весь сервис то есть если у него 10 инстансов запущена мы можем установить лимит именно на количество logo в сумме по этим инсам вот таких вещей допустим не ни в одном open source решение встретить нельзя есть несколько примеров вот допустим это кот файл бита и там достаточно странная такая конструкция сделана этот код определяет какой runtime ну то есть какого формата лак записан в кубер рамками он может быть либо докер либо там контейнер да допустим они определяют это по наличию фигурные скобки в нулевом байте logo ну то есть если это фигурная скобка это джейсон значит это докер если это не фигурная скобка значит это контейнер д правильно конечно было бы сделать ну просто из runtime и взять собственно и из cooper пил взять runtime и запустить парсер соответствующую этому runtime а вот что написано у инструмента вектор тут если перевести на русский написано что в советы при чтении файла сохраняется в том в тот момент когда он когда эти данные про читались то есть если в момент до того момента как эти данные будут отправлены куда-то если вектор перезагрузиться или там произойдет еще что то то все ту же сдвинулись и данные потеряются ну то есть это официальная документация так гласит вот это скриншот из игры logo он показывает насколько хорошо fluent доставляет логе мы запустили один под по крону который записывает ровно 60 логов он запустил запускался на высокой нагруженном сервере где там еще тысячи кодов крутятся и собственно это гистограмма мы проанализировали сколько действительно из этих 60 логов долетая до конечной системы там где палочка чуть ниже значит что-то потерялось вот фонды так работает и давайте тогда перейдем к тому что мы сделали и посмотрим как архитектурное это работает общая схема достаточно простая ну как и у других инструментов есть данные есть они попадают в кой-то input плагин дальше передается в pipeline в котором несколько экшенов запустится чтобы обработать до как-то эту информацию дальше вал под плагин и он уже записывает во внешнюю систему что-то input плагин в нашей архитектуре да он читает некоторые сырые данные отправляют их в pipeline и здесь важно отметить что он как бы наш движок да не запускает их сразу несколько ответственность но том чтобы параллельно там как-то обрабатывать информацию лежит именно на реализация этого плагина экшон плагин простая штука она просто принимает уже не сырые данные данные во внутреннем устройстве движка это и структура event может ее как-то модифицировать и принять решение что делать дальше может выкинуть event может протолкнуть его дальше по папе тайну может сделать такую штуку которая называется hold ну то есть взять этот ивент и подождать следующей овен чтобы их с ними можно было сделать какую-то там склейку или ещё как-то обработать две структуры которые идут последовательно old wood плагин тоже принимает внутреннее устройство logo структуру event он тоже существует в одном экземпляре как и input плагин чтобы можно было самому как-то решить каким образом наиболее эффективно записи записать в конечную систему данные и собственно он опять преобразуете винт обратно в сырые данные чтобы ну потому что внешняя системы с нашими внутренними структурами не работают и теперь рассмотрим вот собственно как внутри есть сам pipeline устроен у него задачи несколько задач во первых он сырые данные декодируют вот какие-то поля в внутреннюю структуру которой лежат в ивенте и он ответственен за то чтобы запускать экшн плагины подряд и здесь уже движок как подумал да за нас то есть за нас я имею ввиду за тех кто пишет плагины да он уже сам автоматически умеет запускаться в нескольких инстансах и может работать параллельно базово вот эти pipeline и запускаются по количеству ядерно сервере или на машине на который исполняется код сделано для того чтобы но так как тут нет ввода-вывода поэтому как бы закрепиться на количество ядер это будет достаточно эффективно и так как все данные проходят через этот pipeline он наиболее чувствителен производительности внутри pipeline выглядит примерно так ну тут немножко есть дублирования как бы логике так с другого слайда но она тут немножко по-другому представлена то есть данное слева направо идем данные приходят тут нету input плагина видно что есть компонент стрим их тоже может быть несколько туда прилетает event они сырые данные дальше все это проявляется в процессор и его внешнюю системам но главная штука здесь на этой схеме это компонент event пул он содержит готовые экземпляры вот этого внутреннего представления внутренней структуры который называется event-ы умеет их быстро отдавать для pipeline а чтобы он там преобразовал сырые данные в внутреннее устройство и дальше использовал как-то и у него интерфейс достаточно простой есть две функции gtb первое отдает те как готовый инстанции 2 с помощью второй функции ты можешь обратно вернуть в этот пул инстанции vento у нас есть к этому компоненту определенные требования так как pipeline это наиболее такое горячее место до к только которому важна производительность к этому event полу мы выдвигаем следующее ограничение во первых он точнее выдвигаем следующие требования он должен быть строго игра ограничен для чего это делается ну допустим у нас есть какой-то быстрый input то есть допустим мы читаем с диска да и медленный путь допустим пишем по сети в какое-то медленно и хранилище так как данные мы можем вычитать быстро память может быстро закончиться потому что мы не успеваем записать до куда-то поэтому количество внутренних вот этих вот структуру которой мы можем заполнять оно должно быть ограничено из-за того что у нас есть требование к производительность сложность алгоритма который отдает нам эти инстанции должна быть у от единички максимально быстро до смысл вообще то вы event пула так же заключается в том чтобы он избавляет нас от каких-то дополнительных и локаций то есть если нам нужна вот эта структура развесив который есть информация пологом там какие-то поля и так далее на каждом цикле обработки вот этого logo элемента не должно быть и локаций потому что структура большая и это очень затратная операция также там не должно быть блокировок но они должны быть сведены к минимуму если у нас поток логов маленький и при этом не весь процессор используются нужно чтобы вот эта штука не крутилась как там в цикле и не жрала при этом процессор есть там в несколько уже готовых решений есть такая штука как символ есть каналы это то что прямо года доступно есть более системные вещи типа мьютекс of и кондишен off также эту ведь можно сделать с помощью каких-то акций алгоритмов которые считаются самое быстрое и есть решение которое мы придумали я но сейчас мы до него дойдем если использовать sinful это все уже за нас реализовано но проблема в том что здесь не ограничено количество инстансов то есть если захочешь там не знаю миллион этих элементов памяти создать the sinful от этого не убережет ну и плюс вот эти инстанции можно могут собраться горбач коллектором тогда фишка с тем чтобы не делать локации она не сработает есть каналы та самая простая реализация и самая медленная там есть много блокировок поэтому она не сильно быстро и если использовать системные вещи имеют акции кондишен это в принципе тоже не очень сложно и это быстрее на 20 процентов чем использование каналов г new topic new таксы кондишен можно использовать вот следующим образом это какой-то псевдокод да то есть мы сейчас рассматриваем реализацию вот этого event пула есть две операции get back где-то дает тебе instance с помощью бег можно его вернуть обратно в пул если рассматривать функцию get она достаточно я простая мы плачем мьютекс и в конце функции его разблокируем все ивенты хранятся в стеке соответственно мы просто берем а тут event счас т.к. но нужно при этом понимать осталась там что-то какие-то структуры остались на стыке или не остались вот на четвертой строчке iv собственно это делает если их не осталось мы уходим в кондишен ждем пока они там появятся как только они вызвалась функция бег положила обратно что-то на стек вызвало кондишен и мы проснулись а далее event назад ну точнее тому кто его хотел взять насчет лап free обычно это достаточно такие сложные вещи которые с первого взгляда там не поймешь поэтому ну скажем так для поддержки это не очень прикольно и плюс там могут быть всякие сайт эффекты например в некоторых алгоритмов может быть зацикленной операция касс которая будет при простое все равно жрать процессор может могут быть операции которые отдают кванты времени какому-то шон дули рутом либо операционной системе либо в случае go-go runtime мы сделали чуть более простую реализацию этого lock free алгоритма но при этом наша реализация используют уокен памяти дополнительный ну то есть ген это количество элементов в нашем event пуля сильно разбирать и я вот этот псих все равно вход не буду потому что достаточно такая технически штука можно будет посмотреть это на презентации либо можно будет где-то обсудить на нашем стенде а зоновской или еще что то в каком то таком формате ну то есть я готов постараться это объяснить уже как на словах не не в рамках доклада lock free нет ну вот основное тут то что то что используется да вы в основном и блок фрины допустим на шестой строчке есть операция cose da она атомарная и по сути наш алгоритм а он ну короче говоря мы сделали так что совместили несколько алгоритмов вадим то есть не только lock free мы сделали поддержку и как бы варианта с new таксами и получилось так что у нас такой оптимистичный подход то есть если мы можем сделать операцию касс и нам как бы она удалась мы отдаем event если ивента не оказалось который можно отдать то тогда мы отдаем квант времени scheduler у и пробуем заново а если совсем как бы ивентов нету в нашем пули и нам действительно нужно ждать долго только тогда вызываем вот этот кондишен получается так что вот такая быстрая оптимистичная реализация вот этого event пула позволяют отдавать миллионы эвенов в секунду для того чтобы параллельно дальше их можно было как-то обрабатывать кроме того внутри вот этого элемента используется библиотека insane джейсон она позволяет парсить джейсон и тоже в стиле без за локации то есть если у тебя есть готовая структурка ты можешь распарсить нее джейсон и потом его перель использовать таким образом будет меньше локацией мы рассмотрели вент пул есть еще два компонента на этой схеме есть стримы есть процессоры сейчас мы рассмотрим для чего нужны стримы они нужны для того чтобы объединять ивенты в некоторые группы кроме того стримы позволяют гарантировать порядок этих ивентов для того чтобы можно было реализовывать какую-то логику на основе этого например можно использовать это для склейки логов ну например вот есть у нас файл и в нем содержится как бы два типа логов 1 из стр 2 засады out они могут быть как то перемешаны между собой и допустим у нас есть какой-то stack trace из-за ошибки да и он пири-пири перемешался с лагами которые но просто обычные логе приложения для того чтобы склеить нам этот такт рейс нам нужно как бы его собратья вот это вот перемещение как бы упорядочить в обратную сторону то есть если на первой строчки на 4 был вот этот вот было the stack trace то нужно сделать чтобы у тебя в обработчик пришел порядок ивентов приходил не 123 14 чтобы ты мог на основе каких-то правил склеить две строчки между собой ну то есть из этого файла получается 2 стрима 1 стр 1 4 строчка вторая стадия вот это вторая третья строчка после этого когда у нас есть правильная последовательность ивентов которые про читалось из файла все это отправляется в процессор в нем ивенты поступают последовательно сами процессоры могут работать параллельным при этом размазывают ом нагрузку по всем ядрам каждый процессор он подключается к своему стриму полностью его вычитывает обрабатывает вычитывает пока там есть данные как только он все вычитал он как бы его отпускает и может прикрепиться другому стриму каждый этап обработки может вернуть вот три варианта развития событий может либо дальше ну то есть event может либо про кинуться дальше либо от броситься либо вот третий вариант collapse он позволяет делать склейку либо обработку нескольких ивентов одновременно какие у нас есть гарантии доставки в файл д во-первых мы треком каждой виндовой в отдельности нет такого что там трека ица batch либо еще что то это отличие от там других систем в том что вот этот каждый винт ждет подтверждение то есть пока он не будет подтвержден за комичен input плагин не имеет право там считать что этот ивент куда-то был отправлен то есть реализован такой механизм commitment of за счет этого можно сказать что существуют вот это вот от листву once delivery то есть каждый винт как минимум один раз будет доставлен если там плагины input and output и правильно написано ну тут съемка сложная но на самом деле ничего сложного нету мы как бы время идет вниз данный дух сначала слева направо потом справа налево мы получаем данные инфу плагина отправляет в pipeline pipeline отправляет вал под плагин output плагин удостоверяется что он все отправил куда нужно и только после этого вызывает вот эти вот методы коми то они пролетают обратно и зал под плагинов pipeline и в input как только input получил commit ну допустим для файл плагина коммент означает то что нужно записать файл с овсеп это мечта информацию мы прочитали это кстати тут отсылка к тому слайду вектор он как бы сдвигая это все ты сразу после того как input плагин вы что информацию здесь все это пролетает через вот такой механизм commitment а это лист vans delivery означает то что могут получаться какие-то дубликаты мы как бы на этапе доставки с ними не боремся мы генерируем для каждого event-а или logo 128-битные иди первая часть это время в миллисекундах когда он был либо записан либо если такой информации нету когда мы его прочитали и какой-то хэш ну то есть вторая часть такой-то хэш от уникального поля которая есть в логе ну например имя пода да мы записываем все это в хранилище а дубликаты убираем уже во время отображения давайте немножко profile плагин поговорим во первых он реализован на fx инструкциях ну мы не сильно упороты в плане того что сами писали там какие-то инструкции есть моя любимая функция в яндекс байт она вот зависимости от архитектуры умеет там на любых процессорах используют эти вот быстрая vx инструкции он читает файлы в несколько worker of то есть может там читать параллельно из тысячи там файлов без проблем кроме того мы специально его писали в стиле файл fast так как нам нужен нужна достоверная достоверность того что всех ну мы считаем максимум информации сколько можем ни каких то проблем быть не должно быть в зоне очень много всяких разнообразных данных поэтому нам важно чтобы если вдруг внутри произошла какая-то ошибка логическая там или еще какая то он сразу падал и мы этот как как инцидент менеджмента такой вот он упал значит мы разбираем эту ситуацию и пока до конца не докопаемся мы как бы не за хлопнем на это глаза для идентификации файлов кроме имени используется еще номер и ноды и точно также как основной pipeline в этом плагине отсутствует локации чтобы работала максимально быстро насчет файловой системы в нашем плагине системный вызов антифа используется только для того чтобы получить файловый дескриптор как можно быстрее то есть у нас при сканировании директорий циклично на вот эти вот файловые дескрипторы не захватываются мы хотим захватить его как можно быстрее для того чтобы работала удаление логов но так как мы захватили файловый дескриптор если в этот момент файл удалится то он пропадет из файловой системы пока есть открытые дескрипторы на самом деле вместо не очистится то есть его не будет места куда-то потерялась поэтому все уже обработанные файлы периодично отпускаются ну то есть дескрипторы отпускаются и открываются заново если файл был удален то он пропадет не только системы но и все данные почиститься если он не удален тому мы собственно получим опять открыто дескриптор можем с ним работать и получается такая схема что если мы в момент создания файла успели захватить файловый дескриптор то никакой информации не потеряется но может быть очень маловероятно шанс что мы создали файл что-то туда записали удалили его тут же и в и и и если мы не успели захватить файловый дескриптор тогда вот эти вот данные могут потеряться ну то есть это в кейсе когда быстро создаём пишем и удаляем файл какими мы руководствуемся не знаю как то принципы медаль для того чтобы данные действительно не терялись во первых нужно точно использовать файловую систему x4 потому что у него внутри есть такой тоже механизм транзакций можно сказать за счет этого там блоге не могут пока ра птица как-то или еще что-то ну то есть она более стабильно чем все остальное нельзя использовать метод ротации копий от ран кейт который есть вот в в ту зе агротрейд который который называется укротит популярный инструмент вот лучше эта штука не использовать потому что данные могут потеряться вот и собственно вот этот кейс когда они успели захватить файловый дескриптор нельзя удалять файлы сразу после записи то есть нужно немножко подождать есть несколько примеров смешных так достаточно с которыми мы столкнулись в во время вот разработки нас были лаги под газ а которые весили одна строчка примерно 800 мегабайт ребята из какой-то команды умудрились умудрилась логировать картинки png без 64 закодированы и писать это влоги было также 4 экранирование джейсона оно чревато тем что каждый экранированный символ превращается в 2 в 4 символов поэтому логе таким образом могут сильно распухать какие есть плюсы минусы плюсы понятно и очевидно что мега быстрый достаточно круто работающий есть коммент month механизм есть порядок ивентов то есть плагины достаточно легко описать очень хорошо масштабируется по ядрам то есть можно там его запустить допустим на тачке где 96 ягер и все девяносто шесть ядер будут использоваться для обработки логов готовы уже из коробки поддержка volta прометея и хорошо эта штука запускается в кубе ри там есть все плагины но есть некоторые минусы так как ивент в пул в нашем решении ограничен если его сделать слишком маленьким то могут быть фрезы случается это из-за того что допустим есть какая-то склейка да она ждет следующие ивенты она не может отпустить event пока они не придут все строчки из этой склейки там допустимых может быть 16 event пул всего на 32 ивента поэтому половину вот мы использовали для того чтобы просто сделать ну склейку таким образом ивентов может не хватать и могут наблюдаться фрезы кроме того него все хэнку так сейчас реализованы вот эти коммент month механизмы но мы ну это конечно решаемая проблема мы будем стараться все это допилить кроме того в будущем ну то есть мы делаем на самом деле экосистемам open source оно будет не только сборщик логов который вот называется файл д мы в скором времени постараемся выпустить в open source также хранилища для логов называется всегда был интерфейс ну пока кодовое название secure но на самом деле у нас тут с брендингом с нейминга мне очень хорошо вся давайте быстрые результаты мы внедрили это решение в кубе ри полностью собирается все с других внешних систем типа там позже сакли хауса кроме того очень важный пункт это контур подписей dss для банка озона вс кого там есть определенные требования к безопасности это тому подобные логе должен и там действительно не теряться потому что это банка это очень важная информация но там это удалось запустить есть уже готовые плагины кафка ластик с 3 там грейлок вот это все это все уже есть и готово можно использовать и вот так вот выглядит переход на нашем кластере с file by the но на файл д то есть видно что до перехода потребления общая в кластере всех вот инстансов сборщиков было 25 лоб лидер после перехода она стала где-то примерно 3 дыра при этом пропускная способность больше все выложено в open source есть сам инструмент файл да есть такие на коле ночные бенчмарки которые можно запустить только на макось и к сожалению и есть библиотека insane джейсон который позволяет быстро парсить джейсон и все спасибо за внимание вова спасибо спасибо за доклад сейчас будет сессия вопросов но это необычно сессии вопрос это сессия просто by нужно тебе выбрать два самых лучших и авторы самых очень вопросы получит дополнительно подарки эта зона пожалуйста вопросы здравствуй а здесь в самом конце а можете нас лает вернуть игривы и стадо рст дауд и вот со стеком trace пример приводили да вот вот он был только что вот у меня по нему вопрос вы после допустим 3 считывание стадо аута и от успешные отправки записываете апсайд на файл чтобы прекращен начать с этого все то читать записываются в сад и на самом деле об и стр стрима std out но когда запускаются файл д он выбирает меньшее в set in a из тех стримов которые к файлу привязаны и поэтому дубликаты получают до могут быть поняла да да пасибо дальше вы назвали проблему в файл бит по моему привели кусок кода вы отправили мир request с исправлением мы провели там несколько других исправлений эту штуку я нашел не знаю года три назад наверное и вот когда подготовился позавчера зашел посмотреть увидел что там тоже самое все еще написано никто не увидел но мы на самом деле еще и как там эта штука будут flowing тоже вот там несколько багов исправили но к сожалению ситуацию не улучшило спасибо за доклад у меня такой вопрос у вас на слайде вы показывали как формируется аиде ивента берется таймс темпа до миллисекунд и берется некий ключ там до название пода и здесь вопрос а вот этот ключ к берется потому что логе могут быть не джейсона вы это не подавая да какие то логия другие это настраивается и не сталкивались ли с коллизиями потому что таймс там до миллисекунд при большой нагрузке да ну может теоретически какие-то коллизии вызвать то то что вот этот айди будет одинаковой да если один под у него много там грудь инь каких то бежит оон в одно и то же время какие-то логе в логе важны туда доставил во-первых time stamp мы в на на секундах спать но можно на самом деле не только название подаришь брать можно там еще чего-то брать не обязательно если такой супер под до который пишет там очень много всего но можно что-нибудь другое придумать да это можно настроить как раз спасибо за доклад я здесь у меня два вопроса первый вопрос ну лог коллекторы ладно там кучу с ними проблемы вы делаете свой о чем вас не устроили хранилища там пластик или локи и особенно web-интерфейс танки бан-али grafana а второй вопрос а где влог коллекторе вольт за какие секреты вы получаете из вальта для логов спасибо так первый вопрос был про будущее храмов работу все да это на самом деле немножко другой доклад да и там в этом нужно было объяснить есть такая концептуальная вещь как open-source называется и озон любит внутри хочет развивать от топан source поэтому там где мы как бы можем это сделать убить как бы двух зайцев да может быть там где-то и как сформулированную короче говоря может быть можно было бы до использовать нам elastic не знаю crack house или еще что то но так как есть часть проблем которые мы хотим знаем как решить это лучше да в этих частях в час в частях лагов и так как мы хотим open source дата это может быть такое логичное решение убить двух зайцев сделать ее хранилище более крутой которая нам подходит и там быстро работает на наших задачах и еще в open source выложить вот и концептуально если по там деталям разбираться кто лучше отдельный доклад делать 2 там еще по моему какой-то вопрос спасибо хороший доклад подскажите пожалуйста у меня тут два маленьких вопросе к петле почему бы в принципе не не отказаться от файлов и посмотреть сторону опыт или митре или чего то подобного и второе что использовать в качестве формат хранения данных для всех о котором вы собственно говоря сказали в самом конце собирать из файлов нет файлов просто не писать файлы и их не будет понятно но допустим я же не только там кубер или сервисы которые мы наши applications есть там база данных есть еще там какие-то инструменты ну и куча да много все как бы не переделаешь большинство из них и спорить пользуются файлами поэтому как бы пока так не знаю всегда же можно сделать какой-то коннектор который будет такие уникальные случаи переводить в том что могут найти dmitry ну и для интересное можно будет как то наверное обсудить если у вас есть какой-то успешный кейс можете поделиться на там стенде подойти да и 2 вот маленький вопрос какой формат данных используйте для хранения всех baby свой бинарных формата какой-то индексируемый то есть нему можно угадать да и то по сути обратный индекс примерно как в ластики она немного хитрый спасибо"
}