{
  "video_id": "VbbfGu5Nkhc",
  "channel": "HighLoadChannel",
  "title": "Как вынести расчет цен для 20 тысяч магазинов из SAP, чтобы сохранить 4 девятки / Алексей Топчий",
  "views": 63,
  "duration": 2221,
  "published": "2023-10-06T07:16:47-07:00",
  "text": "видеть Этот проект начался примерно полтора года назад с набора команды команда набиралась с нуля Вот Эти прекрасные ребята люди менялись приходили уходили но практически в таком же составе команда просуществовала до текущего момента до запуска суть проекта была в следующем дежурная смена обнаружила большую нагрузку на Саб примерно с 9 вечера до трех ночи сап - это огромная система и большая нагрузка в ней всегда очень тревожно воспринимаем воспринимается Оказалось что в этот момент считались цены для 20000 магазинов было решено в связи и с уходом Саб из России и чтобы более контролируемая масштабировать эту историю вынести это все в микросервисы изначально задача была следующая Мы выносим в функционал как есть по дороге его не рефакторим не преобразуем не улучшаем столько с целью того чтобы не при рефакторинге не внести какие-то ошибок то есть максимально быстро вынести и запустить Какие ошибки мы совершили на самом старте мы не предусмотрели количество данных которые у нас было фактически то есть посчитали что у нас есть три миллиарда записей на которых надо произвести расчеты оказалось их почти в два раза больше порядка 6 миллиардов первое второе что мы не предусмотрели секундочку что мы не предусмотрели какие-то нагрузочные тесты на старте чтобы понять Те технологии которые нами были выбраны отвечают нашим требованиям или нет И без таких тестов мы потеряли где-то два или три месяца на анализ понимание что технологии нам не подходит и замена этих технологий на что-то более подходящее и последняя ошибка мы увлеклись правильным проектированием Я думаю вы все знаете что есть определенные наборы паттернов для каждого систем есть паттерны архитектурные паттерны там программирования у меня как-то был случай когда я прочитал первую свою книгу про паттерны и сразу бросился применять эти паттерны в работе применил все там известные мне на тот момент 17 паттернов Через несколько лет взглянул на этот код и понял что это просто какой-то адище код пришлось выкинуть Вот точно таким же образом мы пошли в проектирование и применили самые лучшие паттерны микросервисов которые нам были известны Почему именно микросервисы почему не сап для нас плюсы микросервисов были следующие что мы масштабируем только те кусочки алгоритмы ценообразования которые хотим то есть сам алгоритм он состоит там из нескольких шагов порядка пяти шагов и эти шаги неравномерно распределены по времени по ресурсам то есть в какой-то момент нам нужно больше ресурсов на загрузку данных в какой-то момент на расчет и путем микросервисов мы можем балансировать эти шаги таким образом Как нам нужно второй плюс что при падении отдельных сервисов вся система остается на плаву и продолжает работать то есть допустим если не дай Бог упадет Саб то упадет полностью весь механизм если упадет один из наших микросервисов мы сможем либо заменить его следующим инстансом либо пользователь даже ничего не заметит потому что остальные инстанции подхватят его задачу и работа продолжится и последний плюс на наш взгляд это что мы можем накатывать обновления не останавливая систему и заменяя там какие-то кусочки нашего алгоритма прям на лету То есть если обновление Саб это всегда какой-то даунтайм от нескольких часов до десятков часов то обновление микросервис на архитектуры Всегда проходит бесшовное и безболезненно как правило как мы правильно спроектировали систему Это был набор сервисов каждый со своей базой и в этом наверное была основная проблема на старте что когда мы запустили это архитектурное решение Выяснилось что тот сервис который у нас загружает данные в так называемую систему словарей то есть мы хотели загрузить данные в сервис словарей и потом чтобы все наши сервисы считали работали с этим сервисом словарей то есть только загрузка данных в сервис словарей и получения оттуда занимало порядка 72 процентов полезные нагрузки на нагрузку именно рабочую алгоритмы оставалось только 25 процентов После этого мы поняли что в архитектуре что-то надо менять И вернулись к той архитектуре которая работает и которая максимально нам позволила уложиться в нашей силой То есть это был один большой можно сказать монолитный микросервис с единой БД в этом случае все заработало хорошо то есть мы через один сервис заливали данные в базу данных второй сервис их считал третий проверял четвертый всем этим управлял и так далее архитектуру получилось примерно следующее это наверное не совсем актуальный снимок сейчас у нас порядка 8 сервисов которые в процессе Мы наращивали каждый занимается своей задачей и практически все они представляют из себя стейтс так называемую трубу единую через которую данные проходят и получается на вход следующему сервису когда мы спроектировали решение на единый БД Выяснилось что постгаль Который изначально планировалось для этой задачи она не справляется с нагрузкой то есть только загрузка данных в нашу базу происходило в течение 12 часов а так как у нас и селе на весь расчет цен в районе 5-6 часов максимум Это был неприемлемо мы попытались поднять количество потоков на постгре там пробовали грузить данные в 100 потоков 1000 потоков Но во первых масштабирование постгаре на таком многоточную систему достаточно сложно то есть это приходится делать за счет наращивания кластерных голов и потом мы сталкиваемся с тем что все эти потоки между собой конкурируют возникают взаимные блокировки и вся система просто встает в какой-то момент мы начали судорожно искать решение которое бы нам позволило работать с этими данными быстрее и уложить загрузку в 3 часа как минимум пошли к экспертам по базам они предложили нам какую-то новой школь БД Ну и так как ragies был под рукой предложили сделать это в radise мы немножечко переписали систему хранения так как раньше это у нас была революционка Radisson документарный замерили производительность в принципе нас это почти устроило то есть при этом определенных настройках получалось загрузить данные за три часа но тут возникла другая проблема так как это база документарная у нас отвалился функционал индексов который был реляционке и строить индексы нам приходилось либо в дополнительное время после загрузки либо уже на ходу во время работы алгоритма на построение индексов еще уходило примерно 2 часа но и в итоге мы пришли к тому что Загрузка у нас занимает всего 6 часов что нас не устраивало у нас была задача уложиться в три следом мы еще более судорожно пошли к экспертам и сказали что ребят Нас не устраивают эти характеристики Давайте что-то еще может быть придумаем на этом этапе мы уже поняли что база записью на диск нам точно не устраивает Потому что когда мы грузили в radis первоначально там были цифры в районе 10 часов когда мы его отключили от диска оставили только в Memory вот цифры сократились там до двух-трех поэтому мы сразу пошли в историю попробовали in Memory mysql с ним возникли проблемы из-за того что у нас данные немножко не нормализованные есть дубли есть какие-то данные с ошибками небольшими в принципе для алгоритма это ок Но для msql оказалось что это не подходит и из-за построения индексов уникальных ключей загрузка в mysql в msql занимала порядка суток у нас заняла загрузка данные даже все не успели загрузиться мы это срубили и пришли к Клик хаусу кликхаус нас полностью удовлетворил данные туда загрузились за 2 часа плюс он давал нам из школьный движок который нам очень помог наших задачах дальше мы взяли это решение которое уже более-менее было спроектирована и даже в каком-то виде сделано и рассмотрели те моменты которые могут привести к отказу к потере данных и в итоге к потере денег потому что Саб хоть он и Монолит но перед ним постоянно сидят люди мониторят Если вдруг какая-то нагрузка идет аномальная или сильно насад они могут какие-то процессы отключить добавить ему потоков добавить ресурсов в общем вот этот процесс ценообразования ни в коем случае не останавливается Но это все на ручном управлении и занимает много там человеческих ресурсов и дорого а сам процесс это бизнес критиков То есть если он остановится потери там будут достаточно серьезные поэтому у нас была задача сделать этот сервис максимально отказоустойчивым и задача со звездочкой сделать это так чтобы вся отказоустойчивость достигалась в автоматическом режиме не привлекая там какую-то человеческую силу возможные точки отказа Мы приняли следующее Это был отказ оборудования инфраструктуры системного по и прикладного пола на этих четырех уровнях мы посмотрели что у нас может пойти не так детализировали каждый уровень для оборудования это возможны были сбои там сетевых каких-то сетевых картам сетевая карта сгорела сгорел хаб там не знаю бульдозер повредил какой-то Магистральный кабель от дата-центра в дата-центре исчезло питание каким-то образом а генератор сгорел там ну такие вещи для инфраструктуры это различные сетевые настройки прошивки железа которые могут меняться и после изменения класть сервис А также взаимодействие между системами для системного по это ну как обычно cubernetis операционки драйвера с губернатором у нас была интересная штука на тестовом кластере дивопсы ночью в окошко Там в технологическое с чашей по-моему до трех накатывали какое-то изменение какой-то следующую версию и когда мы пришли с утра весь тестовый кластер лежал причем не только наш но и некоторых смежных систем оказалось что обновление встало и мониторинге показывает что кластер живой на самом деле кластер не работал и вот из-за таких вещей Мы решили на поверните тоже перестраховаться предпоследний уровень это прикладное по это или последний ошибки алгоритма утечки памяти которые мы постоянно ловили там на старте и различные прикладные библиотеки чтобы полностью устранить любые ошибки которые зависели От нас от того как мы реализовали алгоритм мы вынуждены были покрыть наш код стопроцентными тестами но мы делали это не в общепринятом виде как обычно делают там Юнит тесты интеграционные у нас это было примерно так на 5 5 участках алгоритма расчета мы составляли таблицы в которых хранились наши цены также такие же таблицы составлял штаб на своей стороне мы принимали его таблицы и сравнивали их если таблицы были одинаковые значит цены мы посчитали как надо если были какие-то различия мы их разбирали и вносили изменения в наш алгоритм на старте это было еще более-менее когда мы пилотировались с маленькими кусочками данных но потом когда данных стало примерно на выходе у нас было где-то 200-300 миллионов строк который надо было сравнить это было уже очень неудобно громоздко То есть это были там десятки Excel табличек мы начали улучшили алгоритм таким образом именно алгоритм сравнения вынесли его в отдельный сервис и сделали так чтобы он нам формировал какие-то Сводные таблички в которых были проценты расхождения по каждому полю по целиком по каким-то шагам и все это в прогрессе отдать дате Вот примерно такую табличку итогу Мы каждый день на делике обсуждали и смотрели что у нас Прогресс по проекту идет результат улучшаются также у нас был на время расчета загрузки и были опасения что если вдруг в какой-то момент у нас же in Memory clic House и вся работа построена на нем в какой-то момент кликхаус может мигнуть или вообще упасть и Мы потеряем те данные которые Считали и нам придется считать сначала и мы уже в нашей своей не уложимся поэтому там придумали такое интересный механизм как точки сохранения это аналог сохранений в видеоигре когда мы на каком-то этапе сохраняемся и продолжаем с него же вот таких точек мы расставили по алгоритму порядка 20 штук рассчитывая на то что каждая примерно две минуты у нас сохраняется результат расчета соответственно если там даже все сервисы грохнуться в какой-то момент то сервисы в другом дата-центре смогут подхватить задачу и досчитать с того момента как закончил предыдущий алгоритм расчета вторым куском там челленджем была загрузка данных и Саб так как у нас грузилась 6 миллиардов записей они должны были загрузить за три часа грузили мы пачками по в сто потоков пачками по 300 тысяч примерно записей и даже кратковременная там какой-то мигание сети или какой-то инфраструктуры при потере вот пары таких пачек по 300 тысяч записей алгоритм уже могут давать сбой поэтому Нам нужен был какой-то механизм Чтобы на время вот кратковременного мигания вот эти сбойные пачки куда-то положить чтобы потом их сохранить обратно для этого мы посовещавшись командой сделали такую хитрую штуку она очень простая но по-моему гениальная обертку на gdc драйвером который позволял нам писать в несколько баз одновременно и читать из одной и вот на этом врапере на этой обертке мы сделали механизм который при любой ошибке записи в какой-то из баз те пачки которые пытались записаться в эту сборную базу писал в другую базу но в отдельную схему по окончании заливки вот эти все так сказать мы их называли все эти пачечки собирались и заливались ту базу которая была сбойная на момент но жила так как у нас опять же были жесткие Sli на расчет а гарантии того что дата-центр всегда будет онлайн стопроцентной дать нельзя мы Разместили наши Полностью мы это называли цепочки расчета то есть свои изолированные цепочки в разных дата-центрах то есть при падении или каких-то проблемах в одном дата-центре второй дата-центр продолжал работу но тут возникла проблема что цены для магазинов допустим в Иркутске должны быть посчитаны в самой первую очередь за счет сдвига часовых поясов Поэтому вот эти все пачки данных по расчету они Строго приоритизированы по часовым поясам соответственно если мы пачку которая считается для Иркутска считаем на одном дата-центре А он умирает нам надо обязательно ее досчитать на втором за какой-то определенный промежуток времени поэтому из этого родилась идея распределенного регистратора который как бы размазан по дата-центром и он управляет всеми цепочками во всех дата-центрах То есть это такая своеобразная модель где у нас паблишер это вот этот оркестратор А сам скрайберы это цепочки сервисов в каждом дата-центре То есть когда они поднимаются они регистрируются в этом оркестраторе и он их использует как компьютерноды для расчета алгоритма правда такие я уже сказал на предыдущем слайде дальше так как у нас вот это вот такие работала и данные грузились в много потоков много инстансов возникало вероятность того что какие-то данные запишутся либо несколько раз какие-то могут вообще пропасть поэтому Нам нужен был механизм как бы итоговой сверки загруженных данных и Саб Чтобы понимать правильно ли мы загрузили или у нас что-то пошло не так и надо там либо перегрузить либо догрузить данные аналог некой контрольной суммы данных на которых мы делаем расчет цен это мы сделали очень простым механизмом Саб После загрузки всех данных отправлял нам список табличек которые он отправил всего табличек было порядка там 180 штук отправлял список этих табличек и для каждой количества записей которые в этой табличке он прислал мы на своей стране по метаданным базы сравнивали количество и понимали что там по 175 табличкам данные пришли в полном объеме по 5 что-то не пришло либо пришло больше такое тоже бывало и для каждого из этих случаев принималось какое-то решение там либо таблицу перегрузить полностью либо догрузить какие-то пачки которых не было до этого после того как мы запустили пилот и какое-то время работали появилась необходимость в исторических данных они нужны были во-первых для отработки инцидентов то есть в магазин отправили цены из магазина позвонили и сказали что там пару дней назад вы нам прислали цену почему такая цена там почему она такая большая такая маленькая мы не понимаем так как модель нашего расчета была основана о том что мы загружаем данные из Саб считаем а потом базу полностью стираем То есть каждый день У нас расчет начинается с чистого листа нам надо было где-то хранить данные о том как мы Считали и вообще историчность но так как данных много там порядка 6-6 миллиардов записей хранить их каждый раз в памяти это очень накладно и опасно Так как если сервер мигнет данные потеряются поэтому мы в отдельный сервис который мы назвали сервис архивации вынесли такие Механизмы как полное копирование схемы из in Memory в таблицы на диске и другие механизмы которые позволяли скопировать только те данные которые мы посчитали это там порядка 20-30 таблиц вот какие выводы мы сделали по результатам этого проекта первое это обязательно надо точно оценивать объем данных на старте проекта потому что мы оценили объем данных в 3 миллиарда у нас получилось 6 миллиардов и из-за этого поменялись и технологии поехали сроки и систему пришлось переписывать на старте раза три То есть те слои и сервисы которые работали с данными нужно было там вплоть до того что переписать полностью какие-то выкинуть только из-за того что неверно был оценен объем данных на старте второе обязательно Следуйте принципу failfest это тоже к и к объему данных и к нагрузочным тестам То есть если бы мы на старте сделали бы сразу нагрузочные тесты которые нам позвонили позволили бы оценить За сколько мы загрузим эти 6 миллиардов мы бы долго и тяжело не выбирали бы базы данных а могли бы выбрать их за пару дней когда мы оценивали последние базы выбор между Microsoft SQL и Click House у нас уже на это ушло два дня То есть переписывание дата лейера и оценка За сколько данные могут быть загружены занимала всего два дня на старте это у нас занимало по-моему три недели И последнее это наверное не стоит слепо следовать принципам и паттерном до того как вы получите рабочую систему которую 2 лет всем и слои То есть можно сделать систему которая будет идеальная красивая в лучших традициях но она вместо трех часов будет работать 23 часа такая система никому не нужна ее лучше выбрать А можно на старте получить какой-то рабочее решение Пусть оно будет на костылях Пусть оно будет внутри некрасивое но оно будет считать хорошо и считать в заданный срок потом это решение можно уже и перепроектировать и улучшить это наиболее оптимальный вариант Ну и какие решения интересные мы вынесли из этого проекта Первое это вот этот вот простенький jdbc wrapper это если говорить об объемах кода там порядка трех или четырех классов который дал нам кучу всяких преимуществ и интересных возможностей от delateq и заканчивая отрас параллеливания загрузки и всякие такие вещей второе это точки сохранения Когда у нас есть вероятность что система может упасть в какой-то момент и не выполнить slay мы сохраняем промежуточные результаты и считаем с того момента как закончили последний раз третий момент это распределенный оркестратор который управляет многими рабочими нодами в разных кластерах и которые единственные знают о том какой набор сервисов Где находится и из-за этого сервиса становится проще потому что они выполняют только одну свою конкретную задачу А сам оркестратор не выполняет какой-то там сильной нагрузки он просто дирижирует и из-за этого он простой легенький и не требует много ресурсов И последнее это сверка и тестирование то есть вот те там Excel таблички которые начинались С простых а в конце концов усложнялись тоже достаточно простое решение но сэкономившее нам кучу времени и позволившее даже можно сказать позволившая в будущем рефакторить систему без страха что-то поломать Спасибо большое что вы слушали Прошу вас оценить доклад по qr-коду теперь ваши вопросы так вот сейчас девушка Привет Меня зовут Дмитрий не Крылов Можно пожалуйста последний слайд три вопроса как нему Первое это точки сохранения Какой объем точки сохранения сколько она после сохранения занимает и насколько она замораживает кластер когда сохраняется так хороший вопрос точки сохранения у них разный объем то есть на старте алгоритма у нас где-то несколько наверное сотен тысяч записей то есть объем точки сохранения на старте Это несколько сотен тысяч объем данных точки сохранения в конце алгоритма это уже несколько сотен миллионов записей сохранение занимает но так как база in Memory там сохранение протекает Ну там меньше секунд Но вот из того что мы мерили на самом последнем этапе вот эта точка на несколько миллионов она может занимать до минуты в гигабайтах мы не считали То есть у нас так как опять же база в памяти и мы смотрим просто на графике что мы не уперлись в память там по моему Вот сейчас при работе все алгоритмы мы не вылезаем за границу там 512 ГБ памяти Ну а всего у нас там 700 то есть запас есть Поэтому пока за этим не следим Спасибо Давайте следующий вопрос пожалуйста передадим спасибо да спасибо за доклад меня или зовут у меня такой вопрос ведь ценообразования Но процесс динамический Да и настройки этого ценообразования тоже меняются как вывод сам алгоритм меняете когда приходят там категорийный менеджеры или еще кто-то все меняем Да вот то что я рассказывал это уже алгоритм который работает после категорийных менеджеров То есть у нас есть отдельные там целые отделы категориных менеджеров для всех сетей после их работы то есть они рассчитывают какие-то свои цены потом их результаты сливаются в Саб сейчас потом мы из забираем эти результаты вот на них уже накладываются какие-то правила которые тоже в сад ведутся и мы вот в зависимости от этих правил все это преобразуем и отправляем уже в магазины То есть у вас какой-то код есть который Нет не кот Ген Там скорее там достаточно Все просто это просто операция со множествами применение каких-то параметров фильтрация Ну то есть просто очень сложный но конечный автомат спасибо спасибо Вот у нас глубине зала вопрос Здравствуйте Меня зовут Никита Спасибо за доклад У меня два маленьких вопросика первый про враппер Почему вы не использовали очередь между базой данных и собственно второй базой данных которую данные грузите например rabbiting там тоже есть Лидер Челлендж и второй вопросик Про Сервис архивации вы не думали над тем чтобы например просто писать по tcp логи распределения Ой какие интересные вопросы так на первый ответ очереди не использовали потому что у нас сначала была мысль использовать кафку но мы столкнулись с тем что вот любые решения но так как она все-таки насколько наши эксперты сказали по кафке она не может работать чисто in Memory Она всегда что-то пишет на диск А вот из-за наших как раз slf в любой момент когда мы сталкиваемся с записью на диск вот этих вот больших данных у нас сразу производительность проседает и алгоритм выбивается из времени и плюс работа с очередями все-таки мы до сих пор Боимся что вот любые накладные расходы на там Цивилизацию дисреализацию там получение паре что мы стараемся как можно меньше данных гонять по росту и там обратно по очередям и так далее Вот только из-за этого так а второй вопрос был про а Про Сервис архивации чтобы писать там Ну как-то редулогами да репликации какой-то это тоже то есть там очень узкое место как раз вот это когда загрузка из Саб идет этих 6 миллиардов буквально вот любое даже Мы пытались какой-то логирование более подробное для целей производительности прикрутить к этому То есть как только мы в этот механизм вот получения этого громадного количества пачек что-то включаем оно тормозится там ну до полутора раз Вот и мы Ну как бы на этапе тестирования мы еще эти возможности включаем учитывая что у нас там ну на тестировании мы можем больше сделать Ну больше время занять но напротив всегда отключаем потому что любое вмешательство в эту загрузку приводит к деградации производительности не выходит Спасибо Следующий вопрос Здравствуйте Алексей такой вопрос поскольку мы все говорим высокой нагрузке очень часто в проектах встречается первый пункт предыдущего слайда недооценка требований почему бы собственно говоря не принимает сразу ну грубо говоря сразу X2 по требованиям то есть мы знаем что менеджмент считает что там какое-то количество записей но мы поскольку разрабатываем системы сразу закладываем ну допустим X какой-то коэффициент для работы причем в условиях ограничения оборудования еще мы Тестируем нагрузочное тестирование Когда уже упираемся по объему в хард и всё в таком духе то есть Почему здесь сразу не заложить риски и риски роста продукты то есть количество записей со временем как бы увеличивается при этом мы всё равно укладываем либо ошибки бизнес-требований Спасибо да да Ну вот кстати это хорошее решение что закладывать сразу X2 Просто у нас на старте прямо было уже некое рабочее рабочий прототипчик где вот эти все данные были уже посчитаны другое дело что почему их объем увеличился потому что по мере разбора этого алгоритма он был там очень старый в сапии развесистый появляется какие-то новые таблицы новые данные и то есть вот мы думали что этот объем данных на старте Он точно будет таким же но при распутывании алгоритма Выяснилось что он там увеличился в два раза поэтому мы конечно могли умножить на два но там путём какой-то экстраполяции то есть мы изначально приняли что у нас объём данных там в год будет прирастать где-то на 30 процентов и вот эти риски мы заложили на то что у нас объём данных увеличится в два раза такого не ожидал никто спасибо спасибо И наверное вот здесь вот будет от меня вопрос я вот здесь рядом по начальным требованиям сначала было сказано что у нас есть три миллиарда записей потом они внезапно превратились в 6 миллиардов записей и я вот лично я наверное коллеги которые слушают тоже не до конца поняли А как так получилось где вот этот вот ошибка планировании была ну вот только что объяснил расскажу еще раз То есть алгоритм Саб он был там исторически на протяжении нескольких лет может быть даже десятка лет разрабатывался эволюционно и как он работает до конца не знал никто поэтому те Ребята в сапе которые разбирали это алгоритмы и передавали нам на разработку они пошли по какой-то самой коротенькой дорожке я предполагая что возможно мы захватим еще какие-то куски какие-то ветки этого алгоритма но не факт вот проход по этой короткой дорожке выявил там порядка 80 таблиц объем которых был понятен но когда мы начали уже считать сверять и увидеть Что у нас по ценам идут расхождения консультантный цап залезали в свой алгоритм говорили А ну вот наверное вот здесь ещё зацепилась вот эта ветка а если это ветка зацепилась там появилась ещё три таблицы и вот это вот прохождение по разным веточкам дало вместо 80 порядка 180 таблиц так бывает спасибо если у нас еще вопросы Ну что ж я не вижу если вы все-таки решитесь продолжить задавать вопросы спикеру можете ловить его либо в дискуссионной зоне либо дальше на конференции Давайте же поблагодарим его за этот прекрасный Спасибо Спасибо тебе за рассказ У нас для тебя весь Презент Спасибо вам что были с нами и слушали Такие интересные доклады пока что мы уходим на перерыв А после этого можно будет возвращаться Да а у нас есть подарок за лучший вопрос Тогда нужно выбрать лучший вопрос вот молодому человеку около колоночки поднимите руку чтобы вас нашли тогда еще раз спасибо вам за ваше внимание за ваши вопросы спикеру за его доклад и мы скоро увидимся на следующем Всем спасибо"
}