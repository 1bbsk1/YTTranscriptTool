{
  "video_id": "hs8K7tHP86Y",
  "channel": "HighLoadChannel",
  "title": "Статистические методы и инструменты анализа производительности систем / Алексей Лавренюк (Яндекс)",
  "views": 251,
  "duration": 2181,
  "published": "2017-04-22T14:47:44-07:00",
  "text": "всем привет меня зовут алексей я работаю в компании яндекс и сегодня мы поговорим о том как мы анализировали данные производительности одной из наших систем эта система представляет собой такой обработчик событий она получает на вход пачку событий которые происходят в интернете там пользователь кликнул куда-то по рекламе мышку подвинул и ищет среди них интересные для нас то есть пачка приходят не размеченных событий на выходе пачка размеченных событий эти пачки поступают раз пять минут и у них разный размер там может быть разное количество событий в зависимости от того сколько событий за эти пять минут произошло ночью их естественно меньше где-то 1 миллион дням их больше 5 миллионов например и нам очень важно чтобы мы успели обработать эти все события до тех пор пока не пришла следующая пачка этих событий что мы хотим знать о нашей системе во-первых мы хотим знать насколько ее еще хватит запас производительности если у нас будут увеличиваться размеры наших логов когда произойдет перекрытие вот это вот когда нам не будет хватать времени на обработку во вторых нам нужно уметь сравнивать разные релизы и разные стенды например есть у нас продакшн и есть у нас предстоит нам нужно знать они вообще соответствуют друг другу по производительности чтобы мы могли ориентироваться на престол был или нет или что-то нужно менять или два релиза хотим сравнить на одном стенде запустили посмотрели как работает запустили еще один тест по работала система посмотрели сравнили и еще мы хотим следить за тем как производительность нашей системы меняется от релиза к релизу и как она развивается во времени в зависимости от входных данных число пользователей растет соответственно растут наши логе событий и нам нужно вовремя заметить когда нам нужно добавлять машинки и сколько их нужно добавлять или может быть вообще уже пора всю переписывать потому что нас узкие места проявляются и мы не сможем больше увеличивать производительность просто добавлением машинок то есть нам нужен такой набор градусников для того чтобы можно было поверить в разных местах температуру наша система вообще в яндексе есть процесс нагрузочного тестирования поставлен очень хорошо на поток практически приходит сервис там стандартизированные практически действия выполняются обстреливается сервис выясняется узкие места все хорошо мы используем для этого инструмент наши индекс танк то не слышала индекс танки отлично многие слышали уже раньше меньше народу руки понимала тесты вообще происходит следующим образом мы собираем мы готовим тестовый стенд который состоит собственное станка и мишени по которым мы будем стрелять потом готовим запросы то есть патроны набор запросов которые мы будем расстреливать сервис и потом начинаем генерировать нагрузку которая у нас начинает возрастать постепенно и смотря в каком месте у нас случится затык и систем например вот на этом графике видно что на какой то нагрузки у нас времена отклика от системы резко выползли вверх и у нас есть дженкинс который филина этот танк у нас много много тестов автоматизированного около половины уже разработчики при выходе нового релиза могут сами прийти тыкнуть кнопочки у них все про тестируется или вообще уже по выкладке на машинку пакетика осмотически запускается тесты но в нашем случае с нашей системы это не прокатило во первых у нас приходят большие пачки событий и мы не можем просто так стрелять этими бочками событий по миллиону событий и заверять времена отклика а во вторых нам вообще нельзя туда синтетическую нагрузку посылать потому что для нашей системы для этой важно история если мы пошлем туда два одинаковых logo в первом blogger событие интересные посчитается о втором уже нет во втором уже нет потому что они уже были и уже не интересны мы можем только взять входную нагрузку которая вот у нас сезон на это вот недельный график видно что ночью нагрузка меньше дня он больше это надо колеблется и естественно от недели к неделе тоже меняется мы можем взять вот эту нагрузку умножить ее на какой-то коэффициент и посмотреть как наша система под этой нагрузкой работает вопрос как в таком случае вообще можно сравнить два периода работы системы когда у нас входная нагрузка вообще разная себя внутри наша система выглядит примерно вот так у нас есть три мастер машинки которые на которые приходят и диалоги и машинки ставят задания на слои вы разные слои вы там крутится крутится крутится и выкуп в итоге выходит размеченный лак каждое задание это такой фильтр который пропускает через себя ток и извлекает из него какую-то полезную информацию размечает флаги ставят и сохраняет историю еще у нас фильтр друг от друга зависит то есть может быть что одному фильтру нужна история другого фильтра поэтому логу то есть ему придется ждать или от двух фильтров и они выполняются на разных машинках заранее не ясно на каких вот такая у нас там архитектура первое что мы решили сделать но естественно сначала мы нарисовали эту архитектурную схему узнали как у нас система работает чтобы говорить на одном языке с разработчиками с админами потом мы решили всё обвешать приборами метрики которые мы собираем бывают двух типов первый тип это бизнес метрики за бизнес метриками нужно идти к разработчикам они вам скажут либо где их собрать можно какие метрики вообще важно собирать и могут даже сами написать средства для сбора этих метрик бизнес метрикам у нас относятся число событий в логе входном время обработки каждого logo время работы каждого фильтра над этим логом время отставания нашей машинки ну то есть на сколько старыми выходят размеченные логе и размера очереди сколько логов накопилось и конечно всем известны второй тип системные метрики процессор память диск сесть и так далее за этими метриками кабмин им нужны и те не все знают о том как работает система на машинках непосредственно можно вместе с ними обсудить какие метрики собирать чем собирать вот мы начали собирать эти много метрик и что на них можно увидеть во первых можно увидеть резкие скачки когда вы включаете какой-то эксперимент например у нас было такое что мы выключили ненужный старый фильтр и увидели сразу что процессор освободился резко вот это на левом графике видны второе это следить вы можете за бизнес метриками в данном случае на правом графике видно размер очереди и видно что она растет растет растет растет растет потом в какой-то момент начинают рассасываться и что самое важное рассасывается она быстрее чем росла это на самом деле был эксперимент когда мы остановили тестовый стенд на некоторое время на разные промежутки времени и смотрели как у нас очередь будет разгребаться в данном случае это такой хороший пример что она все разгребать все хорошо окей теперь когда мы можем смотреть на много метрик нам бы хотелось еще вообще начать копать вглубь разбираться как работает наша система у нас очень много графиков появилась для каждой машинки это около 50 метрик машинок как я уже сказал очень много естественно смотреть сразу на все графики невозможно объять умом эту картину можно да если у вас произошел факап то вы можете увидеть почему произошел почему сейчас происходит посмотреть там где-то мы в процессор уткнулись где-то там каша в памяти не хватило начала писать на визг но им можно в прошлом посмотреть если что-то было не так но аномалии и первые признаки этого пока по вы на графиках не заметить и потому что они начинаются очень мелкое сравнить два периода тоже сложно потому что вы поставить рядом два графика процессора и on входная нагрузка была разная и что из-за этого теперь можно но они оба волнисты только это можно вынести мы стали смотреть на то вообще какие у нас бывают виды этих метрик мы разделили их на входные на зависимые метрики и независимые метрики независимые метрики это те метрики которые характеризуют входящую нагрузку размер логов что в них вообще ну качеству качественный состав логов это независимые метрики от них зависит уже утилизация процессора памяти время обработки каждого logo то есть у нас получается такая функция многих переменных которую неплохо бы исследовать для того чтобы исследовать нам нужно уменьшить число измерений за которым мы наблюдаем мы стали пробовать разные методы вот в этой книжке которые я конце расскажу можно посмотреть какие методы есть для поиска корреляций но по большому счету у нас сработала интуиция наша и метод проб и ошибок мы подумали принципе что нам важно из выходных метрик нам важна только время обработки logo насколько там процесса при этом был загружен неважно главное что блок обработался во время мы стали искать от чего зависит время уродки logo вот мы стали строить так называемый scatter plot это графики на которых каждая точка соответствует а по горизонтальной оси у вас одна метрика по вертикальной а другая каждая точка это наблюдение другой системе соответственно по вертикальной оси у нас всегда важно для нас время обработки а по горизонтальной оси мы разные пробовали вот в одной системе мы попробовали по горизонтальной оси ну сравнить размер logo и время его обработки на левом графике вы видите что они там не очень-то и коррелируют то есть они как бы принципе наверное линейный но все равно большой разброс это значит что у нас размер входного logo не полностью определяет время обработки нас от чего-то еще она зависит а вот для нашей системы нам повезло и мы увидели что время обработки практически полностью зависит от размера входного logo то есть даже не важно какие там события разные были может быть они там по разному обрабатываются разное время занимают но логика столько большие и события в них настолько разнородные что все усреднил оси получилась такая аккуратненькая линия что еще мы какие еще выводы мы можем сделать из этого графика во-первых мы видим что когда логе становятся большими время обработки растет нелинейно мы исследовали почему и узнали что у нас эффект проявляется потому что у нас перестают влезать наши блоги в память и начинают котироваться на диск операции мы искали второе мы увидели что с уменьшением размера logo время его обработки до нуля не падает то есть если мы даже запустим пустые логе в систему все равно они будут там вертеться где то секунд 20 если мы захотим с 5 минутного интервала например перейти на минутные интервалы для того чтобы уменьшить время отклика системы мы столкнемся с проблемой потому что мы не будем успевать за минуту обрабатывать наши логе меньшего хоть и меньшего размера и третье наблюдение это то что у нас присутствуют выбросы некоторые логе обрабатывались они точки получились вдали от общего тренда интересно посмотреть что там происходило еще одна классная вещь которую мы получили построив эти scatter plot мы можем на одном графике отобразить две группы точек разными цветами например на этом графике у нас отражены приз temple pilots тент нагрузочный и мы видим что на нагрузочном стенде все точки смещены вверх то есть все логе хотя они приезжают во абсолютно одинаковые они обрабатываются за большее время это мы проводили эксперимент мы сравнивали производительность как раз 2 релизов и увидели что новый релиз быстрее что мы еще хотим теперь мы хотим чтобы мы не только смотрели на статичные картинки но еще могли какую-то информацию узнать интерактивно про взаимодействовать с этими графиками во-первых мы если внимательно присмотреться можно заметить что некоторые точки на этих графиках они более прозрачные это временное измерение . который устаревает отображается более прозрачным цветом то есть яркие точки это то что вот прямо сейчас происходит в системе если яркие точки появляются долей от основного тренда мы сразу видим что система что-то не там надо копать еще можно узнать какая точка для калуга навести мышку дам всплывет айтишник logo можно смотреть уже в системе что с этим блогом происходило такие интерактивные инструменты они не только ускоряют работу вашего они у качество меняют вообще процесс и выводы которые вы можете сделать потому что если вы можете только потратить там полчаса раскопать какое-то был мог например или что там происходило это одно а если вы можете навести мышку и увидеть разу то это совсем другое вас просто процесс меняется и так мы научились делать сравнительные тесты и теперь хотим по исследовать наши конкретные точки что там внутри происходит как я уже говорил у нас системе множество фильтров которые зависят друг от друга и мы решили построить визуализировать этот граф зависимостей во-первых а во-вторых его взвесить на реальных данных то есть посмотреть в этом графике что сколько времени занимало занимала для каждого logo и построить критический путь критический путь это самый длинный путь в этом графе от начала до конца обработки logo то есть если вы оптимизируете фильтры не лежащие на критическом пути например то у вас время обработки logo не уменьшается потому что есть фильтры которые всех задерживают если вы оптимизируете фильтры лежащие на критическом пути у вас время обработки уменьшается пока вы встретите на пути следующий физический путь вот мы стали собирать информацию об этом стали смотреть какие у нас когда критически и пути бывают и стали отображать на нашем графике для каждой точки критический путь то есть по наведению мышки на точку теперь можно увидеть клинический путь который выглядит примерно вот так большие синие полоски это время сколько занимала непосредственно обработка данных фильтром название подписаны а тоненькая серега полосочка это сколько фильтр ждал зависимости или вообще там ждал пока логе приедут в общем ничего не делал понятно что если какое-то время нам здесь не нравился мы будем пытаться его оптимизировать разбираться почему так происходит то есть может быть там какая-то ситуация если это outlier дабл мы посмотрели может быть там какая-то ситуация сложилась нестандартная и у нас критически размер критического пути вырос а может быть у нас так всегда и если мы оптимизируем то будет вообще большой прирост производительности еще и интересно то что критические пути зависит от входных данных например у нас фильтры могут иметь разную сложность один линейно зависит от размера входных данных другой экспоненциально и у нас тот фильтр который линейно зависит может на маленьких логах работать дольше экспоненциального она больших соответственно наоборот и мы увидим что в какой-то точке у нас критический путь изменяется и так вы научились копать вглубь теперь мы хотим автоматизировать процесс слежения за противо деятельностью и смотреть как у нас измеряется произойдите 3 лизок лизу и от входных данных поскольку мы видим линейную зависимость на наших графиках ну круто было бы применить линейную регрессию и смотреть за коэффициентами получившийся прямой мы попробовали взять просто место наименьших квадратов и применить его к нашим точкам и заметили что у нас очень сильно влияет на результат шум то есть если там появилось два trial player но далеко отстоящих то 100 нового тренда мы сразу видим колебания в этих коэффициентов мы и мы стали искать способ как отбросить взял player и остановились на методах кластеризации мы использовали dbsk этот метод базируется на взаимном расположении точек он объединяет в кластеры точки которые близко другую расположены и мы можем взять кластер с наибольшим количеством точек и строить тренд уже по нему а все остальное считать шумом кроме того мы можем взять другие кластеры которые мы нашли и смотреть что там происходило потому что это скорее всего какая-то какое-то отклонение в работе системы например вот здесь вот слева можно видеть кластер маленьких логов которые обрабатывались почему-то за большое время и естественно этот теперь позволяет наблюдать за тем как у нас развиваются во время ну деградирует наша производительность системы в целом или нет итак теперь все в целом сначала мы рисуем архитектурную схему вместе с разработчиками с админами чтобы договориться о терминологии чтобы каждый понимал что где находятся какие потоки данных существуют системе чтобы уже на этом этапе представить какие могут быть узкие места и в общем чтобы все говорили на одном языке потом мы начинаем система обвешивать метриками мы уже знаем где потенциальные узкие места туда будем больше метрик вешать соответственно знаем где важные бизнес метрики тоже будем их вешать завершение этого этапа успешно когда вы можете для любого интересующего вас промежутка времени месяца назад был или год назад был предоставить набор метрик который вас интересует получить данные оттуда то есть графики построить дальше мы начинаем разделять метрики на входные и выходные искать между ними корреляции после того как мы это сделали мы учимся копать вглубь анализировать отдельные наблюдения анализировать outliers и когда мы уже так хорошо знакомы с нашей системой мы это дело автоматизируем разрабатываем киты инструменты автоматизируем наблюдение делаем мониторинге когда все прошло плохо теперь о том какие инструменты мы использовали в нашей работе и вы можете их использовать потому что они все open source на лежат в открытом доступе ну не нами написаны пока метрики мы собираем с помощью инструмента даймонд на самом деле не только с помощью него есть еще всякие там коллег д разные самописные скрипты даймонд это система для сбора метрик написаны на питоне там очень много модулей и он имеет отсылать данные в графит а графит это распределенное хранилище временных рядов то есть вы можете загрузить туда все ваши данные потом по запросу получить за какой-то промежуток выбранной вами метрики когда вы научились данные храните собирать на вам нужных обрабатывать мы используем для этого сгибаем это питоновский набор библиотек он также широко известен используется и в научных кругах состоит он из нескольких частей я вот три упомянул об этом ноутбук это такой веб-шоу то есть вы можете написать ну зайти в браузер и на сервер написать там кусочек кода азова выполните увидеть там график или какие-то результаты расчетов и pandas этой библиотеки для выполнения вычислений матричных вычислений панда стати похож на matlab и на r кстати тоже похож они написаны на си поэтому производительность это нормально и последняя библиотечка из-за скипа я это за kettler это библиотечки машина обучения мы использовали из него из нее методы регрессии кластеризация наших наблюдений и отдельно библиотечка network x для работы с графами позволило нам строить граф и и находить не критические пути когда мы данные проанализировали нам нужных визуализировать простейшем случае это временные ряды и для временных рядов мы использовали библиотечку качаться the java script олова библиотечка поэтому ну чтобы использовать придется написать приложение в приложение которое сданными будет работать хатчерсон слегка платный есть еще другая библиотека d3.js она более низкоуровневое но может очень многое кроме графиков там можно строить интерактивной визуализации на сайте на их много примеров очень красивые затем вокруг d3.js написано библиотечка рикшу которая предназначена для построения держи графиков мы сейчас потихоньку переезжаем скачал фонарик шоу потому что пришел бесплатный на свободный точнее ну хотя раз по сравнению с рикшу более взрослый такой продукт с ним проще работать и отдельная вещь это уже не библиотечка а программа которая называется еду и и очень удобно использовать для построения как раз архитектурных схемы там билетик редактор графов такой вы можете расставить блоки назвать их расставить между ними соединения а потом 1 кнопочки хотите то психику удобную схему в которой можно будет ориентироваться потому что лет умеет автоматически организовывали граф расставлять блоки там между ними соединения тоже вставлять и еще одна замечательная особенность этой программки вы можете сгенерировав автоматически а потом тоже расставит расцветить и вам не придётся по вашей там допустим схеме зависимости строить это все вручную и единственная книжка который я упоминал это да это нарисую open source туз на самом деле название тут само за себя не говорит потому что книжка на мой взгляд больше про методы анализа данных чем про средства даже про подход к анализу данных там собрано большое количество методов по разным разделам и для каждого указано плюсы минусы для каждого указаны инструменты которыми можно этот метод к вашим данным применить тоже для инструментов плюсы-минусы хорошая книжка я думаю маст рид просто если вы хотите заниматься анализом данных вот спасибо за внимание приходите в twitter задавайте вопросы еще у нас есть коммьюнити вокруг нашего инструмента индекс танк ещё там есть чатик которым прямо в интерактивном режиме можно спрашивать добрый день алексей себя за так вот такой вопрос в какой команде во первых все это делали в яндексе и какой размер сколько людей сколько человеко-часов от общего размера команды было потрачено на графике то есть кто этим занимался были отдельные люди выделены или все по очереди насколько это ресурса емко вот решение данной задачи которые который вы рассказали у нас сейчас используется в нашей команде и небольшой из трех с половиной человек методология скрам но я не в основной команде нагрузочного тестирования сейчас создаю а нашего отдела рекламных технологий отдельная своя команда и у нас там многое мог задачек и это вот задачки по этому проекту одни тоже и снова большого числа ну и по очереди их там дан пилим в основном саму программку для работы с графиками но я и не показывал может быть катаемся выложил point source да я про нее расскажу писал в основном я сам ну пока она не допили на пила на внутри о не нравится на питоне да но да ну там много java скрипта клиентского поэтому там удобнее на на джесс сколько времени заняло в целом ну не знаю даже сложно сказать ну примерно это месяц три год ну и понятно что такого не единственным в таком режиме туда-сюда где-то год наверное около вот очень удобно в этом красной python ноутбуки то что вы можете взять и работу на коленке использовать готовые методы поиграть данными это очень быстро ясную инструмента по поводу стресс на время затрат на сколько профит результат работы профит какой получился то есть для компании ну вы потратили много времени результате что стали выбирать русском или результате мы стали вообще понимать как работает система и чего от нее ожидать потому что раньше это вот как что-то случается начинаем копать что там произошло а тут вот все более прозрачно стала да добрый день вопрос про поиск корреляций я здесь сзади вот вот наш него корреляция каким образом только на графике смотрели scatter plot или какие-то автоматические методы использовали потому что я так понял метрик много комбинаций тоже много смотреть надо много ну во первых я уже сказал нам было важно только время обработки logo то есть у нас уже число выходных метрик уменьшилась до 1 мы посмотрели разные варианты которые как нам казалось самые вероятные ну в тупую от размера logo если пойти ну сделать предположение что размер блога влияет на время в обработке это как бы очевидно и попали здесь точку естественно в других местах в других системах мы ну вот я показывал там второй график где такой разброс большой там мы не попали в точку и там придется поискать мы пока не использовали там других методов автоматических спасибо за доклад очень нравился вопрос единственное что смущает реально от практического применения это все-таки что в данной системе нужен человек как минимум один с глазами зрячий для того чтобы сидеть и смотреть и мониторить эти графики были какие-то попытки все-таки это автоматизировать все таки перевести это на какой-то алгоритмический уровень вообще именно сам мониторинг критических каких-то вещей или же попыток таких не было по мы вот сейчас как раз к этому идем мы хотим автоматизировать релизные тесты то есть нам нужно во-первых понимать как когда у нас начался тест когда он закончился то есть отслеживать выкладку релизов автоматическом режиме во вторых нам надо научиться сравнивать эти релизы такой степени что красный смотреть до глазами говорить этот релиз плохой лет релиз хорошее для этого нам нужно выработать данном месте с алей а чтобы к этому прийти нам нужно сначала вы глазами дальше мы конечно пойдем по пути автоматизации чтобы уменьшить ресурсы на поддержание системы я хотел спросить такую вещь вот вы выбрали вашу выходной метрику в заранее выбрали вы как-то знали что это именно она почему пример нилова ты вираж на машинах или что то еще потому что нам важно время обработки logo такое советник знали ну мы хотим чтобы логе укладывались 5 минутный промежуток причем ну какой то мало ты веришь при этом был на машинке ну неважно главное что укладывается конечно когда начинаешь копать почему там же они уже не укладываются мы уже будем смотреть на разные другие метрики потому что не массажа собираюсь это легко сделать лишь и спасибо за код такой вопрос в упоминали закир вы воспользуетесь вообще почему питона не р который более защита тела . чушь и ну мне лично р как язык не нравится потому что ну для не знаю программистского ума там немножко нестандартный подход и где он не стандартно выглядит я бы тоже использовал и пока решил пойти вот с питоном пока можно тем более питон проще встраивать в разные там автоматические системы если для того чтобы r поставить там хотя бы на машинку там нужно кучу литейщик под сайт питон как бы практически одной команды ставится то с чисто субъективно да . ну больше да кому то нравится r нас тоже есть люди которые используют р естественно и они не тоже спрашивали почему бетон мунир питон привычнее спасибо большое"
}