{
  "video_id": "Xx8ErhM6U9Q",
  "channel": "HighLoadChannel",
  "title": "Apache Ignite теперь с CDC! / Николай Ижиков",
  "views": 1987,
  "duration": 2440,
  "published": "2022-03-21T12:55:00-07:00",
  "text": "и сегодня мы поговорим с вами в докладе про три вещи значит я постараюсь вам рассказать про это что такое чудо паттерн обработки данных для чего нужен какие юз кейсы покрывает при каких условиях как я состоят нас команда я реализовал женщина captcha фичу вы знаете и собственно как с помощью этой фиче я реализовал логическую mesh кластерную репликацию опять же вы починить так начнем здесь мои контакты про меня я кантри бьющего пачек знает уже порядка трех лет является эмиттером пенсии тоже в кафку пишу соответственно кто хочет пишите значит представим ситуацию до то есть обычной ситуации у вас есть какая то база данных интер праздное там лежат данные которые очень нужны бизнес очень нужными пользователям она довольно высок а нагруженным то есть туда постоянно пишут читают там есть какие-то жёсткие солей по чтению по записи по обработке по таймингом и нагружать их дополнительными какими-то вещами не хочется да этом сервис и то же самое вот количество компонентов которые используют эту базу данных дай которые хотят получать из нее данные каким-то образом реагировать на изменения в в данных их довольно много и появляются в течение времени все больше и больше соответственно значит тут встает вопрос либо мы как как как нам как писать компоненты которые собственно реагируют данное изменение данных вот там появилась какая-то запись клиент создался к вот заказ еще что то что то мы хотим сделать значит и когда у нас база нагруженной асинхронную обработку да там куда-то их навешивать на наш микро сервис который вставляется суда этот заказ навешивать какой-то функционал на значит триггер какой-то дозатора не процедуру писать бывает нерационально потому что собственно тратить дополнительное время и значит увеличивает тайминги по ответам и здесь вот нам на на выручку приходит такой паттерн который называется через do to capture соответственно наше приложение оно делать изменения в базе данных и вот классических архитектурах значит практически там все базы данных которые хранят изменения на диске ну то есть не менее memories нервные что они каким-то образом значит для ускорения записи для оптимизации операции пишут журнал журнал изменений в которых последовательно значит базы данных записывает тут дельту которую вы собственно и в нее и вставляете вот и соответственно сидите через это коптер это приложение которое умеет обрабатывать эти логе логе изменений и соответственно выделять из этих налогов изменений события изменений дабы об изменении в данных и уведомлять об этом рудникова приемника да там никого потребителя этих изменений которые уже собственно реализуют бизнес-логику собственно значит что относится к через этот коптер значит в чем его преимущества недостатки да то есть вы получаете значит линейные да там соответственно упорядоченные по времени значит по времени в которых они происходили события изменений данных собственно что было что есть какая операция на какой таблицы там или там кашам произведено в случае пачек на это значит в чем 2 авто 2 как бы особенность в том что это не синхронная обработка то есть это не триггер это не храним процедура это значит через некоторое время у вас уже к данной за камедь или все приложения который вставляет или там изменяет оно пошло дальше работать а вы через некоторое время получаете соответственно опять в другом процессе каком-то другом приложении значит уведомление о том что а вот это изменение произошло вот соответственно вот при и и если такой паттерн обработки данных вам подходит а собственно через это коптер это то что вам нужно значит в какие уже поставщики и да по субд и собственно реализуют или позволяют релизов позволяют использовать эту возможность практически все тут собственно перечислены если вы по ключу папа и поищите там папа гульки по ключевым словам то мы искали сидиси его ракал сидите и так далее соответственно вы найдете нужным нужно библиотеку нужные пей и сможете как раз в любой практически суббота реализовать данный паттерн идем дальше значит вот бизнес-кейсы какие же нас бизнес кейсы есть для соответственно так у такого рода обработки вот это значит если вам нужно про стремитесь к это хранилище либо там значит граничил логов каких-то если да то мы либо хранить значит enterprise на значит какая-то облачная система которая накапливает данные для аналитических запросов там подобное значит соответственно вот как раз вы можете это выгружать потому что обычно там тайминги не требуется в реальном времени доступ реального времени аналитика это поступал требуется просто их накапливать и обычно раньше там писались какие-то процедуры которые там раз в час раз в сутки перегружают эти данные до дельты как-то определяют а тут как бы ты вы уже можете близко к реальному времени соответственно делать значит вот пост обработка событий что она себя представляет когда у вас произошло какое-то событие у вас бизнес процесс построен так что вам нужно инициировать какой-то другой следующий бизнес-процесс соответственно процесс опять же там вот на следующих слайдах приведу конкретные примеры ну понятно расчет онлайн аналитики тоже значит события вы накапливаете в какой-то вас есть аналитическая функция которая работает нас на событиях нас на стриме событий и соответственно значит можете это реализовать с помощью одессе ну и вот логической репликация значит дальше и мы ее рассмотрим по докладу там я все подробно расскажу начну вот это опять же примеры тех вещей которые только на золотом зарегистрированный клиент мы хотим отправить письмо письмо управляется долго бывает всякие разные там где-то у нас там лежит почтовый сервер где то долго учета отправляется еще что то там соответственно мы просто берем и асинхронно его отправляем понятно что там если минута две три пять даже 10 подождет клиент и все нормально вот выгружаем заказы аналитическую систему до значится опять же произошло заказ мы хотим значит в энергетической системе где-то смотри что у нас там столько то там это какой-то оборот идет о компании такие то это самое мы значит можем практически в онлайн-режиме выгружать и соответственно значит это в аналитической системе уже видеть очень быстро значит быстрее нежели если мы будем это по каким-то более длительным тайм-аутом дело до с помощью там каких-то там таймеров которые не привязаны к базе данных вот модерация значит от например там клиента он загружает знает накид рекламный материал и загружает какой то еще контент там такого договора какие то еще что то значит ну и соответственно их надо про модерировать посмотреть что с ними в порядке вот собственный тут мы можем тоже значит снять нагрузку с основной базы данных и переложить ее на сидиси значит тем самым ускорив и значит делать более надежному наше основное приложение понятно месячный бонусы то же самое это онлайн значит аналитика которой мы рассчитываем по стриму изменений окей значит в целом я думаю что даже должен быть понятным сотку сидиси да зачем она нужна и перейдем к тому как она реализована бабочек на учитесь несколько ключевых особенностей да там которые позволяют скажем так сделать надежно позволяют сделать все это дело быстро и независимым начну на что значит я вот когда проектировал то все делать на что вы какие ключевые особенности я хотел достичь apache игнайт это распределенная база данных она обычно применяется значит в тех случаях когда требуется какое-то максимальная скорость когда требуется ускорения приложение она не терпит того чтобы это всю эту обработку означает изменение происходило долго значит это первое второе она требует некоторым любая база данных требует надежности соответственно если ты устраиваешь в основной поток изменений далее в основной функционал база данных какие-то возможности тот и соответственно ну как разработчик баз данных и унесешь определенные риски где-то будет подключить где-то будет тормозить еще что то то есть любая новая фича база данных это как бы некий риск ники возможность напортачить так чтобы потом на кроме упала и тебе было бесконечно стыдно за свои изменения вот соответственно значит вести 10 вот я принял решение что это отдельный должен быть процесс совершенно отдельный отдельный процесс операционной системы который значит сам себе работает и не зови никак не должен практически трогать основной процесс играет эту себя по основной процесс игнайта он работает как и работал там практически никаких изменений не происходит дальше что он сделает значит то что его я писал да значит apache игнайт это когда значит работает persistent режиме при режиме сохранения данных на диск значит она изменение записывает как любая собственно классическая база данных в в рай то hotlog про это hotlog это соответственно бинарный файл который содержит последовательные изменения последовательные дельты тех записей которые мы кладем базу данных соответственно мы значит и приложение сидите и обрабатывает архивные датами есть момент когда вал вал сегмент переходят в архив обрабатывает когда увидит что появился новый архивный сегмент его обрабатывает видят эти события которые у нас есть и соответственно уже кончаю мир то есть потребитель этих изменений уже может реагировать на изменения в данных что такое нет перерасхода места на диске да значит архив уже есть то есть это штучку канал тут я полагаюсь на тот функционал который же разработан соответственно значит он нужен для восстановления после чего нужна вообще в целом во архив архив нужен для восстановления после сбоев вас я упала вы начинаете подыматься повал архива идете смотрите что у вас было последним сделано ну и соответственно восстанавливаетесь на ту точку в которой вы упали так как мы обрабатываем те же самые архивные вал сегмент это соответственно новых никаких данных не появляется на диске и сидите в этом плане работает без перерасхода места на диске точно новых никаких данных мы не пишем все что писалось мы просто как-то дополнительно начинаем их обрабатывать сохранять состояние чтения на так как это отдельный процесс отделе просто операционной системы понятно что он тоже может глючить падать что-то не может происходить соответственно нам нужно каждый раз когда произошла какая-то там потребитель определил что они прочитал столько данных к 100 я могу сохраниться в состоянии мы должны как баз данных это поддерживать сохраните состоянии соответственно после если если при вас произойдет к это сбой что-то произойдет начну должна восстановиться и читается собственным с местом где нам пользователь последний раз обрабатывал я полагаю что с точки зрения failover с точки зрения того что вот чтоб что то должно произойти как мы должны останется после сбоев я полагаюсь на средства операционной системы то есть это должно работать как и приложить нужно будет как сервис упала мы у заново подняли упала заново подняли все как бы тут понятно достаточно как бы распространенный паттерн у и соответственно значит для того чтобы все это дело можно было использовать что все это делал все эти бизнес кейсы которые там были причислены можно было реализовывать я реализовал значит паблик и 5 для получения изменений вот и вы собственно уже можете его использовать да тут еще стоит оговориться значит что означает реализовалась что означает можете использовать значит этот функционал сейчас мастер игнайта он за комичен вот сейчас мы выпускаем нам уже выпустили или в процессе процессе релиза 211 в 211 эта функция не вошел он будет два в 12 вот то есть соответственно там через несколько месяцев он будет уже в бинарном релизе которые можете скачать и использовать да то есть то что я сейчас реализовано это означает что сейчас находится входом в ходе да и ну вы можете собрать нами скачать скидка бы исходники и собрать и релиз себе и соответственно использовать значит бинар бинарный как это будет 212 ук идем дальше значит ну вот соответственно значит исходя из всех этих дизайн принципов как у нас очень сжато капчи работает на уровне 1 ноды базы данных у нас есть но да вот это файлик процесс игнайта sage которая работает обрабатывать запросы от клиентов изменять какие-то данные создают выдает кашель удаляет каши и соответственно процессе своей работы она пишет в рай take it look про это hotlog опять же по логике внутренней логике ноды переносится в архив в какой-то момент вот и соответственно для того чтобы получать изменения мы обязаны запустить настроенные и гноить идите приложения которое поставляется вместе с на этом и собственно она начинает следить за папочкой в которую складываются архивы последовательно получать сегменты вал архива и обрабатывать их вот тут показано как это выглядит собственно в моем мое тесто инсталляции мы этой старой сборки да то есть у нас вот есть и папочка вал там есть это это хищник ноды ну и соответственно здесь вот это те которые текущие значит сегменты в которой мы пишем по кругу а вот сюда уже откладываются у нас в архив значит архивные сегменты вот и для того чтобы значит тут есть небольшая тонкость для того чтобы значит и архив он тоже не бесконечна прошу не бесконечна и места на диске значит и в архив и складываем сколько-то сегментов на 10-20 сколько настроили для того чтобы не пересекаться да то есть например там значит у нас здесь идет тормозил здесь 10 метров накопилось и начал сверху удалять осирисе и еще не обработал избежать такого значит клавиши такого пересечения значит вот это архивный сегмент значит в виде жёсткой ссылки переносится вот в эту папочку то есть вот это и это это одна и та же одни и те же данные это жесткие ссылки на одни и те же бинарные данные соответственно если мы удаляем из архива здесь файлик остается и данные доступны если мы удалили здесь the pub как бы когда в архиве удаляться данные да папа опять же по алгоритму игнайт из канады соответственно мы эти данные на диске удалим ну и собственно все и в этот момент произойдет как раз очистка вот собственно примерно так это работает теперь рассмотрим те изменения в конфигурации изменений выпей которые собственно понадобились и как это дело вообще использовать значит вот тут есть 3 флажка который вам надо настроить значит и которой являются там один из них является как раз пройдохам основным при использовании сидиси значит понятно флажок сидящий на и билет означает на включено выключено функция это если она труд а собственно вас все включено значит у вас есть путь к папочке вот которая была предана спирова на предыдущем послании вот вот к этой папочки сидиси и там вы можете там зависимости от вашего деплоя создавать на по различным путям если у вас там диск какие-то там или еще что-то и вот соответственно вал force архив таймов значит там есть тут тут тут есть небольшой то рядов значит для того чтобы вал архив быстро работал он работает как мы маримар маг мопед файл да то есть соответственно это файл которая атма плен в оперативную память средствами операционной системы и соответственно когда пишем мы фактически не пишем на диска пишем в память операционной системы уже решает когда этот файл сбросить либо мы ее просим когда этот архив верни сегмент заполняется ну естественно когда он значит сбрасывается на диск это долгая операция привет приводит к тому что достаточно она она долго выполняется есть некоторые там пенальти по производитель себя в этот момент производительность но дано меньше вот но так как у нас все диси получает значит уведомляя получает звучит и узнает об изменении в данных только в тот момент когда архив сегмент заархивировать и соответственно если вам нужно быстрее об этом узнавать то вы хотите чтобы сегменты как можно чаще архивировать и понятно что с одной стороны мы должны их активировать как можно реже чтобы вся но до себя вела быстро с другой стороны мы должны с точки зрения сидиси их архивировать как можно чаще чтобы как можно быстрее узнавали об изменении в данных и тут есть рядов которые надо как бы с точки зрения вашего приложения решите на сколько вас там сколько вам надо выставить этот тайм аут ну и соответственно значит этот тайм аут он будет говорить о том что даже если полностью сегмент не заполнен он будет архивировать какая то вот эта часть значит сколько данных вы записали в него и он станет доступен для обработки значит садись и так идем дальше теперь соответственно самое интересное собственный консьюмер то есть у видом значит слушатель тот кусок кода который пишет при пользователи которые пишите вы если будете использовать эту функцию и соответственно который позволяет узнаете проконтролировать об изменениях в данных . функции понятно старт-стоп вначале приложению вызывается старт что все за инициализировать в конце стоп и через некоторое какое-то количество времени происходит уведомление callback он эванс в который итератор с функциями приходит значит в новинке там вот можно заметить что это более возвращается то есть если вы вернули true вам все будет закончено ну и соответственно следующий раз вы уже будете знать мере не мы вне вы acidity будут знать какого места вам продолжать стримить эти события вот он и wants вы можете пройтись по этим sopa по событиям которые к вам пришли ну и соответственно каким-то образом их обработать значит что доступно в событий событий доступны те данные которые нужны кей вылью вот целью может быть нам в случае удаления понятно да и то если операция режимов у вас вид отдалит случае ветра сама иску или the value будет нам будет только лишь доступен признак праймари происходит событие произошло ли это событие на праймари длиной бэкапе номер партиции там для того чтобы принять решение вот распределение данных на основе данных которые распределения которые есть вы знаете значит версия вот чуть позже я про неё расскажу и соответственно edit идентификатор кэша то есть это wi-fi катар того кошака котором произошло это изменение собственно используя вот предыдущий слушатель до которые зачитаю и вот эти вот события мы можем делать реализовывать и бизнес-функции которые собственно вам могут понадобиться вот теперь мы пришли к ситуации следующий у нас есть приложение которое в асинхронном виде получает уведомление обо всех изменениях всех данных которые происходят внутри кластера игнайта и это очень хорошо потому что на основе этого функционала мы можем рисовать как бизнес-функций которые я говорил так и логическую реплика отсюда то есть есть у нас 2 2 типа репликации ну-ка конечно гораздо больше счастлив с другом как бы по другим параметрам делить но есть физической репликации и логическая физической репликация вы реплицируется собственно бинарные данные куда внутреннее представление она там p&g какие-то или там целые файлы но вот и между либо инстансами до баз данных на наш случает распределенная база данных дату с между пластинами в случае логической репликации вы реплицируется логически изменения то есть именно те изменения которые делает пользователь можно так как мы получаем здесь уведомление можно воспроизвести где-то в другом классе значит и вот дальше значит приведена схема вот их 2 в целом сейчас существует эта схема которая доступна и у нас есть такой проект игнайт extends называется соответственно там расширение игнайта и вот собственно реализация сидиси концу мира которая позволяет реализовать который реализует логическую репликацию соответственно там она доступна вы тоже можете ею же воспользоваться если соберете все из исходников разорили жена она будет как я сказал версии 213 вот значит что мы имеем здесь мы имеем ту же самую ноду да там вот про флажки чуть попозже скажу для чего они нужны будут значит вал архив вал пишется вал архив и соответственно вот тут вот вы указываете гнать-то игнайт сидиси стример что он себя представляет он себя представляет там канчи мира до стримера который внутри себя подымает клиентскую но дугна это значит конектится к тому кластеру в которой нужно значит стримить логически изменения ну и соответственно каждый раз когда получает изменения стримит его просто просто отправляет обычную операцию путь с небольшими там дополнениями про который я сейчас подробнее расскажу на следующий слайд то есть в целом как бы ну вот схема она очень примитивно и связи с этим довольно хорошие хорошо себя показывает надо отдельно сказать про то что происходит если какой-то кластер недоступен да то есть так как у нас вот это все асинхронное значит если не доступна игнатовская но тогда точно надо упало все этот значит процесс остался то соответственно этот процесс не будет просто видеть никаких новых файлов и просто будет вечно ждать пока но да не запустится либо его самого не прибьют ну то есть понятно что никаких новых данных поступать не будет только те которые уже но тут пока была жива сгенерировал он обработает если упал сидиси значит да процесс упал что должно произойти во первых на стальных на отдых он будет жив да так как у нас кластер и соответственно там это все дело будет продолжаться во вторых то что я сказал до мы ожидаем что через некоторое время или сразу a person система перезапустит он подымется посмотрит какие изменения он обработал какие нет ну и соответственно продолжит их отправлять в соседней класса что происходит если соседней кластер либо там сетевая связано с потерялась да то есть тут вот какой два раза делали это для мир содовой репликации до насчет связано с методами порвалась и мы не можем отправить не кисни сюда это означает что просто играете диси тучи также упадет ничего не произойдет или prison всего перезапустит он опять попадал уподобиться в этот кластер и пока собственный но он не доступен этот кластер он будет продолжать долбится ничего не сделает как только он появится он сразу пойдет туда и собственно начнет у него отправляйте изменения которые накоплены вал на диски диск является буфером изменений и изменения будут копиться пока они не смогут быть обработаны и не смогут быть отправлены в ту точку в которую собственно нужно ну и вот 2 2 2 2 2 вариант значит этой же репликации если по каким-то причинам вам 2 классе zegna это связать какие-то проблемы есть и вы хотите вот например кафку использовать в качестве транспорта та же самая схема на той стороне вы видите вал архивы значит используйте тут немножко другой значит триммер игнайт туков к он раскладывает попортится им кафки там соответствии с партициями кэш игнайта данные для распределения и на этой стороне тут есть значит опять же доступны в extend шинах приложения кафка то играет которая собственно эти данные забирает и точно так же отправляет их в принимающий кластер игнайта ну и соответственно если у вас репликация которая называется active актив да когда изменение идут и вот кластер именно это один и в кластер гнать 2 соответственно вам в обратную сторону все то же самое надо настроить здесь вам нужно поднять садись и вот он тут нарисовано в ту сторону какой-то другой топик описать изменения ну и на той стороне его эти изменения обрабатывать и применять значит теперь перейдем вот тут указан конфликт резольвер значит есть тоже еще как бы небольшая тонкость любой кто сталкивался с аппликацией примерно себе представляет о чем идет речь вопрос что произойдет если одни и те же данные изменены на одном кластере и на втором одновременно в связи с какими-либо ошибками бизнес-логики либо просто так спроектировано значит что произойдет а произойдет у нас в нашем случае следующая отработает конфликт резольвер то есть мы отдаем это наводку пользователю предоставляют дефолтную кульминацию значит логике которая позволит конфликт разрешить с помощью нашего еппие вы можете значит конфликт резольвер значит конфигурировать вот свойство которое он работает на каждое изменение отрабатывает там приходит данные об изменении то есть вот старая entry вот новая значит что с ними делать вот это доступно там из public и 5 немножко он сейчас в интервал лежит там в следующих релизах обязательного вынесем в настоящий public вот и соответственно реализовав там определенные интерфейс вы можете написать какую-то свою и помин то цию вот значит есть реализация которая работает по умолчанию значит и которую надо использовать чтобы соответственно вот эти вот ситуации конфликтные значит разрешать значит алгоритм который вот мы там долго тоже выбирали тут надо сразу оговориться значит а хорошего решения при конфликтах изменений его такого универсального хорошего решения не существует когда то есть типа ничего не зная данных принять решение о том какое изменение правильно какой неправильно невозможно он соответственно тут мы как бы действуем исходя из каких-то трейдов исходя из какого-то понимания того как нам хотелось бы чтобы система которую лично я бы использовал в качестве значит основной базы данных себя вела ну и вот мы долго думали обсуждали значит и прилив такого рисовали такой вот алгоритм если изменения производить произошло на том классе на котором вы сейчас отрабатывает на 43 доллара но всегда выигрывает по сравнению с тем которое было до данные значит изменение с одного и того же кластер сравниваются по внутренней версии у нас есть там такой а значит штуках внутренняя версия м передать каждый раз когда вы что то изменяете удаляете версии она инкремента соответственно если под исходя из этого можно 2 entry между собой если они если они изменены на одном и том же классе 3 между собой эти два изменения упорядочить соответственно если и старая n3 и новая n3 соответственно были изменены на одном и том же кластере то понятно что должна остаться так которая имеет более большую версию тут всё в целом понятно значит если опять же у вас там ситуации когда конфликты в данных возможны часто происходит и вы знаете исходя из своих собственных данных значит как у вас эти данные эти две entry для записи надо сравнить вы можете как рассказать поле которое однозначно говорит о том какая из этих данных какая из этих записей старшая какая из этих записей должна выиграть это должно быть comparable поле понятно по conti request айди не знаю что то что то такой таймс темп обычное поле которое растет и который позволяет сравнить между собой 2 записи если все эти три пункта не выполняется то изменение отбрасывается там печатать соответствующий варнинг ну и понятно что тут в этот момент данные разъезжаются поэтому в тот момент когда значит вы решите внедрять собственную репликацию тут вот нужно хорошенько в этом месте подумать и исходя из бизнес-логики исходя из бизнеса стала данных принять решение о том значит как в вашем случае надо конфликта рисовать возможно ли соответственно уже тут разбираться это как бы тонкий момент надо о нем помнить в целом у меня все значит я хотел еще раз сказать отдать вот ссылки значит приходить на скамейке это open source можно посчитать все посмотрите киты там описаны все более подробно ли вы примерно также как я сейчас рассказал дальнейший план и что что что дальше будет будь то pelena чтобы эта фича еще была более более лучшей лучше себя вела и позволяла эксплуатируется без проблем кроме так значит метрики да сейчас сейчас в метрик нету никаких там и почти склоки начнут добавлены метрики какие файлы на обрабатываем сколько их когда последнее время точную и возможность в ваш консьюмер засунуть метрики тоже будет добавлено эту штуку будет вам достаточно просто наблюдать за этими метриками вот ну и второе там у нас значит кто знаком с игнайтом есть и memory кашель из persistent каши да сейчас все это дело ясным образом работает для persistent а потому что ковал persistent режиме работает в режиме scandisk каким-то образом хочется поддержать еще in memory каким это вот на этапе сейчас дизайна разработки архитектуры тут будем думать все спасибо за внимание друзья из зала вот прямо по центру при руки спасибо большое за доклад а подскажи пожалуйста получается что в консьюмер всегда это только одно приложение правильно ожидается что консьюмер он будет говоришь покажу я здесь изобразил значит игнайт это классика секта вот тут же есть несколько нот и каждая но да она должна работать так одинаковым то есть вот это изображено 1 но до на самом деле их там ну сколько у тебя в квартире 840 у нас бывает ещё сколько-то там шисят вот и соответственно сидиси и консьюмер он должен быть запущен на каждую ногу точно всех 60 нодов будет отпущен из дубля положений и там он будет получать изменить уведомление об изменении я больше здесь имел ввиду масштабирование есть например у нас база высоко нагруженная получается что консилер который подписывается на седан может не справляется ну что очень-очень большая из винтов как скелет есть такая вот такая проблема возможным если консьюмер тяжелее чем запись на диск изменения да это это это проблема возможно значит и тут скажем так нужно принимать решения исходя из твоего как бы как про не сказать паттерна работы да то есть например если у тебя всегда вот всегда такой поток данных с которыми консьюмер не справляется понятно что тебе нужно перекладывать его куда-то значит какое-то эти изменения как-то во-первых ибо агрегировать либо значит что-то с ними делать куда ты их переложить так я их уже можно хранить ну то есть смотри давай так вот ты горишь меня есть да у меня есть нагрузка которая значит с точки зрения обработки изменений она дольше чем произвести само изменение то есть и соответственно в этот момент тебе надо изменения и где-то сохранить собственно очевидно да и где сохранить это уже вопрос тебе например пример переложить в qaf куда то есть буковка опять же она же как кафка это будет тот же самый диск и по сути это тот же самое во лбу так уже где-то на другом сервере на другой машине если там диски как бы тебе хватает перекладывают применяя все с очки которые тебе нужны если как бы у тебя диск например жирные ты можешь поставить на имена и треску ну поставь туда же черный диск как бы не собственно там будет притормаживать у тебя ну какой то момент и разгребешь события тут вопрос именно такой как бы где где тебе с точки зрения архитектуры с точки зрения железных ресурсов с точки зрения там не знаю дастур серверов удобно это с буфере zero вать понять нужен спасибо же одну там были еще вопросы спасибо за доклад еще страстно давай давай давай спасибо за доклад меня зовут артур вопрос насчет конфиг pressol вера у тебя там на слайде было написано что в первом приоритете рисуется в пользу локального изменения это не очень понятным этот момент допустим есть два кластера на них каким-то образом пришло изменений одессе тех же там они через 70 провели изменению друг другу и каждый и зарисовывал его как свои локальные в итоге у нас данные рассинхронизировались нет мешка не так то есть если тебя произошли до изменения в обоих кластеров то именно эти кластера буду читать и что они локальные они к себе их всегда применим вот а ступень когда это посидите пройдет то есть через 10 данный которые через сидиси приходят резольвер знает что они из другого кластер а вот там приходит версия и версии есть айтишник кластера и соответственно точно урезала будет знать что это изменение она и и равно из другого класса и соответственно же пойдет другой обработка то есть вот в этом смысл вот и как бы локально изменений тут в чем как бы смысл да вот у тебя например это реплицирования изменение даты штука типа она прилетала вот этот как бы такой какой об основной паттерна использование вижу либо у тебя просто какой то есть стендбай классов который просто уцепиться с в этот активный а этот стенд бай да когда стоит тот упал и тот начал работать на изменения соответственно тут как бы у тебя значит все время идут просто одного и того же класса мельница на украсить изменений в эту шторм это первый даты и тут как бы все вроде как нормально вот теперь второе изменение 2 когда у тебя есть актив актив да там два кластеров которые есть какое-то распределение по не знали идентификатором по еще что-то . кайта роутинг изменений на уровне бизнес-приложения дождь и под этом знаешь что половины клиентов а тут мы обслуживаем плане запросов там аполлон запросов у тут и вся задача да то есть обеспечить отказоустойчивость что если одна из реплик упадет просто тут будет на 2 2 раза больше нагрузки ну и вот соответственно значит ты в этот момент вот распределяешь в этот момент вот это значит логика она как бы работает не знаю как понятно и объяснимо вопрос надо уточнить или точнее что-то непонятно понял спасибо на 3 ряду рядом с телевизором у меня заставлен несколько вопросов один человек мне тоже к разбудит интересная у него шаг разовью если получается правильно понял что на каждый нодди кластера подымается концу мир который локальные вал изменению вопрос о том то есть по факту они все независимые другом никак не общаюсь средства у меня нет возможности не имея какой-то кафки или стороннего хранилища подписаться на весь поток кластера да нет спасибо тут вопросы ты хочешь получить в каком-то едином месте да весь поток кластера нет не важно давай потому что но у играть лишь распределенной нет вот данный вопрос понятно и еще собираюсь выкупила complication получает свое со всей этой истории потому что свал архиву вы совсем такое получается момент доставки до 2 класс страдания и шкуру момент доставки тут зависит от нескольких параметров да там и тут надо значит есть смотри тут вопрос приоритетов вот опять же вопрос к приложению которое значит вот это у себя внедряет привет я имею виду смотрите тут может быть несколько приоритетов мы можем взять и задать очень маленький архея тайм-аут архивирования валов в этот момент мы получим очень маленькую значит там типа секунды значит да там значит время доставки до соседнего кластера но мы получим что что у нас скажет или постоянное значит новые сегменты вала генерируется это плохо скажется на производила синода в целом да понятно секунду я просто прост родов павел дацюк и последний маленький вопрос соответственно сейчас долго вылетела что происходит если у нас приходит большая транзакций вал атомарная оно гарантированно также атомарной применится полностью нет сейчас транзакции не поддерживаются значит эти изменения не и защиты применяются по entry вот там есть есть тонкости стан фракционным протоколом там и как он отражён в архиве вот поэтому консистентной транзакции их их нет то есть применение оно не консистенции с точки зрения транзакций она консистентной с точки зрения последовательность изменений в партиции на ноги прошу здравствуйте спасибо большое за доклад на такой вопрос вот если вот этот процесс который young tight сидиси он упал что-то с ним произошло дальше там валы валы валы один вал файл потерялся есть ли возможность не слышат чтобы начать за ну как бы начать с кусочка snapshot в во первых по snapchat поддерживается вот у нас есть вы меняете снапшоты это просто совсем это часть не связанная функциональность и она как бы в данном как бы в данной fitch она не рассматривать что ты можешь снять народ и поднять его где-то на другом кластере это не проблема вот случае с валами то есть если ты опять же кто значит потерялся он там не теряется там там потеряться можно как вручную учета удалишь нутуз тип у тебя все работает вот куда я сейчас немножко вернусь на слайд назад где-то так вот и работает и каждый раз когда у тебя сегмент архивируется давайте здесь создается жестко ссылка вот соответственно ну типо вот сюда больше никто не лезет у тебя отсюда удаляет только процесс сидиси то есть ибо когда он обработал файл он его оттуда удаляет соответственно потеряться файлы тот может только в одном случае суть окончила с места на диске то есть я настолько долго приложений сжал что весь все места на диске оторвалось пришел как бы админ и руками что-то поудалял автоматическим сейчас это дело не удаляем вот соответственно вот в этот момент может потеряться но если такая ситуация произошла такой инцидент а этот intent с точки зрения как бы ну всего как бы здоровья квакеров всего работоспособности кластер retweet видимо должен удалить либо стоит удалить полностью да и начать уже с какого-то того что у тебя сохранилось либо какие-то такие компенсационные меры принять либо довольство от собственно перенести и продолжить вместо того которые ты как бы то есть стал с текущего места продолжить то есть тут уже вопрос опять же именно operations как ты это будешь сопровождать кроме общак ну так управлять в лесу на упал этот процесс как управлять какого момента начинать или он сразу начинает только стоил dial up along он сам начинает дождь смотри вот давай с точки зрения и перед и это контролируешь только это не здесь с точки зрения и 5 это контролируешь вот здесь смотри вот те приходят какие-то события даты какое-то количество обработано либо все вычитал и принял решение что теперь я могу за комитете и про буду продолжать с того же места с которого я вычитал ну собственно возвращает true из этой функции она комитета и ты продолжаешь с того же места когда и если упадешь при при запускали последний вопрос вот давайте раз прошу прощения уже микрофон взяли давайте ясно что спасибо за доклад так и вопрос как эта штука работает с динамическим кашами и создан хэш он как автоматом приедет и второй вопрос как дела смита даты она тоже мигрировать между кастерами ашот касатка динамические к шипы что у крис старт хэш из да ну так когда я понял вопрос водка шаги то есть как только ты создаешь к новый кэш тебя начинает приходить ну значит изменение суд с этим каша диета будет новый бишкек нового каша собственно тут никаких ну то есть никак не завязанного код статическую конфигурацию просто там тесто те события которые начали валиться они тут и придут по поводу metadata очень хороший вопрос metadata сейчас не переезжает и это как раз один из тех им improvement of которые мне обязательно надо сделать это ближайшее время есть на это тикки ты как бы уже это сделаем ответ metadata сейчас не переезжает как бы собственно нужно как-то опять же она доступна вот и здесь из этого и периода там бояре объекты кто знает чуть побольше шок кишков значит игнайта до внутренности есть у нас баян или обжиг ты здесь при приезжают как раз бояре объекты вы можете все это metadata от тут динамически получить для того чтобы динамические именно конкретно вашей схемы мигрировать сейчас этого нету это я прикручу в теперь будущих релизов очень скоро"
}