{
  "video_id": "cvd0NkhjK3Y",
  "channel": "HighLoadChannel",
  "title": "Эффективные алгоритмы поиска подобных объектов для терабайтов данных / Евгений Журин (Segmento)",
  "views": 539,
  "duration": 1430,
  "published": "2017-04-07T12:30:43-07:00",
  "text": "всем привет меня зовут журин евгения дата zante с компанией сегментом и тема сегодняшнего доклада это эффективные алгоритмы поиска подобных объектов для больших объемов данных хочу начать с байки возможно вы уже слышали но она хорошо иллюстрирует где могут может понадобиться но собственно данные техники все началось в американском магазине таргет в который как-то пришел разгневанный мужчина который держал в своей руке стопку буклетов рекламных и требовал позвать менеджером так как ему очень не понравилось что его малолетней дочери присылают рекламную продукцию для беременных вот ну manger конечно пришел извинился лояльность покупателя важнее всего и казалось бы на этом история закончена но нет через пару недель manger решил еще раз позвонить и извиниться и услышал в трубку такой немножко потеряны голос отца и как оказалось дочь была действительно беременна и аналитики эта компания узнали об этом раньше чем собственно родной отец решать задачи можно абсолютно разными способами один из подходов это например найти ну взять сегмент беременных женщин про которых точно известно что они беременные и найти собственно похожую аудиторию в том ваших данных и показать им собственную рекламу жалкой похожесть как вообще формализуется это понятие обычно его формализует через математическое определение расстояния всем хорошо известна и евклидова расстояния мне неизвестно то же только расписанием а хакерское расстояние на картинке видно чем они отличаются вот более интересный вариант очень интересный еще вариант расстояние катара можно считать между множествами простая джакарта она тоже достаточно простое оно что она позволяет делать обход позволяет определить насколько похожи между собой два множества как она считается мощность пересечение множеств на мощность объединения множества прошу обратить внимание дальше она нам понадобится и подач будет использоваться вот мы у нас в рекламе таргетированный тоже решаем задачу поиска похожие аудитории более поэтично она у нас называется задача look-alike и расскажу на конкретном примере собственном какие конкретные кисть может быть перед нами поставлен у нас например есть сайт example.com и мы заблокировали какую-то часть аудитории которая зашла на него и например посмотрело больше двух страниц считаем что это аудитория заинтересован в этом сайте и теперь нам нужно найти похожую аудиторию во всем том сегменте интернета который мы видим и показать им рекламу run продукции например этого сайта итак у нас была у нас было 250 миллионов профилей миллион площадок и нагрузка в 30000 рпс достаточно большие объемы данных с этого всего у нас получаются и много профилей с которыми дальше и работаем штука и для нас профиль профиль это какая-то контекста информация которую мы видим в момент проведения аукциона на рекламу который более подробно рассказывал мой коллега предыдущем докладе ну вот оффлайн данные которые мы либо закупаем обменяемся с партнерами такая информация и нами за лакированная история поведения людей в интернете то есть какие сайт они посещают что они на них делают какие страницы смотрят вот понятно что данных много в профиле получается и описывать профиля можно абсолютно по-разному один из вариантов описания это через набор доменов которые они просмотрели на которых мы их увидели это реально ки из которого мы начинали и он действительно сразу дал бизнес-результаты после внедрения мы сразу смогли улучшить качество аудитории которые мы приводили на сайт и реклама да коли наших клиентов даже через такое простое описание это граф демонстрирует движение трафика в том в части сегмента интернета который мы видим видно что есть кластеры с которых трафик идет намного больше чем с других сайтов для данного типа представления требуется совершить следующую очистка куют очистку данных что мы делали мы выкидывали профили для как про которых мы мало что знаем и сайта из которых ушло больше и меньше всего трафика все это мы отрезали по перцентиль им то есть у нас есть система которая каждый раз обходит но секс на наши данные забирает агрегат агрегационную статистику мы по ней примером тогда можем представить ну собственно в каких диапазонах мы работаем дальше вы стать просители который по которым будем в наши данные чистить и собственно мы взяли профиль представили его через помощью набора доменов которые они посетили и теперь мы собственно что хотим делать мы хотим считать расстояния джакарта между этими профилям и считать что если профиль посетили примерно одинаковой доменом считать что не похоже им примерно то же самое интересно и мы можем показать ему рекламу и это собственно даст улучшения результата все равно считать честно расстояние от же карты мы не хотим потому что это очень не компактное описание получается профилям с этим нам может помочь он горит mensch собственно у нас есть сайты которых мы видим обратите внимание мы проиндексировали и у нас есть хороший про плохой злой это профиля с которыми мы работаем и мы можем собственно рассчитать я показал пример расчета расстояния джакарта собственно для этих конкретных профилей конкретных значений сейчас просто хочу кратко описать алгоритм чтобы вот то что делаем массаж мы делаем не казалась какой-то не знаю магией вот вот это собственно основная часть осталась удачно ней не подробнее возьмем профиль конкретно хороший он посетил сайта keddr.com машин но не точка ру и у них индексы мы увидели 13 мы берем какое-то количество хэш-функций о том как выбрать количество я расскажу чуть позже и как и будет про мы 3 хэш-функций и делать следующие операцию мы берем хаш от индекса каждого сайта который мы видим и было уберем минимальное значение то есть получается что в конечном итоге профиль описывается через набор минимальных значений хэш-функций относительно тех индекс этих сайтов которые он посмотрел вот это пример расчеты для всех профилей в нашем примере мы видим и при помощи этого представления теперь мы можем также рассчитать аппроксимированной расстояние джакарта то есть с какой то ошибкой как выбрать количество хэш-функций тут все зависит от того какую ошибку мы готовы на себя взять если мы готовы ошибаться в десяти процентах случаев вращал не большим не большим 10 процентов то нам достаточно все сто хэш-функций один процент уже 10000 хэш-функций собственно как теперь сгенерировать когда мы определились с количеством им дам тебе нужно как-то сгенерировать эти функции мы используем ну собственно у нас функции до xp moze и мы используем случайные числа меньше чем наш максимальный индекс в коллекции и собственно c какое-то простое число чем больше чем макс x это с этим у нас завелось вот хорошо что мы теперь имеем резюмирую у нас есть профиль у нас есть теперь более компактное представление через значения хэш-функции например от количества которым мы выбрали например 100 вот но мы все еще не хотим считать расстояние между всеми элементами то что это также дорого и очень долго ли там до этого чтобы решить эту проблему мы используем технику localities in city fashion собственно чем ее суть у нас есть таблица в этой таблице представлен как раз представляем по которой говорил до этого мы нарезаем их равномерно на бэнды то есть на какие-то куски то есть в данном случае у нас профиль на пляжу зло представлен из 4 4s функций мы берем и нарезаем на 2 бэнда то есть наберем 1 2 значения проверив тары и последние два дальше совершаем следующий операцию мы считаем что два профиля является кандидатами на сравнении если значение грубо скажу если значения в бензин у них совпадают то есть например у при такой нарезки ухо злого и у хорошего значения в первом бы делу хэш-функций 12 равны поэтому мы считаем что они являются кандидатами на сравнения мы кладем их рядом в band 1 вот следующее что он получается получается следующая картина у нас 6 м фунтов на которые мы разбили и там какие-то группы профилей которые мы определили но собственно кандидаты на сравнения мы отфильтруем сейчас еще раз вернусь ли ты их изначальной задаче мы ищем похожую аудиторию на целевую аудитории целевая аудитория поэтому мы фильтруем сразу те кто где q я сгруппировал столько целевая аудитория или только за новая аудитория и выбираем bands и последующей папа стоящему правилу такой в листики мы берем тот band в котором достаточно и относительно бизнес требований количество новой аудитория и максимальное из возможных целевой аудитории вот то есть например у нас есть band 12 а у них пример она у них одинаковое количество целевой аудитории но в burn в банде один больше новой аудитории и нам нужны объемы какие-то и поэтому вы мы выбираем band 1 даль для дальнейшего расчетам а также мы делаем обычный к ближайших соседей отделах этого бренда и собственно делает выборку которую уже дальше используем для таргетирования рассчитывать краз расстояние джакарта нам не нахожу представление про которое до этого рассказывал дальше мы собственно отпуска после операции заливаем данную систему и таргетируемся вот как выбрать количество бэндов потому что от этого многое зависит ну зависит соусом точность которую вы получите на графике представлены два варианта это с если мы возьмем б это количество bondov это количество строк в банде синий график показывает что например пример возьмем синий график пропустит например все профили у которых метрика джакарта около 0,4 то есть он будет пропускать больше он более жестко будет пропускать не похожий профилям зеленый более мягком будет работать более точно поэтому я сейчас говорю про много форму какие-то графики рисовал но эксперимент никто не отменял и дергая две ручки основные это количество бэндов и количество хэш-функций мы можем получить совершенно различные результаты абсолютно с отличающимся метриками качества поэтому вас там все равно в конечном итоге мы все основные параметры подобрали на экспериментальном то есть мы всегда какой-то пытаемся баланса пути между дорого дорого ну честное очень хорошо и быстро дешево но не очень точно собственно вот этот рассказал кейс который мы делаем для того чтобы искать похожую аудиторию еще смотрим на другие алгоритмы один из последних который попал 7 нагар за это алгоритм димсам вкусная картинка как оказалось димсам это еще закуски наверное ребята из twitter тоже об этом знали надеюсь суть его вот в чем у нас есть прямоугольная матрица m на n в данном нашем контент случае это профиль например на сайт а где м много больше м то есть у нас намного больше строк чем столбцов вышла на spores и еще требования в алгоритмы заколоть это что она должна быть нормирован от нуля до единицы к сожалению на ну напрямую на поиск похожих строк как нам нужно это не ложится но эти требования какие варианты можно забиты математической строгости попробовать все равно ну использовать эту технику для расчета попробовать все равно сюда стоит тут заведется мы еще пока так не делали напрямую это как изначально авторы предполагали это позволяет их техник назвать легко вычислить расстояние между столбцами если ваши данные удовлетворяет сразу данным ограничением то техника сразу напрямую ложится у нас как это можно применить это на 1 первым мы можем просчитать похоже сайтов на основе их аудитории этом иногда ну собственно формальному форме этого расстояние между столбцами для чего для чего это может быть нужно ну конкретно если мы представляем профиль как набор сайтов то это позволит например дать данный для маркетинговых исследований которые от нас надо требуют если мы представляем профиль уже как набор фишек какой-то то есть который мы считаем по профилю и дальше используем в предиктор в каких-то на шкаф расчете ставки на аукционах рекламных то это позвал паза позволит снизить размерность то есть за счет точно можем ощущать расстоянием похоже 7 же между столбцами из техника который на основе этого уже позволяют выкинуть ненужное фича то есть тоже достаточно полезно бывает и улучшается качество работы алгоритмов и уменьшает скорость убивающий скорость вычислений вот это не сам алгоритм я рада рассказывать не буду он достаточно простой в реализации вот ну просто проведу мотивирующий надеюсь пример оценок который мы сможем получить если мы напрямую считали расстояние между столбцами через мап reviews и если бы мы использовали этот алгоритм то есть там на самом деле суть в том то что просто часть данных не учитываются и поэтому получаем как бы ошибку будут выиграем скорости но получаем какую-то дополнительную ошибку и собственно насколько большой шаг он получим это все зависит от параметра гамма видим что мы можем уйти от лавский и shuffle за из это метрики оценки определенных задач которые предлагают авторы ну ладно сирийский на всякий случай напомню это ключ она редко were дусю которую максимально попадает о большой объем информации шатаясь это объем самоса который мы тянем во-первых продюсером вот ну видим что можем уйти от квадратичных оценок и все привести к размеру линды который гаммы который позволяет нам заданной заданной точностью ну собственно получить результат как этом эти задачи использовался так технологии питон ходу луиджи hbs луиджи это удобный питоновский фреймворк для организации pipeline of между данными то есть его удобно сикхи телеф и мы собственно для написания грамм определенных задач то есть можно сделать просто pipeline замок прекрасных задачей получить ну то что вы хотите и потом куда-то залить все спасибо всем за внимание дам ну да у меня вопрос по поводу соответствия профилей площадок что там на складе и собрали нам помню было 250 миллионов профилей и 1 миллион площадок то есть среднем на одну площадку всего лишь 250 пользователи ну собственно откуда так много площадок тогда ну как получается это все короче куни куни куни уникальные же площадками лика у него и миллион интернет-площадок но когда мы получаем профиль то на профиль ну как бы каждый профиль посещает свое количество площадок один профиль флейтиста площадок не или не понял вопросам у меня тогда вопрос что называется площадкой потому что я так понимаю на одном и сайте явно больше чем 250 человек данном случае площадкой пути подразумевается домен то есть у нас профиль это список грубо говоря посещенных доменов которые мы увидели то есть профиль 1 iunie он почтил авито машин лётен кто то то то и то то и то то собственно ну если я правильно понял то есть соотношение сайтов и пользователь в интернете примерно 1 250 . ну и ну например на ну да спасибо скажите пожалуйста может быть поподробней просто расскажите чем вы руководствовались для группировки хэшей в группы если какая-то логика потому что судья под по математике которого пользователь сетка в watch винчи существенно влияет на результирующий выборки которые мы были точно потом сравниваем и второй вопрос как вы именно уже кандидаты кандидатов сразу сравнивать между собой и и оцените релевантность это просто предложение каких-то разреженных матриц или какой-то более алгоритм тех кандидатов с раннего между следующим образом как раз через мэр мы морщинка раз расстояния джакарта между vintage представление о которых я говорю и берем ну как бы пока ближайших относительно целевой аудитории вот я ответил на второй вопрос вот вот тут на самом деле просто берем хэш-функцию от делаем ключ определенный от значений and harsh представление об энди да мы берем отдел определенную хэш-функции которая по пятнам в число и после этого и группируем по ключом и собственно вот так а может быть просто меньше хэш-функции стоит выбирали использовать нет я не расслышал может быть меньше и хэш-функции использовать но все равно мы их потом группируем как по кому-то еще признаку может быть я вам может не очень понял вопроса но у меня еще вопрос вот по первому алгоритму который был описан как я понимаю вы имплементировать и это все мы придется да и вот собственно вопрос когда мы делим все профили на бэнды и потом внутри каждого бренда применяем календарный метод ближайших к ближайшей связи on собственно в каком месте здесь происходит мы то есть распараллеливание вы кнн раз параллели уйти или задачи на бандах некая как я уже я уже делаю нет ни параллельно mapreduce таль коэн локально на машине на вычислительный да надо каждый из брендов собственно мы пить не не каждый к которым мы выбрали тогда я не совсем понимаю где здесь параллельность нет мы сделали мы сделали собрали бэнды выбрали тот band который удовлетворяет условию количество целевой аудитории количество аудитории после этого внутри уже этого банда взяли вот эти локальные группы посчитали к ближайшие соседи и относительно целевой аудитории и новой аудитории выбрать новую аудиторию ну собственно я уже использовали я не совсем понял то есть при киевском и где здесь применили как еще раз мы прийдешь мы где здесь применили applebee's мы применяли для расчета как раз ну собственно на предыдущем мы делали следующая операция мы сначала делаем макияж нас приходит профиль мы делаем хэш представления профиля после этого мы mensch представления разили на бренды выкинули в mapi ключ-значение от этих например значения в индия no reviews мы сгруппировали по ключу и знаем в каком это bundy ключ группировка по ключу и после этого уже после этой процедуры мы собственно уже собственно получили какие-то компактные группы кандидатов на сравнения ужас применяем операцию расчет расстояния только в этих более компактной группах но трасса от которых собственно де посчитать расстояние понятно то есть водка ближайшие соседи вы вы уже не 10 beauty можно же было и плавной планируем я думаю что тоже можно это дистрибутив но конец хорошо спасибо 1 вопросов больше нет и кипение можно отдельно подойти и спросить все что нужно да спасибо"
}