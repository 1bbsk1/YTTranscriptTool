{
  "video_id": "37cPVzoFIGw",
  "channel": "HighLoadChannel",
  "title": "Консервативный Backend на Node.js / Дмитрий Ляпин (Recrumatic)",
  "views": 11686,
  "duration": 3220,
  "published": "2018-01-16T13:12:15-08:00",
  "text": "отлично Меня зовут Ляпин Дмитрий я назвал свой доклад консервативный Кэн на Спасибо что пришли что выбрали мой доклад Я буду рассказывать про одну систему в которой Я участвовал в качестве архитектора и разработчика это платформа для рекв ли её делать ровно 2 года назад в июне 2015 года через 4 месяца был первый релиз то есть таким образом система чуть больше чем полтора года находится в продакшн а её за это время оказалось а достаточно удобно поддерживать и развивать и что что важно что не хочется сейчас существующий код взять выкинуть и переписать его с нуля А такое бывает не так уж часто поэтому я и рассказываю сегодня об этом продукте Перед тем как мы перейдём к непосредственно технической части я расскажу несколько слов о самом продукте чтобы вы понимали что же такое именно мы там реализовывали Для чего были приняты эти решения в первую очередь это сас сервис который предлагает рекрут инструмента первый инструмент - это односторонне видеоинтервью инструмент - это онлайн-тесты и третий инструмент автоматический планировщик А теперь немного Подробнее по каждому из них А вот так выглядит одностороннее видеоинтервью это такая возможность для рекрут создать анкету из нескольких вопросов и отправить ссылку на эту анкету кандидату кандидат откроет её через браузер у него включится веб-камера и он сможет записывать видео Отт а рекрутёр потом в удобное для себя время сможет просмотреть видеоанкеты а второй инструмент - это онлайн-тест онлайн-тест состоит из серии вопросов тут могут быть вопросы разных типов там выберите правильный ответ или выберите картинку или Заполните пропуски или Просто введите текст а всего у нас есть 12 типов таких вопросов тут Важно то что результат онлайн теста система вычисляет в большинстве случаев единственное есть исключение когда есть вопрос типа Напишите эсс именно эти вопросы рекрутёр должен как-то вручную оценивать ну и наконец третий инструмент автоматический планировщик до него доходят только те кандидаты которые не были отсеяли планировать собеседование онлайн собеседование через Skype или личные встречи у каждого рекрут есть такой календарик в котором зелёном Он отмечает время когда он доступен вот а так выглядит интерфейс для H он видит список кандидатов может их продвигать дальше видеть их результаты либо выбрасывать из процесса вот собственно Это всё что я хотел сказать про то что делает наш продукт дальше уже переходим к технической части архитектура системы крупным планом выглядит довольно-таки Просто у нас есть Single page Application на фронтенде и rest IP сервис на кде я сегодня буду рассказывать про архитектуру бэнда А мой доклад состоит из четырёх частей а по возможности эти части Я старался сделать не связанными друг с другом чтобы Вы могли взять что-то Одно только и не обязательно для этого было использовать три остальные рекомендации скажем так А если говорить кратко то цель моего доклада рассказать про простоту и Надёжность а No JS RP история номер один мы выбрали nodejs в первую очередь потому что предполагалось что на проекте будут работать СТК разработчики когда ты СТК разработчик То есть ты лазишь и на Кэн и на фнн то самая для тебя большая Боль - это переключение контекста ты что-то делал на бэнде ты перешёл на фронтенд ничего общего практически нет А И хотя бы если мы можем сделать такую небольшую но приятную вещь что если у нас будет один язык программирования и как следствие мы можем единый Style Guide взять то это сильно сокращает боль переключения контекста а также node JS для нас ценен тем что в нём есть асинхронный ввод-вывод и однопоточный вспомним Как работает классическая модель обработки запроса чтобы сравнить нам приходит запрос http запрос сервер для него создаёт новый поток или новый процесс смотря что у нас там за веб-сервер дальше начинается какая-то работа Да начинает процессор разбирать запрос дальше идт Дан Вот красная область это поток ничего не делает он ждт когда нам вот вывод ответит когда база данных пришлёт ответ Дальше он что-то сделал с этими результатами Ну допустим ему нужен второй отправить запрос базу данных он опять ждёт наконец получив эти результаты он подготавливает ответ отправляет их Всё окей тем временем пока это ВС происходило нам Приходи за под него был создан также отдельный отдельный сред и там происходило примерно тоже самое но мы ограничились одним запросом к базе данных тут может показаться что разница между синими и красными прямоугольниками не такая уж большая но Давайте посмотрим цифры на следующем слайде и вот обращение к оперативной памяти у нас занимает 100 наносекунд обращение к супер современному SSD диску 150.000 наносекунд если бы мы взяли старый диск тут в этой таблице его нет но просто скажу что если бы мы взяли не SSD диск А обычный диск то тут был бы уже порядок 10 млн наносекунд То есть это цифры совершенно несопоставимы И если бы я предыдущую картинку нарисовал в правильном масштабе то она выглядела бы так у нас было бы всё красное то есть мы всё время чего-то ждём Да и соответственно Спрашивается если мы всё время чего-то ждём То зачем нам в ДХ потоках Почему бы нам для этого не оставить один единственный поток Ну видимо это же заметили те кто придумал асинхронный ввод-вывод и теперь давайте рассмотрим как всё это происходит в У нас есть наш си сейчас будет те же самые два запроса первому запросу нужно два обращения к базе данных а второму одном вот пришёл первый вообще-то говоря синий прямоугольник здесь мог бы не заканчиваться то есть после того как мы обратились к базе данных мы не обязаны заблокироваться и ожидать результат мы могли бы продолжать какую-то работу но чаще всё-таки нам нужно получить ответ чем делать что-то дальше поэтому тут как бы мы ушли тем временем приходит второй запрос в тот же самый поток также обращается к базе данных потом начинается происходить ответы база данных снова к ней обращение тут готов нас второй респонс тут готов первый респонс всё хорошо на всех хватило одного потока но как бы очевидны плюсы что мы не тратим ресурсы на многопоточность или даже на множество процессов и не столь очевидны но не менее важны как бы обратная этого сторона Да она заключается в том что если какой-то синий прямоугольник станет действительно тогда ВС остановится То есть если нам потребуется сделать какое-то серьёзное математическое вычисление и это будет долго какой-то у нас большой будет вложенный цикл по какому-то прилично объёму данных гоняться то у нас встанет Всё у нас новые запросы сервер не будет принимать пока мы процессор не закончит эту работу а классическая модель она продолжила бы создавать новые потоки для новых подключений и как-то медленнее коне обрабатывала поэтому это важно понимать таким образом к nots можно сформулировать две основные претензии существуют Первое - это то что у нас есть всего один поток и мы не можем создать новый поток и что-то в фоне делать и второе - это так называемый callback Hell но а если вам не нужны длительные вычисления то это не является проблемой и вы имеете наоборот преимущество потому что Вы не должны ээ связываться с особенностями многопоточного программирования вам не нужно связываться с Текса вам не нужно делать Enter Critical section и заниматься вот этим всем достаточно болезненным сложным процессом Если же вам действительно нужны длительные вычисления то вы всегда их можете запустить в отдельном процессе и дождаться его завершения асинхронно а что касается проблемы которая называется callback Hell А я предлагаю о ней поговорить немножко сейчас подробнее и посмотреть какие есть Какие есть способы её обхода и Какие из них наиболее предпочтительны на сегодняшний день по моему мнению для того чтобы её продемонстрировать я взял из нашего репозитория функцию аутентификации пользователя Это команда sign in на вход нам приходит и пароль на выход мы должны Как бы отправить либо всё плюс некий ДСО с информацией которая нужна зарегистрированным пользователям либо ответи 401 до свидания как бы мы вы ввели что-то неправильные данные и Я подготовил четыре реализации первая реализация будет Как раз Call Hell и дальше три способа как как это написать по-другому а сейчас я буду объяснять что здесь происходит так кратко по слайду будет двигаться фокус как бы вчиться в этот код Сначала мы отправляем к базе данных запрос просто ищем нашего пользователя по имейлу как бы если мы его не нашли то сразу уходим на 401 ошибку если нашли то сравниваем хэши палей если они не совпали то опять же 401 Уходи если совпали то мы вызываем некую внутреннюю функцию которая не так важно что она делает важно что она также выполняется асинхронно и в свою очередь отправляет запросы к базе данных когда она завершится то мы сможем уже послать 200 Оке и с необходимыми данными которые нужны за залогинен наму пользователю что в этом коде как бы плохо плохо в нём во-первых то что нам везде приходится дублировать стандартную вот эту носку проверку ошибки и во-вторых мы видим что мы смеемся вправо Чем больше мы будем делать тем правее будет сдвигаться наш код Вот Но честно говоря этот код выглядит не так уж страшно на много подобного кода это это нормально когда приводят примера ко то обычно что-то такое несуразно как бы рисуют но трудно себе представить что человек в здравом уме такое напишет А вот такой код встречается и он как бы не идеален способ номер это на самом деле именно так как это сделано но сейчас я бы это сделал по-другому об этом мы поговорим потом просто на тут Важно помнить что Мы начинали проект 2015 году на тот момент как бы такой способ был предпочтителен А тут мы используем библиотеку ан она представляет различные инструменты управления потоком выполнения кода чаще всего мы пользуемся функции под названием как она работает она принимает массив функций которые выполняются последовательно асинхронно но последовательно друг за другом и каждая следующая функция в качестве аргумента а принимает результат который отдаёт предыдущая А тут мы видим что в принципе вот это вот смещение вправо исчезло Зелёная Стрелка показывает что всё хорошо в этом смысле но есть ээ такой Неприятный момент что нам пришлось вводить дополнительную переменную потому что между вот этими функциями нам некоторые данные нужно протаскивать как-то вот следующий способ с помощью промисов он хуже чем предыдущий способ потому что промисы не очень-то хорошо годятся в том случае когда нам из цепочки наших действий Результат где-то есть уже в середине и его уже можно вернуть но промисы заставляют нас как бы либо резолвится либо выбрасывать ошибку и по-любому должно быть продвижение дальше по цепочке поэтому тут приходится делать выбрасывать некий некий псевдо который я назвал бй и в конце проверять это вообще нормальный Exception или как бы нет И мы уходим в Next только если это не наш псевдо Exception Ну в Next что будет будет ошибка залогина и будет пользователю 500 выдан Вот Но промисы нам открывают другую возможность которая появи в 76 использовать синтаксическую конструкцию он evate так что-то фонит так это нормально что сейчас происходит А да в nons 76 Появилась возможность использовать конструкцию asn Weight то есть мы по промис можем ждать когда он зарез вится и этот код выглядит так как будто бы он был синхронный хотя на самом деле он асинхронный это называется со программа Когда у нас ну подпрограмма - это такой кусок кода в который есть одна точка входа а со программа такой кусок в который есть несколько точек И вот на каждый EV У нас тут появляется дополнительная точка входа и тут всё здорово Тут видно что кода уже значительно меньше и выглядит он так как мы привыкли Это видеть там в каких-то других языках программирования но опять же есть небольшая проблема на самом деле мы не можем сде ком потому что большинство библиотечных функций в том числе функций стандартной библиотеки nots не работают с промеса на данный момент а работают с колка соответственно эта функция не возвращает нам промес но есть способы это обойти Если эту функцию обернуть с помощью инструмента который берёт функцию вида который работает с промеса и возвращает функцию то есть Берт функцию вида которая работает с колми и возвращает функцию которая работает с промеса раньше для этого использовались различные сторонние библиотеки но в node.js версии 8.0 которая вышла вот буквально на прошлой неделе появилась у нас возможность сделать util promisify То есть это в стандартной библиотеке есть такой инструмент который превращает функцию работающую с калб ками в функцию работающую с промиса И по ней уже можно делать aight то есть сейчас уже есть все возможности писать код так и конечно стоит это делать потому что это выглядит гораздо лучше чем предыдущие варианты Давайте на них ещё раз посмотрим как бы вот то есть 18 строк - это лучше чем 26 Следующий вопрос который я хотел бы рассмотреть в первой истории это проектирование рест путей тут мы допустили одну ошибку в результате которой через месяц примерно программирования многое пришлось переписывать для того чтобы подойти к этой проблеме рассмотрим сначала несколько простых примеров очевидных вот допустим хочет получить информацию о компании номер 123 путь выглядит следующим образом тут понятно вопросов к нему Нет а как ему ещё выглядеть Теперь мы полезем внутрь этой компании и посмотрим какие в ней есть интервью Ну тут тоже вроде тоже всё нормально а теперь мы хотим залезть внутрь отдельно взятого интервью этой компании и получить допустим видео Отт и начале мы делали что наши пути выглядят вот так как вы считаете Есть ли тя проблема Если есть то какая какая А проблема тут такая что фронтенду с этим работать очень неудобно потому что И то и другое обе эти цифры - это уникальные идентификаторы Да и нам не нужна вот эта 123 нам Достаточно знать идентификатор интервью чтобы чтобы получить на него ответы вот тут оказалось что просто да люди которые работали на фронтенде взвыли от того что им непонятно откуда было брать лишние идентификаторы всё это было неудобно и ну как бы на бэнде это тоже стало очевидно через какое-то время что как-то всё идёт не так а сейчас кажется вроде бы абсолютно очевидным что надо делать именно так Тем не менее мы такую ошибку допустили примерно через месяц достаточно много кода пришлось переписывать и после чего мы стали руководствоваться правилом что нужно в путях использовать минимально возможное количество ID Ну тут как бы на всякий случай хочу отметить что это именно пути к нашему кду То есть это не те пути которые пользователь в браузер видит да А те пути которыми фнн обращает посылает команды к API сервису Вот на этом первая история заканчивается как бы итоги тут такие можно подвести что во-первых ЕС то нужно понимать что есть у нас всего один поток и поток этот блокировать надолго мы не можем иначе всё встанет использовать As сегодня уже можно начинать как бы новые проекты которые этим пользуются и нет причин этого не делать Ну и как я говорил про пути что не нужно нужно туда сувать лишние ID вторая история называется данные и SQL вот буквально передо мной Тут в соседнем зале High Николай Самохвалов читал Очень классный доклад про в которой как раз Обозначил эту мысль и развивал её и вот с его тезисом что сердце системы - Это суд я абсолютно согласен хотел бы его повторить на своём докладе что сердце как бы система - это Это суд всё остальное я считаю неким неким фасадом и исходя из этой парадигмы Мы мы выбрали у у нас у нас на проекте пагс как бы Почему пагс Потому что во-первых нам нужна реляционная СУБД А реляционная нам она нужна потому что для нас важно иметь возможность свободно выбирать данные то есть смотреть на них по-разному а не только таким способом каким они скажем были созданы да то есть допустим если у поста есть комментарий то мы только можем получить комментарии этого поста как бы нет нам важна Свобода нам важен язык который хорошо для этого подходит который позволяет нам гибко выбирать данные SQL - Это очень хороший язык который который специально для этого создан Ну и во-вторых нам важны транзакции нам важна предсказуемость си при многопользовательской работе именно мы выбрали потому что он хорошо решает эти задачи реляционной базы данных также у него сильное сообщество В том числе российское и то что в нём есть тип JB который даёт реляционной базе необходимую гибкость который Ну которой честно говоря е не хватало Потому же не на пустом месте появились Да допустим есть у нас карточка компании и нужно мне туда добавить какое-то малозначительных никакого особенного значения не несёт когда разговор заходит про реляционную базу данных то чаще всего задают люди вопрос Какая у вас урм как будто бы само собой Разумеется что если вы используете реляционную базу данных то вы должны пользоваться ум я с этим Категорически не согласен Я участвовал в некоторых проектах где использовались РМ и всегда всегда это было большой проблемой особенно большой проблемой это становилось со временем Чем дольше шло время тем больше росли данные тем большей проблемой была У потому что она генерирует много запросов больше чем на самом деле могло бы получиться и потому что она генерирует неэффективные запросы она не может составить такие же эффективные запросы которые вы руками Напишите потом если мы уж говорим про nots то последняя часть этой аббревиатуры слово Пинг тут не очень-то актуально получается для жава скрипта либо какого-то другого динамического языка Потому что у нас нет статических классов нам не нужно мапить ни на что мы получили рекорд и это сразу наши объекты мы сразу с ними совершенно естественным способом можем работать Итак мы не используем м пишем чисто SQL запросы и у нас есть для этого четыре помощника первый помощник - это на собствен большая библиотечка также помогают SQL представления триггеры и красивая схема теперь немножко Подробнее по каждому из них А вот так выглядит обычные типичные типичное обращение к базе данных из нашего бэнда на node.js тут используется метод нашей библиотеки Q который отправляет в базе данных текст запроса массив массив каких-то параметров которые используются в запросе в кобе получается массив строк запросы у нас обычно небольшие но они были бы большими если бы мы не использовали представление красным здесь отмечено имя представления как раз то есть вот большинство запросов имеют примерно такой размер Для чего собственно говоря нам нужна наша библиотека Она работает поверх такого довольно-таки стандартного для nos решение которое библиотека под названием ПГ но на е представляет некоторый сахар нам помогает то есть допустим если нам нужно не массив строк а какой-то одно поле то есть такой метод как Q value или же если нам нужны какие-то примитивные варианты инсертов апдейт То для этого также есть вот такие вспомогательные методы Но если нужно хоть как-то что-то усложнить то есть Delete допустим не По условию что ID равно чему-то А По условию там что что-то равно чему-то и что-то другое больше чем что-то то это нужно уже возвращаться к методу и пользоваться им и на самом деле мы в основном используем Именно его мы Сначала думали что у нас будет много простых запросов Но оказалось что их на самом деле не так уж и мало не так уж и много мало помогают представления благодаря представлениям во-первых мы получаем высокую повторную используемой того кода который мы в них пишем и во-вторых компактность кода и читаемость тут фиолетовыми кружочками я Обозначил вычисляемые поля То есть как мы поступаем появляется какое-то поле которого как бы нету в столбцах наших таблиц в первую очередь мы думаем А можно ли это добавить в представление И если это можно добавить в представление А в большинстве случаев это именно так то мы идём и добавляем это поле в представление благодаря этому мы можем это использовать в разных местах нашего нашего потому что как бы он везде как таблица мы на него ссы Мы можем с ним Джони мы можем как угодно его использовать следующий Помощник Помощник номер три триггеры Мы не очень-то часто пользуемся триггерами но В некоторых случаях они прямо очень полезны Один из таких случаев - это ну тут я расскажу как у на устроено хранение файлов об этом поб позво для того чтобы этот пример Прочитать это тоже важно сами файлы мы храним на S3 а в базе данных У нас есть табличка с некой Мета информацией по файлам она называется Медиа на эту таблицу ссылаются другие разные таблицы а в таблице Media У нас есть такое поле под названием Links Это счётчик ссылок когда счётчик ссылок становится равным нулю То есть у нас специальный фоновый процесс который такие записи соответственно про Селект удалит их из S3 и удалит их из таблицы управлять в каждом случае использования файлами Было бы очень неудобно этими этим полем Links А вот сделать триггеры на каждую таблицу которая ссылаются на файлы и сделать чтобы при вставке Links увеличивался а при удалени Link уменьшался оказалось очень удобным мы это как бы сделали и забыли про это мы просто пользуемся этим как буд как будто бы поля Links нету то есть оно вся сложность связанная с ним инкапсулировать по одному триггеру на каждую таблицу которая ссылается на Медиа следующий помощник очень важный это красивая схема базы данных я её назвал и как бы действительно а действительно много сил и труда тут фрагмент этой схемы вся бы она никак не уместилось мы много труда потратили на то чтобы эту схему делать И хорошо что мы начали делать с самого начала когда таблиц было ещё не так много и Честно говоря я лично был против того я не понимал Зачем делать столько работы мышкой Когда можно вроде бы как открыть файл schema.sql и там как бы текстом тоже же всё написано нормально можно прочитать Но нет слава Богу другие люди были против и мы сделали эту схему и через через пару месяцев я понял что просто я на самом деле открываю этот файл вот эту картинку каждый день когда начинаю работать перед тем как написать какой-то запрос Я смотрю на эту картинку поэтому это трудоёмкий процесс особенно если вы хотите чтобы у вас стрелочки были по ровнее чтобы они как можно меньше изгибались как можно меньше пересекались и чтобы всё это так выглядело симпатично Но это того стоит есть для этого несколько различных сервисов Мы в частности используем vert рекомендую этим пользоваться неважно какой вы сервис для этого возьмёте или просто будете рисовать там в паинте это дальше я расскажу уже в завершении этой истории о том как тип JB нам помог помог нам иметь в нашей схеме на 24 таблицы меньше чем чем их могло бы быть как я уже говорил у нас один из типов испытаний - это онлайн-тесты онлайн-тест в свою очередь состоит из вопросов 12 типов и вот всю разницу типами вопросов мы убрали в поле под названием Data которое имеет тип JB также есть ответы на вопросы и там тоже структура этого ответа она в принципе зависит от типа вопроса и тут у нас есть тоже самое поле дата с типом JB это разные даты в вопросах и в ответах но важно то что у нас 12 типов структур дата для вопросов и 12 для ответов Если бы не было джисона то нам пришлось бы делать 12 разных таблиц для вопросов и 12 разных таблиц для ответов А тут мы имеем такую гибкость что база данных не знает о том сколько у нас вообще есть типов вопросов мы можем Добавить новый тип вопроса никак не касаясь базы данных ничего в ней не меняя а всей этой спецификой касающейся чем типа вопросов отличаются друг от друга этим занимается уже not JS backend и frontend по-разному это ото для ба данных это неважно И это в данном случае очень удобно Подводя итоги второй истории хочу Ещё раз сказать что SQL - Это мощный выразительный язык который который нужно знать лучше его любить и им чем больше им пользоваться тем тем лучше будет работать ваш энд Если вы используете реляционную базу данных то есть не нужно это отдавать на откуп инструментам которы делают неявное важно Нарисовать схему Это поможет писать запросы поможет понимать ваши данные Ну и как я говорил Jon B добавляет реляционный базам необходимую гибкость которую которой пользоваться удобно третья история называется J веб токены Кто кто знает как устроен Web toen Ну не все я в любом случае планировал рассказать как они устроены поэтому хорошо что не все руки сейчас оказались подняты Web - это такая штука такая последовательность букв и цифр которая вот вы видите с левой части экрана они она разделена точками состоит из трёх частей на самом деле это закодированный в 64 первая сть это там нет ничего интересного вторая часть - это там содержатся полезные данные в этом примере я взял We наш авторизационный и в полезных данных ну во-первых есть полезные данные которые присутствуют во всех токенах это время создания токена и время его истечения дальше Вы можете добавлять скоко угодно своих присутствует льва нам ничего не нужно нам нужно знать только ID пользователя и последняя очень важная часть - это подпись подпись - это некая функция которая вычисляется от заголовка от полезных данных и от секретного ключа который известен только серверу мы используем J веб токены в трёх сценариях для то есть вернее не для а вме сессий для выдачи го временного гостевого доступа и для загрузки файлов теперь немного Подробнее по каждому из сценариев как у нас происходит аутентификация пользователя он в своей формочке вёл email вёл пароль и фнн отправляет на эн вот такую вот са in команду пост запросом отправляет туда email и пароль мы уже смотрели Что именно он там делает в четыре целых реализации этого видели а но в итоге он сформирует в том числе Jon Web token и вернёт его фронтенду внутри этого токена в полезных данных будет только ID пользователя при всех последующих запросах а frontend будет передавать вот такой заголовок такого вида в котором содержится токен то есть там на самом деле содержится ID пользователя Кэн видит ID пользователя и он может ему доверять Если бы мы тут написали просто ID пользователя передавали то очевидно что это было бы совершенно небезопасно потому что можно было бы frontend мог бы отправить ID любого пользователя а тут он отправляет подписанный токен в котором внутри содержится ID пользователя который однозначно пришёл от бэнда потому что никто другой не знает секретный ключ А конечно М использование ДВТ вместо сессии - это не Панацея хорошего тут то что сессии нам не нужно хранить на сервере то есть нам не нужно в нашей базе данных для этого таблицу иметь или нам не нужно пользоваться каким-то хранилищем типа дис для этого что часто делают а но мы имеем обратную сторону что мы практически никак не можем управлять нашими сессиями то есть мы не можем допустим Взять и увидеть список активных подключений потому что мы просто не знаем у нас нет сессии в нашей базе а также мы не можем взять и убить какую-то отдельно взятую сессию Единственное что мы можем сделать это изменить секретный ключ тогда одновременно отвалятся все сессии То есть все должны будут перелоги но нас это устраивало в принципе что что у нас нет возможности мониторить всех подключенных пользователей кого-то прицельно убивать поэтому для нас важнее тут оказалось то что нам не нужно хранить эти сессии потому что это такая как правило самая активная таблица самые активные данные - это вот обновление вот этих вот сессий подключений логины логау у нас как бы всего этого нет следующий сценарий - это гостевой доступ когда соискатель прошёл интервью то у него есть ответы как бы уже на это интервью то рекрутёр с помощью пользовательского интерфейса Может отправить кому-то ссылку на это интервью Ну типа посмотри там какой какой интересный кандидат Скажи мне какое-то мнение о нём какому-то не зарегистрированному пользователю для этого формируется такая короткая с человек по ней идёт frontend в итоге загружается по какому-то такому ул это не д ween Это наша короткая ссылка такая восьми символьная последовательность что происходит Дальше поскольку ннд пока не знает что эта короткая ссылка означает он посылает команду к Кэн и спрашивает энд А что это за короткая ссылка такая Расскажи мне пожалуйста но он идт в базу видит там информацию по этой сл вид что это ссылка для того чтобы предоставить гостевой доступ к интервью И помимо прочей информации которая нужна для этого действия фронтенда отправляет токен который При следующей команде также будет использоваться для авторизации пользователя и этот токен позволит Не будучи юзм системы получить доступ именно к этому интервью есть по с этим токеном нужно делать а наконец третий способ как мы используем эти токены мы их используем для загрузки файлов представим ситуацию что какая-то что администратор какой-то из компаний решил обновить логотип у своей компании что он для этого будет делать А В первую очередь Он отправит методом пост логотип к бкн Он backend увидит этот логотип положит его на S3 и добавит в таблицу с файлами после чего вернёт фронтенду токен внутрь которого зашит идентификатор этого файла из таблицы файлов пока он этот файл ни к чему не привязан следующим этапом frontend уже пошлёт команду которая обновляет логотип у отдельно взятой компании и отправляет этот самый полученный токен тоже самое можно было бы сделать проще если бы мы просто сразу вернули бы ID файла и тут бы мы как бы отправили ID файла но в этом есть проблема мы могли бы взять ф мог бы взять Не свой а чей-то чужой ID файла который также может быть ещё пока ни к чему не привязан Потому что его только что загрузили и таким данным не мог бы доверять А вот этому токену он доверяет потому что он сам его подписал уб по что единственно У нас есть метод который отправляет пост с контент тапом отличный от джисона все остальные методы гоняют туда-сюда дн данные и не заморачиваюсь о знании того что нужно ещё какие-то файлы куда-то отправлять для этого существует всего один метод и дальше это используется везде вот таким аналогичным способом а Подводя итоги этой истории А Я хочу сказать что нам подошло использование ДВТ вместо сессий но оно подойдёт не всегда также ДВТ оказывается удобен для других задач там где нам необходимо как-то подписывать подписывать наши данные иметь гарантию того что это те данные которые дал нам сервер Ну и уже финальная история моего доклада небольшая история про Медиа Сервис продолжая тему с файлами пользователи загружают контент в том числе картинки различные страницы фронтенда одну и ту же картинку показывают по-разному в разных размерах и существуют различные в принципе способы жизни с этим наиболее распространённый способ иметь сразу необходимые версии картинок при загрузке то есть пользователь добавляет картинку мы сразу готовим её в тех размерах которые нам нужны Но это не гибко потому что дизайн в любой момент может измениться могут появиться новые страницы в котором картинка в каком-то новом размере оказывается и поэтому у нас есть такой специальный медиа-сервис который нам масштабируется картинки на лету он выглядит следующим образом то есть принимает команды следующего вида что мы Обращаемся к к некой картинке и сразу же есть здесь даём известную ширину известные размеры которые мы хотим получить размеры тут могут быть любыми и картинка будет создана Как это работает алгоритм такой что в первую очередь Когда диасервис видит такой запрос он проверяет кэш если в кэше такой картинки ещё нет то он берёт оригинал натт на него Image Magic который делает нам картинку в нужного размера делает Рей и кладём в кэш после чего делаем Директ то есть в итоге вот такой вот URL у нас а среди тица На кэш в который мы собираем картинки кэш тут совершенно необходим Потому что если бы мы на лету генерировать картинки бы при каждом обращении то это Это просто бы не работало как бы мы по наш процессор был бы занят постоянной обработкой графики А тут это гибкое решение которое работает быстро и картинки формируются а только По мере того как они возникает в них потребность как к ним реально кто-то обращается Но конечно Этот алгоритм сильно упрощённую что-то подобное тут Важно помнить о двух о двух вещах первая вещь - Это то что нужно ставить блокировку когда чтобы если так получилось что по одному и тому же URL Вам пришло примерно в одно и то же время два запроса чтобы вы не собирали одну и ту же картинку два раза Это первое и второе что может прийти а кто-то злой и написать скрипт который будет Вот перебором вот эти числа зелёные как бы от там единицы и до бесконечности вам значит создавать в разных комбинациях и ваш кнд умрёт потому что будет тоже занят постоянной работы формирования этих новых картинок и будет переполняли легко решается с помощью белого списка а В смысле не IP адресов а размеров картинок вы потому что через какой-то время попользоваться на продакшене там или даже до этого в принципе можно посмотреть в кэш и увидеть какие какие реально есть размеры и их добавить в белый список и потом обычно дизайн уже меняется не так сильно и когда он меняется можно просто добавить будет новую строчку в этот белый список и как бы будет вся та же гибкость но достаточно защищенная на этом всё Подводя выводы вспоминая все четыре истории что хочу сказать что самая главная рекомендация не использовать РМ знать SQL научиться им пользова Если вы этого не делаете и очень хорошая вещь которая поможет сильно ускорить А сильно ускорить ваш кнд и очень сильно упростить отладку А ну и если вы используете node.js то тут Важно помнить про то как устроена его асинхронная модель про то что там всего один поток про то что мы не имеем права его надолго блокировать иначе всё остановится на этом всё спасибо готов ответить на вопросы здравствуйте Спасибо вам за доклад и у меня такой вопрос насколько важно было в вашем проекте обеспечить высокую производительность для других пользователей и насколько много уделили вы этому внимания а в данном проекте это не тут как бы у нас совершенно обычное количество идт запрос секунду Поэтому с какими-то проблемами лода мы здесь не сталкивались но в целом выбор должен нам позволить упростить масштабирование когда эта потребность возникнет просто из опыта вот S зачастую вот парсинг самого SQL требует достаточно времени в том числе делает й То есть как быль запрос пар один раз Потом это уже становится йм который не нужно базе данных повторно парсить отправляется в базу данных уже непосредственно просто имя сй и параметры хорошо и раз вы упомянули про синхронное программирование измеряли ли вы производительность пров и прочих вот синхронных подходов Нет я эту производительность Не измерял потому что как я говорил в нашем сейчас бэнде реализован способ который работает с колми и с использованием библиотекой ан вот эти способы которые появились буквально Да ну без пре процессоров пользоваться анв Мы можем с февраля этого года вот поэтому конечно сейчас внедрять переделывать старый проект чтобы переехать на это я думаю не стоит и к тому же действительно с производительностью з есть некий некое негативное влияние но как я говорил всё это совершенно незначительно по сравнению с тем временем которое запрос проводит в базе данных то есть вот это такая экономия на спичках здесь была бы хорошо понятно А вот ещё При использовании токенов для загрузки файлов как Вы намерены бороться с невостребованными картинками то есть они загрузились потом у клиента потерялось соединение и оно остались на сервере Да я вот когда рассказывал про триггеры там был как раз пример что у нас в таблице с файлами есть такая такое поле Links Это счётчик ссылок и есть процесс фоновый который ходит по этой таблице и все файлы которые были загружены дольше чем определённое время назад и на которых никто не ссылается удаляются хорошо спасибо у меня больше нет вопросов Спасибо за вопрос Здравствуйте Скажите пожалуйста а у вас not JS как backend основной стоит или перед ним н используете а перед ним используем jing да то есть каширование в н джинсе ещё у вас настроено Да нет НС ничего не каширу Нет просто он именно для балансировки нагрузки Да идёт да для балансировки нагрузки только Ну и для https в первую очередь то есть https через н работает ещё один маленький вопрос А по поводу видео Вот вы не говорили рекрутёр же видео Могут своё загружать его как-то обрабатывайте у себя на сервис для работы с видео мы используем сторонний сервис он называется Zig Geo Он позволяет нам встраивать видеорекордер в своё приложение и процессинговая еся и копируем это на свой S3 вот так такой workflow а Спасибо за доклад Я здесь хотелось бы узнать А где всё это у вас дело крутится у вас к докер или полноценная Тачка на которой всё завернутое это амазонок машина то есть всё в амазоне да у вас не Да мы используем вообще много амазонок сервисов там начиная от виртуальной машины заканчивая отправкой емейлов там в общем много для чего они у нас используются активно то есть вы не захотели свой зоопарк вот этот ве строить и выбрали уже в том числе pasg это у нас Amazon RDS как бы работает на Amon RDS Поэтому нам это просто администрировать у нас нет специального системного администратора как бы администрированием у нас в том числе эн разработчики занимаются то есть я захожу на в Панель управления амазона что-то там создаю новую instance RDS и всё это просто короче для этого не нужно каких-то супер хардкорных знаний лисо Ну вы же как-то балансирует всё равно собираетесь на будущее какие-то у вас есть реальное видение проекта или замыкай на том что сейчас есть у вас сервисе Нет это это достаточно легко балансирует То есть это теми же средствами амазона Да можно сделать балансировку что один домен обращается к нескольким виртуальным машинам и они у нас абсолютно й эти бэнды вот Ну а что касается инстанса базы данных то он должен быть один Ну и Amazon RDS обещает что он может быть достаточно большим по крайней мере нам надолго этого хватит Ясно спасибо Здравствуйте Вопрос такой вот вы говорили то что используете перед соответственно статику Вы тоже сдаёте тику С3 раздаём А я понял то есть смысл в том что в этом как раз был вопрос что и или вы про НН я говорю про картинки которые вы динамически генерирует то есть смысл в том что Ес какие-то есть за я показал бы это А нет не сломался вот смотрите А у нас также для кэша используется S3 то есть мы делаем Директ когда ннд обращается к этому Rail в который он через параметры передаёт размеры картинки ему посылаются 300 первы 301 Директ на amazon На кэш который у нас в Amazon S3 это в случае если картинка уже сгенерирована да А если не сгенерирована вы Гене не сгенерирован то он сделает тоже самое только не сразу а пару секунд подождать придётся всё понял А ещё один вопрос можно вот смотрите вы говорили про токены которые используете для верификации запросов Ну в том числе чтобы не подделывали пользователи свои шники соответственно сессий хранить не нужно больше но хранить токены нужно всё равно вы храните их в основной базе данных или в ради сами токе тоже хранить не нужно в токене нам ционный токен то мы просто лезем внутрь токена там р ID содержится Да юзеры в базе данных есть то есть когда нам приходит запрос мы знаем какой пользователь это этот запрос отправил я понял то есть вы вот этот дишни вы его генерируется на стадии регистрации пользователя То есть он как статичный получается ID пользователя Да ну там 1 2 3 4 ну как как как первичный ключ базе Да спасибо ещё вопросик а выде используете Ко и соответственно евошний Да роутер и так далее или всё-таки старые ещё какие-то нет нет мы не используем коа потому что мы используем модель колков то есть мы используем экспрес потому что мы в 2015 году это начали и как бы мы не переписывали это всё в феврале Когда появился Син сойм Ясно Ну во втором такого то же самое всё можно писать во втором что коа я про коа говорю а ну во втором коа - это который со Син советами работает уже да да дадада да да Ну да да я знаю мне кажется что до этого им пользоваться смысла как бы вообще не было Потому что вот этот вот синтаксис с генераторами мне совершенно не нравился как бы ну мы мы планировали дождаться Осинка Айта и как бы и дождались Ясно Ясно спасибо спасибо за доклад такой вопрос Вот вы в начале сказали что когда вы принимали решение о стеке технологии для вас одним из критериев было то что можно было Вот человеку стек заниматься и разработкой на Note JS и на фронтенде Но вот сейчас Note Ну как бы уже восьмая версия Note Да она поддерживает такое огромное количество вещей которых там браузером ещё далеко Там шагать шагать Ну с исключением Хрома может быть а вы ограничивается соответственно как-то Ну там не знаю А я не понял что вы имеете в виду по поддержку то есть Ну использование чего именно синтаксиса языка или что Ну да в том числе Не ну frontend сейчас же тоже никто так не пишет его же все там бабеля при процеси туда Ну то есть все пишут на современном языке и при процес его как бы в es5 Ну то есть всякие там но не мы на самом деле у нас frontend в es5 Понятно спасибо Всё спасибо спасибо за внимание"
}