{
  "video_id": "lnD4o25Qok4",
  "channel": "HighLoadChannel",
  "title": "Аномальные случаи высокой нагрузки в PostgreSQL, и как мы с ними справились / Михаил Жилин",
  "views": 268,
  "duration": 2242,
  "published": "2023-10-06T07:19:32-07:00",
  "text": "Всем привет Меня зовут Михаил Жилин я из компании постга с профессиональной и сегодня мы поговорим об аномальных случаях высокой нагрузки в плоскость квилль Так ну что это вообще такое нормальные случаи Так у нас база данных подрасквель всем известно как хорошо работающая под высокими нагрузками выполняющие четко свои задачи и иногда бывает так что вроде все должно уйти как по маслу но неожиданно наши ожидания К сожалению рушится Вот как раз это и есть Аномалия которых мы сейчас и поговорим немножко о себе во-первых Меня зовут Михаил Жилин Я инженер по производительности Также люблю иногда по контрибьютить в Open Source различные как суббоды операционной системы Java приложение все что угодно Все это нравится вот и сегодняшний доклад я буду конечно строить в первую очередь а реальных случаях когда нагрузка явно просто пробивает отрас всегда начинает вести плохо Мы лезем туда со всякими инструментариями гвоздями ножами и так далее Разбираем этот случай вскрываем его анализируем находим проблему пытаемся понять как бы эту проблему решить снова погружаемся снова находим прекрасное решение и выдаем В итоге в некоторые там решения наружу иногда не выдает увы начнем мы в первую очередь инструментария чем же мы все-таки пытаемся как бы вот эту всю нашу проблему проанализировать база данных потребляет два основных ресурса это процессор и диск процессор это такой черный ящик который стоит где-то там на материнке в серверной в дата-центре далеко от нас и чтобы понять что происходит в нем внутри К сожалению на микроскопа недостаточно нам нужны инструменты профилирования самым известным инструментом профилирования является в linuxpr он доступен во всех инструментах дистрибутивах но есть еще другие БПФ более продвинутые старые и так далее прекрасный инструмент перв умеет профилировать все что нам нужно но единственный с ним вещь то что это все-таки инструмент себе он минимален он выдает наружу много текстовой информации которую может быть даже десятки мегабайт которые просто так глазками просмотреть и понять Ага вот она проблема вот здесь указать нее невозможно И тут на помощь нам приходит система такого вот она анализа и визуализации инструмент Flame Граф написанный бренданом лет 10 назад и он умеет генерить вот такие вот красивые картинки как показано на слайде справа если кому интересно погрузиться в тему профилирования именно после современными инструментами есть прекрасный доклад Дмитрия Долгова конференции этого года пиджакон Юра 2022 ссылочка вот по qr-коду есть Кстати я забыл сказать что в конце у вас будет ссылка на эти же слайды поэтому не обязательно их там фотографировать все у вас будет сразу же Итак едем дальше перв прекрасный инструмент сразу можно запрофилировать любую операционную систему набрав два слова perf пробел топ и сразу же видим какие функции занимают Больше всего времени в ядре процесса в процессоре и можно уже какие-то первые выводы сделать иногда нельзя сделать потому что причина проблемы находится в функциях которые вызывает данные функции и они скрыты сами по себе и Нам нужен полный стек вызовов и сэмплировать его с некоторой частотой например 99 Герц в этом случае помогает такая вот маленькая шпаргалка которая представлена данном слайде который выводит уже мегабайты данных которые мы отправляем slamgrap и получаем прекрасный результат виде вот тех свг картинок как был на предыдущем слайде но здесь надо сразу сказать два момента первый момент чтобы получить качественный результат профилирования по адреса нам нужны Пакеты дебаг-инфо дефолтные пакеты содержат обрезанную информацию об функциях хищных функциях возгласа И когда вы запрофилировать вы ничего не получите По сути никакой информации поэтому первое ставим дополнительно пакеты дебаг-инфо второе это то чтобы получить качественный стек вызова хищных функций из бинарного стека лучше всего использовать библиотеку либо онлайн это прям библиотека который то единственное его сейчас в opensort который лучше всего строит стеки зачастую Бывает так что дефолтный перв который предоставляется пакетом дистрибутива собран без библиотеки без поддержки это либо онлайн и надо будет вручную пересобирать первым хорошо клёво инструмент у нас есть Давайте посмотрим а какие на примере чего мы можем вообще с ним с помощью него сделать вот здесь на картинке сразу показано Ну что мы здесь видим свг внизу видим метр функцию Getz nevshot дата Ага интересно что-то непонятное но мы знаем что она потребляет Больше всего времени судя по этой картинке она вызывается из другой функции г- транзакшнэпшот А там уже вызывается из экзеквал символ экспресса Хмм интересно Ладно берем идем в Google вбиваем Вот этот экзайку Simple Expression и понимаем что это функция выполняет некоторые простое выражение не в самом погребе а дополнительным экстеншине который называется plpg SQL хорошо читаем дальше в Google нам в помощь Что такое простое выражение в пыль в коде это Например I равняется плюс один Что такое Неужели простые выражения так долго выполняются особенно какие-то вот это снапшот дата вызывает читаем дальше И выясняем что оказывается до 13 после любой вот такой вот простое выражение требовало генерацию с нимка о снимок что-то новенькое вот Давайте теперь про снимки почитать лезем в документацию И что же мы там видим что снимки нам нужны для того чтобы организовать изоляцию транзакции чтобы мы как работающие с базы данных не видели тех людей клиентов которые тоже подключились к СУБД и нам мешают тоже там что-то меняют данные и так далее то есть для режима транзакционной изоляции Ну ладно хорошо это не так интересно что же вообще-то снимок что это такое Оказывается можно на него даже взглянуть это есть специальная функция ПГ Коран снэпшот который нам возвращают что x-min минимальное значение активной транзакции x-max это будущее транзакция которая только-только вот сейчас генерится и список активных транзакций список всех активных транзакций в системе Вообще легко его собрать вообще вот этот список всех транзакций интересный вопрос Ну что же мы еще узнаем Из документации что генерация данных снимков зависит от того какой режим работы с базой данных мы выбрали по умолчанию это ритметит и снимок генерится на каждый запрос Ну можно сказать репетита был Рид и тогда снимок будет генериться только раз в начале транзакции если у нас очень длинная транзакция которая делает там десятки сотни вызовов то мы можем получить экономию на генерации снимков просто переключив сессию нашу в репетабарит Ну ладно хорошо давайте Вернемся все-таки вот к сложности построение вот этого снимка раз он уже занимает много времени процесс процессоре Ну блин узнаём что до четырнадцатой версии чтобы получить вот этот снимочек нам нужно было перепройти по всем подключенным клиентам и посмотреть у них статус а клиентов Сколько может быть Ну десятки тысяч подключений к базе данных легко это активных транзакций Ну бывает даже на два порядка меньше то есть ну там десятки сотни и узнаем что в 14 версии сделали оптимизацию которая позволяет не обходить всех под все подключения а только посмотреть список активных транзакций его выделили в отдельный массивчик и с помощью него теперь генерится другая проблема пока мы генерируем совершать мы получаем так называемый блокировку что мы читаем данные об активных транзакциях и другие транзакции к сожалению они могут добавить в этот массив получается немножко ограничиваем масштабирование так вот что же нам сделать делать Ну во-первых если мы видим у себя в результате профилирования данный метод гэтснет дата то смело бежим обновляемся до 14 послеза там все уже хорошо А если не помогло Ну не помогло конечно не очень хорошо Давайте попробуем тогда уменьшим частоту генерации этих снапшотов с помощью там например опять же того же самого репета баллорид Ладно транзакции транзакции на транзакций тут транзакций там но оказывается выясняется иногда что в плоскость существует не только транзакции А еще такие называемые под транзакции многие о них даже вообще не подозревают что они существуют пока в один прекрасный день они с ними не столкнутся например во время какой-нибудь инцидента Когда в продуктовом контуре неожиданно производительность всех запросов читающих пишущих резко просаживается в разы и что делают Ну как у нас же есть прекрасное представление вьюха ПГ стат-активити там же написано что чем занимаются процессы Давайте посмотрим в неё там есть колонка Ожидание и видим там может быть с Автотранс Control может быть просто саптранс может быть саптранс и с л рулок что-то их очень много развелось последнее время этих локов Ну вообще-то все гораздо проще просто до 13 версии были вот эти разные Локи а в 13 версии их заменили только одни саптрансы с рулоком ладно завтра Завтра что это такое снова идём в документацию и видим там что сам транзакции нужны для того чтобы организовать выполнение команд Save Point или же в каком-нибудь языке программирования типа PL или SQL или PL Java или PL V8 или перл реализовать механизм трайкач Забавно А что же вообще такая по транзакции чем она отличается от обычной транзакций она по сути та же самая транзакция то есть точки зрения инвестиций снимков так далее это обычная обычная транзакция Только у нее есть еще родитель Кстати этот родитель может быть тоже под транзакцией это получается у нас такая целая цепочка дерево этих под транзакций А как проверить статус транзакции по транзакции закомить или нет но наверное надо проверить свой статус и наверное самый статус родителя вот показ родительская транзакция не закатится вот транзакция нет тоже не закомилась и нет котилась усложняется получается статус проверки нашей транзакции Ну ладно давайте подумаем вообще что там у нас как она и вообще работает в постгрейси вшаренной памяти есть такой прекрасный массивчик называется прок Рэй в нем Выдели на 64 элемента под под транзакции для каждого подключения дальше эти 64 по транзакции собираются в одно снимок и в снимке уже используются для того чтобы проверить транзакция заканчилась или не заканчилась информация в общем все хорошая Ну окей Ну тут стоит вопрос А что если у меня в подключении шестьдесят Пятая под транзакция человек получу ошибку нет нет мы можем посмотреть на конечно же на диске в папочку ПГС там вот сохранится вся информация родительских транзакций для каждой транзакции Ну она конечно хранится не всё время там не за всю историю база данных как вакуум например почищать старые строчки так и чекпоинт подчиняет информацию с ПГС Ну хорошо Блин она каждый раз ходить на диск это же блин вообще расточительство блин читать с диском Давайте нет введём какой-нибудь кэш вели кэш l.ru выделили 32 буфера по 8 килобайт на под транзакции Ну получается туда вмещается 65.000 транзакций уже с одной стороны хорошо а с другой стороны Подождите ну 65.000 транзакций бывает так что за секунду пробегает на высокой нагруженном контуре и в наш кэш вообще попадёт совсем маленькая часть того чекпоинта который зачистил эту таблицу вот вам домашнее задание Попробуйте на своем каком-нибудь самом боевом контуре посмотреть сколько у вас транзакций в этой папочке Но что же нам делать вообще Что за проблема у нас вообще встречаются Ну кроме маленького размера slruksha есть еще и вторая проблема чтобы найти вот этот Блок из 32 нужный нам нам надо к сожалению перебрать все и посмотреть внутрь каждого это наш блок похоже не наш следующий так далее так далее так далее и на это тратится очень много процессорного времени если честно такая проблема со всеми силурукашами не только для пол транзакции но еще для мультитракции и тому подобное и проседания в результате вот такого вот постоянного хождения в кэш на диск И конечно мисов может достигать просто в разы Ну хорошо давайте подумаем теперь что же нам делать Ну самый простой вариант который интуитивный понятный не использовать больше чем 64 под транзакций в рамках одной транзакции тогда мы не будем уходить в эти каши и диски и так далее Все будет хорошо Но если не получается то решили как-то все-таки решить проблему с рук Иша вот те как раз две проблемы его маленький размер и линейный поиск для этого предложили пальчик в мае двадцатого года Андрей Бородин отправил его в ПГ хакерс который позволяет администратору базы данных самому сказать сколько нужно кэшировать с помощью параметра если кейл а также улучшил поиск вот этих буферов в SLR с линейного на бинарный Ну хорошо пиши к ишами Погоняем мы это Мы все знаем А Какие еще бывают клише Ну примеру есть кэш системного каталога системный каталог это просто наш набор табличек индексов информация о колонках их размерах и так далее используется этот каталог в первую очередь для чего для того чтобы выполнять запросы по их парсить разбирать и планировать вот так иногда оказывается что наше планирование оно выполняется довольно таки долго появляется это в первую очередь например когда вы заглядываете в топ и видите что ваши все основные процессы занимаются выполнением никаких то есть команд А команды Вот либо же заглянуть в ПГС от statements и там есть отдельная колонка называется Total planning там для каждого запроса и вы можете понять сколько же запрос планировался Сколько реально выполнялось Ну ладно хорошо системный каталог кэш системного каталога Зачем он нам Наверное чтобы быстро планировать и разработчики позгресса вместо того чтобы каждый раз ходить на диск они занесли информацию об этом системном каталоге даже не в шареную память а сразу в локальную память отдельных процессов каждого подключения И если нам Ну когда подключение только создается кэш пустой мы зачитали с диска сохранили в кш и эту информацию держим у себя долго в память но иногда приходят какие-нибудь другие подключения говорят Альтер тейбл Эд колум и нам надо информацию о табличке которая хранится в нашем клише поменять это так называемый сделать инвалидацию кыша инвалидация бывает два типа первая по табличная как я вот сказал там колонку и надо Вот сбросить информацию только по колонке бывает глобальные Ну когда надо сбросить весь кэш Ну и все такие инвалидации они генерации в результате выполнения DD или dml и усилите команд Ну мы же все знаем что в постггасе ddl транзакционный значит если кто-то выполняет Альтер тейбл эдколом то не надо бросаться сразу рассылать всем инвалидацию кэша другим процессам А надо подождать конец транзакции вдруг наш транзакция откатится и ничего не надо валидировать поскольку Это вся природа такого вот инвалидации США носит такой бродказ характер потому что нам надо всем сразу разослать то разработчики по адреса придумали отсылать так называемые сообщения через шареную память и хранят эту информацию в циклическом виде циклического буфера из 4.096 сообщений когда другие процессы выполняя начинают выполнять запросы или там открывают relation то есть периодически заглядывают в этот циклический буфер и смотрит нет ли новых сообщений для него и Если есть то выполняют то или иное действие но бывает так что процесс немножко Там потупил подвис и так далее а тут за это время уже 4.000 сообщений сделали Круг и старые сообщения начали перетираться то для таких процессов оставляется специальный флажок Типа все Извини парень ты отстал сбрасывай свой кэш который ты там накопил гигабайт информации и перечитывай заново это так называемый ой печаль заключается в том что такие запросы начинают такие подсоединения начинают резко тормозить как раз таки на планировании и нам что же делать в первую очередь уменьшать количество ddl команд постгры с прекрасная база данных для того чтобы сравняться с ltp нагрузкой вставлять запись удалять и так далее Она изначально не предполагалась для того что еще бы еще каждую секунду создавать и удалять тысячи таблиц Поэтому если вам нужна временная табличка создать ее в начале сеанса подключение и Используйте сколько вам нужно 5 10 100.000 не надо их в каждой транзакции удалять создавать по тысяче Ну и вторая проблема здесь которую я хотел бы подсветить то что в ванильном возрасте К сожалению нету механизма мне неизвестно как вообще мониторить эти инвалидации есть единственный способ который я знаю это вот расширение ПГС ПГ простат который входит в состав ПГП про стандартный Enterprise которая содержит информацию о том как часто разные стейтменты генерят вот эти сообщения инвалидации и как часто происходит эти ресеты то есть мы можем вообще контролировать наконец-то и мониторить это механизмы на валидации Но кроме этого есть еще так называемый антитюнинг антитюнинг заключается в следующем что заглядываешь иногда параметры Видишь там выставлены параметр Ford параллело мод равняется он считаешь документацию и видишь этот параметр заставит все запросы выполняться параллельно звучит очень хорошо клёво всё станет Работать быстрее наверное Ну вообще Надо подумать А если запросы маленькие мелкие то есть каждое подключение будет пытаться выполнять его параллельно создавать дополнительных параллел воркеров эти параллеловокеры Будешь ждать пока они выполнится параллель worker должен форкнуться подгрузить информацию о системном каталоге выполнить спланировать что-то выполнится В общем начинает дико все тормозить второй антипат антитюнинг это параметр debug discard cash который просто говорит не используя системный кэш оба этих параметра относятся к так называемым параметрам для разработчика ни в коем случае не стоит их использовать в промышленном контуре потому что разработчики создали для себя для того чтобы сформулировать ту или иную нагрузку для цели разработки девелопмента Так ладно Идем дальше пиши к ишами процессоры греются и бывает так нам приходят случаи когда CPU в сто процентов лоу тэвордж почти уже сотня при этом Как видно по топу больше всего времени мы проводим в так называемом kernel Space то есть в пространстве ядра на сервере ничего не крутится кроме постгрыса никакие другие процессы не могли На это повлиять Значит сам подсказ находится постоянно в пространстве ядра вот здесь видно что 88 процентов времени мы проводим в системе Ну что поделать вспоминаем правило надо заглянуть в процессор это черный ящик а для него есть перв а для перфа есть два слова perf топ Ну вот запускаем наш команду 1 и видим что видим да много методов в пространстве кернов и называются эти функции азишные аудит подчеркивания что-то там заглядываем в документацию ядра линукса и видим что это некоторый функционал для того чтобы мониторить системные вызовы и их куда-нибудь логировать можно в сеть можно на диск можно еще как-то Ну и первая наша рекомендация Попробуйте пожалуйста отключить этот мониторинг вызовите команду Control минус и 0 хорошо проходит полчаса и проблема Как не бывало юзер тайм вырос с 10 до 17 System упал 8 раз и как оказалось по проверили правила вот этого самого настройки аудит системы и выяснили что Видимо безопасники просто немножко накосячили написали немножко неправильно правила безопасности и выкатили на данный сервер тем самым испортили производительность вот сразу помог выяснить Кто кто виноват но бывает так что админы очень бдительные следят за своим продакшеном внимательно и постоянно смотрят как раз таки вот в это представление ПГС от Activity и заглядывают в него и смотрят там что происходит Все ли нормально происходит и тут неожиданно выявляют выясняют что все активные подключения неожиданно начали ждать ожидание клайнтри И бегут к нам говорят слушайте У нас тут какой-то клайнтрит вроде системы себя ведет нормально TPS хороший все хорошо наш мониторинг не ругается но при этом мы же видим что вот есть какое-то ожидание непонятное клайнтрит на активный запросах странно как так что это такое Мы вроде как бы выполняем запросы с другой стороны Мы вроде читаем клиента Ладно документацию смотрим все вроде ничего не такого не описано как бы за странность такая документации нету лезем в код а в коде выясняем что данные ожидания выставляется и внутри библиотеки и говорит о том что мы сейчас отдыхаем наш процесс ничего не выполняет и мы ждем когда сокет Читающий станет доступным когда клиент отправит к нам какие-то бантики Ну например запрос или вызов комит или еще что-то а мы просто Сидим и ждем как только ожидание Ну сокет станет доступным мы никуда не убираем хорошо Может быть тогда статус неактивный запросы может быть просто криво отображается но смотрим когда выставляется активный статус проверили в начале любого нормального действия он выставляется А как только мы доходим до метода secureit он перед этим сбрасывается То есть получается Согласно коду мы не можем быть одновременно и активными и читающими клиентовские пакетики Так что ж тут тогда не так может быть наше представление тогда неправильное ПГС это Activity мы заглядываем внутрь а как оно вообще работает а вот и видим что ПГС тактилити собирает информацию ни за одного места а из двух массивчиков первый массивчик называется Back and status Ray и хранить себе информацию А какой запрос выполняется В каком статусе сейчас выполнение Какие ip-адреса подключения время начала транзакции тому подобное то есть такая медленно меняющаяся информация и быстро меняющаяся информация из массивчика про э Рей и там хранится как раз информация об ожидании То есть он из двух этих массивчиков слепливает представление и выдаёт наружу но Беда в том что он слепливает это информацию не одновременно и может быть так получиться что у вас новые релиз они ребята всё потемнели всё постарались запросики начали выполняться быстро и они выполняются настолько быстро что статус остается по-прежнему активным а через некоторое время мы читаем из прокара информация она там уже оказывается ожидание клиента в результате погасло Activity вот так вот немножко криво показывает нам информацию про пачек мы уже отправили получили фидбэк сейчас его перерабатываем отправим снова пачек в комьюнити Надеюсь что 16 версии или там семнадцатой примут И это всё исправит Так ну это все хорошо давайте перейдем вкусу а вкусно нас индекс вот самое вкусное в космосе это конечно индекс первое а-а проблема которая сегодня хочу рассказать это индекс onlyscan вообще это операция позволяющая читать из данные из базы данных не заходя при этом в табличку то есть обычный индекс что делать находит по ключу Где находится данный в табличке потом идёт в табличку и выбираю выбирать нужные данные а индекс он говорит о том Ну слушай всё что просили меня достать из базы данных ну в селекте все эти Колонки есть в индексе нам не нужно лезть в таблицу Давай сэкономим себе заход все есть в индексе и вот как бы получается Он быстрее чем просто обычный индекс can но тут есть беда в постгрессе как мы знаем в индексах не хранится информация о транзакции то есть x-min X Max те самые которые нам нужны для снимков чтобы проверить что строчки все видны Ну Ответ простой Давайте сходим в табличку там же хранится информация Так подожди Зачем нам ходить в табличку в индексуальной скании если мы вот как раз хотим чтобы он был все-таки индекс поняли сканом и мы не ходили в табличку блин Что же делать придумали такой вот оптимизацию под названием визибилитимат в этой это очень компактное представление об информации об транзакциях для которой выделен один Бит 2 бита на блок один из бит которых говорит о том что вот в этом блоке все строчки хорошей не нужно проверять x-minx Max они уже все готовенькие забирая их они все видны Ну прекрасно Да вот поняли что два битабильте Map на один блок таблицы на 8 килобайт это же прямо сжатие прямо в разы а один блок везде биллите МАПП 8 КБ соответствует 256 Мб А таблицы но тут есть маленькая беда индексон как выяснилось умеет работать одномоментно только с одним блоком а что это означает вот если мы захотим выбрать из индекса скажем 100 строчек для очень большой таблички в терабайт вот мы выбрали 100 строчек и начинаем смотреть первая строчка а для ней вот тут везде билеты мап блок а для второй строчки одни из другое место и так далее То есть нам приходится перескакивать с одного блока на другой индекс от этого не очень хорошо мы придумали патчик отправили его в комменте сейчас я не буду вдаваться в детали а просто покажу результат результат покажу на простом тесте создал табличку из одной колонки ID просто численная колонка туда залил 60 млн строчек и хочу Выбирать из этого Из этой таблички все строчки в упорядоченном порядке то есть по возрастанию написал простой запрос ордер бай ID из таблички тест и запустил что я вижу прошел за 60 миллионов строк за 18 секунд отличный результат всё зашировано всё прекрасно 18 секунд туда еще может быть лучше а применяем наш патчик и время резко падает в два раза до 9 секунд Профит Профит все хорошо ну как бы все бывает прекрасно в нашем мире все хорошо но бывает такое что некоторые проблемы мы еще не смогли решить но мы о них уже знаем мы их нашли и Одна из таких проблем называется индекс во внешней части лупа все знают вот такие простые слова индекс внешней части плова всё хорошо Ну как бы исходный запрос я не здесь не буду показывать он очень сложно и непонятный Там и так далее но есть простая способ Как симулировать эту ситуацию сгенерительностью плод и так чтобы он заходил создаём маленькую табличку я её специально назвал Вот который там содержит условно там 10-20 записей по ней индекс просто по данной колонке И вот так вот с помощью генерить Series и нескольких отключенных инструкций захожу в этот в эту табличку 5 миллионов раз Ну проверяю план вроде хороший nested loop есть индекс во внешней части есть Loops проверяю сколько раз зашел я в этот индекс тоже 5 миллионов время отличное смотрите время-то две секунды все шикарно Что еще можно желать лучше 5 миллионов за 2 секунды Ну прям прекрасно Ну подождите это же я зашел вот выполнил запрос только в своём подключении А что если таких как я сотни Ну представить да Ну ладно давай запускаем бенчмарк и видим что время начинает линейное расти запросы То есть если я один выполнял запрос это было 2 секунды А если таких уже 10 то это уже 30 секунд Ого то есть время растет Линейная система не масштабируется то есть я ожидал бы что вот я выполняю запросики и все они параллельно отдают одно и то же время Подождите вы скажете У тебя мало ядер нифига у меня здесь самый современный скей третьего поколения 24-ядерные и все весь процессор просто начинает больше и больше больше кушаться от того что я добавляю больше воркера все больше больше греется процессоров Ну и второе подтверждение проблемы это вот график А сколько раз в секунду мы смогли Во всей системе зайти в этот индекс а график даже начинает немножко падать То есть он не должен был расти масштабирование должно быть линейное а никакого линейного масштабирования нет вот на одном запросе уже нет масштабирования Ну к сожалению вот такие бывают проблемы в заключении Я хотел бы отметить что позглиз SQL база данных которая постоянно развивается как функционально в ней добавляются новые фичи команда мерши сон и тому подобное так и по производительности Как вы видите вот с 12 до 14 версии очень много было введено новых изменений и будет так продолжать дальше жизнь перформанс инженер вообще очень удивительно Мы сначала берем черный ящик потом Делаем его белым потом понимаем что он сломан потом его чиним очень долго и упорно и получаем огромный когда он начинает работать хорошо и завершить наверное доклад хотелось бы короны фразы Олега бортунова нужны слайды Вот как раз тот qr-код который я обещал вот это ссылка на те слайды звали Меня зовут Меня Михаил Жилин Прошу вас достать свои телефончики и голосовать вот помощью вот этого qr-кода заданный доклад если он вам понравился то лайк не понравился дизлайк любой фидбэк Спасибо вам огромное Спасибо большое Рука уже поднята Кто быстрее Ну ладно ты быстрее я бы на таких ножках тоже бегал но у меня другие пожалуйста Спасибо за интересные доклад не значит ли Вот эта работа вокруг индекса что в воздухе пора сделать индексные организованные таблицы как это кое-где есть а может быть но лучше решать конкретную проблему и ускорять конкретно ее потому что ну как бы вот запрос есть и от него уже никуда не деться он где-нибудь еще наверное выстрелит поэтому лучше исправить его тоже пожалуйста Спасибо большое за интересный доклад возник вопрос по субтранзакции затронули больную тему и хочется спросить вот это вот пачка который Владимир отправился общество Он уже вышел и анализировали какой прирост производительности он дает то есть Он решает проблему или все-таки транзакции надо отказываться патч он уже есть он впг хакерс его идет обсуждение он дает прирост однозначно он улучшает sl.ru конечно позволяет закошировать но идут по параллельной дискуссии например Давайте избавимся вообще перенесем все shad batis и пока комьюнити не придет к некоторому горизонту Согласие он не будет принят то есть да он помогает Вот ждем когда все придут к единому мнению сложная но интересная так следующий спасибо Вот Будешь добрый Михаил Спасибо за доклад сейчас Российские компании начинают Ближе ближе микрофон Российские компании начинают смотреть на риск файф платформу вот Занимаются ли постгры с Professional с портированием постгарса на рисква и в том числе оптимизация Вот давайте кулуаров обсудим Вопрос хороший но Ну пожалуйста еще Сейчас я посмотрю что там в чате даже можно в чате вопросы задавать вы пока Подумайте друзья о чем спросить еще три два один и наш супер просто приз уходит автору вопросы про под транзакции Да а Магните рукой пожалуйста вот сейчас наши коллеги вас найдут тебе тоже памятные призы от ручкой лоуда Спасибо мне друзья 18:00 здесь будем продолжать танец вокруг баз данных на этот раз уже с Яндексом но кто-то приходите послушать кто-то потроллить В общем все будут счастливы в конечном итоге однозначно Я кстати придумал как перед поездкой в Ереван можно говорить Может говорить спасибо спасибо"
}