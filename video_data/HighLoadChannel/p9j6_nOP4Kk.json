{
  "video_id": "p9j6_nOP4Kk",
  "channel": "HighLoadChannel",
  "title": "Безболезненный Fallback cache на Scala / Олег Нижников (Tinkoff.ru)",
  "views": 2197,
  "duration": 3033,
  "published": "2018-08-16T05:00:23-07:00",
  "text": "добрый день всем собравшимся и перед тем как я начну вам рассказывать какой же совершенно безболезненно фбк мы в тиньков сделали на скалам прошу поднять руки всех тех чья архитектура полный соответствует реактив манифеста и составные части приложения могут масштабироваться не ограничены с возрастанием нагрузки независимо друг от друга и выдерживают падение любой знак вот вы свободны но помимо этого вы поймете нашу основную боль связанную с появлением системе вот таких вот слабых мест таких вот слабых не масштабируемых кусков возможно это что-то что вы купили возможно какое-то партнерское предложение но на делают очень важную часть работы которую вы сами пока сделать не можете и у вас возникает вопрос что ж с этим сделать как же обеспечить хайло так и какие-то части явно для хайло да не предназначены или были предназначены для хайло до лет десять-пятнадцать ну что то приблизительно так какие-то цифры показывают что ваше приложение возможно работает очень очень быстро при взаимодействии этим брендом но все равно backend делает основную часть работы внутри себя он перемалывает большую часть данных и несмотря на то что ваше приложение очень сильный масштабируем а вот эта часть совершенно никак не масштабируется и вы думаете каким образом можно ослабить мне нагрузку но первая идея вы берете какие-то данные которые вам нужно только читать в кито запросы которые вас получают данные и делаете кэш на уровне каждой ноты in-memory естественно как живет пока надо не перезапустится и хранит только это последнюю часть данных то есть если у вас приложение отказывает и заходят какие нибудь пользователь новые которые не заходили последний час день неделю у вас естественно приложение ничего не можешь с этим сделать второй вариант вы конкретно сделать какой-то прокси который берет на себя часть запросов либо каким-то образом модифицирует в общем работу продолжения немного помогая ей но в любом случае вы не можете вот в этом прокси просто за само приложение делать всю его работу и в качестве третьего варианта вы рассматриваете вот такой хитрый случай когда какую-то часть данных которые у вас ваш backend возвращает вы скажем так можете надолго положить в какой-нибудь хранилище и когда они у вас понадобится даже если они в этот момент будут уже не актуальны клиенту это будет лучше чем ничего показать именно вот про такое решение мы сегодня и рассказываем этом наша библиотека фон bph для тех кто не сторонник скалы не любит скалу мы постараемся минимум времени уделить сама искал нас будут небольшие кусочки коды которые вы сможете перевести на любой язык на котором вы разрабатываете основная знаю что вы получите из этого доклада это в общем принцип в общем идею каким образом сделать что-нибудь у себя на своей стране выглядит наша библиотека плетеного так у нас есть какие-то какой-то общий функционал который касается fall back а у нас есть большой кусок посвященный со взаимодействием с этим хранилищем у него есть две важные такие компоненты компоненты которые отвечают за процесс непосредственно инициализации то есть каких-то предварительных действий что-то нужно сделать поговорит с о б д при перед тем как собственно можно поезд fall back и шум и некий модуль генерации автоматических реализаторов то есть у вас есть какие-то запросы они где-то уже посередине продолжения пользуется каким бы типами промежуточными чтобы хранить состоянии ну чтобы сын так плыть в это в этой форме выражайте данные которые получились кэндо течение одного или нескольких запросов у вас есть какие-то параметры которые вы отправляете какой-то свой метод какие-то данные которые получаете от туда и вот эти все данные нужно каким-то образом месте реализовывать чтобы хранить их нашем хранилище для того чтобы вам нужно было сделать минимум работы и вы могли просто взять кусочек кода и в 1 действии обернуть для этого нужно вот эти данные каким-то образом хитро стерилизовать чтобы их можно было хранить в базе данных вот за это отвечать такой модуль и плюс мы воспользовались паттерном церковь breaker которым посвящена еще один отдельный кусочек приложений нашей библиотеке которому вам расскажем вот так выглядит в общем наша библиотека собственно какие же хранилище мы рассматривали ну нам во первых нужно было этику это хранилище который может хранить данные достаточно долго потому что какие-то портили какие-то действия могли представить очень давно и нам все это время нужно хранить их где-то там то есть нам не подходили in memory но и memory нам больше не подходили вследствие большого объема данных то есть это может быть от сотен гигабайт до десятков таро байт данных которые нам нужно в этом как сохранить может быть и больше с дальнейшим ростом из-за это вот такая сильно разветвленная все это хранить в памяти не очень эффективны потому что большей части данных не запрашивается постоянно надо очень долго лежит ждет своего юзеры который зайдет и спросит нам естественно нужно чтобы наша свобода была постоянно доступна в отличие от нашего сервиса и чтобы с ними происходило на оставалось доступным нам нужно чтобы при внедрении нашего решения мы минимум какого-то overhead и терпели вследствие того чтобы дополнительно что-то отправляем наш кэш и в качестве такого дополнительного бонуса хорошо бы чтобы наша база данных была расположена к тому чтобы хранить чтобы возможно вытаскивать не целиком кусок данных а допустим point интервал например там список лечить людей 2 историю пользователей с такого-то дня по такой-то поэтому чистый киева илью возможно нам не очень подходит в качестве альтернатив мы рассматривали да еще естественно так как это очень сильно сужает список мы делаем некоторые ограничения предполагая что мы уже реализовали все другие вещи мы предполагаем для чего нам нужно конкретно fall back ешь мы предполагаем что мы не пытаемся сохранить целостность между двумя разными get запросами поэтому если они отображают два разных состояний которые друг друга мне консистентные мы пожалуй смиримся с этим нам не нужно таким образом инвалидизировать эти данные потому что в момент когда запрашиваться предполагаешь носки из какая-то последней версии мы ее показываем что было бы хочет хоть чтобы что и соответственно нам заранее известно более менее данный которым отправляем в этот backend и данные которые оттуда получаем как они собственно устроены с каких полей состоять наш прозрачной структуры и в качестве альтернативы мы рассматривали три основных варианта это кассандра благодаря своей доступны сока доступности и очень легкой масштабируемости и механизму сериализации за счет коллекции которые были добавлены во второй версии с появлением секрет и unity которые были добавлены в третьей версии или в конце второй которая позволяет опять же очень эффективно складывать структурированные типы то есть у детей это used define type означает что у вас есть некий тип вы заранее знаете какие у него есть поля эти поля для стерилизации помечаются каким-нибудь отдельными тегами и вот как например в 3 вт или протокол батерс и вы прочитав эту структуру можете на основании тегов понять какие у вас поля есть и вам достаточно метаданные чтобы понять как эти поля называются и что у них у каждого польза тип дальше естественно кассандра имеет помимо вот этого пар тишинке дополнительный класс string и то есть специальный ключ пузыря которому данные упорядочиваются на одной ноги что позволяет собственном реализовывать в эту дополнительную опцию виде интервальных запросов и кассандр в общем то вот относительно долго существует на рынке длине есть много решение мониторинга и в общем говоря все более менее известно ну и в качестве минусов многие в этом зале могут рассмотреть оживаем как она не все считают как самый производительный вариант для платформ на которые можно написать су бдк какой-то вверх от как какие-то проблемы с garbage collection нам и так далее средства альтернативный второй второй вариант мы рассматривали как бейтсон точно так же у нас обеспечит высокую доступность хорошо масштабируется просе реализацию надо думать гораздо еще меньше это такой как бы трейдов и плюс и минус нам не нужно в общем контролировать схему данных у нее есть глобальные индексы которые точно также глобальным уже образом по кластеру позволяют нам запускать какие-то интервальные запросы и само по себе коуч bass в общем говоря представляется в таких гибрид дико к обычной соды прилеплен memcache который позволяет кэшировать автоматически все данные которые есть на ноги самой горячей точке высокой доступностью поэтому она благодаря своему кашу может быть очень быстро если у вас одни и те же данные запросу запрашиваться очень часто этот схема лес и джейсон может быть также и минусам потому что за кажущейся простотой скрывается тот факт что если у вас зато длительное время пока хранятся данные приложения изменится и структура данных которые он собирается сохранять и читать тоже изменится может быть так что предыдущей версии у вас будет несовместимо и вы об этом узнаете только на момент тени они на момент например разработки данных может данные там лежат на продакшен и нужно думать каким же образом правильно мигрировать старых данные а это именно то что мы не хотим делать особо сильно задумываться добавляя какой-то очередной кусочек какой-то очередной связь с нашим брендом покрывая нашим footbag кашу и следующий вариант это тарантул он славится своей очень-очень большой скоростью у него есть замечательный движок lua который позволяет писать кучу логе который быть нового jit исполняться прямо на сервере но с другой стороны это такой в общем модифицированный киева илью данные хранятся в кортежах теплых и нам нужно самим думать как их правильно и реализовывать это может быть не всегда очевидны и задачи и также ней специфический специфический подход к масштабируемости сейчас мы поговорим в чем проблема если говорить о подходах вот шар lingerie плетей шин а нам он наверное нужен нашем приложении то кассандру нас предполагает такую структуру обычно зайца кольцом то есть нас есть много нот каждый но да хранит какие-то свои данные которые принадлежат плюс данные с ближайших not с ближайших нот в качестве реплики и если одна из нот выбивая выбывает но ты рядом с ней могут в равной степени обслуживать ее ее часть данных пока сама но да не поднимется таким образом за sharding applications отвечает одна и та же структура если нам нужно например сделать rush радировать на 10 кусков и хотим сделать рип личный фактор 3 нам достаточно будет 10 вот собственно каждая надо будет хранить две реплики соседних not есть коуч bass у него похожим образом устроена структуры между взаимодействие есть данные которые помечены вот символом актив за который отвечает сам аноды есть реплики соседних not которым также себя хранит если одна но дух убивает соседней ноды по которым мы 1 шар деле берут на себя ответственность за обслуживание вот этой части ключей а вот в tarantul и архитектура сделал похоже на мангу где бы только немножко вывернута то есть у нас есть какие-то шарден группы и они друг друга реплицируются таким образом вот если как на картинке нам например захочется сделать четыре шарда и плетей шин фактор 3 нам для этого потребуется 12 нот они вот 4 как в случае предыдущих двух арте тур это конечно компенсируется наверняка скоростью работы который тарантул гарантирует но тем ни менее специфика и новизна вот только из за того что вот только только недавно когда мы это внедряли появились модули опциональные для шарден гафта ранд или мы все-таки в качестве нашего основного кандидата выбрали свобода кассандра и говоря субботы кассандры мы вспоминаем о том что мы говорили о ю специфической сериализации о том что протокол sequel он предполагает что вы определите схему данных она морда свободно определено вам нужно ее определить ему и мы можем использовать это в качестве преимущество то есть стерилизовать данные таким образом чтобы наши развесистые структуру с большими длинными именами полей вот эти имена полей не хранились каждый раз в наших значениях чтобы у нас были некие метаданные которые рассказывали как у нас устроено данные и плюс сами судите сами юзер define types рассказывали какие же метки какие же теги соответствуют полям с какими именами поэтому автоматически генерируемые цивилизации происходит пройдите вот по такой схеме если нас есть один из базовых типов которые мы можем один-в-один поставить соответствие ему типа с базовых мы так и делаем у нас есть набор типов int long string дабл который в общем то есть один в один в кассандре если нас в какой структуре случается опциональное поле мы ничего дополнительно не делаем вот ровно в то ваш должно прощаться это поле ровно в то ровно такой же тип мы для него и превращаем просто в структуре будет храниться на у и на уровне детализации если мы найдем нам в нашей структуре мы предположим что это нас отсутствие значения дальше все наши типы коллекций у нас скале их большая-большая большой набор плохо видно мы превращаем в тип лист упорядоченные коллекции у которых есть вот некий элемент соответствии с индексом неупорядоченные коллекции которые гарантируют наличие ровно одного элемента с каждым значением сет у нас дальних that опять же в кассандре существует специальный тип сад если у нас есть какой-то mapping у нас естественно и скорее всего очень много в особенности со стрингами ключами у нас в кассандре точно также есть специальный тип fmap для этого и он точно так же типизированный имеет два параметра типа так что мы можем любой ключ для него сдать любой соответствующий тип и дальше у нас есть какие-то определенные типы данных которым уже определяем сами в нашем приложении часто во многих языках их называют алгебраические типы данных то есть типы данных определенную с помощью двух операций 1 это определение именованного произведения типов то есть структура вот такую структуру мы один в один будем ставить соответствие юзер define тайпу то есть каждое поле структуры будет соответствовать одному поле в нашем юзер define the pit если носить алгебраическая сумма типов но то есть это такой тогда тип ему соответствует несколько подтипов или под разновидности заранее известных мы также определенным образом будем ставить ему соответствие структуру сейчас посмотрим так и так у нас есть какая-то вот структура и мы отображаем и и вот как видите один в один для каждого поля определяем для нее поле в нашим создаваемым видите нашей кассандре соответственно примитивные типы превращаются в примитивные типы ссылка на какой-то заранее уже определённый у нас до этого тип приходит фроузен это значит это специальная специальный такой вейпер в кассандре означающий что мы не можем читать из этого поля по кусочкам то есть он весь в мороженом вот в это состояние мы можем только целиком сохранить туда юзера или целиком сохранить список как как случае стайками либо целиком прочитать и если мы начальнику это опционально и поле мы отбрасываем тот факт что она опционально берем только вот тип данных соответствующий тому что у нас зайти поле будет честно если мы встретим здесь нам то есть отсутствие кого-то значение мы запишем в соответствующее поле на ул и точно также при чтении будем брать соответствие на умном если мы встречаем некую некий тип который имеет несколько заранее известных альтернатив тогда мы определим точно также новый тип данных кассандре и для каждой альтернативе альтернативы определим поле в наши в нашем типе данных наших детей и вот в этой вот структуре в результате только одно из полей в каждый момент времени будет не на ул то есть если мы встретили какой-то тип юзер и он нас фронтами оказался что the instance модератора у нас более модератор будет взывать к это значение остальные будет нам если если будет админ слышно админа остальные будет нам это позволяет нам собственно вот таким образом закодировать структуру нас есть четыре опциональных поле мы сами гарантируем то что записано будет них только одно а тот факт что кассандра использует вот всего лишь один тег для того чтобы идентифицировать что конкретно и поле наличествуют структуре мы получаем такую структуру хранение без верха до то есть фактически для того чтобы сохранить тип юзер если нас тут например модератор потребуется вот тоже количество байт который нам нужно для хране модератора + 1 байт для того чтобы показать какая именно альтернативу нас здесь присутствует ну и собственно поговорим обо инициализация как же устроен этот процесс процессе инициализации то есть вот такой прозрачный процедуры к предварительной процедуры которую мы должны выполнить до того как мы можем пользу нашим футболкам мы должны сгенерировать у нас на в каждой ноги на основании вот тех типов которые нас представлены определения таблиц типов и подготовить запросы внутренне подготовиться сгенерировать текста запросов дальше мы читаем что у нас сейчас есть субботы в кассандре мы можем легко это сделать просто подключившись к ней во всех практически драйверах когда мы подключаемся сам объект цесис выкачивает метаданные кие space и которым он подключен и дальше мы можем посмотреть что у нас есть в этих метаданных дальше мы продвигаемся по этим метаданным проверяем что все что мы хотим создать у нас разрешенного что можем сделать некую инструментальную миграцию если ты все нормально если у нас инициализация возможно успешно мы ее выполняем и подготавливаем в конце запросы все наши такой препарат statement кто не знает что такое препарат стоит над собой все знают происходит это по таким образом нас есть какие-то типы которые могут зависеть от других типов которые в свою очередь и других типов вот такой рекурсивный процесс дальше на сиськи этой таблице который зависит от из типов и водки и ты запросы которых зависит уже от таблиц из которых они читают данной инициализация проверить эти зависимости и создаст всу где все что может создать повод определенным правилам если как как же мы определяем что мы можем инкрементальный как мы говорили мигрировать тип мы читаем как у нас сейчас с обода этот тип определен если нас вообще он из него вообще нет и мы узнаем что мы придумали какой-то новый тип который дает у нас уже не существовали мы просто запускаем клей type как он есть если нас уже такой тип есть мы пытаемся сопоставить поле за полем существующие определение с тем которым мы хотим этому типу дать если мы выясняем что мы хотим добавить просто несколько полей которых уже не существует мы так и делаем мы создаем список собственно вот таких матирующих операций altera type и запускаемых если так получается что у нас есть какое-то поле который нас было другого типа например у нас был лист стал мэром или у нас он ссылался на один юзер define type а мы пытаемся сделать в другим мы предполагаем а мы генерируем ошибку эту ошибку разработчик может увидеть еще до того как он запустит функционал на продакшене предполагаешь там точно такая же схема данных есть в его development среде он увидит что он он каким-то образом создал не мигрируем схему данных и может переопределить вот автоматически сгенерируем и добавить какие-то автоматически генерирует реализацию добавить какие-то опции перри миновать какие-то поля или переименовать все типы целиком и таблицы так чтобы избежать этих ошибок соответственно представим что как же у нас собственно проходит инициализация под в отношении типов представишь нас есть какие тут определение ских типов кейс класс это ну вот тоже самое что например страх в растянул просто класс который содержит набор набор полей кто не понимает вот что написано с калле с этими структурами данных все больные не понимают да все нормально мы создадим вот сгенерируем вот придите на такие определения данных для каждого из четырех типов то есть то что мы хотим в итоге провернуть как видите у нас тип юзер offers зависит от типа offer at всем видно хорошо как видите тип юзер offers нас зависит от типа offer лидер продуктов тоже зависит от типа типа продукт здесь ошибка и ядер продукта зависит от типа продукт и your info зависит от второго и третьего типа то есть нас кредит на вот такая зависимость между типами и мы хотим их каким-то правильным образом инициализировать вот здесь на схеме показано что мы будем уникализировать ебут юзер offers юзер продукт параллельно это не значит что мы на самом деле запустим два параллельных statement а мы все утверждения все анализы будем запускать последовательно для того чтобы мы случайно не пытались создать в двух параллельных потоков один и тот же тип но у нас есть некая параллельность на уровне разруливания ошибок если нас например произошла какая-то ошибка вот в типе от которого все зависит все что от него зависит потянет за собой эту из на исходную ошибку которую мы в самом начале получили если у нас только какой-то из параллельных ветвей сгенерирует ошибку все что зависит от нормально мигрируем их данных будет сгенерирован без ошибки то есть если там дальше будут определением таблиц при повисает метать них мы сможем спокойно вот эту часть нашего фонда каша инициализировать и нам нужно будет до in these только оставшуюся часть мы можем хоть частично инициализировать нашел баг и потерять связь только с какой-то частью нашего брендов или какой-то функциональность если так получилось что два параллельно инициализируем их типа у нас сгенерирует каждый свою ошибку в итоге функционале который зависит от того и другого мы получим суммирующий тип ошибок таким образом разработчик инициализирую свой fall back и нибудь там в девелопмент среде получит полный список того что вот на данный момент у него неверные тесно может исправить ошибку здесь получить ошибку дальше но по крайней мере не будет такого что одна какая-нибудь совершенно не зависящая ветка у него закроет ошибки которые могли бы мы получить мы могли бы получить независимо от от этой ветке собственно дальше мы инициализируем создаем таблицы если нас есть вот какой то такой запрос он может прямо сразу запускать рез запрос или слаб запрос или он может внутри делать какие-то дополнительные операции можно запускать несколько запросов все зависит от вашего кода как вы организовали код так и будет fall back совершенно не анализирует что происходит у вас внутри методы на который вы вешаете вот такую заглушку место у вас где-то на другой синхронным потому что сам footbag асинхронным скале у нас-то помечается вот один из вариантов вот такой вот специальный тип фьюче это значит что результат нас вернется только однажды когда-нибудь мы тоже не знаем когда может быть сразу может быть не сразу мы для него создаем вот такую таблицу в качестве ключа в таблице будет выступать ты упал то есть кортеж из всех параметров этого метода типов соответствующих параметров а в качестве значения уже не ключевого у нас будет выступать результат которому я синхронную возвращаем и для каждой такой таблице мы заранее подготавливаем вот два таких параметрических запроса вставить данные и прочитают данные все все для того чтобы взаимодействовать с убуде у нас готовы и осталось выяснить каким же образом мы будем читать данные из fall back а собственно нас приходит ответственность зону того чтобы называем circuit breaker серкет breaker достаточно известный паттерн вот эта картинка почти что срисована сайта а к о о о вот типично состоит из трех состояний замкнутое состояние такое дефолтное состояние по умолчанию когда мы читаем данные сначала из бэг-энда и только если нам не удалось получить от туда лезем наш fall back если мы получаем успех в нашем бренде следам не потребовались fall back мы сохраняем данные в нашем фабрики и ничего не происходит но если у нас много-много раз подряд происходят какие-то проблемы мы предполагаем что возможно наш backend прилег и нам не хотелось бы с память его гигантским количеством новых запросов поэтому переходим в такое разорванное состояние в котором мы пытаемся читать данных данной только и столбика и если нет мы сразу вращаем ошибку даже не пытаемся лезть в наш основной backend после какого-то времени мы говорим но может быть наш backend уже очнулся и пытаемся сбросить состояние в такое короткоживущие состоянии халфу по нам срок его жизни ровно один запрос если в состоянии half up on мы получаем успешный мы получаем следующий запрос если мы успешно достучались до fall back а мы переходим снова в состоянии замкнуто если не удалось достучаться до fall back а мы возвращаем состоянии разомкнута но уже длительное время теперь такая мы добавили сюда два дополнительных состояния которые у нас явно не связано с нашей схемы это такое насильно замкнутое состояние и приоритетно разомкнуты ревет с такой инвертировано замкнутое состояние мы сейчас разберем что они делают вот такая блок-схема достаточно большая но в общем говоря самое главное что вы должны из нее понять что сохраняемый fall back параллельно этот символ означает параллельную параллельно с тем как возвращаем бэг-энда если нас в бэг-энде все прошло хорошо и если у нас все прошло плохо мы прочитаем из fall back и если и там и там плохо мы приоритетно возвращаем ошибку из двух ошибок выбираем ошибку бэг-энда и параллельно с этим если на все пошло плохо мы инкрементируем счетчик и переходим в разомкнутое состояние если запросов слишком много разомкнутое состояние ооп у нас гораздо более простое мы просто читаем постоянные спал bk чтобы там ни произошло и через какое-то время пытаемся перейти в состояние half up half up on по структуре своей очень похожи на замкнутая клаус состоянии с той лишь разницей что случае успешного ответа мы переходим в замкнутое состояние а в случае неуспеха мы переходим обратно в разом ты состоянию с увеличенным интервалом и дополнительное состояние которое нас интересует в основном в момент когда мы прогреваем наш конечно когда заполняем данные которые не пытаются никогда china this fall back а только добавляет него записи и другое такое надуманное состоянии которая играет роль persistent новый кэш а то есть если вы хотите реально просто снять нагрузку перманентно с вашего бэг-энда несмотря на то что вы понимаете что данные могут быть совершенно не актуальным вы включаете то состояние которое сначала лезет ваш backend и только если не нашло там сначала влить ваш fall back и только если не нашла там идет уже в бэг-энд и собственно разбирается с ним вот такие пять состояний замкнуты еще раз это самое основное состояние которое закрывает наш backend разомкнутая на момент когда наш backend по нашему мнению лежит half alpen короткоживущие состояние когда мы выбираем сомкнуться сновали разомкнутся но еще более длительное время forst для прогрева кэша и reverse когда мы хотим снять нагрузку приоритетно собственно со всей этой схемы у нас возникло несколько проблем вот такая самая серьезная проблема у нас возникла с осознанием того как работает припер statement of кассандре эта проблема уже исправленной версии 40 но она еще не вышла поэтому расскажу кассандр рассчитан на то что у вас к ней подключается миллионы клиентов сразу и все миллионы клиентов у вас пытаются подготовить свои prepared statements естественно кассандры не пытается каждый препарат стоит подготовить иначе не просто закончится память на это все поэтому она вычисляет некий md5 от текст запроса плюс каких-то опций bluesky space и если приходит точно такой же запрос точно таким же вот md5 она берет уже подготовленный запрос в это подготовленным запросе у нее есть уже информация о том какие вот метаданные там есть как и какими-то данными обращаться если так получилось что у нас кассандр работает работает и мы выпускаем новый релиз мы в нем там успешно накатили миграции добавили каких-то полей в типах и запускаем собственно на наши prepared statements у нас возвращается при простоять это с предыдущей версии нашего состояния и у вас с предыдущей verso стояние с предыдущей версии метаданных то есть с типами без полей и на момент когда вы уже читаете данные пытаетесь записать данные вашей новые обязательные столбцы вы сталкиваетесь тем что вас их просто нет кассандра как нет это вообще другой тип я такого типа не знаю другое как мы с ним справились мы очень сильно чита 0 и мы добавили какой-то уникальный текст в каждой из наших подготовленных запросов то есть просто для того зная что нас не будет миллионов подключаемых клиентов нас буквально там 1 сессия на каждую ноту которая держит там сколько-то подключений для каждой подготавливается один раз statement поэтому мы предполагаем что ничего страшного если например на каждую версию приложения или даже на каждый старт ноды мы будем делить какой-нибудь уникальный текст который явным образом будет в текст нашего запроса то есть мы добавили такое специальное поле чтобы с ним хитрить и при вставке записываем в это поле константу от constant явным образом записано запросе она уникальна для каждого стартом или для каждой версии приложения как захотите как настроить и вашу библиотеку и при чтении мы используем вот это имя как алиас для вылью которым мы достаем то есть запрос точно такой же мы все еще делаем селе целью но теперь в текст у него все равно немножко другой и кассандры славу богу не догадываюсь что тот же самый запрос вычисляет друга md5 и подготавливает запрос заново с новыми метаданными у нас будут еще пара проблем например есть такие достаточно серьезные проблемы например если у нас мы захотим сделать несколько параллельных миграций мы запустим несколько нот и они одновременно начнут все это вот вычислять это время запускать creed iii black grey type и и так далее вот одновременное создание клей теплов может привести к тому что на каждый ночь или в каждом из ваших правильных потоков она успешно пройдет и у вас успешно создадутся как будто бы две таблицы а кассандр внутри себя запутается и вы будете получать таймауту на запись на чтение в общем можно очень сильно поломать кассандра слепа подпись ли пытаться параллельно делать одно и то же с нескольких потоков лишь низких нот поэтому предполагается что при миграции вы будете запускать одну специальную ноду если вы знаете что у вас должна быть миграция фбк которая быстренько пройдет сделать иммиграцию и потом уже вы можете стартовать все свои ноды именно при релизе другая проблема связана с тем что у нас данных fall back еще может сразу не хватать то есть может так быть что вот мы заполнили метод о нас должен хранить исторические данные как мы записали там за год назад а на самом деле мы его запустили вчера и для этого мы предполагаем что вы используя вот то специальное состоянии forst будете запускать специальные возможно но оды которые не будут общаться с реальными пользователями а возьмут все возможные вот ключи которые предполагаете будут по кругу например прогревать кэш достаточной скоростью чтобы не убить ваш backend которую вы читаете ну и собственно все о чем я хотел вам рассказать спасибо за внимание и есть вопросы да всем привет дорогой лев укринбанк я вопрос вот там где 4 с запросами годам ключик смысле версию приложения фактически в поле подставляя там просто коммент нельзя было воткнуть какой-нибудь или коммента она выкидывает как шокирует конечно то есть там нет такого даже построитель предложили как ничего красивее пока нет не нашли но точно висит ешь ей в кассандра 40 они будут md5 метаданных добавлять в md5 основного сша и это поправиться когда-нибудь но пока что так и никакой деградации нагрузки не замечен с людьми а еще вопросы дпс не рассматривали как charger each бы из просматривали но все равно он связан с моим нотами и нам показалось это чуть меньше планировали бились мы рассматриваем как и решение для большого количества данных они для супер супер доступности данных спасибо здравствуйте а как вы отслеживаете зависимости между данными метапрограммирование на скале или франции в базе ли как дам то есть эту часть доклада я намерен не включил но там есть целый блок посвященный мета программированию то есть у нас есть макросы которые анализируют определенные вами типы смотрят таких типов они зависят и генерирует большое количество вот таких вот прецедентных определений скажите такой вопрос вот вы упомянули что у вас есть запросы по диапазону да вот этот диапазон ну как как с ним вообще работа ведется то есть это какие-то данные которые за генерировались в определенное время вы их запрашиваете или этого просто дубликат запрос вот он всегда такой значит там из из-за того что мы его все еще пока что в продакшен не вынесли я решил вот так подробнее рассказывать но для этого у нас мы в таблицу в определением таблицы добавляем дополнительные поле с диапазоном в коде который определяет вот такие интервальные запросы он дополнительно определять трансформации каким образом можно понять из ответа каким интервалом он принадлежит и соответственно наоборот как если мы соберем данные по интервалу как нам теперь всю эту коллекцию свернуть обратно в ответ вот этот алгоритм предоставляет сам под который хочет использовать интервальный fall back и собственно в кассандре каждый раз когда мы запрашиваем данные по интервалу мы добрасываем туда вот этот интервал то есть нас может быть этот интервал еще один еще один еще один вот все независима друг другом лягут в один кластер а потом если мы хотим что-нибудь посередине прочитать даже если получится так что на самом деле там должно быть что-то еще что мы никогда не запрашивали мы об этом не узнаем но мы еще раз исходим из стратегии что это все равно лучше ничего понятно спасибо расскажите пожалуйста я как разработчик в какой-то момент ломаю тип так что миграция не пройдет когда я об этом узнаю и каким образом у вас будет такой разновидность integra теста который попробует запустить инициализацию но без того чтобы что-нибудь в реально в базе изменить который просто предстоит метаданные и проверит что вот то что вы определили соответствует вашим метаданным то есть это когда вы сделаете pull request и ваша seo и система запустит integra тест вы получите там набор ошибок и в этот момент вы поймете что сделали что-то не так и нужно что-то что заменять спасибо здравствуйте скажите вот версию кассандра вы использовали open source ну или дата stax и замечали какую-то утечку памяти и как с этим боролись использовали open source научить их утечек не замечали сейчас пока 14 раз спасибо за доклад у меня вот такой вопрос на одном из слайдов и показывали примерно как создается крытый bounce рак шанс до при ну по генерации получается типа искала там или не важно вопрос такой используете ли вы пар тишинке для оптимизации хранения для повышения скорости при генерации таких вот собственно грибов ну собственно такие ты будет пар тишинке нет здесь получается я так понял это вот на запрос она сами типы которые вот генерируется там где просто ты был получается идет о мод самые первые получается были слайды самые первые слоя ты еще раньше да да да да да еще раньше до насколько помню вот примерно там где крытый был аккаунт и проще вот в таком нет мы предполагаем что вот параметры нашего метода которым покрываем fall байками возможно будет один из многих между в котором разом покроем full такими вот его параметры нас и будут определять их ешь будет определять портишь им то есть мы ничего специальным для пар тишинке не делаем сейчас спасибо спасибо за клад а можете сказать сколько сейчас серверов сколько данных и как уменьшилась время запроса той же живые данной концепции очень интересная хотелось бы узнать цифра да с цифрами немного сложно вследствие безопасности но в основном как это сказать в общем я полноценно не могу ответить на этот вопрос но могу ответить что как правило мы видим не уменьшение времени запроса а вот какие-то периоды когда мы знаем что нас вот этот сервис бы отсутствовал был бы недоступен а мы увидим что у нас доступен и от негативных отзывов нет и такое в общем случается в последнее время данных меньше по катара байта но мы мы предполагали изначально что должно быть около терабайта но вот снайп вместе с вот этими или define the pink так хорошо их скомпоновали что ну и плюс мы построить сделали очень большой реплики чем фактор потому что нам не нужно там особой consistency поэтому в общем пока не пока i меньше to buy the dam сам сами разработчики вот приложения когда им поступает такая задача что у них есть вот такие вот сервисы и вот мы как правило продукт оунер прибегает к разработчикам говорит что вот из-за проблем с перфомансом люди не получают этот сервис и разработчик говорит ну хорошо мы можем сделать вот так но там у вас на странице возможно появится плашки не актуальные данные или просто пользователь увидит прибили доступность не актуальные данные и продукт он говорит ну хорошо делаете хоть так до насколько много нужно внести изменений чтобы поддержать что-то принципиально совсем новое чтобы подержать принципиально совсем новую мы или ли это уже проблема такая версия не рование да мы предполагаем в данном случае определять практически новые контейнеры для fl bk если у вас что-то так серьезно изменилась и сделать миграцию например с помощью спарка из одной из предыдущей версии blitz другую спасибо всем сначала вы смотрите на каком уровне вы можете собственно его за фол бычить так чтобы у вас там было уже не слишком много данных при мешен их там из вашего приложения но данный из вашего сервиса уже достаточно хорошо обработаны вы выкинули из них все лишнее вот вы находите тот момент его оборачиваете fall back и дальше у вас появляется и ниша лазер такой специальный объект который должен запустить у вас создание вот всего что нужно для того что fall back работал то есть все все для того чтобы определить fall back там почти ничего не нужно писать все автоматически сгенерируется а вот и ниша лазер нужно как-то вынести в какой-нибудь ваш внешний код возможно в главное приложение которое в кубе джоби запустит и убедиться что она отработать до так вот подскажите вы есть поддержка вторичных ключей в кассандре есть здесь прикидывается нет в кассандре есть у нас пока не было необходимости для вторичных ключей потому что детки это не бизнес кейс не бизнес данные поэтому и можно 2 то есть вы говорите что вы patterns йорке bk использовали и это под капотом это все-таки реализация а капская нет под капотом нашу собственно из за того что мы добавить до своих состояний и плюс еще мы туда не важно все до доступность 24 на 7 итак помощи бизнес задача стоит одну обеспечить 24 на себя downtime и как ставить и почти как то происходит вообще ну это больше где в общем как они поддерживают кассандру но и ли вы той мы есть вообще как говорят блага что у нас нет down time for да да все спасибо"
}