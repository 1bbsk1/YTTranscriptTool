{
  "video_id": "zKPOAdNOQx4",
  "channel": "HighLoadChannel",
  "title": "Особенности шин данных для очень больших инсталляций на примере YDB Topics/Алексей Дмитриев (Яндекс)",
  "views": 166,
  "duration": 2398,
  "published": "2024-10-29T03:05:49-07:00",
  "text": "цена твоя пожалуйста сы что-то у меня а работает Меня зовут Алексей Дмитриев я технический менеджер в Яндексе и в зону моей ответственности в том числе входит эксплуатация наших больших ров через которые мы передам Данные есть этото Я буду рассказывать Кстати а я без кликера и здесь кликера нет А где кликер вот в общем Сегодня я хотел в рамках он сорса зайти не про то как Сколько мегабайт в секунду можно передать не то какая у нас задержка А вообще почему большим компаниям во-первых сложно брать готовый Open Source решение а во-вторых поговорить что с точки зрения бизнеса Спасибо о а во-вторых поговорить вот с точки зрения бизнеса Что будет если Яндекс например возьмёт и начнёт использовать сегодня о поч ковку вот я постараюсь это всё посчитать прямо в цифрах и прямо Показать наглядно почему с осом на самом деле нам было бы очень сложно а и Давайте немножко сначала начнём вообще про шины данных то есть шины данных у них есть какие-то конечно базовые свойства они должны передавать данные они должны их передавать быстро должны передавать много и у них есть конечно различные требования к скорости то есть они должны в норме передавать данные за какие-то единицы или десятки миллисекунд они должны передавать всё это отказ устойчиво надёжно и вот на что очень часто не обращают внимания все эти системы они должны относительно дёшево стоить то есть не должно быть такого чтобы эксплуатировать ваш кластер нужно например отдел 100 человек И точно также не нужен целый дата-центр для того чтобы передавать ваши объёмы данных то есть нужно чтобы как можно меньше людей обслужи систему как можно дешевле Она стоила в эксплуатации и занимала минимальное количество оборудования если рассказать немножко про нашу историю то в Яндексе кавка была в 2013 году вот вчера мои коллеги про это рассказывали и в 2013 году у нас уже несколько сотен серверов на которых работает кавка мы передаём через неё все виды данных мы передаём биллинговые данные мы передаём журналы приложения ещё какие-то данные и у нас происходит два сбоя два полных сбоя когда мы теряем все данные которые у нас были то есть мы потеряли два раза полностью биллинговые данные вот после первого случая мы испугались а после второго случая подумали что сейчас нас всех уволят потому что Можете посчитать биллинговые данные в объёме Яндекса Вот и поняли что в общем надо с этим что-то делать и начали строить свою систему в которою мы хотя бы там плюс-минус могли быть уверены Да я знаю что все скажут что кавка мы не умеем готовить что кавка на самом деле хорошая Вот в тот момент мы в общем решали что делать решили таким образом А в 2017 году мы запустили нашу систему уже в продакшене Яндекса То есть все потоки данных которые у нас были мы перевели на неё и в двадцать втором году мы её выложили в Open Source в составе а vb платформы теперь немножко цифр то есть в среднем за день мы передаём Примерно 200 Гб в секунду в среднем а но так как у нас большинство объёмов данных они в том или ином виде создаются пользователями если происходит какой-то инфоповод а например чёрная пятница как она только что была или просто какое-то событие активности становится больше потоки данных у нас растут и мы доходим там до 300 Гб в секунду или даже больше и всей этой системой пользуются примерно все разработчики Яндекса то есть больше тысячи команд они создают десятки тысяч топиков и предмет нашей особой гордости ровно один человек следит за всем этой системой За всеми тысячами серверов которые обслуживают эти инсталляции и сегодня мы как раз поговорим про ряд вещей связанных с эксплуатацией таких больших систем и начнём мы с вопросов оборудования где поговорим про или HDD диски мы поговорим про отказ устойчивость про реже кодирование то есть какие-то вещи связанные напрямик с физическим оборудованием первая вещь вообще какие-то наши объёмы то есть в целом у нас используется больше полутора тысяч серверов в пяти дата-центра для того чтобы передавать все вот эти вот данные и у нас есть такой интересный параметр это 18 часов меньше которых мы не разрешаем пользователям хранить данные То есть если они начинают передавать данные в нас меньше 18 часов Нельзя просто физически настроить параметр А почему мы так сделали потому что 18 часов - Это максимально известный тайм инфраструктуры Яндекса То есть за всю историю больше 18 часов никогда не было И когда мы решали что нам важнее Надёжность или стоимость система то есть Надёжность Понятно больше железа выше Надёжность или меньше железа немножко пониже мы выбрали вариант с большей надёжностью поэтому минимум 18 часов и соответственно на этих объёмах пользователь за это время успевают создать примерно 10 петабайт данных которые в каждый момент времени находятся у нас внутри наших шин А какое-то время назад мы активно использовали обычные HDD диски у себя в серверах но с HDD дисками есть проблема потому что вот если вспомнить требования к шине данных одно из требований - это задержка то есть норме сервера шина должны передавать данные за десятки миллисекунд и вот HDD диски Они очень не любят когда идёт на них нагрузка большое количество его операций То есть вы что-то пишите читаете пишете читаете им становится плохо и в итоге нам приходилось иметь большое количество жёстких дисков просто для того чтобы обеспечивать вот эти вот десяти миллисекунд задержки в какой-то момент мы решили пересчитать А что будет если мы просто возьмём nvme диски и заменим HDD диски на них и оказалось что если мы такое сделаем то нам понадобится А в два или в три раза меньше серверов относительно того что был То есть просто заменив HDD диски на nme мы сэкономили в три раза количество серверов то есть на текущих масштабах вместо 4.500 серверов У нас сейчас получилось почи но у нас появилась другая проблема HDD диски были большие места на них было много маленькие мы начали упираться Теперь уже в объём хранения и когда мы как бы это мы стали внимательно смотреть вообще как данные можно хранить вот если посмотреть на стандартное Open Source решение типа той же Кафки они в основном реплицируемый обратно 3000 серверов но есть способ на самом деле лучше он называется реже кодирование это достаточно такой известный математический фокус Когда вы берёте четыре блока данных к ним добавляете два блока контрольных сумм и в итоге вот эти вот шесть блоков могут выдержать выпадение любых двух из них то есть это то же самое что кавка из трёх выдерживает выпадение одного Мы из шести выдерживаем выпадение двух но при этом оно требует всего полтора с коэффициентом полтора необходимо место для того чтобы всё это работало соответственно мы вот эту разницу очень хорошо видим То есть если бы мы взяли каку мы заплатили за это полутора серверами а второй параметр на который тоже часто внимание обращают у дисков у них есть такой интересный параметр называется или он говорит Какое количество пере из на ваши дис циклически их пере записываете то вот это вот время наработки на отказ оно сильно сокращается и вы начинаете очень часто менять диски то есть опять же если вы начнёте много писать данных потому что у вас коэффициент репликации большой и будете часто перезаписывать будет много дисков бизнес будет недоволен а следующая часть связана с управлением конфигурациями Серов желе вр приходит приходит понно приходит порциями пачками то есть Пришёл заказ или приехал до заказ или ещё что-то и вот здесь вот приведён реальный график то есть как у нас сервера добавляются видно такие ступеньки и когда они добавляются Мы конечно хотим чтобы вся нагрузка которая у нас есть она моментально начинала разъезжаться на все до появившиеся мощность то есть мы не хотим чтобы вот тот кластер который у нас был он остался тут сбоку добавились какие-то новые нужно думать как туда что-то перебан сирова нет мы хотим чтобы была полная автоматика сервера приехали они добавились и всё работает на самом деле Кроме добавления серверов зачастую есть ещё процесс уменьшения кластеров А Он возникает если у вас происходит миграция между дата центрами То есть вы жили в одном дата-центре он уменьшается или он выключается вам нужно всё это перевести в соседний и в ответ на это у вас один дата-центр растёт второй дата-центр уменьшается и такой вот постоянный процесс меньше больше меньше больше он перетекает вот та же самая кавка этого жутко не лют у них до сих пор нет возможности уменьшать разме вот что для нас на самом деле к потому что держать Одновременно несколько больших кластеров нас просто технически не хватает оборудования А теперь давайте перейдём ко второй части это отказ устойчивости то есть так как у нас находится куча данных у нас находится биллинговые данные Конечно мы хотим чтобы всё это было отказ устойчиво чтобы мы не боялись каких-то потерь данных и нам про это говорить с типов трафив которые триб вид это биллинговые данные это то что ни в коем случае нельзя потерять это то что нужно доставить ровно в том порядке в каком к нам пришла нельзя поменять порядок система должна всегда принимать данные система должна всегда отдавать данные то есть максимальные гарантии из возможных а второй немножко Полярный к этому вариант данных - это журналы приложений то есть так как Яндекс находится под большим количеством аудитов иных ных различной политики комн Мы в журнал сохра огромное количество данных то есть там действительно речь уже на экзоты идёт вот мы храним несколько лет как всё это требуется и с точки зрения логов а нет какой-то особой необходимости их доставлять за миллисекунды А в них могут появляться дубли в этом тоже нет проблемы потому что принимающая система база данных она сама их де дупли она сама их выровнять поэтому тут какие-то гарантии такие ослаблены и третий вид трафика который есть - это пользовательские данные То есть это а разработчики которые отправляют данные в шину с другой стороны их забирают и строят какие-то свои процессы поверх этого и для того чтобы с этим работать у нас есть два варианта инсталляций то есть первая инсталляция она называется oss DC а э инсталляция для самых критичных видов трафика которые у нас только есть то есть это биллинговые данные и эта инсталляция она полностью переживает выпадение Датан пользователь даже не замечают что что-то происходит для них система продолжает полностью работать и второй тип инсталляции он называется Федерация в этом режиме пользователи отлично знают что у нас несколько дата-центров они знают как система себя ведёт при выпадении дата-центра и учитывает в своих приложениях каким-то образом А все вот эти вот модели я сейчас про это подробнее расскажу вот с точки зрения oss DC для пользователя Cross DC кластер который натянут поверх трёх реальных дата-центров он выглядит Как просто одна большая инсталляция куда он может писать данные и совершенно не задумываться о том что что-то произойдёт то есть такая система она выдерживает выпадение любого одного дата-центра плюс выпадение стойки в соседнем То есть это стандартная модель отказа в Яндексе то есть любой сервис должен жить при минус одном ДЦ и стойке в каком-то соседнем технически это происходит за счёт того что мы построены поверх wdb платформы которая сама по себе умеет такие случаи обрабатывать И мы этот факт у себя используем и в общем он нам супер полезен федера то есть в случае Федерации как я сказал пользователи отлично знают что стра у них есть что дата-центров несколько а при этом если дата-центры выключаются пользователи тоже отлично об этом знают Вот и для того чтобы вся система работала при выключении дата-центра У нас есть отдельная сущность которая пользователями командует То есть она может сказать так пользователь у нас выпал первый дата-центр пожалуйста половина трафика переди сюда а ВТО половину трафика переди в трей Датан потоки данных переключаются они начинают писаться все данные получают все счастливы почему пользователи вообще выбирают вот этот вот вариант Потому что если вернуться к железу в случае oss DC инсталляции нам нужно всё ещё три полных реплики для того чтобы полностью выдерживать любые варианты отказов А вот в этом случае мы работаем как раз модель реже кодирования и нам не нужно закладывать вот эти вот коэффициенты 3X и с точки зрения вот пользователя на внутреннем биллинге они отлично видят разницу то есть разница между oss DC кластером и федеративным она больше чем в несколько раз различается и пользователи деньгами голосуют за такие инсталляции то есть по факту больше 90% данных мы передаём именно в режиме Федерации а не в режиме ксдц теперь вот очень интересный вопрос а с точки зрения и ршм настройте между ними репликацию данных с помою реплика и но о м кака не говорит она не говорит о том сколько мощности вам нужно держать в этом случае про запас то есть что происходит вот у вас есть два дата-центра они одинаковы если у меня Дант о выключается все мои писатели которые там были они же продолжают создавать свои данные и все эти данны мощность для того чтобы вся эта система работала То есть на наших объёмах условно 500 серверов в каждом дата-центре нам нужно 500 серверов иметь просто про запас на тот случай если какой-то дата-центр выключится А если же мы можем работать с большим количеством дата-центров то цифры становятся лучше если у нас точно также умирает какой-то дата-центр то потоки из него мы можем поделить по двум оставшимся и в результате в резерве мы уже имеем не 500 серверов всего 250 Чем больше дата-центров тем меньше вот эта вот степень резервирования простая всего железа поэтому мы любим пять дата-центров потому что Чем больше дата-центров тем меньше мы резервирует таким вот образом данных и нашего оборудования и более того о чём кавка тоже не говорит а дата-центры При таком резервировании они не одинаковые то есть зачастую бывает что вам нужно получить какое-то железо Но тот дата-центр Где вы хотите его получить его там нету оно занято чем-то ещё Или например там происходит какой-то процесс обновления же Нест Поэтому в реальности ваши потоки будут распределяться не так как полностью 100% в один или 50% в другой они Бут делиться по каким-то другим более сложным формулам например 83 про о в 17 в другой или в какой-то ещё похожей формуле Вот и здесь я опять хотел вернуться к тому вот самому слайду с Федерацией Что именно поэтому мы в основном предпочитаем эти кластера и они того что мы в том числе гораздо меньше железа тратим на такое резервирование то есть в случае oss DC У нас очень большой запас железа А здесь запас железа гораздо ниже А теперь давайте перейдём к следующей части тоже про отказоустойчивость здесь немножко сначала контекста чтобы было понятно То есть vdv платформа Она явно делит у себя слои хранение и слои компью То есть у нас есть отдельные процессы которые отвечают за хранение данных понять Като произвольное количество динамических нот которые занимаются вычислениями И они будут получать данные системы хранения с ними что-то делать И эти данные могут в принципе рассы в произвольное место почему это важно базовым примитиво нашей системы является такой компонент он называется по-английски по-русски зачастую говорят таблетка а проще всего его вос этот компонент на самом деле хитрый он использует подход который называется rsm или State ма и у него основная идея Какая что у вас есть какой-то набор данных он лежит в нашей системе хранения У вас есть входящая очередь команд в этот компонент компонент специально написанным однопоточный Он забирает команду забирает своё состояние системы хранения что-то выполняет и потом транзак говорит я команду обработал новое состояние забрал Это означает что в любой момент времени этот компонент можем убить можем остановить сервер можем сделать всё что угодно он будет поднят в соседнем месте точно также поднимет своё состояние точно также поднимет свою очередь и продолжит свои вычисления то есть таким образом очень удобно легко переживать любые виды отказов какие только бывают и первое Чем это полезно - Это балансировка нагрузки У нас есть специальный компонент называется ха который следит за тем чтобы все наши динамические ноды то есть уровень компью бы примерно равномерно загружен а когда у нас появляются новые сервера этот компонент обнаруживает что что-то у нас какие-то подозрительные свободные мощности и берёт часть таблеток и переносит их на эти сервера И в этот момент пользователи даже не замечают что что-то происходит это процесс очень быстры то есть мы дождались что завершилась команда перенесли оно всё продолжилось оно таким образом всё продолжает работать то есть вот новых серверов он не заметен он очень-очень быстр и с точки зрения вообще каких-то цифр вот такой вот а процесс реакции на какой-то сбой он занимает несколько десятков миллисекунд То есть как только наша нода перестала отвечать на чеки в течение 20 миллисекунд вот эта таблетка будет поднята на каком-то другом сервере она возьмёт нагрузку продолжит вычисление и пользователи часто даже не замечают То есть почему не замечают потому что хотя вот Все меряются цифрами говорят у нас скорость 10 миллисекунд на скорость 5 миллисекунд по факту Никто из наших пользователей не ставит алерты на такие маленькие значения То есть у всех алерты настроены на десятки секунд когда вот уже какая-то идёт обработка поэтому задержки уровня 20 миллисекунд они не замечают оно происходит полностью прозрачно и люди даже вот об этом не знают Вот и почему это ещё важно потому что есть интересный процесс обновления кластера Когда нам необходимо выкатить нашу новую версию на на 500 серверов Дант и в этом случае процесс Он полностью аналогичен проходит происходил до этого мы берём какую-то наду Выключаем её система балансировки видит что у нас есть какие-то таблетки которые надо перенести переносит их на свободные мы обновляем версию появляется сервер обратно пустой мы обратно возвращаем все вот эти вот таблетки Итак оно происходит Шаг за шагом ролин гомбрович релизы и в этом случае у нас возникает какой-то момент отката Он повторяется ровно так же в обратную сторону Вот и Бывает даже несколько раз вот причём зачастую оно бывает довольно забавно То есть может оказаться что релиз был хороший всё шло хорошо но потом какой-нибудь старый сервер он вернулся из починки на нём старая версия она проснулась Начала Начала отправлять какие-то данные вот и весь кластер начал себя вести странно потому что он не ожидает что такое может быть Вот Но в любом случае те версии которые мы строим они совместимы между собой вперёд и назад в пределах одной версии для того чтобы очень быстро их как-то раскатить и быстро теперь с точки зрения управления кластером Вот Мы создали наш кластер разобрались с балансировкой и теперь возникает вопрос что видят пользователи когда начинает в него заходить и здесь большой вопрос про коммунальные или выделенные кластера ПРО какую-то ресурсную модель которая есть и первое что хотел показать это реальные цифры из нашей системы то есть мы ВС время используем большие коммунальные кластера потому что вот если бы мы выдали Т Мы в одном дата-центре выдали 360 Гб в секунду пропускной способности при этом по факту люди используют не больше 100 То есть фактически за счёт того что мы смогли систему сделать Коммунальной мы сэкономили 70% оборудования 70% оборудования это 4500 серверов то есть цифра такая вот достаточно внушительная но положа руку на сердце а у действительно есть некоторые выделеные ластра которые мы делаем устойчивости потому что действительно бывают случаи когда релиз какой-то неудачный идт масштабный сбой и мы хотим чтобы были кластера которые к этому устойчивы и вот супер критичные какие-то инфраструктурные кластера они действительно существуют Вот Но их очень Малое количество они нужны в основном для отказа устойчивости Потому что если опять вернуться назад если бы мы все сделали такими выделенными вот мы потеряли бы огромное количество железа Вот и тут тоже такой небольшой камень в сторону каки который рекламирует создавайте свои маленькие кластера все Вот опять же если бы мы туда пошли Ну вот ещ 3.000 серверов мы потеряли бы на это а теперь с точки зрения ресурсной модели то есть с одной стороны мы очень похожи на кафку У нас есть точно такие же понятия топик и партиции но при этом у нас есть понятие которого нет в кафке оно называется аккаунтом аккаунт - это количество мощности которое выделено команде то есть команда делают свои заказы желе в какой-то момент Они получают желе выражается внутри аккаунта и знание о том что это железо есть оно приходит из информационных систем заказа аккаунт сдаются автоматически а пользователи уже внутри этих аккаунтов живут и с точки зрения квотирования вот кавка всё время рассказывает о том что у них квоты они принадлежат одному серверу они внутри брокера находятся но по факту система КАТО все квоты которые мы делаем они все распределённые то есть пользователь может прийти на любой из сотен серверов начать писать данные переместиться на другой сервер что-то делать но при этом он всегда будет ограничить теми квотами которые есть и у нас есть ещё Да теми квотами которые есть у нас есть ещё одна очень интересная квота так зря я сюда ушёл я вернусь А это квота на холодный старт кластера то есть когда-то у нас такой квоты не было и был очень занятный момент когда в Яндексе происходит регулярное учение по выключения дата-центров они обычно происходит в пятницу В пятницу дата-центр выключается потом спустя несколько часов он включается и дальше наша система начинает нагонять вот это вот несколько часовое отставание А мы очень хорошо старались написать код код Очень эффективен поэтому мы с огромной скоростью начинаем качать в результате мы уходили далеко за сотни терабит данных впер перегружая все то можно были вид на всех сетевых мониторинга и в итоге мы тормозили си работу большого количества остальных систем и в итоге к нам пришли попросили В общем как-то умерить аппетиты потому что всё хорошо но слишком быстро Вот и ещё одна квота про которую тоже обычно не думают а это квота приго дата-центра мы выдали пользователям 100 мб в секунду в одном дата-центре выдали во втором и вот у нас первый дата-центр выключается и когда он выключился весь поток из первого дата-центра данных пошёл во второй но там квота 100 мб в секунду То есть технически мы не можем принять его поток потому что железо не позволяет Но в этот момент мы расширяем эту квоту и разрешаем пользователю временно писать больше данных чем у него есть на самом деле и в тот момент когда дата центр возвращается мы обратно эту квоту сжимаем и показываем пользователю что уже всё хорошо То есть это вот тоже такой неочевидный момент квод который возникает только если вы жонглирует как-то дата центрами и с точки зрения аудита А как я уже говорил у нас большое количество аудитов большое количество комплайнса поэтому мы собираем логи наверное во всевозможных сочетаниях каких только можно делать по консьюмер по партиции по читателям по IP адресам То есть много-много всего то что на самом деле в Open Source каки нет и оно появляется только в коммерческой версии в конфлюенс А дальше последняя часть - это то без чего бы мы наверное умерли То есть если бы мы не научились всю эксплуатацию всю работу с кластерами отдавать в самих пользователей То есть если вернуться в 2013 год когда у нас была кавка у нас была целая команда 12 человек все са админов которые обрабатывали входящую очередь джира и реагировали на запросы пожалуйста создай мне топик настроим такой мость заведи мне е один топик заведи мне кластер и 12 человек с утра до ночи Они обрабатывали такие тикеты чтобы что-то делать Вот наша система с того времени возросла То есть если у нас было несколько сотен серверов то сейчас несколько тысяч вот можно так посчитать у нас было бы 100 человек просто перемалывают в жире вот для того чтобы этого не допустить Мы очень сильно постарались чтобы все операции Какие людям нужны они мог выполнять сами есть поно в режиме то есть они создают топики создают читатели правила чтения они что-то пишут то есть они полностью всем занимаются своими силами причём в тот момент когда мы Тим релиз они могут запросто прийти что-то начать перенастроить вот Единственное что они сами не могут настроить они могут настроить аккаунты потому что они связаны с количеством железа которое они заказывают То есть это вот то что приходит из информационных систем и в итоге для того чтобы люди могли вообще сами как-то на ВС реагировать мы дам огромное количество метрик ИТ на сотни для того чтобы люди могли как-то настроиться в алерты и с этим работать то есть алерты бывают всевозможных вариантов точностью до партиции до читателя до трафика между дата-центра то есть всё это откладывается исторически для того чтобы люди могли своими силами как-то разбираться своими проблемами вообще не используя при этом нас вот и здесь вторая часть про метрики что на самом деле их очень-очень много вот и для пользова мы предоставляем готовый шаб для то чтобы они понимали вообще начиная с чего начинаются проблемы То есть наме с 90% нехватки квот или с 8 и таким образом им становится попроще И тут я бы уже начал на самом деле подводить итоги и первое О чём сказать что Open Source зачастую он не совсем подходит для больших компаний Вот например для компании нде потому если бы мы вли Open бы в 20 человек на поддержке если бы мы взяли вот ту кафку которая есть а мы бы вместо наших полутора тысяч серверов имели бы 8.000 серверов которые надо как-то обслуживать а сервер - Это не просто железка которая что-то стоит это на самом деле места в дата-центра которого не хватает а это сеть это большое количество сопутствующих вещей а дальше второе - это то что когда вы становитесь большими Нужно обязательно маштабе внезапно оказывается важным и нам приходится этим заниматься а и немножко заключительных слов То есть а vdb Topic - это основная шина в Яндексе через которую мы передаём большой объём данных вот а у нас большие планы по её развитию в какой-то момент мы когда вышли в Open Source поняли что Несмотря на то что наши протоколы Они вообще классные очень эффективные но по факту перестраивать всё по переписывать его наш протокол это нереально поэтому мы занялись поддержкой протокола кавка И в данный момент мы полностью совместимы с какой на чтение и буквально через несколько дней не успели Хотя спешили а будем доступны наоборот Мы совместим на запись будем доступны на чтение Вот и с точки зрения наших направлений развития А мы очень много сталкивались с тем что не в этом проекте в других когда мы хотим сделать какую-то оптимизацию в орсе который экономит например 1% причём много для этого пишем кода комьюнити отвергает говорит что вы что-то слишком сложное делаете Это не нужно но на наших масштабах один процент экономии - это на самом деле десятки серверов То есть это очень большая цифра и вот то что вчера рассказывали ребята Мы в моменте уже догнали кафку мы с ней сопоставимы вот и мы на самом деле видим Куда дальше улучшаться Мы хотим улучшаться и по процессору и по сети и по объёмам хранения потому что вот эти вот проценты о которых сейчас идёт речь Мы на самом деле очень-очень хорошо видим и в заключении хотел сказать что vdb топики - это не вещь сама в себе это часть большой vdb платформы куда входит ещё транзакционные база данных аналитические нагрузки федеративные запросы топики То есть много-много всего вот и всё это проверено масштабами Яндекса всё это используется у нас внутри здесь приведён ссылка на репозиторий гитхаба Вот и внутри у нас ровно такая же версия как снаружи то есть нет такого что мы внутри делаем что-то одно сст окружаем другое это на самом деле идентичная версия Вот и на этом всё спасибо большое что послушали уху Алексей Спасибо тебе большое Очень круто и Значит у нас есть ряд вопросов вот я вижу здесь руки тут руки блин прямо первые ряды прямо всё с руками Так у нас Давайте Вот первый вопрос э вот здесь Ну давайте Вы да и второй вот сюда передадим так пожалуйста Представьтесь Здравствуйте меня зовут Илья Попов ВТБ два связанных вопроса Первый про таблеточки Вот вы говорили что таблетка там куда-то уезжает потом считывает задачи и продолжает работу у меня сложилось впечатление что не работает ли таблетка сама с сервисом топиков а таблетка - это часть сервиса топиков то есть таблетка - это подход и она у неё есть реализация сделана под сервис топиков А и задачи она из сервиса топиков забирает хорошо спасибо за вопрос Давайте по одному а второй можно будет задать дискуссии потому что очень много рук хорошо Пожалуйста вопрос здесь и потом будет Вопрос вот молодой человек держит руку Привет лё отличный доклад Спасибо тоже про таблетки хочу таблетки хочу вот эту функциональность у себя в решении которое за 20 миллисекунд там переключается там февер делает э как мне её получить На каком языке мне надо программировать тут сложный ответ во-первых мы пишем все на C ПЛЮСПЛЮС потому что нам нужен максимальный контроль скорость всё вот это вот Но на самом деле этот вопрос сильно технический Поэтому вот у меня тут сидят ребята рядом они вот на все эти вопросы могут ответить можем выйти и там они вот всё расскажут Спасибо Спасибо большое Так сейчас вот молодой человек здесь и Давайте с этой стороны зала ещё есть руки Так давайте тогда вот молодой человек вот там стоит у стены вы давайте туда будет второй микрофончик пожалуйста Спасибо Очень интересный доклад Денис Маркет Гуру вопрос очень простой вы сказали что одна версия совместима с другой Ну получается на один шаг А если например вот мы сделали инсталляцию Self hosted и спустя недельки две-три решили апгрейды там три-четыре релиза То есть у нас будут проблемы или всё-таки нам придётся так слайд-шоу одну заодно пока не догоним да Ну на самом деле это не так страшно звучит как кажется потому что процесс обновления в тот момент когда мы выложили чтото в Open скорее всего мы уже прошли сами вот Ну понятно что никто не застрахован но скорее всего он просто да вот из нескольких частей Спасибо большое Кстати я так понимаю вот полная совместимость с какой Хотели к хайду так сказать докатить её но не успели будет новогодний подарок я так понимаю хорошо так тогда молодой человек вот там который стот и потом вот здесь вот молодой человек который держит руку сначала там пожалуйста Спасибо за доклад у вас там был слайд прой кодинг а общее количество чанков и количество чанков которое необходимо для успешного чтения оно как-то конфигураторе делить Или это у вас захард кожено Извините я только не вижу кто задаёт вопрос я только это я задаю Вот здесь Да да Всё нашёл у нас встроен блок 4.2 Ну вот просто он зашит Вот потому что для нас стандартная модель отказа там с точки зрения дата-центра Вот я думаю что если там нужны какие-то другие гарантии вот можно с ребятами поговорить но мы используем блок 42 То есть это не конфигурация Да прямо сейчас нет Понятно напрямую сейчас пока нет но можно пообщаться будет в кулуарах Да отлично Спасибо большое Так сейчас секундочку у нас микрофончик вот здесь потом микрофончик Давайте вот в ту сторону зала потому что ни разу туда не ходили Добрый день Спасибо большое за доклад очень стало понятно Зачем Яндекс своя кавка Всё ясно а очень конкретный вопрос Что происходит если я нарушаю свою квоту То есть у меня там 100 мегабит в секунду я начинаю писать 200 ну то есть у меня будет ошибка я получу при записи ошибку правильно нет вас будет ролить то есть мы считаем На каком окошке вашу скорость и мы вас будем в неё вот так вот выпивать я буду тайм-аут получать при записи То есть я Ну ну там не совсем ну типа Да вы будете замедляться мы вас будем замедлять Окей спасибо большое так с спасибо Так тут есть кстати вопросы из онлайна поэтому сейчас вопросик вот в той части зала потом будет вопросик из онлайна и вот здесь были подняты руки так вот молодой человек вот здесь вот в углу сидит потом сюда Так скажите пожалуйста как обстоит дела с транзакционные мы Спасибо за вопрос Мы активно этим занимаемся мы сделали вот полностью транзакционная передачу данных чтение из топиков запи табли вот И теперь мы вторую часть чтения из таблиц запись в топик или наоборот да Наоборот в общем у нас просто задача она не считается выполненной поэтому я в моменте перепутал порядок вот мы хотим там за какое-то время полностью закончить то есть почему это делаем Это пришла внутренняя Потребность у нас есть биллинг Вот который хохочет точно читать данные из топиков делать какой-то процессинг и писать данные в таблице Вот ребята конечно супер ловкие ВС умеют но периодически вылезают какие-то косяки а это всё время Ну как-то страшно Да что-то пойдёт не так там не добил перебил какие-то выяснения Вот и в итоге мы для них делаем транзакцию чтобы вот просто можно было написать считай Посчитай Запиши если что-то разлома ось Повтори Ну вообще это круто на самом деле если это как когда это окончательно заработает так а сейчас небольшой вопросик из онлайна возьмём э Александр задаёт вопрос Можно ли взаимодействовать свой db по http протоколу Ну коротенький вопрос в моменте нет то есть у нас всё взаимодействие по grpc Почему так Потому что вот когда кластер очень большой из нескольких сотен серверов то чтобы с этим эффектив То есть у нас каждый из серверов может принять входящий запрос и шные клиенты они знают структуру кластера они знают куда ходить и таким образом у нас нет какой-то единой точки Ну какого-то отказа перегрузки или ещ чего-то А это протокол требует чтобы мы куда-то Термини в одно и то же место как-то сами реша самом деле про него думаем потому что для части сценариев дест очень удобно и просто Но изначально мы специально делали чтобы работать условно с серверами в большом кластере То есть через так сложно так хорошо спасибо большое Так значит вот здесь молодой человек и потом вот там вот за колонной ещ есть туда будет микрофончик Иста настроить или обеспечить это таким образом чтобы если у нас есть несколько инсталляций в разных цода а при этом у нас так чтобы аккаунты работающие с приложениями в тех же самых цода работали именно с ними же так происходит да А и В случае отказа устойчивости это бы всё переезжала оно ровно так работает да и соответственно если какие-то у нас централизованные решение то Ну соответственно тоже скажем так оптимизируется и есть возможность вот скажем так передавать данные из топика в топик внутри кластера Вторую часть я не очень понял Первое ровно так работает то есть оно работает за счёт того что у нас есть балансер но они стоят в каждом дата-центре и когда балансер приходит трафик он пытается сначала Термини свой ближайший Ну фактически в текущий если что-то идёт не так он уже начинает там куда-то раскидывать и вот тут мы начинаем управлять Спасибо большое за вопрос и пожалуйста вот микрофончик туда за колонну если можно Представьтесь пожалуйста Да спасибо большое за доклад Юрий а очень понятно Зачем Яндекс не стал пользоваться осом А вот мне как маленькой компании имеет смысл пользоваться он Source на idb если у меня масштабы намного меньше чем у Яндекса Ну спасибо большое за вопрос отличный Нам его задают на самом деле раз за разом то есть а вот я бы сказал что vdb сейчас пытается стать платформой то есть предоставлять сразу не одно решение а много Почему мы это делаем потому что в этом случае нужны специалист не в разных системах там не знаю специалист по кавка по Линку там я не знаю по гн пму ещё почему-то А мы пытаемся двигаться в сторону такого zer еля zer M То есть когда нужно минимальное количество людей чтобы обслуживать то есть Может быть с точки зрения там всего она кажется громовское вот всё вместе скрестить уменьшить какие-то вот сложности эксплуатации В итоге может быть в общем наоборот более удобно но мы тогда мся Спасибо большое за вопрос и я считаю что это будет последний вопрос ребята все остальные вопросы можно будет задать в кулуарах Потому что Алексей с нами останется и Давайте поблагодарим нашего докладчика Алексей У нас есть совершенно замечательный подарок для за лучший вопрос можешь его выбрать А можно вот последний вопрос мне последний вопрос всё да Мне кажется он такой честный очень Тогда тогда по подарок в студию Y"
}