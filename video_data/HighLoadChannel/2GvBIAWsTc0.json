{
  "video_id": "2GvBIAWsTc0",
  "channel": "HighLoadChannel",
  "title": "Потоковая обработка BigData для МТС / Евгений Ненахов (МТС Digital)",
  "views": 1072,
  "duration": 2445,
  "published": "2023-01-19T06:56:45-08:00",
  "text": "коллеги привет меня зовут не нахождение я работаю центре bigdata мтс директа и последние несколько лет я занимаюсь преимущественно проектами big data в частности я очень много времени уделяю поток в обработке данных в этом докладе я бы хотел рассказать о некой концепции или даже методологию потоку обработки данных и применения ее на практике преимущество этой концепции в том что оно достаточно универсальна же позволяет решать широкий круг задач потока обработки данных и и можно рисовать практически на любом стойки технологий мы в мтс следует а концепции смогли реализовать некий универсальный инструмент потоку обработки данных и построить на это и на этом инструменте достаточно мощную систему стриминга я верю в то что послушав этот доклад и следует и концепции используя похоже из тех технологии или может быть свой любимый stack технологий вы сможете у себя сделать подобный универсальный инструмент и сэкономим себе кучу времени истин и сил для начала я скажу как меня в этом докладе нужно понимать я знаю что очень много людей очень ревностно относится к различного рода англицизмов используя терминологии своей речи поэтому я сделал такую небольшую табличку своих терминов если я говорю например стримим то я имею ввиду по току обработку данных если я говорю 3вт то я имею ввиду опасен 3 вт ну и несколько других примеров я надеюсь что такая табличка позволит вам избежать каких-то не назначить моем докладе теперь ближе к сути все мы прекрасно знаем фразу время день и применительно к ти и эта фраза означает что чем быстрее данным и обработаем тем больше выгоды из этих данных мы сможем получить лучший способ это сделать это обрабатывать данные режиме реального времени то есть применить так называемый стриминг процессе 3 мин процессе дает нам возможность обрабатывать и получать выгоду и скоропортящиеся данные то есть данные которые актуальны у нас небольшой промежуток времени на основе этих данных мы можем делать какие-то какую-то персонализированную рекламу предлагать скидки специальные с точки зрения финн тех это может быть приложение по кредиту с точки зрения телекома это может быть новый тарифный план наиболее сложные какие-то кейсы и различного рода советские если на этом не ограничивается это все только вашей фантазии в мтс тоже очень много данных которые можно и нужно обрабатывать режиме реального времени в основном это данные которые у нас поступаю с коммутационным оборудованными базовых станций ну и конечно же это различные устроиться сайты приложения все эти данные в принципе можно разделить на несколько доменов это геолокация звонки нахождении абонента в роуминге типичный калек stream то есть поток большой достаточную горлом ну и проще различную информацию по абонентам данных очень много очень много и все эти данные очень хочется обрабатывать получать из них выгоду и стало понятно что нужна такая мощная и при этом универсальная концепция которая позволит сеют один все эти данные обрабатывать требования такой системе предъявлять сложно да и в принципе формулировать требования к такой системе предъявляй сложно поэтому мы пошли от наших хотелок а что нам хотелось хотелось нам производительность причем достаточно высокую от 5 до 10 миллионов событий секунду не хотелось бы терять событие то есть должна была быть надежный механизм отказоустойчивости не хотелось бы иметь какую-нибудь болью масштабируемость хватилась бы наоборот без проблем как видите как вертикально так и горизонтально масштабироваться с точки зрения функционала хотелось бы иметь гибкую функционал фильтрации трансформации данных из одного формата в другой уметь не дублирует данные на потоке и для нас важным было пунктом нас сделать xii руку от ну или хотя бы laugh at настройка обработки данных или выключение новых источников не за хоть не хотелось закладываться в полной жизни цикл разработки по хотелось тратить на это будет как можно меньше времени но и streaming речка признает за ним нужно следить при чем следить пристальный хотелось детализируем мониторинг хотелками разобрались что в принципе есть на рынке и стека технологий который позволит покрытий хотя бы часть наших хотелок и еще интереснее стало посмотреть а что же в принципе люди используют ли решение подобных задач продакшне и наш список сократился в принципе до четырех технологии the spark streaming клик на wi-fi и кафка для каждой технологий мы провели отдельные рынки взяли там совокупный железок взяли специфичный свой набор данных свою обработку данных и провели и рэнди были в принципе у каждой технологии есть свои как преимущество такой недостатки изливают этих технологий позволяет решить конкретные задачи но нас интересовали именно наши хотелки соответственно мы учитывали несколько критериев первую очередь это наверное развитость комьюнити этой технологии мы учитывали в принципе на сколько это выходит релизу данной технологии учитывали куда в принципе держит движется технологий куда она развивается еще важным критерием для нас было это конечно же опыты компетенции нашей команды ну или уровень душ не что кто как называет это вот соответственно выбор технологий у нас полна spark streaming и здесь стоит обратить внимание что это именно spark streaming они spark структурный streaming качестве основного языка программирования мы выбрали скала считаю что это мощный язык который со своим функциональным стилем идеально подходит для решения задач по току обработки данных и в качестве транспортных шины данных выбрать как хорошее решение уже зарекомендовавших себя для решения задач когда-то со стеком понятно чего совсем этим делать и героем ест который приходит голову это ну просто взять какой-то большой обработчик написать большой монолит взять там щепотку скала запихать эту мясорубку спарка запустить на кластеры пускай гонять данные из кафки в капкан все просто ну или можно даже сделать наоборот можно декомпозировать задачу и под каждый поток сделать свой костру свою кастомную обработку но у каждого из этих решений есть ряд минусов которые нас не устраивали в первую очередь любое изменение это очень долгий процесс это полный жизненный цикл разработки по мы ставим задачу в аналитику начинаем писать код тестировать на различных стендов делать составить план релизов релизе цвет это долго это несколько дней может быть даже недель и это нас не устроил потому что нам приходит клиент и говорит ну хочу посмотреть гипотезу на потоковых данных примерно там за пару часов это не работает такие системы сложно документировать лестно сложно тестировать если мы эта система сложим тестировать то появляется высокая вероятность появления критичных баков на продакшене соответственно возникает лавинный эффект им становится сложно в принципе писать код потому что мы больше тратим время не на развитие нашего проекта не внедрение новых фич она поиска этих неуловимых багов и мы ни че не баги я просто делаем их меньше и больше владеем важнее становится релизе появляется куча различных версий конфигурации которые сложно поддерживать и это не просто и все становится сделать сложно сложно тестировать писать код релизе слегка только выгореть у я какой он деревне выращивать овощи и жизнь бы замечательно ну и рос со всеми вашими скалами и spark этой в принципе сейчас даже заманчивой идеи но не сегодня дружок понятно значит нам это решение не подходит хочется что-то более универсальная какую-то более гибкую концепцию и лучшим решением для нас стало сделать так называемый конвейер до ног или в нашей терминологии pipeline что имею ввиду под конвейером данных это когда мы берём данные из потока ставим его и эти данные как бы на конвейерную ленту и эти данные путешествуют от обработчика к обработчику последовательно при этом изменяя свое текущее состояние когда данные доходит до терминального обработчика то есть до последнего обработчика обработчик смотрит на конечном состоянии этих данных и принимает решение что же с этими данными нужно делать нашей реализации pipeline а у нас всего пять обработчиков твой из которых являются обязательными the source и экшн если у нас есть источник есть куда данные сливай значит всего поток у нас есть остальные в принципе может могут не принимать участие в обработке данных но у нас есть хотелки значит у нас есть еще другие обработчики эту стоит обратить внимание именно на обработчик фильтрации мы очень хотели иметь гибкую систему фильтрации в рамках этого плана хотели задавать там не один фильтра целых несколько и чтобы сделать такую гибкую методологии достаточно было сделать как оказалось совсем небольшой disel реализовать два логических операнды это and и or и скобки для установки приоритета и уже вот этих операндов достаточно чтобы создавать большие выражения которые позволят гибко фильтровать данные потребитель достаточно указать только это выражение чтобы свои данные каким-то образом отфильтровать в нашем понимании функционал эту по и планом было недостаточно нам хотелось сделать что-то против олега чтобы у нас был кубик и этим кубиком был в наш pipeline соответственно этих кубиков мы хотели собирать нечто большее расширять еще больше наши возможности соответственно захотели сделать именно конструктор pipeline of чтобы все наши планы могли собираться в 1 мега pipeline ада в нашей цепочки планов и спускался в рамках одного installs a spark стриминга и при этом мы хотели чтобы это еще запускался параллельно чтобы несколько потоков нас работал и и тогда наши возможности будут там грубо говоря безгранично наши реализации пропилами будет выглядеть следующим образом это обычный класс pipeline а который содержит основном только два метода start и stop причем старт понимает основную главную движущую силу нашего решение это стримил контекст streaming контекст это наше сердце наше все и streaming контекстно создается ровно один раз на уровне абстракции выше в так называемом pipeline менеджер менеджер следит в принципе за всем жизненным циклом коллекции pipeline of и чтобы стартовать двери стартовать какой-то план достаточно обновить эту коллекцию и перезапустить streaming контекст запуск pipeline это в принципе вещь тяжелая как я уже сказал это перезапуск примем контекста поэтому прежде чем запускать какой-то pipeline лучше сначала же конечно проверить все конфигурации от оков мастер ментальному обработчика является action то лучше проверить именно его настройки прежде чем запускать конкретной по плану и конечно хотелось бы рисовать метод стоп чтобы все-таки pipeline и останавливать когда нам хочется теперь давайте по подробнее о каждом экшне который у нас есть по и плане экшн sword что он должен делать обработчик source должен принимать данные из источника создавать на основе этих данных streaming и детализировать эту эти данные в нашу внутреннюю модель дальше это внутренняя модель будем называть в месяц будешь путешествовать от каждого обработчика к обработчику изменяют свое состояние так называемый вводится контракт основной источник данных для нас это кафка в мтс и все данные и которые у нас есть в потоковом режиме обычно сливаются в кафка соответственно мы реализовали несколько типов именно кафка основными из них является 3 вт и джейсон так как большинство данных наверно процентов 70-80 у нас хранятся формате 3 вт и тут возникает вопрос можно ли сделать другой источник данных не кафка конечно можем можно например сделать какой-нибудь hdd с афро и натравить этот сорт на gdfs директорию и смотреть как появляется новый файлик и какие изменения вносятся в какой-нибудь схему авра чтобы это сделать достаточно рисовать 3 царств которым вот есть основные методы основным этом является стрим массаж и он rdm стрим как я уже говорил принимая streaming контекст причем streaming контекст у нас будет путешествует rinse тивно через каждый план и каждой обработчик данных и на основе инструмент контекста создается так называемый им будет стрим то есть дискретный поток данных после чего применяется метод массаж которой зависимости от типа идите реализуют наши данные во внутренней модель если это 300 по схеме 3 то вам нужен внутренне модель если это джейсон то соответственно будут mapping полей еще интересно методом у нас является он рдд and он позволяет нам как раз и реализовывать некоторые вещи связанные с дефекации источников например для кафки мы можем вручную комитете ассеты это очень удобно если вдруг в нашем плане произойдет какой-то инцидент кто-то из обработчиков себя будет плохо вести выдавать какие-то эксепшен а то мы не потеряем данные мы перезагрузим pipeline и начнем считывать данность тела с того момента на котором последний раз мы за коми телись приходим к обработчику это фильтры и фильтров мы сделали прям вот много причем как оказалось вы сначала клепали фильтры которые были более-менее общее скажем так это видно в названием есть эклз контент на хождение по потому но все эти фильтры были достаточно производительный то есть у нас идет огромный поток и самая мякотка идет как раз таки на фильтрации то есть все циpкa выгружается именно на эти фильтры потому тем более у нас в может быть множество фильтров в одном деле соответственно стали делать фильтр более производительные более специальные то есть учитывающий специфику данных например стоит обратить внимание на второй снизу фильтр это три контент лист он содержит реализацию алгоритмах а карасика который основан на прекрасных деревьев для поиска подстроки в строке для чего нужен он нам он у нас используется в частности для поиска доменов определенного уровня в потоке урлов и такая штука нам позволил увеличить производительность по сравнении с обычным контентом на процентов 30 и это действительно спасла и у нас переставил нагружаться фильтр реализовать нашем случае не ну не так просто надо родилось всего два метода и реализовать rinspeed рейд треть фильтр у нас имеет частично определенную функцию которая содержит по умолчанию сразу два метода из define это и play из define эту нас проверяет участвует ли данный фильтр в обработке данных участвует прямо в pipeline в конкретном деле если участвует то применяет метод тепла которым уже реализовано фильтрация конкретному сообщению следуем дальше нас данное уже отфильтрованы данные от электроны поступают у нас уже в трансформации тут у нас достаточно просто все нас несколько трансформаций так как у нас основной формат данных это 3вт а потребители хотят видеть глазами эти данные 300 нас это sequins white глазами его не очень получается смотреть соответственно сделали трансформацию данных csv джейсон и есть даже трансформации рисунки джейсон в этой трансформации мы просто убираем лишнее поля или переделываем поля так как хочется потребителю если на вход у нас например пришел 100 полей то мы выдаем только пять нужных потребителя уменьшая тем самым размер самого потока все это конечно же настраивается потребителем на самообслуживание рисовать достаточно просто взять три пт и в принципе реализовать похожий оказался на фильтрацию это те же метод define от apple с тем же назначением и наступает очередь следует в наши обработчика не дубликаты и здесь сразу возникает несколько вопросов как в принципе делать в дубле к цию данных на потоке когда у нас есть какой то конечно набор данных там все понятно у нас есть сколько-то сообщение нас есть сколько записей на основе них мы можем понять где какие данные являются дублем на потоке у нас бесконечные количество данных соответственно нам нужно выбрать какой-то интервал времени в рамках этого интервала времени хранить состояние нашего объекта и после него уже сравнивать состоянии конкретно других объектов для поиска дублей где хранить эти объекты и в какое время это хранить какое время мы отдали это на откуп потребителем именно потребители устанавливает время а где хранить тут уже стал вопрос мы хотели иметь самодостаточны инструменты не хотели платить большое количество технологий и какую-то использовать внешних ранигу для этого тоже не стали и подумали ну есть же spark streaming у него есть экзекуторы которые запускаются на различных но до которые умеют между собой общаться и есть механизм рот костов может быть есть что-то что позволит именно spark стриминга сделать сохранить стране и конечно да получилось у нас есть де стрим дискретный поток данных у него есть так называемый метод move estate причем могли state в исходниках спарка помечен как эксперименту мы поэкспериментировали с этим решением и нам это эксперимент очень понравилось достаточно просто передать туда функцию по определению поправим определения дедупликации и все spark streaming саму себя по механизму грудка забыл хранить конкретное состояние причем нам даже любезно предоставили метод тайма узко к нам нужно хранить данные в памяти sparco это решение оказалось для нас очень удачно но какой-то мои мы поняли что мы имеем здесь и недостатки если мы вдруг приложение наши перезагрузим если мы инструмент наш перезагрузим то получится ситуация когда мы уже потеряем отфильтрованные и дает трансформированные данные это ну нас не устраивало при этом мы не могли никак понять а правильно ли вы у нас работают у потребителя дедупликации то есть на это тоже тратят много времени и решением было такое просто разделить на 2 pipeline а конкретное решение то есть взять вы читать данные отфильтровать трансформировать отправить эти данные с помощью экшена в промежуточном топиков к для дедупликации и вторым планом этим же приложений вычеты данные прасаде дуплицировать в конечном итоге отправив can конкретный топик такое решение для нас стало приемлемым ре зация дедупликации всего лишь метод тепла и иди стрим смотри стоит туда передаем функции высшего порядка которая-де дуплицировать данный сохраняя все по механизму мрут костов и указываем той мал для тайм ту ли его нашего конкретного состояния и переходим уже к терминальному обработчику в этом обработчике нам достаточно было рисовать 3 выхода это канской дефисы hbs кафку мы можем взять данные в любой класс стр в любом направлении также мы можем данные записывать как палики наш дпс в различных форматах причем мы умеем коллирует фабрики как по времени так и по размеру ну и конечно же можем записывать данные лишь бы из в hbs по ключу для этого всего у нас есть конфигурации пользователя tinkoff игра сами пользуются при этом в рамках плана у нас может быть несколько экшенов то есть source у нас как минимум один пай плане секса может быть несколько это сделан для того чтобы уже а трансформированной и уже фильтрованной данные мы могли параллельно записывайте несколько топиков кафки или несколько директорий гефест или в принципе куда-то всего одновременно по ключу как я уже говорил action должен принимать решения о том что же делать данными когда вы уже данные к нему пришли когда они когда едешь на уже видит конечно его состояние и вот здесь интересный момент допустим у нас есть некоторые простой diy селе это несколько фильтров которые соединены и логическом операндом and и пускай у нас есть сообщение которое высчитывается из источников поток у нас есть выражение у нас есть фильтры и каждый фильтр применяя принимает участие обработки данного сообщения то есть сообщение путешествует абсолютно по всем зрителям которые указаны нас здесь или каждый фильтр устанавливает отметку в нашем сообщение точнее это даже бить их в битвой маски этого сообщения то что конкретный фильтр успешно прошел фильтрацию для этого сообщения соответственно пройдя каждый фильтр и каждое сообщение накопит все берг конкретное состояние и когда придет в экшен нее посмотрит так называемый триггер триггер сравнит состоянии битвой маской конкретного сообщения с условиям действий фильтрации и поймет что же с этими данных делать если условия побит в москву совпадают то данные передаются в экшен и уже action знают куда эти данные дальше отравлять если нет то данный будет просто отфильтрованы экшн реализовывается тоже достаточно просто это тот же против anx значит у него есть есть define нет тёплой но при этом есть еще пару интересных методов например он parties and ion rdm для чего нам нужна он портишь ну например для при реализации штифт с текст на по записи данных вождей фриз мы в этом методе роллируем файлик по времени или по его размеру оон рдд он позволяет в случае успешной обработки рдд оправляет какие-то дополнительные метрики по мере по мимо технических метрик например метрики данных для data quality с концепцией понятно разобрались как этим пользоваться где в принципе хранить конфигурации опять же идея была сделать самодостаточный инструмент и не плодить различному кучу много их технологии в принципе чтобы наш потребитель не имел каких-то супер сложных компетенций для того чтобы этим пользоваться поэтому первое решение сделать какой-то структуре ный файлик и в этом файлики хранить это работает до тех пор пока у вас всего пару pipeline of ну может быть штук 5 ладно эта штука работает хорошо но когда становится по плану штук десять двадцать тридцать то следить за этим управлять становится невыносимо тяжело поэтому а почему мы не положить весь наш pipeline все наши обработчики в плоскость может быть это хорошо ложится в ту модель который может нам предложить возраст и как казалось да все наши данные все наши именно не данные этап обработки мы можем разделить на табличке связать их все воедино причем аккумулирующие опять же табличкой будет у нас векшин который будет себе содержать все остальные результаты обработчиков тайпанов но это то что на картинке а в реальность получилось вот так то есть немного страшнее причем ну на первый взгляд кажется там действительно все очень сложно но хочу заверить что там большинство таблиц которые имеют связи это технические таблицы которые в принципе заполняются автоматически чтобы в этом забраться достаточно сделать пару select of и insert чтобы настроить нужного рода pipeline хорошо разобрались pipeline ними разобрались концепции то есть взяли скала сделали spark написали все это дело написали код и протестировали теперь думаем надо все это дело наверное запускать на кластере сделали себе кластер сделались пламенный файлик и запускаемся спаркс отбиты у нас вдруг никуда ничего не едет мы начали копаться стали понимать что начинались проблемы у нас попадают экзекьютив салатов мимо exception to у нас какие-то подписания top почему-то микро матчей друг за другом не двигаются не как куча проблем причем совершенно каких-то магических мы начали копаться в коде думаю что мы очень плохо написали код на самом деле оказалось что мы просто не настроили ников кунис парк streaming и в принципе история о том чтобы тюнить spark streaming и кафка это история не долго и очень сложно мы потратили на это очень много времени и вы или для себя несколько параметров которые по вы позволили повысить нам производительности нашу отказоустойчивость этим параметрам я бы хотела тоже с вами поделиться первую очередь мы должны снизить нагрузку на грести в совокупности следующих параметров именно совокупностью параметров по отдельности это может там не оказать влияния первую очередь если вы по какой-то причине не указывать не используйте garbage man короче коллектор своих машинах то это ну наверное надо исправить потому что горбачев one очень хорошо работает с большими объемами памяти и это мы подтвердили своими эмпирическими тестами также стоит установить максимальный пауза джесси в 500 миллисекунд но это наверное больше наша спецификация и я понимаю конечно что это рекомендательный параметрам для джесси скорее всего и в большинстве случаев джесси будет игнорировать этот параметр будет превышать этот лимит но все уже какие-то там 53 процента позволит вам сэкономить и также я советую поиграться с параметром который указан указывает заполняемость кучи перед параллельной сборкой мусора мы установили эмпирическим путем что 35 процентов это для нас золотая середина где мы оптимальнее всего расходом ресурсы и пауза став зовут у нас уже не такие большие еще одним интересным параметром является кантором да причем я знаю что не все люди в принципе знают о том что такой параметр существует не все люди знают как в принципе правильно его настроить как корра позволяет нас повысить параллельно с работы спаржа баф papillon и в нашем инструменте реализован таким образом что при обработке мы берг микро матча у нас будет максимум два джабба причем эти два джеба будут работать последовательно при дефолта настройках sports стриминга и если мы настраиваем например штук пять наших pipeline авто в нашем спаркс тремя приложений будет вы идеи десять гробов которые будут работы последовательно а это нас не устраивает у нас много цепова мы хотим чтобы все были за действия в один момент времени поэтому мы устанавливаем припяти pipeline грубо говоря 10 конкор джобсе у нас работают все pipeline и параллельно при этом у нас нет такого что какой-то job у нас подзавис из-за этого подзависла просто какая-то . эта тачка висит она пожирает одну цыпа все остальные цепную сидят курят и мы не можем взять при этом следующий микро batch в работу так вот устанавливаю streaming анкары job в правильное значение мы можем взять в работу следующий миг rubbage не дожидаясь обработки предыдущими карма ча еще одним интересным параметром является спекуляций дику лечим позволяет перезапускать в автоматическом режиме тоски которые подвезли у spark стриминга как спорт string понимает о том что тоска подвисла вот об этом говорят параметры мультиплеер и квантиль мол тёплой 3 квантили 0,9 это означает что если тоска время выполнение тоски в три раза превышает медиана и время 90 процентов выполненных остальных to suck то значит эта тоска подвисла то есть если мы берем грубо говоря 10 to suck который выполнились девять из которых выполнить за одну секунду а наша одна тоска работает уже 3 или 4 секунды то ее стоит перед опустить большинстве случаев процентов наверное 70 spark перезапуска в эту тоску и эта тоска работало на ура прямо на раба от работу намного быстрее чем а темы то есть это возникает на в основном из различных интеграции с овощами источников где на источник указан тайм-аут и например у вас ваш интервала установлен там 10 секунд и вы ожидаете что вы каждые 10 секунд хотите обрабатывать данные а тайм-аут у вас установлен в четыре минуты и соответственно вы висите на этой тоски 4 минуты пока тайм-аут не отобьется и тоскане перезапустится спинку лешим в этом плане у нас очень сильно выручу все интересно параметров играется blacklist если вдруг у нас спаркс 3 мин запуска это какой-то нодди экзекуторы вам постоянно падает то он помечает эту ноту в черный список и больше на этой ноте какое-то время экзекьютив и не запускается не запускается других модах и за этому ему мы можем сохранить свою производительность особенно в пиках и при этом нам не надо руками вводить ноду из кластера чтобы понять что с ней происходит оно просто продолжает дальше находиться классный мы можем с этим дальше работать еще одни баран там это тюнинг именно memory и тут наверное все знают про мексику the memory но многие забывают про memory overhead нам overhead в с портным ремонт нужен для в основном живым различных нужно при для интернированных строк и на больших потоках данных как у нас дефолтное значение в десять процентов от основной памяти этого не хватало поэтому эмпирическим путем опять же нашли компромисс и на и вы читали что где-то 30 процентов от этой памяти нам хватает и у нас уже экзекуторы не поддаются out of memory стоит обратить внимание на конкретные параметры катки особенно на макса и temptations он должен очень хорошо как коррелировать с интервалами кабоча макса и ферб артюшин говорит о том что у нас сколько максимальное количество запись у нас будет вычислено в одну секунду из одной партиции одного топика это естественно нужно вычислять на потоке эпическим путем еще на помогла очень вот такая вот табличка это табличек они наши мы нашли ее на одних их на просторах интернет в одной из статей и этот парнишка говорит о том что вам нужно и как какие параметры уголки нужно выставить например ax и мин и минусик реплика нас нам подошла именно третья строчка на мы очень хотели иметь высокую пропускную способность лет вести нас не очень интересовала потому что весь в этом sick of key у нас бы сожрал spark streaming интервал и нас интересовал достаточно высокая доступность поэтому вы сова или акцию в и именно секрет лик в двоечку мониторит здесь более менее стандартную историю spark streaming имеет достаточно много технических метрик есть на каких-то метров не хватает мой причем на питоне экспортеры все это льётся у нас у сбит weight после чего отдается prometheus уизли движутся графа не а далее если что-то происходит не так на прадед то письма . а лед менеджер уже приходит к нам на почту блоге тоже собирается стандартным образом это гель лака стек все идет вся обработка идет флаг стаж хранится эластики а анализируется визуализировать все таки бани и на чем все это дело работает у нас есть кластер из 18 did not и три ноты для управления мы этим классом и в принципе другими предложениями по характеристикам это 36 others триста восемьдесят четыре гигабайта рамы и тут стоит обратить внимание на obtain 600 гигабайт оптина добавляется у нас в ram и менеджер ресурсов и у нас используется yarn видит именно гигабайт терабайт памяти на одной такой найди и это и это память она отрезана медленнее чем равно она нам очень помогая при решении задач где публикации ну и 8 терабайт на хдд нас вполне устраивает также у нас отдельный класс стр под кафка под промежуточной турки это 5 кафка над с практически такими же характеристиками только без obtain и поменьше gd что в итоге у нас получилось нас были ожидания по 5 или 10 миллионов эти секунды и судя по метрикам графа не разбил разбитые по доменам данных у нас пока что выходит 6 миллионов событий секунду в среднем и 7 пике то есть у нас еще есть три миллиона событий запасе еще у нас начиталась примерно три девятки отказоустойчивости за год и это все благодаря небольшому зоопарку технологии и механизм отказоустойчивости sparco и кафка ну так же масштабируемость за счет спаркой кафку нас обеспечивают как вертикально так и горизонтально и весь функционал фильтрация формации дедупликации у нас в ходе в pipeline а при чем здесь есть небольшой совет стоит лучше разделить на 2 инстанса нашего инструмента the instances парк стриминга как фильтрацию так и дедупликации нить их каким ним промежуточным точкам кафки потому что фильтрации в принципе просит больше циpкa и ей надо больше дать спу и дать чуть-чуть памяти для там того же интернированы строк для дедупликации нужно больше памяти оставят чуть-чуть циpкa на того для того чтобы не задыхался даровать collect or a girl code настройка обработка данных здесь у нас вышло наверное в принципе laugh at потому что чтобы настроить планом достаточно сделай пару insert а у меня на этом все коллеги спасибо большое за ваше внимание тип спасибо евгений за доклад давайте перейдём к вопросам из зала вот там вот кажется был первый вопрос у нас жизнь спасибо большое за доклад но хочется задать вопрос почему не другие технологии как вы все-таки проверяли и как вам непосредственно за виду те или иные решения почему именно выбраны такой стресс стакане стрим 100 например или knife ай да спасибо за вопрос это хороший вопрос я постараюсь но тезисно сейчас пока что него ответить оставляем могу продолжить там в кулуарах потому что это наверно долгий вопрос в принципе любой рэнди это долгий вопрос у нас есть было несколько критериев и буду были набор своих специфичных данных и например нам очень нравилось в африке и воле пенсию там несколько миллисекунд но другая обратная сторона этой медали то что на это в этом с и тратится очень много ресурсов и например для того же набора специфичных данных для того до тех же железок для тех задач fliku требовалось намного больше данных на тот момент мы поняли что spark streaming ведет себя стабильней когда у него идет нагрузка то есть мы можем спрогнозировать сколько всего понадобится ресурсов или или в принципе железок вот нагрузку а под клин у нас получалось так что деградация шла как-то непредсказуемо на сайт тоже все очень интересно классная сразу из коробки решение где мы зиру код делаем все то есть мы натыкаем клик на тыкве мышкой процессоры с ними что-то делаем и делаем допустим небольшие какие-то потоки данных и они отлично работают когда становится данных больше когда становится потоков больше это в принципе нам показался очень тяжело поддерживать и fling у эльфа и начал еще сильнее деградирует чем fling плюс нам и на френки именно на альфа и не очень понравилось писать свои кастомные процессоры а нам для этого как раз таки нужно было написать также мы рассматриваем именно решение к искры но на тот момент это решение был немножко с ароматом и нам мы встретились с несколькими богами как не захотели исправлять и у нас опыт уже был счас парком поэтому мы и думали ну свое ближе поэтому взяли spark streaming вот там вот еще следующий вопрос евгения спасибо за доклад я вот хотел спросить вы сказали то что сначала конфигурации задавались просто файлики а потом вы переехали в bdp сгрыз и вот хотелось узнать скажется что если мы задаем конфигурации файлики куда-то допустим мы можем пропустить этот файлик через процесс review куда-то выложить после чего централизовано раз катить и как бы про этот этот процесс видит все все видят то что изменения произошли в случае каких-то ошибок в pipeline я его можно легко откатить также вот нет ли проблем связанных с этим при переезде на по депо сброс то есть типа если мы можем просто ким пинсер там испортить какой-нибудь buy плане на да это хороший вопрос я не упомянул но мы конечно же не оставили голый по сгрыз под пользователей мы поставили перед ними представление то в речке и все данные которые не только окружают у нас проверяются триггерами процедурами и процедуру же погружают нужные данные в нужные таблички то есть принципе нас будет нашему потребитель на использовать не позволительно сделать какие-то плохие вещи которые могут попортить там чужие pipeline и что то еще то есть в этом плане мы защитили себя именно процедурами и 3 kermi я думаю о том что в принципе было бы неплохо иметь какой-нибудь rest api тянуть к куда какой-нибудь гуидо сделать you a wix но для этого нужно отдельно компетенции отдельная там штат ки в команде и в принципе ipad всех не сделаешь придется постоянно это что-то дорабатывать поэтому оказалось вот таким вот чопорным простым но недорогим решением сделать интерфейс через базу данных берет на действие у вас базе данных есть прям табличка с примененными конфигами или грубо говоря делать сколько insert который на несколько табличка разлетается который целом будет тяжело откатить там именно insert по колонкам то есть там нет олег лежит понял спасибо как можно использовать что-нибудь скажи сам куда не добавишь под газ все становится лучше извините я предвзят просто знаете нам нужно узнать если вопросом в онлайне их нет тогда можно перейти к еще одному там кажется вот зародить даже крайне было жестко давайте сначала я слышно же не ермаков индекс сперва думал что у меня угнали вопрос прям тут же передо мной но в близко в предыдущем вопроса как у вас устроен тепло и тестированием то есть ensure сделали процедуру этом триггер отработали в целом как то тестируется тепло и c и откатывается ну тестирование у нас несколько слоев нас в первую очередь конечно же это куча теста которые юнит-тесты также нас есть скучен традиционно в тестов и нас есть специально выделенные тестировщики обычные которые знают различную концепции наших nightline of есть несколько стендов где мы все проверяем ее в том числе и регрессионный тесты нагрузочные тесты как мы вносим изменения какие asshole происходит там деградации все это дело со свежим на это вопрос хороший это не просто скажем так это нужно все время просматривать куча различных кейсов и вопрос про диплом все это работает чем кинсей с патлами всей семьи куда достаточно там выставить какие-то параметры джабе мая планок и у нас все зарелизить все работает на менеджеры ресурсов явно на спасибо и второй вопрос на слайдах было три девятки вопрос почему не 6 могут пытать про-паков чтобы это было конечно были ситуации были ситуации с down дай маме и были ситуации например к сожалению мы как инструмент не можем гарантировать то что происходит на источники и бывают такие ситуации когда сам источник например какой бы класс старков к которому вы подключили потребители взяли там свой продакшн решение свой продакшн инструмент моделей на самообслуживание все это работает на продакшн к страховке и потом вдруг этом инструменты подключая какой-то кластер кафки который используется для тестов грубо говоря до для каких-то исследований это класса россия начинает себя очень плохо вести то реплики плохо дают данные то еще что то происходит и инструмент начинает подвывать начинает все плохо вести из-за этого происходят какие-то downtime и и downtime и происходит из за того что у нас в автоматическом режиме начинает streaming рестарта ваться streaming начинает рестарта ваться он не успевает сработать . который уже есть и снова приходит restart из-за этого были downtime и пришлось вот чинить скажем так быстро круто спасибо спасибо за доклад тут еще как раз следующий доклад до следующего просто давайте заслушан женя вот такой вот вопрос на самом деле я что-то похожее делал и проектировал и вот такой вопрос а вы операторы даже не фильтры трансформеры делаете универсальным образом подходила чтобы они подходили для всех типов сущностей или они могут обрабатывать только один тип сущности один тип данных одно событие и соответственно если потому что то приходит другое то уже нужен другой другой фильтр реализовать непосредственно и если это универсальный все-таки то универсальные фильтры то в этом случае сериализации детализация какая у нас в кафку у нас это универсальные фильтры то есть в самом начале у нас есть оператор source который здесь и рисую все во внутренней модель единый внутри модель и эту единую внутреннюю модель мы применяем как раз вот к этой единый внутренний модели к по факту классу мы применяем все наши фильтры но ради удобства мы сделали по факту фильтры для двух типов данных это для 3 вт и для джейсон то есть именно детализации идет как tried to колесом то есть решается все единым единой модели с да и садко ск основными атрибутами то есть атрибут ему этой модели могут бы да то есть мапо до подключении новых источников сложной задачи подключай новый источник сходится к сложности 10 лизации данных возможной модель"
}