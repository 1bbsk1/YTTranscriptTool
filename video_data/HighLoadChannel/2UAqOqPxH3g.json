{
  "video_id": "2UAqOqPxH3g",
  "channel": "HighLoadChannel",
  "title": "Как мы храним и анализируем большой социальный граф / Максим Бартенев (Норси-транс)",
  "views": 1497,
  "duration": 2642,
  "published": "2017-04-22T14:47:42-07:00",
  "text": "сегодня я бы хотел поговорить про грабовой базы данных я расскажу про наш опыт использования громовых б.д. почему мы использовали грабовой базы данных не of a j из парксе каким образом можно постараться выжать из них максимум и каким результатам мы в итоге пришли здесь сразу стоит заметить что графу и база данных с парксе совсем недавно получила такое свое название она еще совсем недавно называлась dex и если вы знаете что-то о громовых базах и слышали об этом продукте то скорее всего знаете и его именно под названием dex в последнее время наблюдается крайне бурный рост интереса к системам хранения и обработки граф в их данных во многом это связано с тем что в нашем мире различных социальных связей графова и представление данных является наиболее естественным примеры граф вы можете видеть повсюду это и интернет его веб-страницами различными ссылками между этими страницами маршруты грузоперевозок да и вообще любые маршруты которые только могут быть дорожные карты социальные сети с отношениями дружбы и подписки пользу одного пользователя на друга и все это примеры граф в реальной жизни но что более важно это бурный рост количества эта игра в информации на примере тех же социальных сетей я уверен вы знаете что и несколько лет назад речь шла о миллионах пользователей с максимум возможно сотнями миллионами отношений между ними сейчас уже речь идет о миллиардах пользователей с сотнями миллиардов и даже триллионами отношений между этими пользователями и если с хранением этой информации все более-менее ясно загрузить граф в виде списка ребер в реляционную базу данных при наличии достаточного количества внешней памяти скорее всего никаких проблем нет то вот чтобы обработать эти данные что-то них получить вплоть до обходов нахождения каких-то подгруппы кратчайших путей тут могут уже возникнуть сложности при работе с реляционный б.д. я не буду останавливаться на том почему в реляционных плохо работает обработка графа если вам интересно или может вы это уже знаете я оставил пару ссылок в подготовительных материалов сегодняшней лекции там вы можете про это почитать и в том числе например найти сравнение сколько работает аналогичной операции в реляционные или в каком-то новость к или хранилища итак перед нами стоит абстрактная задача анализа графа в каком-то своем примитивном представление скорее всего в список в пески ребер мы его получили в результате какого-то предпочтет а или же там нам этот граф дал заказчик это не сильно важно важно то что у нас есть большой какой-то граф с минимум сотнями миллионов ребер мы хотим о нем что-то узнать для этого мы хотим найти какое-то решение какое-то уже скорее всего существующий продукт позволяющий работать в с графами в не табличном представлении и позволяющий как-то эффективно эти данные графы вы анализировать причем особенностью поставленной задачи является то что на мне интересно какая-то разовая обработка статичного графа нам бы хотелось чтобы этот граф была возможность постоянно поддерживать в актуальном состоянии то есть по мере поступления новых данных мы могли про погружать их хранилище и в этом хранилище потом выполнять какие-то графа вы и запросы потому что ну в зависимости от того один раз мы обрабатываем граф или как-то накапливаем графа вы и данные чтобы потом с ними что-то делать с актуальным состоянием графа здесь могут быть использоваться разные решения таким образом у нас вырисовываются три основных этапа работы с нашим потенциальным графа вы мк раниль ищем первый этап который нам нужно выполнить это загрузка графа в хранилище некоторые импорт скорее всего речь идет о каком то большом полученном графе они какие-то его маленькие кусочки второе это выполнение на про груженом графе на правильно сказать наверно актуальном состоянии граф выполнении различных аналитических задач и третье это да загрузка данных по мере их поступления почему я третий этап вообще выделяю отдельно хотя он кажется таким очевидным что мол ну загрузкой то есть загрузка а потому что в случае какого-то вот использования такого решения работающего с графами возможно такое такая ситуация что загрузка будет идти совсем не так быстро как нам хотелось бы и если вот это да загрузка в наш граф будет выполняться слишком долго то выполнение аналитических задач на не актуальном состоянии граф вряд ли будет кому то интересно вообще говоря графова и запросы особенно обходы раз параллели ваются достаточно плохо мы для тестирования для своих задач вот ну для этого доклада в первую очередь выбрали три таких базовых запроса которые было бы интересно выполнить на графа и б.д. первое это поиск всех соседей одной вершины то есть достаточно тривиальная задача просто взять вершину по всем инцидент им ребрам пройти во всех соседей второе это выполнение обхода в ширину на всем графе то есть pfs и третье это нахождение кратчайшего пути ну то есть такое типа простая задача поиска и соседи сложно ну относительно сложная задача такая тяжелая на всем график bfs из примерно средняя share спас первое с чего мы начали вы вполне естественно и тофу j потому что она известна у нее большое сообщество она действительно распространенная это известный продукт наверно единственный продукт из графах б д про которые можно сказать что он действительно распространен у него высокая функциональность то есть многие задачи которые мы можем перед свой поставить они уже там решены в виде соответствующих функций плюс очень мощный язык запросов сайфер конкретно нас в нашей работе это может не очень интересовала но вообще для конечных пользователей крутая штука когда есть вообще такой очень удобный язык запросов на котором можно записать и главное его не сложно изучить достаточно пуджей может быть как серверным приложением так и встраиваемым она написана на джаве то есть просто можно работать как через какой-то интерфейс так и просто подключить как библиотеку kajal проекту и написать приложение на джаве и есть бесплатная комменте версия распространяемая по лицензии gplv2 от есть и платная версия enterprise она на трех дней доступно бесплатно gopro главное отличие расскажу позже ну главное отличие помимо понятно того же нужно платить деньги за коммерческое использование я не буду рассказывать о том как там присоединительного джей проект проекту как создать в нем вершины или там ребра индексы украинцы расскажу немного вот про какие-то основы не буду углубляться потому что вы так это сами можете все найти в документации все достаточно просто написанной это не так интересно я бы хотел остановиться на проблемах и особенностях которые могут возникнуть при работе с на f и j ну и соответственно дальше при работе сос парксе как и уже говорил ну что вполне естественно мы хотим использовать на fuji как backend для какого-то анализа на крупном графе то есть нам нужно погрузить крупный граф и первое с чем мы сталкиваемся когда начинаем работать на f и j это необходимость объединять все операции в транзакции будь то создание вершины ребра обход какой-то все что угодно все должно быть внутри транзакции это конечно нужный и правильный подход для промышленного решения все это естественно отказоустойчивость это важно но это первое из-за чего импортного джей работает совсем не так быстро как хотелось бы если вы просто начнете работать снова fuji своем первоначальном виде в котором она есть то максимум что по-нормальному скорее всего получится погрузить это ну там может быть пара десятков миллионов ребер какой-нибудь такой граф это не столь интересный не то чего нам хотелось бы добиться второе это при таком если мы работаем с на его fuji как с бэндом для аналитики то скорее всего мы хотим про грузить тот граф который уже имел какую-то свою структуру и вершину в ну и возможно ребра в каком-то другом случае имели свои собственные идентификаторы которые мы погружаем но фуджейра да и как вообще скорее всего любая другая но вскоре б.д. при создании соответствующих объектов присваивать ему свой внутренний идентификатор и только поэтому идентификатору мы можем очень эффективно получить доступ к этому объекту то есть чтоб нам пол быстро получить вершину нужно будет знать какое она имеет идентификатор который ему выдала на f и j а мы же работаем с графом который подгружаем сами со стороны у нас есть свои значения какие-то этого графа ну типа там с ним какую-то условную соцсеть грузим мы погрузили туда пользователей пользователи там идентификатор вася пупкин а и на fuji ему присвоила 10 мы хотим чтоб потом сказать найди мне всех друзей васи пупкина а не f и j как бы не знает ничего про васю пупкина просто знает что у него идентификатор 0 и все и мы должны это каким-то образом знать первое что касается трансакционного подхода чтобы ускорить в общем импорт есть специальный инструмент по чем сердце это специальный не отказоустойчивые не потока безопасный режим работы с экземпляром базы на fuji который при этом позволяет действительно быстро импортировать данные то есть тут речь идет о том что скорость загрузки данных возрастает на порядки то что он не отказоустойчивые не потока безопасные здесь уже нет никаких транзакций это не особая проблема потому что когда мы работаем с таким действительно большим графом когда нам нужно его загрузить нет никаких проблем и во время импорта заблокировать доступ пользователей к хранилищу а после того как импорт завершён вернуть им обычный транзакционный способ доступа теперь что касается идентификаторов это такая насущная проблема которую при любом раскладе нужно как-то решить и даже не то чтобы проблема скорее особенность потому что маловероятно что сись какая система позволит вам давать свои собственные идентификаторы объектов и тут может быть два возможных решения первое это мы создаем у вершины дополнительные атрибуты понтифика таро и соответственно когда создаем вершину добавляем этому для диффе катару соответствующие значения и ну исходного иди которые у нас было либо же мы в каком-то внешнем хранилище будь то хоть какой-то объектом java вский может быть и сторонние именно решение типа редиса мы храним именно отображение из исходных идентификаторов в новые не of a j таким образом мы можем если потом нам приходит какой-то запрос на графе я мы просто васю пупкина переделываем там вы дентифик атор 0 который узнает но и fuji и уже его ищем и получаем там какой-то результат если мы создаем атрибуты на вершинах или ребрах то понятное дело что когда мы захотим выполнить какой-то поиск по этому атрибуту то будет осуществляться поиск по всем вообще существующему атрибутом в системе это будет очень долго и этот атрибут нужно за индексировать какие возможности индексирования предоставляет на fuji и их в принципе всего два первой и основной рекомендуемые разработчиками это вот то что я назвал метод схема . индекс пор фактически с помощью схемы данных мы просто указываем для какого типа атрибутов строить индекс если индекс построен при поиске по соответствующему атрибуту будет он использоваться если индекс не построим то будет поиск этого объекта по всем вершинам просто очень задолго работает только для атрибутах на вершинах второе это устаревший метод вот этот граф db . яндекс он возвращает объект менеджера индексов который фактически позволяет создать самому объект индекса который будет висеть в памяти в котором будут храниться вот эти вот отображения то есть это по сути сторонние раки его или хранилище такой индекс которым в которой мы сами добавляем объекты по которым потом будем хотеть производить поиск и третье это аналог вот это устаревшего менеджера индексов но только для режима бачин сердца потому что если мы работаем режим бачан сердце там так сделано что мы не можем сами взять и создать такой же яндекс он там не работает ну так вот сделано данные мы погрузили допустим настолько быстро насколько это было возможно какие у нас теперь есть варианты оптимизации доступа к данным мы хотим выполнить обход или какую другую аналитику хотим это сделать помощью java api или с помощью языка запросов сайфера не сильно важно что но fuji нам предоставляет для оптимизации этих запросов есть два типа каширования в f и j & the memory mapped каш и ну низкоуровневый как можно назвать не скоро у него кэш и объектный кэш 1 memory mapped кэш фактически служит для ускорения чтения и записи с диска фактически это такой такая система проецирующие файлы диджей файлы базы данных на fuji в оперативную память что вообще представляет собой экземпляр f и j на жестком диске это просто директория с набором файлов где каждый файл отвечает за какой-то свой тип объектов ну то есть файл с вершинами файл с ребрами индексами свойствами на вершинах ребрах и так далее и вот каждый из этих файлов делятся на странице одинаковой длины и те страницы в которые происходят часто и попадание при чтении или записи то они проецируются в память те которые в которые производят часто и попадание они не проецируются в память ну то есть очевидно система сама хранит свой внутренний коэффициент k попаданий каш промахов в зависимости там от того сколько вы ли на память и от того каков этот коэффициент странице проецируются в памяти линии проецируются значит как нам узнать сколько памяти нужно выделить под этот кэш особенно если мы допустим у нас память у нас памяти много и мы хотим спроецировать в память все размеры всех объектов известны вершина 15 байт ребро тридцать четыре байта атрибут на вершине или ребре сорок один байт и строка и массив они представляют из себя несколько блоков по 128 байт соответственно чтобы нам знать сколько нужно каждому типу каша вопрос нужно умножить размер объекта на количество объектов понятно тогда скорее всего нам нужно знать или предполагать количество объектов которые будут загружены у memory метод каша есть две основные настройки отвечающие за как за него первая настройка и самое важное по сути дела это такой флаг юз мимо ремонт burgers принимает значения соответственно true или false в случае если стоит значение true to для реализации этого каширования будут средства использованная встроенная в операционную систему если значение фоллз то будут те средства которые предоставляет самонов у джей здесь ждет солидная подстава всех пользователей windows потому что фактически юз memory map буфер со значение true на windows нормально не работает этого нигде не сказано в документации об этом не написано единственное что об этом известно это что на windows это значение по умолчанию falls а на всех остальных операционках но фуджина в и в линуксе в mac os поддерживается там стоит значение true и более того если вы запустите например импортного j в режиме бачин сердце и со включенным устном ремонт буфер сна винде то приложение вообще свалится по ошибке так что для оптимального каширования вообще на fuji на windows обламывается 2 настройка этом up my money фактически отвечает за то указывает количество памяти необходимо выделить для соответствующего каша для файла ребер файла вершин свойство так далее объектный кэш это уже такой более привычный кэш в обычном понимании то есть служит для ускорения доступа к данным для ускорения обходов грамма хранит в себе только вершины и рёбра некоторые особенностью является то что за вытеснение объектов из этого каша отвечает обычный сборщик мусора java а потому рекомендуется использовать параллельный сборщик мусора чтобы более эффективно производилась работ с памятью в этом каши вот тут есть главное отличие enterprise версий от коммьюнити бесплатной версии это то что в enterprise есть еще один тип кеширования специализированный так он так и называется high performance кэш это намного более сложная система и в нем речь идет о увеличение производительности но этого каширование в несколько раз за типы объектного кэша в но fuji и отвечает параметр кэш type и он может принимать соответствующие значения но это объектной кэш полностью отсутствует софт это стандартное значение для бесплатной версии подразумевает такую наиболее оптимальную работу с памятью из производительностью но могут возникнуть некоторые проблемы при обходах всего графа когда вот как раз объекты не успевают выталкивается из кэша то есть происходит такое заполнение каша слишком быстрая и потом он очень туго себя очищают значение вик фактически то же самое что и софт только время жизни данных в каше уменьшена и в принципе обходы с таким параметрам кэша производится быстрее strong соответственно грузит все значения в кэш которым при был произведен доступ это очевидно наибольшая производительность но память вообще съедается на 1 и вот этот high performance кэш в enterprise версий мифа j который фактически является главным поводом видимо купить именно enterprise версий пользоваться ей потому что в ней по умолчанию и все остальные каши там даже как бы не рассматриваются теперь я бы хотел рассказать про менее распространенный проект грантовой базы данных и тасс парксе которая как я уже говорил в прошлом называлась dex мы решили на нее посмотреть в первую очередь потому что оно много где фигурирует как специальная база данных для высокого ну для высокопроизводительного обхода графа это и сами разработчики заявляют и это же сказано во многих статьях на эту тему где там производится строго сравнения каких-то графа хранилищ данных из недостатков это то что она только встраиваемая фактически это просто библиотека а кстати написан на си плюс плюс с различными масками для некоторых языков то есть есть тут нет java и все остальное но на fuji понятное дело тоже есть там все коннекторы основным языком которые нужны она не особо распространенная а соответственно и сообщества и и достаточно слабая и в лучшем случае если у вас возникнет какой-то вопрос по ней то вы будете писать в google группе разработчиков или напрямую разработчикам блага они отвечают и она это база полностью закрытая то есть если на fuji и посмотреть код можно то здесь код вам никто не покажет ни в какой версии и единственной информацию которую можно почерпнуть о внутреннем устройстве с парксе ее можно узнать из ну максимум презентации разработчиков или там слов разработчиков то что они говорят приятный бонус то что она полностью бесплатна для исследований даже самая максимальная версия вообще лицензирование в парксе осуществляется просто по количеству объектов типа сколько денег заплатил столько объектов можно загрузить и достаточно написать разработчикам сказать что занимаешься исследованием описать задачу которую ставишь и они предоставляют лицензию хоть на неограниченное количество объектов в принципе для нас это было важно потому что мы проводили больше исследовательский проект такой и не были уверены что в конечном счете это будет использоваться в коммерческом решение что есть в особенностях spark те которых стоит упомянуть здесь в отличие от не of a j есть обязательное указание схемы данных то есть мы сразу должны указать какого типа мы создаем вершины какого типа мы создаем ребра атрибуты на ребрах все это сразу указывается и более того сразу для каждого типа атрибутов или ребер указываются там свои настройки индексирования об этом сейчас дальше скажу и так же как и в на fuji возникает задача отображение исходного идентификатора в внутренней дэн фиксатор системы здесь понятное дело тоже присваивается свой какие есть usb arxi настройки которые можно выделить которые влияют на обходы во первых при задании схемы данных мы когда создаем тип ребер мы можем сразу указать два параметра во-первых является ли ребра ориентированными во вторых производители специализированное индексирование всех соседей каждой вершины до там есть прямо специальная такая фишка которая впоследствии позволяет этот запрос выполнять очень быстро а раз этот запрос то и соответственно все обходы когда мы создаем атрибут какого-то типа на вершине или на ребре мы точно также можем еще указать является или этот атрибут просто какой-то дополнительной висящий информации либо же по нему будет производиться поиск то есть мы указываем что атрибут на tribute строится индекс кроме того мы можем сразу указать что атрибут является уникальным и помимо того что будет построен на яндекс система сама автоматически будет проверять что к этому атрибуту такое значение еще никогда не присваивалась принципе для хранения идентификаторов вершин вообще идеальный параметр при том что здесь индексы работают на действительно достаточно быстро в парксе есть один тип кеширования аналог объектного каша вафа джей и он точно так же служит для ускорения доступа к данным для ускорения обходов хранит в себе вершины и рёбра и в принципе главное единственная его настройка но единственная ни с кем так на самом деле там есть еще дополнительно стройке на главная настройка это просто размер этого каша который указывается в мегабайтах если указано значение 0 то соответственно используется вся свободная память - 512 метров которая система подразумевает что хватит чтобы системе там не повиснуть если память вообще все забьется что же мы в итоге к чему смогли прийти какому результату на попробовав эти базы данных мы тестировали на таком достаточно мощном сервере кстати кстати я еще не сказал что вообще нас в первую очередь интересовало чтобы все задачи графа вы и выполнялись в рамках какой-то одной локальной машины 1 там надо или сервера но на чем то одном то есть нас не очень интересовали класса рисованные решение потому что вообще задачи на графа вый анализ параллель это достаточно плохо за исключением того что мы просто можем в лучшем случае разные совершенно задача запустите в параллель но вот распараллелить например bfs это та еще задачка и потому интересно было насколько хорошо все это работает на одной машине поэтому нас процессор на я мощность не особенно интересовало а памяти как внешне так и оперативно и выделим был достаточно много 64 гб оперативки и 4 терабайта на жестком диске но fuji я использовалась последняя комьюнити версия на ubuntu соответственно ubuntu потому что ну в принципе любой linux подходит главное чтобы не windows потому что на windows не работает нормально memory буферы настройки java машины 64-разрядный профиль плюс 40 гигов на хип и параллельный сборщик мусора почему на хип 40 гигов они ну там 64 которые у нас есть потому что если вот этот memory mapped кэш реализуется средствами операционной системы то память на него выделяет тоже сама операционная система и памяти это будет выделен они в хеппи поэтому подразумеваем что 40 гигабайт на объектный кэш плюс все внутренние потребности на его j и 20 гигабайт на мы время буфер а ну и режим бачин сердцем для быстрого импорт естественно марксе использована последняя версия с неограниченной лицензией полученный с помощью просто общения с разработчиками для исследовательских целей на windows server 2008 64 разрядном код написан на dat нити и под кэш выделено 60 гигабайт ну то есть мы подразумеваем что наш джей и spork-и использует одинаковые объемы памяти которые им доступны что касается импорта мы тестировали на 3 наборах данных 100 миллионов ребер 500 миллионов ребер и миллиард ребер нам кажется считать в ребрах наиболее интересна потому что количество вершин вообще не растет с такой скоростью как количество ребер количество вершин их не бывает так много как ребер потому что ну это вполне естественное состояние графа и вершины в принципе вообще всегда можно хранить и в память в самом худшем то и случае а ребра и как бы более важный параметр их количество постоянно растет они постоянно добавляются это вполне естественно то есть здесь в этих наборах данных количество вершин составляет примерно 10 процентов от количество ребер ну то есть от миллиарда 100 миллионов вершин как мы видим и на fuji из парксе на 100 миллионах ребра ребер показали себя достаточно неплохо то есть они без проблем прошел этот граф спарки чуть больше часа на его j даже быстрее часа на графе в 500 миллионах миллионов ребер уже видим определенные сложности у него пуджей время импорта возросло не пропорционально объему данных а что касается графа в миллиард ребер здесь и то база это уже грузия достаточно долго время импорта непропорционально не совсем пропорциональное количество данных и она уже слишком большое для того чтобы это было интересно потому что если мы захотим выполнить какой-то какую-то анализ а у нас все еще идет импорт то понятное дело мы будем проводить анализ в лучшем случае но на старой версии графа это вполне тоже такая задача может быть поставлено и она может кого-то устраивать но нам это был не очень интересно то есть мы видим что ну скажем так когда речь идет о 6 4 гигах оперативы то здесь ну самому максимальным пределом разумного времени импорта данных является миллиарда же про не сказать меньше миллиарда ребер что касается анализа вот мы данные все-таки про грузили те объемы данных которые нормально прогружаются если у нас 100 миллионов ребер 10 миллионов вершин то и на уфа джейс парксе в принципе выполняют все за нормальное разумное время время в секундах указано но мы действительно видим что вас парксе тратит времени меньше особенно это касается от обхода всего графа и поиска пути а легковесный запрос типа получить всех соседей на этом объеме данных выполняется быстрее уефа джей на графе в 500 миллионов ребер мы уже видим определенные сложности пуджей на анализе всего графа то здесь тоже скорость bfs а также как и скорость импорта она уже возросла не пропорционально росту количества данных ну здесь так как бы сказать в общем на fuji и на объеме данных когда памяти ей начинает не хватать оперативный начинает работать плохо особенно когда и данные х нужно выгружать из немного так и можно сказать то есть мы пришли к этому выводу и несмотря на всю распространенность для больших данных то есть когда у нас там уже идут миллиарды ребер графа j на одной машине не подойдет spark си ведет себя здесь тоже вполне разумно ездил результаты обработки вполне такие достойные особенно стоит отметить что поиск соседей на этому графику спарте занял приблизительно 3 секунды кстати все запросы вот здесь это ну естественно запущенный они ни один раз это худший результат потому что 33 за три секунды на получение всех соседей это тоже не сильно здорово это скорее самый плохой расклад когда у нас у какого не ему какой-нибудь вершины очень много соседей такой там вполне может быть очень много инженерных ребер там речь идет о том что их могут быть там десятки тысяч все их нужно поднять вот на это требуется определенное время ну так вот у с марксе на этом объеме графа 3 секунды и на предыдущем объеме проч почти такой же результат 2 секунды то есть мы видим здесь сохранение такой результативности и этот как раз достигается с помощью того что мы поставили специальный индекс для вот фиксирование всех соседей на вершинах из парксе когда настраивали схему данных что в итоге это фактически наверно все что я хотел сказать подведем итог во-первых в целом с марксе действительно показывает себя более производительным чем на f и j особенно это касается когда нам нужно сделать тяжеловесный обход поднять какую-то большую часть графа и когда данных ну максимально много настолько многое вот насколько эти данные могут нормально уместиться в оперативную память в на f и j выделяются хороший очень результат обработки легковесных запросов особенно когда данных не так много то есть от типа 100 миллионов ребер и вот здесь на верху джей отлично себя показывает она быстро импортирует данные до такого объема она потом быстро получает всех соседей все легковесный запрос получаются как бы на ней очень здорово но в целом все все равно сводится к тому что если мы работаем в рамках одной машины не кластере зова най системы то у нас все упрется в оперативную память и как только что одну систему что у другой место напиши люблю играть и работать намного меньше и поэтому принципе мы пришли к выводу что на одном общение граппы миром больше миллиарда они будут обрабатываться достаточно посредстве на либо и их нужно как-то отсекать и делать не знаю какие там особой активизации из-за которых пострадали результаты если хочется обрабатывать все таки много данных здесь уже можно смотреть в сторону других решений старейших из арестованных их так например голды быть и там есть которой основательно нас и линии графа по многим сигнал или есть решение на ходу by the graphics возможно эти решения помогут в том случае если вам нужно обрабатывать действительно совершенно почти граф но у нее есть тоже свои ограничение на сошли серьезные поэтому они ранены даже как хотелось бы на этом все спасибо за внимание если есть вопросы я отвечу здравствуйте простой достаточно вопроса о чем я граф 200 миллионов узлов 13 миллиардов связи да и боится требуется грубо говоря находить соседи и присоединяет некоторые атрибуты зачем это вообще делать а вы если вам нужна только находить соседей вот только соседей ну в смысле вам не нужно делать более группу глубокий обход графа ну мне осторожностью термина графа сформулировать я могу описать исходную задачу ну давайте есть баннеры игровые на одноклассниках но и требуется писать под баннером надпись такую простую в эту иглу игра этом васи пупкина еще 30 твоих друзей какого сорта вещи вот на чем и считать на вскоре ли она плохо считается вот если в рамках только такой задачей но махи крылья не смог там это за разумное время загрузить больше и быстрее чем за две недели это там на полтора терабайта там данный грубо говоря 13 миллиардов связи и он году он помирает на подпись если ты еще не бабу я вот я думаю брать под лед или на самом деле если бы передо мной стояла задача вот ограниченная извините я забыл сказать время время ответа миллисекунду нужно да это важное условие на самом деле если прямо передо мной стояла именно задача вот ограниченная получением всех соседей без какого-либо более глубокого им про то есть нам не нужно в общем делать никакие обходы не нужно искать пути то я бы конечно в первую очередь попробовал что и похимичить соску элем возможно быть что-то получилось но если нет то на самом деле на fuji при том раскладе в котором мы точно знаем вот наш исходный набор данных можно попробовать загрузить данные специальному попробовать распараллелить бочки импорт есть такие системы я сам правда про них читала и например кое-что есть блоге разработчиков на эту тему когда мы можем отдельно начать грузить сначала все вершины а потом грузите все ребра то есть мы загрузим почему во многом возникает проблема вот когда мы грузим например только рёбра появляются новые ребра и мы не знаем что-то об этих новых ребрах типа там они существовали или нет потому что мы когда производим загрузку нам нужно еще проверить существуют ли такие вершины которые являются константами этих ребят раз они нам нужно это проверить там из отвесно там лезем в яндекс или ещё куда-то на все тратится время на fuji тратит на их дополнительную память если используется и и средства и все работает фигово если мы в принципе точно знаем что вот нам нужно загрузить сначала только ну вот это весь наш набор данных с четко заданным объемом вершин о которых мы знаем все и потом с ребрами на этих этих же вершинах без дополнительной до загрузки то можно это попробовать вот раз параллели почем part 8 я бы попробовал сделать на него джей спасибо и да извините сразу добавлю то есть почему науку джейд а потому что если вы загрузите данные то поиск соседей потом скорее всего будет достаточно эффективно работать там в после здрасьте а а да спасибо за доклад есть вопрос по поводу того примера где было два два куска памяти один хит и как 40 гигов и 20 шт анода какова была утилизация этих двух кусков памяти и пробовали вы варьировать вот эти значения для этом эксперименте извините что как сказали утилизация памяти да ну как бы может же так оказаться что допустим вот 24 который вы оставили да да они постоянно перезаписывали там чего то не хватало и притом если бы вы хип уменьшили к примеру самого приложения ставили немножко больше под кэш возможно показатель был совершенно других да да да на самом деле мы экспериментировали но все равно мы пришли к тому что вот этот memory and cash не работает лучше чем если под него выделить память и вот максимум столько чтобы загрузились все файлы то есть там сколько ты не выделяли большего чем нужно то есть 20 гигабайт здесь которая рассчитана это чтобы вот влезла миллиард чтоб в лес вот подразумевается если в общем мы то что экспериментировали если выделять больше памяти то лучше результата не было так вот смотрите вот в лес миллиард а у вас их там полмиллиарда до к примеру ты даруются лишняя память до эту память можно там использует для того чтобы реже горбач collecta да да я согласен у если у нас памяти меньше там 500 миллионов то ну как бы я говорю на 500 миллионов да но в принципе работает она как раз начинает работать плохо когда памяти и вообще вся заканчивается то есть когда нам у нас выделенному былин максимум для мы марионетки сша и заполнилась все снова основное но все остальное а пробыли вот это вот на бесплатных кашах да да да да они деби выводить даже не упомянули хотел там шарден аренде be a да не упомянул ни не просто не занимались им вообще глупо сданных много оно клевое например транзакции всякие умеет ну вообще там шарится я ничуть не спорю и я не утверждаю что все графа вы и базы будут работать плохо просто мы рассмотрели одно как бы самое распространенное решение которой есть много fuji-k темно про него знают и одно решение о котором все вроде как говорят что она типа очень производительная для больших графов я не говорю что все остальные графу и базы они не будут ни с чем работать конечно можно решить мы сейчас на самом деле остановились на том что мы решили реализовывать свою систему потому что мы теперь как бы точно знаем что нам нужно как мы можем оптимизировать память это нас в общем то сейчас больше устроила антифриз свои сузилось подпишите до эмоции"
}