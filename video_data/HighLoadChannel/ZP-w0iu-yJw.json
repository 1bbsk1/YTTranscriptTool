{
  "video_id": "ZP-w0iu-yJw",
  "channel": "HighLoadChannel",
  "title": "Как PostgreSQL работает с диском / Илья Космодемьянский (PostgreSQL Consulting)",
  "views": 3812,
  "duration": 2674,
  "published": "2017-04-22T12:23:31-07:00",
  "text": "меня зовут илья космодемьянский я работаю в компании пузыре сколь консалтинг занимаюсь собственно говоря самыми разными вещами связанными с под гриссом с его производительностью и тому подобными штуками сегодня я буду рассказывать о том как ну вообще в принципе многие базы данных на в том числе пожгли сработают с диском и вот например если вдруг у вас есть какие-то проблемы с записью right ahead logo если у вас там высокой проблемы с высоким моё в подгрести тот этот доклад для вас будет некоторое количество теорий но настолько насколько можно там в 35 минут там плюс свою на вопросы время вместить и такой концентрированное выжимка рецептов как бороться если есть проблемы с вводом-выводом как правильно подходить к вопросам настройки под gresso соответствующий ну собственно говоря вообще зачем базе данных диск это будет первый пункт по которым мы будем говорить еще немножко поговорим про особенности погреться на этом месте рассмотрим потенциальные узкие места где может начаться проблемы с диском и почему как оценить эти проблемы что они возникли как отслеживать их на регулярной основе как на какие параметры лучше смотреть и естественно поговорим о том как какое аппаратное обеспечение выбрать под сервы базы данных на погрейся как лучше настроить это харви и как лучше настроить операционную систему и непосредственно сам под grease для того чтобы максимально хорошо он у вас справлялся с большой нагрузкой на диск ну во-первых база данных оперировать страничками я думаю все более-менее кто с ними работает это знают страничке нужно читать с диска записывать на диск но прежде чем записать на диск они должны быть записаны в рейдах и блог потому что это быстрее у многих бас бывает проблема с записью райта hardlock потому что много транзакций и соответственно как бы не успевает диски подрядах и блогам с этим справится но самое главное такая проблема это в общем то выполнение чекпоинта когда у нас происходит синхронизация right ahead блога с хранилищем с блочным которое в котором эти странички живут перманентно у пост длится добавляется еще своя специфика подвеса есть такой процесс of the vacuum это грубо говоря подчистка старых версий предыдущих версий данных которые уже выпали из области видимости транзакций postgres выполняет их отложенную очистку с помощью демонов то вакуума в принципе это и при правильных настройках такая фоновая не очень сложная процедура но если настройки неправильные там может быть много всяких разных проблем еще под колеса есть так называемый пиджи силок это битовая маска с текущими статусами транзакций закончена забор china zara обречена и для ускорения доступа к этим вещам postgres кладет на диск такой файлик пиджи силок и вот в принципе наряде бас с очень большой нагрузкой и т.п. бывают проблемы что вот наступает перегрев на этом месте ну для борьбы с этим я сразу могу сказать можно использовать например ramdisk этот файлик совершенно безопасно можно положить на ramdisk если ramdisk при этом у вас развалятся будут небольшие тормоза пока под грех этим разберется и сделать новый файлик но в принципе как бы потерять его совершенно не критично эти данные как бы используются только для ускорения но не являются таким критичными данными ну и опять же всякие темпы дисковые сортировки хэширования что в общем-то тоже общие для многих баз данных единственное что как бы об этом стоит сказать если у вас запросы сводится на диск для того чтобы произвести там сортировку хэширование так далее это в принципе не нормальная ситуация и несовместимо с быстродействием базы данных по хорошему вам нужно параметр в общем-то память который выделяется на каждый маркер под gresso увеличить чтобы соответственно эта штука влезала туда ну естественно смотреть на запрос в explain анализе отображается эта информация что запрос освоился на диск и соответственно там тюнить уже в соответствии с этими вещами ну как я уже упомянул самое критичное это вот эти самые чекпоинты так называемые спайки от английского пик вершина на графиках диска и утилизации которое очень сильно ставят под вопрос возможность базы обслуживать остальные транзакции почему это происходит потому что например отличие от oracle а у которого есть лук райдер и деби raider который умеют отапливать дополнительные процессы чтобы быстрее синхронная запись осуществлялось после все делает через iv sing он поддерживается потому что многими платформами и так далее вот и все мкад такой ученик ресничный вызов там в unix и и поэтому если пошел и sing особенное в sing большого количества страниц то база очень слабо может что-то обслуживать еще и общем-то для операционной системы это тоже очень большая нагрузка поэтому основная речь пойдёт о том каким образом оптимизировать вот эти чекпойнты потому что они являются наиболее такой общей проблемой ну как устроена вообще картина мира ucoz glyco имеются жареные буфера имеется кэш операционной системы через который с диска и на диск происходит обмен страничками вот этими вот готовыми то есть когда у нас страничка просто поднята в память жареную память с диска она является чистой то есть мне нет никакого изменения если мы сделали изменения произвели апдейт insert или что-то такое хотя бы одного табло в этой памяти то страничка помечается как грязная что такое чекпоинты как это свод все собрать воедино вот эти вот самые чистые страничке когда помечаются грязными прежде всего происходит запись последовательная вал необходимый для восстановления информации когда эта информация записана у нас еще все еще жареной памяти висят грязной страничке но как бы информацию о них записано в валл-и commit уже возвращает что транзакция успешно закончена и все хорошо прошло чтобы синхронизировать этот вал с обратно с блочным хранилищем и чтобы грязных страничек жареной памяти не осталось база вызывает такую функцию check point он вызывается там по некоторым событиям триггере to check point занимается тем что он и звала данные переносит с помощью псинка опять же в облачное хранилище если у нас жареные буфера достаточно большие ну сейчас как бы нормальных денег стоит такие сервера где можно себе позволить 128 56 гигабайт оперативной памяти 400 с чем-то то эта операция может быть весьма больно и для всей базы данных и для всей операционной системе в целом потому что ну вот представляете через вот эту вот картину до обжаренных буферов через кэш и операционные системы к дискам прокачивается такой большой объем данных при этом прокачивается более-менее одновременно ну как во первых это понять если у вас будет правильный мониторинг этого дела а правильный мониторинг в данной ситуации как минимум включает дисковую цели утилизацию последнюю колонку от такой вот выдачи 100 то почему хорошо смотреть не просто и опциями на дисковую утилизацию у вас на ней будут пике когда у вас диск и утилизация маленькая это значит что база накапливает вот эти вот изменения которые у вас есть в жареных буферах у вас там много грязных страниц при этом себе более менее хорошо работает потому что диск ничем не занят как только у вас пошел чекпоинт пошел дамп этих грязных страниц через pdf ваш в конце концов вниз на диск и соответственно дисковое а возрастает многократно и вполне может быть что вы упираетесь в сто процентов дисковой утилизации это очень плохая ситуация потому что в данном случае у вас во первых ибсен блокируется что только можно ничего большая операционная система делать не может и база соответственно тоже и плюс к тому банальна это может продолжаться некоторое время и вы не можете там не знаю там банальный select сделать если все совсем запущена и можно смотреть собственно говоря такую статистическую верху 50 bg raider которая говорит о том как check point произошел какие чекпоинты произошли и на основе нее можно делать такой разумный тюнинг ну как и пользоваться я немножко позже покажу вот собственно говоря пиджи stand by gerald r если вы посмотрите какую такую статистику но это взято с простой виртуалке на которой ничего толком не настроена просто коробочные настройки и тут мы видим что все достаточно плохо у нас чекпоинты ну вот первые две строчки запрошенные и по таймауту срабатывают примерно в каких-то сопоставимых соотношениях нет такой ситуации что одних много других нету и это скорее всего значит что она что-то настроена не оптимально если мы посмотрим в такой ситуации на график диска утилизации то там тоже будет все не очень хорошо вот как бы это признак того что нам надо какие-то гайки покрутить если у нас как бы все по умолчанию идёт то с самого начала инсталляции базы у нас считаются вот эти счетчики это не очень полезно для оптимизации потому что на характер профиля нагрузки на базу меняется чаще чем с момента того как мы поставили по сгрыз поэтому полезно эту статистику сбрасывать периодически приведенные вот здесь вот командой и анализировать например за какой-то короткий период времени 3 сзади иногда в случаях когда очень много нагрузки то лучше даже за какие-то более небольшие промежутки времени например за час или за два часа то есть периодически надо вот таким вот образом сбрасывать только вот эту статистику что делать ситуации когда у нас все плохо с записью на диск ну во первых нужно обеспечить базу правильным hour 2 если более менее нормально и железу то у вас все будет более-менее неплохо до очень больших объемов нагрузки как правило мало какие веб-проекты с таким объемом нагрузки правильный как бы такой полезной сталкиваются во первых ни в коем случае не надо покупать дешевые raid-контроллер что называется дешевым рейд контроллером основная цена нормальную рыть контроллеры такой этот чип который на нем есть его собственные мозги если этого чипа нет и контроллер стоит там условно говоря там 100 долларов за новый не был ушли контроля значит скорее всего там это очень планету и этот контроллер будет использовать ваша сепию если контроллер использует вашу семью то у меня для вас плохие новости в принципе любой сад верный рейд будет лучше потому что как бы будет происходить драка за ресурсы там где ее не должно быть рейд контроллер должен быть сбегаю с батарейкой то есть у вас должен быть кэш и этот кэш должен быть забу каплин батарейкой чтобы если ваша система упадет то соответственно у вас эти данные остались как это связано с быстродействием быстродействием это связано очень прямо потому что собственного если батарейка у вас есть to sing проходит на диск данные попали на батарейку и после этого и стинг возвращает что он успешно записал а уже батарейка характерно гарантирует что данные будут записаны если же батарейки нет она например села или просто не поставлен не предусмотрена то начинаются проблемы такого рода что пока достоверно не записаны данные на диск f sing не отвечает и у вас вот это вот ситуация с чекпоинтами еще больше усугубляется поэтому когда вы работаете со льдом батарейка должна присутствовать быть исправна производителя вот если так рекомендовать рейды это не так критично в принципе то есть я не рекламирую какого-то конкретного производителя если у вас есть опыт работы с каким-то конкретным рай дом и вы знаете какого настраивать и все хорошо то как бы пользуетесь им мы обычно как бы любим более всего megaraid и перк что в общем то более менее одно и то же то есть лассо и del потому что у этих систем как бы не известно нам таких неприятных фокусов в основном за долгие годы опыта и плюс к тому у них очень консервативны и утилиты управления то есть все гайки на привычных местах и с ними работать удобно вот например очки дела и тоже очень хорошие рейд контроллеры но вот у них ситуация обратная мы несколько раз за последние время напоролись на такие проблемы когда вы покупаете не топовые диски вставляете в топовый контроллер и диски искусстве нашей пяться по скорости потому что производитель заботиться о том чтобы покупали только самые дорогие диски вот и этого никак нельзя понять кроме как сравнить несколько под номеров в принципе это как бы нехорошая ситуация и особенно когда берут сервера у вариант у хостера на такие вещи наступают вот таких штук надо остерегаться значит для рейда в принципе имеет смысл соблюдать вот эти вот настройки то есть должен быть включён right back кэш и а мод должен быть директ и потому что асинхронным это плохо потому что как бы под глисон умеет и в sing такой вот очень простой и disk write cache мод ну тут вопрос такой если у вас не очень хорошие диски не самые такие топовые enterprise ные то его лучше выключать если у вас как бы хороший например там ssd серверного класса у которых есть конденсатор то соответственно он там наоборот должен быть включен потому что эта штука гарантирует то что у вас при попадении железо как бы конденсата успеет записать сохранить на флешке то что у вас записалась на этот диск уже с контроллера попала что касается самих дисков чтобы все работало хорошо ну как бы такая дефолтная рекомендация коми специфических случаев используйте маленькие счас и маленького форм-фактора они вполне себе есть уже достаточно скоростные и при этом вы выигрываете в скорости сика чисто за счет физики вернее даже обсказал геометрии потому что банально по небольшому диску головки двигаться меньшее расстояние там меньше соответственно происходит это все быстрее не используйте десктопного класса ssd pny key в ssd щас все верят как в панацею что она спасет мир это не совсем так потому что ssd бывают очень разные поставившие не очень хорошие создаешь ник вы рискуете получить скорость сопоставимую со то и еще кучу проблем с тем что он может элементарно отказать развалится у него может оказаться меньше циклов перезаписи чем гарантировано производителем и так далее и тому подобное и я бы еще не советовал использовать ssd он для инсталляцию вообще для база данных для подвеса в частности потому что помимо тех вещей где создают выигрыш у вас есть какие-то таблицы где страндом sick у вас есть еще райта ходу волок у вас есть темп у вас есть еще много всякой такой записи которая в общем то никак не ускоряется ssd потому что ну как бы последовательно я записывал это не очень хорошая вещь для создает вот сокращает количество циклов перезаписи и у вас приходится часто менять эти создашь ники при этом они могут сгорать там ну достаточно непредсказуемо вот и вы не получаете никакого выигрыша кроме хлопот вам нужно будет там представлять админы с лопатой чтобы он подкидывал туда как в топку насчет новые винты не самая лучшая идея ну опять же что касается рейда тут я думаю никакой америки не открою лучше использовать десятку да потому что иногда в велик соблазн сэкономить и получить чуть чуть больше места за счет 5 или 6 но во первых этот рейд более медленной во вторых более уязвимой просто потому что ну сгорела вас диск который в по ринге участвуют и у вас уже начались серьезные проблемы stripe да быстрее но тут опять вопрос сохранности данных если у вас type развалился то все таки плохо вот и соответственно если у вас нет возможности хороших диски поставить то надо выбирать с включенным синхронным коми там когда база данных выполняет commit и до того пока все комменты не попали на диск на батарейку или куда то еще не возвращает и ждет вот как бы без нормального райда с батарейка или хорошо настроенного массива это никогда не будет работать быстро поэтому если у вас от одесские какая то более менее имеется нагрузка то эту штуку лучше ставить вов но при этом понимать что вы можете потерять последнее транзакция которые за комичен и с одной стороны ничего воде в этом страшного нету потому что база у вас все равно будет консистентная но с другой стороны ваше приложение считает что на эти транзакции получен положительный ответ commit a в эти транзакции потеряли в общем скорее всего можете никогда об этом не узнать эта ситуация такая неприятная здесь как бы можно выбирать только из у вас очень критичны и данные такие штуки делать что касается файловые системы как обеспечить максимальную производимой в производительность базы ей во первых ну про a time все знают я думаю что как бы 100 мом будет медленнее чем без него но как бы не все знают что лучше еще отключать барьер есть такая опция джи-би-си барьер дуба барьер который соответственно включена на большинстве правильных файловых систем типа и к 4 или xfs по умолчанию что это делается когда у вас есть запись журнала в нальем и файловой системе данные для журнала записались или наоборот данные для енотов а соответствующие этим данным для журнала данные и нодов не записались вот и получается как бы такая ситуация что если в этот момент обрушиться напряжения то вы не сможете восстановить систему средствами журналирования встроенного журнала в такой ситуации в линуксе вызываю вызывается этот syscall который останавливает дальнейшей дамп на диск и ядерный буфер начинает перестраиваться чтобы эти данные для этих данных журнала нашлись те данные нодов которые надо записать в этот момент представляете если у вас 128 гигов жареных буферов то вы имеете очень большую проблему и реально вам никак не помогает ваш хороший raid-контроллер потому что он никак не используется bootleg до него то есть за счет вот этого вот барьеров начинаются проблемы обратите внимание например в небе они его можно посмотреть только если включить полную выдачу маунта минусом иначе эта опция не показывается ну еще как бы полезно понимать что если у вас есть какая такая вкусная и удобная для админа система депозитов с да где софтверный рейд гибко все настраивается все можно переносить практично туда практичным сюда как правило это не про performance то есть для тестовой разработчики следы этой работает для продакшена это медленно и надо использовать простую тупую xfs там или к 4 в линуксе соответственно что касается операционной системы у нее в принципе тоже устроена такая же штука типа база данных да то есть есть чистой грязные странице их надо добить на диск по умолчанию почему-то не знаю почему это контролируется параметрами выставленными в такие вот значения в в м дети решил 20 там или соответственно по гранд хорошо 10 это умолчание там большинстве дистрибутивов что это такое pdf уж когда скидывает грязные страницы на диск не начинает работать если не накоплено 10 там или соответственно 20 процентов от оперативной памяти в большинстве случаев это очень много представьте себе у вас 128 гигов оперативной памяти у вас 20 процентов от этого дела дорогой хороший cashmere идеи ну гек 2 там редко бывают час больше еще до то может быть и 512 мегабайт соответственно вы эффективно забиваете в есть крыш этой штукой при этом когда эта штука еще накапливается pdf ваш не работает и не использует это окно когда можно более безболезненны эти вещи сдам пить на диск соответственно лучше перестраиваться найдете боится-то альтернативная настройка если вы в какое-то значение устанавливаете то первый вариант настройки эффективны становяться и равен нулю и по этим байтом чтобы она достоверна у вас помещалась в кэш батарейки тогда у вас как бы ситуация будет существенно лучше чем с этими дефолта me опять же если у вас более простая инсталляция и нету кашан r&d тем более вам нужно еще меньше эти значения поставить потому что если много оперативной памяти 20 или 10 процентов вам ввод-вывод убьет с гарантией эти вещи надо достоверно менять ну и в конце концов нужно настроить еще пуск и сколько он чтобы у вас эти чекпойнты писались поаккуратнее получше во первых что для этого нужно сделать вот вал баферы вал баферы это на самом деле те файлы логов которые пишет пост goes right ahead их можно сделать чуть чуть побольше чтобы накапливалась побольше изменений после этого происходил чекпоинт и как бы большим скопом данные переносились и соответственно не получалось так что у вас постоянно я такая пила на десткой утилизации что постоянно диски чем-то заняты и реально никогда не эту ситуации с оптимальным вводом-выводом вот но тут надо как бы думать нам если вы исходите из идеи что у вас должно быть по мере накопления грязных страниц один большой такой flash происходить на диск вы ставите check point сегмент в какой то более менее большое значение но здесь вот 256 значение большое у меня например там есть кое где и там 1000 сегментов между чекпоинтами если это оправданно можно ставить и высокие значения но надо понимать что в такой ситуации у вас уже например не через 48 мегабайт накопление грязных страниц будет чекпоинт а вовсе даже через четыре гигабайта что в общем то довольно много для большинства таких не очень продвинутых рейд контроллеров вот в такой ситуации вам нужно как бы исключить чекпоинты по таймауту чтобы они ни происходили слишком часто и чтобы не перегружать вот таким поразительным вводом-выводом систему вот поэтому вы выкручиваете check point таймаут на максимум и тотчас по-моему сейчас по умолчанию и тогда все чекпоинты вас более-менее при большом рынке записи будут происходить только по накоплению сегментов и соответственно ну как бы с разумной частотой в 500 by gerald r у вас одно значение будет 0 другая там будет расти соответственно тому как с какой частотой вас происходит чекпоинты в принципе тут можно применять две идеологии два подхода можно наоборот сделать чекпоинты только по таймауту выставив какое-то разумное значение а сегменты поставить каким-нибудь очень большими чтобы соответственно чип intel очистка промежутки времени сугубо исходя из того как а вам нужна скорость восстановления случае аварии потому что если у вас чуть point происходит чисто по сегментам у вас немножко дольше займет время восстановление чем если он у вас будет происходить по таймауту опять же есть такой параметр check point com пляшем таргет который мы советуем выставлять где-нибудь 07 и 09 это как бы процент времени до следующего чекпоинта за которой предыдущий должен завершиться то есть это такое средство размазать вот это вот дисковую нагрузку между двумя чекпоинтами чтобы она постепенно полога спадала и соответственно не было слишком интенсивных записей прямо в момент чекпоинта а потом более-менее никаких соответственно если бы она была выставлена скажем в 01 это бы означало что необходимо за 10 процентов того времени которые происходят между чекпоинтами скинуть все а грязной страницы на диск и это было бы соответственно очень очень интенсивная запись что не особо хорошо в принципе как понять что все классно и мы все сделали правильно у погреться bluesman жан который уже здесь выступал прекрасный доклад сделал есть прекрасная утилита им написаны пиджи тесты в sing вы просто смотрите как вы настроили операционную систему как вы настроили харви и смотрите сколько и опусов эмуляции вот это вот нормального жизненного процесса чек-поинтов под gresso сколько операции ввода-вывода вы получили если вот вы получаете такие не большие цифры это виртуалка на моем ноутбуке да то значит это не очень хорошо значит вы что-то не достроили может вы там например барьер не отключили а по моему здесь не отключал либо у вас там плохие диски и так далее если у вас там цифры отличаются на порядок в лучшую сторону то значит наверное все таки по крайней мере на стороне операционные системы и файловую систему у вас проблем нет но здесь не вся выдача показано там она длине и там разные тесты производятся с разными размерами страниц и так далее в общем посмотрите изучить ее на досуге когда вы собираете h2o на новый сервер это штука очень полезно для того чтобы на нее посмотреть ну еще такой небольшой хак который очень сложно истолковать и поэтому мало как бы кто его так в тупую советует помимо чекпоинт ира грязные страницы в паз грецку или на диск может списывать by gerald r ты сам как бы backend и это в ряде случаев полезно почему это полезно потому что чекпоинта массово списывает много грязных страниц и в этот момент как бы нагрузка на дисковую подсистему самая максимальная by gerald r может списывать некую страницу которая грязная но давно не использовалась она утонула по кашу вниз там простой достаточно но как простой условно простой сложно на самом деле алгоритм у вас 30 views и если она больше никому не нужна она может быть списана на диск самим брендом в отличие от чекпоинт эра это происходит потискать фоновом режиме и не сильно загружает на запись все это дело то есть принципе обычно бега райтер не занят такой запись в интенсивной и он может себе позволить некоторое количество страниц списать и тем самым разгрузить чекпоинтах вот вот эти вот параметры 3 они регулируют ток каким образом страница падает в к шейла streisand ли юст и полезно их на максимум который возможен выкрутить вот соответственно максимум здесь указан там 10000 1010 вот пять параметров ставятся и в такой ситуации мы наблюдаем что у нас как бы чипа enter разгружается от лишней записи и больше нагрузки ложится на by gerald r и в принципе как бы ситуация вот с этими большими чекпоинтами немножко выравнивается на экстремальных нагрузках по апдейтом inserting когда много logo генерится большая-большая оперативная память там много грязных страниц эта настройка правильно ее нужно использовать вот про что ещё я забыл так сказать и обязательно нужно помянуть полюсе есть вот эта самая очистка устаревших версий of the vacuum of the vacuum с ним есть такая неприятная вещь ним очень многие люди мучаются потому что вот of the vacuum включили он там третий день работает занял очень много места и в общем все плохо давайте мы выключим чтобы он очень не мешал его выключают потом убивает процесс или как-то потом значит начинается дальше дальше дальше он опять стартует пытается работать все дольше потому что грязно самых предыдущих версий накопилось много ну и в общем дальше заканчивается все печально по таблице 40 мегабайт соответственно банальный select идет там 30 секунд и решить в этом роде и вот а потом сначала злобно обвиняется позарез а потом ищется виноватой да вот виноваты мамаши машет ручками вот ну как бы такая ситуация регулярно бывает и надо просто знать как правильно настраивать of the vacuum чтобы таких проблем не было of the vacuum из коробки настроен не агрессивно что это значит вот есть два параметра of the vacuum vacuum sky фактор прежде всего и такой же параметр право на life of the vacuum анализ scale factor вот по дефолту они там вот первый из них выставлен в 20 процентов это что значит 02 что у вас про пришли изменения в таблицу изменилось 20 процентов записей от них остались предыдущие версии потому что позарез реально не делает апдейтов он делает insert нового табло и делает дэвид дэвид эффективно никакой не дали то просто он убирает из области видимости текущего ского по транзакции данную версию этапу продолжает лежать на диске of the vacuum должен вычистить вот вот у вас накопилось 20 процентов данных в таблице представьте что это будет если у вас миллиард записей на и после этого вакуум начал мучительно несколько часов подряд это все дело перекрашивать и соответственно это большой overhead по диску потому что ему надо это дело писать и соответственно куча проблем такого свойства что у вас там длинные транзакции какие-нибудь там где деле они соответственно мешаются с фото вакуумом и как бы база чувствует себя плохо по хорошему эту штуку надо выставлять в минимально возможные показателя то есть например на тысячная 100 что-то между ними то есть эффективно меньше 1000 ставить не это самое не получается потому что слишком часто будет риге rites of the vacuum по данной таблице в такой ситуации у вас of the vacuum будет срабатывать тогда когда нужно да то есть маленькая порция данных изменилось of the vacuum пришел быстренько прошел по этой таблице после этого как бы у вас нет такого вверх и до по одесскому вводу выводу и так далее у вас все of the vacuum и быстренько отрабатывают и начинают заниматься другими табличками какой здесь может быть подводный камень по дефолту вас три worker of the vacuum а если они все три у вас постоянно работают то есть там 9080 сто процентов времени это значит что скорее всего у вас не хватает этих маркеров вам получается что табличка на нее выставлено что при изменении там 1 процента и и или 0 1 процента нужно сделать of the vacuum когда этот момент наступает нет свободного worker чтобы это выполнить у вас образуется очередь табличка тем временем продолжает там обратиться жить изменяться и реально когда освобождается worker of the vacuum а чтобы по ней пройти ее от of the voca уметь в ней уже легко может быть заменена 20-30 50 процентов данных и вы получаете тот самый длинный of the vacuum который часами работает и всему мешает вот поэтому если у вас процесса работают часто то имеет смысл подбавить там поставить 10 20 ну там проследить чтобы у вас хватило в окне моно это дело но чтобы of the vacuum и у вас успевали все это дело хорошо отработать в принципе если вы их например за на исети кронам они не будут сильно сжать диск и в фоновом режиме отрабатывать если их много достаточно то более менее по всем таблицам и вас of the vacuum будет хорошо справляться вот ну вот это было более менее все у нас осталось даже не говорят 12 минут на вопросы так что задавайте спасибо так мур-мур можно презентацию если не трудно назад чтобы я показал вот там есть ещё она lays on алайский фактор этот то с какой частотой будет происходить она лайс вот он менее критичен для производительности хотя там тоже есть свои проблемы потому что он на самом деле откручивает счетчик транзакции 32-битной на прежнее состояние вот поэтому его нельзя делать так чтобы он по 50 процентам таблички ходил но он может быть настроен чуть менее агрессивно например там соответственно в две сотых в три сотых там в четыре sata где-то так вот вот чтобы демон обновлял статистику планировщика проходился по этим табличкам чтобы у вас как бы всегда планировщик выбирал адекватный план зная сколько у вас изменилось чего в табличке как то так можно вопрос я правильно понял что автомаг он занимается удалением уже удаленных записей из таблицы он занимается именно удалением потому что собственно говоря когда просто происходит делить сам-то пау реально остается ему просто прописывается xmax самая максимальная транзакции найди где этот топор еще виден то есть если из базы данные практически не удаляются от на автомойку можно поставить например на 1 сутки нет не стоит этого делать потому что таких баз где данные никогда не удаляются и не обратиться не бывает у вас например есть пиджи каталог в котором хранится очень много служебной информации и при отключении вакуума глобальному вас на пир в каталоге вакуум тоже отключится и эффекты потрясающий получается то есть как бы тормоза начинается совершенно непредсказуемы потому что например чтобы посмотреть какой тип данных его проверить да там например прилуках по индексу приходится обращаться к очень распушите фрагментированной таблицы служебной и соответственно производительность падает очень сильно такой тип еще вопрос добрый день скажите пожалуйста есть ли какие-нибудь особенности в настройки под криса при запуске в виртуалка ну например к в м с драйвером вертела я бы сказал так есть некоторые особенности работы под грессов таких виртуалка х именно возникают различные проблемы с вводом выводов прежде всего из-за непредсказуемого latency диска принципе подходы все более-менее те же самые тока как бы вот такие агрессивные настройки чекпоинта например выставить невозможно из-за того что как бы виртуальные у это дело просто не проживет даже sliver там вот второй момент состоит в том что в общем то наверно на virtual как лучше жить с отключенным синхронным коми там вот от параметра по которой я говорил да потому что тогда немножко получше бы получается производительность ну так же как для медленных просто дисков делается именно из этих проблем с производительностью виртуальных дисков но надо быть надо понимать что вот у вас там 3 коммента произошло вот они накопились где-то в любви рту и в этот момент у вас что-нибудь упала по какой-то совершенно другой причине да и вы рискуете эти там транзакции потерять часто как бы с виртуалками это делают но надо как бы знать свои риски илья спасибо за доклад на три вопроса если можно давайте значит первый вопрос вот вы упоминали что вы используете в sing вы используете имени ибсен к или в data sync все-таки но в принципе как бы в большинстве случаев между ними не самая крутая разница но вот это вот утилитка по г тесты в sing она покажет как раз как на вашей платформе с вашими настройками с вашим бедром конкретным какой из типов уфсин к лучше работает и вы просто как вы можете посмотреть на этой платформе и выбрать включить его пузыре сколько он в тот который у вас работает быстрее и это как бы правильный подход спасибо не второй вопрос вы упоминали что на дисках не ssd особенно на слабых и т.д. дисках эффективно отключать райт кэш на диски на самом вот можете как-то прокомментировать потому что на самом деле райт конечно же позволяет как бы рандомной райт и ускорять смотреть в чем твоя смотрите point состоит в чем на дорогих интер прорезных северных дисков на всех есть конденсатор вот соответственно это значит что когда с контроллера туда попали данные чтобы не случилось они будут туда записаны при этом эта штука более-менее надежно я прошу конденсатор реально он вечный он нет не батарейка его не надо постоянно менять в ситуации если у вас на диске есть кэш но нету конденсатора проблема заключается в том что вас рейд со своего каша прокинул запись на диск страничку она уже как бы с точки зрения база данных точки зрения системы записалась а на самом деле в этот момент у вас сдохнет диск по каким-то причинам там электрическим и механическим кем угодно и эти данные реально не доходят до 100 раджа и вы имеете не консистентную поломанную базу вот собственно говоря и единственная причина по которой этот конечно надо отключать если у вас нету там каница конденсатора понятно и третий вопрос вот планируется или каким-то образом не знаю может быть покатил расширять чтобы вот некоторые настройки типа для рейдов и так далее чтобы он делал как то автоматически то есть ему говоришь у меня есть теряется с таким так уж он а он дальше там все делает знаете это как бы довольно сложный вопрос разработчики дискутируют об этом уже очень давно и как бы поскольку это такая не то чтобы супер критичная для производительности или для маркетинга фича дискуссии очень длинный развесистые и в общем-то ни к чему не приводящие то есть потихоньку потихоньку там вот если обратили внимание жареных буферов чуть-чуть стало больше там в окне матче стало больше но вот как бы это все в направлении того же самого вот когда это дойдёт до операционной системы и тому подобных вещей совершенно непонятно я думаю что не в ближайшем будущем потому что опять же под glyco есть идея что он должен заводиться в любой кофемолки куда вы его не поставили а тут нужно смотреть на очень много всяких параметров потому что вот общему пример все что я рассказал это очень лину в специфичные вещи нам еще тут рекомендуем в основном на хороших последних версиях ядра linux подгонять вот там с при выезде это будет уже немножко другие особенности если это будет solaris личке x они будут вообще там совсем другие и как бы под то разнообразие платформ который сейчас поддерживает postgres сделать такой wizard это очень сложно и как бы никто за это не берется пока что поэтому как бы вот имеет смысл составите такой чек лист на что посмотреть что проверить и соответственно по нему действовать еще вопрос насколько эффективно пост газ работает на бензине насколько там идет потери производительности понимаете в чем дело в принципе он там работает скажем так now free bsd есть очень много вещей которые в силу там векторы развития современного они отстают от linux отстают здорово ну вот хрестоматийный пример это например пейдж да то есть лишь появилась появились в bsd позже нормальная поддержка для для пуска леса которые сейчас вот в 94 есть она работает только с линуксом да то есть вы например будете иметь overhead по использованию маленьких страниц памяти на больших жареных буферах это будет легко могут быть порядке по скорости если у вас такой специфический workload опять же с производительностью синко на диск на современных там ядерных старше 33 linux вах там есть много оптимизации сейчас сообщество разработчиков очень плотно сотрудничает ядра с разработчиками там под грей скую или mais quel и там тоже производительность может отличаться там но если на порядки то в разы во всяком случае то есть к сожалению выезде при выезде хотя очень хорошая и на такая надежная и удобная администрирование система она от этих вещей отстаёт плюс к тому там например опять же что касается таких оптимизацией ядра там не стоит забывать что многие из этих оптимизации более-менее вносятся такими игроками как орка лувре объем до для их бас да тебе твоего варкала собственно говоря они спонсируют эти разработки сами частичные кодируют а соответственно на free bsd никакие классические базу данных такие коммерческие не поддерживаются соответственно везде они обходят своим вниманием вот проблема такая спасибо более менее можно считать ну по крайне мере мы всем нашим клиентам так рекомендуем и опыт показывает что это эффективно так что вопрос у меня такой вопрос от чтобы может быть вы порекомендовали для bас которых отсутствует апдейта нотка класс просто у них только всегда добавляются новой записи также для редон либо сну или база которая обновляется там 1 месяц грубо говоря ну смотрите если грубо говоря поток insert of большой то по записи рекомендации все те же самые да то есть как бы апдейтов конечно нету но вот это самое оптимизировать запись можно точно таким же способом единственно какой здесь момент есть неприятный если у вас база только на insert это знаете что она у вас неуклонно монотонно растет и вот это уже как бы ситуация более-менее плохая потому что как правило это какие-нибудь time bass inventory да когда ну какие то события пишутся по темпу это означает что эффективно вы умеете горячую голову по которой вы делаете всю какую-то свою аналитику и очень холодный большой архив который реально борется с этой горячей головой при рандомном каком-то чтение за жареные буфера завод вывод и за прочие вещи то есть вам на самом деле скорее всего нужно наводить какую-то процедуру архивирование чтобы не актуальны и вещи держать то боевой базе более-менее агрегированные а соответственно старая все куда-то архивировать и сносить плюс к тому наверное вот для редон либо вас где много чтения на каких-то и таких вещах имеет смысл вот такую классическую архитектуру там ssd использовать когда у вас вся база живет насосах а ssd соответственно живут только под отдельным ты успей сам и вот те таблиц из которых например идет наиболее интенсивное чтения выносить на этот tbsp ssd особенно их redex и вот чтобы у вас чтение было максимально быстрым и соответственно кэш прогревался представьте базы наиболее эффективно и быстро за счет этих и вот тогда вы можете например всякие такие касты типы рэндом печь cost опустить по сравнению с дефолтом послушайте ssd быстрая и соответственно у вас тогда оптимизатор будет выбирать более оптимальные планы у вас этих таблиц будет более быстрое select и они будут отосланы в памяти лучше работать до можно еще последний вопрос давайте тогда последний вопрос да вот про архив спросили или какой последний вопрос да поподробнее история такая вот например есть у вас позиционирована я таблица потом неделя-другая недели например вот вы держите горячую эту самую голову 3-4 недели ну сколько вам реально нужно по этой аналитики ездить все что дальше вы например схлопывается в одну большую партицию и старайтесь к ней не ходить лишний раз чтобы соответственно не мешалась в воде выводя либо эту последнюю партицию вы просто даете он остин другую машину если вам нужно которой они имеют онлайновые лтп нагрузки по вот этой агрегации всякой и если вам нужно получить эти данные вы туда идёте и соответственно там гоняете эти запросы чтобы не портить картину на главной базе в общем так еще последний вопрос или как все коллеги спасибо за внимание поскольку у меня осталось 30 секунд если что вы можете меня найти нас там стойки в экспертной зоне где написано под греис quelle и любой вопрос там у меня или у моих коллег еще дальше уточнить как по материалу этого доклада так и вообще спасибо за внимание"
}