{
  "video_id": "zqEfB7C00sc",
  "channel": "HighLoadChannel",
  "title": "Computer vision API: highload ML on GPU / Юлиана Лихолай (Mail.ru)",
  "views": 3540,
  "duration": 2520,
  "published": "2019-12-05T08:19:47-08:00",
  "text": "секция нейронных сеток на хэллоуин является весьма новой темой вот мы будем рассказывать про компьютерное зрение в крупных компаниях таких как компания mail.ru как происходит процесс вывода не ровной сетки в продакшн у нас существуют группа людей которые условно называются ресеч иры они занимаются тем что создают неровную сетку с нуля они ее обучают и пишут скрипт на питоне в котором показывают как правильно это нейронную сетку нужно запускать и использовать но для больших нагрузок нам необходимо и другая команда а именно команда программистов эти программисты будут заниматься тем что будут разрабатывать backend который будет обеспечивать высокую нагрузку он будет отказоустойчивой и он будет нацелен на то чтобы максимально утилизировать и ресурсы который он имеет модели которые обучают наши ресеч иры мы гоняем на си плюс плюс ирис вечер и они конверте от нашей модели специальный формат который мы можем себя гонять так вот я работаю на данный момент в компании mail.ru и я программист я занимаюсь именно тем что разрабатываю backend который нужен для того чтобы использовать эти нейронные сетки в продакшене наш сервис компьютерного зрения он был создан для того чтобы обрабатывать фото и видео на данный момент он позволяет на изображении находить различного рода объекты достопримечательности он позволяет распознавать документы и лица по сути наш backup & the rest api который обрабатывает http-запросы запросе у нас содержится картинка а в ответе у нас будет джейсон джейсоне написано что именно находится на данном изображении если мы говорим про распознавания лиц то к нам прилетает также сообщения затем мы запускаем уже внутри нашего сервиса детектор лиц и находим все лица на этом изображении для каждого лица мы запускаем сетку распознавание и вычисляем вектор признаков embedding затем этот вектор мы пытаемся найти в нашей базе данных и если мы не находим ничего похожего мы считаем что в нашей системе появилась новая персона назначаем ей какую либо метку и сохраняемся в базе данных следующий раз когда в нашу система попадет картинка на которой будет тот же самый человек мы вычитаем embedding найдем у себя и в ответе вернем и минуту метку которая была присвоена ему изначально основными клиентами на данный момент нашего сервиса компьютерного зрения являются внутренние проекты компании mail.ru это такие как почта облака а виде публичного piano доступна на платформе mail клауд solution где каждый может зарегистрироваться и играть с ним послать туда запрос как можно в продукте использовать компьютерное зрение здесь на слайде я представила кейс из программы облако mail.ru облако mail.ru она хранит файлы пользователя например фотографии каждая фотография которая загружается в облака на самом деле отправляется в наш сервис наш сервис выполняет ряд операции распознавания и возвращает набор тегов для каждой фотографии на основе этой информации создаешь создаются умные каталоге например фотографии могут быть для пользователя разделены по персонам которые были найдены у него либо например по объектам кошечки спорт и так далее города достопримечательности и так далее переходим на вас непосредственно к самой интересной части доклада в своем докладе я буду рассказывать про то с какими проблемами мы столкнулись при разработке нашего бэг-энда и почему он устроен именно так каким образом мы диплом наши backend и проблемы его эксплуатации к сожалению я не занимаюсь вопросами которые связаны с обучением неровных сеток и про то что такое не ровной сетки почему именно они используются для компьютерного зрения и если у вас есть вопросы по ним вы можете задать следующему докладчику который будет прямо после меня это эдуард центов он тоже из компании mail.ru может об этом как раз рассказать намного лучший больше я же буду рассказывать непосредственно про backend для задач компьютерного зрения в наше время используется машинное обучение а именно используется герона и сетки для обучения нейронных сетей их прогона существует фреймворке существует их достаточно большое количество например когда мы захотели сделать детектор лиц мы обратились пресечь epam и они нам принесли нейронную сельскую которая была обучена в кафе это framework который как бы позволяет прогонять в турнирную сетку затем мы решили сделать распознавание лица обратились к нашим режиссером прошло какое-то время и они принесли нам вторую нерону сетку который уже была обучена на torch и когда мы их просили почему они для этого использовали 2 фреймворк они сказали что кофе для этого не подходит потом мы решили сделать распознавание объектов и достопримечательности и опять обратились к нашим ресеч epam прошло какое-то время и они нам принесли новую нейронную сетку которая была обучена в новом фреймворке а именно кафе 2 время шло а количество фреймворков который нам приходилось встраивать наш backend значительно увеличилась и росло каждый из этих фреймворков имеет свои плюсы минусы как говорили нам research эры а мы их встраивали и стравили в результате мы просто столкнулись с большим количеством проблем какие проблемы например могут быть во первых в одном приложении нельзя запустить неровную сетку которой обучена в кафе и кафе 2к эти два используют определение блобов из кафе и в момент инициализации неровности у вас будет просто сообщения об ошибке 2 неприятный момент который связан с запуске запуском нейронных сетей обычных разных фреймворков связаны пример с тем что на одной видеокарте нельзя запустить неровную сетку которой обычно в кафе 2 и в torchi потому что в процессе эксплуатации данное приложение может просто зависнуть когда у нас зависла приложения мы решили разобраться в проблеме и обнаружили зависание в видео драйвере имеет большое количество фреймворков плохо поэтому если вы будете разрабатывать backend для машинного обучения то желательно использовать минимальное их количество на данный момент мы и пришли к тому что мы будем использовать python и все модели который у нас имеется мы конвертируем в по и торт и в будущем будем потихоньку избавляться от всего того что у нас уже там имеется вторая проблема которая связана с запуском эксплуатации модели она связана с памятью gpu чтобы прогнать модель на gpu карте для прогона нейронных сетей из пальца gpu почему они используются потому что процедура вычисления нейронных сетей а именно матричное перемножение отлично ложатся на google карт и так и пол используется для прогона нейронных сетей чтобы прогнать изображение на нейронной сети нам надо сначала изображение скопировать в память gpu а затем нам необходимо проинициализировать нашу модель в памяти gpu но память gpu она не резиновая и в какой-то момент она заканчивается и если мы захотим запустить две сетки 3 сетки на одной видеокарте в какой то момент мы получим ошибку куда out of memory получается задача которая будет нам распределять наши обученные нейро сетки по видеокартам таким образом чтобы мы не словили ошибку куда out of memory и при этом для того чтобы запускать на одной видеокарте модели которые были обучены в одних фреймворков это очень интересная задача которой можно позаниматься но мы этим не стали заниматься вот чтобы решить проблему с дидлами с памятью мы и пришли к более простому решению а именно мы и пришли к решению что нам достаточно в наших масштабах использовать одну модель на 1 га бу почему мы используем это решение мы решили что для нас очень важно утилизировать gpu карту максимально и оказывается мы можем утилизировать на 80 90 процентов видеокарту даже с помощью одной модели то есть у нас в память позволяет загрузить гораздо больше моделей но мы используем одну но используем видеокарту по максимальному зато при таком подходе мы избавляемся от кучу проблем связанных с памятью а также от проблем связанных с дотла гамме и так далее вот это вот правило 1 1 модель она накладывает свой отпечаток на то каким образом построен весь наш backend по сути архитектура нашего бренда она достаточно стандартные у нас существует 1 микро сервис которая берет пользовательские запросы и видят task-ов складывает его в очередь у нас есть второй микро сервис который ходит в эту очередь и забирает оттуда задачи картинки и задачу он прогоняет нога пушки а результат складывает обратно в очередь и эта модель она запущена простая и очень легко эксплуатировать и она работает но у нас бывают машины на которых используется распознавание лиц для распознавания лиц у нас происходит вычислением биллингов и поиск похожих им базинг в базы данных к сожалению на таких машинах нам не удалось по максимуму загрузить гopoдa карты потому что мы уходили в проц процесс не позволял забирать из очереди больше задач а раз мы не можем забирать больше задач мы не можем утилизировать видеокарт поэтому для тех случаев когда мы на тех машинах для которых используются у нас распознавания лиц у нас появился третий микро сервис куда мы вынесли все те операции которые были связаны и которые осуществлялись на проце благодаря этому мы разгрузили второй микро сервис и значительно улучшили утилизацию для модели распознавания лиц ранее я говорил о том что мы вели правило 1 гappu одна модель но исходя из этого правила нам достаточно просто его немного трансформировать и сделать как давайте напишем ад-дин applications одно приложение который будет работать с одной моделью и запускаться на 1 га таким образом micro series 2 это applique шин который запускается только на одной видеокарте количество apple тишина в которой мы можем запустить на одном сервере оно равняется количеству гopoдa карт который имеется на этом сервере с у вас четыре то у вас будет четыре applique еще на которую гоняются на данном сервере а правила которые я сказала ранее 1 1 модель у меня стран сформировалась 1 1 модель 1 instance приложение оказалось что данная модель она не только избавляет от всех проблем которые связаны с г пушками но в нашем конкретном случае она на самом деле еще отлично ложится на кубер нить из потому что она очень хорошо горизонтально масштабируется а у нас большие масштабы и поэтому нам важно чтобы в горизонтальном масштабировании было достаточно простым приложение который работает с моделью она работает только с одной единственной моделью вот и тут представлен пример что у нас допустим есть сервер ip сервера 4 gpu здесь показан пример о том что 4 единство запущена каждый из которых написано с какой именно модели так как приложение работы только с одной моделью когда он ходит в очередь на самом деле ему не интересно забирать из очереди задачи которые на другую модель он хочет забирать только те задачи которые непосредственно относятся к этой модели в качестве очереди у нас используется тарантул тарантулы отлично для этого подходит он выдерживает высокие нагрузки и внутри тарантула у нас для каждой модели заведен отдельные space то есть фактически у нас отдельной задачи хранятся в отдельных таблицах и applications входит непосредственно в ту в таблицу в которой хранятся задачи от на которые относятся именно к его модели это очень хорошо оптимизирует в целом процесс очень положительно сказывается на всем бэг-энде давайте непосредственно поговорим про то как устроен вот этот applications который прогоняет модель applications работает с одной моделью и он работает с одной группы у карты и он должен максимально и и утилизировать что значит максимально и утилизировать и что это за цифры компания nvidia предоставляет утилиту им видео сми которым можно запустить я на в консоли выводят циферку вот она обведена в красный кружок эта цифра говорит об утилизации то есть о том что видеокарта хоть как-то используется согласно моей практике 80 90 процентов это хороший утилизации видеокарте если она ниже это означает что backend построена таким образом что мы не можем максимально утилизирует группу значит где-то нам не хватает задач и значит весь backend имея достаточно плохую архитектуру и надо что-то менять мы пишем приложение которое бы эту цифру держал на уровне 80 или 90 процентов у себя внутри компании мы проводили серию экспериментов для того чтобы выяснить что именно влияет на эту цифру первое что мы обнаружили нейронные сети они обучаются на изображениях фиксированного размера но то есть моделька она обучается на изображении там 200 на 300 пикселей от пользователи приходят картинки разных размеров это может быть full hd это может быть 1000 на 100 и так далее и нам надо все эти картинки привести к тому виду в который требуется для не rhino для ирана сети а именно нам надо сделать ресайз нам надо сделать crop нам надо сделать перевод во float и и ряд других махинаций если эти махинации они делаются на проце то получается что в потоке приложений которые выполняют непосредственно эти операции будут момент времени когда выполняются эти операции а будут момент времени когда вызывается непосредственно к полушка с инферн сам то есть прогоном нейронной сети оказывается что если мы все что связано с процом вынесем в отдельные потоки или даже мы вынесем в отдельные микро сервисы в этом потоке которые работы с гопалу карты останется только непосредственно копирование уже готовых данных прогони раваной сети копирование результата копирование данных и так далее она просто будет поочередно обрабатывать все запросы и в целом именно такой подход когда у нас потоки ничего другого не происходит положительно влияет на утилизацию видеокарте приложением второй момент который активно используется это то что нам надо прогонять большое количество изображений если мы будем на gpu карте прогонять по одной картинки the utilization нашего приложения будет достаточно низкой она будет ну порядка 25 процентов поэтому на самом деле для прогоны картинок нам надо их группировать группировать в такие наборы это будет многомерные тендеры и время прогона который называется батч но то есть набор изображений время прогона 1 оба чем она примерно такой же как но она такой же как время прогона одной картинке но пропускная способность значительно выше а сама утилизации gpu тоже значительно выше потому что нам надо задействовать сильнее видеокарт приложение но нам надо написать исходя из тех мыслей скат которым мы пришли но что делать если в очереди нет задач на обработку а мы хотим сделать batch на самом деле мы можем просто взять и немножко подождать мы можем подождать немножко 50 100 миллисекунд в надежде на то что в нашей очереди появятся эти изображения это добавит latency в конечно к нашему бэг-энда именно время на обработку одного запроса но с другой стороны это в целом положительно скажется на пропускной способности и такая стратегия носят название стратегия фиксированного в этом си и мы у себя ее используем и внедрили для того чтобы эффективным образом формировать baci и повышать эффективность следующий момент который касается непосредственно разработки бэкенда который связан с нейронными сетями он достаточно очевиден для людей которые занимаются компьютерным зрением но я хочу проговорить его вслух для всех остальных программистов и которые не очень сильно с этим связаны компьютерное зрение существует уже десятки лет и для одно и то же задачу существуют десятки методов которые позволяют ее решать одни методы они работают на циpкa другие на gpu и иногда когда вы разрабатываете вы должны основываясь на этой информации на чем вы должны запускать эти модели выбирать ту модель который наибольшим и лучшим образом будет подходить под именно ваше железо на котором вы будете гонять например вот мы хотели сделать детектор лиц для детектирования лиц существует метод phil jones который работает на циpкa но дает очень низкое качество нам надо высокое качество поэтому мы искали другие модели и нашли оказалось что вот есть модель которая гоняется наглядно gpu и дает достаточно высокое качество и и в принципе можно было бы использовать но для нашего бэг-энда она медленно и поэтому мы поискали еще немного и обнаружили что для тестирования лиц оптимальным образом нам подходит mt cnn детектор потому что он гоняется на gpu достаточно быстро дает достаточно неплохое качество и удовлетворяет наши потребности но если вам надо сделать детектор лица на телефоне или вам надо сделать browse и не факт что это детектор вам подойдет вам надо смотреть на то что подходит вам есть еще очень интересная вещь а именно продукт компании nvidia допустим у меня есть неровная сетка которую я хочу использовать но это нирвана сетка достаточно медленная и что же делать в этой ситуации один из вариантов это использовать тендер верти тензор верти он позволяет загружать нейронную сетку которая была обучена в любом фреймворке например в кафе кафе 2 это но в общем в другим фреймворке затем в танце россии происходит различного рода оптимизации прогона нашей нейронной сети и на выходе мы получаем оптимизированный inference который мы можем использовать в продакшене для прогона нашей нейронной сети то есть это будет не совсем то сеть который мы загрузили изначально но это будет inference который мы можем использовать у себя в продакшене и я бы хотела подвести итоги первой части в которой я рассказал о том с какими проблемами столкнулись и какой отпечаток они наложили на наш backend пкм достаточно стандартный но для того чтобы избежать проблемы связанные с эксплуатацией gpu мы прибегли к формуле 1 га по одна модель 1 incense нашего приложения instance нашего приложения максимальным образом утилизирует gpu она и утилизацию г пол влияют bathing а также вы нас различного рода операции на цикл в отдельный поток также положительно влияет на развитие нашего бэг-энда наличие отдельных очередей для каждой из моделей мы это делаем в таранто ли поэтому это у нас в то дельное space и но вы можете сделать это по своему переходим ко второму пункт связанный с тем как именно это приложение теперь нам тепло и для деплоя нашего приложения мы используем докер докер умеет работать с видеокартами для того чтобы запустить наше приложение внутри докера нам надо поставить драйвера на хост машину на сервер на которой мы будем его запускать и поставить драйвера внутри докер-контейнер затем когда мы будем вызывать докер нам надо будет прокидывать туда девайсе видеокарты как показано непосредственно у меня на слайде вот здесь и это в принципе работает но есть ряд проблем например драйвера на хост машине и внутри контейнера должна быть одинаковы и если в какой-то момент у вас появляется машина на которой будет стоять другие драйвера у вас просто может случиться такое сообщение об ошибке то есть драйвера разошлись ваш контейнер и не работает не запускается и все что вы видите это сообщение об ошибке оказывается что для работы приложения на gpu в докере гораздо разумнее и удобнее использовать докер от компании nvidia invideo докер nvidia докер это runtime на докером который охватывает все обращения к видео драйверу из внутри докера и получается нам надо только поставить драйвера на хост машину но нам не надо ставить драйвера внутрь докер контейнеры потому что он будет перехватывать эти обращения и брать все вопросы связанные с обращение ведь о драйвера на себя оверхед от использованием видео докеры и запуска нашего приложения внутри докера достаточно небольшой его и можно использовать в продакшене после того как мы поместили наше приложение в докер нам это докер надо как-то каким-то образом за деплоить мы поизучали существующее решение для деплоя докер образов и пришли к выводу что на данный момент самым готовым и универсальным является каберне this кубер нить из он позволяет автоматическим образом разворачивать нашу систему масштабировать а масштабы в нашей задаче достаточно важны у нас обрабатывается порядка 400 тысяч запросов с картинками в минуту так как картинки достаточно большие то мы считаем что это holod хоть это 400 тысяч но из-за что обработка занимается этим там иногда и может занимать по 500 миллисекунд связано с тем что прогоняется на нейронной сети то у нас highload нам надо и хорошо масштабировать сейчас у нас 100 серверов в каждом сервере по 4 видеокарт и купер найдите отлично подходит для масштабирования такого кластера он поддерживает работу с видеокартами даже у себя из коробки все что нам надо сделать для того чтобы запустить докер с приложением на группу внутри кубер не tissot это на самом деле имеет более менее свежие драйвера видеокарты поставить непосредственно тот самый nvidea docker и прописать его в качестве дефолтного для до для докера то есть мы заходим в непосредственно в конфиге докеры и прописываем в качестве дефолтного м-видео докер затем внутри нашего кластеры мы ставим плагин для работы с гopoдa картами и после этого спокойно наше приложение взлетает внутри купер нити с и больше никаких проблем фактически у нас нет я надеюсь что те люди которые присутствуют зная в зале они и знакомы с кубинцем но пару моментов я проговорю минимальной сущность кубер на эти цвета под внутри пода запускается контейнера и вот для того чтобы запустить внутри кода контейнер в котором запускается приложение на gpu мы подпишем примерно такое описание ямал файла и так яма файл содержит описание сущности вида под со следующими то данной и задается такой спецификации внутри плода развяжу не мне пожалуйста контейнер gpu backend но то есть одна часть которой у нас связано с gpu имеющий такой образ и внутреннего просто вызове и приложение google backend и передай ему на вход в качестве параметра модель вот в качестве ресурсов мы всегда указываем о том что для данной для данного кода требуется гappu карта в тот самый момент когда кубер нить из будет выбирать ноду то есть это тот сервер на котором запустить наш под он будет искать под который будет соответствовать нашим требованием если в требованиях написано что нам требуется видеокарта и всех серверов он выберет именно та в которой находится видеокарт проблемы эксплуатации видеокарт в купер найтись и на данный момент это то что кубер найтись не умеет шарить память видеокарты если вы не укажете что вам требуется одна видеокарта то он будет кубер нити запускать все ваши приложения на одной и той же видеокарте то есть 1 модель запустил 2 моды и все на одной видеокарте но как я говорила раньше в какой-то момент вас просто произойдет куда out of memory и память закончится если мы прописываем о том что требуется одна видеокарта то он отдает целиком полностью эту видеокарту и никаких проблем связанных шаринган памяти внутри кубер нити с и у нас нет то есть опять этот моим модель которая говорила раньше однако по 1 модель один из нас он здесь отлично ложится на кубер нить из отлично масштабируется и соответствует специфика кубер нить из правда моё правило она не мог трансформировалось и туда еще добавился том что 1 ст он запускается в одном позе количество кодов которые я запускаю себя в кластере оно равняется количеству видеокарт я не могу запустить больше поводов чем у меня есть видеокарт но мне не надо ручками запускать все эти коды потому что на самом деле там есть такая сущность как deployment и под каждую отдельную модель я создаю отдельный deployment и говорю о том сколько именно кодов для каждой модели он должен поднять чем модель более популярнее тем больше на нем запросов тем больше поводов для нее надо поднять и так здесь представлен небольшой слайд из нашего по play на мы потому что почти пришли вся и сиди мы пишем код мы затем заливаем его в git лап куат автоматическим образом собирается у нас формируется докер-образ проходит серия тестов и этот докер-образ он дальше diplo & c в тестовый кластер это все что я хотел сказать связанные с диплом мы используем invideo докер для тепло и наших приложений которые используют гopoдa карту а докер мой диплом с помощью каберне tissot осталось проговорить только проблемы связаны с эксплуатацией итак допустим у нас имеется всего 4 видеокарт и у нас имеется три модели у нас есть модель для распознавания лиц у нас есть модель для распознавания объектов и модель для распознавания номеров и вот мы каким-то вот таким образом пришпандорить модели к тем видеокартам который у нас имеется идет день два идут запросы но в какой-то момент количество запросов на обработку лиц она значительно вырастает а количество запросов которые идут на распознавания объектов у нас равняется нулю но в этот самый момент мы понимаем что то видеокарта который обрабатывала объекта она простаивает нам бы в идеале хотелось чтобы она взяла на себя нагрузку связано с распознаванием лиц то есть мы хотели бы чтобы у нас было авто балансированием авто балансировка и видеокарты не простаивали когда мы встретили с этой проблемой мы попытались найти пути ее решения и оказалось что внутри кубер нить из и есть он у внутри купер найти со есть сущность которая называется горизонтальный of the skin of those келлер кодов и он позволяет масштабировать нашу под и в зависимости от каких-либо характеристик из коробки авто скейлер поддерживает загрузку по циpкa и память но нам бы хотелось масштабировать их от того сколько запросов у нас имеется каждой модели поэтому мы для этого используем prometheus мы пишем сервис который вычисляет количество длину очереди для каждой модели мы пропихиваем это prometheus а prometheus непосредственно пропихивать это в кубер нить из и эта метрика она доступна в качестве кастомной метрики для горизонтального of those келлера кодов и тогда когда мы пишем его спецификацию мы просто указываем что для масштабирования использую пожалуйста вот эту метрику и с таким таргетированным значением если количество запросов будет больше он просто поднимет больше кодов под это самый модель и всё было бы хорошо ну то есть мы написали приложение мы запихнули его в докера докер за тепло или с помощью кубер не tissot но на самом деле когда мы пишем это и когда мы это используем мы у нас тоже есть проблемы и сейчас я назову те проблемы с которым вы столкнулись за последний год при использовании нашей системы первая проблема мы используем фреймворке помните я говорил о кафе кафе 2-я и python и так далее дело в том что каждый этот фреймворк он собран под определенную архитектуры видеокарты если в нашем кластере появляется видеокарта с новой архитектурой нам надо все наши фреймворке которые мы внутри у себя используем пересобрать заново под новую архитектуру архитектуры появляются достаточно часто стоит вам доставить еще 10 серверов и вам придется пересобирать абсолютно заново все ваши зависимости в общем когда вы попытаетесь на новой архитектуре и запустить ваш старый фреймворк вы можете просто увидеть сообщение в лучшем случае такого вида о том что я не знаю этой функции и так далее и для сборки вам надо указывать непосредственно в сети архитектуры которые присутствуют в вашем кластере здесь представлен пример для сборки архитектуры например кайф torch а и так далее второй момент который связан с эксплуатации группу во времени в какой-то момент у нас все прекрасно работала и все было замечательно но мы заметили что с одного сервера начали приходить ошибки когда мы попытались выяснить что именно произошло мы зашли на этот сервер и вызвали утилиту компании 2din видео сми она нам честно сказала что она потерял gpu и все что нам оставалось делать это надо было просто при старте ть машину и после этого гappu карта нашлась но бывают и другие неприятные моменты все работает но на одном сервере например у нас случилось так что количество запросов которые обрабатывалась они обрабатывались гораздо медленнее чем на других серверах мы заметили это и решили еще и решили что надо с этим что-то делать зашли на сервер вызвали эту самую команду invideo сми и обнаружили для себя что оказывается есть проблема с кулером который охлаждает видеокарту из этого видеокарта берет и обрабатывает медленнее наши модели и в целом производительность падает вся эта система оно конечно хорошо мониторится и мы собираем статистику о том какая утилизации видеокарты какая у нее температуры и собираемости данные достаточно часто и в случае когда происходят какие-либо проблемы у нас на прозе обычно у нас существуют сигналы у нас все это мониторится сейчас помощью граф анны на который выводятся различные графики здесь представлен пример например когда оно случилось так что за весла один из наших applications of на одной из видеокарт как мы это заметили у нас просто вот на том в графике где розовым цветом и заметили что у нас растет количество задач на у в очереди растет количество задач на одной из моделей мы зашли на сервер и обнаружили что один из серверов просто-напросто за вес моего паре старте ли и все стало нормально но в этой системе могут быть ошибки это нормально ошибки случается всегда вопрос заключается в темное что это надо замечательно это надо реагировать и желательно мониторить в случае если возникают проблемы с видеокартами могут помочь инструменты которые идут для видеокарт это куда мемчик это куда gdb бывает такое что необходимо залезть и посмотреть что именно происходит какие процессы идут в того чтобы избежать этих проблем последний интересный момент который я хотел бы рассказать про эксплуатацию оказывается мы говорим гэбуль гэбуль гэбуль но на самом деле на прогон inference а именно прогон нейронной сети оказывает влияние частота процессора чем выше частота процессора тем выше утилизацию тем быстрее у нас гоняются нейронные сети самые простые способы повышения частоты процессора это проставление режима performance для в непосредственно нашего процессора и например использование turbo boost а это в целом положительно влияет на работу нашей системы и того всем докладе я рассказала вам как устроен наш backend почему он устроен именно так я рассказала что мы будем через докер в процессе эксплуатации у нас периодически возникают проблемы автор распределение модели мы сделали через кубер нить с а именно горизонтальный of those келлер мы используем активную инструменты которые позволяют анализировать проблемы на видеокартах и используем мониторинг для своевременного выявления этих самых проблем если у вас есть вопросы давайте поблагодарим или она так там вот вижу там раньше подняли туда идем пока в конце в конце вот в желтой футболке спасибо за доклад а у меня такой вопрос я правильно понимаю что у вас не рынок распознает абсолютно селиться который приходит mail.ru то есть всех пользователя абсолютное ледника то сначала выбирается на не будете распознавать так для начала я хотела сказать что у нас используется несколько моделей это и для распознавания сцены то для распознавания объектов но помимо этого у нас есть распознавание лиц распознавание лиц это один из методов нашего api он например используются в облаке и если у вас есть облако mail.ru и у вас есть фотографии то эти фотографии а ник прогоняется через этот метод и на ней распознаются все лица для каждого клиента существует своя собственная таблице 2 доли для которых сохраняется список персон эта информация только конкретно для каждого пользователя спасибо понял так здесь еще вопрос говори да тихо вроде слышно все концерты из доклада я понял что вы использовали его для оптимизации моделей попытались использовать оптимизация модели вопрос использовали ли вы inference server at underworld и потому что он делает примерно то же самое что вы говорили и про оптимизацию пытались ли использовали применяете ли оптимизации ввп 16 18 до лишь в этом мы используем об этом расскажет это как раз после меня будет об этом рассказал что из вы получаете уже оптимизированные модели так давайте здесь у нас был вопрос сейчас передам привет меня зовут антон и меня первый вопрос вы считаете metric утилизации нагрузку нагрузку видеокарты плане расчетов то есть насколько она загружена но при этом остается такой вопрос относительно утилизация памяти gpu вас и и остается просто ну то есть судя по скриншотам ее достается очень много и тогда как вы решаете это вопросу просто покупайте дорогие видеокарты ставите и как бы память на запас на будущее или вы подбираете стали скорее видеокарты под задачи некоторых моделей это хороший вопрос вообще как бы смотри получается что память позволяет загружать и дверь модели и три модели и четыре модели вот и мы могли бы это делать вот но в наших масштабах нам важнее гораздо так чтобы это хорошо горизонтально масштабировались соответственно у нас большие масштабы и нам важно чтобы видеокарта использовались по максимальному то есть у них было максимально утилизации мы не стремимся максимальным образом использовать память о стремимся максимально повысить утилизацию если бы мы запускали две модели утилизация с целом выросла но мы этого не делаем потому что с запуском нескольких моделей на одной видеокарты существует ряд проблем которых мы пытаемся избавиться в наших масштабах и избавляемся тем что используем один applications одной моделью на 1 группу эта модель очень хорошо горизонтально масштабируется она максимально утилизирует gpu она отлично уложиться в плане купер не tissot и в компании mail.ru это типа нормальное решение потому что у нас с то серверов то 400 видеокарт но если есть backend например поменьше у которых всего три видеокарта 4 видеокарты наше решение может быть не является оптимальным в этих случаях я говорил не конкретно то что то есть допустим концепция валидная говорил про то что а железо тогда вы получается берете стандарт самый максимальный что возможно или бы подбирайте железо под решения нет под решением и не подбираем данном группирование по решения примера вам нужно всего лишь два гигабайта видеопамяти там допустим выберу там каким 1060 а для более тяжелых там допустим фильтры подмешивать вам нужно много совсем прямо патчами закидываете там можете использовать все 1080 у нас закупались 1080 до того момента когда и запретили использовать у нас использую сейчас теслы но внутри мы не делаем во втором распределение с учетом того какая видеокарта потому что пока не видели в этом смысла ok а второй вопрос это относительно вы сказали что вы на части бэг-энда делать некоторой оптимизация чтобы на micron на машин academy красе раскрутиться выполнилась меньшее количество себе операции а вы не пробовали часть решений просто переписать на том же самом tensorflow чтобы сделать а то что обычно запускается на себе уже на gpu пробовали мы пробовали весь наш при processing связано с риса и зам с флотами там крапинка мы пробовали делать на gpu но к сожалению пересылка данных и попал учениях обратно из-за затем отсылкой их непосредственного фреймворк получилось так что профита от этого никакого не было и мы не боялись это просто вадим pipeline тензора закинуть но мы пока не увидели от этого профита и поэтому пока отказались и оставили предобработки на циpкa и сейчас пришли к тому что на самом деле весь при процесс можно делать не только в отдельных потоках но даже в отделе микро сервисе который будет в очереди уже складывать готовые блоки туда поставить сильно сервера который будет быстро выполнять при processing спасибо так дальше у кого у нас лапа вопрос кому да давайте спасибо за ваш доклад у меня такой вопрос скажите а как у вас устроен стейджинг то есть причем мне больше интересует контекст то что вот человек то здесь называл 1080 и и профессиональные видеокарты то есть как бы проблема тут заключается в том что результат обучения он не всегда одинаковый поэтому как вас в принципе с этой проблемой справляется с эйджинг ну я на самом деле сейчас так затрудняюсь сказать ответ на этот вопрос вот поэтому можем обсудить а уже после она спасибо так еще кто у нас поднимал руку я точно помню кто то поднимал мне казалось сейчас подожди секунду пожалуйста я я не против но мне кажется просто кто-то обижены сидит и не поднимать теперь точно не поднимет клады до вопрос чего у про припас processing я заметил что на слайдах все сервисы называются одним одинаково gpu сервер или gpu что-то там это это на самом деле название 2 micro сервиса потому что про него я рассказывал этими ну тут микро сервис который гоняет картинки на куклу есть micro сервис один микро сервис 3 ну про их я не рассказывал потому что одно из стандарта micro сервиса и говорил именно про пушки и поэтому там был углублен то есть bbn который гоняется на gpu и я ими уже было про него да да да имел ввиду что а или то есть сыр и результат работы нейросети мы получаем в один микро сервис возвращаем за 1 его запятые даем другой представляет представьте что мы решаем задачу вокализации объектов результатом локализации объект является сложный тензор который нельзя напрямую отдать пользователю как результат нет но нет пост процесс осуществляется тоже группы в бэг-энде на ацпу дана эта часть осуществляется в группу бакинцы в отдельном потоке сейчас да а bange просто там все модели захардкожены в один кубок and do году backend он работает с моделями с какой-либо одной да и весь пост процесс он тоже сейчас пока делать что у кого еще есть вопросы киря не то я сейчас начну обратный отсчет как обычно да ну тогда начинаем 321 спасибо или они за доклад"
}