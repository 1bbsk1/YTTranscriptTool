{
  "video_id": "Z9u4jbBE6YA",
  "channel": "HighLoadChannel",
  "title": "Стендбай в бою: масштабируем приложение в топ-2 мировом классифайде / Константин Евтеев (Авито)",
  "views": 1781,
  "duration": 2495,
  "published": "2020-04-27T13:26:00-07:00",
  "text": "я валит возглавляю w-net авито это классе fight с аудиторией размером целая страна это номер один курс fight в россии и номер два в мире после craiglist ежемесячно к нам приходят более 35 миллионов уникальных пользователей и каждый день они генерят более 100 новых объявлений и закрывают более там 100 тысяч транзакций при этом в офисе там более миллиарда уже давно у нас находится объявление и следующие цифры могут как бы посвятить масштаб проекта или напомнить кому-то у нас находится более 600 серверов инфраструктуре во время вечернего часа пик трафик на отдачу без статике это примерно четыре с половиной гигабит на прием где-то 2 гигабит и отдельно еще статика есть наши бэг-энда обслуживаю где-то 1 миллион запросов в минуту и в подгрести мы храним более двадцати терабайт данных не только храним но и обрабатываем они распределены где-то более чем поста но дам при этом средний уровень запросов к одной ноги это где-то 8 тысяч транзакций в секунду при этом самая крупная кластер под газ это где-то пять терабайт и он обслужить это 20 тысяч транзакций в секунду но так было не всегда и следующий слайд вам может показать пример на динамику и скорость роста проекта в предыдущие годы и как можно догадаться вот этот скорость ставила перед нами различные вызовы и на старте решит проекта решения хранить наше объявление в подгрести и обрабатывать их помогло нам справиться с вызовами роста нагрузки распределения нагрузки доставки данных в различные аналитические подсистемы в поисковые под системы взаимодействия между нашими микро сервисами базами данных и синхронизацию распределенных системах и легендарная отказоустойчивость встроенная репликация богатый набор фич а также best practices которые от коммьюнити помогли нам как бы реализовать грамотно нашли свое применение в нашей инфраструктуре и сегодня я хочу рассказать одной из такой вот корневой фичи распределенной инфраструктуры под газ и простым buy под нагрузкой мы имеем достаточно большой опыт и я сегодня хочу поделиться значит план выступления будет следующий сначала я скажу несколько слов в общем простым buy и про его историю потом поговорю про то какие у нас возможно проблема при использовании асинхронного репликации для чтения дальше скажу как вави там имплементировать одну из техник для того чтобы избегать style риц потом расскажу что вообще в принципе еще есть различные подводные камни при специфичных нагрузках например при высокой нагрузке или при настройке репликации через архив например технику использования полости боев под свечу еще один пример масштабирования с помощью экологические репликации чтоб для сравнения то есть сравнить бинарную логическую и в конце сделаем выводы и так с тобой вообще изначально какого можно использовать для высокой доступности если у вас авария на мастере у вас должен быть горячий резерв чтобы иметь возможность делать быстрый flower а также можно использовать и для масштабирования когда вы будете часть своих чтений перенаправлять на одну или несколько реплик изначально вообще комьюнити она не планировала с дамбой как встроенное решение она говорилось что репликация это вообще будет что-то в стороне и так было то есть наш соотечественник в 2000 году вадим михеев после того как он на я реализовал он весь еси и сделал отдельно стоящие рекреационное решение логическая р серов и оно основывалось на логике инвестиции механики то есть основная идея была в том что получить изменение которые не были видны в предыдущем снова счете стали видны в текущем далее в 2001 году появилась right ahead бог но это не тот right ahead блок который мы сейчас с вами видим он был сделан только для того чтобы ускорить врать performance 2004 год я навек берет идею вадим и михеева и делает enterprise логическое решение с логической репликации слой не называет как в честь автора русский слон 2005 год появляется point in time рекавери и point in time recovery в тот момент когда появилась многие 20 юзера и у пользователя поняли что на скриптах можно делать воинством buy что они начали делать 2007 году релиз решение логической репликации транзакционных очередей от skype самые хвалит как раз много используем и есть много докладов от нас 2008 году функции вот вот это вот логика каско в которой можно делать логическую репликацию выносится на уровне sql функций то есть там комитете они а также фича warms the nba is релиза на и 2006 году получает еще множество упрощений именно поэтому до сих пор можно увидеть много решение по всему миру немного но встречаются люди которые до сих пор используют под газ 83 десятый год hots томбой позволяет читать со стенда фича значит streaming репликация упрощается этап репликация одиннадцатый год синхронная репликация позволяет уже настраивать такие конфигурации которые дают возможность с меньшими трудозатратами поддерживать высокий уровень слоя для критичных данных то есть до этого чтобы не потерять данные нужно было писать либо в два места либо ждать пока измене проиграется нас тумбой а теперь появилась синхронная репликация тринадцатый год фича с тумбой может подхватывать новый timeline и соответственно тулин для рекавери можно делать проще четырнадцатый год рипли кислоты делают удобнее и безопаснее настройку репликации без использования архива но при этом есть как бы другая сторона вопроса если с тобой сломается может привести к аварии мастера и закладывается фундамент для встроенной логической репликации шестнадцатый год несколько синхронных сын боёв позволяют строить более надежные кастера ему утопла и создает возможность наконец-то без боязни сервировать чтение с тумбой и без использования каких-либо техник и семнадцатый год логически репликации с коробки и так мы видим что с тобой может быть логически физический встроенные отдельное решение для записи не только для записей синхронная синхронной и сегодня мы будем говорить про streaming репликацию асинхронное работает оно следующим образом подключается client for каяться процесс получают данные он соответственно через шарит буфера меняет какие-то изменения заносят комитет информацию и далее изменения пишутся вал а дальше с помощью рипли течь на сладкое вал сендера они транслируются на стенд бай нас там был ресиверов передает эти данные recovery процессу изменения применяются и мы можем уже отправлять пользовательские запросы получать эти данные так вот при использовании стенда я асинхронного в бою он может отставать от по отношению к позиции к мастера и поэтому различные виды подходов для отправки запросов нас там почитающих подходят различным приложением начнем с первой техники вообще ничего не использовать никакого подхода просто все ощущение отправляем на стендбай и многим этот подход подойдет ну просто потому что репликации очень быстро лак маленький иногда под определенными нагрузками ошибок практически нет или очень мало просто эллет соответственно вроде работает многие пользуются нормально мне не очень нравится этот подход давайте более интересные рассмотрим бывают случаи когда есть какие-то специальные бизнес условия бизнес-логики ваши как у нас во это был несколько лет назад у нас было 30 минутный лака до того как ваше объявление увидят другие пользователи новые это ограничение было например для проверки на различные мошенничества и другие ограничения и мы эту технику использовали очень успешным и ваши запросы к чужим объявлениям направляли на реплику при этом ваши запросы к вашим объявлениям направляли на мастер что вы имели возможность отредактировать работу с актуальным stay там чтобы поддержать эту технику не слышишь нам нужно было это следить за тем чтобы лак стек был меньше 30 минут но самое интересное начинается когда нельзя вообще недопустимо старец а еще интереснее если нужно несколько стендов использовать бою для достижений еще больше масштабируемости так вот мы успешно использовали второй подход когда мы внезапно столкнулись со следующей истории на графике вы можете увидеть утилизацию лоты we reach на 28 там машины 28-ю физическими ядрами когда мы начали использовать chopper фреттинг мы пробуешь марк или и увидели что наша нагрузка все очень замечательно включенным гипер трейдингом скейлится но потом характер нагрузки поменялся и результат как раз виден на графике на графике есть от спайки различные и они начинаются когда лоты вич подбирается количество физических ядер точно такая же история видно и на графике утилизации циpкa с точки зрения пользователя это выглядело как будто их запросы начинали выполняться в 10 десятки раз медленнее обычного то есть получается такая вот масштабирования которое ограничено получается одной базы данных ограничено самым мощным предложением по рынку а у нас уже стоял самый мощный сервер на тот момент и если он не подходит это capacity проблемы и вот находясь под такими условиями обычно вообще архитектура приложения так вот чтобы быстро что-то переписать это не очень быстро и требует достаточно много усилий находясь в таких условиях нам нужно было как-то решить этот вызов и если вы посмотрите на график вы видите что вот эти вот пике они ушли мы справились с этим вызовом переключив больше чтений на нашу реплику то есть на следующем графике увидите количество запросов в секунду на 100 мбайт может ведь что она увеличилась реализовали мы это с помощью одной из техник для обхода style рица детально потом послать на вы можете по ссылке перейти ознакомиться основная идея заключается следующем для каждого изменения данных мы храним лак sequins набор то есть позицию валят для каждого успешного изменений для каждой сущности самое последнее лак sequence number и дальше когда мы хотим выполнить чтение мы проверяем какая из реплик достигла этой позиции вала и выбираем одно из них если ни одна из них не достигла этой позиции воли соответственно мы выполняем наше чтение очень близко после того как мы сделали запись и мы просто делаем тогда fall back на мастер таким образом вне зависимости от того в каком статусе находится наше реплики у нас не будет отстающих чтений но ловиться когда мы начали столкнулись с этой проблемой у нас была большая монолитная архитектура и мы она была в процессе перехода распила на микро сервис и соответственно мы имели очень много сложный бизнес логики большая вложенность вызовов и вот эти условия они делали невозможным быстрой перспективе реализовать для нас вот эти вот стикез сессия строка не мог секунд сомбра но при этом с другой стороны у нас была историческая специфика у нас в таблице айтемов а под но объявление и пользователей была колонка стоим стоим и мы ее заполняли при помощи функции на после функция которая дает время начала текущей и дату транзакции и мы решили использовать вот этот темп темп вместо и осин вы конечно же скажите как же так время база данных время применять для того чтобы реализовывать операции по порядку в базе данных но это нонсенс а тем более например говорить о том как мы будем сравнивать мастера и реплику их статус и как бы относительно друг другу с помощью времени так делать нельзя мы использовали это допущение на основании того что у нас все транзакции очень короткие не длятся десятки миллисекунд мы все чтение к сущностям которые менялись в последние 70 половиной минут отправляем на мастер а реплики для чтения мы используем которые отстают не более чем на пять минут вот с такими допущениями мы реализовали следующее решение называется она назвали авито smart cache мы заменили наш кэш который был сделан с помощью редиса другим решением с помощью дата платформы тарантул она имеет внутри под собой стройную и memory база данных и сервер приложений двухуровневую smart cache в первом уровне мы хранили время изменения последнего изменения для каждого из пользователей его данных то есть вот эти вот стихи connect и получается доставляли мы их следующим образом мы доработали наш фреймворк для работы с базой данных мы туда добавили он камень хук и доставляли соответственно вот в это вот первый уровень каша изменение от времени изменения вы скажете так может произойти там мир фон весе что-то поменяли а дальше авария и в приложении или 30 и в кэш данные не занесли вот чтобы обойти этот вопрос мы со стороны позже с помощью его fitch alyssa на тихой эти же изменения транслируем лисе неру там есть вот узел на слайде тоже сейчас покажу вот это вот listener эти измене транслируем еще или сеньору и он с другой стороны тоже пишет их в первый уровень каша также лисин трека это время отставания репликации на каждый риза реплик имеет аж теперь 5 с помощью которого тарантул может забирать эти изменения основной же кэше он просто замена предыдущего качканар одессе и он нужен только для того чтобы минимизировать утилизацию по сгрыз базы тут есть две особенности вы можете увидеть тут 16 сортов 16 рядов сделано для того чтобы повысить отказоустойчивость случай если один из сортов как сказать аварийно ним произойдет средствами под grass свободно сможет обслуживаться без проблем 1 16 запросу то есть fubag произойдет на базу данных а второй момент если мы будем уменьшать вот этот интервал который мы используем для балансировки запросу в какие запросы можно отправлять на реплику количество запросов на реплику возрастет но это тем самым увеличить нагрузку на реплику и увеличит вероятность того что реплика отстанет и все запросы вернуться на мастера а если они вернутся на мастера очень вероятно что он один не сможет сервировать все запросы и это будет авария и это подсвечен следующий факт то есть если у вас есть две ноты в продакшене нужно иметь третью для отказа обеспечения отказоустойчивости но об этом мы поговорим чуть позднее то есть а дальше мы переключаемся от основной как это работает smarts мы стараемся найти данные в основном кэша если получили то есть если же в самом кошение оказалось значит мы идем вот этот слой дима хранимое время изменения данных для каждого пользователя если там есть информация это значит что дано недавно менялись и надо идти на мастер за запросам если там данных нет но стенда я стал больше чем вот как я говорил на пять минут все равно надо идти на мастер иначе можно получить со стенда я и записать данные в конечно соответственно основной уровень то в том числе вы можете заметить что там разные значения детей все равно во всей этой архитектуре присутствует вероятность гонки и чтобы минимизировать вероятность потери там где не консистентными чтения вероятность больше мы ставим меньше теперь вроде бы все хорошо мы реализовали и венчались синхронизируем и кэш то есть consistency каша балансировщик который может на 2 надо балансировать запросы на несколько нот но далее вот на этом слайде вы можете увидеть график на котором изображено количество запросов на нашу реплику и там где вы видите провал и это стендбай отставал и запросы в трафик переключался на мастером например может или другой стендбай соответственно я хочу рассказать что это еще не все есть еще очень много подводных и вот те которые мы нашли и знаем как обходить я сейчас поделюсь с вами опытом первый момент представьте себе что у вас есть две таблицы таблица 1 таблица 2 на мастере мы открываем транзакцию и начинаем изменять данные в первой таблице на с тобой тоже открываем транзакцию и там читаем данные из второй таблице потом на мастере меняем данные во второй таблице на с тобой читаем данные с первой в подгрузку или версия менее 10 это будет d блок который не решится у вас просто будет ждать об этом нужно знать и нужно это учитывать когда вы будете писать код какие-то изменения нужно упорядочивать эти действия не открывать транзакции в которых вы будете менять данные нескольких таблицах если у вас есть чтение в обратном порядке на с тобой например если говорить про этот случай второй случай как мы применяем изменения к структуре наших таблиц многие из вас скажут statement тайм-аут statement тайм-аут можно использовать это значение в миллисекундах после которого длитель запрос деятельностью больше этого значения будет отменен ну время отсчет начинается простого как сервер получает запрос от клиента а есть еще одно значение она менее подсвечена в различных источниках я смотрел всякие разные d-блок тайм-аут d-блок тайм-аут это такая настройка которая управляет временем сколько нужно подождать налоги перед тем как проверить если условия для блока проверка до блока это достаточно дорогая процедура поэтому решили что не надо проверять каждый раз пока мы ждём получение блокировки есть там условия блока таким образом увеличивается значение мы уменьшаем количество ненужных проверок на тот локи но увеличиваем время о репортите а настоящим до блоки почему так вообще постоянно не проверяем в том числе вообще принципе в продакшене если у вас пациент блоки на что-то не так то есть битлов для продакшн это какая-то такая вот необычная ситуация и дефолтное значение этого там одна секунда и по идее это вообще минимальное значение которое вообще вы захотели бы себе выставить для более нагруженных систем можно его ставлять больше вообще и обычно нужно выставлять это значение но должно расширять длительность вашего обычного запроса для того чтобы типичный запрос мог уже закончится перед тем как возникнет необходимость проверить надо длог а также я хотел сказать что-то блок вообще это также это настройка которая говорит когда нужно отменить конфликтующие вакуум prism изменение но например вашим операцией структуры таблиц умеет galant например добавляем и в боевой системе когда вы одну секунду будете ждать и все будет переводчика это перед тем как отменить вакуум эта проблема еще хотел сказать что область применения стать мать тома тайм-аута и начала его действия например если у вас statement mode вы ставите внутри хранимой процедуры то вызывая эту хранимую процедуру вот этот statement тайм-аут никакого значения на нее влиять не будет то есть как бы ничего не сработает то есть об этом когда вы будете с настройками пользоваться посмотрите когда она начинает работать и так замечательно мы все узнали мы выставляем эти настройки там десятки миллисекунд и с повторением пытаемся днем взять маленькую блокировку изменить нашу таблицу структуру если вдруг не получается мы пробуем это ночью когда трафик меньше если ночи не получилось но обычно получается там просто увеличим время вот этот блокировки для изменения структуры и вот все получилось и тут нас томбой проигрываются эти изменения она с тобой стоит мы тайм-аута дилок тайм-аут они никуда не проигрываются если у вас на с тобой идут читающие запросы у вас все перил училась запил в ваших графиках общем все очень плохо чтобы решить этот вопрос малавита используем следующую инфраструктуру с помощью очей прокси мы управляем нашим соответственно трафиком нас тамбове когда мы хотим изменить какую то таблицу мы ставим на паузу проигрывание репликация на реплики на которой идут пользовательские запросы применяем изменения на 2 реплики потом переключаем трафик на 1 реплики применяем эти жизни и мы возвращаем ее в пул активных сын боёв ещё одна история а еще process of the vacuum авто очистки он может отдавать делать чистку так и отдавать место назад операционной системы это случается когда все вот эти вот ненужные данные находятся в конце дата файла но для того чтобы его обрезать он берет эксклюзивную блокировку краткосрочная она очень короткая и не всегда это должна быть короткой сейчас по днищу раскрою вот и он последовательно пытается ретро избрать блокировку но да и далее происходит разблокировки потом опять блокировки но проблема в том что на стендбай unlock приходит только один когда происходит камин и у нас варит а случилась такая ситуация когда у нас на мастере у нас все нормально мы проиграли то есть of the vacuum то есть подрезал файл все нормально он с тобой такой вот много много лаков мы начали разбираться у нас вот этот интервал между блокировкой разблокировкой 75 баллов это очень много еще я хотел сказать а какое может быть решение для этого для этого случая вообще ура в двенадцатом подписи будет такая вот опция отключить возможность на определенной таблицы вот взять такую чистку там решали другую проблему для уменьшения блокировки там проблема еще в том что когда вы происходит подрезание файлы там идёт полный скан по всем буфером чарт буфером и и эта проблема на мастере она у нас тоже мы с ней столкнулись график тут мне не попал сюда в общем я расскажу словами у нас есть центре и там произошла какая-то чистка мог данных удалили когда вакуум начал подрезать файлы у нас началась проблема уже и на мастере то есть там был график скво викингами и у нас то есть очень сильно как сказать деграде а длительный период деградировала производительности за того что вакуум подрезал и брал вот эти вот эксклюзивные блокировки а второе решение предложили пост гаспра фешина уменьшить количество блокировок который надо брать из тамбова вид а вот первый раз и мы нашли сейчас мы в разных местах это ловим но первое место где мы нашли у нас была практически такая append only таблица с лагами очистили мы и там раз в 3 недели по условию удалив все данные которые старше 2 недели и конкретно тот случай 1 как мы решили на reply чтоб на реплики не было вот этих вот запилов мы просто начали вызывать процесс чистки каждые десять минут такой костыль ники еще один кейс lavita наша инфраструктура с тем боёв построена при помощи архива это сделано для того чтобы иметь возможность случае аварии на мастере или на реплики восстановить вот эту вот ноду из архива и привести ее к согласованному состоянию то есть была возможность любом случае любой узел упавший восстановить из архива а теперь переходим какие проблемы возникали соответственно первая история в пятнадцатом году где-то вот на графиках видны такие вот запилы это количество вал файлов которые готовы для того чтобы к отправке в архив то есть мы уперлись наша часть сервисов начал генерировать столько записи что наши архив команда не успевал их отправлять в архив решение для этой истории мы сделали следующие на ссылка на слайде на git have мы выложили мы сделали мульти трезвую отправку файлов wav файлов в архив то есть если у нас количество вал файлов превращает определенное количество начинаешь параллельно отправлять в архив вроде все хорошо дальше мы видим другую проблему сталкиваемся уже с это архив командой и был большой вызов нас с тобой начинает отставать и для нас было целое такой вот хорошие и интересные приключения найти причину почему же 100 мбайт встает и если посмотреть на график утилизации циpкa он практически не утилизированы но тайно в деталях сжатия одного файла занимает 60 миллисекунд то как мы смотрим мы наблюдаем утилизацию циpкa это слаг фото a snapshot не отображает всю картину более лучше отображает картину какие-то каунтер между менты такие метрики и на графике слова или вич тому же это видно что мы приближаемся к числу капец количество физических ядер например и там же есть стрелочка зеленая которая показывает что принципе мы решили этот вопрос и решили мою с помощью новой инфраструктуры для архива значит сначала расскажу про старую архитектор хев схему у нас значит была смонтирована архив помощью нфс на с тобой вал файл отправлялся через стендбай класное tfs и получается стендбай сначала сжимал волны а потом разжим аллах таким образом вот это вот возникла проблема что у нас когда много баллов ничего генерится у нас все циpкa с тобой были утилизированы тем что не сначала заливала потом разжевали их в новый архив схем и мы сделали следующая ссылка есть тоже тут вот на слайде она тоже упал сурс выложено на нашем гитхабе мы то есть и архивы и бэкап и соответственно как это работает мы во-первых на предыдущей схеме архив был это единая точка отказа мы зарезервировали наш архив вал файлы пишутся обычно в обычном режиме сразу на два архива но если один из них не доступен или аварийно ним произошла мы просто продолжаем писатель на один из двух архивов далее после каждой процедуры backup а мы запускаем синхронизацию в двустороннюю между архивами вал файлов операцию запускаем при этом все все ресурсы по сжатию распаковку по сжатию волос занимается уже циpкa одного из архивов вот эту всю архив инфраструктуру мы делали для поскольку или версии где были недоступны и джерри civic слог или поджариваем с помощью этих утилит гораздо проще реализовать отказа устойчивую инфраструктуру на слайде можно увидеть пример авария где мастер по крошился но тут возможно дальше вариантами что после аварии может быть ваш архив и с тобой будут в одном статусе а может так быть что архив будет впереди 100 мбайт позади или наоборот и как с помощью вот этих вот утилит переливают джерри сетевых слог это можно реализовать проще отличная статья есть как это делать хикки доклад тоже ссылки есть 2015 года как сделать правильно вам санбой и когда что то идет не так происходит авария очень трудно сконцентрироваться и сделать все правильно об этом свидетельствует множество post more to move от коммьюнити по всему миру ну поэтому я призываю вас сделать чтобы designs to recovery планшет он был понятен ответственным людям чтобы они постоянно поддерживали в актуальном статусе и понимали что как происходит и лучше еще автоматизировать его со своей стороны я хотел подсветить еще одну историю что даже если мы настроим синхронную репликацию в этом случае после аварии все равно есть вероятность что ваш архив и с тобой будут разных статусах даже если архив синхронной репликации smb синхронная репликация потому что как работает синхронная репликация изменение применяются на мастере и пишутся вол а далее есть такая memory структура данных которая говорит о том что клиентам просто нельзя показывать еще эти данные но они уже применились а далее мастер ждет пока все синхронные реплики пришлю этому ответы что они успешно получили применили эти изменения зная об этих всех подводных камнях и чтобы с ними жить потому что избежать их нельзя еще одна такая вот решение которое можно чтобы обойти их это пустым боёв мы с помощью вещей прокси реализовали следующую логику если ваш стенд бай отстаёт больше чем верхней границы для нас допустимая мы закрываем его для за для клиентов и откроем чтение только когда он до гонится до нижней границы который мы тоже заранее выставим это нужно для того чтобы тесто нба и равномерно не отстали чтобы реализовать такую логику на стендбай нужно организовать запись какую-то запись можно сделать с помощью фарингит европе или же какую функцию написать на python который файла будет писать эту метку чтобы вот это вот значение что с тобой сейчас отсталым и какое-то значение примерно 5 минут теперь мы откроем его для печей прокси только тогда когда он вернётся ритлок репликация фен на одну минуту это немножко за рамками сегодняшнего доклада но я хочу сказать что параллельно с бинарная репликация есть логическая репликация и миша тюрин в 2009 году на старте проекта когда не драл по сбросу а вид и начал использовать по сгрыз он параллельно изучил все материалы от коммьюнити по подходам и реализации масштабированию с помощью логической репликации с помощью skype лс и реализовал очень много важных и эффективных решений по масштабирование с использованием логически репликации которые во многих местах до сих пор используются ловите и одно из этих решений я хочу сейчас вам поделиться предыдущий можно найти в наших докладах старых я хочу поделиться как мы организовали была организована выдача показ выдачи результата поиска для всех наших пользователей 2009 до середины айда началу 2015 года на основной базе источники данных все данные были нормализованные и там хранятся активные неактивные могут храниться объявление и чтобы организовывать результаты выдачи надо получается joy это тяжело было реализовано материализованные представление с помощью триггеров на слайде есть ссылки очень классная техника очень удобно использовать вообще если он надо подобные вопросы решать рекомендую ознакомиться и заработать очень здорово мы где нужно как раз вот за скейлится чтобы нормализовать данные очень часто используют а дальше вот это вот происходит магия вот это вот мотивированны представление она с помощью логической репликации реплицируется на отдельную машину а ну как растут с картинкой тут где-то 2009 год картинка была нарисована а эта машина она сильно дешевле она сильно меньше и слабее по характеристикам единственное что там есть там вот эта табличка она помещается шарит буфера в память и далее я хочу показать графики на которых получается вся поисковая выдача для рунета от авито работает с одной снова дешевого сервер и очень эффективный патин для масштабирования у меня есть очень много чего еще рассказать вы не можете поспрашивать про логическую репликацию это просто не за рамками доклады все что я хотел сказать что существует логическая репликация и бинарная репликация и у каждой из них есть свои вызовы то есть у подводных камней в использовании логически репликации тоже очень много и знания об особенностях обоих решений позволит вам сделать правильный выбор для реализации того или иного решения в своей инфраструктуры и второй момент который я хотел сказать что вообще когда я собирался делать этот доклад я хотел вам сказать что ребят не используйте бинарный стендбай для того чтобы масштабироваться чтобы запросы пользователей посылать потому что очень много сложных вызовов и прочего и собирался более того волита прекратить использовать собой под нагрузкой для как бы пользовательских запросов однако я говорила хотел сказать что давайте sharding использовать ну вот sharding использовать но однако на 1 если в случае вид и у нас поменялись обстоятельства и мы сейчас будем строить инфраструктуру распределён на несколько дата-центров и будем сервис и плавить в несколько тогда центров вместе с экземпляром их базы данных мастера илистым баян и чтение будут локально обслуживать соответственно если с тем buy the system buy a запись будет перенаправляться в мастера а с помощью 100 мбайт что можно просто делать просто можно делать он даже нужно делать это для отказывая устойчивости для аналитических запросов некий такой backup можно держать отстающий стендбай чтобы быстро иметь возможности установить истину из бака по долго восстанавливается отстающая реплика на 12 часов он поможет быстро догнать на ошибку который произошло там полчаса назад и для пользовательских запросов где нужно избегать диас tail риц не проблема типа такей случае если другие условия я с вами поделился к подходами как обходить и как вот использовать под высокой нагрузкой с высокими требованию местам боев боем если вы знаете о каких-то еще нюансов и подводных камней камня поделитесь комьюнити это очень интересно давайте обсуждать эти вопросы еще один такой вот интересные моменты важной это отказоустойчивость designs to recovery план он должен быть он должен быть актуальным но я немножко про другой хотел сейчас рассказать когда у вас есть мастер и стендбай в бою я предполагаю что вам нужно делать мажорное обновление под гасса и наверное многим из вас нельзя делать длительной downtime и скорее всего если у вас две ноты в бою если обновить только один мастер он один может не выдержать постов как вы обновитесь пока вы там через длительное обновление с тобою сделать или sperry создадите вас нового мастера и чтобы сделать обновление с минимальным downtime am можно воспользоваться логической репликации можно пиджак брей там использовать лает и мы используем пиджи апгрейт и тут я хотел поделиться нюансам которую я не нашел в документации испугаться не очевидная request сделал в комьюнити в документации написали что последний вал файл сюда он чекпоинтам он в архив если у вас репликация через архив не streaming протоколов shipping не переносятся из томбой не получится эти изменения чтобы не побить с тобой нужно этот вал файл руками перенести в архив и дождаться пока он применится нас там боевая и он соответственно играет restart он сделает и будет президентом состоянии с мастером или же просто переключить на streaming просто об этом надо знать что потом не было мучительно больно с побитыми данными вторая история мы в авито используя настройку де фер kanab печь обычно запрос которые значение приходят они приходят горячим данным а эта настройка управляет тем что вакуум чуть отложить чтобы он не менял те данные которым будете ощущение чтобы не было конфликта с тобой а но на сервере где у нас эта настройка было 900000 выставлены когда мы начали делать пиджи a break нас был не очевидно а у не работает проблема была в том что вот эта настройка мешало сделать ты же апгрейда вакуум фриспич же каталога мы соответственно обнаружили это в документации я не нашел никаких запрещать запретов тоже сделал report и от с вами делюсь этим этим знанием заключение я хочу сказать что вообще позы сейчас есть возможность очень просто настроить репликацию логическую бинарную и очень высокопроизводительное я надеюсь что в будущем эти фичи будут развиваться и будут делаться удобнее и проще это очень большое достижение репликации и ещё я хотел то есть сказать что вам спасибо за то что вы меня послушали хотел подсветить тот момент что в 2 у меня есть вакансии не пропал gres есть интересные вакансии про тарантул парковку про мангу общем много интересных вещей если интересно ссылка соответственно представлена на этом все спасибо вопросы здравствуйте и спасибо доклад мне вот интересный вопрос я насколько знаю вы сейчас идете по пути микро сервисной архитектуры и слышал что вроде бы собираетесь придерживаться подхода одна база на микро сервис и вот с учетом такой вот сложной конфигурации что опять же для каждой базы нужны эти за их старика were план делать и так далее вы что-то используете для того чтобы оркестре ровать базы данных потому что наверное ручная настройка каждой базы данных для каждой микро сервис уже становится очень сложный вот в этом вопрос спасибо мы строим dbase база как сервис то есть у нас сейчас вызов перед командой строи стоит чтобы прямо по кнопке базы diplo велась с ограничением ресурсам в текущий момент то есть как бы есть еще параллельно той текущие способы diplo и как мы диплом база над ними есть некая автоматизация но основной вызов вот то что база данных для каждого сервиса отдельно пока что у нас по большей части конфигурация коммунальные сервера когда несколько различных сервисов живут на одном сервере но коммунальная база это проблема в том что соседи начинают локтями толкаться то есть выбирать ресурсы соответственно далее следующий путь можно нашли нужный нам способ для ограничения то есть либо персональное железо либо ограничение ресурсов по и о по памяти по цвету и по сети но вы это уже автоматизировали то есть у вас уже по кнопке это делается или вы только идете к этому сейчас есть скрипты и скриптами но именно непосредственно полноценной автоматизация оркестра таро и тепло именно по кнопке без участия совсем человеческого соответственно это вот текущей наша задача и вызов перед нашими 2 той мы процессе work in progress как бы в этот момент идет и в том числе вот вакансия как раз тоже про это и заниматься только для на узко или примерно спасибо нет так нравится термин коммунальная база но в любом случае ты еще здесь сегодня да да я да и сегодня еще хотел посвятить у нас на стенде во витая симптом в шесть часов вечера будет сессия вопросов и ответов можем пообщаться на различные темы целый час вы приходите просто от меня ловить и задавайте вопросы спасибо большая примите нашу благодарность и вопрос был только один на кожу соответственно этот номер спасибо"
}