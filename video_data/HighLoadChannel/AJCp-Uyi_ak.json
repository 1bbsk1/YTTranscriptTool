{
  "video_id": "AJCp-Uyi_ak",
  "channel": "HighLoadChannel",
  "title": "YDB-оптимизации производительности под ARM / Максим Кита  (Яндекс)",
  "views": 571,
  "duration": 2281,
  "published": "2024-10-29T03:07:34-07:00",
  "text": "так Всем привет Меня зовут Максим я разработчик wdb до этого я работал в кликхаус в wdb Я специализируюсь на построении и выполнении запросов работаю в команде quy execution Вот ещё я веду курс по базам данных в Шаде и в вышке вот интересно что материалы более-менее в открытом доступе То есть вы можете Если хотите пройти лабы почитать посмотреть лекции Вот ещё у меня есть блог где я пишу про разные оптимизации производительности про High performance вот ссылочка на слайде так и про что мы сегодня поговорим а сегодня я расскажу про то как мы оптимизировали wdb pada ARM и в целом а Сначала я расскажу Вообще говоря про я не буду прямо там это не будет ар 101 я расскажу про какие-то вещи которые кажутся такие более-менее Advanced которые встречаются на практике с которыми мы столкнулись когда мы переезжали на на а вот а затем я расскажу про бенчмарки которые мы уже смотрели после того как мы какие-то оптимизации делали я покрою Click Bench ycsb и tpcc собственно начнём с ARM optimization Basic Ну во-первых что хочется сказать первое с чем ты сталкиваешься когда Ну вообще говоря берш там машину на Арме начинаешь что-то под неё оптимизировать это проблемы инфраструктуры под Арм низкоуровневые библиотеки Часто вообще говоря не имеют Арм поддержки Ну просто не имеют также многие низкоуровневые библиотеки не оптимизированы по даром Ну например библиотеки для сжатия разжатия данных L4 разные библиотеки для хэширования многие Тулы тоже не оптимизированы пом например Ош Dump пор очень сильно тормозит perf пор намного хуже работает Ну и всякие мелочи типа gdb работают чуть хуже А и четвёртое компиляторы генерируют менее эффективный код вот конкретно gcc и clank и всё за счёт того что для Арма бэнды имеют намного меньше платформ специфичных оптимизаций Вот и намного сложнее вообще говоря правильно закон рить компилятор под свой а какие есть проблемы с реализацией основные первая и самая основная оптимизация которую хочется первая и основная проблема которую хочется чтобы все запомнили - это разная модель стоимостей Ну например в сравнении с x86 64 виртуальные вызовы на Арме сильно дороже а томики сильно дороже про них я ещё расскажу подробнее например чтение запись не выровненного в общем много всяких таких низкоуровневых мелочей вторая вещь с которой вы можете столкнуться если у Вас какая-то например есть колоночная нагрузка или ба Processing это то что и вы используете много S инструкций это то что не О это вообще говоря не sse 4.2 не X2 не x512 это что-то своё это похоже на вот эти стандартные instruction Set x86 64 Но немного другое например там нет P Mask B инструкции которая позволяет вам от вектора перейти к битовой маске и библиотеки которые конвертирует Neon конвертирует X64 x86 64 в Ne они обычно нече ти и третья огромная проблема - Это то что у вас наверняка в проекте просто гора платформа зависимого кода Ну скорее всего x86 64 вот хорошую ссылочку Я на слайде оставил Как оптимизировать под процессоры Гравитон оттуда Я в целом взял довольно много Советов и многие советы действительно очень полезные на практике и подходят под все армы Очень советую Так давайте начнём с проблемы с которой мы пря об неё ударились и в целом Скорее всего вы тоже ударите об неё ARM - это Weekly ordered архитектура похожая на Power похожая на другие современные архитектуры когда x86 - это Total Store ordering архитектура и в целом Вы можете например ставлять барьеры неправильные в под x86 64 Когда пишете программу или у вас в целом Вы можете не ставить барьеры Ну например решили не ставить и у вас всё работает но на Арме это всё работать не будет И вообще гово arm8 вот четные амы они имеют такую интересную архитектуру Order mul Atomic вот я даже PDF оставил можно почитать про неё собственно первая проблема с которой которую вот что вам нужно включить чтобы если у вас много Томико в программе вы в целом вообще хоть как-то могли подар разрабатываться это large System extensions L System extension появи v8.1 и в целом доступен уже с этой верси если у вас версия ниже Арма вы например хотите деплоить ваше приложение например под новые армы и под старые армы например а просто ARM V8 Вы должны Ну вы можете использовать опцию в компиляторе M outline Atomic compile flug и в таком случае когда вы будете пользоваться Амика у вас вместо вот этих large System extensions инструкций будут использоваться Будет сначала использоваться Run dispatch который проверит поддерживаете вы их или нет Если поддерживаете будут использоваться инструкции покруче если нет похуже Если вы не хотите НТА dispatch Наверняка вы это не хотите вы можете выставить Arch R v82 такой Time FL и у вас всё скомпилировать graviton instan начиная с graviton 2 амазонок которых я тестировался они тоже уже поддерживают этот эту версию Арма вот Ну и все современные армы тоже вот и прочитать про этот экн можно по ссылочки но я расскажу очень кратко собственно lse э вводит в instruction Set атомарные инструкции и это вообще говоря самае стандартные атомарные инструкции compare and swap Atomic Memory instructions Ну например а взять там Амар прибавить к числу какое-то число и атомарный swap вообще говоря если у вас архитектура до lse то у вас вообще говоря Вы могли бы удивиться что у вас произойдёт в ассемблере и я дальше покажу на слайде в целом в таком случае Ваши атоми реализовывались как R modify Write последовательности используя Exclusive Load и Exclusive Store атомарные инструкции собственно например Вы хотите сделать инкремент какой-нибудь shared variable Ну например числа какого-нибудь вам нужно сначала Прочитать это число используя Exclusive Load затем прибавить к нему используя инструкцию затем сделать Store используя Exclusive Store И вам вернёт вообще говоря удалось ему сделать Store или нет И затем вы это должны проверять как это может выглядеть просто в цикле Ну представим вы написали такой вот простой Каз собственно тут есть атомарная переменная val есть val вы сделали такой вот и он реализовывается в такой ужас а этот ужас это как раз-таки то про что я вам рассказал То есть это такая пос такой цикл который как раз-таки реализовывает эту вот Load Store последовательность Але тут так особо не важен просто очень интересно получается но если вы уже включили lge System extensions то у вас всё прекрасно у вас будет инструкция Каз Вот теперь давайте подумаем Где вас вообще говоря это может по аффектив вообще говоря это касается не только касс это касается вообще говоря любых атомико но предположим вы используете в своей программе простейший spinlock вот тут вот есть такая простейшая реализация то есть метод Log Unlock Вот и правильно расставлены мемори ордера про них я ещё потом поговорю и в целом над UN Unlock смотреть смысла нету ну обще говоря этот ass так прямо изучать не надо Но в нём прям есть этот вот цикл вот я его как раз выделил на слайде если мы компилируется на тарную инструкцию swap и насколько это может вообще говоря по аффектив Вашу программу А на простом бенчмарке который меряет Lock Unlock производительность для шестнадцати потоков разница Примерно в три раза то есть вообще говоря если у Вас в коде используются атоми без large System extensions скорее всего у Вас просто невероятно всё будет тормозить и вот в idb у нас было очень много атомико у нас есть свой shed там очень много амиковры код где ещё много всяких emory барьеров разбросано то есть в целом м Вам эта вещ нужна Теперь давайте поговорим немного про Proper Memory orders в целом на x86 64 почти без разниц что вы там расставляет я прям не буду давать ссылку на стандарт вот я скажу так более-менее на практике собственно Seal consistency гарантирует вам глобальный порядок между всеми Амика и он почти вам никогда не нужен гарантирует вам порядок на одном атоми и почти всегда вы хотите использовать именно это вы хотите строить свои примитивы синхронизации используя эти эти emory ордеры единственное на что нужно быть очень аккуратными потому что есть инструкции которые обладают и acquire и relee семантикой например fch Add И третье - это КСТ инструкции обычно вы используете Это для почёта всяких каунтер когда вам в принципе на на порядок неважно у вас будет порядок только на условно говоря на этом вот одном атоми но он не будет гарантировать вам happens before О'кей Теперь давайте как бы что происходит в реальных приложениях в старых библиотеках может быть невероятное большое количество неоптимальных реализации различных примитивов синхронизации не оптимально реализованы спинки кастомные лоф стеки которые не КФ стеки кастомные КФ структуры данных разбросанные мемори барьеры и в целом Вот это всё оно как бы нормально работает на x86 64 но на Арме Оно просто начинает невероятно тормозить и одна из проблем что это очень сложно дебажить Потому что часто совершенно непонятно В чём конкретно дело на и на Арме ещё такая опасная вещь что такой код может содержать огромное количество багов потому что он вообще говоря тестировался только на x86 64 его очень тяжело мейнить его очень тяжело модифицировать в старых библиотеках ещё до появления Ого стандарта смиком люди реализовывали прямо на ассемблере знаете такие ассемблерные вставки серьёзные про Мист писали разбрасывали атомик барьерами туда-сюда и это просто нереально тяжело вообще говоря манить Ну то есть просто даже поддерживать этот код его прям очень тяжело непонятно баг там или нет например непонятно вот эта вот инструкция какая у неё семантика acquire или relee а у него вообще есть какая-то семантика и этот код невероятно тяжело модифицировать как раз-таки тоже поэтому тут в целом одно решение весь новый код нужно нужно писать с использованием студа Томика и строить Все примитивы синхронизации используя вот этот вот туда Томик Теперь ещё один прикольный момент - это размер кш линии Вы наверняка часто видели такую такой код человек пишет тут условно говоря платформа dependent padding Ну например на x86 cashline 64 байта и человек такой вот пишет например Амар переменную Потом пишет панг и 64 минус Si of это вот атомарная переменная А это может на Арме стрелять Понятное дело потому что размер может быть другой это можно в целом пофиксили но можно найти в Open прямо наха по первой ссылочки реализацию вот которая это сделает прям даже можно сделать с интеграцией с сиком Окей такая е в столкнулись с этой проблемой но когда мы занимались портирование кликхаус по Арм Мы как раз-таки с этой проблемой только ну в основном только и столкнулись Когда у вас появляется эта проблема Когда вы например то есть вообще говоря как сит может использоваться в вашем приложении у вас может быть автовектор То есть вы ну вы просто там условно говоря пишете свой цикл и кн или gcc его автовектор если у вас сит используется только так то скорее всего всё будет прекрасно и вообще говоря это такая опция которую вы Ну должны использовать по умолчанию но часто бывает что вам нужно написать какие-то симд алгоритмы и использовать симд инструкции голыми руками ну в основном как бы вы используете для этого интри сики вы можете написать прямо свой assem и на x86 64 вот такие вот интри сики вам скорее всего по проекту придётся вылавливать Ну вы просто там их на самом деле весьма много я парочку приложил э так как ну рме это просто даже не соберётся и э в целом вот в таком случае вам придётся использовать интри сики Арма а или же есть некоторые специальные библиотеки которые немного могут вам помочь с этим всем вот я приложил несколько библиотек по ссылочки Вы можете их Подключить подключить в места где вы используете x86 64 Иринки и всё автоматически будет работать они будут конвертировать ва а Иринки в Neon о'кей и последняя вещь - Это куча платформа зависимого кода на самом деле это такая большая проблема потому что Представьте есть какой-то разработчик 10 лет назад он написал If defined x86 64 else abort в какой-нибудь библиотеке И вам нужно теперь это найти иначе у вас может быть приложение в продакшене упадёт А вот тестами Конкретно этот бранч не покрыт Вот и вот такой платформ dependent Code тут он на самом деле может Вот я показал несколько инклюдед вот define x86 64 то есть скорее всего вам придётся все вот эти файны в своём проекте Ну условно говоря аккуратно просмотреть и вы их просмотрели и для ама обычно вам придётся сделать собственную реализацию То есть вы добавите бранч например для ама а для сим инков вы ну условно говоря подключаете ARM Neon фа там будут синки для Арма конкретно Ну и вы реализуете ваш алгоритм голыми руками на Ар Иринка теперь расскажу про одну проблему такую с которой мы столкнулись в wdb собственно Вот есть такой простой запрос From Hits и вот это был это бы ну этот запрос мы делали Ну условно говоря с этим моментом мы столкнулись почти сразу же вот и в перто Ну видно было что приложение прям серьёзно тормозит и в пе видно что у нас 30% CPU тратится на какой-то CRC вот ну кажется CRC так долго считать не стоит было разбра в м проблема Иво в страницах проверять Вот то есть была примерно такая Ужасная картина собственно Проблема была в том что был невалидный атек disch в CRC библиотеке собственно знаете в низкоуровневых библиотеках часто бывает такое там например x86 64 else If ещё что-то ещё что-то ещё что-то и вот как раз таки вот самая последняя бранча она была самая неэффективная реализация и туда как раз мы с Арм попали вот это пришлось поправить собственно добавить реализацию пор И после этого ВС стало лучше Вот и в целом на самом сервере мы уменьшили потребление CPU вот таким простым более-менее фиксом на 20% и для запросов Это было около 10-20 про ускорения Теперь давайте поговорим немного про бенчмарки собственно у меня как бы для моих тестов было два кластера один кластер Кунь Пегов собственно это процессор 920 4826 у него 48 физических я и у меня таких процессоров То есть у меня два сокета то есть два процессора и всего у меня на машине 96 физических ядер арх 500 гиб оперативки и SSD диск на x86 оперативка оперативки Чуть поменьше но для вот наших тестов это вообще говоря никак не не влияло диск примерно такой же но CPU немного другой это Intel X Gold Вот у него получается на одной машине 12 физиче ядер 24 ядра с виртуаль с гипертрейдинг И вообще говоря суммарно на машине вот таких процессора было два 48 ядер с гипертрейдинг получается в целом вы Спросите кажется какая-то серьёзная разница в ядрах в целом это нормально объясню почему цены на эти процессоры примерно одинаковые Вот то есть вы можете такие такие два кластера собрать примерно за одну и ту же цену Теперь какие бенчмарки мы смотрели я начал смотреть с Клик бенчан этот бенчмарк нравится потом мы смотрели Y csb и tpcc Давайте поговорим про Click Bench собственно я расскажу немного про этот бенчмарк Хотя может быть многие в курсе собственно он открытый орный данные в нём построены на арованы данных Яндекс продакшена Яндекс метрики в датасете есть 100 млн строк 70 ГБ разжал примерно 20 ГБ сжатых данных запросы в основном аналитические но некоторые такие типа технические запросы которые человек мог бы сделать в kv какую-нибудь базу данных Когда у вас например нету индекса Ну вот тут например Select User ID From Hits userid Ну и какой-то дишни И основная цель вообще говоря Почему я начал именно с этого бенчмарка это чтобы можно было утилизировать и сделать стресс-тест системы под нагрузкой найти какие-то горячие места которые вообще говоря можно оптимизировать потому что в целом такая бач нагрузка Она позволяет всякие такие условно говоря места которые на Видном месте находить Окей и про загрузку данных в целом вообще говоря с чем я сравнивал я с с это Bene я сравнивал с пасом Сначала я покажу сравнение с пасом потом сравнение кластера с кластером Вот мне просто было интересно сравнение с пасом потому что пог кажется весьма неплохо оптимизирован пором там довольно много патчей принимается вот поэтому мне было интересно посмотреть как там он будет работать собственно на заливку данных в удалось залить данные чуть-чуть быстрее вот это и на и на x86 машину вот цифры тут такие условно говоря не оптимизированная то есть я сейчас дальше немножко про это расскажу собственно по конфигурации какая у нас конфигурация idb мы запускаем на одном железном сервере одну ж наду которая собственно говоря занимается условно говоря хранением данных И четыре компьют нады которые занимаются собственно говоря вычислениями и это наш стандартный это наша стандартная конфигурация для больших серверов мы её используем потому что у нас внутри свой шедулер и наш шедулер хорошо работает когда ему дать небольшое количество потоков Ну условно там например 20 потоков А на такой большой машине Ну Пришлось сделать больше динамических узлов вот как как уже сказал все узлы на одной физической машине и конфигурация греса - это оптимизированная версия из Клик бенчан видимо её делали какие-то люди возможно из PG комьюнити единственное что я поднял количество воркеров и размер буферов кашей чтобы в целом полностью машину можно было утилизировать Вот и если сравнить с wdb Вот ну как условно вот наш наш стандартный строчный движок то у нас получилось так что мы почти всегда что мы всегда быстрее Иногда прямо сильно быстрее в целом это не что-то Сверхъестественное потому что PG вообще говоря под такую Click Bench нагрузку не оптимизирован в принципе вот а у нас компьют слой весьма оптимизированный то есть весьма много специализаций вот поэтому так так и работает плюс у нас есть ещё Ира quy параллелизм то есть мы у нас есть параллелизм внутри запроса в постгрес параллелизм внутри запроса тоже есть но кажется он такой более консервативный теперь Так сейчас секундочку теперь графики с x86 тут примерно такие же графики на wb Вот такая нагрузка работает быстрее тут я немного хотел отойти в сторону и сказать что в целом Это понятное дело не предел у нас недавно появился который может для Вот таких вот можно сказать каких-то бач нагрузок тических нагрузок сильно серьёзно улучшить вашу производительность у нас git асинхронный то есть ваши запросы компилируется асинхронно чтобы не мешать низко латентной транзакционный нагрузки Вот и с Вот вот сейчас jit у нас работает только под x86 и в целом для всех запросов более-менее видна разница в два раза для некоторых запросов видна прямо очень серьёзная разница но тут можно заметить что запрос в целом очень странный он считает кажется 90 сумм вот такие запросы в целом можно встретить в серьёзных аналитических базах данных которые считают всякие статистики вот Ну в целом весьма Интересно теперь Давайте посмотрим Ну самое интересное собственно ARM vs x86 тут э ARM всегда быстрее и в целом э в целом как бы это можно было бы аккуратно объяснить У нас хороший Ира quy параллелизм и на Арме больше ядер то есть в целом с утилизацией ядер у нас вот на таких запросах проблем не возникает И за счёт того что больше ядер хоть каждое ядро может работать и похуже в целом есть прирост производительности Вот и запросы получились в целом в два в 2 с по раза быстрее вот именно на этой нагрузке то есть вообще я тестировал ещё и другие всякие аналитические системы тоже тестировал и в целом мне показалось что ARM - это прямо отличная платформа для деплоя всяких аналитических баз данных Вот то есть Теперь давайте поговорим про ycsb собственно Что такое ycsb ycsb - это Yahoo Cloud расшифровывается Yahoo Cloud Сен Benchmark это бенчмарк в котором собственно говоря у вас есть K value нагрузка её ну сделали в яху собственно там есть несколько Ke value вордов и каждый workload он параметризм записей количеством потоков количеством условно говоря сколько запросов каждый поток должен сделать ещё из интересного там Zip распределение в целом а так в теории скорее нет смысла в это вдаваться могу просто сказать что там есть некоторое подмножество горячих ключей к которым запросы происходит сильно чаще чем к остальным какие там есть лоды там есть workload A который update Heavy workload там 50 на 50 чтения записи там есть workload B где 95% чтений и 5% записей workload C где только чтение workload workload D E и F они в целом не такие интересные workload D например читает latest То есть вы вставляете новую запись и сразу же её читаете workload E он вообще говорит Не value там просто читаются нжи и workload F - это такой интересный workload modif Где вы читаете запись модифицируется её и затем записываете обратно этот Work в целом может быть довольно сложный для систем который используют lsm деревья Вот теперь какие у нас тут были датасеты вообще говоря с ycsb очень удобно 1 млн строк там 1 гиб вот так можно запомнить то есть 100 млн строк - это 100 ГБ 300 млн строк - это 300 Гб вот эти вот все Клод я их прогонял с разным количеством трейдов начинал с 512 и затем заканчивал 8000 И сейчас я сначала покажу slee конфигурацию потом кластерную конфигурацию собственно на Арме заливка данных прошла примерно на 50% быстрее и после заливки данных можно всегда посмотреть как у вас вобще говоря данные за партиционирование Теперь давайте посмотрим бенчмарки на sle noe собственно я я тут покажу ну близко Work А и C а затем покажу вообще Сури картинку в целом на клоде а а Арм быстрее на клоде C тоже быстрее но в целом на клоде C мне тут графики выглядят более-менее одинаково но на Арме Ну вот примерно на 10% быстрее получалось и если смотреть Сури то на синоде вообще говоря вот ну такой вот setup Ke value бенчмарка на сингл ноде получилось так что ARM Ну примерно там на 20-25 про всегда быстрее то есть в целом это неплохие цифры но как уже было замечено ранее То есть например на аналитической нагрузке мы получали примерно X2 вот и это на самом деле всё очень сильно связано с тем что это одно ядро получалось сильно мощнее вот Окей теперь по по времени загрузки на кластер на кластер время загрузки на Арме на 25% быстрее можно тоже посмотреть сколько там было партиции собственно я так обычно всегда и делаю чтобы примерно понимать Ну какой concur я ожидаю Вот и дальше можно посмотреть и тут уже видно что тут цифры не такие хорошие в целом Наде А И Наде ам примерно на там вот на 10-15 про быстрее но как бы тоже ожидалось ожидали результаты сильно лучше Вот и в общем на Клода там примерно такая тенденция и соблюдается Вот теперь что хочется сказать вообще говоря про этот бенчмарк ну его пропускная способность в целом с размером с увеличением количества данных она растёт и растёт прям Ну не совсем линейно за счёт того что там Zip распредели всё-таки там есть какие-то горячие партиции Горячие Ключи но весьма хорошо растёт а в целом на 10-30 быстрее но из того вот когда я вот эту вот вещь конфигурирован намного более сенситив например к пере подпискам по ядрам Ну например Вы выде чуть-чуть больше ядер и между ними возникает переподписать как-то Так теперь про tpcc я расскажу немного про этот бенчмарк собственно это такой Индустриальный стандарт стандарт индустрии для oltp транзакционных баз данных там очень сложная схема с базой данных какого-то поставщика чем хорош этот бенчмарк он параметризм числом количеством хаусов и каждая транзакция То есть это транзакционный бенчмарк и каждая транзакция обращается к множеству таблиц используя очень сложные методы доступ то есть там прям очень сложный стандарт Я оставил на него ссылочку на слайде можно почитать я покажу схему запоминать её не нужно Я скорее покажу Так что она Ну действительно вот как прям настоящая какая-то такая схема в базе данных тут есть вот можно посмотреть W House тут есть камер тут есть Order и посередине New Order New Order - это как раз-таки самая важная таблица это транзакция когда кастомер делает новый ордер то есть новый заказ и tpcc меряет tpmc количество вот этих вот New Order ций то есть самих запросов в транзакционных в tpcc их намного больше их Примерно там 20-30 штук Но вот именно вот это вот New Order транзакцию мы измеряем и в целом это такая интегрируемая можно сказать Метрика такая общая Метрика как вообще кластер себя в этом как кластер себя в этом бенчмарке чувствует И это первое число которое мы получаем и второе число которое мы получаем после того как мы запускаем бенчмарк - это эффективность эффективность - это тот tpmc который Вы получили поделённый на максимально возможный tpmc который собственно этот бенчмарк сам посчитал сколько вы должны были бы делать И ещё можно посмотреть латентности для каждого типа транзакций Но обычно в бенчмарке собственно говоря Ну В результатах бенчмарка различные ли база данных этого не пишут Ну просто за скобками оставляют потому что там если например у вас латентность в какой-то момент становится очень плохой то tpcc просто ну отказывается работать вот на а загрузка данных была примерно в два в три раза в два в три раза быстрее там заливается одновременно сразу много таблиц то есть можно хорошо машину утилизировать И вообще говоря Никаких никаких там значимых значимой разницы на tpcc Я между этими машинами не заметил мы я Мерил 10.000 верхаус 15.000 верхаус с разными конфигурациями но в целом у меня CPU кажется совсем не был батлнете там были Батл нека как раз-таки распределённые транзакции между шарда то есть CPU там особо ничего не упиралась Теперь какие у нас вообще говоря в idb дальнейшие шаги Ну вообще говоря хочется улучшить наш shed То есть у нас используется кастомная актор система в в idb и хочется её улучшить её реализацию лучше для низколактозный тюнин низкоуровневых библиотек То есть это Например ча encryption xx3 вот всякие такие библиотеки можно ещё потютьков не будут работать на Арме или будут просто тормозить и низкоуровневый библиотеки все необходимо оптимизировать Есть ли какие-то вопросы Максим Спасибо за доклад и популяризацию АРВ тем презент от организаторов и спонсора компании Газпром и у нас вопрос из зала у Давайте вот вопрос А вы выбираете кому я выбираю потные сидят про Добрый день Не пройду эфире А Максим Спасибо за доклад арестов Константин слаер А я прошу прощения я опоздал на начало вы какую операционную систему используете а Linux не это понятно что Linux а дистрибутив А я вот к сожалению на тех кластерах на которых я измерял я не могу сказать дистрибутив Ах я как раз могу сказать потом в колур Ага понятно Вот И второй вопрос э я больше ну связан с тестированием транзакционных баз данных вот аналитические БД для меня тёмный лес поэтому глупость возможно спрошу а Насколько я понял у вас размеры тестовых баз меньше чем объём оперативной памяти всегда да э там Если попробовать скажем полутора терабайт ную базу или для аналитики это просто не имеет смысла эти тест Ну чтобы у вас начало прогреваться как бы грубо говоря не только память процессор Вот это меж соединение А вы весь тащили бы да вообще говоря Click Bench - это как раз таки такой бенчмарк который в целом весь помещается в оперативную память совсем мало сжатых данных и он как раз-таки используется для аналитических баз данных чтобы ну вообще в аналитических базах данных он используется используется чтобы смотреть Stage насколько у вас там аккуратно индексы используются что вы например мало данных будете читать даже из оперативки ну например лежит Это первый момент А вот конкретно у себя я его использовал чтобы именно CPU посмотреть Угу всё спасибо А друзья не забывайте ходить по QR коду голосовать за доклад давать обратную связь Это важно и спикер и организатора и у нас следующий вопрос Да у нас так я наверное включу QR Код Да с ра кодом мы сейчас решим и у нас следующий вопрос м Добрый день Я немножко продолжу предыдущий вопрос Вот вы довольно много говорили про цпу отчасти затронули сеть Есть ли какие-то особенности для амов при работе с дисковой подсистемой конкретно у нас в wdb там используется вообще говоря свой distributed там используется своя файловая система которая работает с дисками напрямую я уверен что особенности есть но конкретно с ними я не столкнулся А вот этот самый ж он тоже реализован на арми или это всё-таки Intel а весь то есть вот Весь вот этот вот деплой он весь был на армия то есть этот Stage Ну он как условно как программа вот этот вот Stage Note то есть это один и тот же Бинар wdb просто запускается в режиме Режа то есть тоже на армии всё да спасибо а такой интересный вопрос для меня а пытались запустить лаер на rasberry тре боюсь не получится слишком маленькая машинка А на четвёртом а может быть и запустили надо а коллеги возьмите пожалуйста микрофон Олег прокомментируй или к нам Выйди кажется ответ был запустили у нас стоит кластер на rasberry P вот да у нас точно есть кластер я вспомнил у нас там человек Энтузиаст запустил такой кластер ну собственно Максим уже всё сказал Да у нас стоит в офисе а Скажи для чего для фана конечно Для чего ещё потому что могу отве и на следующий вопрос ответ кстати достойный кало Да потому что може а Ладно я всё-таки спрошу Ладно спасибо за доклад А скажи пожалуйста вот у меня наве два вопроса первое пробовали ли вы для simda Google Highway значит чтобы нивелировать разниц архите а второй вопрос пробовал ли ты объяснить разницу производительности различным размером Шей у этих процессоров А да вот с Highway библиотекой Мы её не использовали в целом у нас конкретно в idb кажется это можно было бы использовать в ядрах которые аналитические вот там где у нас действительно векторизация происходит вот в кликхаус кажется год назад мы тоже Мы пытались затянуть себе эту библиотеку там есть удобные примитивы для сортировки вот Виктори зова то есть мы хотели это себе затягивать возможно уже Как раз-таки коллеги затянули а получается а второй вопрос как раз-таки с кэша Да я думаю разница в кашах точно есть но конкретно я себе ещё больше ну вот объяснял когда делал например свои синтетические тесты тем что просто на x86 намного больше времени уделено на различные бранч предикторы различные там фенг оптимизации вот этих всех вещей То есть мне кажется там просто ну грубо говоря само ядро Ну вот конкретно одно ядро оно быстрее и за счёт за счёт этого например низколактозный на интелеком машине лучше но на Арме Просто после того как мы Фрут через какую-то границу переведём при которой x86 машина уже не держала бы такой Фрут в принципе ну то есть Лан уже в бесконечности уходил бы вот в таком случае Вот как раз таки это золотое место для Арма и у нас следующий короткий вопрос да спасибо за доклад вопрос действительно короткий они пробовали всё-таки ужи мать на арми количество потоков до 48 ядер чтобы посмотреть Как соотносится производительность в расчёте именно на одно логическое ядро конкретно вот так вот я я не делал то есть Ну скорее всего я делал но там получается всё-таки наверное пря аккуратно рассчитать количество ядер То есть у нас там ну там так как система много поточно там же ну выделяется чуть больше ядер всё-таки там есть небольшая пере подписка и пря так идеально не померить но я Мерил производительность одного ядра своими тестами Вот и производительность одного ядра на Арме у меня была хуже вот конкретно на тех синтетических тестах которые я делал Спасибо всем за замечательные Вопросы Спасибо за очень детальные подробные ответы вы сможете продолжить дискуссию в зоне луали справа либо слева где Вам удобней и от ведущего основной вопрос Выбери лучше вопрос Вот наверное Руслан задал самый интересный вопрос про кши вот пакетик Нашёл своего Руслана Спасибо тебе что ты с нами сегодня ВМ зале N"
}