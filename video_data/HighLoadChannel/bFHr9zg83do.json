{
  "video_id": "bFHr9zg83do",
  "channel": "HighLoadChannel",
  "title": "Групповые чаты в Одноклассниках / Андрей Тимофеев (Одноклассники, VK)",
  "views": 681,
  "duration": 2417,
  "published": "2024-04-17T01:09:28-07:00",
  "text": "Всем привет Меня зовут Тимофеев Андрей Я ведущий разработчик в компании Одноклассники и сегодня вам хочу рассказать о том как мы делали групповые чаты и какие решения приходилось принимать значит сначала пару слов в числах она нами пользуются сообщениями в Одноклассниках пользуются более 50 миллионов пользователей они отправляют более 10 миллиардов событий в день и в каждый момент времени пользуются сообщениями более трех миллионов пользователей Что такое мессенджер Кто из вас пользуется вот уже есть что такое мессенджер наверняка все из вас представляют на самом деле в Одноклассниках есть встроенный мессенджер и в принципе можно установить отдельный там там где можно зайти в профиль через Одноклассники либо отдельно но внешне они смотрятся очень похоже Что такое все знают слева обычно список чатов у нас хронологическом порядке По последнему сообщению справа выделенный конкретный чат и вот в нашем докладе в групповых чатах мы будем рассказывать в основном О я буду рассказывать в основном о доставке уведомлений Что такое уведомление в чаты во-первых это весь список чатов слева когда мы заходим в чат первый раз и далее это вот все инкрементальные изменения в чатах Вот например сообщение в чате в котором мы находимся либо в чате в котором мы находимся но мы будем всегда видеть как сообщение туда приходит и подпрыгивают вверх увеличивая счётчик непрочитанных сообщений или марки это соответственно информация прочтении каким-то пользователям любым участником чата значит какие на самом деле марки мы видим также еще и слева в списке чатов сразу же даже если там мое сообщение последнее и кто-то прочитал Мы видим что его прочитали Какие задачи мы ставили себе для групповых чатов мы хотели поддержать чаты до 20 тысяч участников безлимитные каналы каналы это тоже самое что чаты только туда могут писать отдельные люди отдельно выбранные Мы хотим чаты видеть в хронологическом порядке По последнему сообщению хотим получать все уведомления ничего не теряя И поддерживать несколько устройств Что это значит Это значит что если я на захожу в мессенджер с разных устройств Я всегда вижу там одинаковый список чатов одинаковые счетчики непрочитанности Марков в принципе требования в основном заставляет нас все хранить на сервере и клиенты как правило синхронизируются с клиентами сервером так пропустили да Но для того как начать делать групповые чаты у нас уже были достаточно популярные диалоги То есть это чаты один на один когда люди переписываются друг с другом естественно мы хотели использовать по максимуму инфраструктуру диалогов Кто из вас знает что такое Кассандра хорошо отлично много кто так вот сердце наверное сообщение это сообщение у нас хранятся в кассандре на этом такой я не буду очень подробно в этом углубляться про это рассказывает Олег Анастасия в своем докладе А я расскажу что нам важно во-первых мы храним все сообщения в единственном экземпляре на чат То есть в качестве ключа у нас выступает Так мы сейчас про диалоги говорим два пользователя пользователь один пользователь второй и все эти чаты позиционируются в кассандре получат ID То есть у меня как у владельцев нескольких чатов мои чаты будут разбросаны по всем партициям что нам это дает это нам дает экономию места потому что у нас уже 140 ТБ данных текстов текстовых данных и хорошо что в одном экземпляре храним и это из коробки нам позволяет запустить групповые чаты так очень хорошо масштабируется на любой размер чатов но это что касается сообщений достаточно ли одной базы Кассандры чтобы запустить сервис-менеджер какие у нас основные функции это отправка сообщения в чат в принципе в Кассандра она все хорошо ложится она идеально подходит для добавления в ряд сообщений Чтение сообщений по чату также в принципе все очень неплохо работает прямо используем Store ну плюс каши конечно что там всякие но Все работает отлично и вот как раз мы приходим к методу загрузки истории чатов которая Как раз на экране помимо истории чатов хронологическом порядке Мы хотим еще видеть счетчики они прочитанности и и нам все надо как-то собрать по текущему сторожу кассандре Где хранятся сообщения можно попробовать собрать но Давайте посмотрим что из этого выйдет если мы попробуем просто по плечу попробовать поискать то из этого мало чего выйдет потому что мы знаем только одну составляющую ключа это пользователи которые запрашивает историю вторая составляющая нам неизвестно мы храним этот ключ нам получается перебирать их не вариант слишком много пользователей можно сделать индекс пользователей времени сообщения тогда мы можем запрашивать все последние сообщения последнего нашего визита в Но это будет работать на небольших размерах в случае даже не очень больших например посмотрим У меня есть 10 чатов каждый из них написали по 100 сообщений и мне для того чтобы выгрузить первую страничку мою Где находится около 10 чатов как раз с учетом того что каждое сообщение у нас может быть до 4 КБ 4 мегабайта и 4 мегабайта Это не просто данных которые надо вытянуть на надо их вытянуть обработать то есть это достаточно много будем тратить ресурсов и в принципе можно еще какие-то придумывать индексы еще какие-то поверхности решение но оно все будет плохо работать в больших случаях поэтому Мы подумали Нам нужен еще отдельный понятное дело для истории чатов и решили их поместить которое умеет обнаруживать конкретную модификации то есть принципе мы можем туда складывать все события счетчики и все будет хорошо работать более подробно про него рассказывает мы Давайте разберем как же мы храним эти сообщения историю понятная история хранится по юзера идеи такие в качестве value мы храним прямо список всех чатов в которых участвует пользователь отсортированный в хронологическом порядке первый список соответствует первому списку второй второму и так далее В каждом чате у нас находится вся информация необходимая для отображения на Первом нашем экране это и пользователь с которым мы переписываемся и количество непрочитанных сообщений и время последнего сообщения и перед Марк оппонента нашего но мы рассмотрели чтение у нас теперь идеально простое получается за один запрос Киеве или сторож мы достаем сразу всю историю и там есть все данные можно очень быстро отрисовать никаких проблем нет но нам необходимо эти данные поддерживать контентом состоянии то есть получается всегда когда есть какие-то изменения мы должны Дописать как это происходит вот наш смотрим пример у нас есть два пользователя Андрей Сергей у них есть общий чат какой-то допустим пока он уже весь просчитан и Если Андрей пишет сообщение Сергею после того как сохраняется сообщение в базу сообщений сразу же синхронно мы изменяем и историю чатов у себя соответственно подбрасывается вверх так как это последнее сообщение пришло и Сергея при этом у него еще увеличиваем всё хорошо работает обработал Если есть какая-то коллизия сохранил но какая Здесь проблема для того чтобы обновить всего лишь несколько чисел и передвинуть чат нам пришлось прочитать и сохранить весь список чатов это еще проблема известна под названием плитейшн и давайте рассмотрим насколько вообще серьезно эта проблема может быть у нас 90 процентов пользователей у нас имеет около 100 чатов не более 100 чатов около одного процента более 1000 чатов Ну есть пользователи которые имеют еще больше мы храним в принципе историю до 10 тысяч чатов на каждого пользователя и если рассмотрим такую такие действия со списками чатов у нас около делается 200 тысяч запросов в секунду stargue не стоит переписок и возьмем даже размер границы сверху снизу размер средней чата если бы мы хранили все чаты мы получили бы достаточно большой трафик вот перемножим еще умножаем на 3 потому что storage Шелдон морти кворумный мы должны хранить три реплики поэтому и апдейт идет 3 репки сразу получаем 48 это очень большой трафик для метаданных помимо там же будет еще трафика сообщений и конечно же мы не хотим жить с таким трафиком помимо трафика этой нагрузка на цпу каждый раз надо достать список его обработать обратно сохранить поэтому естественно надо как-то решить эту проблему это проблема решается Вполне себе просто мы делим данные на горячие и холодные мы знаем что пользователи Даже те кто имеет достаточно большой Граф связи как правило общаются с небольшим списком пользователей в конкретный момент времени поэтому все его текущие переписки в которые мы прямо сейчас идет Мы храним в активном списке как раз горячие данные где храним не более 50 переписок и все остальное что оттуда туда не попадает помещается в архивные где мы храним как раз наши 10 тысяч в этом случае как у нас происходит работа если мне кто-то пишет сообщение и что мне приходится делать Я достаю у себя список весь чатов в активных помещают туда наверх новый чат если последний чат У меня заходит за предел 50 мне приходится переместить в архив для этого я читаю данные из архива помещаю начало также и все это сохраняя обратно это мы правда рассмотрели негативный сценарий Когда нам приходится что-то двинуть в архив как правило 95 процентов всех запросов они связаны с тем что чаты перепрыгивают в рамках активных переписок и нам не приходится делать запросы в архивные чаты то есть что мы в итоге имеем у нас 95 процентов идет в активные чаты активные чаты у нас ограничены теперь размером они не более 1 кб занимают архивный чаты у нас средний 10 килобайт Если учесть разделить общий трафик на количество запросов и таким образом мы снизили потенциального трафик который мог у нас быть без разделения горячей холодные данные до 5-10 раз очень неплохо и принципе второе что мы получаем может быть даже более важно Это линейное масштабирование теперь наш трафике нагрузка будет расти только с увеличением активности потому что в принципе самые размер истории он растет и постепенно без какой-то активности пользователя они постепенно добавляют новых друзей Граф общаются с ними и архивные переписки вклад в общей слишком маленький мы этого не замечаем отлично В принципе так мы разобрали Да не все разобрали вот Еще хотелось сказать в активный у нас идут запросы примерно среднем около 1 миллисекунды базу в архивные 2 секунды вот значит у нас таким образом были устроены диалоги база сообщений и база истории переписок куда мы сохраняем абсолютно все изменения и за один запрос на чтение достаем историю конечно же групповых чатах мы когда делали групповые чаты хотели по возможности переиспользовать все эти стороны чтобы иммигрировать ничего не делать с этим ну или рядом Давайте посмотрим что же можно было сделать для того чтобы заработали простая схемка Как смотрится работа с диалогах у нас приходит запрос сервис который может писать базу сообщений в принципе самом простейшим сценарии нам достаточно добавить базу участников тоже в кассандре туда Очень неплохо подходит список участников чатов редко сильно меняется добавляются и вроде бы все хорошо Да мы можем также продолжать писать и у нас есть поддержка чатов но поддержка чатов У нас есть только если они совсем маленькие случае больших чатов Например если у нас будет чат на 10 тысяч участников время обработки такого запроса будет Как раз около 10 секунд с учетом притом это Нижняя граница потому что могут быть какие-то походы в архивной переписке конечно же мы можем это все распались на 100 потоков тогда время запроса у нас меньше доставили секунд вроде бы неплохо но на самом деле будет не сто потоков а 300 потоков потому что мы пишем 3 реплики а во-вторых основная проблема в том что мы перестаем управлять нагрузкой на сервис конкретно у нас есть какой-то инстинкт который получает запросы обрабатывает на него может прилететь неожиданно тысячи запросов такие большие чаты и ему просто не хватит ресурсов на то чтобы обработать эти запросы не потоков ничего понятное дело нам нужно как-то управлять нагрузкой Ну и обычно это делают с помощью очереди мы все такие долгие операции как оповещение всех участников пишем в очередь и некий обработчик очереди читает события и читая всех участников чата уже пишет в базу истории переписок вроде бы так все будет отлично работать Единственное что понятное дело одного модификатора нам не хватит потому что он будет Вот у нас около 100 тысяч запросов в секунду приходит Да если опять же на 3 реплики получаем 300 тысяч удаленных вызовов в секунду он не потянет естественно мы захотим его размножить у нас будет теперь много читателей очереди в принципе они могут ее быстро разгребать Но все равно это работает будет плохо Почему Потому что когда мы будем читать события для какого-то пользователя например они будут лежать подряд в очереди попытаемся их параллельно Во много потоков и много процессоров писать в нашу базу наша база конечно хороша И умеет разруливать как раз такие конкурентные модификации давайте рассмотрим как она их разруливает вот у нас например есть два процессора которые пытаются сохранить изменить какое-то историю переписываться для того чтобы изменить они должны сначала прочитать эту историю потом первый допустим идентификатор изменил ядовые 11 и попытался сохранить если ему повезло его версия V1 совпадает с текущей на момент сохранения в стороже V1 он успешно ее меняет и все хорошо тем временем второй процессор изменив значение для своей версии V12 попытавшись сохранить сто раз наткнется на коллизию его версия V1 предыдущая не совпадает с текущей версии V1 поэтому Им придется проделать всю операцию Заново заново просчет заново попробует поменять если повезет никто другой не поменял то успешнее то есть принципе мы видим да что Когда возникает коллизия она в принципе обрабатывается Но в данном случае вместо двух запросов мы сделали три и с ростом количества участников и параллельных запросов не коллизий в худшем сценарии у нас количество запросов будет как сумма арифметической прогрессии Мы рассматриваем самые лучшие сценарии есть все что ты можешь рассмотреть придумать сам оно вроде всегда произойдет надо про это думать и давайте рассмотрим простой пример у нас нет никаких ограничений на подписки я например могу подписаться на 100 чатов на 10 каждый из них 10 участников и с учетом того что например в этот чат одновременно напишет по одному сообщению это Очень вероятно В итоге в худшем сценарии мы на эти 100 сообщений получим 5000 запросов в базу достаточно много мало того что это 5000 запросов так еще и время худшего запроса у нас будет ни одна миллисекунда а 100 миллисекунд в лучшем случае И если мы даже предположим что всем участникам чата решим так все участники этих чатов подписаны на все эти стучат Да мы получим вообще 50 миллионов запросов Ну тут сразу ясно да что эта схема не работает и надо с ней что-то делать Давайте зафиксируем какие у нас есть проблемы с такой обработкой Когда мы читаем очередь и параллельно их обрабатываем во-первых рост коллизий Что приводит и к времени выполнения запросов никаких ошибкам и есть такая явная проблема что мы теряем порядок событий это для мессенджера очень важно потому что например могут быть события сообщения удаления сообщения нам нельзя их поменять местами меняем местами то уже будет неправда в истории и как как происходит смен порядок мы вы четыре события начали параллельно их обновлять начали появляться коллизии и там уже в рамках коллизии уже они могут по-разному обрабатываться мы уже порядком не управляем вторая неявная проблема есть влияние чатов друг на друга и вообще пользователей такие большие чаты которые создают много активности Если вдруг произойдет взрывная взрывной рост они выедают все ресурсы и мы таким образом не даем работать другим чатиком маленьким которые хорошо работали и Они вроде не причем время растет понятное дело это как сопутствующая проблема которую в какой-то момент просто не даст работать сервисы вообще Что можно сделать в этом случае Понятно самое что приходит в голову таким образом последовательно сохранять Все изменения для пользователя то есть в одном потоке но для этого нам надо собрать все события которые у нас идут в одну очередь и разбить ее на очереди для каждого пользователя то есть сортировать по сути вот в идеальном случае мы рассматриваем у нас есть очередь прямо для каждого пользователя каждую такую очередь читает свой обработчик и потом спокойно пишет storage и более того он может не просто писать в один поток он может еще и батчами читать из очереди если не успевает и сохранять Stories у нас Киеве или Stories поэтому Бачи там вообще идеально ложатся получается за один запрос мы можем сразу много изменений записать Да в принципе мы так и думаем сделать И на самом деле это очень напоминает модел Кто из вас не знает что такое актеры все знают Отлично На самом деле Да что такое поднять объект он имеет обрабатывать события создавать другие актеры отправлять им события и он работает в одном потоке Это важно Очень что он работает в одном потоке и сам он является потоком нас этих объектов могут быть миллионы Как нам и надо у них есть по сути своя локальная очередь событий и сами театры Мы в принципе у нас есть небольшая совсем небольшая библиотека мы ее активно используем Вот и в 11-х рассказывает своих докладах о том как мы это делаем в других сервисах и здесь мы тоже ее используем давайте рассмотрим просто как в случае актеров происходит обработка события Например у нас есть очередь общая для некоторых чатов и обработчик с полом потоков для примера просто два у него потока и когда мы учитываем события создается для него актер для этого чата ему вмещается очередь события выделяется поток это поток обрабатывает события если ему приходят другие события какие-то они просто добавляется очередь тем временем событий для других чатов спокойно обрабатываются их актерами для них создаются свои авторы свои потоки выделяются я не обрабатывают если актер например выполнил первое свое событие и у него появилось время выполнить свои события из очереди очень удобно после того как все обработали секторы удаляются потоки освобождаются мы можем их использовать и для других факторов В общем все отлично но тогда приходится немного усложнить схему что нам нужно сделать для того чтобы эта схема заработала нам придется разбить нашу одну общую очередь на несколько очередей так как мы теперь хотим чтобы процессор в котором находится актеры для конкретных чатов и пользователей всегда получали события гарантированно они должны читать очередь которую приходят события для них поэтому по чату позиционируем событие пишем в своей очереди и какой-то конечное число То есть это не для каждого чата соответственно каждый час процессор читает свою очередь учитывает все события таким же образом позиционируют события для всех пользователей которые читают во время своей процессоры и они соответственно в один поток могут писать эту историю и что мы получаем В итоге у нас вообще нет коллеги потому что мы теперь пишем в один поток все события у нас нет никакого влияния на соседей Потому что если вдруг у нас появляется какой-то даже если появляется какой-то спам чат который нас прошел все наши спам защиты вдруг на короткое время и начал спамить то самое плохое что может произойти это его очередь начнет переполняться и никак он не повлияет на другие чаты Ну и как важная плюс когда то что мы теперь управляем нагрузкой то есть мы можем вот этими батчами размером патчем пользователям которые например не активны увеличивать чуть время если хотим чтобы собрать побольше Бачи и сохранять события например 85 процентов всех событий Мы обычно сохраняем теперь батчами и простой пример за последнее время у нас количество событий выросло с 10 до 18 миллиардов и мы наши тоже никак не увеличивали некоторые события просто чаще пишутся добавляются пишущий очень хорошо легко масштабируется просит есть но в принципе так мы пишем события но есть одно такое волшебное событие которое называется redmark в чем его особенность про него хотелось прям отдельно сказать Дело в том что перед Марк Мы один посылаем всегда всем участникам чата а при этом одно сообщение могут прочитать тоже все участники чата То есть получается один Марк можем отправить квадратичная зависимость получается то есть тщательно 10 участников мы можем на одно сообщение отправить 100 миллионов это прям плохо И на самом деле мы просто не отправляем марки в таких чатах то есть в больших театрах больше 100 участников мы их не отправляем всем участникам то есть марки сохраняются для самого пользователя их даже может можно посмотреть в интерфейсе кто что прочитал Но это по отдельному запросу здесь мы рассмотрели так как мы масштабировали запись новых событий Но на самом деле больших чатах помимо записи еще есть чтение и оно очень сильно влияет протокола в рамках этого доклада я не успею подробно разобрать что мы поменяли в протоколе на самом деле приличные вот Юрий буянов рассказывает своем докладе а я про кратенько пройдусь скажу что во-первых мы их сделали клиенты более толстыми то есть принципе может быть они были не совсем тонкие но стали еще толще в чем основные изменения То есть как работал клиента раньше клиент когда получал уж о том что появилось что-то новое что мог сделать он запрашивал запрос тоже новая появилась сервис собирал данные необходимые рендерил ответ я давал за триделенные чаты и сообщения на клиент это очень неплохо работает в диалогах потому что максимум это двойная нагрузка когда отправитель получатель на пушек самом деле чатов мы получаем проблему Когда у нас появляются большие жирные чаты а то получается на каждое сообщение если в онлайне сидит много участников Все они будут делать запросы и это на самом деле хорошо спамят и плюс Северный рендеринг который мы тоже необходимо собрать данные для отрисовки даже с учетом всяких Кощей которые там можно делать но это работает не очень поэтому мы переделали протокол Да мы сделали более толстые клиенты которые все кэшируют и сообщения пользователей Все изменения Они получают по пушам то есть теперь им не надо делать дополнительные запросы на входящие количество чтения у нас полностью зависит теперь опять же количество пользователей которые именно активно что-то делают Они получают проблему и что же я хотел сказать заключение то есть мы мастурбировали нашу запись чтения запустили чаты на 20 тысяч участников и если безлимитные каналы где более 100 тысяч участников находится в принципе люди пользуются все работает ничего не падает самое главное среднее время доставки у нас в диалоге около меньше менее 100 миллисекунд в чат Мы доставляем за секунду не более чем за секунду уведомление благодаря тому что мы вот делали такие оптимизации с записью и протоколом даже с тем учетом что у нас появились чаты групповые Которые теперь тоже пишут большое количество событий в базу мы наоборот даже сократили нагрузку на нашу историю переписок Вот она сократилась до 100 тысяч до 100 тысяч запросов в секунду И что же как же где же это все работает Это работает у нас вот на таких кластерах у нас два кластера активный активный чаты они в принципе похоже по объему данных по нагрузке понятное дело активное чуть выше и события рассылают которые мы рассматривали на которые живут актеры у нас 24 таких сервисов которые читают очереди и вот так у нас работает Возможно у вас есть какие-то вопросы напомню за лучший вопрос бывают призы Да так пожалуйста вот у нас тут много желающих задать вопрос кто несет микрофон спасибо спасибо за доклад мне интересно было пропорционирование в очередях что случается если одна партиция выходит из строя у нас ли какой-то влияние на пользователей что в этот момент вы делаете сами партийцы у нас реализованы наши очереди которые в принципе отказа устойчивая она тоже 3 реплики содержит и она не должна отказывать если конечно все три реплики откажут Ну такое произойдет Но конечно вот эти пользователи которые должны работать они не сможем записать события и клиент который отправляется сообщение он получит ошибку Извините сообщение Но это для этого должно произойти что-то очень страшное за последние годы у нас Понятное дело и происходит аварии центрах обычно это отказывает одна реплика не бывает такого чтобы более двух реплик Если произойдет мы получим ошибку Спасибо тебе отправить А еще один вопрос по поводу толстых клиентов Клиенты у вас разные и получается и веб и мобилки и все прочие они все по одному принципу устроены Да сами короче один общий протокол прямо полностью и наваги на мобилках Ну Единственное что на мобилках понятно это мобильное приложение но протокол вообще Спасибо Здесь вопрос Привет Спасибо за доклад А можешь пожалуйста вернуть 82 слайд сейчас вернем получается что у вас есть две базы в одной вы сохраняете ну актуальное состояние чатов и сообщений а в другой инкрементальные изменения но у вас есть какой-то Ну распределенная транзакция или как вы Ну поддерживаете атомарность когда да на самом деле Да тут ну как бы не Инструментальная немножко изменить там сообщение нет самих да то есть счетчики всякие Если произойдет какая-то ошибка то есть мы например записали транзакцию во-первых Нет сразу скажу то есть если мы пытаемся записали в базу и что и не смогли записать в базу истории также кидается ошибка клиенту клиент при попытке он еще раз запишет это сообщение но сообщение оно уже просто еще раз записывается поверх своего и он еще раз попытается сохранить историю то есть и это будет повторяться постоянно клиентам пока не починиться и нормально Привет Спасибо за доклад по поводу вопрос по поводу Почему мы один Марк отправляем квадратичной зависимости каждый пользователь должен получить rootmark о том что кто-то что-то прочитал Но это линейное А и каждый прочитает каждый прочитает и каждому отправит что он прочитал да да так здесь Да Андрей Спасибо за доклад Насколько помню discord тоже использовал кассандру потом они перешли на сцену диби у них были проблемы с кассандре по моему вплоть до того что у них чтение было дороже чем запись у вас кассандрой проблем никаких нет я думаю что я читал статью Я думаю что у них Проблема была как раз в том что они читают они пишут про свой протокол скорее всего Они читают сообщения слишком часто Вот например как я рассказывал как у нас был устроен до этого клиент протокол Да мы на каждый пушек пробовали еще раз прочитать и это приводило к большому количеству чтений и в таком случае да конечно будут проблемы чтения когда идут много вопросов на одну партицию конкретно там спасают каши вот поэтому и ребята из города там какие-то умудрили еще что-то в нашем случае у нас нет такого количества чтений в основном оно Когда происходит когда клиент ходит на сайт Messenger Он зашел хорошо прочитал а все дальнейшее изменение у него происходит по пушам он не делает запросов базу в базу получается происходит запись и пушиком это сообщение прописывается всем участникам то есть единственный момент когда происходит серьезная нагрузка это когда популярный канал приходит какой-то пушек мобильный и клиенту вагинется попрошу и высчитывают Но это происходит разовый во-вторых они не одновременно это делают после приходят это немножко размазывается по времени самое плохое когда вот по нашему соединению ходят если в этот момент пробовать делать запрос будут проблемы потому что это реально очень Одновременно по-настоящему одновременно происходит у нас такого нет вообще и я думаю что у них в этом проблема была и они решали пытались решить на уровне кэнда они Это моя догадка У нас в общем проблем нет Все отлично работает у нас тоже есть пиши потому что как раз для загрузки первого вот этого списка сообщений мы используем пришли чтобы не проваливались на диск и Ну это хорошо справляется а можно мне вопрос я вот насчет 100 одновременно тянуть чаты истории не совсем понял и 300 потоков это все истории вы решали её архивными чатами архивными базами поиском Вот это они сами понял А в каком кейсе нам нужно сотку тянуть ведь например Открой приложение с истории групповых чатов тоже телеги у меня максимум но они считают переписки шесть а сотка О каком кейсиме нужно сотка Я не понял первый самый Да мой вариант когда я рассмотрю Да вот зачем 100 тянуть сразу 100 а кажется да это я бы хотел рассмотреть нам же надо достать список всех чатов Это я рассматривал вариант если у нас тут сообщение есть а мы хотим сформировать Нет просто сообщения а список чатов А зачем вот ну юзеру надо всего лишь четыре вот видно максимум Зачем сотка чатов видно больше чем четыре там около десяти видно Вот как раз в этом весь нюанс ведь это 10 чатов в каждом чате может быть много сообщений если они по времени отсортированы в индексе Например я могу Прочитав 100 сообщений прочитать только все сообщения из первого чата которые сверху например там много сообщений Я не прочту другие части меня может быть тысячи сообщений в чате в самом верху чатик висит и у него там последних может быть тысячи сообщений и если я прочитаю 100 сообщений я только этот я не смогу другие чаты прочитать я понял спасибо и вы архивной Базы Да решали вот это как показано складе с архивными базами Да это решили такую проблему Когда нет с архивом Это уже другая немножко проблема Да это мы же выделились сообщений вот отдельная чатике То есть у нас все сообщения хранятся отдельно чаты именно с последним вот этот список который мы видим он хранится отдельно да и его Да мы как разделили на активный активный Потому что если ты листаешь список ты конечно потихонечку будешь листать вниз и перейдёшь и начнётся архивные листать но основные вопросы они связаны неслистанием а именно с изменениями которые ходят туда-обратно то есть инкремент ингримитирует счётчики перед марки сбрасывают и они как раз все происходят именно в этом активном списке маленьком хорошо спасибо большое зала и на этом наверное надо будет заканчивать вопрос я здесь вопрос такой как раз пока Какой ключ арбирования для Кассандры в случае групповых чатов интересуются Какой ключ Ну смотрите я сказал Да что там два две диски а далее У нас используется берется хеш-код от этого всего то есть и берется уже по ходу мы сортируем пошло Спасибо Андрей вопрос кто кто получает при за лучший вопрос много было хороших вопросов но я запомнил про транзакции Да Пожалуйста поднимите руку Да несем книжку есть отлично Да у нас есть подарок Спасибо Вы тоже можете подойти на стенд на стенд подойти вам там дадут подарочек прошу также на самом деле прошу спикеры сразу не убегать где-нибудь снаружи зала там стоять чтобы Те кто не успел задать вопрос Могли пообщаться возможно Андрей будет найти и тоже скорее всего Спасибо"
}