{
  "video_id": "7-uGFO9Rcc4",
  "channel": "HighLoadChannel",
  "title": "Яндекс.Метрика и нестандартный ClickHouse / Александр Макаров (Яндекс)",
  "views": 1495,
  "duration": 3301,
  "published": "2019-05-15T03:56:42-07:00",
  "text": "меня зовут александр макаров я работ и мой доклад сегодня называется яндекс метрика и нестандартный клик house ну как всегда начну с небольшой саморекламы яндекс метрика это одна из лидирующих систем веб-аналитики мы 3 популярно популярности сервис аналитики в мире и в россии мы конечно же первые объемы тех данных которые мы обрабатываем чтобы вы понимали это наша принимающий сервера держит нагрузку в 80000 рпс пиковые моменты даже и больше бывает мы обрабатываем более даже 80 миллиардов событий в сутки и 90 процент для сто восемь процентов этих событий мы обрабатываем не более чем за пять минут то есть за пять минут или еще даже быстрее минутка саморекламы закончены чтобы было ясно каким образом мы связаны с клик хаосом как и когда наше сотрудничество началось я немножко расскажу об истории и в 2009 году появилась метрика 10 тогда был модный подход такой так называемые предок легированные данные то есть у нас есть заранее уже созданные отчеты эти отчеты они как бы фиксированы прибиты гвоздями их по сути менять нельзя у нас для каждого отчета заводится своей табличка туда приезжают данные мы их туда складываем пользователей то видит все хорошо ну как бы время шло становилось понятно что нам тоже нужно куда-то двигаться и поэтому хотелось сделать уже что-то такое красивенькая гибкая чтобы пользователь сам мог выбирать то что он хочет видеть чтоб он мог строить графики чтобы он мог фильтры какие-то применять мы понятно что текущая система под эти хотелки ну прям совсем была не готова нужно было что-то делать и понятно что в первую очередь все упиралось в субботу был ряд требований выдвинут что нам нужно то есть нам нужны были быстрые запрос и нам нужно было чтобы эта система была отказывал стоит чтобы она могла хранить большие объемы данных чтоб можно было в реал тайме в нее вставляете вот тут тут же это прямо было видно что вот она вставилась хотелось также еще чтобы был достаточно гибкий и хотела сискель подобный запрос язык запросов ну и вот так вот еще давно в 2015 году появилась метрика 20 это было метрика вокруг клик хауса клик хаус стал именно той суде которая удовлетворяла всем этим требованиям и и которые мы воспользовались в результате получается что вот мы уже три года уже даже чуть больше работаем вместе с килька усам за это время мы собрали ряд интересных моментов о которых хотелось бы сказать это не совсем те моменты которые вот то для чего клик house сделаем это не совсем такие классические из кейса клик хауса но между прочим это это очень очень полезные вещи это рабочие схемы у нас это работает это быстро это надежно и хотела бы вам об этом рассказать вот три пункта на которых мы подробно остановимся это как мы организовали вычислительного боковых клик хауса это как мы считали тайминги вставок и как мы организовали поверх клика us a key value хранилище ну для начала я вкратце обрисую как у нас выглядит движок метрики чтобы примерно понимали хотя бы о чем речь у нас приезжают на принимающие сервера приезжают события мы эти события записываем местах брокер после чего вот в промежуточные результаты считываются из этого места чп брокера обрабатываются опять же промежуточные результаты этой обработки тоже сохраняются и готовы уже результаты потом записываются в клик house стараясь на эти промежуточные результаты должны где-то жить мы решили что почему бы их не поселить вычислительное облака вот собственно так мы и пришли к первому пункту нашу программу касаюсь в чем не типичность подхода обычно что такое клик house как используется это вот такое большое хранилище туда пишем вот логи и потом там какие-то отчёты строем ходим смотрим select и тут же немножко другой принцип тут мы и небольшие порции данных записываем храним а потом считываем когда нам это нужно и то есть скрипка в каком-то смысле это реально хранилище промежуточных результатов общая иерархия примерно так все вот облака оно разбивается на шарды ну понятно шкалирование это распространенная техника все так делают куда ж без этого сорта этой группы серверов желательно из разных dc мы стараемся их разносить об этом позже поговорю соответственно на каждом сервере крутится крутится несколько демонов обработчиков обработка у нас конвейерная то есть каждый демон берет порцию данных обрабатывает и записывает и и и на каждом сервере еще стоит instance калек хауса как я уже сказал все данные мы обрабатываем порциями мы их называем чанки соответственно эти порции данных ну по сути это почивай обработка тоже это теперь известная техника там все ею пользуются по сути собственно чанг это вот группа событий примерно 100 200 тысяч в среднем включаюсь это они хранятся в табличках с типом старой плохо ли то и не лог это как раз вот идеально подходит для этих целей и они вот созданы друг для друга что называется эти движки и бачка обработка выглядит вот это примерно так ну понятно что если у нас демон на одном шарды в рамках одного шарда может работать только один instance демона соответственно если на первом серый он работает он на остальных серверах он простаивает и длится от на всех серверах есть клик house внутри вот этих клик house of они между собой очень сильно похожи в рамках одного шарда и внутреннего все разбито на базы данных каждого каждая база данных соответствует своему типу влога то есть это тип входных событий для какого-то из диванов обработчиков ну или выходных для предыдущего в конвейере соответственно и внутренних сгруппированы чанки чанки у нас лежат в клик хаосе соответственно нужно как-то еще хранить информацию метаданные какие-то них этого и и полезные нужно соответственно река und request это буквально калька с английского запрос на пересчет это для демона служит неким ходом он говорит ну хранит эту информацию о танках как допустим тепло га минимальное время события максимальное время события в чанки говорит сколько мы строк в чанки имеем ну и где он лежит то есть хост база данных табличка рикон 3 класс ты живут в сути период внуки пиритом и иерархической древовидной туда система поэтому все очень просто мы выбираем какую-то базового но до в которой говорим что вот все и аккаунт request и будут лежать вот отступает этой ноды вот в ее потомках соответственно мы заводим но для шар дав мы их внутри именуем слоями но ты заводим также еще внутри для демонов ну и соответственно когда мы прошли этот путь мы гарантированно пришли к нужному шар ду к нужному демону и значит все река unde3 квесты которые есть в этой ноте все child потомки они собственно это рикон три кости которые нужно обработать демон берет считает и тире кантри квесты из-за кипера после чего с вот здесь и реализованный ли кантри квестом он идет в менеджер облака это некая сущность и мы на нее очень подробно остановимся чуть позже соответственно он говорит менеджер облака вот река und request выдай мне пожалуйста соединение с кликал сам он возвращает после чего мы эти данные из этого соединения зачитываем обрабатываем что-то там с ними делаем после этого очевидно записываем ну и записываем опять же через менеджер облака после этого мы вот ключевой момент тренд транзакционному удаляем старые рикон 3 класса который только что обработали и создаем новое почему это важно потому что чтобы не было публикации данных с одной стороны и чтобы это было отказоустойчивых с другой то есть чтобы мы и ничего не теряли и в то же время дважды данные не записывали и не обрабатывали ну после этого мы идем на новую итерацию наша песня хороша начинаешь сначала вот собственно я заговорила менеджер облака и теперь мы на нем остановимся подробно у него есть ряд функций одна из них это поддержание информации о состоянии о состоянии всех машинок в облаке там каждые пять секунд пингуется клик house считается через забит лота в г средняя загрузка машинок вот на основании этого позже расскажу как будет производиться балансировка ну так же мы храним динамический пул соединений ик хаосом на каждом сервере менеджер облака он также разбивает сервера на группы и каждая группа ставится в соответствие слою то есть формирование она в общем то в каком смысле даже динамическое ну и так же как я уже говорил все дима напишу читают ну там также есть куча всяких полезных запросов как не знаю там попросить удалить какую-то табличку посмотреть есть ли табличка общем вот такой вот высокоуровневый интерфейс для работы с калика сколько у сам в облаке но все эти функции как функции чтения функции записи вот это все функции score него интерфейса они на самом деле упираются в такой важный вопрос как оптимально сервера особенно это критично для чтение то есть вот у нас есть список приоритетов ну понятно что в первую очередь мы если у нас сервер может быть активным может быть забанен им сервис становится забанены мысли произошли какие-то ошибки там при чтении при записи либо если почему-то отвалился прям вообще не пингуется никак кликов на этой машинке соответственно активно это все остальные как бы случае понятно что забаненные мы сразу отметаем они нас не интересуют ну следующий привет очевидно что проще и быстрее читать из локалхост а чем куда-то в удаленную машинку ходить сеть нагружать и все такое но и по времени тоже то медленнее будет вот ну конечно что для чтения критично это мы хотели выписать в текущей dc они в другой все-таки между 10 тысяч километров это в общем то заметно и также уж самая последняя проверка это у нас мы пытаемся разрешить запрос гдр с то есть из всех если по всем остальным критериям два сервера одинаковы мы на всякий случай проверяем резолвится ли имя dns аналог вкусный минус f если почему-то он валится проверяем host name если их устным провалил что считаем что тогда все запрос к dns упал соответственно как я уже говорил мы можем забанить сервера выходит из бана по таймауту сейчас у нас текущая настройка это одна минута ну понятно что если если машинка умерла то этот сервер выйдет или тут же обратно вернуться в банк если ошибки были и ошибки продолжатся он опять же вернется в бан но бывает такое что там почему-то по шаталась что-то как-то в результате было плохо мы забанили сервер прошла минута все восстановилось все в порядке в него спокойно можно из него читать в него можно писать поэтому он возвращается в строй вот мы поговорили про выбор оптимального это в каком-то смысле чтения это целиком выбор оптимального серая то есть как чтение происходит мы берем выбираем оптимальный сервер читаем из него отдаем это соединение запись у нас ведется немножко по другим принцип то есть там тоже выбираются оптимальные сервера но там учитывается следующий факт мы запись видео параллельно на сразу много серверов это много передаем запросе мы всегда пишем когда демон просят записать данные он говорит запиши ко мне на рипли creation фактор серверов это для чего это нужно ну понятно что во первых при записи могут произойти ошибки во вторых мы хотим дублировать данные чтобы это все было отказывал стоящего сервера понятно выбираются в рамках одной группы потому что ну как бы вся обработка она локальная мы хотим это все как можно больше локализовать обработку и в результате мы получаем что-то работает очень быстро потому что это работает параллельно у нас код на си плюс плюс поэтому мы используем клик х устные нативные протоколы вот и это очень отказоустойчивого получается мы также еще пытаемся писать в разные dc и тут я на этом заострю внимание мы очень часто говорим про отказоустойчивость и обычно отказоустойчивость мы считаем типа ну вот у нас есть одна машинка есть вторая машинка ну и там где-нибудь рядом еще 3 замечательно все отказа устойчива на самом деле нет в реальном мире случаются чудеса допустим у вас есть один дата-центр приезжает excavator и выкапывает кабель а вы говорите ну ладно у нас там есть еще и запасной дата-центр с ним то все будет и внезапно через пару часов абсолютно другой excavator приезжает в абсолютно другой to the center находясь за тысячи километров от 1 этаже выкапывается кабель туда это действительно был такой случай и вот собственно именно в эти моменты мы понимаем что ох как хорошо что у нас несколько дата-центров и мы это говорим про отказоустойчивость не только абстрактно но и также в терминах датацентров при записи мы также у нас есть некая терпимость к ошибкам то есть у нас есть некий порог если при записи количество ошибок вот на некоторые сервера не превысила этого порога то мы считаем что запись прошла успешно иначе же мы говорим что все плохо зато типа запись прошло неуспешно мы ничего не записали вот теперь перейдем к такому достаточно важному моменту как алонси ровка облака как я уже говорил мы раз в 5 секунд считаем нагрузку нагрузку считаем через get low tvg после чего у нас есть список серверов список их лей есть просто выбираем сервер с минимальной малый но в случае с текущей конфигурации мы это делаем для группы то есть в группе выбираем сервер с минимальным аллей после чего смотрим если перебираемся остальные сервера если выполняется вот это условие то есть с одной стороны загрузка чем больше чем чем загрузка просто его ющего умножить на некую константу и больше чем чем загрузка плюс некая константа если удовлетворяют оба эти условия мы считаемся что сервер перегружен ну примерно понятно откуда растут ноги у такой формулы с одной стороны но мы хотим считать что если у нас одна машинка нагружена больше чем условно простаивающие вы несколько раз это как бы естественно подсчет хотите считать это критериям вот но в то же время бывает ситуация что у вас очень маленькая загрузка и тогда получается что не знаю там на одном сервере будет загрузка на еду один а на другом три это совсем не значит что сервер где три перегружена поэтому нужно еще ввести не кид flash фолд который будет показывать что на самом деле еще и калечит то есть не только относительно но и в абсолютных значениях потенциально перегруженный сервер действительно перегружен ну соответственно после этого мы просто если сервер призван перегруженным мы сгоняем с него диман обработчики по одному до тех пор пока его ну вот потенциальный лей который мы насчитываем после этого не сравняется с со средним в группе несмотря на кажущуюся такую простоту и может даже в упорной схемы оно очень эффективно работает и действительно прям прям видно как она вот если случаются просадки а но тут же этот сервер убирает ее тут же разъезжаются дима на и все снова становится хорошо вот ну ну понятно что в первую очередь вычислительного лака это удобно у вас есть клик house вы в него уже пишите вы с ним уже пользуетесь соответственно он где-то нужно хранить промежуточные данные поэтому почему бы их не хранить уже в клик хаусе вот помимо этого вот организация которая горела с помощью менеджера облака организация вообще группы шардена в первую очередь отказывал устойчиво она предоставляет вот менеджер облака предоставляет единый интерфейс для доступа к данным и это как бы внутренняя библиотечка в потом ею пользуетесь везде вам нужно прочитать нужно записать вы пользуетесь этой библиотечка вы не изобретаете велосипеды когда новые обработчики создаете мы умеем балансировать нагрузку и как вы заметили в общем-то численные характеристики они нигде не присутствуют то есть все то о чем я говорил это очень масштабируема штука то есть у нас даже поставки на с тем что нам нужно было добавить серверов это вычислительное облака мы их просто взяли и добавили изменив конфигурационные файлы там подкрутив пару констант и все причем подкрутка констант происходило но совсем в легком режиме то есть это это не было там каким-то аврала миша и все заработало из коробки больше ничего менять не пришлось по-моему это реально здорово вот но в общем ладно мы погорели вычислительном облаке вот у нас есть эта замечательная облака вот она вставляет в клика us все хорошо теперь хочется понимать а сколько времени занимаются собственно обработка хочется считать именно то когда именно вот просто тайминг этой вставки то есть сколько времени проходит у событие даже хочется не просто это как-то абстрактно считать хоть какие-то там квантили мерить графики строить вот ну понятно что для одного события эта задача вполне себе решаемая то есть мы взяли событие мы там как-то его отметили после чего мы pingu им кликов смотрим там условно появилась ли это событие в клика уже появилась мы говорим о лувра вот обработалось ну это как бы замечательно для одного события но это абсолютно не масштабируемая история и разговаривать об этом смысла в общем то наверное нету можно было бы пользоваться какой-нибудь клика устной фишкой хотите функций в клик хаусе но включалась такой функции нет и и вообще сложно сделать потому что там есть реплицирует таблицы движки реплицирует и они отправляют по сети блоки не понятно что считать именно моментом ставьте в общем там куча сложности если я неправ лёша меня поправит вот ну в общем на стороне кликал со это это сделать прям реально сложные даже местами и не совсем ясно как это выглядит должно ну получается что нужно что-то сверху клик хауса прикручивать вот ну понятно что плохое решение прям совсем плохое это брать какой-то какую-то временную отметку говорить что а давайте-ка мы в клик хаусе посчитаем максимальное значение этой временной отметке и считаем слот отставание это на a минус значение отметки бы понятно почему это плохо это абсолютно не масштабируемая история то есть она вообще ничего вам не говорит в этом это можно конечно же делать ни один запрос много ну понятно что это опять же будет не точная картина неполная и это нужно еще думать о сколько нужно взять чтобы балка чтобы выборка было представительной в общем это какая-то совсем очень мутная история и так лучше не делать вот что предлагаем мы предлагаем решение получше ну вот у нас есть метка прихода события в яндекс метрику будем называть эту метку rt листьев time stamp ну понятно unix timestamp который вот показывает когда мы на принимающих серверах вот тех самых которые 800 крп с держат когда вот это событие туда попала мы так умеем понятно после чего мы выбираем вот некую дельту пусть вот это будет дельта 1 минута мы идем в crack house и смотрим сколько событий у которых time's темп в относительных интервалах по одной минуте лежит сейчас в клик хаосе ну то есть вот мы считаем сколько количество вот для определенности что прям было наглядно больше штат в 14:00 и мы делаем этот запрос вот мы смотрим сколько событий пришли на принимающей сервера там в 1359 тире 1400 сколько пришли в 1350 8-13 59 и так далее в прошлое на обозримое какой-то то есть ну допустим до двух часов например вот это примерно делается вот таким вот запросам он достаточно понятный но самое интересное что из него можно в нем можно отметить это каунт iv это такое то есть это аккаунт и сверху у него специальный комбинатор вот и в комбинатор это вот из документации по клику алсу цитата он приписывается ко всем агрегатным функциям и тогда агрегатные функции считаются для только для тех строк которые удовлетворяют условию которое ну вот передается эти параметрам вот если же условие общине разу не сработала то возвращается некое значение по умолчанию вот значит этот запрос у нас отработал вот у нас вот такие вот одна строка в этой таблице будем считать что заполнена дальше мы через будем считать для простоты что ровно через одну минуту то есть через ту же самую дельту повторяем этот запрос только теперь мы из полученных в этом запросе значений вычитаем значения которые были получены в предыдущем запросе за этот временной интервал получается как будто бы мы если про таблицу речь вычитаем значения слева сверху ну то есть у нас было and событий там со 14 до 13 5059 и да теперь у нас 1350 9 до 14 м событий пришло на принимающая сервера ну и соответственно несколько усе появилось м событий и вот эта вот разница означает что за вот эту вот минуту которая прошла с 14 до 14 0 1 к нам попала вот ровно столько событий которые вот в соответствующий интервал пришли на премию пришли на принимающие сервера то есть получается что мы знаем события которые записались в клик house за последнюю минуту и обработка которых занимало соответствующие столбцу количеству минут таким образом мы уже можем говорить о том что к нам за последнюю минуту пришли н событий из них там за одну минуту там такой-то процент за две минуты одну минуту обрабатывался такой-то процент 2 минуты обрабатывался такой-то процент и так далее таким образом если ну вот менять дельта если менять периодичность мы получаем просто достаточно подробные графики и значения того как у нас происходит что у нас происходит какое время у нас события обрабатываются в облаке и сколько сколько времени проходит между тем как как события пришли на принимающей сервера и из ставились в клик house поэтому можно строить разные графики вот например один и из дашбордов вот тут наверное не очень хорошо все таки видно но я поясню вот эти вот разные линии это 50-процентный квантиль 90 процентной квантиль 99 процентный квантиль по оси y у нас секунды которые прошли вот с того самого времени получения принимающим сервером события а по оси y время замера то есть в точка на графике это квантиль в какой промежуток по времени уложилась 50 процентов событий которые к нам пришли ну и соответственно это для 50 процентов а квантили я для 90 процентов но квантили это тоже самое только понятно чаю вот но соответственно с этим все с ставку считать умеем смотреть сколько у нас обрабатываются в облаке события и теперь такое очень полезное применение коллег хаоса как key value хранилище когда эта задача возникает ну вот на самом деле предыдущий докладчик рассказывала примерно похожих и успей сах когда нужно немножко другие вещи считать не совсем те которые обычно вы смотрите то есть например нам хочется для пользователей знать с каких устройств а не заходил то есть хранить локаль хранить ось хранить географию какую-то ну например хранить посещение или там в случае с от метрика кричит установок приложения понятно чтобы получать эти данные из текущих ну вот широких таблицы вот этих наших нам нужно по сути select там чуть ли не за всю историю то есть если мы хотим что-то специфичная для какого-то именно клиента глянуть типа какая у него ось была нам нужно просто выборку всего смотреть и это не очень удобное и не очень даже хорошо так делать вот соответственно что предлагается предлагается организовать отдельные хранилище для вот таких вот вещей ну значение которое нас интересует они в общем то бывают двух типов глобально одни типы это категориальные ну вот как я грязненькие системные сведения это допустим там регион там допустим локаль ну и какой нибудь суд м интересы то есть это что то что может быть только одно и со временем она либо меняется то есть обновляется либо наоборот обновлять мы игнорируем об этом чуть позже поговорим и второй большой тип это числовые всякие характеристики ну вот например количество визитов количество установок приложения количество покупок она в общем то то есть понятно что она со временем увеличивается ануса нос суммируется приходит новая информация она как бы сверху доливается естественно как это организовать вот категориальное значение предлагается записать в таблицу с движком replacing мир 4 ну или реплики эти тому же зависимости от того как вы хотите это организовать он будет удобно будет смотреть на первичный ключ дублирующиеся он записи удаляет соответственно если вы передадите вот при вот этот третий был запрос собственно тут есть параметр как столбец с версией он не обязательный если вы его укажите то тогда он будет смотреть на вот этот вот столбец с версией и оставлять будет только те события у которых наибольшей версии собственно что и происходит ну допустим случаем с типом операционной системы у нас приезжает новая информация мы увеличиваем там счетчик версии на 1 и записываем новую информацию с новым значением после чего если мы хотим это прочитать мы тут нужно отметить что мы типа для чего мы делаем аргамак сун оживить клик house он сам все удаляет этот а до я но есть такая тонкая что мы не знаем когда именно он это удаляет то есть клик house в этом смысле он не будет хранить лишнего будет удалять ненужные записи это хранилище не будет разрастаться но проблема в том что все равно в определённый момент времени у вас может быть несколько записей с одним первичным ключом и с разной версии собственно чтобы прям сразу посчитать то что нужно нужно просто арк максом воспользоваться он вернет ровно то что ну нужно бывают иногда так сейчас немножко убежал вперед бывает такой случай когда нужно хранить первое вхождение то есть например у вас есть какой-то какие-то данные ну например дата первой установки приложения вы очевидно вы обновлять эти данные не будете соответственно что в этом случае делать в этом случае вы просто пишете какое-то значение версии а потом вставляете события со значением там меньшим чем эта чисел k вот и будет ровно также работать все на автомате будет подхватывается будет счастье ну и соответственно числовые значения это примерно тоже самое только тут мы хотим суммировать поэтому это сами нг мер 3 при слиянии клик house их будет две строчки объединяет одно и сумма значений из и значение в цифровых столбцах будут суммами соответствующих цифровых столбцов и строк not crazy ball выглядит примерно так cams это необязательный параметр его можно не указывать можно указывать если указать то он будет суммировать только эти колонки которые который вот указаны вот ну и чтение происходит точно так же ну возможно вы захотите воспользоваться каким-то там хитрым поэтому вам придется суммы фаток и достаточного сумма общем-то хватает вот ну таким образом это все пойдет на это все понятно работает быстро это у вас есть некое хранилище который не разрастается в тоже время это у вас текущая инфраструктура то есть у вас вот есть выходной кластеру прямо на нем селить и эти таблички и не нужно ничего придумывать вот но чтобы заключение сказать как я продемонстрировал у нас есть несколько полезных из кейсов один из них это вот хранения промежуточных результатов поверх этого мы отказывал стой чего и балансируем а и облака сделали можно с помощью и мингов вставки считать сколько мы обрабатываем в этом облаке но кроме этого у таймингов вставьте это вообще но бизнес показатель сам по себе очень важные и как бы и и мониторинг полезный при этом при всем то есть там профит с этого куча ну и соответственно если у вас какие-то простые данные вы хотите их хранит key value хранилище для них устроить это тоже несложно сделать с помощью клик хауса вот пример а это работает и выселить и прям там где у вас все остальное и все у вас хорошо ну что в заключение хотелось бы сказать что вот мы уже больше трех лет живым сколько у сам нам все нравится все работает все быстро и на самом деле не бойтесь экспериментировать также потому что иногда применение инструменты которые рады как делался для другого можно найти вполне себе очень полезное и нужное применение в том месте где никто не живёт спасибо за внимание вот собственно телеграм-чате клик хауса телеграм-чате к метрике есть ли вопросы какие-то да сейчас прошу прощения а можно питать ада и еще пока не забыл у нас есть памятные подарки для лучших вопросов поэтому вопрос записываются нет не совсем у нас есть выберите про записи промежуточных результатов или или вот конечных конечно хорошо нет мы не успешность проверяем мы проверяем время которое эти события обрабатывались то есть у нас вот события пришло на принимающей сервера там в два часа дня допустим да мы хотим знать сколько это событие обрабатывалась прежде чем она вставилась клик house я понял да они действительно мы тайминг этого не считаем мы просто ну то есть мы асинхронно запускаем запись если клик house сказал что все в порядке все поставилось то мы ему верим и считаем что действительно значит все поставилось соответственно мы смотрим ответ и всех серверов куда мы писали мы принимаем решение если ошибок вообще не возникало что чаще всего и происходит то значит понятно все хорошо если вдруг возникло несколько ошибок смотрим количество ошибок не превысила ли определённый порог но вот терпимость к ошибкам волос на если этот порог превышен то мы считаем что все вставки были неудачными и просто возвращаем ну вот в демон по сути мы возвращаем исключения шути по also реки у нас тут провалилась запись противном случае мы считаем что что запись успешно прошла поскольку мы знаем в какие сервера на самом деле она успешно прошла здесь на серверах куда провалилась вот запись мы их игнорируем и вот когда будет создан аккаунт request информация о танках где они лежат будет актуальная то есть не не все сервера в которой мы пытались писать о тех которые мы реально записали не утрачивает нет они не утрачиваются нет еще раз если у нас состоялась вот запись успешно то есть не превышен тот порог считается что запись состоялась и все как будет делать больше не нужно ничего создаем новые recall трико выезд удаляем старые идем на следующую итерацию вот это как бы успех в случае неуспеха считается что вот у нас ничего не вставилась поэтому все провал все плохо эту же самую операцию начинай сначала ну примерно так иногда оно происходит но у нас такая тонкость мы чанки при вставке у нас определенный способ их по именования то есть мы обычно используем там нить общей префикс для logo после чего мы вставляем там всякие временные метки после чего есть некое случайное число которое мы генерируем один раз самом начале потом прокидываем его дальше и вот это случайное число она очень часто нас то есть практически всегда она нас выручает у чанка имя получается фиксированном . если мы одни и те же данные обработали мы получили один и тот же это же тоже имя поэтому дублирование не будет мы удалим табличку да-а-а можно передать микрофон ребят а хорошо извините здравствуйте спасибо за доклад два вопроса первый немножко вот предыдущему относится вы сказали жду вас обрабатываются пересчет и в транзакциях насколько я сейчас понял это скорее не транзакция и dupont и дым патентной операции которые при повторе ну дают на выходе тот же результат они совсем транзакционных нам нужно в тот момент когда мы удаляем река und request из старой ну который мы только что обрабатывали и создаем новые для следующего демона в конвейере вот этот момент нам нужно либо одновременно удалить и создать либо вот не трогать вообще в этот момент рынок цион ность как раз таки нам нужно вот это тот момент рандомности звуки пера котором мы прям пользуемся хорошо и тогда второй вопрос вот replacing бирж 3 вы используете версию клик house требуют использовать версию каким образом у вас получается инкрементировать то есть вы там 100 мб используйте либо у вас где-то хранится в версия последняя которые вы записали для конкретной ну на самом деле для разных случаев разные мы ну по-моему в большинстве случаев используем просто вот время но иногда да мы используем все таки и версии и тогда пересчет их ну там нетривиальный то есть что-то типа мы сначала в таких случаях selective типа текущую максимальную версию потом вставляем следующий но это по моему очень редко то есть самому честно сейчас навскидку не скажу по моему где то что такое нужно было для чего-то ну вот все юз кейсы которые вот мне приходят к которой я вспоминаю с которыми сталкивался они все в общем то time с темпом покрываются спасибо вот с той стороны хотели давайте спасибо за доклад об искре пожалуйста ваш менеджер облака это можно закрыть к закрытой разработка либо есть опыт сигета нет в open source и нету это это наш код целиком наш код мы ну и он достаточно специфичен то есть его конечно же можно адаптировать под другие реалии в общем то легко ну мы об этом даже как-то не задумывались то есть это это исключительно наша там там весь код нами написан сути дела вы же компенсируете окрас этой разработки то что вас нет нормальной как кластеризации в приказе и то же самое цены ну это не совсем правда то есть скажем так мы это делаем для того чтоб все балансировать самим и не задумываться тем более что там есть такой тонкий момент как ну в общем шарди рование по сути динамическая то есть она у его условно можно считать статическим но не исключено что может в теории наступит такая ситуация когда почему то умрут все машинки принадлежащие одному шар ду ну теоретически такого исключать нельзя вот и в этот момент как раз таки о менеджер облака проведет полную перебалансировку и он перри разобьет на группы соответственно ничего плохого не произойдет то есть все данные останутся там же возможно разъедутся обработки по разным вот машинкам и в какой-то момент данные будут читаться не локально писаться считаться вот не локально будет возможно вот такой вот затуп но в целом никто не умрет и система продолжит работать и вот ключевое главное что данные не потеряются я понял спасибо еще вопрос вот эти вот временные метки которые вы пишите для ну там вы и считывание эксплуатационных всяких чтобы там сколько запись подавалась прочее вы это пишите прямо историческое хранилища либо вы где-то выкидываете там на этапе запись уже австрийское хранилища нет мы прям метки прокидываем на самого конца это бывает очень удобно иногда посмотреть бывают ситуации когда нужно посмотреть на некоторые такие вот я помню у меня недавно я сталкивался с тем что было сделано там некая новая функциональность нужно было она частично задевало старую нужно было сравнить в общем и как раз таки она завязывалась на определенное там время и нужно было как раз таки смотреть старт дейт то есть вот события а именно метку нам было важно именно метка прихода события на вот наши принимающая сервера и это даже однажды вот сработал то есть это это прям нужно то бывает очень полезно я спасибо и еще у вас возникают проблемы с раскатывание всей конфигурации то есть получается что у вас очень много клиентов которые висят музыки переправили да у нас вот звуки pir это прям такая точка которая этого он пока что держится но мы понимаем что ну это это вот сейчас в данной системе прям самая уязвимая . думать думали каких-то путях отхода так сказать ну не то чтобы прям думали но думали о том что можно уже подумать вот примерно как-то так конкретное решение уже от клиента и вот такого нет но уже заводились разговоры то что вот у нас тонкое место нужно бы как то я вот подумать что будет если вдруг однажды будет плохо спасибо добрый день спасибо за доклад такой вопрос если есть несколько наборов промежуточных данных собственно тоже используем промежуточным таблицы для промежуточных данных и потом большим-большим порядка нескольких десятков миллионов меж собой их до обрабатываем насколько плохо использовать join в кли хаусе или все-таки лучше вы делать на стороне у нас такое было мы даже активно join или скажем так до тех пор пока все идет хорошо в это место даже не замечаете но если вдруг внезапно у вас начинается какая-то вот прям тяжелая нагрузка ну такое случается вот история могу рассказать кучу там в под того что иногда наши клиенты неправильно используют данные плоды того что вот когда был чемпионат мира по футболу нам кто-то засылал каждые пять секунд просмотра видео отсылал события но понятно что когда смотришь футбольный матч который длится там 90 плюс минут сколько событий пришлет и сколько от людей вот в такие моменты мы понятно что несколько but all back off вот roi join и были одним из ботаников в результате мы пришли к выводу что нам выгоднее просто брик андре квесте хранить иметь один река und request на сразу несколько типов логов если нам нужно реально оба типа logo мы как раз аббас читаем и уже будем там ну мы знаем там внутри нее ключи joy на какие нам нужны мы будем уже внутри программно грубо говоря joy нити это будет то есть это вот мы сейчас перешли на вот такую схему ну понятно просто в какой-то момент тоже столкнуться с батл на небольшим в нагрузках тоже и вот стало про все таки отказаться от джона который вроде бы удобен или нет то есть лучше отказаться но мы отказались в результате здравствуй а спасибо за доклад вопрос такой вот вы сейчас рассказывали про движки для агрегации меньше 3 транзакционные движки при такой обработке постоянные постоянные заменены данных вставки обновление позволяют себе расти и деградировать как у вас с этим дела обстоят вы подчищаете дополнительно как угроз мозга с каким-то лаком или как а если речь идет в проводке value хранилища то их подчищать не нужно просто кликал всех подчищает сам а если речь идет про эффективность это очистки надо бы вроде тоже удаляет данные когда ты говоришь билет на самом деле нет клик house так не делает он если а вот и он в фоновом потоке magic ну вот на предыдущей лекции на предыдущих поклади как раз рассказывалось подробно как это делается на самом деле там ну начнем с того чтобы это можно просто мониторинг на месте смотреть сколько вот этих вот частей который part которые кусочки есть вот на самом деле эффективно поддерживается там 30 40 кусочков и и понятно что они чистятся ну достаточно быстрая не чистится по-честному то есть это не такое что я сделал вид что удалила на самом деле нет когда клика успеть он чистит прямо по честным поэтому ну по факту то реально эффективно то есть если вы в логах там клик house сервера читаете что вот он повернул там удалил значит это действительно удалилась и и памяти больше не вообще не занимает то есть нас устраивается производительность более чем с чистой совестью могу там одну строку хоть десять раз обновлять перезаписывать все будет хорошо в отличие от ну понятно что можно это делать с такой частотой что поплохеет кому угодно но в целом да это рабочая очень схема это вот это работает муки попробуем спасибо вот тут передайте пожалуйста микрофончик спасибо возможно я прослушал там было вас слайд где нарисована было на мошенник ли cause 2 демона эти демоны это инстанции пентхауза элита сторонний процент мнение и демоны это демоны обработчики инстинкте хауса и я подозреваю что вы говорите вот ну час я про кликаю попробовал по-быстрому вы наверное вот вот про вот эту картину нет это сервер который в облаке вот единицы грубо говоря рабочие это вот сервер что на сервере на сервере дивана обработчики крутятся свои процессы и также еще интинский хаоса поднят это как бы отдельный процесс они у вас там было что у вас есть менеджер облака и он позволяет записывать данные да но при этом он отдает connectionstring запись у вас происходит на в демон или все-таки в клик house или демонит демона вас записывать в пик house нет менеджер это не демон это некая такая библиотечка у нее есть определенная часть которая работает как демон который отвечать за балансировку вот и а запись этой это некий высокоуровневый интерфейс он просто как ну вот у нас в плюсах поэтому буду говорить типов терминах плюсов это это библиотечка это его подключаешь пользуешься интерфейсом интерфейс предоставляет запись но запись происходит очевидно честно то есть он внутри себя вот хранит именно вулкан экшенов он выбирает нужные connection и прям в них идет в них записывает клика устные на земные протоколы вот эти вот передачи тебе ремоут out put blockstream про них говорилось тоже на предыдущем докладе о соответственно вот это все вставляете честно вставляете честно смотрите там клика ус не ругнулся ли есть вот ни на что после чего уже сообщаете а сегодня подскажите а как подчищается данные вот когда recall кришны вы читали и записали старые именно как они вот да очень хороший вопрос у нас на самом деле и для этих целей служит демон это на самом деле в общем то стоило отметить потому что в кли хаусе и есть в систем требл есть такая волшебная колонка как modify кейдж time по-моему если что лишь поправит меня точнее и она говорит когда последний раз изменялась таблицами то есть случаями с такими вот одноразовыми по сути когда она была создана и поэтому можно сверху натянуть демона который будет ходить по вот так вот покликал сам смотреть искать там сильно устаревшие таблички их удалять потом у нас это организовано некоторые дивана подчищают сами за собой то есть каждый чанг это отдельная таблица создается да как я и говорил а вот ну да действительно не типичное использование клик хаоса но по сути это распределенная очередь которая через звуки пир сделано до загнул он почему просто не взяли готовы очередь танков например там ну вот парковку вопрос ожидаемый я правда не знаю что там сейчас но когда в свое время шли вот когда собственно все это создавалось вот я уже говорил несколько раз транзакционных нам важно то есть мы хотим одновременно удалить старые рикон 3 квесты создать новые от кафка вроде так не знаю как сейчас но вот в то время на тогда ты точно так неумело то есть она не умела трансакционного прочитать и записать то есть ты сначала прочитал говорит что все я прочитал а потом ты записываешь игре все записал и таким образом получается что если вот при записи произошел какой-то сбой то нужно хранить по сути стоит то есть чтобы данные вот не потерялись их нужно как-то хранить то есть поддерживать state стоит ли сделаны это очень интересно но на самом деле это очень больно у нас есть парочка stateless точнее стоит full демонов это прям боль поэтому мы за стоит лишь вот все вот эти вот дивана как вы заметили stateless они подают ничего плохого не происходит абсолютно все равно можно хоть как угодно шатать они поднимутся и пересчитают точно так же данные и точно также ставит не будет ни дублирование не проливки данных то есть вот это очень важный момент спасибо"
}