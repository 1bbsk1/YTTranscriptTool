{
  "video_id": "BqnQrl75CVQ",
  "channel": "HighLoadChannel",
  "title": "Опыт разработки, отладки и внедрения системы горячего резервирования торговой системы / С.Костанбаев",
  "views": 586,
  "duration": 3049,
  "published": "2018-08-16T03:49:51-07:00",
  "text": "здравствуйте меня зовут кастом боюсь сергей я работаю на московского и бедра вы наверное все видели голливудские фильмы где показывают нью-йоркскую фондовую биржу кучу людей что-то рут махают творится полный хаос но у нас такого никогда не были торги на московской бирже идут электронно изначально на текущий момент бирже обрабатывает десятки миллионов транзакций в день и обработка каждой транзакции ядром занимает 10 микросекунд любая секунда простое приводится к миллионам у потерям но тем не менее я сплю спокойно и мне этому помогает система горячего резервирования так не работает что-то не работает спасибо немного истории где-то с 2010 года появилось такое явление как high-frequency трейдинг или высокочастотная торговля и всего где то за два с половиной года на наши сервера увеличилась нагрузка в 140 раз и было необходимо как-то к этому адаптироваться на тот момент мы использовали так называемый мишин критика и шгпи супер дом серверы это относится к high-end сервером мы категории но уже на тот момент они были неконкурентоспособны по производительности и к тому же архитектура тех серверов по риск фактически была мертва вендор не предлагал никакого существенного обновления мы стали думать что же можно было выбрать посмотрели intel itanium это тоже high-end направлении но у него уже на тот момент практически не было никакого будущего посмотрели даже мэйнфрейм m-power и как ни странно обычный x86 оказался самым высокопроизводительным приняли решение переходить на обычные сервера во что это выливалось мишин трицикл сервера использовали и 4x операционную систему она пасек совместимы под достаточно просто было с мигрировать на red hat linux замена риск архитектурно x86 вылилось небольшие отличия соответственно это big data место little endian другая модель памяти но это минорное изменения но при переходе на обычной кому эти сервера мы теряем кое-что с аппаратной точки зрения все high-end сервера обеспечивают возможность горячей замены процессоров у них многократное дублирование контроллеров резервирования рамы это не просто контроль ошибки возникающие в памяти это непосредственно фактически raid-массив и из рам модули памяти где можно один спокойно вынуть заменить и все эти сервера позиционируют себя как зиру downtime можно все менять непосредственно в ходе работы естественно ничего этого не было всего этого аспекта на обычных серверах соответственно потребовалось программные решения в обеспечения надежности для чего мы все это делали схематично наше ядро можно как бы разделить на 3 уровне верхней это клиентский уровень где работают непосредственно брокеры клиенты все они взаимодействуют с серверами доступа сервер доступ и такой каширу ющий сервер который обрабатывает все информационные запросы локально допустим вы хотите узнать находится они сейчас торгуется сбербанк данный запрос направляется в сервер доступа но если вы ставите какой-нибудь приказ там я хочу купить акции газпрома то это идет уже на центральный сервер и данных серверов было по одному на рынку соответственно это было самое критическое звено непосредственно для них мы делали данную систему что мы хотели добиться во-первых переход на обычной к мульти серверов молодой что не менее надежно поэтому что мы заложили в основу это выход непосредственно самого сервера из строя возможно какие-то проблемы сетью проблема сетевой картой дальше данная система могла просто зависнуть и через некоторое время отвиснуть и все это было необходимо обеспечить чтобы система переключалось на резерв за минимальное время это за секунды желательно меньше главное чтобы ни в коем случае не было потерь обработанных транзакций то есть если мы что-то ответили пользователю что его запрос принят мы ни в коем случает они должны были потерять также все это должно быть абсолютно прозрачна для нашей инфраструктуры и клиенты не должны видеть никакие разрывы соединения и естественно не это не должно вносить никакую существенную задержку ну что задержка это критический фактор для бедра мы изначально не рассматривали такие вещи как двойные отказа да пусть у нас перестал работать сеть на одном сервере и завис основной сервер естественно не рассматривали ошибки softy так как это является входят тестирования и не рассматриваю неправильную работу железа что из себя представляло вот эта схема у нас есть главный сервер в которой нет непосредственно взаимодействует со слоем героев есть резервный сервер на которой будет реплицироваться транзакции и есть арбитр мы его называем гувернер который координирует переключение в ходе возникновении каких-либо проблем давайте посмотрим как происходит обработка транзакций а прилетает на главный сервер моментально реплицируется на backup при этом главный сервер обрабатывает ее и ожидает подтверждение от резервного сервера здесь мы не ждем выполнение транзакции на резервном сервере чтобы обеспечить минимальная задержка так как время гуляния по сети фактически соответствует времени выполнения тем самым мы не вносим как бы дополнительной задержке однако мы можем сверить состояние как у нас обработал главный сервер и резервный сервер только на предыдущие шаги то есть как обработалось текущая транзакция мы не знаем но это было вполне нормальное решение давайте посмотрим как происходит переключение вот наш главный сервер займа действий со своим битва iv есть связь рипли кации и проверка результатов дальше у нас возникает проблема на главном сервере известно битвы продолжает взаимодействовать срабатывают таймаут на резервном сервере он обращается к вернеру тот назначает ему роль главного сервера все битвы переключаются главный сервер ну дальше допустим каким-то либо причинам main все-таки а твистом блока это проблема с операционной системой у него также срабатывается внутренней тайм-аут так как он видишь у него не было никакого общения за определенное время с git вами он также обращаются к вернера my ига вернер его исключает из схемы и тем самым мы до конца как бы торговых периода работаем с одним сервером так как вероятность выхода из сервера достаточно низкое это вполне приемлемое решение достаточно простое не было никакой сложной логики просто тестировать в общем все хорошо честно поставили эксплуатацию но как говорится в теории все хорошо но на практике всегда что-то случается непредвиденное и мы с этим столкнулись первое время эксплуатации так случилось что на главному узле от транзакция у нас обработалось не успешно на резервном сервере обработалось успешным стали разбираться смотреть пологом в чем где у них разошлись показаниям оказалось что простая математическая операции вычисления экспоненты на главном сервере вообще дала отрицательный результат на резервном сервере было все отлично стало очень интересно как такое может быть естественно взяли да багира всевозможные дамбы стали искать какое могло быть отличия стали в одном месте нашли фактическим отличие было только в одном бите всё 2 регистре этот бит отвечает за округление то есть куда округлять при работе с вещественными числами либо вверх либо вниз либо tuner естественно напишем простую тестовую утилиту вычисление экспоненты и как оказалось здесь все было просто это в той версии red hat linux у которые мы использовали был баг работе с математической функции когда я выставлялся определенный бит округление все просто пишем view в red hat они делают патч почем сервера но остался один непонятный момент откуда вообще взялся этот бит то есть стали смотреть code откуда это могло вылезти из на за этот бит отвечает session ее функции в is it round и казалось бы что надо найти где-то у нас ошибку в коде возможно там есть какой-то рейс кондишен какой-то хитрые условия которые мне обратили изначально вниманию стали очень стали дальше искать ошибку честно попробовали все шло далеко можно провели логический анализ кода все функции которые используют округление их было совершенно немного попытались воспроизведи воспроизвести тот ту торговую сессию использовали разные компиляторы с разными опциями с используя статический анализ динамический анализ хоть что-то чтобы могло пролить какой-то свет в общем ничего не дало каких-либо результатов на что могло повлиять на эту ошибку стали думать а может это была вообще не программная ошибка может это было к это аппаратная ошибка например неправильно работал процесса соответственно нагружаем процессор тестами на нагрузку которую используется в high performance компьютере чтобы определить неисправность ноды это не дает в общем никаких результатов тогда стали думать может какая-то ошибка с памятью хотя все сервера используют е цеце память но она не защищает от многократных ошибок то есть если в одной ячейке случается много- битовая ошибка и и могут не зафиксировать это очень маловероятное событие но тем не менее мы нагрузили тестами памяти данный сервер естественно ничего не нашли тогда появилась третья казалось бы единственная верная теория это возникает высокоэнергетическая частица который попадает наш data center пробивает стенки корпус и подойти ответственно процессор и в вызывает залипание триггерные защелки непосредственно в том петти все это абсурдная теорию мы назвали nejtrino но на всякий случай мы этот сервер исключили из эксплуатации и стали думать калью нам доработать схему резервирования если будет что-то такое не совсем неприятно и мы ввели так называемые теплые резервы это асинхронные реплики они фактически получают тот же поток транзакций которые могут сразу находиться вообще говоря в разных дата-центрах но них нет активного взаимодействия то есть у них может быть некий лак по транзакциям что это нам дает ну допустим в данном случае у нас резервный сервер выходит из строя и вот этот форум сервера можно также сцепить в связку с главным сервером то есть это ворон переходит в backup и наша схема снова становится сцепленный мы находимся в горячем резерве и тем самым это можно будет вводить многократную ротацию и получается схема в общем-то не убиваемая в общем все хорошо протестировали ставим в эксплуатацию и выясняем что ошибка не только не ушла она стала появляться даже чаще и на разных серверах посчитали что средняя частота воспроизведения данные ошибки где-то полгода на сервер соответственно к вендору сильно не пойдешь потому что они требуют какой-то более конкретный прав стали думать что же может быть еще что мы изначально и упустили из анализа появилась теория может быть это проблема непосредственно в коррупционной системе также как и была ошибка с липси написали простенькую программу которая буквально выставляет вызывает функции в съезд раунд запоминает текущее состояние и делает это бесконечном цикле чтобы усугубить ситуацию делается это множестве потоков которые между собой конкурируют с на запустили такую утилиту и выяснили что это простая утилита очень хорошо ловит эту ситуацию залипание бита происходит где-то за пять минут активной работы соответственно пишем в support и на удивление это ошибка у них не воспроизводятся попробовали на некоторых наших серверов и действительно у нас тоже этой воспроизводится не на всех серверов то есть это вас пролетели столько на определенных процессами но так как на предложили решение заменить на более новые дрон за не напольную на поле новое ядро полностью решает проблему бизнес доволен в общем все довольно истинные причины не совсем очевидно но вот не так давно вышла статья на хабре называется как я нашел баг процессор intel skylake уже все очень похоже с чем мы столкнулись но тот человек довелось как бы более до логического конца и выдвинул теорию что было ошибкой микро ходе при обновлении я ядер фактически производителя также делают обновление микрокода то есть у нас могла быть та же самая ситуация в общем проблему мы решили но остался неприятный момент что же нам делать подобных ситуациях если мы один раз на это натолкнулись это может быть еще раз совершенно очевидно соответственно стали думать над улучшенной схемой резервирования на этот раз мы считаю что уже некому доверять нельзя сервера могут работать неправильно поэтому нужно мы же гитарное резервирование фактически когда у тебя есть либо два конкурса по которым нельзя определить направление то есть нужно иметь как минимум три и соответственно выбрать куда нам какой из них показывает правильным соответственно здесь уже необходимо обеспечение консенсуса и то ли вам и сложились на двойное отказы также данная схема должна быть не хуже предыдущей то есть обеспечивает максимальную живучесть то есть если классические схеме обеспечения концерту говоря facing потеряли более плане на сортиров мы уже не можем жить нам это вообще это неприемлемо мы должны жить максимально вплоть до самого последнего сервера любой простой это просто деньги естественно выбор должен быть максимально быстрым и взаимодействие по сети должна быть минимальна чтобы обеспечивает минимальную задержку соответственно посмотрели если вообще что-либо готовое в этом направлении да в общем то есть есть enterprise n и данных которая заявляет что у них есть похожее решение но во первых они все очень сложные все очень дорогие и время на изучение тоже требует очень много поэтому этот процесс нашел параллельно непосредственно с основной схему посмотрели какие есть алгоритмы обеспечения консенсусу на тот момент самый распространенный это показ на которой все так много ссылаются единственно его проблем он очень и очень сложной чтобы его разработан реально в нем разобраться это нужно потратить очень много времени у него очень много состояний его сложно описать сложно тестировать на тот момент еще не было готовый ранд такой публикации но тем не менее он свободным не очень подходит поэтому мы начали делать свое схемам так наша схема состоит из двух потоков обмена данными это поток репликации и непосредственно поток обеспечение консенсуса и публикации результатов что интересного в потоке репликации мы за ложились на те вещи что в общем-то это сообщение до резервного сервера может быть доставлена на нам нужно получить гарантию что она не было искажено поэтому мы ввели дополнительный контроль проверки в качестве контроля мы выбрали функцию сердце в основном потому что но есть аппарат на уже на текущих сервером работает очень быстро может считать до десятка до десятков миллионов транзакций в секунду и фактически это не вызывает никаких доплат дополнительные накладные расходы также мы провели провязали все наши транзакции в единую цепочку то есть контроль текущие транзакции закладывается на контроле предыдущий транзакций тем самым мы можем гарантировать у нас не нарушена последовательность не выпало какая-то промежуточная транзакция и у нас скарба обеспечивается исходная последовательность очень похожие технологии используются в блок шейных дальше что у нас есть с ответом по результатам исполнения каждой транзакции торговая система генерирует ответ клиентам этому произвольное число байтов там может быть ваша заявка поставлена такой-то номер столько ты сделок вы совершили какой-то ее номер единственная проблема что 300 байт пересылать допустим о высокоскоростными систем таким как infiniband это накладные расходы поэтому мы пересылаем не сам ответ а контроль от них также он пересылаем число измененных состояний допустим транзакция породила сделки и похода на совершила две сделки изменила цену акции по которой сейчас она тикает и вот список всех изменениях число изменение состояний также мы передаем общую статистику сколько данный сервер обработал транзакций и все это считается нажмем совпадать на всех репликах получается несколько десятков байт которые быстро отправить и быстро проверить не вносят дополнительных накладных расходов дальше мы кого производим сверху результатом если что-то отличается 100 соответственно данный сервер исключается давайте посмотрим как это все происходит во первых каждый сервер вмещает свою картину мира то как он видит других соответственно допустим у нас есть main он видит гарнера синхронного и асинхронного дальше он видит что второй сервер его тоже видит 100 вторая строчка таблицы и тем самым получается вот такая полная таблица не так допустим у нас на главный сервер пришла транзакция мы ее от реплицировали на 2 бэкапом тут две линии вверх и или не так называемый потока репликации нижней линии это поток обеспечение консенсусу то есть по нижней линии идут сообщение для обеспечения консенсуса и вернера есть только одна нижняя линия фактически поток транзакции он не анализирует допустим пришло следующее транзакция здесь мы видим что все сервера начали и выполнять статические зеленые линии то как бы логически исполнения с ее подхватили исполнении серы был один еще не получил малиновую транзакцию дальше он ее получает допустим сервер было два уже и и обработал кружочек соответственно он опубликовал результат который также разослал со всем серверам и у него включился тайм-аут то есть он анализирует ответ от всех серверов течение определенного тайма это нижняя синяя линия дальше допустим у нас main вышел из строя ну просто не отвечает известный сервер был один также обработал транзакцию приют публиковал результат сера было два уже было два закончился тайм-аут он получал ответ только от бы у один сервер от main он так и не дождался ответом понимает что-то пошло не так и инициирует обращение к вернером видим стрелочку вниз и га вернер переходят так называемое состояние выборов фактически они выборов есть у большинства алгоритмов обеспечения консенсуса дальше у сервера пу-1 также закончился тайм-аут он также пришел к вернеру за уточнением свои роли вернер еще ожидает некоторое время мы на может он к ним еще присоединится мог этого не происходит срабатывает таймаут на выборы он выбирает из тех свирлов которые к нему обратились есть два сервера он выбирает допустим было один назначает ему роль мейна было два подтверждает его текущую роль ига вернер переходят так называемую стадию подтверждения практически во всех алгоритмах типа автобакс и то есть превью и фактический к места одета так называемую превью стадия мы разослали я ожидаем чтобы все узлы подтвердили свои роли ну допустим в упрощенной схеме все сервера подтверждают свою роль вернер переходит в стадию комета и рассылает финальное подтверждение ролей если случился бы таймаут на кавер не ори и он не получил подтверждение от всех узлов то практически начались перевыборы все это и началось вот с началом после того как узлы подтвердили роль был один может опубликовать результат транзакции отправить результат клиенту зеленая стрелочкой вверх соответственно мы отправляем результат клиенты и здесь мы делается специально мы не отправляем результаты клиентом до тех пор пока мы не обеспечим что это действительно правильный результат он непротиворечивой так как если клиент получить какой то неправильно результат непонятно что делать с этим дальше ну и малиной транзакция также от работалось успешно соответственного уже два активных сервера они отправили ответы друг другу они поняли что все окей и также малиной транзакция отправляет результат клиентам здесь я просто ну допустим main у нас не полностью вышла строим а так сказать завис на некоторое время и потом отвис все сообщения с его точки зрения он также обработал транзакцию также положил сообщение в очередь на отправке у него сработал тайм-аут он также обратился к вернеру но ничего этого не произошло какое-то время допустим все эти восстановилась и все это разом полетела гувернером соответственно вопрос что в этом случае делать отвесно можно проанализировать как бы состояние узлов подумать как все это разрулить но все комбо классические схемы обеспечения консенсус собой так называемый термин поколение литер авантюрам допустим в рамки как в этом случае это выглядит у нас это так называется generation для удобства он представляется двумя цифрами в рафти это просто непрерывно увеличивающаяся счетчик то есть когда происходит выбор и когда завершились выборы мы его инкрементируем на каждый этап выборов мы как бы увеличиваем его так счетчик так сказать попыток сделать выбор и это удобнее с точки зрения анализа эксплуатации то есть мы видим сколько у нас было переключение если одно переключение занимал очень долго то есть это проще проанализировать понять что было там не так рассмотрим ещё один интересный случай допустим main получил транзакцию но начал ее исполнять но соответственно не было она не успела от реплицироваться на остальные сервера соответственно эту транзакцию уже никто не видит когда вернер назначил нового майна он стал принимать поток транзакции и он принял эту голубенькую яркон голубую транзакцию и получилась такая ситуация у нового мэйна транзакция номер 3 1 у старого мая на транзакция номер три совершенно другая и тут у нас как бы совершенно отличие от классических алгоритмов допустим враг те есть такое понятие как перезапись история то есть если бы мы работали непосредственно баров там того как бы данный сервер он должен был понять что у нас бы сменился лидер изменился лог истории откатить лук истории применить новый лог истории но непосредственно реализации это очень сложно и мы стараемся исполнять транзакции по мере их поступления чтобы обеспечить минимальную задержку и такие накладные расходы мы просто не можем себе позволить поэтому все те транзакции которые летят на серого начинает непосредственно непосредственно обрабатывать незамедлительно и если детектируется такая ситуация во первых она проверяется поясе rsi в потоке публикации которыми я говорил ли вторых это дополнительно проверяется гувернером то что если вдруг данный сервер поднялся он дает ему приказ выключится из кластер а и дальше он уже никак не задействован если необходимо как бы увеличивать число серверов то мы запускаем асинхронные сервера и также можно включить данную схему возникает вопрос а что будет если наш га вернер бы выпадет как его резервировать нужно или его резервировать на самом деле не является существенной проблемой во первых и вернер это стоит лось сервер его можно запускать любой момент времени он собирает состоянии от всех узлов системы тем самым не представляется проблемам но если пытаться это автоматизировать допустим зарезервировать governing то возникает больше проблем которое нам не очень хочется иметь например если вдруг сеть поделятся то как в этом случае быть соответственно 2 garnier уже недостаточно нужно 3 га вернера получать заводить говорит он обеспечение консенсуса то есть детская двойная схема оно очень сложное сложно тестировать сложно эксплуатировать поэтому мы пришли случае что арбитра не нужно дополнительно резервировать его можно просто перезапустить и систему мониторинга помещается фона есть да и самое важное когда у нас идет обмен транзакциями и нет никаких исключительных ситуаций нет тайм-аута у нас нет взаимодействия с георгием то есть если мы в процессе работы его выключим то весь кластер работает как и работала ничего не чувствует только когда случилась какая-то исключительная ситуация inservice и взаимодействие с боков то есть его можно спокойно погасить поднять процессе работы никаких особых проблем с этим не будет что еще важно вопрос про водку таймов наверное все знают что использовать так называемые реальное время в обработке таймаутов это не очень здорово то есть если допустим на севере поменялось дата или время то у вас функция ожидающие той молота может завершиться гораздо позже и либо гораздо раньше чем ожидалось в принципе в схемах обеспечения консенсуса найти есть закладки что это никак ее не рушит однако принятие решения при этом может отложиться на очень не определенное время соответственно это нам совершенно не подходит поэтому все-таки схему как правило использует клок муна тоник таймер однако он тоже не идеален на данный таймер влияет интере то есть любая коррекция времени она изменяет ход течение этого таймера если допустим применил сентябре на одном сервере но не применялся на другом сервере у вас изменился ход течение времени и тайм-аут и сработали неожиданно по-разному то есть как бы проблемы существенные здесь нет никакой но например для нас как бы это увеличение периода выборами это не здорово мы пытаемся обеспечить минимальную возможную задержку поэтому есть третий способ это так называемый клок моно тони кроу это как бы чистый х дверный таймер без всяких модификаций он идет идет на серверах чуть-чуть да по разному зависимости от точности часов но основная проблема у него это нет никаких вид функций то есть нельзя сказать я хочу продолжать там ровно 10 микросекунд поэтому таймеру то есть здесь нужно использовать программный полинг и ничего нет но в нашем случае это было единственное оптимальное решение мы можем попались но лучше лучше обеспечить чтобы не было увеличения задержки в обработке что еще можно сказать про тестирование разработали алгоритм понятно стает первый вопрос нужно ли его вообще говоря верифицировать мы соответственно начали его верифицировать по пытаясь описать модель на текущий момент модель полностью не написано это заняло гораздо больше времени чем мы планировали и в то же время как бы даже если мы до конца верифицируем модель не то совершенно не гарантирует то что наша система работает точно также как наш исходный алгоритм поэтому мы перешли непосредственно к самим тестом соответственно unit-тест они покрываются отлично случае когда у нас есть все эти переходы все выборы когда роли заранее определены они известны это отлично но еще существует ряд проблем что делать в реальной системе когда есть готовая система как как и и тестировать соответственно здесь мы используем всевозможная комбинация хилов sextape а все continue и кстати вот six topsy continue самая убийственная вещь когда вы притормаживайте фюрер дают ему работать снова притормаживайте снова даете работать может возникать много этапов выборов дальше мы делаем сетевые проблема соответственно у нас есть скрипты на и 5 бласс который эмулирует полное пропадание сети так называемое мигание сети то это прям часть времени мы придаем пакеты часть времени сети работает счастливы мне снова передаем тоже своего рода влияет и самое главное как протестировать то что сервера вдруг посчитали неправильно можно соответственно данное заложить в код но это не очень удобное решение мы пошли путем что сделали специальные gdb скрипты которые относятся к процессору и меняют определенные ячейки памяти тем самым и эмулируем как бы про такие аппаратные ошибки когда что-то в процессе пошло не так и смотрим как это влияет уже на выбор и естественно все это делать вручную очень неудобно поэтому у нас все высоко уровня и тесты по управлению кластером написанным на питоне есть как бы такие высокородные функцию из типов на заморозить убить сервер ввести проблему в сеть вести моргания сеть описано там набору множество тестов кейсов когда есть одиночная ошибка двойная ошибка все это выводится на тепловую карту и также все тесты визуализировать но к примеру визуализация одного из тестов то есть пошел поток транзакции далее мы приостановили выполнение там допустим six стопам остановили сервер произошли выборы видно что просела обработка транзакций потом этот сервис заново вцепилась в кластер а у него подскочила выполнение все эти события нумеруются внизу и так очень удобно анализировать все эти ситуации что еще было интересного как оказалось схему можно использовать даже не по назначению еще нескольких интересных случаях как ни странно это помогало находить ошибки ошибки такого рода кто-то забыл там и стоял rent функцию которая по разному отработал на серверах какой-то хитрый там неправильно инициализирован и и переменных дальше это помогло нам сделать так называемую возможности миграция между дата-центра ми-8 и имея теплое резервы мы могли постоянно переключать и как бы постепенно мигрировать всю схему с одного дата-центра на другой и еще одно интересное применение также с теплыми резервами мы могли их отключать и мы могли их отключать и соответственно выставлять новую версию тем самым получается как бы обновление на ходу детям и так таки можно сделать основные выводы во-первых неправильная работа железо операционной системы системных библиотек это вообще говоря не редкость на это как бы стоит учитывать этот фактор второе саму горячие резервирование это не лечение всех проблем это условно говоря вы имеете raid-массив но это не гарантирует что вы не потеряете все ваши данные также вам соответственно нужно иметь план на тот случай когда бы как не сработает и нужно его хорошо проработать понимать что делать когда что то идет не так чтобы не терять это время непосредственно в работе у меня на этом всё всем спасибо спасибо за доклад не могли бы пояснить как вы рассылаете транзакции на торговой сервера одновременно но у нас используется мультика шина данных поэтому содействие на моем пути к стиву группа они посетили передаются сразу на все сервера это какой мультик россию т.п. это и идей это наша реализация да и дипе multicast поверх ионного наворачивается алгоритм recovery то есть поедите multicast вы можете потерять какой-то пакет соответственно нужно еще дополнительная recovery потери покер это только часть проблемы да вот нарушение порядка да все это как бы решается вот с этим вот схемой еще подскажите как вы вводите в классе сервера под зоне ну то есть как у них нет начального состояния да вот давайте на сервер как у него получает смотрите есть несколько вариантов во первых на этих форм серверах у нас есть постоянная процедура чекпоинта мы постоянно генерируем чекпоинты когда необходимо загрузить новые серии мы берем check point стартуем из этого чекпоинта и дальше сервер подключается к этой связке с транзакций допустим м он понимать и минут даже нужно догнаться еще там сотню транзакции он получаете то транзакции по репликации фактически репликации the persistent storage он отыгрывает эти транзакции уже обращается гувернера говорит все включу включая меня в активную работу и им спасибо спасибо за доклад у меня такое я здесь у меня такой вопрос у вас какое количество теплых резервов и еще раз такой обработка у вас везде транзакции 1 поточная смотрите изначально обработка транзакция полотна по точной в текущей версии транзакция разбивается на так называемая этапная любую акцию можно представить типа это парсинг это проверка прав доступа это проверка торговой логике непосредственно исполнении вот эти все операции аннеси реализуются к потокам и каждая операция выполняется на своем ядре что касается пробором бэкапов и в принципе можно делать много но мы не делаем очень много то есть там порядке с 3 такого количества держим в активе если кто-то выходит из строя то соответственно мы уже просто включаем новые скрыть просто вы можете оценить что что хочет эффективность с точки зрения затрат что выгоднее использовать вот это про перед арно и решение от hp или вашу ваши решения видеопипл про какой просто денег с точки зрения денег то есть вот сколько вы могли там планеры все эпохи во первых когда покупаете проприетарное решение у вас нет стопроцентной гарантии что она полностью работает как надо то есть выставку это вкладываете время в освоении в тестировании то есть если бы мы использовали какой-нибудь энтерпрайз совершении уровня нам самого прошлось все все это тестирование с нуля но так как у нас есть теперь опыт непосредственно мы знаем что нужно смотреть то есть когда мы параллельно вели эмуляцию вот этих enterprise n у нас уже были рабочие кейсы мы как бы сразу знали что смотреть и у некоторых вендоров которые нам предлагали мы где-то минут за 5 вводили в plaster ли консистентные состоянию игры что нет это какой-то очень экзотические случаи но тем не менее этот критический случай это один из наших кейсов то есть для нас это был очень интересный опыт теперь мы как бы точно знаем что нужно как бы если будем даже что закупать в будущем мы точно знаем что нам нужно вы вернетесь системам где вот этого все резервирования делается на аппаратном уровне или на уровне где вы вообще не можете никак мне у воздействовать ну смотри любите ли вы следующие объемы очки там знаю spark oracle или еще что-нибудь или останетесь на community вопрос интересный тем не менее как бы даже вот это все аппаратные решение также не обеспечивает стопроцентной гарантии как бы однозначно ответить нельзя но даже выкладываю много денег us равно как бы не получает стопроцентные гарантии аппаратного решения чтобы пони смотрим в эту сторону сейчас понятно по деньгам вот насколько ваше решение дешевле либо дороже чем то что есть готовая это не может сказать я не могу сказать спасибо за доклад я слева вот можно диаграмму которую показывали слайдик какую именно временная диаграмма где там консенсус да вот синий транзакция 3 которая пришла на старой main жару в итоге случилось с точки зрения клиента он может повторить через какое-то время там летом прислать вам рекламацию данная транзакция она осталась на уровне gateway'ев оно исполнится повторно через некоторое время то есть то что он исполнил на майне он и результаты и никак не увидел и слой гид wave и исполнят повторно уже на другом сервере то есть для клиента это не выглядит как какая-та потеря просто данный транзакцию него обрабатывалась дольше чем обычно какой то и целые со стороны клиента есть что если мир и транзакцию не было там обработка в течение 30 секунды и можно слать повторно предыдущие гарантированно не будет обработано но с точки зрения слабое сейчас я не могу точно ответить на вопрос то есть такие тайм-аут и после определенного времени которого как бы сама он сам она сама наша плоть делает это автоматически как бы клиент отправляет и он на отыгрывается повторно если не получил никакого результата этим можно управлять как бы каждый клиент и настраиваю тайм-аут и по-своему допустим для роботов это естественный там минимальное тайм-аута если это рабочие места там с увеличенной тайм-аут и вот как-то общем эта схема не вызывала у вас прецедентов когда транзакцию стороны клиента дублировались нет она как бы применение транзакцией дома по тем то есть у каждого есть уникальный reference и если серый понимает он уже исполнил это транзак свои он ее не исполняет он просто отсылает к ширу ющий результат который у него хранится то есть целостность заключается в референсы который генерирует удары и понятном почти большой я здесь спасибо большое за доклад у меня такой вопрос скажите пожалуйста как отчисляется удержание collection от типичных между клиентом и сервером на момент когда пропадает основной сервер получает ли клиент в этот момент какие-то reject или cloth и и как осуществляется потом привязка допустим там backup новоселья на эту же здесь и здесь непосредственно клиентское соединение с типичной соединено останавливается с ги твоим а ветвей устанавливает соединение с главным узлом то есть при переключении главного узла с моей надо backup лет никак не видишь у нее что-то произошло после connection держится до сервера доступа он как бы отправил и просто в через некоторое время получил результат занимается совершенно прозрачная схема еще один вопрос 2 использует ли вы какие или планируете использовать каким-нибудь в пиджей матрицы либо какие-то такие вот решения для протоколов ну и там другая для парсинга sexual протоколов исполнения и так далее спасибо очень хороший вопрос такой интерес на самом деле да и пока матрица на первых используется но есть определенные ряд трудностей первых то что хорошо делать вас пугает а какие-то простые алгоритмы на текущий момент у нас очень такие по российские специфики не простые алгоритмы там оценки риска всевозможные режимы торгов в общем специфики столько что реализация это на испуга будет заменить занимать во первых очень много времени это требуется очень много времени на тестирования и в итоге это даст в тайну совершенно небольшой прирост производительности за со всей специфики то есть если было бы как эта простая математическая функция которая там занимает место процентов времени и и выяснить мега да тогда было бы какой-то эффект но у нас нет такой вот единого места вот именно что вот здесь вот тормозит здрасте я немного организационные два вопроса первое по поводу команды вот эту вот всю систему резервирования за батэ вал тоже команда что выполнял продуктовый фич или отдельно и второй вопрос по поводу от куда пришла вообще сама задача видео верования именно от заказчика или там менеджмента вот насколько вы согласовывали этот объем работ менеджмента есть кто и кто решал насколько качественно она должна быть другая достаточно личного видео верования там от двойного сбоя нужно защититься ну смотрите ну что говоря про команду то есть у нас есть несколько команд которые отвечают за разные направления пусть у нас есть команда которая занимается ядром и посвящено торговой системы там у нас люди как бы более имели динамически то есть они могут быть некие продуктовые фича которые непосредственно к торговому ядру относятся могут там некие такие транспортные вещи то есть это зависимости вот там big logo как мы распределимся естественно крут имеет компетенции больше в одном направлении кто-то больше в другом направлении но тем ни менее такого жесткого прямо что кто-то занимается резервированием кто-то только продуктовыми фичами такого наверное нет что касается как мы все это дело внедряли но сноу когда был переход с высоконадежных серверов естественное и бизнеса и уайти службы эксплуатации вызывали какие опасения как бы обычной команди сервера соответственно мы предлагали схемы было широкое муфтами обсуждении принимали соответствующее решение которое всех удовлетворяются добрый день у меня вопрос к вам когда вы толкнули инцидентом некорректно отработки процессор ных инструкторы вы привлекали к расследованию этой проблемы команда безопасности выясните что умеете виду здесь командой безопасности у меня такого как бы предварительно вопрос вот он тем что есть более реальный вопрос вы в курсе что в современных in таких процессорах на рим каменную при прошитая не давите мая операционную систему которой вы не имеете никакого дата по это realidad intel management engine а вот и аналогичный функционал я твоим душных процессорах кота и соответственно рассматривали ли вы вероятность того что это вмешательство снаружи помощью данного бот на этот на buy in the mind and then she на я понял вопрос этот режим называется smm мы активно сотрудничаем с часы hp по этому вопросу соответственно даже чтобы настроить сервер на работу с максимальной с минимальной задержкой необходимо кого-то включать все эти вещи потому что вот это вот smm которое возникает вот это менеджмент фриче они очень хорошо видны по задержкам то есть если происходит переключение на работу вот в эту операционную систему это уже десятки micros даже десятки сотни микросекунд задержек по сети переключение не очень хорошо видны мы активно работали с ментором уж во первых чтобы их минимизировать во вторых даже если они есть то утверждается с точки зрения intel они совершенно прозрачны то есть они не могут влиять на задай на контекст задачи основного то есть можно как бы менять память там еще чего-то но кабы контекст задачи непосредственно модифицировать нельзя ну думаю постарался хотя бы ответить таки да все всем спасибо"
}