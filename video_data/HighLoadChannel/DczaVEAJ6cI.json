{
  "video_id": "DczaVEAJ6cI",
  "channel": "HighLoadChannel",
  "title": "Как мы переписывали бизнес логику высоконагруженного приложения на PLPGSQL / Илья Колокутский (БФТ)",
  "views": 78,
  "duration": 2416,
  "published": "2023-10-06T07:21:02-07:00",
  "text": "Всем привет Меня зовут Илья колокоцкий и Сегодня я расскажу вам о нашем опыте как мы переписывали высоконагруженное приложение с oraco на постгрес Я работаю в компании бфт это крупный отечественный интегратор который занимается разработкой поддержкой продуктов для госсектора сам я технический архитектор уже более 10 лет работаю с базами данных и основная моя деятельность это работа с продуктивными системами перформанс тюнинг миграция интеграция и все что с этим связано немного проекте Расскажите поднимите пожалуйста руки кто хоть раз оформлял больничный себе круто круто рук даже много больше чем я ожидал айтишники обычно не болеют так вот на самом деле система которую мы мигрировали это система которая охватывает Там прям всех нас это социальная сфера это электронный листок не трудоспособности что это такое Это аналог обычного бумажного старого больничного который наверное тоже все видели чем он так хорош его очень просто контролировать меньше ошибок его нельзя подделать Ну и с ним не нужно никуда ходить достаточно просто сообщить своему работодателю номер больничного Также вы можете его посмотреть на портале госуслуг аудитория этой системы это 11 часовых поясов нашей страны и более 20 тысяч медицинских организаций немножечко цифр 2020 год 16 миллионов граждан в течение года оформили почти 40 миллионов электронных больничных в системе которая работала на базе oraco на базе хранимых процедур написанных на Пеле SQL 21 год пришел слон в виде пост и мы мигрировали систему срока на постгресс она начала работать системе начали оформлять еще больше больничных еще больше людей начали пользоваться этой системой 22 год аудитория растет количество оформляемых больничных растет пока я добирался сюда там возникла интересная мысль и цените сколько это 48 миллионов больничных в бумаге Ну если представить то это примерно пачка бумаги высотой 5 км суть проекта заключалась в том что мы должны были взять и просто поменять уроков на постгресс но система устроена была таким образом что в ней очень много бизнес логики написано Пеле SQL очень много почти сто процентов и просто так переписать наверное было нельзя почему это можно считать его во первых это огромное количество данных 30 терабайт Я считаю что это не так мало 100 тысяч строк или кода который было достаточно сложно переписать если оценивать в количестве в нагрузке наши сервисы это до 500 бизнесовых запросов в секунду подлетающих на сервисы и это в базе данных 8 плюс минус тысяч ежедневная система прирастает примерно на 40 Гб есть куча разнообразных интеграции написанных как вообще устроена система но в принципе те кто когда-либо пользовались ханинками наверное использовали что-то подобное то есть есть сервисы есть база данных в которой очень много хранимок вьюшечек Ну и прочего как все это работает в больнице врача есть рабочее место в котором он заполняет электронную форму в этой электронной форме он указывает все необходимые данные кому выдается больничный когда почему дальше все это упаковывается в xml подписывается шифруется и отправляется на наши сервисы на самих сервисах я Останавливаться не буду там все тоже очень непросто дешифрование сбор и так далее я становлюсь только на части связанные с базой данных устройство системы до и после То есть я уже говорил что до у нас было какого после у нас стал пост-гресс но это не простой пост гриз а пост газ Professional City Fight 11 версия пока мы мигрировали систему мы часть логики связанные с разбором xml которые там тоже присутствовали вынесли на уровень приложения И тем самым база чуть-чуть разгрузили интеграция ранее они были как я уже говорил написаны на db линках после миграции мы для интеграции использовали где-то пентаху где-то писали сервисы там с использованием высота 2 ранее не применялось никаких инструментов для того чтобы кот вообще версии анимировать то есть там были ручные обнов ручная подготовка скриптов и так далее Все кто с таким сталкивался знают какие у этого побочные эффекты бывают мы при миграции приняли ликви Base там для формирования релизов и автоматических диплоиев Ну и после переписывания у нас среднее время отклика системы улучшилась практически в 10 раз для заказчика было важно импортозамещение И в качестве импортозамещения здесь выступил после SQL чем он был так хорош это куча русскоязычной документации он плюс-минус похож на ракового Пеле SQL него открытый Исходный код Ну и если посмотреть то есть достаточно много докладов уже успешных миграциях ранее как я уже говорил мы использовали там ряд инструментов То есть это погресс ванильный пазгресс Professional ванильный мы использовали изначально для того чтобы вообще начать разработку и вообще стремились максимально использовать все возможности только в ванильной версии posgris мы использовали для того чтобы сократить себе количество ручной работы попереписыванию битбайки Джерри Бейс для того чтобы как-то контролировать проект pinka всо для интеграции джимметр Джинкс мы использовали для того чтобы провести тестирование наших сервисов нашей системы Ну и разработчики в основном использовали дебювет datagrip кому что было удобно но главный инструмент здесь все же это голова и руки следующий шаг это генерация кода я уже говорил что мы взяли эту педжи и попробовали при помощи вот эту пиджи как это рекомендуется перенести кот из уроков постггис шаг 1 это генерация Del таблиц индексов все почти классно то есть ортопеджи с этой задачей справляется на ура за некоторыми исключениями ворот ли у нас были селекционированные таблицы где-то был еще и саппортирован и В таких случаях стоит дополнительно обратить внимание на сгенериный код внести какие-то свои изменения также у нас ворот ли были отложены ограничения Ну от них там удалось отказаться были временные таблицы еще были хитрые функциональные индексы вообще на все это стоит обратить внимание после генерации кода нужно тщательно провести ревью следующий шаг это вьюшечке через которую у нас приложение получали данные из базы тут уже не так все прекрасно как с таблицами не так прекрасно потому что во вьюшечках были запрятаны достаточно хитрые запросы Если сравнивать Oracle и postgress то ворокли раньше достаточно часто не обращали внимание на неявные приведения типов можно было взять сказать там Джой одной таблице к другой таблице и допустим в одной таблице поля будет строковое в другое поле будет числовое около от съест и всё будет прекрасно с постг весом здесь валится ошибки и подобные запросы надо переписывать надо добавлять какие-то явные приведения типов так живо как ли есть достаточно много специфичных функций которые разработчики очень широко использовали потому что это удобно в постгассе этих функций нет но есть куча разнообразных аналогов А также есть расширение которое позволяет закрыть глаза на то что в поиск каких-то функций нет Ну и еще такая очень неприятная штука выявилась это нонанси Джейн синтаксис Когда вы через запятую перечисляете в селекте там 10 таблиц допустим А в блоке вписываете каким образом вы будете соединять на такие запросы отдельно пришлось обратить внимание Там прям полностью их переписать потому что они были очень проблемными но и следующий шаг это генерация кода для хранимых процедур К сожалению ортопеджи нам здесь не помогла совсем то есть там было как я уже говорил 100 тысяч строк Пеле SQL кода он содержал в себе Вообще практически все что угодно это разбор сборы xml вложенные процедуры всякие публичные константы глобальные Кто знает что такое какие-то общие процедуры были Кроме того бак в коде разбросанные много где Ну и в общем еще куча всего специфичного именно присущего около Пеле SQL дальше так как сгенерить хранимки нам не получилось Мы решили что сейчас мы их переработаем для начала мы постарались максимально навести порядок в коде уроков или SQL для того чтобы как-то структурировать этот код там пометить что-то себе где-то какие-то блоки то что потом было с ним удобно разбираться На что мы обратили внимание Первое это структура кода мы заранее договорились о том в каком виде мы будем переписывать то есть мы договорились что вот у нас будут опишечки которые работают непосредственно с данными изменяют добавляют какие-то новые версии у нас там будут в юхе которые должны быть определенные структуры договорились о том на что мы заменяем какие-то константы договорились о том как ним код в гите в каких ветках каких каталогах каких-то структурах и так далее и я считаю что это был один из факторов успеха этого проекта дальше картинка про именно структуру кода то есть работу с данными мы выносили вопишечки были написаны и задачи там типа заблокировать запись Чтобы никто другой не поменял пока мы не работаем выполнить какие-то изменения дальше отпустить Ну и собственно поверх всего этого также бизнес логика также в хранимках только уже не пелись quel apel gsql то есть мы не делали в бизнес-процедурах каких-то Селект нет insert update там Delete мы вызывали Уже именно пешечке внутри фишечек разрулилась вся работа с базами с данными с таблицами но сервис на Джаве просто вызывал вот эти API функции дальше стоит отметить момент про копирование данных как я уже говорил данных в системе достаточно много это 30 терабайт из-за этих 30 терабайт 10 это реляционные данные 20 это разнообразные журналы в которых хранились Эти пакеты Ну и какая-то дополнительная к этим пакетом информации средний рост если был там 30-40 Гб в сутки это тоже стоило учитывать так надолго нельзя было систему остановить поэтому тут пришлось хитрить на этапе когда мы создавали себе деф контур тест контуру мы спокойненько скопировали себе данные при помощи ворота PG потому как было немного но когда пришло время переносить все это в Production пришлось более плотно задуматься О том А как же мы перенесем 30 терабайт и при этом не будем останавливать систему там например на неделю мы воспользовались пинтах когда-то integration в ней мы написали так называемую умную миграцию данных то есть миграция началась за какое-то определенное время до продакшена и фоне мы просто догружали Дельту которая там поступало каждый день ночью условно запускался Job копи данные и таким образом к моменту когда нам надо было выходить в продакшн мы достигли того что в течение часа примерно мы могли до копировать Все недостающие данные все проверить Ну и в общем-то запуститься следующий достаточно интересный шаг это тестирование то есть вот мы вроде бы все сделали вроде бы все прекрасно переписали код поправили вызовы в Джаве и первый раз запускаем наши сервисы получаем огромное количество ошибок Что где-то что-то забыли где-то что-то не до копировали что-то не учли всплыли какие-то интересности с тем что там допустим схема не была указана при обращении К объекту Ну и мы провели работу над ошибками Что здесь хочется отметить на что стоит обращать внимание это первое обязательно там проводить тщательное код ревью обязательно пользоваться гитом оставлять комментарии это на самом деле круто многие почему-то на это не обращают внимание Но потом когда разбираются своими ошибками не могут понять что же там было после того как мы поправили все ошибки запустили снова наши сервисы и попытались запараллели там нагрузку на наши сервисы Ну за параллели запросы сегодня начали летать через какое-то время у нас всплыла такая интересная ошибка которая наверняка там была у многих когда сервисы просто упали все И больше работать с базой данных не могут мы начали разбираться в чем же дело а дело на самом деле оказалось в производительности есть достаточно большое количество разнообразных инструментов при помощи которых вы могли бы посмотреть А что вообще медленно работает что не так на что там обратить внимание это конечно же тактивити раковые аналог поисковый аналог какого jvcation это pgstar statements из которого мы можем получить информацию о том как быстро работают наши запросы насколько сильно там время их исполнения отклоняется от среднего Ну и найти из них какие-то запросы на которые стоит обратить внимание стоит переписать а это представление там PG stato indexo tabus Ну и еще очень много всего Да это не так удобно К сожалению как ворот ли ворот ли у нас был Cloud Control в котором мы могли открыть много красивых интересных картинок покликать мышкой Оля иди какой-нибудь и посмотреть все ли с ним Ок ну и в общем у позге с охоте не так удобно но очень много всего посмотрев на все эти инструменты воспользовавшись ими мы обратили внимание на то что у нас в каких-то таблицах оказался очень большой болот то есть они распухли пока мы их переносили особенность это было связано с тем что у постгаса там своеобразная реализация мультивершен конкаенсе Control и с тем что при переносе Мы в таблице добавляли служебные поля и нам надо было заполнить эти служебные поля какими-то значениями поэтому Перед выходом в продакшн нас над таблицами было выполнено достаточно большое количество операций апдейт вот что и привело к разбуханию таблиц Ну это исправили исправили при помощи там вакуумов настройки автовакумов которые там помогли Да еще в Праге следующее с чем мы столкнулись у нас были временные таблицы Да мы примерно понимали что использовать временные таблицы для подобного рода сервисов не стоит Но все же мы решили попробовать до прода Конечно же это не дошло Это осталось на этапе тестирования чем они были плохи тем что изначально они использовались для того чтобы разобрать xml сложить туда данные и дальше с этими данными провести какую-то работу мы заменили просто временные таблицы на обычные хип таблицы но и секционировали их то есть получился такой Костыль который на самом деле достаточно неплохо справляется с задачей То есть это секционированная таблица в которую также разбирается сервисом по xsd схеме xml-ка складывается с неким гуидом и дальше обрабатывается раз в сутки там секция просто убивается как не нужно и вроде бы все прекрасно следующее с чем столкнулись это логирование наверное каждый У кого есть логика в базе данных в хранимках пытался как-то залогировать эту логику и посмотреть где есть ошибки что не так И workly для этого есть автономные транзакции в ванильном позге автономных транзакций нет но они на самом деле могут быть получены при помощи использования белинков вроде все хорошо Но в нашем случае как я уже говорил сервисы довольно нагружены и варианты логирования использования белинков он достаточно медленный но у нас конечно же был погресс Professional поэтому мы не могли не воспользоваться автономными транзакциями в общем-то это решило нашу проблему производительности при логировании и логирование у нас там было поделено на уровне фоги бак рортон критиков и когда все это дошло до провода мы просто на продакшене оставили уровень логирования то есть стали логировать только ошибки Еще одна очень интересная особенность когда мы вообще мигрировали Мы понимали Как устроен плоскость как он работает и старались максимально ориентироваться на то чтобы наши хранимки только вставляли данные в таблице и ничего не изменяли Мы думали что мы сбежим болото и все будет прекрасно но на самом деле совсем не так в какой-то момент мы увидели что вот у нас тормозит один из запросов Но почему начали разбираться оказывается таблица пахнет как так в ней только несет дальше мы поняли что оказывается в нашем приложении есть ошибка выполняется insert приложение доходит до какого-то шагает Exception и все просто откатывается но при этом запись таблица остается И от этого получается было таким образом распухание таблиц в том числе Может сигнализировать вам о том что в приложении есть какие-то ошибки далее я ранее показывал картинку на которые были вьюхи и были хранимки так вот вьюхами пользовались сотрудники фонда Как пользовались есть некий юань под ним живое приложение которое из этих фишечек на юань начитывает какие-то данные это больше нужно для аналитики для того чтобы построить какие-то небольшие чатики Но это в каком-то смысле можно назвать там лап нагрузкой аналитической и там параллельно вещи утп нагрузка А еще есть интеграция и в общем когда все это заводится вместе начинаются проблемы эти проблемы решили тем что под каждый вид нагрузки Под каждый тип приложений выделили просто свой пул и каждый попросту ограничили это позволило нам дальше запуститься Ну и дальше мы исправили все ошибки которые у нас были Вроде все прекрасно перенесли данные Ну и за дублировали получается снова продаю нагрузку на наши сервисы решили посмотреть как все это работает на картинке представим представлен график работы сервисов за сутки здесь поминутная разбивка то есть видно что там за минуту сервис держала на тот момент это 2020 год там 7-8 тысяч бизнесовых запросов в минуту Ну и дальше мы ставили готовиться в продакшн То есть все же сделано все исправлено все переписано вроде классно но не тут то было пока мы иммигрировали система изменилась вообще Наверное ни один заказчик не готов остановить развитие своей системы проект длился примерно месяцев 6 по переносу и за эти шесть месяцев там где-то поменялось функциональность где-то изменились структуры и нам пришлось снова вернуться назад и снова пройти все шаги Но что уже было классно первое как я уже говорил мы определились со структурой кода и мы ее придерживались хоть и где-то может быть она была ошибочной мы определились тем как мы все это храним в гите по сути прошли все те же работы подготовили какой-то набор скриптов набор хранимок Но вот и нам не надо было выкатывать это все вручную мы сделали это при помощи Liqui Base То есть все это нам позволило условно сравнить ветку когда мы отпочковались от продавой системы раковой с веткой которая у нас была в гите под наш подгрессовый проект с хранимами процедурами оттуда посмотрели что поменялось внесли где нужно изменение снова потестировали и в общем-то запустились все прекрасно так да но прекрасно но не до конца когда мы начали обновлять продакшн с ликой Бейс мы получили ряд интересностей первое для того чтобы там например в пост грисе пересоздать Ну не пересоздать изменить тип поля у таблицы Ну в нашем случае нужно было например увеличить длину поля нужно было Для начала удалить все зависимые от этой таблицы объекты то есть мы должны были поубивать в юге и мы это сделали но потом как оказалось мы попросту забыли дать права на эти вьюхи вот это было решено тем что просто в скрипты создания View были добавлены определенные наборы грантов для дешевых ролей Ну и в общем-то все в целом все работает как надо мы получили бесценный опыт миграции из одной в другую мы запустили стены в Production и они работают уже два года да есть свои особенности может быть кто-то смотрел есть такой фильм 28 часов спустя 28 спустя и по-моему 28 недель спустя и вот это же я считаю что можно вполне отнести к пост грису вот а мне для вас хотелось бы там отметить порекомендовать Если вы собрались делать такой же проект то важные моменты это определиться со структурой кода определиться с какими-то соглашениями внутри команды никогда от этого не отклоняться стараться максимально автоматизировать все что можно Ну и комментировать свой код и не бояться мигрировать в общем-то у меня все Всем спасибо оценивайте мой доклад кому понравилось всем спасибо большое И конечно благодарим нашего докладчика Илья ну понятно миграции это как пожар переезд два пожара Да примерно так коллеги А если есть вопросы Давайте зададим вот мне на самом деле кстати пока вот сейчас созревают вопросы в зале поднимайте руки девушки с микрофонами подойдут вам маленькие вопросик вот самом начале вот собственно говоря вот последний гэп который в самом конце такой Твист твоего рассказа Где Вот пока мы несли оно изменилось часто история для всех насколько сильно повлияло сдвинула сроки ваши а в нашем случае понадобилось примерно 1 неделя для того чтобы учесть все эти изменения быть Счастливчики просто Счастливчики просто потому что все эти изменения они были в хранимках хранимках править просто ну я считаю что просто хорошо отлично повезло я считаю повезло Так давайте Если есть вопросы Поднимите руки А Вот микрофончик уже есть молодой когда Давайте вот пожалуйста на первый дом А подскажите как решали проблему с разным поведением транзакции в workly и то есть воронка у нас транзакция длится столько сколько нам надо И один комит в конце в подгрессе по умолчанию автокомит по умолчанию автокомит Но на самом деле транзакциями управляла приложение то есть приложения вызывало ранинку и самостоятельно завершала там в конце транзакцию вот у нас были попытки использовать не Явный откаты изменений в после своих корыстных целях но потом от этого отказались в общем то приложение управляет транзакциями и я считаю что это правильно То есть то что раньше было в ворохле хранимках и там были коммиты баки мы от этого ушли пришли к тому что приложение там что сделало хранинку вызвала и само в зависимости от результата который хранимка вернула этому приложении либо cometic либо откатывает отлично Спасибо большое вот пятый пятый ряд Спасибо за интересный доклад вот Приветствую коллегу по счастью перехода Вопрос такой смотрите самый интересный момент уже момент переключения то есть вот у нас допустим был период параллельной эксплуатации вы переключались сразу в омут или у вас там параллельно работала или Было ли откаты обратно на старую и потом снова вопрос интересный на самом деле откатов на старое не было у нас была возможность рядом поднять можно сказать Клон продакшна вот к этому клону продаж естественно доступа мы не имели но у нас была возможность задублировать ту нагрузку которая шла наоборот при помощи Джеймса запросы на вот этот Клон продакшна и понаблюдать как он будет себя вести Да это был не очень короткий период наверное несколько недель этим занимались плавали какие-то новые известности и поэтому Когда нам пришла пора переключаться в Production мы на самом деле уже наступили на огромное количество горблей с вот этим вот клоном и при переключении там был какой-то на выходных по моему на определенное время Down Time о котором договаривались запустились до запустились не гладко брать не буду у всех так бывает Но с первого дня система работала и все было прекрасно в целом Спасибо проблемы решались Спасибо пожалуйста молодой человек размеры вашей команды работает с BD И второй вопрос переобучение вашей предыдущей команды как это было обучение организовано да Вопрос тоже очень интересный команда стояла из Пеле SQL разработчиков из Java И pelp.jsql на самом деле были ребята которые уже ранее сталкивались с постесом но хранимок не писали при этом у этих ребят было очень большой опыт работы с уроков пел SQL обучение небольшое проводилось внутри нас ну Никакое обучение вам практику никогда не заменит просто эти ребята на какое-то время были помещены в команду которая занималась поддержкой развитием этой системы вот вообще хроники достаточно похоже на рокковые написание кода там Оно плюс-минус такое же единственное есть куча нюансов и когда мы обучали своих ребят мы на вот этих нюансах как раз таки застряли внимание старались этого избежать как-то так хорошо спасибо большое потом будет вопросик из чата Спасибо большое за доклад А вот подскажите как вы проводили функциональное тестирование допустим вам вы конвертировали процедуру И вам надо убедиться что она работает идентичным образом на одних и тех же данных или как тоже вопрос очень интересный у нас были заранее заготовленные какие-то образцовые запросы их Конечно было достаточно большое количество наверное можно сотню бизнес кейсов каких-то набрать и мы должны и Мы понимали Какой ответ система должна давать на запросы вот такого вида и функциональное тестирование оно проводилось при помощи метр помощи метра эти запросы просто закидывали наши сервисы но далее мы просто смотрели насколько у нас ответ Он совпадает с тем что мы ожидаем у нас такая возможность была сравнить этим пользовались собственно вот все функциональное тестирование так Спасибо Давайте вопросик вот из чата значит не рассматривали ли вы распиливание базы данных по разным сервисам по разным сервисам Да рассматривали но вначале Я не стал сильно останавливаться на том что мы сохранили архитектуру своей системы дабы минимизировать какие-либо риски на самом деле там внутри данные их можно было поделить на две части часть первая это реляционные данные часть 2 это часть журнальная в которой лежали вот все эти xml и прочее но дело в том что этот юань который был нужен для аналитики каких-то отчетов он использовал все вот эти данные и интеграции тоже были нужны все эти данные поэтому мы решили что распиливать сейчас мы ничего не будем дабы уложиться в сроки и выполнить задачу которую нам поставили Ну вот хорошо спасибо большое вот там сзади будут молодой человек пожалуйста будьте добры и потом вот здесь на четвертом на пятом ряду Добрый день я Спасибо за доклад У меня два вопроса Первый вы упоминали про проблемы явных преобразований не было ли желания скажем так воспользоваться пользовательскими оператами для решения данной проблемы и сразу второй вопрос не использовали статические анализатор кода для выявления проблем Ну соответственно чтобы с сократить трудозатраты на поиск уязвимых мест хороший на первый вопрос ответ не задумывались просто этические анализаторы мы использовали их для но для постгаса не использовали Спасибо большое здесь на пятом ряду потом будет два вопросика из чата Здрасте Спасибо за доклад У меня вопрос такой Были ли какие-то проблемы при миграции данных проблемы при иммиграции данных Да по больному практически Да конечно Да конечно Проблемы были и поэтому я упоминал в своем докладе что мы включали до копирование данных по ночам когда нагрузка на система минимальная видели этот график это основная нагрузка на самом деле на систему приходится где-то часов с пяти по Москве и часов до пяти по Москве то есть когда основная масса людей они приходят в больнице оформляя себе больничные Вот и мы постарались просто впиковые часы не нагружать это мараковую систему еще дополнительно копирование оттуда данных Да были еще момен тем что я говорил надо тщательно очень проводить ревью кода структуры которые были в окле Ну они идентичны структурам которые были в постгасе Но типа не идентичны где-то вот я говорил что нам пришлось менять например длину строковых полей вот мы до обожглись это пришлось исправлять но Мы заметили это доп рода и это было классно успех практически Спасибо большое за вопрос два вопросика из чата не рассматривали вариант переноса функциональности по частям перенос функциональности по частям был невозможен потому как это Единая слитное система так было написано изначально программа так было написано изначально если брать вообще мне кажется почти любую систему на Пеле SQL я достаточно много повидал там внутри все вот так вот просто переплетено еще что-то запросы в которых там 10-20 таблица объединяются Если вы начнете все это разъединять Ну проект Может затянуться на долгие годы Мне кажется просто дешевле выкинуть и написать снова Спасибо Давай еще один вопросик из чата есть какие-нибудь хитрости версия они в погреce Ну кроме грантов которые ты уже рассказывал хитрость они мы сильно на этом не заморачивались нам основная задача была это автоматизировать свою работу по донесению изменений до продакшена Ты что мы делали у нас была какая-то основная ветка мы в ней вели разработку нас была ветка соответствующая кому-то контуру в момент когда Мы понимали что допустим вот все Мы набрали объем изменений которые можно тащить на следующий контур мы их просто сравнивали брали GIF упаковывали этот Диф в некий релиз Ну и описывали его там в виде некоего Сета набор через это все ну а дальше Просто Уважаемые коллеги давайте мы если остались вопросы Мы зададим экспертной зоне сразу за залом А сейчас поблагодарим нашего докладчика Уважаемые Спасибо большое спасибо У нас есть небольшой Презент который хотелось бы вручить соответственно здесь в зале для тебя как Спасибо тебе большое вот программных Комитета и организаторов А на этом мы заканчиваем это выступление Спасибо вам большое ждём вас в этом зале на следующем докладе Спасибо большое До скорых встреч"
}