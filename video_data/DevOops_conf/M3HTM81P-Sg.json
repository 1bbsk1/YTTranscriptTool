{
  "video_id": "M3HTM81P-Sg",
  "channel": "DevOops_conf",
  "title": "Григорий Кошелев — Как готовить Кафку, чтобы не пригорало",
  "views": 3079,
  "duration": 3573,
  "published": "2020-02-07T07:55:52-08:00",
  "text": "у всем спасибо всем придется топку и за желательно так чтобы эта готов к закончилось хорошо и ничего не сгорело план у нас такой вначале расскажу немножко вообще зачем нам нужно кафка чтобы понимали какие у нас сценарии и может быть понимали как по маппить наши сценарий на свои и посмотреть насколько наш опыт применим для вас вторым пунктом мы разберем такое введение в кафку чтобы мы говорили на одном языке чтобы по терминологии не было никаких ты разночтений и было понятно какой компонент какой момент времени мы сейчас говорим далее я буду рассказывать про то как мы мониторим кластер а какое инструментарием для этим для этого пользуемся ну и закончим всем большим таким разделам про управление кластеров кафки ну и соответственно тоже какой инструментарий нужен для того чтобы это все у нас получалось получалось хорошо итак начнем с того зачем нам кафка вот у нас в компании эксплуатируется огромное количество микро сервиса все они имеют огромное количество телеметрии и соответственно нам поставили такую задачу нужно сделать такую трубу которая всю телеметрию могла в себя сосать и на другом конце разложить по правильным брендом то есть там допустим логе положить в ластик search метрики положить в графит трассировки соответственно в другую систему из которой можно было бы там по вот этой вот этим трассировка строить красивые такие деревья меж сервисного взаимодействия общего такая штука мы ее сделали вот тоже про неё и про эксплуатацию краз поговорю с точки зрения кафки вот кроме того мы эту штуку предполагаем расширяемую то есть можно будет команде сказать смотрите ребят атласу такая труба вы можете у нее закидывать любые свои кита бизнес ивенты и мы их надёжно доставим второе применение кафки это для поисковых рекомендательных систем на вход подается кафки какое-то количество данных они потом могут также быть переданы в какие то поисковые движки или в какие-то машину leaning системы которые то данные будут обрабатывать но поскольку в кафки данные хранятся persistent на то они могут быть переданы другим алгоритмом другим программам которые могут с другими настройками работы то есть можно какую-то воспроизводимости повторений результатов попробовать сделать третий сценарий использования эта шина данных то есть ее классическом понимании у нас есть какое-то количество микро сервисов и некоторые микро сервисы хотят взаимодействовать между собой непосредственно ттп просто асинхронно отправлять события в шину в кафку в данном случае и соответственно один или более микро сервисов могли бы эти события обрабатывать наконец последний сценарии использования он в целом очень похож на первые два это стрим processing здесь я выделил в отдельный пункт потому что здесь сам сценарий он довольно интересен тем что вот есть некоторые источники данных который генерит поток событий эти события попадают в кафку а потом другие сервисы читают их возможно что этим с потоком что-то делают трансформирует может быть как-то фильтрует обогащают данные и порождают таким образом и другие потоки данных и вот так вот такой do the pipeline строится но и в конце там куда то данные уже наконец попадают в общем это то для зачем нужна кафка как мы ее используем и вот небольшой туда блиц-опрос что понять кто из вас общее использовать кафку поднимите руки кто упаковку же есть отлично 8 а вот теперь давайте попробуем понять по точнее у кого какая версия кто использует версию которая меньше чем 011 есть такие два человека окей версия вот ровно 011 какая-то побольше 1 версия мажорная уже есть еще больше 2 мажорная версия но отлично у нас больше всех почему это важно дело в том что в каждой версии кафки есть свои баги само собой вот кроме этого некоторые фичи они есть в новых версиях но нет старых но наверное поэтому тоже можно по ходу доклада поговорить и будет понятно одно и давайте попробуем такое небольшое введение сделать на в перу очередь для тех кто с кафкой незнаком но смотрите у нас есть приложение наши которые производят некоторые события продюсеры в терминах кафки из такой абстракции к кафка продюсер отлично то они создают события на другом конце соответственно дожны быть некоторые потребители этих сообщений концу мир и в терминах кафки то абстракция кафка концу мир между ними находится кластер кафки это ничто иное как множество брокеров при этом взаимодействии между продюсерами костюмером осуществляется через брокеров при этом такую маршрутизацию довольно сложно организовать если брокеров если продюсер cнова концу меров много поэтому это взаимодействие происходит в рамках топика то есть события как передаются они логически обвиняются в такую структуру при этом физически каждый топе представляет собой множество партиций портится этого то что он хранится там на диске данные в ком-то упорядоченном виде эти события находятся при этом что важна каждая такая partition у нее один из брокеров является лидером лидер это тот брокер который ровно отвечает за запись и чтение из этой participle смотрите продюсер пишет данные в топик на конкретный брокер этот брокер является легендой партиции и он же отличает этот же брокер для того чтобы эти данные попали потом концу миром один из брокеров в этом класть или выбирается в роли контроллера контроллера координат работу кластер а как раз он решает какой брокер является лидером для какой партиции там устану это все распределение он определяет самостоятельно помощью этого приходит кластер руки перо находится рядышком с кластером кафки для чего нужна ну во первых для того что же сказал по поводу выбора контроллера какой брокер будет отвечать за координацию кроме того там хранятся информация по топиком то есть до конфигурация топиков это распределения participle брокером состоянии реплика синхронизированы не синхронизированы в ком они состоянии находится кроме того там так называемый кластер state то есть состояние кластер а если очень просто это какие брокере в данный момент находится онлайн какие брокеры работают и резонный вопрос возникает что из этого нужно мониторить вот как вы думаете что из этого мониторит нужно правильно нужно мониторить абсолютно все вот но смотрите мы сейчас больше говорим про такую эксплуатацию и соответственно мы будем говорить про те части которые не относятся к непосредственно приложением то есть приложениях как это должно быть устроено это больше про разработку мы будем говорить про кафку и бронзу kipper но прежде чем говорить про мониторинг я немножко расскажу как устроена наша инфраструктура сбора метрик чтобы было понятно почему мы те или иными инструментами пользуемся во первых у нас исторически сложилось так что мы в качестве хранилища метрик используем графита есть и данные по метрикам со всех приложений состав у нас попадает у него вот кроме того нас пользуется grafana для ну как frontend к графиту то есть для построений каких-то дашбордов смотря чтобы рисовались красивые графики и мы смогли на телевизорах наблюдать и радоваться что все работает ну или бегать в панике когда там что-то происходит не так но чтобы бегать в панике реже и не бегать в идеале вообще у нас есть море эта система лифтинга она использует ровно те же самые данные которые лежат в граффити вот но позволяет в реальном времени на какие-то триггер срабатывать и отправлять alert и но это могут быть телефон телефон и звонок от роба женщины это могут быть какие-нибудь уведомления в slug в почту куда угодно в общем вот эта штука мы пользуемся для того чтобы мониторить наши приложения и вот это уже мы хотели бы использовать для мониторинга кафки и сопутствующих сервисов что мы мониторим ну во-первых важно мониторится до системные ресурсы независимо от того кафка это у нас или какое-то другое приложение для мониторинга мы используем даймонд и такой этот инструмент который как раз умеет собирать состав метрики и отправлять их непосредственно в графит ну что мы системных ресурсов мы собираем стандартные утилизацию циpкa владимирыч утилизацию памяти как работает у нас диски и сетевое о той сколько байтов у нас приходит на тачку сколько уходит по какому из интерфейсов но смотрите у нас и java и закипит и кафка это по сути java-приложения поэтому важно говорить про еще специфику вот таких такого инструмента вот как вы думаете что сама важно при мониторинге java-приложений что мониторить что по до память и сборку мусора на потому что это такой круг караульный камень и это очень важно но отлично вот эти вещи тоже нужно мониторить и вопрос топчи как вот у нас java-приложение этого дела можно мониторить есть такой gemix joy and ex наш который позволяется как раз вывешивать через специальный point по специальному протоколу эти данные есть инструменты которые имеют эти данные забирает он наверное самый популярный известно это джим x-trans который забирает метрики чуть g-max любого из java приложений и отправляется сразу в графит кроме того есть такой инструмент как же локи который позволяет также собрать метрики gemix но не отправить их куда-то а просто уже вывесить их в другом интерфейсе плохо ттп чтобы уже какое-то другое приложение нет не имеющие культа java специфики могло эти данные обрабатывать но смотрите мы вот такие метрики собрали посмотрели допустим что там у нас собирается для дециметр и для сборки мусора вот у нас используется один сборщик мусора вот у него такая метрика там я инженер решим это сборки мусора молодого поколения но там есть некоторое количество сколько от этих сборок уже произошло с момента старта и время соответственно которое накапливается сколько времени приложению пришлось потратить на эту часть и такая жизнь для этом старого поколения и там точно такие же параметры и вот опытные эксплуататоры java-приложений задумаются а что же там с стоп зовут паузами то есть известно что сборка мусора довольно сложный процесс он состоит из нескольких этапов и некоторые этапы они проходят параллельно с работы приложения они которые блокируют его то есть если паузы становятся большими приложения становятся неотзывчивым и неплохо было такими паузами смотреть но стандартного инструмента для чуть живется у нас не предоставляется ну давайте посмотрим все а какими опциями мы пользуемся при запуске java-приложения ну во-первых мы указываем какой сборщик мусора использовать в этом мы говорим о том что неплохо бы писать логе а сборки мусора кроме того указываем что их надо делать очень подробным что в них можно было покопаться и поизучать если что-то пойдет не так плюс делать привязку к ко времени но это удобно когда у тебя в логах daytime и по нему очень легко ориентироваться вот у нас влогах в обычное приложение что-то происходит и так же можно посмотреть на gc log и вот если мы добавим вот такой секретный ключик pringles applications stoptime в принципе ключевым словам может можно догадаться что он делает так вот делает он следующие в каталоге который пишет приложение у нас появляется да вот этот меточка времени и у смотрите какое важное придут предложения total time for which applications and who стоп то есть означает время в течение которого у нас потоки приложения были остановлены и дальше какой-то чисел k с указанием что это в секундах вот это в принципе то что нам нужно но ты сразу придаст ригу это на самом деле не только stopsol пауза там еще есть некоторые причины по которым java vm приходится останавливать потоки но по большей части как раз это ровно стоп завел паузы при сборке мусора но что самое главное это как раз те пауза который влияет на отзывчивость нашего приложения ну что с этим можно делать мы можем взять вот такой белок регулярно чикой парсить из него дату вот эту чистилку отправлять соответственно это все voxtel где мы это будем делать блок стоишь это передаст в 100 т.д. агрегатор метрик для графита вот ну и соответственно статус да я уже переложит агрегированные метрики например за минуту и таким образом мы уже будем знать сколько у нас сборка мусора останавливало приложение допустим в течение минуты и можно смотреть это поминутно как это у нас происходит это очень удобно и это очень хорошая штука для мониторинга таких вещей но двигаемся дальше уже будем смотреть более ясно что например у нас звуки пиром закипели у нас есть за кибер коллектор для даймонда то есть здесь в принципе можно перес пользу им какую-то инфу готовую инфраструктуру вот этот коллектор делает не что иное как отправляет команду монитор в зуке пир и на это звуки пир выплевывает вот такую картиночку здесь есть некоторое количество метрик но наверное самое интересное то за к его рычали танцы и макс лет инси то есть это в среднем как быстро закипел работает и максимально как он долго отвечает на наши запросы все это как раз кафка она чувствительна к тому как быстро закипел будет делать свою работу но смотрите там еще есть пару метрик ну и пару значение которое игнорирует даймон коллектор но 1 за к вершин нас мало интересует интересно посмотреть на вторую это за к сервер стоит это написано фолловер это давайте попробуем обратиться с такой же командой в какой-нибудь другой сервер который является не фоловерам а лидером вот у нас вернулось соответствующие метрика лидер и вот если посмотреть здесь еще добавилось несколько метрик за к followers 4 за kasing fall over 4 закопане нгс tanks 0 так вот это как раз метрика которая говорит о том что у нас во первых есть лидер и если лидер у нас есть он должен быть только одиннадцать из на предмет рику должен репортить ровно один из ровно 1 изн отзвуки пера а второе то что у нас состоянии кластер и должно быть синхронизированы то есть у нас языка followers должно равняться количество нот минус 1 раз одна из них является лидером ну и соответственно не все должны быть синхронизирован вот это самое наверно важные метрики которые говорят о том что он кластер за кибер целенький и все хорошо никого спрей на у нас нет не наблюдается в целом пирату довольно надежная система она работает бесперебойно если в нее не вмешиваться и в этом плане как раз вот этих метрик в принципе достаточно для мониторинга поэтому движемся дальше и перейдем к непосредственно кафки вот если посмотрим какими способами метрики можно забирать сказки там точно так же можно использовать тот же самый джеймс и метрики приложения туда забирать а вот а еще есть специальный интерфейс кафка metrics reporter который позволяет передавать метрики непосредственно в какую-то систему not мы используем кафка графит metrics reporter все ссылки но окон собственные продукты которые которых я буду рассказывать ссылочки они в правом нижнем углу есть потом можно быть поскорее презентацию и по всем этим ссылкам походить и все нужное для себя взять так вот а настраивается довольно просто мы должны в папочку кафка lips скопировать нужные jar никита есть там metrics графит уже лежит нам надо подложить только кафка графит то есть ту сборочку которая вот по ссылке есть на втором шаге мы должны все properties просто указать настройки для данного метрика коллектора ну данном случае вот мы указываем этот кафка графит metrics репортёр включаемого предаем настройки для графита еще некоторое количество других настроек над самое важное после того как вы это сделали метрики ваши уже польются автоматически в графит на перед тем как посмотреть на эти метрики давайте посмотрим вообще как они устроены непосредственно в кафки метрики в картине устроен следующим образом вот есть некоторых тракции метрик name который состоит из нескольких частей ими метрики некоторая группа ну что некоторые метрик они сгруппированы логически вот они поэтому удивляются в отдельную группу и что важно здесь счет есть такой словарик примерно такого содержания то есть некоторый ключ допустим топик со значением тест парте шин со значением 0 и какой то еще там так и не со значением сам белье вот что делает вот этот репортёр когда мы хотим получить вот эти метрики в граффити ну во-первых он вот этот словарик сортирует сортирует он лексикографические по ключу это не нож немножко перед сортировались на втором шаге он заменяет символ точечка потому что для графита это значимый разделитель в уровни в уровнях иерархий метрик и заменяют ее на подчёркивание отлично это пока еще не похожим на звание метрики поэтому на втором шаге он joy нет через точку ключик значения получают что-то такое ну и тут уже остается последний шаг и собрать большую большую-большую строчку получается вот такое строка с разделенной точками соответственно уже непосредственно графит попадет следующе то есть некоторый настроенный префикс группа вот это вот большая большая строка которая получилась после склеивания всех тегов и в конце имя и вот здесь я хотел бы сразу показать вот такую вот штуку которая казалось бы не очень логично вот у нас идет partition номера и потом топик и название топика казалось будут у нас есть структура данных топик которые состоит из партиций но в метриках нам придется ответить вот такое не совсем удачное решение но с этим ничего не поделаешь на просто иметь ввиду ну и нужно понимать что вот когда у нас такие партиции топике находится в путях метрик то таких метрик будет много вот на данном на одном из кластеров у нас примерно час графит отправляется порядка пяти тысяч метрик с одного брокера это получает зависит а чего от количества топиков от того сколько у нас в этих топиках партиций в принципе сколько у нас брокеров то чем больше брокеров там тем больше между брокер на взаимодействия социса тоже соответствующий метрики и вы так далее так далее таких метрик накапливаться довольно много и поэтому еще с разберем самые важные метрики которые помогают следить за состоянием кластера но первое для сна и что важно о том что он сквозь тир живет но для этого 1 метрика который репортят каждый из брокеров это брокер state и вылью соответственно если метрика нери портится у нас просто выключен кафка брокер если эта метрика репортят а можно посмотреть на это значение и понять каком состоянии кластер натрите там значение 3 насчет брокера онлайн и он работает у него все хорошо идем дальше контроллер также и портит информацию о том что он есть что он живой у него все хорошо он должен репортить единичка вот в этом вольют в этой метрики актив контроллер каунт и тут важно смотреть что если у нас допустим 2 брокера репортят вот эту метрику значит у нас в кластере произошел сплит brain появилось два контроллера каждый контроллер там выберет своих лидеров и общем у нас данные развалятся и кластер развалин ну такое может провести по причине того что допустим у нас плит brain произошел в кластере пера ну если мы там соответствующий метрики раньше увидели звуки перину мы это узнаем чуть раньше эти меня за этим приглядывай все же стоит вторая важная метрика контроллера это оффлайн парте шанс каунт что такое оффлайн партии шиндо портится которая недоступна на чтение и запись для клиента для наших приложений и понятно что это значение если больше нуля то у нас в кластере какие-то проблемы и какие-то из клиентов не могут либо записать ли вы прочитать данные сказки поэтому мониторить это очень важно ну и наконец метрика которая напрямую не покажет что у нас власти работает или нет но даст какую-то пищу для размышлений и покопать в нас постером не так происходит здесь у нас выводится информация о том как часто выбираются лидеры в нашем кластере смотрите если у нас лидеры постоянно переключаются то очевидно что то у нас не так в кластере нужно с этим разбираться вот эта метрика она помогает это понять то есть в идеале у нас никаких перевыборов не должно происходить у нас кластер должен быть стабилен носишь заговорили о том что есть какие-то реплики и перевыборы давайте посмотрим на то как и реплик какие метрики у нас отправляются для этого каждый брокер отправляет информацию о том сколько у него партиции когда это может быть полезно ну например ситуации когда у нас есть дисбаланс по на partition который обслуживает конкретный брокер и мы видим что некоторые брокер не до загружен партийцами друга и другие перегружены и соответственно как раз у нас возникает идея неплохо бы это перри балансируете перекинуть нагрузку на какие-нибудь другие брокеры то же самое касается следующий метрики андорре прикрыты партий шанс это говорит о том сколько у нас партиции еще не до реплицировали вы смотрите у нас на другие брокерах из реплики они себя синхронизирует данные из лидера ну и соответственно если у них по данным они отстают то неплохо бы понимать сколько у нас этого происходит но это какая-то такая средняя температура по больнице ну да окей мы увидели что значение равно нулю но она не говорит о том как с какими конкретно топиком с какими клиентами у нас проблема благо есть такая метрика которая в разрезе портится и топиков то есть мы можем посмотреть у конкретной партицию конкретного топика какая слез на partition у нас не реплицировали ну и таким образом локализовать как-то нашу проблему еще набор общих метрик для кластер а этот трафик это речь про количество сообщений входящий в кластер байтов и входящих и исходящих и то же самое в разрезе по топиком ну примерно то же самое то есть вы видите на своих графиках что у вас вдруг произошла просадка входящего трафика значит и думать ага наверное что-то произошло с нашими писателями можете пойти посмотреть какие конкретно топике про сели и соответственно как-то на это отреагировать торс она касается при потреблении каких-то данных в принципе у нас настроенный alert энн если количество сообщений которые к нам попадает ниже какого-то порога на грани которого гарантированного порога движемся дальше здесь мы перес пользуем метод red рейд rs юрий шин для этого тоже из кафки соответствующий метрики тут нас 1 чит интересует метрики для протеуса то есть это имеет информация потому сколько у нас данных сколько запросов приходит на запись в из-за продюсеров этой самой печи печь это концу мире которые потребляют данные из кафки но и также засечь им скрывается другие кафка брокеры которые реплицируют в себя данные там тоже там потребляют с лидеры данные чтобы реплицировать их себе вы тут в принципе не надо так очень страшно смотреть на r который написан перед звездочкой дело в том что все метрики они пишутся сюда просто то что не является ошибкой называется р но он ну типа не ошибка но просто запросу них так просто все вместе накида на 1 по ним можно смотреть как часто и как много о к нам приходит записи и как раз duration что посмотреть для этого есть соответствующий метрики которые пока показывают сколько вообще времени запрос провел у нас то есть total time в миллисекундах для продюсера здесь уже разделена fetch консьюмер и печи фолловер фолловеры так раз брокер который себя реплицировать данные с лидером вот от этих метрик в принципе достаточно чтобы вывести их на даже борды за ними следить и относительно спокойно жить поэтому можем с чистой совестью двинулся дальше и посмотреть как вообще глостера можно что с ним можно делать и потом наки метрики для этого надо будет смотреть на начнем со стандартного туринга который есть и наверное сразу приведу такую бородатую шутку по поводу того что есть bootstrap серого и брокер лист 2 опции которые часто встречаются в стандартном ту ринге вот их не надо путать брокер сервер bootstrap сервер это тот хост кафки которому мы обратимся из этого скрипта чтобы какие-то применять наши изменения а брокер лист это список брокеров на которые будут применены изменить то есть смотрите прийти можно к одному из брокеров но он потом там все изменения разошлет на соответствующих список брокеров вот но это ну да вот как раз еще есть 3 опт визу кипер где тоже некоторые настройки передаются через него но на сейчас уже устаревшие эта опция и потихоньку ее выпиливают в какой версии 24 до но до тут правильно говорят дело в том что тут есть тип 500 кипяток of control проползал это документы где предлагают скит архитектурные улучшения в кафки они применяются там после проходит какой-то этапы обсуждений в конце концов там принимаются ну либо нет но в данном случае как раз идея в том что вообще избавиться от звуки пир в целом из кафки и соответственно понятно что если звуки пера не станет тот эти опции которые звуки perm они рано или поздно полностью пропадут но так вот есть серьезный минус вот этого стандартного толлинга он многословен там много параметров нужно передавать эти скрипты как правило нужно создавать сделать несколько действий одного не достаточно есть мы первым там забираем кита первый параметр и потом их подставляем и второй скрипт и передаем дальше и некоторые из них требуют довольно много джейсона то есть большим количеством строк этих это количество строк все зависит от того насколько у вас кластер большой-большой кластер начинала передавать больше большие джетсоны и поэтому как раз здесь потребуется что-то еще для этого но ты здесь условно touring и разбил на 4 категории честно просто по каждому из них пройдемся not web юрий это примерно тоже самое как сила и только в вроде все логично второе это то чтобы команды были попроще их было понятно как делать соответственно это что придет к тому что это снится порог входа в эти инструмента есть не нужно там обвешиваться с десятком скриптов нас есть какая-нибудь красивой мордочке чист который можно что-то поделать одним из таких инструментов является кафка менеджер это тот самый выпей который во первых что важно поддерживать несколько кластеров это очень здорово ну что как правило у вас есть один кластер вам о какой-то момент становится малый вы поднимаете еще еще кластер а вот как раз эта штука позволяет умерить ваши желания и работать с низкими классами одновременно вот что важно она этот инструмент дает статистику по кластером брокером топиком и портится позволяет через себя создавать удалять и редактировать топике также плюс еще умеет в некоторые там административные задачи и мониторинг блогов кантемиров но про это я чуть позже расскажу сейчас покажу картинку этот пример так выглядит интерфейс этого приложения вот здесь есть возможность перейти в топике данного кластер но данных пластик 242 топика можно перейти в информацию по брокером если мы провалимся там получаю информацию какую-то сводную по брокеру ты сколько в нем топиков где он является лидером сколько в него примерно входит сообщение от общего кластер а вот можно посмотреть какие то более детальные метрики там со средним значением с разбивкой по времени тоже самое по топиком при этом обратите внимание он смотрите это прям реальные скриншот из реального реального кафка менеджер от реального брокера здесь у нас еще некоторые штуки подсвечиваются таким желтеньким чтобы мы обратили на это внимание это подсвечиваться эти разные такие нюансы которые стоит обратить внимание чтобы что-то пофиксить в данном случае здесь говорит о том что вот этот топик он не равномерно распределён по брокером то есть некоторые брокера не так перегружены для вот этого топика то есть партиции на них слишком много ну и требуется перебалансировка а также есть точно такая же метрика с статистикой как и для брокеров но уже в разрезе непосредственно топиков тоже самое можно посмотреть по конкретным брокером какие партиции конкретного топика они себе содержат то есть вот здесь можно видеть что брокер один он столько то партицию у себя имеет в таких он является лидером ну и там перечислены портится какие из по номерам есть в принципе можно посмотреть увидеть в каком состоянии они лидер он не лидер и так далее такая же статистика может быть в разрезе каждой отдельно взятой партиции то есть можно посмотреть партицию какой у него все той сколько сообщений у нее уже нападала какой из брокеров является лидером силе и реплики синхронизированы ну и так далее всю информацию можно там посмотреть в целом луковка man уже есть альтернативного концов сны инструменты вот я покопался погиб хабу нашел кафка игл кафка яичников дроп по каждой штуке есть ссылка на github но мы пользуемся кафка менеджер у нас полностью устраивает вот движемся дальше и переходим к администрированию про днестре на тайский задачи в чем мы хотим решать но во первых это обновление настроек брокеров обновление версии кафки добавлении удалении брокеров добавлении удалении дисков в в ноду на их балансировка нагрузки по брокером давайте начнем самого первого про обновления настроек брокера но с версии 11 появилось разделение настроек по типам есть редон и настройки которые настраиваться сервер properties и при их изменении необходимо перезапускать брокер а также есть еще два типа настроек upper брокеры кластер white в документации как раз каждый из этих настройка например china соответствующим флажком но в разнице в чем что они оперы в отличие от редон и они уже динамически то есть не надо перезапускать серы при изменении этой настройки между ними отличия в том что пир брокер это настройка кто применяется конкретного брокера кластер white это значение которое будет дефолтная для соответственно всех брокеров если она не переопределена явно для какого-то отдельного брокера как эти настройки применяются есть скрипт кафка can fix в котором моды указываем bootstrap server указываем что мы хотим менять настройки брокеров соответствие передаем либо номер брокера которым хотим применить для стройку либо указываем что мы хотим менять настройка в целом div настройка по умолчанию для всех брокеров 10 обязательно флажок alter что мы меняем что-то при этом если мы диск райп укажем там просто выведем соответствующие настройки и посмотрим а какие настройки были применены к соответствующим брокером ну и сами настройки не применяются таком виде что он просто key value передаем туда название настройки значения до нее чтобы удалить на стройку нужно просто отделить конфиг и соответственно перечислить ключики причислить настройки который мы хотим удалить вот эту штуку делаем и в принципе она позволяет менять на лету настройки брокеров движемся дальше и обновление версии но смотрите вот есть два таких параметров две настройки interpreter протокол вершины log message format вершин это двери данные настройки в принципе они не обязательны для указания в сервер properties но если вы хотите обновлять вашу версию кафки вам обязательно нужно будет их добавить сервер properties при этом что важно вы должны будете указать ему версию ту которая сейчас запущена версию кода который вас запущен и второе что вы делаете вы обновляете код кафки после этого делаете rolling рестарта есть по очереди перезапускаете все ноды кафки дальше обновляйте первую настройка интер брокера протокол вершин на ту на которую хотите поменять опять делаете кафка rolling restart обновляете второй параметр еще раз делаете кафка ролик restart вот как вы думаете какой из этих занятий такое самое непредсказуемое и довольно муторное вот этих семи пунктов до действительно потому что очень несколько раз здесь появляется но давайте посмотрим что для вот этого у нас вообще существует на 1 ти таку к общей автоматизировано кафка роль increase the artistic то автоматизирует вот эта смола поэтому думаю что эта тема будет большинство полезно вот ну для этого мы можем использовать кафка ите us ссылочка на гитхабе что это такое это набор скриптов один из них на питание написанных один из них кафка rolling restart он позволяет нам указать кластер которому нужен в который нужно передать стартовать указать на стройку чек интервал это в секундах то есть мы рестарту им какой-нибудь брокер и проверяем 1 5 секунд восстановилась ли работа кластера или нет и убеждаемся что это в течение трех раз то есть что три у нас проверки должны подряд закончится успехом туда мы считаем что брокер рис оставался хорошо можно переходить дальше вот и еще обратить внимание на стройке joe locke апорт и joe locke префикс это как раз информация о том где находится он же локи которая смотрит на наш шкаф к брокер чтобы оттуда забирать метрики и ровно по ним определять восстановился кластер или нет это очень важно чтобы вот эту штуку использовать нужно начале будет поставить жалкий у на каждый из нот ставки но давайте посмотрим как это все работает вот оно смотрите есть кафка кластер 3 брокера и мы делаем rolling restart у нас от 3 сервера при этом если мы запустим этот скрипт он вас предложит ввести confirm вот если вы но confirm просто скрипте укажите то он сразу автоматически посчитает что вы согласны с тем что вы будете часто делать и двинется дальше что он делает он во первых вначале проверяет в каком состоянии находится кластер жив ниже фонд not он видит что все партиции реплицировали никаких оффлайновых брокеров нет все хорошо наш кластер стабилен и можно приступать к рестарту не что он первым очень делает он берет самый первый брокер под номером 1 и останавливает у брокера становился соответственно лидерство переехала с этих партиций на какие-то другие ноды вот лидерство разъехалась брокером со становился что делает дальше скрипт он берет и пытается запустить этот брокер а вот он запускает мы при этом месте он пытается обратиться к этому брокеру и узнать у него метрики он увидит что он отсутствует ну и есть некоторое количество они реплицировали партиций и соответственно у нас на у нас брокер потом рестарту ица следующая проверка которая через некоторым происходит она смотрит а брокер уже восстановился missing брака с равна нулю партиции пока еще никуда не разрекламировали то есть у нас брокер только и столкнулся он еще не восстановил свое состояние вот после этого на его восстанавливать состояние и какое-то время опять происходит чек-чек кластер состоянии кластер а здесь уже смотреть уже все реплицировали что сюжет кластер полностью восстановился неких брокеров оффлайновых нет это проверка происходит 3 раза потому что мы там настройках указали все после этого считается что кластер стабилен и можно переходить следующему брокера мы переходим следующему брокеру его начинаем останавливать соответственно лидерство разъезжается на два других брокера кластер остановили брокера сна или запускаем брокер пока нас отсутствует после этого запускается запускается брокки роде бы запустился произошла какая-то проблема и вот смотрите он от не может в себя реплицировать данные нас прошло прошло много много много проверок результата мы не получили его здесь в зависимости от того он хелси time limit какая настройка в секундах указано то есть если в течение в данном случае 10 минут у нас не восстановился кластер то скрип завершает работу с ошибкой что что-то не получилось вот и на случай если вдруг у вас где-то прервался с ошибкой вот этот rolling restart мы всегда имеем возможность этого момента ее продолжить мы ясно указывал опцию step 2 и таким образом в кластере мы просто пропустим первые два не будем ли стартовать уже оставшихся последний на данном случае брокер так эта штука работает и позволяет очень сильно сэкономить время но и не заморачиваться и в руками не смотрите в ком состоянии партиции идем дальше такая штука как распределение партиций по брокера но во первых смотрите если мы добавляем много брокеров кластер у нас кафка не позаботиться о том чтобы распределить данные по ним автоматически а также нет какой-то стандартной процедуры по выведению новых брокера из бластера то же для этого нужно что-то свою велосипеде ну и при этом отмечу что изменение реплики чем фактор топика это тоже как у частный случай вот этого перераспределение participle брокер ну понятно что если вы нас вы хотите not die комичен сделать то вам нужно выгнать всех все партиции с него на другие брокер то же самое когда рипли киш фактор он наоборот надо еще на другие брокеры просто добавить попортится вот как это делается теперь же стандартный touring рассматриваем кафка reasoning партий шанс ну вот здесь уже звуки пир указывается потому что эти настройки они применяются казуки перу дальше рио сами json файл туда кидаем большой здоровенный джейсон в джейсоне у нас указано какой топик какой номер партиции и на какие реплики он его переместить и вот тут важный такой момент не забыть про то что вот порядок вот этих вот реплик он не просто так вот та реплика которая самая первая она будет preferred лидер профит лидер это тот тот брокер который будет выбран лидером приза при перераспределении вот это означает что если мы вот вдруг очень неаккуратно вот это перераспределение сделали то какой-то из брокеров у нас окажется лидером очень большого количества партиции но и соответственно будет страдать чтобы он не страдал за этим надо следить и очень аккуратненько это делать перераспределение в целом вот этот же сон не обязательно делать полностью руками самим на можно делать по другому но во-первых мы применяем экзо пьют к нему и тогда он соответственно применит это перераспределение по крайней он запустит это перераспределение а проверять состояние перераспределение мы можем опции вери файн вот сейчас вот как раз покажу как вот этот же сон большой сгенерировать для этого нам потребуется тоже jison тут уже смотрите топе кастомов джейсон файл туда мы придаем еще один же сон другом формате выглядел ищем образом он попроще там нужно только перечислить топике которые мы хотим перераспределять но он соответственно просто выведет текущей нам выдаст нам на выход джейсон в котором просто текущие распределение но мы взяв это текущие распределение поймем как мы хотим перераспределить что-то там руками или может быть как-то автоматизировано по переделаем и отправим в данном случае у нас всего один ген ставка здесь топик указан topic тесты мог этим перераспределять здесь мысль ясна указываться jennie reid чтобы сгенерировать распределение и указываем куда нам делать перераспределение вот здесь как раз опция брокер лист нам помогает ну и потом мы это дело просто применяем вернемся опять к перераспределению там еще есть дополнительную опцию про них тоже будет не лишним сказать вот смотрите есть опция тайм аут тайм аут атаман передается миллисекунды так вот внезапно это время не на вот это действие не на это перераспределение а это просто время на инициацию процесса перераспределения то есть если вы думали что здесь секунд у вас все произойдет нет просто за 10 секунд у вас зашит улица вот этот процесс перераспределения ну не зашит улица если время истекло там казуки перу например не удалось за коннектится здесь важный момент вот это распределение это фоновый процесс который происходит где-то фоном и поэтому он обязательно нужно проверить в реформа в каком он состоянии сейчас находится вторая опция полезна это тротлинг вы смотрите вот у нас начнется такое великое переселение с одного места на другое портится это означает что мы начнем утилизировать диски мы начнем утилизировать сеть и можем просто под завалить наш кластер большой нагрузкой и вот как раз важно правильно подобрать значение для своего кластера но тут есть важный момент и под такой довольно серьезный подводный камень если у блин укажите вери файн танталит настройки троттлинга но не только те которые вот были указаны здесь явно а вообще любые которые вы указывали свой кластер у вас может быть миллион причин для того чтобы указывать своем классе тире тротлинг ну разные бывают ситуации вот эта опция вери файн по 100 как завершится перераспределение он удалит вообще все соответствующие настройки троттлинга это обидно вот это можно поделать в кафка менеджером тоже вот интерфейс кафка менеджер тут специальность большая большая кнопка generate parties in the silence то есть все в принципе все подробно написано чтобы можно было понять без документация всё происходит мы понижаем к и мы видим можно указать брокеры на которые надо перераспределить данный топик и просто сгенерировать ему че дальше-то можно опционально указать реплики чем фактор по умолчанию будет использовать текущую рипли конечно фактор с которым был топик уже создан вот это можно сделать также можно не полагаться на то как автоматически решит к в команды распределить данные можно это явно указать то есть мы можем в таком интерфейсе мышкой по кип покликать указать какую партию на какой брокер нужно распределить ну данном случае у нас вот топик с тремя партициями укажи но и там соответственно 3 реплики потому что реплики что фактор 3 можно по по распределять в принципе все что для вас лишь бы до можно было не пользовать какие-то к терминалы нокий ландыша движемся дальше в принципе есть еще некоторых лично инструментов который позволяет это же делать листиков cottus от linkedin исков к youtube про которое я говорил вот макрос из него пользуемся rolling ли стартом и еще кафка kit но на самом деле там в горшочек не вари таких инструментов очень много но если вы вдруг решите еще свой писать то все клёвые имена уже заняты движемся дальше перемещение партиций по дискам то есть до этого мы портится перемещали по брокером а давайте посмотрим вот новый диз добавили как это перераспределить разумеется автоматически вам никто ничего из коробки не дает спасибо что вообще сделали возможность перемещать как то начиная с версии 11 вот при этом что важно вообще кафка когда вот начинает топике портится как-то раскидывать по дискам она это делает не по объему занимаемого места а по количеству в принципе тоже вроде бы логично но не котором бы хотелось чтобы можно было еще как-то учитывать размеры который занимает вот эти данные но к сожалению этот пока keepon встать и дискос но и непонятно когда нибудь случится или нет но так вот как это происходит здесь возвращаемся к нашему страшному джейсону тот же самый кафка reasoning partisans здесь обязательно опции новое дополняется брокер лист 123 без ничего не заработает вот и да тут все примерно тоже самое но добавлять еще немножко джейсона в каждую строчек мы указываем лог dir-100 есть мы указываем для каждой реплики явно куда нужно будет сложить наши данные вот такая история до джейсон еще стало больше что может здесь пойти не так ну во-первых смотрите если мы решили вот так вот переселять между дисками очень много данных то у нас утилизация дисков ушла вверх у нас такая полочка соответственно новые данные писать то вряд ли получится это может быть проблемой вот в принципе это настраивается опции нам реплика alter лог ders срез который настраивается для каждого брокера сервера properties и она указывает сколько потоков можно занять воды вот такую операцию перемещение данных между дисками и соответственно если указать значение не очень большое the ass нагрузка будет не сильно мыши по умолчанию это настройка равна количеству лог ders то есть сколько вы там пока прописали дисков кафки столько будет использоваться потоков но это нанесем логично когда вы хотите данные переместить ровно на один диск и просто все диски с ним со всею начнут у него писать но и понятно что ему будет тяжко еще могут быть дела не очнется недавно как раз для специально докладом надо было закомитить зарепортить бак ставку в общем мы пробовали вот такое делать перераспределение партиций в рамках одного брокера по разным диском и просто у нас развалился это это дело растворилась по exception-ы и restart не помогал единственно что получилось это просто выключить брокера удалить все что он там на создавал запустить его заново но он такой счастливый запустился и все стало хорошо одно довольно долгий простой получился у нас у брокеров просто надо иметь ввиду там принципе можете почитать описание этого бага и еще важный момент разные диски и структура каталогов она общей беде приведет почему к беде и смотрите вот там были джейсон и где вы там набиваете руками вот эти все свои директории если вас разная структура на разных дисках или на разных брокеров вы явно точно запутаетесь где как должно быть и точного случится неприятность золото так и снасти разного размера диске то тоже когда вы начинаете перераспределять вы перед глазами ты видите свои вот эти структуру но вы не знаете сколько там данных у вас находится и какое распределение ну и поэтому лучше когда у вас ноты к кафке они такие однородны это будет конечно лучше всего на и однородный по именно по дискам по количеству и по объему дисков движемся дальше ещё про одну полезную штуку это preferred лидер election то есть смотрите если у нас вот что там и с кластером делали у нас лидеры абы как поразъехались на другие брокеры то у нас может получиться так что какой-нибудь брокеры там лидер вообще везде им очень тяжело в принципе в кафки есть набор опций который позволяет это дело полечить это of the leader balans enable по умолчанию нутру она получается 1 300 секунд это проверяет и применяется если у нас вот такой дисбаланс по брокером от 10 процентов и выше но важно то что вот это редон readonly настройки если вы их решите поменять то вам придется делать rolling рестарта кластером это не очень хорошо поэтому в принципе для нас по заботе о нас позаботились и сделали скриптик кафка profi 3 а про кафка профер эта реплика election здесь также указан bootstrap сервер и еще один жетончик передаем уже в другом формате в этом сезоне мы указываем топик партицию которую нужно перенести на нужного лидера вот но к счастью если указать без посту json файл та команда распорядиться на все партиции кластера и тогда нам достаточно просто указать bootstrap сервер и все внезапно заработает все будет хорошо в целом это можно так же сделать кафка менеджер там тоже есть большая огромная кнопка ранд preferred рипли collection мы нажимаем и там все нормально происходит но нужно увидеть что последний раз это делалось 29 октября и на там же где то примерно завершилась в один момент времени видимо там все было хорошо с кластерами нажали просто так ладно движемся дальше к перейдем к hell с чеком но во первых для чего это нужно но смотрите часто мы все задаемся вопросом а вот общий кластер но в целом то работает а конкретный брокер работает как вас задержка общее между чтением и записью вот как мы решаем эту проблему мы создаем тестовое сообщение как это выглядит тут у нас есть продюсер он создает специальное сообщение отправляет в кафку а из кафки концу meriva учитывает но и мы смотрим вот мы записали в какой то момент времени сообщение смогли прочитать ну вот у нас есть когда записали прочитали разницу вот мы получили некоторые лэтэн сыну и во-первых если в принципе у нас удалось записать прочитать значит в целом все работает вот мы такой штукой пользуемся но понятно что не все делают на коленке а пользуются какими-то уже готовым инструментами есть кафка монитор от компании linkedin хавчик он устроен следующим образом она 1 да вот так вот and and land and sea умеет читать ну и получается кафка и выберите то есть он может проверить доступность каждого отдельного брокера то есть запись еще не на каждого из брокеров архитектурно это выглядит следующим образом картинка взята из документации кафка монитора то есть у нас есть некоторая концепция апликэйшен сервис который внутри плетей шина естественно можем сервисом считаете такой-то продюсер отправить сообщение в кафку и соответственно прочитать из кафки и посчитать например на эту разницу то есть вот примерно такой сценарий может быть из бонусов эта штука умеет в мультик кластерную кафку когда у нас один кластер реплицирует дублируется в другой кластер с использованием мира мейкера работает следующим образом у нас есть кафка монитор который отправляет сообщение в афк афк а кластер один он реплицируется на 2 и соответственно из 2 2 кафка монитора мы можем посмотреть когда мы это закон сумели и таким образом мы можем понимать на скутерах в принципе работает mirror maker или не работает а второе мы можем понимать как быстро он работает как быстро данные из первого кластер попадут в 2 какую любого другого инструмента кафки тоже есть различные альтернативы похоже нашлось кафка hellsing ничего про него не скажу в принципе кафка монитора для этого достаточно ну или для каких-то просто сценариев на коле ночные решения там с использованием джей метра заходят на уран движемся дальше вот про консьюмер групп лак мониторинг здесь наверно немножко на скале pci как это все устроено что было понятно что происходит вот смотрите у нас есть топик с тремя партициями там уже есть некоторые данные записаны есть парочка концу мира в которой объединены в группу концу мир начинает потреблять данные настройки начинает читать сначала там 1 концу мир прочитал из пары портится дам другой консьюмер прочитал сообщение они соответственно прочитали за к метели докуда дочитали и дальше начинает читать и коммитить но данные у нас постепенно дописываются в кафку нас получается дальше дальше все это движется читать читается и смотрите вот текущее состояние вот этого записи и чтения она образует некоторый лак то есть насколько каждый из контейнеров в сумме отстаёт от головы до то есть от самого самого самого свежего сообщения так вот этот лак и неплохо в мониторить почему его неплохо в мониторить но первых понимать вообще как быстро концу мир читает данные второе а успеваете консьюмер читать данные за продюсером смотрите если продюсер пишет данная быстрее чем концу мир за ним читает ну скорее всего мы делаем что-то не так и у нас ничего в итоге не получилось просто продюсер уйдет в закат и консьюмер просто никогда его не догонит вот в целом здесь можно назвать искать что окей у нас есть метки в клей эти то есть если кто то пользуется допустим жало клиентам там исков к концу мир который при портит свои метрики это все так и все в принципе здорово но важно а что делать если вдруг с концу миром что-то приключилась но там упал тормозит он ищет данные сказки прочитать не может то есть мы никакую метрику не получим не сможем понять а где в общем мы находимся и как там еще состоянии вот поэтому неплохо бы иметь какой-то внешней мониторинг для этого но опять же кафка концу мир групп стандартная туза и на мы указываем группу от по которых этим получить данные на выход получаем вот такую табличку топик partition текущей офсет то есть да куда ты читал консьюмер где у нас заканчивается топик the partition где последние данные были записаны продюсером ну вот эта разница между ними но информация тома концу мире но нас понятное дело интересует этот лак на какое значение мы отстаём ночи что мы с этой штукой на коленочки сделали мы просто взяли и вот в этой табличке и посчитали сумму вот этой и отправили в почитали сумму вот эту и отправили в графит один на выходе мы получили информацию о том в каком состоянии у нас каждый из концу мир групп находится в принципе это удобно чтобы так отслеживать в каком состоянии но это не всегда бывает полезно ну давайте посмотрим на примере к в команду как это работает у нас есть консьюмер группа какая-то и вот у нее здесь сложились можно увидеть metrics файл топик из которого читает это концу мир группой этот лак минус 346 не надо пугаться этих отрицательных значений сейчас попытаюсь объяснить откуда оно взялось здесь уже когда я перешёл на другую страницу изменил значение 300 минус 342 она складывается из отдельных вот этих строк partition вот этот тот самый лог says консьюмер офсет и вот разница между ними ну почему значение может быть отрицательным дело в том что эти две метрики они берутся не атомарном и понятно пока мы одно метрику брали одно значение там второе вот временному шло дальше и мы когда вы взяли там но они не совсем консистентной был но важно то что в принципе в целом мы будем поднимать растет это значение не растет естественно там около нуля или отрицательно но начал хорошо и концу мир успевают читать вот есть более такое технологичное решение для этого это burrow тоже клинки дэна это такой уже дтп с 35 то есть он уже некуда метрики сам не репортить но через rest позволяет их отдавать чтобы можно было их забирать и что на потом с ними делать что он умеет он умеет делать такой time винду анализ для определения статуса консьюмер группы но смотрите вот текущее состояние 2 логан очень сильно скачет и она ни о чем не говорит тут важно смотреть больше в тренде той смотрите мы взяли за какой-то большой промежуток времени и смотрим как ведет себя концу мир группа успевает она читает не успевает вот как раз вот эти вещи позволяют делать когда мы окошечками такими читаем и смотрим это штука умеет делать уведомление на почту эпоху ттп в одно если мы хотим из нее метрики забрать то пользователям prometheus будет все очень хорошо там есть неплохой reporter который позволяет отправлять сразу в проектов prometheus данные вот по аналогии сделан графе 3 порт график графит экспортер ссылка на него есть но мы пока его не пробовали кроме того бюро ул еще имеет некоторое количество интерфейсов то есть там есть специальные тузы которые позволяют вот эти вещи уже объединять в красивой графики можем на графиках смотреть как у нас изменяется в принципе без необходимости reporting а вот этих метрик в какие-то другие специализированные решения как вы понимаете альтернативы тоже для этого есть сейчас мы немножко поговорим когда-то давно воланда решили сделать лучший бюро сделали свою ремор у но по-моему последний там несколько лет они уже забили и в него не contribute to бюро он в принципе развивается и разрабатывается дальше вот и сыщиков к всех монитор кота решает похожую задачу вот поэтому там можно что ты зато выбрать и посмотреть что подойдет лучше вам итак давайте к выводам перейдем той смотрите есть стандартный touring который да где то плохо но в целом он решает свою задачу и в принципе на старте это вполне достаточно чтобы начать что-то делать с кластером маст хэв штука это кафка менеджер мы сразу можем через м зайти посмотреть в каком состоянии кластер топит портится все что угодно если мы работаем с большими кластерами где нужно делать rolling restart аренда ролик из так нужно делать там при обновлениях по изменений конфигурации это тоже маст хав вещь поэтому очень рекомендую над еще две такие опциональные это штука для мониторинга лога концу мэров и штука которая отслеживает общее состояние кластер и там работает он не работает из этих heels чеки в общем эти вещи очень рекомендую и спасибо спасибо григорий это был григорий кашель и в контр екатеринбург у нас есть семь минут про визир ванную гостиную и посмотреть что же нам прислали нам прислали довольно много всего интересного как решается вопрос отделение реплика ционного трафика от трафика консилеров и продюсеров вашем случае или в общем есть но мы мы никак не отделяем трафик в данном у нас может быть это не совсем правильно а как это в принципе можно делать у нас ноды с кафкой у них есть несколько сетевых карт соответственно мы можем настроить таким образом чтобы между брокерами трафик шел по одной сети вовсе терке для клиентов шоу трафик по другой ставки это в принципе хорошо изолируют трафик и этого вполне достаточно будет для работы окей спасибо есть небольших ли важный вопрос а почему же не перешли на prometheus хороший вопрос но самое главное то что у нас это графит исторически штука то есть она уже очень давно и о нас очень много инструментария под это написано в частности это майра open source ный продукт который мы развиваем и мы продолжаем развивать вот ну не знаю может быть когда-то будет prometheus не знаю пока сложно сказать но здесь пока вас просто все устраивает нет никакого специального резона почему бы и нет ну типа работают для хорошо действительно антон вайс 10 на конференции если если кто-то хочет перейти на frame to stop можно обращаться к нему как получать метрики покончу мир групп на кафки версии больше единички ну вот первое это вот как раз использовать буру в принципе но это по логам можно смотреть это вполне неплохая штука но так в целом в самих приложениях тоже есть метрики и можно там смотреть то есть каждый но если вы используете java клиентам неплохо метриками покрыта именно сам клиент кафки спасибо а кстати да еще пользу случаем скажу вот у меня многие всякие разные штуки него шли по тематике докладов в него можно будет завтра вечером прийти на дэмо стоящих по моему в 635 вот там будут кафка позора у меня и за правильные ответы на вопросы будут вот такие вот прикольной футболочки кавказ и кью вот поэтому приходите безусловно конечно я думаю что давай кидай второй раз тут два еще одно давай еще одно тот кто кушает геркулесовую кафку каждый день по утрам рулит то ты бы тут не сидела ты хочешь сказать приходилось что еще нам так нравится так однако между тем у нас у нас есть еще время сейчас я ещё посмотрю потому что у меня из-за этой ловли сбились вопросики так вопросики отсюда да и напоминаю до что наш собственный бот позволяет задавать вопросы спикерам ехать сюда зачитываем так исходя из вашего опыта какое оптимальное соотношение количества сообщений количеству брокеров в риш ими event бас вот это очень сложно вопрос ведь зависит от многих вещей например какой у нас реплики шин фактор используется от того какого у нас количество брокеров какой у нас объем своего сообщения и сообщения могут быть условно там пара сотен бы это могут быть дела по этой десятки килобайт тут нет какого-то однозначного ответа на все тестировать и пробовать вот мы для себя тестировали пробовали да мы пришли к выводу что там порядка 100 150 тысяч сообщений вполне себе брокер одному хватает и 1 класс терри из девяти not у нас сейчас трафик порядка миллиона может ближе также полутора миллионам сообщение в секунду у вас условно говоря вся эта конструкция она одна и вы сбалансировали и ее живете на ней ли у вас есть много разных там песочнице или под под разные подпроекты разные вы подбираете эти вещи каждый раз заново ну да вот то есть там на человек слайд показывал как мы используем кафку то есть каждый из этих сценариев это отдельная кафка даже где-то не 1 то есть это где-то там стейджинг который все живет отдельно на котором могут разработчики экспериментировать но и где они если вы обрушит ну ничего страшного но и параметры собственно соотношение тоже падают они таким образом она там теста тестовых окружениях на звездные рингах затем возможным с помощью мониторинга обратно единственно что добавлять на наших объемах там сложно держать такой стейджинг еще отдельно потому что она полностью инфраструктуры повторить да еще и нагрузку аналогично сгенерировать поэтому не знаю мы можем делать не самую правильную вещь мы тестируем в продакшене поднимите руки кто еще тестирует продакшене все нормально ты в правильном месте у нас наверное заканчивается уже время спасибо большое"
}