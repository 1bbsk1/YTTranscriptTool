{
  "video_id": "kTc4W5XOC3g",
  "channel": "DevOops_conf",
  "title": "Сергей Курсон — Observability of applications in AWS",
  "views": 108,
  "duration": 4388,
  "published": "2020-11-20T04:55:50-08:00",
  "text": "сегодня будет о мониторинге и объем ability на это был я свободен и дпс в чем собственно разница что это такое какие есть инструменты как-то все запускается как-то все работает пару слов о себе да то есть я да и табло с я занимался fuse так разработкой для страховых и а эти клиентов в с начиная с простых вещей вроде написание кода просто заканчивая созданием полного цикла создания высоконагруженных продуктов условиях нескольких команд в разных точках мира до том числе подбирал командует на маврикии обучал этих ребят налаживать процессы как сетевого да и но и сам работа на продукты в том числе всех разрабатывал о чем мы сегодня с вами поговорим давайте так вкратце обрисую картину то есть для начала поговорим об общих концептах для чего все это нужно перестать мониторинг обсе рабиль и т.д. из чего он состоит до покажу небольшую ямку того продукты с которым мы будем работать конкретно тот продукт над которым я навесим кучу кучу мониторинга и который показывает мне кучу вещей внутри этого продукта до потом перейдём уже конкретно к инструментам то есть это основной инструмент сегодня глава дочь это была скала дочь покажу демку по работе с метриками и мне после чего пойдем уже к обзор ability и я покажу демку инструментов собственно которые дают нам обзорность на проект да ну давайте потихонечку пойдем то есть начнем с простого и потихонечку улыбнемся в детали во первых почему у нас мониторинг важен в принципе первое это видимость состояние системы то есть я думаю что нам не нужно напоминать о терминах вроде солей да когда мы весь не укладываемся в аптайм там и собственно должны денег то есть мой коллега допустим он работавший ранее в крупном велика британском ритейлера сказал что у них была такая очень интересная ситуация когда за 50 простое они должны были выплатить порядка 100 тысяч фунтов стерлингов вот если это собственно тот по сути да это service level agreement то есть уровень сервиса который ожидается от вендора конкретно от вас если вы предоставляете продукты и этот сервис но это уровень сервиса да с метрик для этого сервиса контролируется он также определять штрафы и пенальти если метрики на руки ну вот назад к примеру там со 100-тысячным футов фунтов до дали обладая метриками мы по сути обладаем уверенностью что когда мы вносим изменения в код ну или в инфраструктуру какой-то момент опять же инфраструктуру на сейчас как код работает там и эти изменения мы видим влияние этих изменений давольно времени до того как новости у нас дойдут до начальства как пример мы запускаем в рот новую версию и у нас каскадом начинают расти или тесте ответа мы видим эту цифру на слоги замечательно но мы понятия не имеем где это произошло у нас в одном сервисе допустим переполнился диск и он по цепочке зависимости дает он дает раз задержки без нормального 3 лессинга в реальном времени на поиск таких ошибок уходят ну реально сутки уходят дали реальность у нас сейчас такого что клиенты они сейчас по сути очень учила не обмена информации да и последнее что нам сейчас нужно это чтобы наши клиенты нам сами сказали что у нас сервис лагает до 0 и вообще лежит поставим себя на место клиента fda сколько раз мы там бросали покупку на полпути просто потому что у нас там будет сайт крыса слишком долго да даже даже секунда хватает чтобы уже кучу клиентов усло или те же клиент который перестают использовать мобильное приложение просто потому что она падает ну либо либо она постоянно требует обновление там каждую неделю каждый день пример допустим да вот реал там его игрушка где нам нужен очень быстрый отклик и миллисекунды могут накапливаться между между микро сервисами или клиенты для nine игрушки которые допустим группа вконтакте да или в другом мессенджеры они общаются друг с другом и если у нас игра лагает то это мгновенно видно по всей стене и репутации в игры страдают сходу ну и ещё один важный момент что по сути производительности аптайма но у нас имеет прямое отношение сейчас я чувствует бизнес ну просто потому что у клиента сейчас есть 10 разных вариантов которые делают схожие вещи под посредственная работа она придет тому что ну клиент просто возьмут и выйдут в другой инструмент однако у нас мониторинг хоть и важен о что и как мы мониторим она очень сильно различаются с тем чтобы мониторе и там 10 15 лет назад требования изменяются под влиянием изменения подхода к инфраструктуре в целом философия разработки к растущим влиянием пользователя опять же на то есть во первых микро сервисные архитектуры они изменяют системы с нескольких сильно связанных компонент насильно распределенные мульти компонентные системы не как некоторые из которых могут быть использованы разными приложениями и жить в разных аккаунтах это кстати часто кейс для облака тот же допустим мульти региональные динамо db наша но у сиквел база данных да она не могут быть реплики в разных регионах да опять же не могут быть и это кластеры контейнеров которые объединены в федерацию то есть ну кубер допустим да возьмем или или не общаются там друг другом через шины событий а через сообщение порно опять же какие мульти региональные флот и для гейминга где нужно обладать общей картиной как как допустим на реклама дала нагрузку на сервисы в регионах но и прочее да ну и не надо забывать что есть у нас появился новый новый сервис нужно быстро ввести его в строю еще и если вести соблюсти это все кстати не говоря о том не говоря уже о росте коллить количество подключенных устройств вроде aiuti устройств которые уже необходимо мониторинг ну и как минимум собираетесь технологий метрики добавим ко всему и ко всей той красоте мультиаккаунты и среды в чем тут суть сейчас большое количество организации у нас набирает оборот мульти аккаунт на я среда там допустим под каждый проект под каждый ну или даже под каждую среду вроде df и prada отдельный аккаунт видимость между аккаунтами опять же мало того с приходом облака у нас появляется доступ к большому количеству ресурсов ресурсов по требованию а то есть это еще два но виртуальной машины до группа масштабирования сервер лес какие-то короткоживущие ресурсы которые там живут иногда просто минуты и все они требуют того чтобы доступ к данным был как можно быстрее понятней часто на основании там группировки по тегам но еще чем-то итак высокоуровневого очень важно начать такой вещи как план мониторинга то есть который собирает информацию нашего решения в это был с таким образом что вы можете прогиба жить отказ многокомпонентной системы если он возникнет план по сути должен отвечать на вопросы первых какая цель нашего мониторинга скажем вы хотите получить цельную картину ваших ресурсов или создать уведомлений на каждый чих то есть вам уже не сайты какие ресурсы вы хотите мониторить и как часто какие инструменты мониторинга вы будете использовать да кто будет выполнять задачи по мониторингу то есть скажем если у вас там команда которая готова сидеть 24 на 7 смотреть дешворда или будет 12 человек который там за автоматизируйте это дело и автоматизирует alert этом anomaly мы прочь опять же кто будет то должен быть оповещен в случае проблем то есть тот кто contribute to plunder то есть эти вещи нужно нам понятий нужно поэтому этим вопросом нам составить план сначала давайте быстро и описание что такое вообще упомянутая обзор ability до исходя из термина durability это ну обзорность нашей системы это способность понять состояние системы основываясь на водах или выводах водах и выводах да то есть если вы можете понять нет что происходит а значит она обозреваем а то есть конкретно моя система или продукты могут в ответа get запрос вернуть 200 ну круто но мне нужно знать что произошло по пути в моей системе чтобы я этот кот получил то есть ну черный ящик собирай метрики которого я могу сказать что у меня происходит внутри сама тема намного сложнее чем просто собрать немного данных и поставить там даже бог на пару метров до куча сервисов сейчас в это был с они предоставляют инсайты ресурсах допустим тот же динамо db предоставляет метрики там успешных запросах с ошибками lighting и ну как это измеряет сам сервис однако когда мы используем системы которые вы используют эти самые сервиса нам нужно гораздо больше видимости в то как ведут себя ну собственно наш механизм нужны даже отдельные сегменты кода иногда которые записываются сколько времени заняло выполнение конкретных задач ну просто пример если мы там звоним в ждет пойти сервис и нам нужно понять сколько полетать он отвечает да опять же нам нужно будет какие-то метаданные изнутри кода чтобы понять какие данные были связаны с каким-то запросам до в противном случае у нас просто один большой черный ящик который не понятен а вот на картинке сейчас архитектура проекта которую которую мы будем рассматривать то есть проект который я собрал облаке здесь используется множество различных сервисов контейнеров внешне механизмы например до вызова поискового механизма и внешнего сайта да сейчас он развернут на elastic контейнер сервис и elastic обернитесь каберне this service & co с майкой сейчас запущен основной сервис да там веб-сервис и на из есть несколько фольгой task-ов которые отвечают за поиск платежи и но и прочие такие вещи там давайте я покажу кратенько кого рода проект к нет ни и ближе так вот проект очень простой и интересный но занимательный его суть заключается в том что мы продаем зверюшек людям которые хотят их забрать домой это практически в магазин но очень очень симпатичный то есть мы можем выбрать щеночка мы можем быть ищет этих щеночков как-то отсортировать какие нам интересны и да и мы можем щеночка себе забрать домой не обязательно щеночка кстати можно котиком уже кролика вот есть какой-никакой пойман есть рейтинге да ну такая достаточно незамысловатая вещь интересно то что у меня сейчас запущены два этих проектах 1 запущен в во франкфурте и и централ 1 2 у меня запущен в другом аккаунте и он запущен в другом регионе конкретно в ирландии вот такая простенькая к и будем работать сейчас кстати на этот сайт подано нагрузка сейчас ее уже опрашивают давайте вернемся к рассказу и пойдем потихонечку дальше и так начнём основного инструмента которые мы будем рассматривать его не так ладонь эти что это основной инструмент выдумал я сейчас для сбора метрик логов их анализа и интеграции со сторонними системами то есть что интересно до ноября 18 года cloudwatch больше рассматривался нашими клиентами как do the storm большого отказоустойчивый который мониторил за 18 на показатель 18 года порядка одного квадриллиона метрик триггере а больше трех 3,9 триллиона событием жестов там порядка 100 петабайт налогов в месяц но все равно это был просто do the storm большой-большой такое ted астор да но с ноября семнадцатого года значечек blogs логин sites а затем инструментарий начал активно очень развиваться и добавить вещи вроде кросс аккаунт дашбордов кусок own данных до им едет метрики inside из контейнеров добавить канарейки ну и кучу кучу полезных дополнительных механизмов а сама суть кладовой заключается в том что без собирать данные мониторинга и операционной деятельности форме логов метрики ивентов после чего их визуализировать использованием автоматических дашбордов но таким образом чтобы получить обычный вид ресурсов и ws и он примет the premise тоже давайте чуть как глубже копнем чтобы понять механизм операционной готовности во-первых мы собираем наши данные метрики и логе крутится у нас там сайт корф люди контейнер запущены демонстрации не знаю unlock черри логе собирая там кладут шаген неважно не суть затем возможным мы и метрики каким комбинируем преобразовываем будь то механизма ластик search автоматически математические выражения cloudwatch metric фильтры или еще какой то механизм затем с верными метриками и статистикой вы можете уже строить графики чтобы был чтобы быстро получить общую картину и все ли у нас цены в порядке здесь уже используются либо кастомный дашбордов cloudwatch либо как вариант подключается графа нас data source on data source вам как лава что само собой мы мод мы не можем сидеть там и смотреть на тебя сбор до 24 на 7 поэтому оповещения жизненно необходимы для автоматизации проблем решение проблем и затем когда мы исследуем ошибки или анализируем уже паспортом мы используем логи чтобы найти реально детальную информацию чтобы добраться до причины тут уже важный механизм и корреляции метрик метрики логов но говоря человеческим языком чтобы не искать ошибки блога с использованием range использование поиском по времени до 0 и какие-то догадок а иметь возможность получить ответ какие именно ошибки привели ну вот как конкретно этому всплеска 500 их ошибок очень кратко как работ и как вообще используется клал дочь как этим работа идет до то есть во первых это естественно консоль зашли визуально в консоль там тебе даже берды и все что необходимо собственно визуально до целой наш com онлайн команд ником онлайн интерфейс и пей и ну и собственно sdk да но опять же если очень хочется можно искал двача делать себе tail логов ну или или использовать этот party решения которые подключаются кладовочка аксу этот astor давайте по кускам этого слона есть начнем с сбора метрик это река логов по сути да три кило гедонизм оповещения то есть конечных инсов допустим два виртуальных машин или он принес метрики и логе они собираются через кола дочь агента что такое агент по сути это приложение которое ставится либо на виртуальную машину ну либо еще до смотрит налоги и ну или получает их напрямую из приложений и отсылает эти логе уже складочек агент отдается конфигурационный файл который по сути является джейсоном в котором мы говорим собирая данные из вот этих конкретных лог-файлов какие-то метрики тихо их в какие-то конкретные лаками три группы в данном случае у нас пример реального сниппет так ладно чагин то сейчас достаточно просто подключить системные метрики также как и подцепиться к файлам логов для того чтобы стримить их в кладовой как пример история когда у нас допустим разработчики хотят использовать классический tl диалогов с конечной машины но в таком случае потребуется автоматизации на уровне каждой машины конечно можете стремиться локаль налоги можете настроить метрику который автоматически оповестит вас о проблеме перехватив там информацию из логов через этот фильтр в данном случае вот конфигурационный файл который достаточно просто описан ну достаточно просим опять же его можно раскатать на виртуальной машины при помощи скажем вещей таких как шеф по пятам систан с менеджером символ ну и так далее далее контейнера первое мы говорить просто виртуале машин час за контейнеров тут решение масса на самом деле потому что он примет решение this тоже работают в amazon часто использует флинн бит и amazon это был сам поддерживает филин бит как проект то есть эта аналогия стад сделок процессор и forwarder для эфес недавно был запущен механизм так называемый file and shit по сути такое это интерфейс с для многим использующего концов проектов и мбит iv людей который позволяет нам стримить плоти большое количество различных сервисов носят party там в партнерские решение да вроде там сама logic там to the dog мы работаем с проектом file and как и наши партнеры поэтому само решение она но по тексту большое количество различных направлений то есть можно даже там в ваш lk стек стремитесь очень нужно да там или в кино из допустим и логе по сути можно направлять при помощи тегирования может направить направлять использованием регуляров чтобы сократить стоимость том числе да потому что не все логе иногда нам нужно отсылать в одну и ту же мир в одно и то же направление также разделение логике логирования и приложения допустим это отдельный плюс для разных команд одна из которых допустим работать над лугами 2 над приложением как это работает общем исчез при использовании факт г-н страйвер а std out логе контейнера через там через unix socket направляются на сайт как контейнер флинн бит который уже собственно использую конфигурацию тоска которая транслируется в конфигурацию френ бит направляет логе в нужное направление но тоска эта аналогия нам an anal аналог по да да в кубе есть закон по статье но у меня есть ссылочка да потом можно будет ознакомиться подробнее с этим моментом в данном случае у нас пример конфигурации free-lance здесь видна в какие направления мы сливаем ноги это означает что есть совместимость разными сервисами до который мы используем даже если это полностью управляемый сервиса вроде фар gate эта конфигурация для исчез и власти контейнер сервис и далее снизу видно что нужно ещё добавить редко сайт карфи любит сразу оговорюсь пока не забыл это ластик контактировать по сути наш регистратор контейнеров для тех кто не совсем знать что такое да по сути достатке стараться контейнеров зам вся эта весит механизм он работает для и кресле ластик абернати сервиса для повернется по сути устанавливается сайт корф в ад или допустим можно поставить как демон сет на хвост уровня и после чего дыма на нас демона собирает логе из варлок используют конфигурацию и sconfig map чтобы отослать блоге в нужное направление дополнительно есть возможность собирать метрики из прометея допустим через конфигурацию кладу агента для того чтобы собирать эти метрики там в кладовой но здесь именно благодаря гибкости и гибкости настройки направлений фарингит флаги можно направлять через допустим тот же файл hosts на s3 для аналитики до в либо можно пророчить для и где использовать инструменты для анализа а м.ф. на самом деле очень интересный механизм про него мало кто сейчас знает сейчас по сути у нас для для записи хайгардена лики метрик используется механизм который позволяет высылать метрики не отдельным потоком а в качестве части логов он так называется им видит метрик формат им видят встроенной да то есть его суть заключается в том что когда мы отсылаем логе то в них можно встроить кусок с метриками джейсон формате таким образом мы инструктируем cloudwatch забирать метрики из этих логов для этого нужно высылать с логом пределенный заголовок там и x amazon лакс формат из сочи в случае допустим с лямда instrumentation это уже включена да и достаточно просто писать логе в стаде out по сути этот сейчас инструмент он жизнь в далее будет упомянутом инструменте cloudwatch контейнером сайт котором разговорчик hd чтобы использовать mf есть два варианта во первых можно использовать клиентские библиотеки сейчас они есть на в питоне или на но джесс а второй вариант это использовать это руками собирать логе до включать них нужную информацию в правильном формате из отметить допустим через блок events и но или через агента cloudwatch чтобы это все попала в кладовой вещь на самом деле очень интересно почему вот четкий вам пример да есть тысячи подключенных устройств каждый из которых шлет логии метрики если они будут слать метрики отдельно то они ну вот реальный кейс они тратили там порядка миллиона доллара в месяц какие-то колоссальные суммы до это очень много на самом деле и а вот когда они перешли на м.ф. наши наш клиент и да они начали использовать и mr метрик фильтров в том числе да то они тратили старайтесь дали на порядок меньше то есть при этом они получают хорошую точность и унифицированный слогов в том числе ну в метриках и ну опять же стоимость до падать там на порядок в противном случае нам придется какие-то кастомные метрики выковыривать из логов через допустим инструмента relax in sight либо фильтр настраивать либо еще что то то есть если такой инструментарий который позволяет автоматически парсить метрики из логов это очень-очень на самом деле удобно а далее допустим нас пришли логе ладно без без metric фильтров нам нужны какие-то кастомные метрики из них выковали включается механизм метрик фильтров называемый это механизм который позволяет извлечь из логов данные с помощью выражения да с помощью фильтров преобразовать эти данные в числовое приложение и построить их уже построить по этим числам по этим цифрам да какие то какие-то метрики хороший кейс например если у нас несколько команд пихают в логе свои метрики и какой-то идентификатор таким образом operations они могут разделять данные мониторинг вот у нас пришли данные дальше нам нужно настроить даже борды ну данном случае у нас здесь борты дмитрий фильтров то есть нас пришли логе по ним были настроены метрики мета-фильтр до которые извлекли нам какие-то числа выражения злаков и и вот ребят построили у нас дашборд в данном случае у нас показаны как как у нас данный вообще через систему проходит плюс что интересно такой забавный pattern мы недавно выяснили что вы коснулись бордах очень полезно добавлять какую-нибудь полезную информацию сверху данном случае у нас видно что цвет ребят давай не большевики на полную веке чтобы но новые люди которые приходят на проекты или там уже существующие люди которые там заднем забыли что они насобирали они могли там сами себе посмотреть что у них написано и ну вообще разобраться в чем о чем о чем этот дашборд в принципе да в чем важность вообще мониторинга дешворда в данном случае общем данном случае принципе да есть у меня пример допустим когда большой ритейлер он не искал решение проблемы нет ребята они просто не настроили система оповещения да не настроили нормальный дашборд них не был никополь еще не обманывали в итоге в один рабочий день слава богу не в черную пятницу из-за переполнения диска власти ксир читать сайт начал затухать и ушел down time но из-за того что у них по сути подход к мониторингу был ручной с минимальным набором oled tv оповещений та команда узнала что сайт лежит там через несколько часов в крупном ритейлер за мной в принципе тоже такое случалось на ранних этапах сколько масла построен на схеме взаимодействие разных систем до включая там стима очереди оповещение об остановке у меня не были настроены и как это пример вот worker допустим который раз гриба оповещения для пользователей в какой-то момент он просто встал начали скапливаться сообщение в очереди проблем было там нескольких сообщениях которые были плохие до грубо говоря в итоге не было ни был оповещения что в итоге была добавлена но выводы тоже были сделаны до еще кстати важный keys в этом плане это но когда допустим клиент хочет решить у среди он хочет получить какой-то усредненный мониторинг по допустим место сам в комбинации на аккаунте той чтобы видеть если в целом ресурсы потребляют больше нужна вода да кстати немножко назад к этому примеру было несколько интересных примеров когда можно рисовать такие большие даже варды допустим приложений нас висят офисе большая картина с приложением да и показано из каких точек мира на это приложение идет трафик то есть это полезно допустим для adidas определение что у нас ушел 90 полезный механизм для получения нам олей по сути и для наблюдения за известными метриками с непредсказуемым результатом с непредсказуемым поведением это она детекция номоли до его суть заключается в том что основе машинного обучения для метрики строится окно допустимых значений и ширину этого окна мы собственно задаем сами что только значение выходит за окно настраивать зак но она настраивается оповещения ну или что то еще да я этот механизм сейчас в демке покажу вот до после того как мы все сделали все на мониторе или все собрали нам нужно каким-то образом действовать но здесь достаточно простой механизм ачиве видно здесь уживаются чаще всего около 2 ч вентс о которой 3 ряд уже какие то какие то задачи либо это идет оповещение на всех заинтересованных лиц либо идет оповещение там снег кидается либо либо выполнять какое-то автоматическое действие например если у нас машина там шали дата можно допустим эту машину остановить автоматически сделать с нее snapshot отложить этот сушат куда-то и там перезапустить новый машин а есть несколько полезных практик и интересных вещей которые мы наблюдаем ну и вынесли из нашей практики которые думаю будет будет интересно и полезно да и всего вышесказанного то есть во первых это сэмплирование логов то есть вместо того чтобы писать каждую запись подумайте о том чтобы писать каждые n записи то есть существуют разные разные алгоритмы сэмплирования вроде допустим приоритизации по ошибкам медленным запросам правда таким образом может быть сложнее trouble шутить специфичные проблемы и ну допустим и некоторые требования по безопасности опять же могут сэмплирование запрещать да тут можно использовать механизм колдовать агента и так ли клиентской агрегация метрик тысяч допустим он таким образом сократив количество запросов к cloudwatch с-400 50 миллионов до 4 5 ну соответственно тут а нагрузка тут и стоимость далее часто ротация логов но в целом достаточно полезная практика таким образом нас гораздо меньше лагов с которыми мы работаем то есть опять же перекликается следует с предыдущим элементом да то есть мы исключаем дебаг и info да уровень логов опять же мы можем их только включать когда нам это нужно вместо того чтобы постоянно держать то есть и избегает излишне verbose тебя и это дает нам пользу при исследовании логов ну и собственно для стоимость которые теологии опрашивают то есть очень яркий пример когда они на наших клиентов он сливов в целости все еще забивал себе весь сто раз за день два ему приходилось держать ноги только за один два дня что в итоге но опасно говоря прийти митинг а это важно в том случае если один сервис у нас внезапно начинает выбрасывать огромное количество ошибок одновременно особенно с большим stack trace то есть нужно ограничивать количество таких схожих ошибок до чтобы у нас не было большого количества мусора давайте где мы перейдем я покажу как это примерно все выглядит но на нашем вот этом самом проекте до вот они наши кролики зайчики и вот у меня построен дашборд конкретно для конкретно ну вот этого проекта конкретно у меня здесь есть несколько групп различных метрик а начнем пожалуй с вот этого вот этой америке и в чем ее суть заключается в том что здесь я собираю количество элементов из из логов то есть конкретной я беру значение из logs in sight и смотрю что у меня пришло какое-то конкретное количество сообщений в логах то есть допустим я здесь могу отфильтровать что у меня допустим приходила за последнее время там в моих влогах а какой-то конкретный слова допустим р-р да и таким образом я могу мониторить что у меня с приложением что-то не так и сессиями нам какое-то среднее количество сообщений об ошибке или бы или информационных ошибок тогда я уже могу не волноваться сильно да если их количество резко подскакивает то мне уже следует об этом немножко подумать работает это через механизм logs in sight по сути это очень полезный механизм и о нем чуть позже останавливаюсь его суть заключается в том что он позволяет нам опрашивать различные источники логов на какую-то конкретную информацию то есть мы используем все язык который нам говорит что я хочу посчитать допустим сообщений с разбивкой по 5-минутному ок ну то есть вот я получаю конкретные единицы логов и могу даже построить по всему этому делу визуализацию ну собственно нет метрики использовать далее у меня используется утилизация кодов конкретно здесь используется механизм кладовой контейнер insights он не позволяет уже посмотреть нагрузку уровнем дохода то есть я конкретно могу посмотреть нагрузку там допустим циpкa на уровне сервиса я могу посмотреть нагрузку на руль на уровне под об уровне всего deployment а далее идет уже упомянутый anomaly detection конкретно что здесь интересно у меня здесь есть ну вот моя нагрузка да это на самом деле то же самое просто она может быть чуть чуть пошире ну вот чтобы было похоже да и конкретно здесь у меня используется механизм аномалий то есть как это выглядит у меня есть метрика над apple ну допустим за час ну допустим он за день до механизм аномалий он включается конкретно вкладу отседа отдельно покажу где эта галочка сама суть ее заключается в том что он автоматически пытается под мой метрику построить окно то есть у меня сейчас очень скачущие метрика и если возьму за более длительный период у меня будет видно что была очень низкая нагрузка которой это собственно аномалия она адаптировалась вот видно . сел под окно как только у меня начинает скакать нагрузка меняется собственно само окно anomaly да и уже у меня есть и нагрузка в их выходит за это окно я уже могу поесть какие-то оповещению да то есть я могу сказать что допустим у меня сейчас окно там достаточно узкая да я хочу сделать пошире учиться у меня было куда отступить вот таким образом я чуть-чуть сглаживаю проблему до опять же здесь у меня висит оповещения которое говорит что у меня сейчас именно вот этот alarm он но собственно arm а я к механизму о здесь у меня берется цикл метрика и спадов уже из соседнего аккаунта из соседнего здесь у меня уже выбран отдельный аккаунт другой регион и я могу на одном дашборде смотреть уже вместе метрики и по моему проекту на моем аккаунте да и по соседнему проекту там соседям аккаунте и м.ф. собственно это очень полезная штука та самая которой я говорю по сути здесь у меня метрика но как оно сюда попадает вот мне если эта функция она написана на джесс по сути я использую здесь библиотечку которая говорит что перед тем как лог пойдет в стаде out as unlock до добавь к ему основной метрику дополнительно то есть он у меня пишет сейчас и джейсон logo дополнительно вот просто секрет инси метрику она у меня прилетит в логе сначала но поскольку формат предопределен так low дочь у меня поймет что эта метрика дочь у меня сделать на основе вот этих логов уже отдельную метрику это кстати вот ну очень-очень полезный механизм он в плане сокращения костов очень очень интересен сегодня допустим и слоги до нет как да не блогах в метках вот и метриках у меня видно что у меня ну у меня во первых появляется им видит metrics namespace до в нем я уже могу смотреть к этому сервису процессинговый tense вот он это тот мы тут that the same и значит не которое я передаю вот такая очень очень полезная вещь аномалии опять же если у меня есть сейчас давайте вернёмся к это метрики да то есть я допустим могу у этой метрики если у меня есть достаточно и значение я могу включить детектор аномалий и таким образом меня по этой метрики уже появится окно которое построено на основании там машин линга и она у меня уже автоматически скажет ну что у меня какие то проблемы у меня конкретно с этой метрикой а давайте вернёмся к презентации и как-то логически этот кусок шиндо первых у нас есть несколько важных моментов которые нам нужно вынести д то есть в рев нам нужно как можно больше тюрьме три используйте уже готовые инструменты и интеграции с сервисами которые по дефолту позволяет настроить сбор данных до во вторых для расширения возможностей сбора информации сокращение стоимости используйте м.ф. то есть он видит не только формат он позволяет нам передать метрики с файлами которые автоматически становится метриками выкладывать третье у нас допустим есть потенциально проблематичной микро сервис который мы хотим мониторить и мы настраиваем на его метрику anomaly detection этот механизм используется сам обучайся сам обучаясь ios самообучающийся алгоритм для предсказания поведения метрики и если происходит всплеск активности мы сразу вы получаем не просто повышение там до 80 процентов каждый раз когда мы это ждем до а если у нас допустим в 9 часов утра выходят новости и такой подчеркну и ожидаем ли мы такой паттерн сможем сами сидеть его пронаблюдать и там через неделю giving it a pattern уже вы выработать да но суть и сила аномалии текста в том что он понимает таки изменяющиеся пике данных и он он под них адаптируется и последнее что используете мониторинг и от в ответ на события используйте dash барды inside из логов и метриках и автоматически оповещения давайте сделаем небольшой перерыв и вот и запад вича вопросы наверно но и в принципе голову свою очистим перед тем как пойдем следующем куском да за рассказ давай есть несколько вопросов первый вопрос ты упомянул что нужно составить план мониторинга при тем как что то это всегда прекрасно но как понять что там писать и сколько будет этот шаблон где-то можно посмотреть обязательные пункты как должно быть отправились делаем ну я посоветовал в интернете информацию на эту тему то есть я целиком то его не смогу учиться писать да ну это на самом деле достаточно распространенная вещь и тут нет никаких секретов дам нам достаточно просто описать тексте вопрос который описал да ну и в целом эту информацию достаточно легко найти я думаю не проблема так так вот сходу ссылку ссылку я вряд ли дам конечно хорошо тогда следующий вопрос тоже по поводу шаблонов ада в чате все расспрашивает а если какой-то шаблон метрик который вот можно прийти настроить и все будет хорошо ну вот я уже добавляют себя шаблон сердца используемых метки которые можно по умолчанию быками нить наверно ну смотрите есть уже какой-то готовый метре который включен в во многие сервисы да у нас по сути есть такая парадигма что у нас каждый в каждый сервис уже включены включен набор готовых метрик то есть всем этом берем там тот же еще два да там уже будет цифру там уже будет там network in out и прочие вещи то есть шаблон метрик в данном случае ну что мы понимаем если какие-то при подготовке ные метрики да они уже есть они уже включены в сервис и тот же динамо db тоже лямда которое там количество запросов метре тот же там есть два и прочее если нам нужно уже что-то кастомная допустим у нас там на но на game серверов неважно есть количество подключений да но здесь уже придется просто либо либо руками эти метрики слать ну как я уже сказал через mf либо либо там мы через логе шлем и через метрик фильтры это как-то выковыриваем либо через собственный сайт но по сути все ответ заключается в том что для всех сервисов уже есть готовый набор метрик до каких-то базовых а кастомные нужно уже дописывать через механизмы not который спасибо тогда еще один вопрос если у нас есть какая-та инфраструктура на земле он крем и в облаке и хочется иметь одну систему мониторинга можно ли cloudwatch и я например и слать события которые происходят вокально дата-центре анализировать и на могли минут да все верно это вот я очень очень вскользь об этом упомянул на самом деле но суть подхода заключается в том что ставится на землю укладывать агент который уже стримит в cloudwatch какие-то конкретные вещи да ну просто просто устанавливается либо на виртуальную машину либо там что там живет на земле агент настраивается он через конфигурацию там допустим смотрите вот в эту папочку с лагами и эшли и и быть один чего там или еще что-то и таким образом можно за миксовать но собрать там допустим несколько групп логов то есть допустим вас там на облаке есть группа логов и у вас есть там группа логов которые шьется земли до но используем какой-нибудь локсы сайт который может там сделать вам выборку из обеих групп логов одновременно да там через вот это все да из и которые в принципе не проблема опять же также можно и без бороды повесить то есть их кладу агент он пихает метрики с земли в облака да то есть но это совершенно обычный метрики по ним просто строим для сборки у вас такая красивая картина между между небом и землей то есть получается никакой разницы откуда пришел agained и систем мониторинга может работать для всего сразу стоят модификации и для локальных серверов но по сути по сути да либо либо мы ставим агента либо мы можем вообще через sdk в облака писать свои метрики ну просто как кому что удобнее то есть кто чтобы там не заморачивается после джейсон под пятно он настроил ее ну вот он шлет но может можно да можно к себе в код зашить sdk который будет уже там какие-то логии метрики слать напрямую в облака это не проблема и никто последний вопрос про рендерит метров формат и искал что это существенно экономить деньги а получать если какая-то дополнительная цена за используя mf или все уйдет налоги и не от это все там то не тыквы дополнительные цены это просто запрос вы когда вкладывать пишите вы делаете запрос там put put log по моему что такое вот по сути ну цена за вот этот вот за вот эту единицу вызова api запроса то есть либо мы делаем отсылаем логе дать через толпу blogs и отдельно к этому мы пишем там метрики через отдельные api вызов который там под метрика пишет атакой не помню как называется не суть это что-либо куча запросов либо один запрос который содержит уже метрики который будет расспрашиваю там выкладывать какие-то дополнительных костов но я не припомню сейчас хорошо на этом наверно по вопросам покажу всем можно переходить к следующей части ok давайте туда потихонечку двигаться дальше take your ability обзорность уже поинтереснее пойдет да давайте сделаем небольшой шаг назад то есть у нас есть мониторинг но то что мы сейчас обсуждать обсуждали да это метрики логе вот это все есть объем ability чем разница чем они отличаются может это вообще одно и то же как зайда общем случае мониторинг можно рассматривать как определение вещей которые я знаю что они могут пойти не так например и заливаем метрики и или логе с его приложениям приложение и я слежу за количеством ошибок 0 и допустим время отклика моих запросов может возрасти то есть может там опять же вырасти память может вырасти цб особенно это работает случае с монолита me то есть ну потому что я в целом как то представляю как он может упасть до что-то или что-то может пойти не так опять же основывать уже на опыте да но по мере того как у нас система становится все более и более сложными распределенными до мониторинг он ну перестает настолько хорошо работает на самом деле то есть мы знаем что что-то может пойти не так но мы этого не ожидаем то есть мы не знаем откуда это прилетит внезапная drove поминки или кривой запрос базу данных в одном от микро сервисов они там красиво друг от друга изолированы чтобы допустим избежать шумного соседа но все равно вот сервис нас сбоит и по мере роста систем проблемы она по сути только усугубляется то есть допустим нас есть есть люди у которых уже все есть настрой мониторинг но понятно хотя все метрики ok примеры жизни когда у нас все основные сервисы все-все-все хорошая памятником все хорошо да но но но но но ты почему-то дохнут нужно понять где что-то упало до то есть разбирали сутками чтобы понять там карьеру или логе с метриками тянули тянули в итоге до mobility там неделю разбирались вкручивали чтобы это все понять но в итоге поняли что там перепало не переполнить где-то там кэше или диск да но вот по сути ситуация такая что у нас есть группа людей которые обложила себе метрикам но они не понимают я ношу сломалась еще как пример из 3 это сервис который состоит из порядка 130 под сервисов которые общаются друг с другом в очень сложном паттерне технически нереально одному человеку посмотреть на все эти сервисы предсказать где что упадет ну чтобы собственно в этом случае делаем мы собираем телеметрию и сервисов анализируем визуализируем обязательно и теперь есть как минимум возможность понять что случилось и на каком этапе это среагировать вот это собственно и есть у нас der ability to то есть это концепт ну как обрубить по сути обзорность до вызываемой систем обзор на системы до концепт который опирается на разные типы телеметрии то есть логе trace и и метрики как примерах можно описать следующим образом метрики это числа они легковесные я храню и длительное время но постольку поскольку это просто числа да я могу по ним нарисовать там допустим дашборд я могу на них повесить алерта метрики по сути мне ответит на вопрос есть ли у меня проблема вернемся к примеру со 130 микро сервисами ошибки у нас собираются как лавина да и они агрегируются по итогу и как я определю где у меня проблема да мне метрики этого не скажут например у меня в цепочке проблемы со как микро сервиса высылают alert и для этого и собираются трассы они помогают проследить зависимости вызовов через наш workload но очевидно что если нам нужна какая-то конкретная информация об ошибке допустим дра стектрейсы ли исключения не суть-то для этого нам нужны логе то есть поэтому нам и нужны разные типы телеметрии но для эффективное mobility нам нужны все 3 то есть суть задачи на самом деле еще немножко шире потому что нам нужны еще инструменты до который ты сидел решают а несколько достаточно достаточно очевидных механизмов до для для и ws конкретно и для каждого типа телеметрии это во-первых кладу очень metrics деметрий до кладу watch dogs диалогов логично и это bless x-ray для трейдинга что интересно и все эти сервисы они начали друг другом перекликаться по мере того как потребность в / элите она начала растит последнее время но и дальше мы увидим как это все работает но обзора бельке это не продукт который мы можем купить это по сути атрибут системы которую мы наблюдаем конкретно для обзора белики добавились с последнего года в кладовой несколько дополнительных инструментов до помимо известного уже x-ray который я упомянул добавились инструменты с общей тематикой сайт это лакс insights это контейнер inside contributor inside ну и добавились еще x-ray analytics который позволяет чуть чуть глубже копнуть в то что у нас происходит в нашей системе ну вот если примут вернуться к моему примеру с маркерами до то мы конечно ну когда у меня варки разгадка сгибали очереди то мы конечно могли предугадать поведение очереди повесь на нее оповещение но различных сценариев из-за которых что-то могло пойти не так на самом деле огромное количество опять же я как разработчик то время я знал как работает система и в цех быстро мог найти проблему ну во первых это я знала мои коллеги нет опять же они могли что-то знать на могли не знать всех тонкостей до системы а во вторых даже у меня бывали сложности найти какая часть системы переставала perfume теле почему у меня клиент допустим налейте жалуется пока я пока я к этому делу всему не прикрутил x-ray да дело мне не пошло но когда прикрутил у меня уже появилась что меня появилась картина что самое важно да которая дает понять какой именно элемент в моей группе сбоит какая то что было сделано до ну там поскольку мне предложение было частично монолит то ну частично монолит частично отдельной микро сервисы то instrumentation была построена таким образом что в коде монолита у меня использовались три бутыля классов да ну чтобы создать элементы там где вызывали сторонние системы не обязательно так детально дописывая можно там включить механизм несколькими галочками до но он мог закопаться по сути и на уровне всяких land допустим через подключение x ray у меня стали видны вызовы то на это был езда и появилась картина того какая функция у меня занимается сколько времени до самом деле вариантов решений этой проблемы очень много через 1 неделю залезли различные подходы да то есть можно еще использовать lk illegally лоб поверх клауд hd ну поскольку конце обсе рубили озеро видите она сейчас как концепт расширяется в dp-100 появилась необходимость какого-то полного решения но более меня полного да то что то что сейчас развивает у нас сервис лэнс что что в сервис lines по сути такое в двух словах можно сказать что это отчасти слой манипуляции над x-ray но суть у него немножко пошире д а как у нас вообще рисуется подробная карта такие механизм они используют те самые 3 которые упомянут ну по сути они используют небольшой кусочек информации на нашем случае это тролли сойди который перехватывается через заголовки всеми бэкон сервисами и ну по пути по пути следования этого запроса распределенные trace и они мне могут ответить на уже следующие вопросы какие сервисы у меня допустим недостаточно хорошо performed какие опять же какой у меня среднее время отклика между сервисом а и сервис мвд можете делал лишний запроса к базе данных привет к нашим пули рода если меня ботаники а если есть то где там могу ли я западе минировать запросы операции использования используя распараллеливание если у меня блокирующих процессы допустим или почему мне конкретные запросы по у почему не конкретный компонент не работает решают эти проблемы себастьян с использованием двух вещей во-первых это мониторинг инфраструктуру с использованием метрика лоб ну чтобы понимать какие у нас ресурсы работы связка с приложением да и второй это мониторинг транзакции с использованием трессов для того чтобы понять взаимосвязи между ресурсами что для этого делать да он рисует но подобную контекстную карту для понимания взаимо взаимосвязей между ресурсами но это еще не все есть у нас еще такая вещь как проблема корреляции логов то есть простой пример у меня есть ошибки в кому-то моем одном компоненте да я вижу его на карте он красненький у меня паникует но я смотрю корейцы trace и ну да хорошо у меня что-то сбоит меня сбытом запрос где нам и db выбрасывает не код ошибки ну почему мне нужен log но для этого мне нужно сканировать конкретное событие в трассах с конкретным событиям в логах а как это сделать мне там по дате сверяет мне когда миллисекунда да я так толком ничего не найду еще если системы достаточно высоконагруженных да а могу найти но не только если найду если повезет ну хорошо но в любом случае мне пришлось довольно много разгребать по сути мне необходимо подключить x-ray в проект с использованием sdk и иметь агента который trace и собирает на конкретной машине да ну или как сайт корр контейнер поскольку у меня одних стрельцов может быть достаточно желательно и к ним добавляете какие-то атрибуты и метаданные чтобы получить из них больше информации это может там через sdk в том числе делать проблемы корреляции логос решается тем что лаги который выбрасывается приложение в об этом в определенный момент они должны содержать какой-то привязку к этому trace что собственно x3 и решает то есть он он добавляет на уровне езды к едет рейса в лагере таким образом вы можете для конкретного конечного крыса получить информацию с лагами ну и из логов да то есть по конкретному запросу контейнера для них сейчас есть инструмент мониторинга билли кида это вот контейнер insights я уже немножечко упоминал перед этим делом да и а суть заключается в том чтобы предоставить более полную информацию о среде контейнеров то есть конкретно не просто собирать базовые метрики принципу из 5 а именно содержать информацию уже глубоко до уровня до уровня конкретного поле да ну либо либо до уровня конкретного тоска поскольку на сейчас растет требование видимости на среду контейнер в то отдельно выделили вот этот сервис который дополнительно позволяет собирать нам агрегировать и суммировать метрики конкретно циpкa память там количество task кодов хранилища сеть количество инстансов под контейнеры сервисы тоски и прочее как он все делает по сути операционные данные да они собираются как так называемые performance log event и это событие которое используют структурированную джейсон схему которая позволяет хранить уже хай кардинале те данный вклады watch на привет я мог стать используйте все это дело собирается с частотой в минуту из этих данных cloudwatch у нас уже создает какие-то агрегированные метрики на уровне кластер анода под и там ну или сервиса на cloudwatch на века и цикл убери а плотную insights контейнер на сайте он использует там контейнер резервную версию колдовать агента чтобы за discovery уже все запущенные контейнеры в кластере ну вот как пример да у нас была проверка проверка dns тайм-аут тогда мы запускали но в данном случае у меня видно как подскакивали метрики у меня в моем конкретном классе по каким-то своим конкретным показателем да ну видно что мы тут даль нагрузку и видно как это говорю что нагрузка собственно выглядит look inside это сейчас на самом деле очень-очень интересный инструмент потому что он очень часто стал использовать чаще слышу и плюс его кстати в том что он сейчас занята герион с предыдущими двумя сервисами которые описал да по сути это механизм который у нас позволяет при помощи псевдо языка опрашивать кладу очень логе из различных источников визуализировать эти запросы агрегировать коррелировать и ну настраивать какую-то визуализации то есть могу собрать несколько различных источников логов и написать для них фильтр запрос и получить конкретно вот эти вот логе там для какого-то конкретного event-а который у меня произошел а и еще один механизм который сейчас очень полезен на самом деле это контрибьютором сайт он нас по сути позволяет понять что у нас импорт систему и производительность приложения путем определения тяжелых паттернов трафика но и ранжирования sensex системных процесс да по сути создаются правило вот это сама контрибьютором сайт который оценивают структурированные log event и да и по мере того как они попадают выкладывать из допустим glow трейла vip сито мопеде твои неважно и кастами флагом опять же можем может там свои логия по чипе хоть и их и их анализировать данное количество там какие-то входящих элементов то есть как примеру вот для динамо д.б. но это кстати живой пример да он позволяет увидеть горы горячие park shin ki то есть но это реально кисть для autel хорошо подходит давайте перейдем по быстренькому к еще одной демки которая вам покажу так сейчас я мышку свою найду я на господи так ну вот у меня мышка ну давай перейдем но как все это добро у нас выглядит конкретно начнем с сервис лэнс и собственно сервисная карта мое приложение вот то самое приложение возвращаясь да это зайчики кролики ну и кстати можно вернуться к общий архитектуре чтобы слегка освежить нашу память то есть вот как выглядит наша архитектура то есть у меня здесь есть и конец да у меня есть несколько api сервисов есть балансиры и вот так эта картина у меня выглядит сейчас в сервис конкретно у меня сейчас видны все запросы которые прошли через мою систему под нагрузкой из конкретно я вижу здесь сейчас что у меня допустим между сервисом поиском едином и db таблицей большое количество запросов да ну с очень хороший танец то есть давайте по количеству запросов данном случае видно жирными линиями до показан из от направления буду просто показано либо я могу фильтровать по среднему леденцы и таким образом я увижу что у меня допустим вот это вот лямда она здесь ну занимает больше времени чем допустим другие сервисы опять же я могу для каждого но до перейти уже понятно что я могу увидеть метрики доли пенсии запросы ошибки и я могу с ходу перейти в контейнер insights мне уже по метрики для вот этого конкретного сервиса на уровне уже но механики то есть это именно подав сервисов и прочих контейнером сайт сон что интересно он способен тоже нарисовать удар и ну чтобы не ждать он по сути у меня выглядит вот таким вот образом то есть здесь я вижу весь мой кумир с точностью до какого-то конкретного сервиса до конкретного по да да то есть я могу допустим посмотреть что у меня там ну вот namespace х2 честным space и плюс у меня есть би си есть у меня есть дополнительные сервисы до и что полезно ну допустим я могу вот вы сами опять сайт да и я могу уже по конкретному сервису посмотреть вот у меня цикл поэтому сервиса вот мне памяти вот у меня сеть alert и если они у меня есть до ну а лет у меня сейчас кстати нет у меня все хорошо но если если alert появится он то он у меня здесь будет выше чем вот давайте вернемся на нашу картину то есть опять же я здесь могу смотреть между разными аккаунтами то есть я могу получить картину для соседнего аккаунта в том числе каждого надо есть уже отдельная да своя которая показывает мне уже более-менее расширенную информацию конкретно я вижу что вот для вот этого надо все его связи со сторонними сервисами с какими он общается я могу посмотрите tracey да я могу посмотреть его конечным 7 . а если из контейнера да я могу посмотреть допустим не только для лямды здесь у меня как для лямда да и и и вызовы и ну там допустим для с 3 в том числе могу посмотреть да из любой из этих точек я могу перейти в блоге есть если организму там 5 сайт да допустим тада я могу перейти там посмотреть в тренер давайте посмотрим на рейсы то есть у меня есть меня есть тоже будет который показывает не метрики да и и связями с сервисами и отдельно я уже могу посмотреть мои конкретные trace и которые проходят через систему что интересно возвращаясь к вопросу о метаданных то есть я из своего кода я высылаю большое количество различных trace of но я могу их сгруппировать по различным показателям то есть допустим данном случае я могу сказать об этой я хочу свои трейси кровать там ну по кроликом то есть я хочу увидеть все трейси которые относятся у меня к конкретному элемента то есть как то есть который содержит какой-то конкретными да да на в данном случае я вот хочу поставить всех все trace и для кроликов дату из я вижу вот меня с rime lite инсте я вижу конкретные trace и да поэтому вот тип у животных да и я могу уже отдельно видеть 0 до что у меня произошло для конкретно кролика и я могу увидеть полный набор уже сервисов которые у меня прошли вы были пройдены ну конкретно для кролика вот дальше о корреляции логов даль конкретно для вот этого запроса у меня есть набор лагов уже который я могу прямо здесь посмотреть да то есть мы либо могу перейти в кладовой что касается и там уже по подробнее посмотреть каждый элемент как это работает у меня в каждую когда выстреливали слоги до меня было встроен произойди в каждой из этих логов интересный момент что сейчас автоматически это можно сделать при помощи sdk для java только для java если используются какие-то другие sdk там тут нет но даже если еще что то то нужно будет резать и пока что вкручивать в логе руками пока так вот давайте посмотрим еще один интересный момент вернемся карте к моей сервис карте конкретно мы посмотрим вот у меня есть допустим поиск я смотрю его трейси вот и я вижу что у меня есть элементы кота от долга по какой-то причине давайте посмотрим а вот у нас может быть интересного и стирки да давайте посмотрим где у меня на карте ошибки ошибки меня вот здесь в истре чем м ну давайте немножко поподробнее в это дело глянем что у меня случилось почему мне конкретно в этом сервисе какие-то проблемы до тоже я вижу что у меня здесь возросшей to see от одного из сервисов да ну давайте смотреть вот я вижу что у меня здесь аж к и ошибка именно 400 3 4 3 означает экс с диной то это значит у меня между теми двумя сервисами сейчас нет доступа то есть таким образом я вижу что у меня конкретность сервис да не имеет доступа к с3 и поэтому у меня собственно ошибочка дальше немного в чём разница между xm и на лифт спасибо x-ray и сервис как я уже сказал сервис лэнс это такая удобная очень обертка над xrm но по сути функционала x-ray это не отменяет то есть вот у меня есть та же самая картина да но здесь я уже могу получить немножко больше конкретно я могу получить информацию по общению между двумя сервисами получить его среднюю latency количество ошибок и я могу получить средний график по уже но по-моему конкретном и сервису допустим есть я хочу посмотреть вот под search у меня есть у него есть небольшой поступок в и здесь я уже могу собственном делать рейз и для вот этой конкретной плотности что у меня случилось но действительно вот я сейчас смотрю что у меня туда ну вот с 3 вот у меня ошибочка и в нее я уже могу капнуть и посмотреть куда у меня собственно крыса шли до остались две не осталось уже меньше двух минут меньше двух хорошо хорошо вот да очень много информации к сожалению я не успел да все все вам показать очень интересная но в принципе trace и это на самом деле то самое что очень важно и что очень полезно во всем этом деле для анализа ошибок основной этом случае уже слава богу вам показал но если кому-то больше больше интересно куда только рад рассказать да давайте быстренько очень ппс практикам то первых обязательно лагер уйти доступно сети и сетевые задержки да это особенно полезно там чтобы ответить на вопросы там почему-то в запросы были медленно и прочее такое обязательно лаггеру и титры сойди передавайте в бэг-энд вызовах это очень важно да лагер уйти разные метрики light in cee зависимости от статуса ответы размера это важно почему потому что у нас ошибки часто возникает быстро там вроде ox1 а и тротлинг валидации да и если клиенты начинают ловить ошибки по троттлинга может показаться что личность и упала и чтобы избежать подобного мусора в метриках тала делает обычно отдельный таймер для успешных запросов и фокусирует метрику для сборных и аларма вместо общей метрике да таким образом есть есть операции который занимает больше времени зависимости от тела запроса или ответа то ее владеют какой-то кастомизированные вещь да ну обязательно лагер уйти важные метаданные это очень поможет да и на ошибки очень важно провести какой-нибудь каунтер это тоже очень очень очень важно да важные вещи которая стоит вынести в право точно сейчас не просто инструмент для хранения логов это полный механизм для обзора ability и мониторинга сейчас до контейнером сайт позволяет нам получить метрику контейнере зова ну приложение с точностью до подав да обязательно используйте tracing коррелируется метрики логии trace и как можно более автоматизированным вариантом да и для исследования проблем там не спал необходимо использовать продвинутые инструменты вроде там контрибьютором сайт ну вроде уложились спасибо секунд спасибо сергей сергей да здорово мне на самом деле очень понравился доклад мы в какое-то время назад очень коротко мер на такую штуку с мониторингом именно вот игра граф сами рисовали когда вот еще не было его видимо в общем очень дорогой на надеюсь успею подключиться к зуму не знаю вот если вам вас есть вопросы дорогие друзья подключайтесь к зуму я бы вот тоже подключился если бы не нужно было быть дальше спасибо большое встретимся в зуме и на скорых встреч вам да мы переходим сон"
}