{
  "video_id": "hnvOFe02Zwc",
  "channel": "DevOops_conf",
  "title": "Андрей Цветцих — Zero-downtime deployment и базы данных",
  "views": 611,
  "duration": 2877,
  "published": "2025-02-21T00:14:11-08:00",
  "text": "коллеги Всем привет привет Вот Меня зовут Денис а я сегодня выступаю экспертом на докладе про Z deployment и база данных Вот и собственно этот доклад будет рассказывать Андрей вот он Да он тоже работает в т банке Вот и собственно Андрей Тебе наверное вопрос Расскажи как вообще родилась такая идея сделать этот доклад Ну как всегда у спикеров они как чукчи что вижу то и рассказывают на конференции А идея появилась когда я видел много однотипных ошибок и сбоев на продакшене из-за того что люди неправильно обновляли версию и неправильно работали именно со схемой базы данных причём относилась к разным только базам даже к разным классам баз данных это реляционная база Документ отива и так далее вот этот опыт я постарался собрать в докладе чтобы уберечь наших коллег и слушателей доклада подобных ошибок дава и база данных Ну давайте для начала пару слов о себе кто я такой Почему меня вообще стоит слушать Меня зовут Андрей цх я работаю dnet ведущим разработчиком Вт банке конкретно в банке для бизнеса там мы делаем сервисы для предпринимателей общий стаж работы уже около 15 лет точно не считал Ну достаточно большой за это время успел поработать на разных проектах там пилил стартапы и эксплуатировался того последние несколько лет мы с братом Денисом много выступаем на разных конференциях как вот де Brothers и возможно у нас где-то уже видели и вот сегодня я первый раз выступаю на devops надеюсь что всё отлично получится а по теме доклада что же такое Zero downtime deployment это собственно подход который встречается у крупных компаний которые работают с нагружены распределён системами эти системы работают 24 на 7 то есть нет какого-то окна для этих обслуживания они обрабатывают много запросов пользователе ПС обрабатывают большие объёмы данных вот там вероятность ошибки намного выше А нам не только нужно это всё там эксплуатировать но ещё и делать деплой так чтобы пользователи ничего не заметили в этом докладе Я хочу собрать весь накопленный опыт и надеюсь что он будет вам полезен Хорошо теперь переходим ко второй части названия это база данных в качестве баз данных Мы будем обсуждать различные хранилищ класс хранили реляционная база данных с примером на реляционная база данных с примером поса дальше in Memory cashis и документо ориентирование Как эластик посмотрим как они работают с со схемой данных и как их правильно обновлять Но вообще опыт он такой универсальный и с какими-то доработками его можно перенести на любую базу данных на любой стод по сути так для кого же этот доклад Если Вы разрабатываете микросервисы наверняка он вам поможет более важно чтобы у вас было запущено больше одного инстанса вашего сервиса потому что ну микросервисы у которых запущен один инстанс - это как-то странный микросервисы это не очень отказоустойчивого вы хотите разрабатывать микросервисы и пришли послушать как деплоить ну либо просто понравилось доклад это прекрасно а также все примеры кода будут на си шарпе но всё что касается кода оно как раз от стека совершенно не зависит и может быть легко перенесено на любой стек Ну единственное какие-то библиотеки там и так далее для каждого стека будут свои но это у вас обычно не проблема и для начала Давайте такой пример из реальной жизни разберём Ну как говорится все совпадения случайны но вполне вероятны Итак у нас есть версия сервиса он работает с базой база данных реляционная постгрес например и у нас есть табличка категорий где мы переименовали колонку была категория noes переименовали в noes Ну действительно Зачем префикс категории если таблица так называется категории После этого мы запускаем нашла pipeline который там всё собирает тестит плот и так далее Дальше время деплоя возникают ошибки Но мы же опытные инженеры мы знаем что смотреть ошибки время деплоя - это только время тратить как только вот все инстанции нашего сервиса обновлятся до новой версии все ошибки прекратятся Но именно так и происходит после после чего мы всё проверяем всё прекрасно работает рапорту начальство тебя говорят Молодцы ребята и нашей дружной Командо Мы идм пить пиво в ближайшие отмечать успешный релиз вот Ну дальше тёмной при тёмной ночью после релиза город засыпается и просыпается Ну нет не Мафия а интеграция Например у нас есть интеграция с маркетплейсами и каждую ночь мы с ними интегрируем забираем кучу всяких разных данных отчётов и их себе сохраняем и так получилось что в новой версии сервиса у нас оказался Лик течка памяти например мы что-то неэффективно используем Или например к нам подключился клиент у которого очень много данных в бизнесе так бывает что есть небольшие средние Клиенты у которых данных не очень много есть крупные Клиенты у которых данных может быть в 5 10 и так далее раз больше чем у среднего клиента мы пытаемся обработать этого клиента и ничего не можем сделать памяти отравится всё больше больше больше в какой-то момент под выедания по нему опять же обрабатывает данные не может обработать падает по of Там перезапускается и так по кругу то есть вот это у на эта активность привлекает внимание с У нас есть дежурные которые в том числе ночью следят видят что ага Вот этот сервис стал очень часто перезапуска не смотрит причину перезапуска они хотят при Что делают берут Да и откатывать сервис на прошлую стабильную версию что у нас получилось что старая версия сервиса не может работать с новой схемой не может работать с новой колонкой Она работает со старых колонок и при импорте данных у нас постоянно возникают ошибки Что делать ры дальше самостоятельно исправить проблему не могут пора будить разработчиков а разработчики либо ВС ещё в баре пьют пиво либо уже на пива дома в общем для сервиса ситуация крайне неприятная нум это говорит что нам нужна обратная совместимость старой новой версии на уровне базы данных то есть база должна поддерживать на временную работу как старой версии сервис так и вот хорошо О чём сегодня поговорим подробнее это какие виды деплоя кода на кластер бывают разберём основные дальше посмотрим как правильно запускать миграции чтобы всё было хорошо и не было подобных сбоев разберём как мигрировать данные со старой версии на новую на конкретных примерах посмотрим как обеспечить обратную совме для реляционных баз данных и наконец разберёмся чем нам поможет в этом деле так поехали а как деплоить код на кластер первый самый простой вариант называется and Up это когда у нас есть кластер в кластере сть инстан сов вашего сервиса и мы хотим обновить со старой версии первой на новую на вторую собственно что мы делаем мы останавливаемся инстансы вашего сервиса дальше мигрирует на вторую и запускаем уже шесть исов новой версии что мы получили Ну это просто не требует дополнительных ресурсов в кластере Ну и одновременно работает только одна версия сервис это нас уберет это ошибок Из минусов Да так как доклад называется то нам это не подходит можно было бы подумать где можно этот метод использовать но сейчас мы перейдём к более продвинутым способам обновления кода Итак второй называется зам инстан сов старой версии сервиса первого и мы Для начала запускаем ещё один инстанс новой версии второй и останавливаем один инстанс старой версии потом мы запускаем второй инстанс новой версии и останавливаем ещё один инстанс старой версии Ну и так далее по одному мы обновляем инстансы пока у нас все инстансы в кластере не обновятся до новой версии до Второй Круто А когда обновляется база данных смотрите для второй версии нужна уже новая схема базы данных поэтому мы сначала когда работает первая версия сервиса обновляем схему базы данных со старой первой на новую на вторую И после этого у нас в кластере старая версия кода работает с новой схемой базы данных и мы запускаем инс второй версии которая уже работает с новой схемой база данных то есть видите мы одновременно работаем одна и та же база работает ну то точнее две разные версии сервиса старая новые работают с одной и той же новой схемой базы данных Итак что мы получили а мы получили zer Down Time то че мы хотели и Этот способ требует мало дополнительных ресурсов в кластере то есть нам требуется всего один дополнительный истан Ну из минусов а такой плой может быть долгим если у Вас например 30 инстан сов и каждый обновляется Ну пусть по минуте Ну вот полчаса идёт плой дальше у нас одновременно работает старая новая версия сервиса это может быть причиной ошибок ну и наконец Если была проблема И мы хотим откатить проблемный релиз это у нас снова займёт столько же сколько илой то есть на случа считаем полчаса хорошо и третий вариант который мы сегодня рассмотрим это BL тут надо вспомнить что напрямую клиенты на нашиды не ходят на наш и они ходят через балансер то что мы можем сделать Мы в кластере можем к инсам старой версии рядом поднять исов новой версии Потом взять да и переключить весь трафик на баланс когда мы переключили трафик со старой версии сервисов на новую у нас новая версия работает уже с новой схемой базы данных то есть мы получаем всю Ту же самую схему То есть когда у нас работает старая версия сервиса мы берём и обновляем схему базы со старой на новую и у нас получается что старая версия сервиса работает с новой схемой базы данных потом мы переключили трафик на новую версию сервиса и уже новая версия сервиса работает с новой обновлённой схемой То есть у нас опять есть одновременная работа и старой версии и новой версии Вот хорошо а итоги по blen деплоймент а то есть мы опять получили Zero Down Time у нас теперь одновременно работает только одна версия сервиса так как ну переключение трафика на балансе мы делаем весь трафик разом переключаем Да и мгновенное переключение назад то есть откат в случае проблем но из минусов это то чем приходится платить за вот такое мгновенное переключение это много дополнительных ресурсов в кластере то есть на каждые шесть инстан сов вам понадобится ещё столько же инстан сов новой версии хорошо итоги по деплоя на проде мы используем Roll update ли BL depl разные команды используются разные Вот и в обоих случаях у нас старая версия кода работает с новой схемой баз данных То есть это штатная ситуация она нужна для деплоя то есть не только для отката на прошлую версию именно для деплоя То есть это та цена то что нужно платить как раз за Z de чтобы делать dey так чтобы никто не видел Да нужно упомянуть что есть ещё качный релиз Вот это такое совмещение опять же у нас некоторые команды этим пользуются но в плане работы с базой данных это ничего нового нам не приносит у нас в любом случае есть одновременная старая версия сервиса и новая они работают с одной и той же схемой базы данных хорошо тепер поговорим о том как запускать тут у нас есть два варианта пример кода наша то что выполняется при старте сервиса например вот один из шагов пристар это то есть применить миграции баз данных которые запускаются из ума вот здесь на не особо интересует нас интересует то что это происходит именно при старте сервиса Из плюсов Ну это очень быст ре достаточно длинный список минусов например А что делать если база при старте недоступна вот а что делать если у нас Одновременно несколько инв запускаются они пытаются мигрировать одну и ту же миграцию накатывать ну и так далее для нас одна из основных проблем Это то что инстансы стартуют дольше то есть на Доне Джаве инстансы при старте именно потребляют много ресурсов цпу например и вот это критично место которое мы хотим всячески оптимизировать поэтому Одна из основных рекомен для все миграци выносить в отдельный шаг Вот хорошо поэтому мы миграцию будем выносить в па для пример мы собираем Сначала это просто консольное приложение там для сборки нужен вторая строчка Вот это нам нужно сделать оди из шагов па то есть собрать бан и его запустить для Ja применяется и если используете как библиотеки то там запускает миграции на старте вообще для тоже есть ры которые можно использовать в я к сожалению по не специалист Поэтому если у Вас будут вопросы по этому поводу пишите их в чат я пере Можно ли откатить миграцию вот представте в новой версии мы переименовали колонку категори Можно ли такую миграцию откатить Ну вообще можно можно переименовать назад хорошо если удалили удалили Можно ли эту колонку восстановить Ну колонку восстановить можно а данные которые были в этой колонке мы уже никак не восстановим пом вот Ну и не забывайте делать бэкапы особенно если вы меняете что-то в схеме данных в самих данных которые в базе хранятся перед релизом сделайте капчик в этом случае если что-то пошло не так Вам нужно восстановить эти данные вы будете знать откуда их достать иначе ну придётся объяснять бизнесу что Ну вот у нас только старый какой-то п из которого мы можем эти данные достать хорошо итоги по запуску миграции выноси их в это общ рекомендация всех пускаем из джоба кубера например кто-то ещё запускает я слышал из CD пайплайн Ну то есть из того же кластера Где идёт сборка мне такой вариант не нравится потому что разные права доступа чтобы собрать образ для деплоя вам не нужен доступ например в Во Где хранится строка подключений то есть вот такое применение из CCD оно Менее безопасно чем запуск из кубера джоба Ну то же самое в Дж кубер у вас то же самое окружение что В итоге на подах будет Поэтому этот подход э мне больше нравится Итак если вы используете dotnet то мигрирует на ecore шесто или позже Если вы ещё dotnet не используете то начинайте использовать Ну а если вы всё-таки используете jav либо ещё что-то там есть свои раннеры которые позволяют миграцию вынести в пайплайн а если уж совсем с ранера плохо Ну в конце концов можно взять создать утилиту командной строки туда вставить запуск миграции и всё будет прекрасно работать это вынести в пайплайн то есть именно так все тки делали до того как появились в Банд на уровне О хорошо третья часть нашего доклада про то как мигрировать данные на новую версию здесь мы будем рассматривать только обратно совместимые операции такие как создание таблиц добавление колонок То есть те операции которые обратно совместимы со старой версией которые её точно Не сломаю Хорошо давайте рассмотрим варит мы добавляем коло без дефолтов прекрасно всё работает хорошо если мы хотим добавить колонку с дефолтов значением и у нас в таблице много данных ну для новых версий постгрес это на самом деле не проблема то есть э информация про дефолтов значение добавляется в метаданные и всё хорошо опять же для своей базы данных ну уточняйте самостоятельно хорошо А что если нужно вставить какое-то сложное значение которое не может быть сделано как дефолт в базе тут у нас есть два варианта Первое - это а писать значение при первом обращении То есть когда мы пытаемся обратиться к каким-то данным Мы сначала смотрим на новую версию новую схему если там ничего нет идём в старую читаем оттуда записываем в Новую и возвращаем все следующие запросы будут читать сразу новую версию При этом надо понять что да гет запросы будут менять состояние база То есть все говорят что нет они ничего не меняют Нет они в этом случае будут менять но только первый раз опять же первый Запрос к каким-то данным у вас будет задержка больше потому что вам надо будет сходить в старую схему их оттуда Вычитать и перезаписать но зато все следующие запросы будут уходить уже быстро потому что они будут читать только новые данные Ну и второй вариант который часто дополняет первым это фоновая процедура которая вычитывает старые данные и переписывать их в новую базу То есть это опять же может быть реализовано в виде джоба кубера это может быть Command Tool который вы запускаете с терминала то есть зашли на терминал Откуда вы подключаетесь к проду и вот там т эту лну можно будет запустить чтобы она Обновила Бау ну и наконец может быть фоновая Задача в сервисе которая где-то вот в фоне работает и мигрирует Да здесь важно помнить что опять Если вы используете по надо помнить что там есть vcc и при этом обновление или удаление это на самом деле тоже удаление строки на низком уровне Да поэтому вот э вот Ваша процедура заполнения не должна быть чере агрессив активно есть доработать должна мешать работы как нормальной как нормальной работе сервиса так и работе того же вакуума вот дальше Давайте представим что нам теперь нужно добавить новую обязательную колонку что мы делаем мы заполняем добавляем необязательно колонку потом заполняем значение по умолчанию через update просто и делаем колонку обязательной ну в конце удаляем значение по умолчанию мы считаем что данных мало И мы можем просто через это сделать хорошо Ну собственно пошли это делать добавление колонки миграции у нас в одном релизе и миграция применяется в па как мы разобрали то есть используем шаги у нас выглядит следующим образом то есть шаги палана тест потом здесь мы как раз добавляем колонку и сразу же мигрирует тоже работает с новой схемой то есть во время деплоя старая версия будет писать старые данные и А мы считаем что мы данные все уже мигрировали то есть Вот видите здесь как раз из-за того что одновременно работает старая версия новая версия возможны проблемы ошибки как от этого уйти ну самое простое Что можно сделать это мигрировать в следующей версии то есть сначала добавили колонку сделали релиз а потом мигрировали данные вот Но если вы хотите сделать подруго Можно либо Def value на уровне базы делать подходит для простых случаев для сложных случаев синхронизации можно использовать триггеры если значение считается на уровне баз это как раз тот редкий случай когда тригеры действительно могут быть полезны Хотя я предпочитаю обходиться без них и делать несколько маленьких релизов тригеры не очень люблю они неявные когда выполняешь какие-то запросы не знаешь что там есть Гер вот поэтому лучше обходиться сери вот маленьких обратно совместимых хорошо итоги по миграция соответственно если данных много мы их мигрирующая эти два подхода То есть то что используется Часто мигрирует при первом обращении а потом в фоне мы домигр помнить что во время деплоя у вас работают Две версии сервиса с этим тоже могут быть связаны ошибки и ну на конец убираете за собой удаляете всё ненужно после ции код трие и так далее но если у вас меняются данные в базе Не забывайте перед релизом делать по капчик хорошо Теперь давайте на примерах посмотрим как обеспечить обратную совместимость причём для обратно несовместимых операций то есть обратно несовместимые операции такие как удаление таблиц колонок их переименования То есть то что точно сломает старую версию сервиса Ну самый простой пример - это удаление колонки А мы сначала удаляем использование колонки из базы потом добавляем миграцию которая эту колонку удалит и так вот эти две два шага Нужно разместить по разным релизам то есть Сначала мы удалили использование колонки сделали релиз а потом добавили миграцию ещё раз сделали релиз даже такие простые изменения нужно делать в два релиза Ну и общий подход - это мы какую-то обратно несовместимую операцию преобразуем в последовательность в маленьких но обратно совместимых операций сейчас давайте рассмотрим комплексный пример когда мы схему и данные в какой-то в какое-то новое состояние причём само изменение О обратно несовместимое Итак у нас есть табличка категорий есть две колонки статус и статус - это обязательное поле Ну с какими-то значениями Del - это поле необязательное для Del оно заполняется датой времени в то в тот момент когда рока удается соно есть активные категории те которые не Уда не заполнено и давайте тоже самое посмотрим на коде То есть у нас есть статус и у категории есть полете и статус есть активные категории те у которых Пусто и есть операция удаления которая как раз проставляет полете хорошо что мы хотим сделать например вместо колонки Мы хотим использовать статус Del почему Ну например нас такой корпоративный Стандарт хорошо что для этого надо сделать Какие шаги во-первых добавляю новое значение ВМ новый статус deled дальше Мы мигрирует со статусом deled а не с поле Del и наконец мы удаляем используем колонку в базе ещё раз на примере кода что мы хотим то есть мы хотим Добавить новый стату Del внутри категории у нас пропало поле Del У нас меняется логика а вычисления активной категории то есть та которая не удалена та активна и удаление - это проставление статуса делите Вот такая у нас новая логика Давайте посмотрим Какие шаги какие релизы нам надо будет сделать чтобы это реализовать Итак релиз номер один мы добавляем статус deled vam и мы меняем А логику проверки активности то есть активная - это которая не удалена и та у которой статус не делит то есть здесь мы при чтении проверяем старую схему и новую схему данных Давайте подумаем А можем ли мы сразу писать Del в базу статус на самом деле не можем потому что этом это обратно несовместимые изменение для старой версии сервиса то есть такие изменения они должны быть обратно совместимы не только по схеме но и по данным то есть новое значение нам это обратно не совместимые изменени для старой версии хороо во второй версии включаем запись раньше мы пров Теперь мы пров стату хоро ли это изменени да хороши Почему Потому что старая версия Она и так читает обе версии Она читает и статус то есть мы можем писать либо то либо то хорошо третий здесь Вот это делается один раз так как мы больше не пишем Вот и здесь Как видите уже убрали из кода и здесь мы меняем чтение уже нигде не используется мы поменяли чтение то есть активные те у которых категории не делит Ну и последний шаг - это удаление неиспользуемый колонки из базы ещё раз напомню что здесь мы теряем данные то есть вот дата время удаления которая раньше была проставлена после миграции на статус больше Неу Поэтому чтобы эти данные навсегда не потерять Ну с одной стороны хранить не используемую колонку особого смысла не имеет но имеет смысл сделать п этих данных до удаления колонки и какое-то время его хранить Вдруг кому-то это понадобится Итак давайте рассмотрим общий Фло как это происходило У нас есть приложение которое работало со старой схемой и мы хотим мигрировать на новую работаем это значит читаем и пишем данные старой с первым шагом мы начинаем читать моли данных старую и новую далее на втором шаге мы переносим запись в Новую модель но при этом продолжаем читать обе модели А зачем читать Ну так как мы ещё не мигрировали данные на третьем шаге мы перестаём читать модель всё корректно так как этому моменту все данные уже мигрировали на новую модель соответственно после этого старая модель уже не используется её можно удалить вот хорошо и давайте рассмотрим пример с переименованием таблиц зачем их переименовывать Ну например удобно когда в коде и в базе у нас одни и те же термины называются одинаково Если у нас некий есть единый язык в термина ddd то есть очень удобно когда он у нас одинаково называется как в коде так и в базе А вообще ещё в какой-то Старой книжке про mssql дся читал что у многих проектов ну качество кода достаточно хорошее а состояние базы данных от плохого до ужасного Ну в наше время это тоже актуально потому что база куда менее гибкая чем код и менять её сложнее Итак вернёмся к минаю таблицы то есть для этого нужно создать новую таблицу мигрировать старые данные в эту таблицу на время миграции нам надо как-то синхронизировать данные между этими таблицами скорее всего триггерами что-то как-то сложно выглядит поэтому многие забивают говорят а и так сойдёт На одном из проектов на котором я работал схема баз данных вообще была на финском языке поэтому через там конечно МАН на английский настроили но никто из разработчиков самостоятельно схему не менял там были подрядчиками е меняли только основные заказчики такой забавный факт был что нам поможет проще проводить некоторые операции миграции например изучение литературы есть такая книжка Фактори баз данных книжка старая но она всё ещё актуальна то есть там уклон сделан на Шери Database То есть когда несколько разных приложений интегрируется через общую базу А сегодня у нас обычно там микросервисы и нам не нужна общая база но нам нужны подходы которые там описаны чтобы обеспечить вот обратную совместимость между старой того же самого Серви Итак в этой книжке был найден Интересный вариант переименования таблиц например что нужно сделать чтобы переименовать таблицу Ну взять е да переименовать а потом создать просто вху со старым именем Ну и всё то есть не нужно мигрировать данные не нужно синхрони их на время деплоя работы и так далее ВС очень просто и в это старой с данных вот читает и Пит и первом шае мы начинаем писать в модели старую и в Новую читаем только старую после этого нам нуж миграция данных старой модели в Новую и на втором шаге мы начинаем читать новую модель вместо старой тут всё корректно так как данные но моде мигрировать как раз запись стару моде мы перестаём уже писать в старую модель после этого старая модель не используется её можно удалить то есть разница с прошлым подходом там мы читали две модели и переключались А тут мы пишем две модели и переключаем чтение Вот либо один подход либо другой подход можно использовать а Итак итоги по обратно несовместимым операциям что какую-то обратно несовместимую операцию по схеме либо по данных Мы преобразуем в последовательность обратно совместимых операций Ну и Да как уже сказал нужна совместимость в том числе по данным то есть новое значение для старой версии это обратно несовместимые изменения вот у вас будет много релизов и много маленьких миграций Ну так мы умеем реть Это не проблема И вот миграции которые делаются с помощью Ома Ну для это придётся исправлять то разработчики любят наделать кучу изменени в модели потом мне изменения будут обратно несовместимыми поэтому миграции нужно делать маленькими кусочками То есть например добавление колонки это отдельная маленькая миграция таких миграций будет много маленьких но зато Они все будут обратно совместимы То есть у вас будет много-много много миграций маленьких много-много много маленьких релизов Зато всё будет обратно совместимо хорошо и пожалуй самая такая интересная часть это возможно все наши проблемы из-за того что мы недостаточно много используем модный Молодежный а используем какой-то там старый по Вот есть же куча разных решений с решений действительно очень много они со схемой работают по-разному И если мы их начнём использовать все наши проблемы которые мы только что описывали что какая-то обратная совместимость нужна они пройдут давайте мы это посмотрим на опять же паре примеров Итак Хот работает с Бао данных и см реализация будет но по факту нам Ну некото представите этого лас с других буде такая так Итак снова неко время после релиза у нас в логах появляются ошибки вот мы ошибки пока не знаем В чём была причина но на всякий случай Мы откатывается на старую версию по Мы тоже знаем что релиз - это частая причина поломок Ну взяли Да и откатились оно стало меньше чем во время релиза Но полностью не пропали Вот тут-то мы и поняли что что-то пошло не так то есть мы-то думали что сейчас мы на старую стабильную версию отти вот и всё станет хорошо но что-то пошло явно не так что же делать Ну собственно смотреть в мониторинг Это ваши логи метрики трейс и пытаться понять что пошло не так Итак поехали первым делом мы смотрим влоги ищем там что-нибудь с lel и находим там вот такое сообщение что Вот кстати когда делал прогон того доклада внутри компании Коллеги с богатым опытом Мон сказали что у них такое исключение уже давно в голове вы так что для них это тоже вполне применимо и дальше мы для сообщения ло находим поэтому смотрим информацию в тяге ви у нас произошла ошибка сейчас давайте сделаем небольшую паузу Напишите в чат пожалуйста ваше предположение что могло пойти не так а мы посмотрим и возможно там уже есть правильные ответы Ну ладно вариантов пока нет поэтому Давайте дальше Итак что же пошло не так по сообщению об ошибке и по тому что это ошибка десериализации которая была после вызова кэша мы поняли что у нас изменилась схема при работе с кэшем то есть в старой модели было поле типа ин А в новой оно стало типа string Вот и старое значение в кэше сове не читается новой версия а новое не читается старой версии То есть пока работала новая версия на чтото в кш писала мы откатились - это значение по ключу видит но стилизовать прочитать не может то есть в релизе изменилась схема работе с кэш Давайте ещё раз то же самое там на коде подробнее посмотрим Итак у нас есть две модельки V1 старая и V2 новая и в старой модели поле категории типа int А в новой модели Поли категории типа string и вот когда мы пытаемся стилизовать старую модель когда данные у нас уже новые то есть ну у нас ничего не получается мы получаем ошибку хорошо то есть мы причину поняли соответственно как будем чинить Т Напишите опять же в чате как чинить Ну пока не вижу вариантов Ну собственно первое что приходит в голову а давайте-ка мы сбросим кэш вот а здесь опять же Давайте немножко подумаем Вот мы сейчас бросим кэш у нас после этого сразу всё станет хорошо или нет или а проблемы останутся там Денис отправил опрос тоже пожалуйста проголосуйте Как вы считаете если мы сейчас сбросим кэш всё сразу станет хорошо Или наоборот не станет хорошо так Ага Ну вот голоса пошли но на самом деле нет мы сбросили кэш и у нас всё хорошо не стало почему Ну потому что все запросы которые раньше отбивались кшм теперь они пошли в базу Ну база данных пошли всякие тайм-ауты потребление цпу там в полку и так далее либо у вас запросы Каширова не к базе а к каким-то сторонним сервисам вы эти сторонние сервисы Начали досить Ну бывают ещё редкие случаи когда кэшируется результат каких-то там вычислений тогда у вас будет расти потребление цпу на подах то есть лучше не совсем стало хорошо тут надо бы задуматься ваше приложение вообще без кша может работать или нет задуматься прекрасно е сбой не закончился У нас всё ещё ошибки сыпятся что делать у нас пустой кэш Какие есть варианты починки Первый вариант - это запустить подготовленный скрипт То есть если у вас есть Например какие-то товары или категории вы знаете самые популярные категории товаров вы берёте запускаете скрипт и он быстренько эти самые популярные категории намер 1000 штук он туда записывает при этом самые популярные категории теперь отбиваются кшм не популяр но огрею в кэше в штатном режиме Но это требует как раз такого скрипта и поддержание в актуальном состоянии вот списка самых актуальных категорий Ну либо какое-то шаманство То есть вы берёте вручную уменьшает количество коннекто к базе потом подождали пока кэш прогрелся И постепенно вернули подключение на место всё в данном случае сбой закончился все ошибки теперь у нас ушли и запрос отрабатывают штатно и теперь надо подумать А как предотвратить такие ошибки Как сделать так чтобы это не повторялось но надо понять что кэш - это тоже данные Да это данные там хранятся не всё время да да там нет схемы это тоже данные опять же нужно думать об обратно совместимости между старой и новой версией сервиса Ну миграции для кэша мы писать не будем это Смысла не имеет вот поэтому один из приёмов это сделать так чтобы ключ кэширования зависел от версии сервиса то есть в начало каждого кэша мы вставляем версию Ну тоже самое вот в коде то есть некая версия которая ну здесь захарко на самом деле она будет браться кружение Вот и при получении там любой модельки при обращении шумы представляем вот как префикс для любого ключа что мы получили это решение простое быстрое но безопасное работает во время релиза поддерживает откаты и так далее Потому что старая версия и новая версия Они покча вобще не пересекаются но такого подхода есть и минусы То есть например ш Пух два ра на время чтот ие новы хо ста потому что у нас при старте любой новой версии у нас кэш пустой что с этим делать Ну есть фантастический вариант ничего Если ваше приложение умеет переживать там сброс к прекрасно вот есть вариант не допускать броса кэша для этого в том же редисе используется спш или балок но не наш случай то есть использует скрипт для прогрева который можно встроить в pipeline который для новой версии чем-то заполняет кэш вот ну либо плавно включать новый функционал либо коно речным релизом а либо фича флагом то есть мы раскатились инстанса и постепенно по фича флагу его раскатываем Хорошо Давайте ещё раз внимательно посмотрим на то что у нас получилось у нас включить версия приложени То есть если мы каширу и товары и категории из одного сервиса у них префикс будет один и тот же если у нас изменилась схема для категорий кш для товаров Мы тоже скинем Это вроде не то что нам хотелось поэтому можно применить другой способ это версионирование то есть опять же это работает во время релиза поддерживает откат Нет проблемы холодного старта нет увеличения размера кэша то есть Прямо куча плюсов Но чем мы за это заплатили а нужно следить руками за актуальностью схемы то есть в прошлом варианте это у вас было автоматически а здесь слить за актуальностью схемы нужно Вам самим в случае если вы пропустите изменение схемы Вы опять получите ошибку получите сбой но и это ещё не всё бывает что например сервис для работы с категориями у него вообще все данные в кэш это одни категории и сбросить категории это всё равно что сбросить весь кэш Что делать в этом случае ну мы можем конвертировать старую версию в Новую то есть что мы тут делаем сначала берём новую версию если нашли то хорошо Если не нашли то берём старую версию и пытаемся сконвертируйте сложно мы можем явно использовать Две версии в логике то есть сначала взяли новую версию из кэша если она есть то используем Если нет то берём старую версию и её используем Ну если в кэше нет ни старых ни новых данных Ну соответственно читаем новую схему из базы и записываем в кэш вот ну и на самом деле про тот сбой который у нас случился мы его нашли достаточно быстро и поправили А ведь Могло быть и хуже то есть в новой версии могли удалить обязательное поле и лизар это мог проглотить то есть ошибки бы и тогда начинаются всякие неприятные ошибки в логике что-то перестаёт отображаться на Ю передаваться в сторонние системы и так далее То есть это куда менее приятная ошибка Итак итоги по шам там есть неявная схема данных на уровне приложения Вот и нужна точно также обратная совместимость между старой и новой версии вотт можно использовать версию приложения для всех ключей рекомендуй вариант пото что он более простой Ну либо явно версионирование за её сохра хорошо а что же насчёт эластика эластик так Ну давайте пару терминов про эластик да то есть это документ ориентированное хранилище час используется для хранения логов если проводить аналогию с реляционной базой таблица - это индекс в ластики Ну с строка - Это документ и ти поле в документе определяется первому вхождению То есть если пришло вот значение целое Ну это будет число а если туда же потом в in приведёт строка то это будет ошибка такой документ сохранить уже не удастся потому что поля в индексе определятся по первому вхождению то есть в ластике есть схема но она такая назовём это динамической То есть она определяется по первому вхож хорошо и там ещё есть такая операция как rollover А если опыт Хорошо Кто не слышал это как партиции в постгрес То есть можно сказать есть нека таблица как а всех возможных таблиц Да партия - это индекс в ластике и можно на создавать для Алиса мой индекс индекс на каждый день то есть пятого шестого седьмого и так далее И тогда при поиске данных например на какую-то дату Мы сначала можем найти нужный индекс а потом в нужном индексе искать Это намного быстрее Итак как я уже сказал ластик у нас используется для хранения логов более того У нас есть своя система замена сплан которая хранить логи в ластике и мы естественно пишем структурные логи То есть когда у нас отдель строка шаблон строки да отдельно значени которые туда подставляются вот когда мы пишем вло например вот номер туда попадает сначала целое число а потом по тому же ключу нам Мы пишем строку мы получаем ошибку что и мы не можем этого у попадают вот чтобы это отследить Мы вс-таки хотим чтобы все налоги писались вот мы настраиваем а по если сюда что-то попало к нам прилетит а вот что делать ЕС что-то попало ну можно понять где была ошибка и задеплоить Но это сза ребята сделайте ручно у на в этот момент сода но идекс Ну соответственно логи перестанут туда попадать Вот либо можно ничего не делать и просто подождать автоматического Но тогда надо смириться что у нас алерты Бут прилетать на то что что-то попало вот интересны гда попадают сторон ли раз мы вообще в эту библиотеку стороннюю пошли и сделали туда комит в опенсорс Ну и всё продолжило работать итог итог итоги по схеме давайте уже подводить Итак в постгрес есть схема на запись то есть что не соответствует этой схеме вы не запишете Дис как и монго есть схема на чтение на уровне приложения и elastic sech там динамическая схема которая определяется по первому вхождению Итак Э давайте подводить итоги доклада то есть мы поговорили о чём что на проде мы используем Rate либо для деплоя миграции допускаем в палай данные Гри при первом обращении либо в фоне либо эти подходы могут друг друга дополнять Мы последно применяем совместимые по коду и по данным операции и для кэша мы версио вклю и также где нужна обратная совместимость это как раз диаграмма порты адаптеры которы расла в цвета луковой архитектуры нас здесь интересует вот вторичные адаптеры То есть те которые вызывают это вот Web syst adapter это то что вызывает наш система это как правило кака коню I и например граун джобы а то что вызывается от нас это различные реджи это база кэш очереди и так далее так вот чтобы середину вам деплоить без тайма вам нужна везде обратная совместимость на уровне как слева первичных адаптеров те которые Вас вызывают если мы говорим про IP там обычно говорят Да нужно версионирование и обратная совместимость Так вам точно также нужна версионирование и обратная совместимость на уровне вторичных адаптеров которые вызываются из вашего приложения это база кэши http очередь сообщений и так далее а то о чём мы сегодня не успели подробно поговорить но где тоже нужна обратная совместимость это background Джоб которые используются инструментами как Кварц Вот соответственно новый Джоб сначала добавляем в код а потом в базу А удаляем в ряд порядке Ну и очереди сообщений интеграционные сообщение это тоже ваш контракт и там тоже нужна обратная совместимость там нельзя просто так удалять обязательные поля и так далее ну и очень полезно версионирование с самого начала Итак материалы по теме первоя это книжка вот фак баз данных есть классный доклад Николая Самохвалова на вот дальше можно смотреть курс рихтера по архитектуре на тубе можно изучать публичные постмортем и с оговоркой можно посмотреть последний доклад про большую базу данных там вроде неплохо говорится Но они там как раз миграции применяют при старте не в пайплайн из-за этого у них там ещё пробы Пришлось поменять и так далее То есть доклад неплох Но вот всё-таки миграции в пайплайн они при старте и в завершение хочу сказать что да банк он такой один а Нас двое Brothers и на этом всё спасибо за внимание Всем спасибо кто подключился вот Андрею Спасибо за доклад M"
}