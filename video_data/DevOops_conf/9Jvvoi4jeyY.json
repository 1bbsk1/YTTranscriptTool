{
  "video_id": "9Jvvoi4jeyY",
  "channel": "DevOops_conf",
  "title": "Интервью с Андреем Халиуллиным",
  "views": 149,
  "duration": 2165,
  "published": "2022-11-03T01:21:08-07:00",
  "text": "и вот мы снова в эфире меня зовут Антон черноусов я сегодня буду ведущим вот этой активности и вместе со мной прямо здесь вас поприветствовать Уважаемые зрители готов Андрей халиуллин Андрей Здравствуй привет самое что интересное ты был экспертом на одном из докладов здесь же на конференции девупс мы сейчас находимся в онлайне но на самом деле в оффлайне потому что как бы для нас совместилось чтобы были вместе с тобой на открытие оффлайн дня здесь и опять же мы сейчас прямо находимся в онлайне для тех кто смотрит нас и наше интервью длинная конференция получается три дня два дня было онлайн потом небольшой перерыв и сейчас вот оффлайн это круто что хочется мы как будто бы в какой-то момент пропустили в рамках вообще вот конференции вообще поговорить Вот разговор который вот мы сейчас Вот наверстываем эту всю историю разговор вокруг сервер Las потому что ну как бы нужно понимать Да я тут полочки сервер из потому что я ее люблю Как бы все экосистему и смотрю за ней очень пристально как она развивается А ты прям внутри как человек который разрабатывает сервисы конкретные имеешь некоторое представление как все эти механизмы работают изнутри Мне кажется многим кто нас сейчас смотрит может быть полезно то чем мы с тобой так сейчас обсудим и поделимся вот смотри прежде всего что мне хотелось бы Давай немножечко тебя представим более более обще Потому что ты же у нас занимаешься и функциями То есть это клад functions это сервис который является одним из базовых сервисов вообще в принципе неважно В каком облаке А мы оба с тобой работаем в Яндекс Вот и конечно же наши функции самые функции функции но тем не менее как бы где бы эти функции не находились они по-разному называются у разных облаках механизм работы у них примерно один и тот же если правильно понимаю там большей части там есть если это если мы говорим про именно сервис function The service Да там есть функции которые есть как нытик внутри cubernetis но они немножко по-другому там работают это как бы отдельная история Я думаю что мы к этому вернёмся через годик зернём эту историю допустим вот и смотри ты разработчик одного из самых базовых сервисов для системы и конечно же вложился в второй базовый сервис это который находится в промежутке между вот функциями И тем самым губернатисом про который мы говорили а имеется и я ему говорю про сервела с контейнеры То есть если мы напрямую как-то положим Вот это всю историю то есть где-то есть контейнеры которые запускаются в kubernetics Вот это какая-то такая вот монструозная сложная история Да функции с какой-то с другой стороны где вот у тебя есть кусочек вот какого-то кода который ты просто плюнул в облако Да и оно там само без тебя по сути дела работает и вот серовал с контейнеры они где-то посерёдке находятся такие промежуточный какой-то вариант То есть у тебя уже есть контейнер который ты сам собираешь на самом деле Да и ты окружаешь его в рейджестре То есть это тоже как бы такая как бы операция достаточно сложная Ну там менеджер это всё дело надо вот и потом а дальше Потом срабатывает автоматика то есть опять уже начинает все механизмы именно функции работают Вот кажется что для некоторых сценариев одно подходят лучше для других другое вот с точки зрения человека который разрабатывает основные базовые механизмы было бы интересно понять Вот как ты видишь Для чего что какой из сервисов лучше подходит Да тут как это окажется про это так довольно много активно не разговаривали наружу Да внутри только вся эта история обсуждали Вот он наверное здесь каких-то серьезных секретов нет тут Важно такой момент на самом деле мы себя всю пытаемся конечно использовать те технологии которые мы Собственно уже и сделали чтобы не делать одно и тоже два раза и тут есть такой очень интересный момент что сервис сервис контейнер он на самом деле полностью построен на функциях как на инфраструктуре по сути У нас есть единая как бы инсталляция функций в которой живут как вот пользовательские функции так и контейнер Ну то есть грубо говоря каждый сервис контейнер это на самом деле какая-то там функциях пользователей клиенты наши это не видят Вот Но это вот общие технологии в каком-то смысле это как способ продавать функции Вот и да Разумеется когда мы сервис запускали мы Ну как это у нас была какая-то тактика и мы ее придерживались нас была какая-то стратегия про то зачем это нужно Вот И там довольно много Конечно аргументов про то зачем этот сервис должен существовать но наверное основная такая идея у нас была в том что функции Ну то есть вообще заезд в любые функции любого облака они требуют каких-то сервер для специфичных как это сказать знаний чего бы то ни Ну короче люди много-много лет десятков не побоюсь этого слова лет писали какие-то сервисы и они написали определенный набор образов когда им говорят что теперь нужно писать функцию это непривычно люди разрабатывают надо поменять вообще подход такой момент должен случиться у тебя в разработке вообще всей как раз Да у меня был большой доклад про то почему этого бояться не надо все равно боятся и поэтому сервис контейнер он каком-то смысле сам по себе уже действительно правильно сказал приближает немножко к какому-то более классическому что ли способу писать сервисы с точки зрения там модели поведения для контейнеры наши рекомендации все еще на самом деле Это история и так далее Но именно вот форма запаковки она она другая мы туда приносим не ЗИП с кодом а какой-то собранный контейнер а внезапно там здесь втором году примерно каждый девопс знает как собрать докерный контейнер они это делают почти всегда в кубе у вас контейнеры там есть контейнер отнимать ты можешь не помню как она у него маркетингование вот контейнер тесты мы гоняем контейнер уже все в контейнерах если можно взять этот же контейнер за диплоить куда-то в новое место то ну как-то выглядит что клиенту так проще переехать на контейнерную систему то есть там фактически какие-то сбоку рюшечки шильдики вокруг функции Вот получается как бы контейнер и соответственно если говорить про то Для каких сценариев лучше контейнеров для тех функций Ну контейнеры лучше если вам удобно работать вообще с контейнерами а-а есть ряд сценариев которые сейчас в функция в принципе ну как это не то что нативно не решают у нас нету рекомендованного способа их решать нативно Например если вы пишете на каком-нибудь из языков функциях не поддерживает например мы не поддерживаем пока Rust как конечно проще перечислить чем мы поддерживаем Ну да Давай скажем раз и все Дальше по мелочи остальное мне просто раз регулярно приходит нам в сервела скамьюнити ребят таки типа А вот runtime Rust у вас появится мы такие вот это пожалуйста вот контейнеры раз плюсы те же самые которые Ну появились конечно до сервера честно но тем не менее у нас нет да и вот такие вот штуки если вы знаете как свое приложение завернуть в контейнер Почему бы не завернуть вот есть на самом деле места где функции всё ещё как-то рвут контейнеры и Ну не то что всё ещё вот если взять какой-нибудь там Джес Например у нас какой-то год назад по-моему мы э делали анонс про Анну Джес и питон последней версии что они стали быстрее У них там быстрее значит третьего класса это была как раз история связанная с ускорением старта да да то есть у нас там появилась технология которая позволяет загружать часть Я не знаю Сколько деталей будем погружаться перед загружать часть какой-то значит функции которые вообще то есть типа у всех проблемы опишем изначально что когда у нас загружается функция по большому счету она не находится в некотором оперативном пространстве она должна включиться и вот это время старта с момента когда пришел запрос в внутрь нашего облака до момента когда собственно говоря сама функция начнет выполняться вот есть время Вот это самого холодного старта колд старта нужно называется это время когда собственно говоря производится загрузка грубо говоря здесь хранилища поднимается это соответственно функция создаётся Ну мелкая виртуальная машина куда подставляется память диск и собственно говоря инжектец код после этого соответственно Старт производится да да И вот Я вот как раз если об этом говорить там есть действительно этап где мы загружаем именно Ну runtime на случай GSM мы запускаем бинарь на GS с каким-то нашим немножечко кодом а потом туда подгружаем уже пользовательский код функциях и она начинает бегать и соответственно стартап Где нам нужно загрузить наджасной runtime мы его можем оптимизировать функцию потому что у нас много функций над жестом runtime мы можем там загашнике держать немножечко такие перед прогретые виртуалочки в которых это все уже работает вот пул даже до ровно так и это дает неплохой Boost на старте и в общем идея в том что для таких такие решения мы можем проворачивать Джесса для питона для каких-то популярных решений Вот Но это то место где контейнеры даже в перспективе кажется никогда не смогут работать быстрее наверное именно вот этот именно холодный старт Они не смогут никогда вот у них Не уменьшится Да но если мы сравниваем именно сайт типа там функция нано Джесси или контейнер на Джесси Ну потому что Джесси как бы сам тоже часть вот пользовательского кода по сути вот так вот то есть в перспективе Наверное мы тут конечно стремимся к тому чтобы сокращать везде И наверное может придумать что-нибудь чтобы оно было хотя бы не медленнее не сильно медленнее чем функция быстрее Она точно не будет На данный момент конечно жестом быстрее гонять функциях а в конце статистика кстати которую мы не так чтобы давно собирали у нас была конференция Яндекс Скейл где мы соответственно под неё подсобрали статистику год году подбили и что интересно у нас соответственно с одной стороны у нас есть статистика по использованию языков программирования Ну как бы и на первом месте тот самый питон который рвёт всех был момент весной Я выступал Кстати на конференции как раз к этому моменту но GS вырвался вперёд вот мы как бы наша статистика она сошлась со статистикой амазона потому что в амазоне ввсе соответственно первый runtime по количеству запусков это как раз нос Вот вот наша наша разработчики российские прям вот они все переплюнули как бы питаться питанистов и как бы вырвались вперед наконец-то случилось и потом кости обратно откатилась ну смысле они смысле там количество пользователей количество функций все выросло но просто питонисты догнали и опять вырвались вперёд Я такой думаю блин недолго музыка играла но тем не менее Да значит соответственно у нас два самых популярных фантайма - это Джес питон а потом э-э го там как-то прыгнул потом количество уменьшилось но зато увеличилось количество а контейнеров которые запускаются с гору по сути дела внутри и вот Java вот эти рантаймы они Понятно скорее вот превалируют к тому чтобы ну как бы вот запускаться на контейнерах Ну Java это больная тема она конечно по природе больше похода даже с питона и чисто теоретически мы там должны тоже мочь больше профита Ну больше скорости давать именно функциях но функциях сейчас короче я скажем так Ну честно не готов рекомендовать Java для каких-то быстрых операций потому что объективно у нас пока работает не очень Шустро на кол стартах но мы на самом деле этим как раз занимаемся Но это пример того ран-тайма где все-таки как это если бы есть потенциал Да да есть потенциал именно функциях контейнерах там он та же история запускаешь GM Ну то есть мы как-то не можем ее прогреть заранее Но вот это как бы это такое как бы состояние как бы прямо вот на Сейчас если мы будем говорить и это история с которой на самом деле борются все все облака находится вот в состоянии что мы пытаемся придумать какие-то инструменты которые помогают вообще быстрее запускаться И на самом деле главный стоппер для многих переходить в servers потому что ну что это у вас там так медленно все запускается вот оптимизация которую вы сделали с быстрым стартом прогретами контейнерами она конечно очень сильно подтолкнуло вообще всю аудиторию сервис контейнеры тоже очень сильно подтолкнуло всю историю с точки зрения пользовательского опыта но тем не менее есть все еще люди которые не готовы были переходить Потому что Ну говорили что время реакции все еще их не устраивает Но для них вот у нас появилась новая опция Мне кажется она помогает очень сильно ускорить всю работу Ну правда она стоит денег да да у нас появились А как же мы этот документации назвали подготовленный экземпляры прогретый подготовили там год что-то значит это танцевали с тем как это в итоге назвать в последний момент кажется какой-то там что-то писали в документации то и поехала Да у нас появилась такая фича мы не очень громко кажется про неё рассказывали на конференции Skill кажется только вдвоем Да докладе по-моему еще накинул накинул по-моему Данию кино рассказывал практически потому что там одной строкой фактически мы поговорили Давай сейчас поговорим потому это сама по себе прикольная фишка Давай поговорим о том как до этого прогревали функции с точки зрения пользователя потому что одним из самых Ну простых как бы способов был ну Ping по сути дела Да но проблема в том что он там честно говоря не давал никаких гарантий то есть про то сколько функций сколько экземпляров функции живет и ждет следующего запроса В общем это процесс он управляет какие-то наши эвристики то есть это как бы типа это наша забота Да у нас интерфейс пользователя заканчивается на том что если мы дали запрос то где-то обработается дальше он обработался и но мы типа ничего не говорим про то сколько времени там еще что-то витуалка ещё будет жить тут как бы с одной стороны у нас с нашими клиентами цели как бы похожие Нам же интересно как можно более эффективно утилизировать кластер чтоб там было как можно больше клиентов соответственно Мы тоже заинтересованы в том чтобы стартов было как можно меньше Поэтому наши эвристики как-то целиться В то чтобы ну как бы если функцию имеет смысл там экземпляр дать дать ему пожить Вот Но тем не менее это эвристики И вот какие-то механики спинками они эти гарантии не давали потому что мы не можем рассказать как часто надо пинговать И как именно вообще чтобы она там что-то жило Ну да Такая механика была типа Давайте Мы периодически функцию будем Значит тыкать палочкой чтобы она не отмирала Да ну как бы на самом деле эти же механизмы вообще в принципе во всех облаках работают потому что как мы знаем после того как запрос отработана функции есть еще какое-то время когда вот эта самая микровиртуалка еще живет большому счету там есть некоторые утилитарное время за которой она точно будет уничтожена но тем не менее там в пределе как бы где-то можно там между этими туда пытаться палочки потыкать и как бы вроде как это давало возможность людям не то чтобы сильно много тратить денег Но при этом как бы иметь прогреты функции прям вот чтобы они находились в Облаке это механизм ненадёжный он в принципе стоит каких-то и нужно на стороне где-то держать этот попенгатор от чего от чего мы все собственно говоря и пытаемся уйти в сервеласе потому что ну как бы тебя должна быть чисто архитектура вот в том смысле что тебе не должно быть вот этих вот внешних работающих штук каких-то механизмов и в принципе был придуман механизм и он примерно всех провайдеров облачных реализован примерно одинаково Ну у тех у кого он реализован Думаю здесь можем уверенно говорить про ВС и вот у нас тоже также работает примерно все вот про название честно говоря тоже не помню всех называется по-разному все по-моему в последний момент придумывают названия как-то как-то история работает давай про суть расскажем То есть это как это это заранее прогретые функции или контейнеры которые по сути дела стоят под парами и ждут ну по сути пользовательского запроса фактически да то есть у клиента появляется возможность сказать что у меня такой-то функция такой-то контейнер И вот я хочу чтобы там как минимум столько значит экземпляров всегда жила И было готово обрабатывать нагрузку они все еще там Что называется виртуалочки то есть они как бы вот когда они фоне живут они не могут что-то делать все еще модель лестная но физически она запущена и соответственно когда приходит запрос нам не нужно где-то выделять виртуалку значит запускать туда runtime поднимать код подтягивать и так далее Там уже все бежит виртуалку где значит прилетел и как бы она дальше побежала Ну по сути дела Это очень прикольный механизм сам по себе потому что мы как раз здесь убираем вопрос что нужно держать где-то на стороне какую-то штуку которая отдельно работает и не серверная поппингатор оно все там из коробки работает для пользователей не нужно ничего придумать прямо внутри интерфейса сказал конкретно вот эту функцию столько-то экземпляров хочу И вот чтобы со стольки До скольки они работали и соответственно они будут запущены то есть нужно понимать что например если Как как можно вообще подходить к этому если вы мониторите свое приложение Если вы знаете что у вас там например там каждый день в течение рабочей недели у вас с утра всегда есть пользователи и например тех пользователей там 10 человек приходит там ну как бы там каждую секунду Да вы можете понять сколько вам этих контейнеров поднять заранее резервных там за час до вот этого Пика начинает поднимаете резервы соответственно они у вас взводится условно говоря и в момент когда начинает приходить пользователи они уже работают и скорость реакции конечно моментальная практически моментально поставить потому что в компьютерном мире не бывает чего моментально мы все прекрасно понимаем Да но здесь кстати интересный момент что вот эта фича она чуть интереснее чем может показаться на первый взгляд если что она просто начал тоже говорить с того что тут платная такая штука разметика она платная да то есть вот на то время пока у вас зарезервирована условно не знаю там 22 экземпляра Функции там с каким-то объемом памяти Ну мы билим это время в смысле то время простой Разумеется не по тому же счет как этого чеку по которому как-то прайс по которому мы видим вызовы вот сильно дешевле мы несколько месяцев по-моему Сидели там с какими-то и крутили эти Циферки значит про всю эту историю то есть да у нас появляется билинг за Вот это время простое там все равно Ну как для сценариев когда у тебя нагрузки Что такое Старт когда у тебя нагрузки почти нет но иногда она есть вот из этих сценариях запросов мало И вот для этих сценариев имеет смысл действительно использовать прогретый экземпляры Если вы готовы платить за вот во время простое опять же на функциях небольшого масштаба чем это отличается от компьютера от компьютерной Виртуал 128 мегабайт Ну типа 7 не закажете экземпляр функции заказать можно 128 мегабайт зарезервировать Это будет ну там точно дешевле чем минимальная виртуалка Да и более того это же может быть не просто функция это может быть контейнер или контейнер А в контейнере у вас может быть развёрнута чертичо из боку бантик Да в пределах 120 мегабайт Можно конечно естественно поднять и другая механика появляется вот это один сценарий это действительно борьбами для редко вызываемых каких-то функций Но где именно важна вот эта вот история Ну как бы странно реагирует на появление запросов А есть другая история А вот мы же говорим что сервер какие-то деньги экономит когда есть какое-то Ну там необычное потребление детей это мощности они хороши для вот такой вот запросов до горизонта и соответственно хорошо прогнозируем ресурсы Да мы заказываем ровно столько виртуально Сколько надо плюс немножко и резерв там потому что там Disaster всякой рекаве вот этого цвета короче ну ну как-то всё равно Да так оно работает на фоне Вот вот этого общего потолка даже как бы и не роляет Да а вот когда у нас нагрузка какая-то в смысле она вот так вот пляшет еще и трудно прогнозируемая и с очень хорошей амплитудой вот здесь может даже вот там без резервов начать интересные Как играть в серверы потому что собственно у вас та ночью оно скелет в ноль и там стоит ноль а днём оно там ну пикивающим под пике масштабируется но есть ещё это класс сценариев когда у людей нагрузка плавающая но плавающие не до нуля да то есть вот у людей какой-то большой потребление сервисе Вот и то есть грубо говоря у них так это константная вот эта большая тумба на дне ещё вот так вот значит вот такие вот волны идут Так вот тумбу имеет смысл загрязнять резервы Потому что если вы свои резервы за которые вы там значит изолировали Простите более-менее там Full Time на постоянку то вот так будет меньше то есть типа суммарно как это сейчас если у вас заказан один экземпляр и у вас нагрузки ровно столько чтобы утилизировать один экземпляр то это суммарный чек значит за вот такое потребление выходит дешевле чем если он Диман просто без зарезервированных экземпляров такой же нагрузку подать сервис вот поэтому вот Константа тумбочку имеет смысл таким образом оптимизировать с точки зрения денег нам-то это тоже интересно потому что когда у нас накапливается клиентская база которая натыкали себе экземпляров У нас у самих появляется тоже какой-то пользовательский паттерн который мы пытаемся отработать и стимулировать соответственно разворачиваем постоянных нагрузок да Потому что когда у нас как это у нас большой кластер там много-много скажу какому порядка ядер Да вот и при этом там живет там сколько-то не помню там тысяч десятки тысяч или что там разных уникальных функций и каждый из них в каждый момент времени имеет возможность скелиться что-то от нуля до скольки вот и ну то есть это такая слабо предсказуемая штука на больших числах она конечно сходится но всё равно её немножко колбасит то есть на Когда у нас появляется такая постоянная составляющая Нам тоже конечно радостная в этом смысле Кстати это тоже один из паттернов вообще работает то есть когда ты понимаешь как у тебя Ну с точки зрения дефопса Да ты в обратную сторону выгружаешь метрики Ну к себе и такой типа Ага как бы у меня вот действительно Вот такая нагрузочка вот она постоянная Вот здесь она постоянно здесь не постоянная здесь у меня потолочек как бы ты вокруг этого начинаешь оптимизировать вообще затраты у нас кстати был доклад я не помню он успел про этот паттер рассказать или нет Я тоже не помню честно можно будет посмотреть в Интернете потому что все доклады со скейла конечно же доступны но давай вернемся как бы к вот этой вот истории про сервелась экосистему мы начали как бы с функцией функции функции а на самом деле у тебя под крылом конечно же находится еще один сервис который мы анонсировали в этом году Это Клауд логинг и он конечно же работает с режиме полностью утилизируем все то что мы как бы сами производим и там когда будем на полную катушку то есть по сути дела Клауд логинг это такой сервис который по большому счету позволяет тебе из твоих вот сервисов вытаскивать логики складировать их отгружать там и так далее с этим совсем взаимодействовать ну и плюс потом можно нагружать там всякие разные другие разные источники вот что там сейчас поддерживается Ну понятно наша функции наши контейнеры наши аппетитвы вот это всё это конечно же наше всё поддерживается Да у нас еще такой длиннющий хвост сервисов которые вот где-то уже на финальных этапа интеграции с логингом вот я тут тоже не знаю имеет ли смысл это как-то спойлерить скажем так ну короче у нас большие планы по поводу того как как мне сравнение очень похоже когда-то облако запускалось в Облаке окажется не было сервиса мониторинг Ну как централизовано а потом он появился и вот дальше почему-то думал что Соломон всегда был вот мне тоже знаешь в голове немножко ломается давай так по-другому сформулирую когда-то к нам всем дружно пришел значит наш директор облака скажем тогда и сказал Давайте все сервисы у которых есть хоть что-то что имеет смысл выкладывать мониторинг пользовательский Да должна выкладывать мониторинг потому что ну как бы обидеть и вот у нас был такой период когда мы за полгода кажется все сервисы были менее покрыли все свои активности этими мониторингами потому что это такое инфраструктурный сервис который дает пользователь диагностику о том что происходит ресурсами в Облаке И логинг это тоже такой же сервис и соответственно Вот сейчас он вышел билете Кстати у нас там последние несколько дней еще можно покупайте бесплатно С 1 октября включается биллинг сервисе ноября да да с 1 ноября Да поэтому То есть как раз что тут во вторник включится Да да можно ещё успеть почитать какие-то логики на халяву и Да и как бы сейчас у нас как раз стартануло тоже это активность про то что сначала Мы конечно начались были дружественных сервисов поскольку сами разрабатываем функции и ну как бы они там дружили прямо с начала времён А дальше мы бежим по сервисам и туда будем подключать всякие другие интересные Ну там turbernatis уже естественно как бы ближайших планах губернатике сайлб АйТи Простите но у нас просто тоже под боком Поэтому с ним кстати про уйти Давай тоже поговорим потому что тоже мне кажется такой в некотором смысле сервер в некотором смысле потому что под низом всё-таки много всего происходит потому что пользователь как бы он когда как работает у нас по большому счету пользователей есть какие-то железки или там инструменты которые работают протоколу и производится отгрузка данных в облачные вот провайдер назовем это так не помню как правильно называется Сейчас сейчас еще брокер появился который через который можно соответственно железки между железками уже общаться тоже Ну через облако по сути дела у тебя могут они в разных местах стоять ты можешь с одного места как бы взять и накинуть какие-то управляющие воздействия по всем железкам которые у тебя где-то раскинуты я недавно слушал сейчас готовится один из докладов про сельхоз и АйТи там железки которые вот ты будешь смеяться Но это как бы железки которые работают внутри всяких курятников и ты такой блин а вот это настоящая уйти вот это вот ну как это автоматизация производства Да вот эти вот там нет большой автоматики какой-то Ну в смысле нет больших процессоров каких-то это вот низковольтная какая-то вся фигня но при этом по-настоящему идти потому что они отгружают данные в общую систему они принимают управляющего воздействия они собирают информацию и реально помогают там ну банально там самое простое они охраняют тупо это все ну то есть там некоторые железки Да помогают как мониторить А что там сколько и Сколько яиц сейчас как бы ты такой думаешь Опа То есть когда там кого покормить надо там отсыпать Там зерна там закрыть проветрить потому что ну температурный режим наблюдать и такой Подожди вот это всё это же должно работать в it я такой оп и у меня смачились эти истории То есть если до этого я всегда как-то промышленный объекты Ну или Home Home dipo такой то есть когда у тебя дома там розеточки там Алиса Вот это всё как-то оно там живёт у меня почему-то у меня идти вот с этим ассоциировалась Да а потом потом меня расширилась на всякие такие полупромышленные объекты типа парковки типа там заводы не заводы мелкая автоматика каких-то объектов таких промышленных и тут у меня вот третий кусок как бы подъехал сельхозка всякая такой опа для этого у нас в этом году вышел апдейт и собственно говоря немножечко спойлернуть чуть раньше это собственно говоря про брокер Расскажи маленько Да но тут довольно простая произошло как-то изменений изначально эти города запускался под конкретную цель действительно на самом деле дать какое-то потребление в облако от среза наших клиентов у которых есть какие-то Железяки поэтому Там модель работы сервиса она была заточена под сценарий взаимодействие облако с конечными какими-то железками между штуками в тайге там были такие сценарии и это и прячем куда-то не знаю там вечные мерзло то Вот сейчас мы подумали немножко и поняли что вроде бы нет причины не приоткрыть не расширить этот сценарий с другой сценарий Это когда хочется Ну как-то чтобы Железяки друг с другом общались и для этого нужно вот собственно какой-то Центральная точка Вот подразумеваю что взаимодействие по модели звезда есть какой-то сервер и к нему подключается разные штуки не этот сервер или нужно где-то поднимать собственно decked мощности или там дома бабушки там в гараже где-нибудь Там интересно что инфраструктура облака построена таким образом что вот прям все все сломайте одновременно не получается потому что все как бы помогает друг другу выжить до нас Разумеется есть процессы как бы пометикаться по всем поломками даже потенциальным поломка у нас процесс где мы всей толпой собираемся Разбираем Как сделать так что такого больше не было с разных там точек зрения с точки зрения там устранения кого-то с точки зрения реагирования И вообще Вот про это все Мне кажется что если на паблику ребята есть доклад про то как они что-то сломали то это вот какая-то такая скажем тенденция всех вот этих вот такого рода разборов Там должно быть что-то наверное интересное вот с точки зрения опыта Элементарно Ну да потому что вообще вот опыт опыт борьбы с какими-то ошибками он достаточно серьезно накапливается как только у тебя вот какой-то коллективное работа возникает А когда много сервисов естественно вот Работаешь уже в таком режиме что тебе нужно собирать какую-то команду Каждый раз когда инцидент какой-то происходит потому что не бывает в любом облаке Вот это кстати тоже очень интересный момент я хотел бы отметить что всегда что-то ломается вот если вы просто начнете мониторить любое облако вообще какое есть Вы прям вот какой-то момент какой-то один сервис деградирует второй сервис Вы даже можете не знать что это происходит потому что автоматика построена таким образом что она польский запрос например в другую часть облака перенаправляет какие-то моменты позволяют дублировать запросы сохранять рабочее состояние и так далее но на самом деле постоянно идет процесс вот починки как бы разбор этих инцидентов И с этой точки зрения облака достаточно устойчивость самой самой внутри себя при этом серовалась экосистема с точки зрения именно сервер леса и с точки зрения архитектуры именно приложений она выглядит более устойчиво потому что даже если что-то где-то ломается то у тебя как бы новый экземпляры запускаются чего-то где-то я они вот по облаку размазаны там как это невозможно накрыть одним ударом как бы про структуру да Это действительно правда И вот как раз такой есть интересное наблюдение что сервис functions например спокойно переживает выпадение полного там одного до центра полностью Ну как у нас любой сервис конечно строится по такой архитектуре что он должен сам сервис должен переживать в падение до центра но если вы используете например компьютер да сэкономили копеечку и завели себе одну виртуалку да то в случае какого-то полного атаса Я не знаю там свет выключит во всей какой-то там области и дота-центр совсем слотница Ну у вас не будет этой виртуалочки потому что она конкретной зоне а функция она как бы ну типа везде то есть мы на самом деле зачастую тоже практикуем такие штуки когда что-то вроде бы непонятное и странное подозрительное проходит это происходит в центре а давайте-ка закроем в зону функции чтобы ну как бы на пользователей не было вот этих вот плохих эффектов Это как раз одна из один из уроков который вынесен как бы из вот этих вот аварийных ситуаций Что ты на мониторинге видишь что что-то что-то давайте-ка вот сейчас вот просто как бы отрежем туда трафик для того чтобы соответственно наши пользователи не страдали это Это вся работа мелкая она происходит за как бы просто не видно даже собственно говоря и поэтому огромное количество каких-то нюансиков которые происходят пользователи снаружи просто не замечают при этом как бы надо понимать что вообще всегда все ломается Ну то есть горят железки это у всех происходит это вообще этого не избежать там где-то выпадает память где-то там посетить что-то происходит был совершенно замечательный доклад одного из коллег который рассказывал про сетевую инфраструктуру какие там нюансы происходят носки или было я прямо смотрел его и утирал слёзы ушанкой потому что как бы ну то есть там всё где-то провод не дотянули где-то там пыль какая-то была да выяснили потом эти моменты да и вот эти вот инфраструктурные штуки как они сильно влияют на на то что Там сверху построено это тоже очень интересный момент Но при этом что интересно Все работает но это Наша задача как бы на самом деле и Давай вернемся немножечко к серверус у нас не так много времени осталось Вот как ты видишь что следующее мы пытаемся взять какую следующую вершину внутри сервера потому что вот прямо сейчас вот на так сказать у тебя на экране на радаре находится вот у нас осталось пару минут буквально неожиданный вопрос я понимаю внутри много обсуждаем Да да у нас как раз активно идет это такой стратегическое планирование но с точки зрения того что ну сейчас скажу во-первых у нас есть такое направление которое наверное не знаю насколько разными способами хотим наращивать просто потребление это не обязательно какие-то там пользовательские что ты про которые наши клиенты явным образом знают вот есть разные можно нарастить потребление привлекая клиентов там их более старых классических сценариях очень направление которое прорабатывали А с точки зрения каких-то нативных сервера лестных штук Но вот у нас еще появился там клаудэпс например про который мы тут поговорить но он пока потому что закрытом превью в открытом Я думаю что мы потом отдельный доклад на это сделаем историю как потому что там сейчас особенно когда закончится вот подготовительные всякие этапы дополнительные вот сейчас закрытый этап пройдем Мне кажется будет интересно многим послушать как это работает и как это собирается там вот все фактурка она мне кажется очень такая на самом деле здесь направление огромное количество это не уверен что за оставшиеся секунду успею это перечислить но например там хотим как-то стремиться продолжать приближать вот это вот наша система по набору фичи что ли Как будто более классическом компьютер и так далее ну и плюс сделать какие-то высокоуровневые вещи которые позволяют более удобно употреблять в таком нативном режиме вот больше качество сценариев открывать Да ну и я думаю что мы сейчас с тобой и закончим Пока так сказать тизерить и попрощаемся с нашими зрителями До скорых встреч увидимся с вами где-нибудь на просторах интернетов и конференций Спасибо всем пока пока"
}