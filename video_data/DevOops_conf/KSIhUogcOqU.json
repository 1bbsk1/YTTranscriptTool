{
  "video_id": "KSIhUogcOqU",
  "channel": "DevOops_conf",
  "title": "Александр Лукьянченко — Service mesh для построения мультикластерной системы",
  "views": 633,
  "duration": 3621,
  "published": "2020-02-07T07:54:02-08:00",
  "text": "у всем привет от меня зовут александр я работаю в компании авито и занимаюсь созданием нашей внутренней платформы как сервис и облаком то есть делаю развиваю облачные вещи которые мы используем и триаде то вот сегодня расскажу про наш опыт построения системы мульти кластерные какие там проблемы всплыли да как мы их решили вообще посмотрим на разные подходы посмотрим на их плюсы и минусы вот тритон начнём с плана посмотрим сначала на проблемы которые возникают при внедрением низких кластеров в одном окружении посмотрим на то какие есть готовые решения то есть то что можно было бы до взять и использовать рассмотрим их плюсы минусы что они решают что они решают затем бриф или просмотрим сервис наш подход да так он уже был сегодня данным других докладах уже рассказывали про этот проход поэтому быстро пробежимся и далее уже посмотрим наше решение которое как раз его использует да и посмотрим уже в глубь какие особенности что мы там забили ли для того чтобы решать возникающие проблемы вот посмотрим на возможности и в конце подведем итоги посмотрим что из этого получилось что сейчас можно использовать что нельзя какие вообще есть проблемы так далее ok давайте начнем вообще как бы если зайти так издалека у нас где-то вот 4 года назад авито произошла такая трансформация мы начали делать микро сервисы и если раньше это было одно такое большое приложение то теперь это уже сотни дать скоро это будет там четырехзначное число микро сервисов каждый с которым взаимодействует по сети причем это может быть там взаимодействие синхронная может быть асинхронное взаимодействие по шине данных это неважно главное что они все связываются друг с другом по сети то есть как-то общаются по не которому каналу и основная проблема да и задачи которая всплывает когда мы переходим на микро сервисную архитектуру это менеджмент всех этих связей до тепло и приложений решение проблем поиска этих сервисов сервис discovery наливании трафиком на разные инстанции этих сервисов в такой системе которая динамично да то есть когда он большое количество сервисов они постоянно как-то меняются deep ловится то есть такое уже не совсем статике вот и естественно все эти вещи желательно решать автоматически чтобы системные администраторы не писали какие-то там рутинные манифесты не занимались там ручным schedule янгом и так далее вот и для этой задачи мы уже достаточно давно уже больше трех лет продакшене используем регистратор кубер notice который из коробки нам решает эти проблемы он нам позволяет находить сервисы дата сделает из коробки сервис discovery он позволяет нам наливать трафик на нужные инстанции позволяет балансировать между инстанциями чем решает все основные задачи которые нам нужны при работе с микро сервисами вот одеть в целом все прекрасно в пока мы не приходим к тому что у нас появляется несколько кубер notice кластеров в пределах одного окружения например в продакшене вот появляются они естественно не просто так этому есть причины первая причина это внедрение нескольких дата-центров например то есть мы ставим по каждому кубер найти с кластеру по по одному убирать из кластеров каждый дата-центр для отказоустойчивости до чтобы если вдруг происходит к это деградация другом dc мы могли эти ресурсы как-то восполнить и обрабатывать запросы также без одного дата-центра вот поставить один кубер notice кластер на несколько дата-центров технически конечно возможно но здесь есть много таких подводных камней как тонкая настройка базы данных который использует кубер найти сдаетесь иди правильно выставить тайм-аут и чтобы пить и градациях это все system система не развалилась и на самом деле когда будет происходить какой-то деградация в одном из кластеров нужно еще и в пределах тогда этого одного большого кластер а как-то уметь обрабатывать все эти деградации чтобы сервис и все еще находили нужный им инстанция да там в текущем кластере или в другом кластере вот поэтому один большой кластер это не решение мы ставим несколько подбирать из кластеров каждого свое dc и есть еще второй момент мы о нём поговорим уже там ближе к концу это обновление нетесов мы их также делаем через дополнительные кубер на диск кластера которые ставим рядом и обновляем перетеканием всех сущностей вот и здесь на самом деле появляется множество проблем когда у нас эти все кубер найтись кластеры находятся в разных dc они полностью изолированы у них есть свой control plain мы не можем уже так просто например взять и сходить в какой-нибудь сервис например мы идем по dns имени сервис payments когда мы это делаем 3 одного кластера здесь все понятным и отрезал very там виртуальная пи адрес и пошли там через систему стандартную куба по потом да здесь все работает когда у нас несколько кластеров мы уже должны делать какие-то телодвижения для того чтобы попасть другой кластер это может быть там ingress контроллер это могут быть какие-то другие решения ну почему же мы должны делать какие-то телодвижения для получения доступа в другой кластер вот и на самом деле тут стоит вопрос как вообще это взаимодействие выстроить как сделать так чтобы все эти кластеры стали часть в единой системы которая бы не приносило нам какой-то боли при эксплуатации при использовании продуктовыми разработчиками до который просто пишут сервисы и обращаются в другие и здесь мы так формализуем список требований что мы хотим получить до системы до как мы хотим ее видеть в итоге первые мы хотим прозрачной discovery что я вкладываю в это понятие например опять до пример с сервисом payments мы захотели сходить в него какое-то по имени сервис поймать когда мы начинаем открывать новую типе счастью для того чтобы в нее пойти у него поедет мы не должны думать о том где он находится то есть есть он в текущем кластере нет его вся инфраструктура должна сделать так чтобы просто дайте в инстанс который где-то существует причем не важно он локально или он в каком-то другом там кубер notice кластере следующий момент это dns имена это возможно наша такая особенность но тем не менее у нас уже сотни до сервисов ближется близится это к тысяче количество и при переходе на новую схему балансировки и discovery очень больно было бы менять dainese имена то есть нас многие сервисы обращаются в другие просто по по имени то есть это стандартно discovery куба это там имя сервис одним space и пошли в сервисе вот если эту схему ломать ну это боль это все нужно переходить поддерживать сразу же одновременно два flow то есть старый способ discovery и новый желательно dns имена сохранить следующий момент балансировка по низким кластером как такая не знает уже наверное бонус фича в идеале обрабатывать не только ситуации деградации но и в том числе использовать все доступные ресурсы которые у нас есть системе то есть например если у нас есть несколько дата-центров в каждом из них достаточно большое количество серверов и ресурсов доступно то было бы неплохо когда мы идем из одного сервиса в другой в том числе балансира ваться по инстанциям не только текущего кластер а ну и в том числе еще какой-то процент давать на другой кластер другой dc и в то же время поддерживать локальность то есть никто не хочет естественно ходить всегда на там раунд роббеном просто по всем инстанциям по текущему кластеры по другому потому что канал и там между центрами они шифруются до этого там bpm это достаточно дорогие операции это уже повышенный latency для похода в сервис который находится в другом это центре и естественно в идеале нужно сохранять локальность то есть если есть сервис рядом надо идти в тот сервис который полагается рядом и уже такое совсем такая хотелка это конри релизы так как мы занимаемся по сути сейчас изменения балансировки да тот путь как мы это вообще делаем да то было бы неплохо еще и поддержать возможность наливания процент на трафиком то что не умеет кубер носить из коробки то есть на разные сервисы все они разные сервис на разные версии одного сервиса мы льём процентных долек трафик ok первое что мы начали делать это research дамы начали смотреть какие есть решение которого позволяли нам достаточно такой легкостью решить это причем в идеале это должны были быть решения которые были максимально нативный и максимально интегрироваться с кубер найти стенда чтобы в будущем не было проблем при их развитие да там при обновлении новых версий куба и так далее и здесь есть несколько готовых решений которые мы посмотрели первое решение которое мы смотрели был кубер не той это такой специальный инструмент от core dns который позволяет поставить специальный dns сервер который слушает сразу же любое количество кубер на ли сайтов да то есть разных cобрались кластеров из них получает сервис discovery то всю информацию о том какие сервисы то там кий у них айпи адрес от виртуальные полностью наполняется и затем когда мы уже идем например из сервисов какой-то другой сервис мы обращаемся к нему и говорим расскажи мне как где этот сервис живет и уже каберне то и отдает зависимости да там от каких-то правил или просто там раунд роббеном соответствующие эти адреса разных кластеров то есть он может отдать эти адрес в текущем кластере виртуальный может отдать виртуальный адрес другом кластере вот но смысл его в том что он как бы объединяет аккумулируют себе это все вот если посмотреть на плюсы и минусы здесь такой как бы в кавычках можно сказать что это нативный подхода к балансировке который есть кубер на рисе потому что мы из кубер не то и получаем виртуальный адрес стандартный дает который вот кластера и пик умер на тисовой который затем мы уже на там даже каким то способом там сэ 5 был сыпи в с правилами на ноги преобразуем подойти и это как бы схема она очень достаточно на тема для каберне tissot но здесь есть проблема первая проблема это то что когда мы получаем виртуальный адрес другого выбрались кластера это естественно означает то что мы должны на аноде той которой мы сейчас находимся иметь все правила преобразования даже других виртуальных эти адресов других кластеров у себя локально а это значит что мы должны такие компоненты как и прокси да или там роутер любые штуки которые настраивают нам эти правила поставить на все ноды всех кластеров и настраивать все правила всех выбирая кластеров которые у нас объединены в единую сеть это уже сложнее плюс нужно настроить все это так что было не конфликтовала то есть все правила это мой пятый босс которые применяются они должны быть сразу же для всех кластеров это первая проблема на самом деле не такая большая как 2 вторая проблема это dns и на самом деле лучше на него в общем случае не завязываться почему потому что к сожалению мало кто до сих пор уважает отель да и кэширует предсказуемую то есть когда вы пускаете там любых там пользователь разработчиков кластер до который тепло и какой-то софт вы не можете гарантировать то что какой то из авто например не за кэширует на долгое время ip-адрес да там какой-нибудь если и джинкс riho прокси поставить с дефолтным и настройками твой но на долгое время за каширу этот айпишник он там не дай бог окажется айпишник am другого кластера и все о вас там весь трафик будет лица в тот другой кластер там долгое количество времени и это уже как бы не совсем получается балансировка то есть трафик прибивается в одну точку не очень вот поэтому мы это решение skip нули и продолжили сёрфить и дальше такое небольшое отступление в сторону того давайте вспомним как работает основной компонент кубер на тельство который называется контроллер менеджер да это один из таких основных компонентов control play на который поддерживает состояние нашего кластера в нужном виде да в том который мы применяем принимал применяем манифесты то есть когда мы например и плохим deployment и говорим что мы хотим этот дипломант 4 репликах контроллер менеджер видит это и поддерживает это состояние отправляя запрос и в камерной цепи то есть он берет и создаёт там про 4 пода вот тут есть еще до там прослойки виде реплика сайта но и все запустим да и просто нас есть deployment рождаются 4 пода далее если у нас есть еще сервис сущность и у этой сервис сущности у нас есть лейбл селектор который совпадает с этими кодами то кубер notice автоматически да с помощью контроллер менеджер создает нам сущность endpoint в которые есть перечисление всех айпи адресов которые попали под этот лейбл selector и к чему это все рассказываю на самом деле это вот то самое место которое по идее мы можем за патчи для как-то изменить логику работы чтобы вот в этой сущности in point на фиолетовый у нас появились эти адреса сразу же нескольких кластеров то есть это могут быть api адреса текущего кластера и api адреса например другого кого-то кластер а как это можно достичь такой самый straightforward наверно подход может быть когда мы контроллер менеджер сообщаем что давай ты теперь будешь смотреть не в один кубер насыпей а будешь смотреть сразу же несколько на например какой нибудь api сервер 1 open server 2 и соответственно когда у тебя будет настройка по сервис сущности кубер на тисовой что как на какие пи адреса нужно быть ты сразу же получишь and points 1point 2 соответственно из одного кластеры из другого и затем эти два and point of мир лишь в один что мы в итоге получим мы получим что у нас есть виртуальная сочный сервис который представляет из себя имя по сути нашего сервиса и далее механизм стандартный до полность стандартные преобразование этого виртуального адреса в реальные коды которые по нескольким кластером вот в этом плане здесь уже честный пункт это действительно будет нативное преобразование такое же как это делает кубер найти суда из коробки она будет таким же но есть такое можно сказать небольшое но которое на самом деле большая проблема он так из коробки естественно не умеет и для того чтобы поддержать из контроллер менеджера доступ сразу же в несколько uber на детей пиаф нужно его либо format либо написать свою имплементацию но это достаточно большой уже компонент в котором много логики и писать там свой контроллер менеджер это не тот путь который мы хотим выбрать вот поэтому это это первая проблема вторая проблема мы как бы как одна из фич хотели еще коннелли deployment и то есть какую-то возможность по весовой балансировки и в этом случае да так это все происходит на транспортном уровне сделать весовую балансировку затруднительно да то есть это опять-таки подчерк либо какими-то такими странными способами подмешивания mind поинтов нужных процентных соотношениях либо опять таки внесение своей логики в кипр оксида основные компоненты которые уже нужными вероятностями проставляли 5 bus правила которые делали над вот но уже такие вещи как когда нужно влезать в логику основную лайку работа куба и ну это не тот путь который мы также хотели выборе вот поэтому мы решили посмотреть на подход сервис мышь на самом деле мы его уже достаточно давно используем для таких задач как сбор tracing информации для роутинга в тестовых окружениях а там трафика и решили посмотреть можем ли мы решить те задачи которые сейчас перед нами стоят с помощью этого подхода вот давайте так бриф ли пройдемся на на всякий случай еще раз в чем заключается этот подход чем не нравится как бы определение когда мы говорим что сервис миша такой подход когда мы добавляем каждому сервису какой-то единый кусочек логике извне да и начинаем контролировать все сетевые взаимодействия между сервисами то есть это такое некоторые сеть которую мы получаем как бы интегрируя в каждый сервис свой кусочек логике причем одинаковый да и технически что мы получаем у нас есть сервис у нас есть какой то сайт корр контейнер прокси который принимает на себя весь трафик внешне то есть это запросы извне это запросы из-за сервиса они все теперь проходят не напрямую они проходят через этот прокси контейнер причем стандартно это реализуется с помощью t5 bus redirect провел либо тип рокси правил вот то есть это полностью прозрачна для сервиса он даже не знает то что рядом с ним кто-то стоит и слушает весь трафик который проходит к нему или из него и в итоге мы получаем такую ситуацию когда все сервисы перестают общаться друг с другом напрямую они теперь общаются через этот сайт корр прокси причем этот прокси он одинаковый то есть это один и тот же софт который мы добавили каждую ячейку в нашей системы каждому сервису вот зачем это все нужно да как это может нам помочь 1 как я уже сказал это добавление одинаковые логике большая проблема на самом деле внедрить какую-то вещь в гетерогенной системе полностью на все сервисы вот у нас ну не то чтобы зоопарк но у нас достаточно большое количество технологий на бэг-энде используется и написать библиотеки которые бы реализовывали до одинаковую функциональность поддерживали такой фичи берите по вот этой вот instrumentation до основной которые нужно по сети работы достаточно сложно то есть это нужно поддерживать эти библиотеки обычные языке есть такие которые достаточно быстро развиваются в компании они много где используются там инструменты более новые более готовы вот в случае с языками которые уже так ну не особо популярны в компании там библиотеки уже отстают и их нужно постоянно дорабатывать поддерживает чтобы они были в таком состоянии как и везде вот сервис меж подходом такой проблемы нет мы добавляем один и тот же кусок он идет снаружи нам не нужно делать какие-то библиотеки в к сервисам следующий момент по гарантии выполнения сетевых политик на самом деле вот библиотекам есть еще большая проблема вы можете например поставлять некоторые шаблоны да там разработчикам и они будут как бы их использовать всякие то политики которую ты love строите какой-то софт уже написанный он там будет исполняться но до тех пор пока например какую-то этом библиотеку разработчик не отключат до этом не перестанет использовать вот поэтому библиотеками никакой гарантии нет а с прокси и этими контейнером гарантии уже будет так как весь трафик вы гарантированно будете перенаправлять через этот прокси контейнер и еще из таких полезных особенностей вы можете на этом прокси контейнере полностью парсить все что у вас происходит на протоколе прикладного уровня и соответственно делать там любую логику которые вам нужно то есть полностью контролировать весь flow того как у вас-то проходит все запросы парси делать какие-то дополнительные действия дополнительную логику вот с помощью сервис миша если посмотреть на имплементации их вот особенно за последний год стало уже просто огромное количество и их количество постоянно растет все делают свои такие control plain и которые реализуют сервис наш подход вот мы даже написали свой в том числе да и используем его я уже сказал для сбора tracing информации мониторинга метр меж и есть и другие например из тела из тела достаточно уже давно существует а там больше двух или может быть даже три года и разрабатывается есть там linker де который когда-то раньше назывался кондуит да есть достаточно интересный проект консул connect вот я сейчас не буду вдаваться в подробности каждого из них то есть я посмотрю уже сейчас больше в глубь да как они вообще устроен и как они работают и какие есть особенности и проблемы вот мы особенно долго копали в из тела и использовали его пытали всего использовать для нашей системы вот и на самом деле когда мы получили вот эту вот новую проблему с несколькими кластером и мы естественно в первую очередь посмотрели на то какой дизайн представляет из теда и что мы можем использовать оттуда для решения этой проблемы и тут есть 2 основных решения первое это из тенге твой это решение когда у нас двух кластеров стоят специальный гид вей через которые можно попасть как бы любой из сервисов которые полагаются в этом кластере то есть когда вы хотите сходить там и сервиса сервис б у вас всегда есть другом кластеры gateway который знает где располагаются сервисы и вы через него проходите и получаете доступ к нужному вам сервису вот это принципе хороший подход да когда у вас есть какие-то абсолютно не связанные там облака особенно публичные да и вам нужно их каким-то образом связать но не делать из этого культ а общую такую прозрачную сеть вот то есть когда вы четко можете сказать что а сейчас мы идем в другой кластер и делаем это через gateway вот конечно это не очень удобно потому что вам нужно со стороны сервиса до source стороны указывать что мы сейчас идем через какое-то еще дополнительный там балансировщик вот поэтому есть другой подход он называется из теорий пьян кан activity который позволяет напрямую ходить из одного сервиса в другой как раз с помощью этого сервис меж подхода когда у нас в каждом сервисе есть сайт корр обычная цвет карта январь прокси который знает до информацию вообще полностью о всей системе и знает куда идти в нужный нам сервис то есть когда мы приходим на прокси с виртуальным адресам сервиса б узнает что этот под располагается там сейчас кластере 2 и может напрямую отправить туда запрос вот здесь естественно сразу же накладываются некоторые ограничения такие как любой под на из которого мы идем он должен уметь получать прямой доступ к любому другому поводу во всей системе то есть даже в разных выбирать из кластеров подойти они должны быть маршруте зиру и мы из любой точки в любую другую точку тогда этот подход работает вот из плюсов здесь естественно то что это полностью прозрачна для сервиса он не знает где располагается тот сервис который он идёт он просто туда приходит через этот сайт car pack кому-то подойти конкретном куда мы могли можем за маршрутизировать какие здесь есть плюсы и минусы первое это и стива поддерживает эти подходы из коробки вот мы на самом деле все эти вещи копали когда они еще все были в альфа режиме то есть они не были еще такие стабильными вот и тем не менее они работают то есть они логически реализуют те вещи которые заявлены документации здесь есть если так достаточно низкого приседает возможность соблюдения локальности то есть вы можете настроить таким образом чтобы ян го и изначально соблюдали локальности ходили на под и которые располагаются в кластере которым из которого вы сейчас идете то есть это это в принципе настраиваем есть гибкая настройка я это сейчас как бы подаю как может быть такой плюс на самом деле ну вот еще в предыдущих версиях вести а там даже там в 11 по-моему было были десятки этих кастомных ресурсов там больше 50 штук с помощью которых вы можете достаточно тонко настраивать январь прокси до который располагается с каждым сервисом и это как бы с одной стороны плюс другой стороны когда вы там не знаю первый месяц работаете с из тела это большая проблема потому что вам нужно изучить огромное количество этих разных манифестов понять что куда писать для того чтобы правильно настроить этот иного и прокси вот и самом деле это достаточно большая проблема учитывая что документация не всегда там самое лучшее да это нужно потратить большое количество времени инвестировать что мы настроить инвайт так как вам нужно вот и на самом деле такая последняя проблем с которой мы столкнулись это возможность масштабирования este она действительно большие системы где у нас большое количество инстансов сервисов здесь мы получили в проблему и тут я бы хотел сдать в аудиторию два вопроса первый вопрос от поднимите руки кто уже использует сервис наш подход в продакшене вот уже прям постоянно на постоянной основе окей тогда еще один вопрос да можно просто с места выкрикнуть я повторю вот вы наверняка мониторить и да сколько потребляет с каждый сайт корр который injection к сервису оперативной памяти вот сколько в среднем это занимает у каждого сервиса очень мал при при а у вас к прокси вот отлично вот с из тела все дела обстоят иначе самом деле когда мы за inject или ну вообще начали использоваться систему нас с системой там в 6000 кодов да сейчас их там еще больше у нас ян го и начал употреблять там больше гигабайта оперативной памяти но это вот для сравнения да сколько потребляет январь когда он просто стартанул без какой-либо настройки это там что порядка десяти мегабайтов резидентной памяти и это совсем маленькое количество да то есть когда мы диплом уже в большую систему это получается огромное overhead и на самом деле если так умножить и посчитать полную стоимость сколько это все будет стоить это 6 терабайт оперативной памяти на то чтобы за инжектить этот ян го и везде на систему из там 6000 кодов вот который принципе это ну на самом деле не так много то есть это не какой-то супер гигантский проект это на ст-1 кластер такой вот дорого поэтому мы думали что можно с этим сделать как можно и тасс оптимизировать при том что по логике работы да и по тому что решает тесте у нас в принципе все устраивало то есть мы настроили его таким образом чтобы он работал как надо и в итоге мы посмотрели вообще на все решения сервис меж которые сейчас существуют и пришли к такому понимание что большинство этих сервисов наш решений используют сейчас январь прокси да как такой сайт корр вот и просто его настраивают по-разному и решили поэкспериментировать что если мы сами возьмем мы начнем его настраивать нужным нам образом чтобы он потреблял да и и принимал в себя только ту информацию которую нужно нам системе в итоге нам получил у нас получилось и тасс оптимизировать сейчас вот он потребляет в среднем до 30 мегабайт оперативной памяти на каждый instance этого января дал здесь это пример сервиса который в 3 репликах каждый из реплик этот 30 метров при том что связей от каждой из этих сервисов там порядка где-то 10-15 и это достаточно такой жирный сервис который много куда ходит вовне вот если посмотреть уже в таком виде сколько это все в итоге будет потреблять памяти это 180 гигабайтов оперативной памяти на всю систему и это в принципе уже достаточно нормальный цифры потому что это там меньше наши одной физической ноды и если посмотреть что это все распределяется сразу же там по всей системе то это получается совсем такие копейки маленькие капельки которые находятся на каждый из worker not небольшие вот как мы это все делали как мы получили такой результат мы на самом деле пошли тем же путем что и пошел из тела за одним небольшим исключением мы написали свой маленький control plain да это приложение на гул инге которая подключается к абернати себя и и слушает полностью да все что у нас есть кластеров причем слушает сразу же с нескольких губерн одессы это iv мы тепло и абсолютно также каждому сервису сайт корр контейнер январь который по сути весь трафик через себя пропускает ровно так же как и вы стены и далее вот здесь есть одно отличие мы вместо того чтобы всем in воем сообщать сразу же всю информацию о том что есть системе мы получаем ее всю в навигатор то есть навигатор да этот контру playing называется он хранит в себе весь state и также еще и специальных кастомных ресурсов губер на тесс впитывает информацию про канарейки дата как поливать трафиком процентном соотношении и связи в эти вот связи как раз определяют то какой именно discovery нужно раздать конвоем то есть мы каждому in вою раздаём только нужны на адреса нужную информацию которая ему необходима для общения с другими сервисами вот в итоге по механике работы это все выглядит также как и вот системе ping an activity то есть мы идем из сервиса там of service б напрямую с помощью подойти вот и здесь естественно получаем те же ограничения что и выстирать ping an activity как это все работает по сути вообще любой control plain до который у нас есть у сервис миша он такой выполняет роль двустороннего взаимодействия с одной стороны он подпитывается информацией из губер нависает f то есть он слушает различные ресурсы он слушает ресурсы стандартные кубер на тисовые и слушай какие-то кастомные ресурсы с помощью кубер найти стан клиента под гул н это достаточно просто реализуется просто делаем несколько информеров каждый из которых слушает нужные нам ресурсы вот с другой стороны навигатор дает control plain выступает в роли менеджмент сервера для январе январь поддерживает специально там свой и пей протокол который работает на jar писи для того чтобы динамически настраивается то есть он прямо в ран тайме получает нужные нужную информацию для проектирования а для взаимодействия между сервисами вот позже рпц и соответственно здесь сразу открываются возможности для пуша каких-то изменений то есть к нам и нго и подключаются и мы если вдруг что-то изменилось им пропушим сами да не ждем пока он придет там очередной раз за какими-то изменениями вот по имплементации это также достаточно просто делается есть вин в proxy go control plain который содержит все необходимые сущности уже весь ее пей для работы с н воин с полностью инкапсулирует работу с ним представляет такой высокоуровневой api по вообще этому и пиарю что есть можно сказать здесь есть несколько discovery сервисов да мы используем основные вот эти четыре рестлеры кластер и кластер лода сайты road и которые по сути организуют основную основной pipeline работаем внутри то есть когда мы хотим преобразовать вот этот виртуальный ip-адрес в реальной вы двое до в его терминах это выглядит следующим образом у нас начало есть ли сонет рестлер это по сути тот виртуальные печник спортом далее включаются в работу фильтры эти фильтры могут быть абсолютно разные даже к стану написанную до плагинами конвою мы например используем each тебе connection manager это фильтр который парсит протоколы и степи заглядывать туда внутрь и вот это вот как раз место где мы еще подкладываем специальную сущность road которая позволяет нам делать различные еще механику для работы с ее степи уже протоколу вот далее это все прилетает в кластер кластер это по сути просто название сервиса то есть например payments в терминах там джинсы просто up stream и уже этап стрим он балансирует по айпи адресом это уже конкретные подойти которые лежат в кластер ladies and конкретные уже маршруте зиру и мы и падает и куда мы идем если посмотреть на ток это работы в кубер найтись и и сравнить с тем как это работает манго и выглядит это следующим образом в кубер нить у нас есть кластер ай пи до который у нас выдается динамически каждому сервису и есть подойти по сути который в in point их написаны куда мы делаем над преобразование в случае с январем это такое же до подобное преобразование который идет из бисера в кластер лода silent вот здесь то же самое берем виртуальный адрес его на тем уже в настоящий адрес если мы посмотрим на манифесты в манифестах куба у нас до всегда есть этот раз виртуальная печник и в интентах есть уже реальные пи адреса куда идет преобразование случае с январем это подобные вещи то есть у нас это такое приведён очень упрощенный вариант конфигурации января он динамически получает весы нир и в которых указано те же самые там значения это виртуальный ip и порт и в кластерах уже указаны конкретные api адреса куда мы будем перенаправлять из этого леса ниро вот здесь приведена такая упрощенная конфигурация то есть в реальной динамической конфигурации здесь у кластеров указывается что нужно получать discovery через специальный и ds протокол который динамически получится из менеджмент сервера да и мы получим эти кластер логоса элементы сами api адреса ok давайте посмотрим внутрь как вообще он в итоге архитектурно работает как он устроен на самом верхнем уровне у нас идут информеры то есть это кубер найти с информера которые потребляют различные ресурсы это ресурсы стандартные кубер notice a service in point да и то по сути все что нам нужно для того чтобы организовать такую систему и второе это can you realize nexus это уже к наши кастомные ресурсы которые делают это вот механику по отрезанию ненужных discovery сервисов и там наливании трафика в процентном соотношении после этого мы все складываем прямо в оперативную память навигатора специальные каши то есть нас есть каши кубер не tissot есть каши соответствующих сущностей там коннери релизов если сейчас прямо в данный момент мы должны лить трафик процентном соотношении и nexus cachito связи это связи между сервисами далее здесь идет слой x диск сша это по сути уже кэш полностью готовы к тому чтобы отдавать данные двоем то есть это уже такой подготовленный специальный кэш для каждого из нвф которой у нас есть системе при чем здесь если посмотреть на схему стрелочки идут вверх на вся эта система на полностью бо синхронно работает эвент и прилетают из любой части системы и в момент когда идет изменения какого-то из ушей до которого синим цветом выделена там кого семье сканере на xus то прилетает ягодицу специально на тихой о том что что то изменилось он идет в эти каши конструирует полностью тот стоит который у нас новый делает div с предыдущим и затем отправляет информацию об изменении только тем и двоем у которых что-то поменялось да например и заниматься какой-то пи адрес да какое то что что-то поменялось в общем мы не пропущу его им всем каждый раз изменения все вот и затем уже самый такой низкий уровень даст другой стороны эта работа с ян го им эта работа поджарь писи протоколу который реализует как раз его control plain то есть мы просто уже скармливаем те подготовленные сущности в из каши каждому и сын воев окей какие есть ограничения то что я уже сказал это разделение по разным по сетям по коды кластер айпи на самом деле вот эти вот виртуальный класс терапии не обязательно 9 по разным по сетям в разных кластеров потому что ну это виртуальная сущности мы по идее можем поддерживать ну и и преобразование в любом и двое да как бы однозначно то есть мы знаем полностью кий-в везде есть класс терапии они не прибиты какой-то конкретной сущности в нашей системе вот а спадает и они естественно должны быть все уникальны и потому что если мы идем на какой-то это дресс-кода то естественно мы должны претит в нужную точку в нужный сервис то они в какой-то другой сервис который у нас есть там другом кластере вот поэтому они должны быть в разных подсетях следующий момент это масштабируемость да каждый подойти и должен быть муж мотивируем из любой точки и два важных момента сервис сущности должны быть реплицировали между кастерами зачем это нужно на самом деле единственная как бы правило по которому мы можем понять что сервис payments до в в одном кластере это вот тот же сервис пойман с другом кластере это по имени сервис сущности то есть мы смотрим что кубер найти свой сервис сущность имеет одинаковые там имя и namespace и по уже по этим данным матчем и мер джим все intent и все эти адреса по разным кластером какие есть моменты по отказоустойчивости мы тепло им естественно навигатор сразу же в нескольких экземплярах делаем это на мастерноды просто потому что мастерноды кубер найти со обычно такие самые стабильные о них не приезжают какие-то пользовательские под и да и не affected и к своей нагрузкой также мы для походы и s'en va и в этот навигатор делаем балансировку по ним то есть мы ставим специальный ростовой балансер который балансирует уже по разным версиям по разным инстанциям навигатор который располагается на мастерах и уже сам диск балансер просто находим через downward и петьку берна this опрокидываем айпишник hasta текущего где у нас раздуплился под в итоге это выглядит все вот так то есть у нас есть какой-нибудь worker надо на ней стоит сервис сын воем ян го идет через down варды и пейна кастовую worker ноду попадает на х прокси да мы используем для этого х прокси и затем через х прокси балансируется по уже навигатором по мастернодам какой есть еще момент на самом деле это уже такой момент диму наступили на грабли что и важно делать важно делать еще специальный хэштег потому как вообще эта вся система работает потому что есть одна проблема когда мы идем с января навигатор у нас есть достаточно еще большой слой инфраструктура которая находится между ними первое это сесть до непосредственно сетевая связанность второе это вот как минимум тот еще балансер на первых a proxy с ним может что-то случиться на какой-то is not он может например упасть и мы и сын воине получим discovery а значит что наш сервис когда поднимется он не сможет ходить в кит и другие сервисы скоты с которыми он связан и эта проблема поэтому что мы делаем для того чтобы убедиться что эта вся схема работает мы до поднимаем обычный двое он идет в навигатор за конфигурации да прямо на стартапе то есть вначале только он поднялся далее мы параллельно запускаем кубер notice пробу которая спрашивает у января прямо идет в-ingo и говорит ответить мне на специальных all set point готов ли ты сейчас уже работать до принимать нагрузку естественно пока он только запустился у него нет этого discovery он не получил этот intent и он отвечает что нет еще не готов после того как он сходил успешного навигатор он получает обратно этот hold it in point и уже этот успех начинает проходить вот причем делаем мы это что важна только на моменте поднятия этого январь прокси потому что если такое сделать например всегда периодически проверять навигатор то тут естественно можно уступить такие грабли как полный отказ всей системы потому что в ситуации например что например вы там неудачном навели control plain до его завалили у вас все ян го и пошли проверять могут ли они сходить в этот навигатор не могут окей значит снимаем с себя нагрузку и в итоге сразу же со всей системы снимется вся нагрузка и все коды выйдут из балансировки мы получим полную деградацию отказ всей системы вот поэтому такая вещь проверяется только на момент поднятия сервиса и она по сути проверяет просто изначально возможность сходить навигатор то есть то что у нас все узлы посередине работают какие есть возможности по балансировке естественно мы принимали во внимание то что нам нужно уметь балансировать соблюдением локальности поэтому такая возможность есть сейчас я посмотрим подробнее мы умеем да сын в эта комната поддерживает балансировать нагрузку сразу же разными способами это не только round robin иран дом на самом деле любые в том числе весовые балансировки есть возможность сразу же чекать со стороны и двое am активно или пассивно те сервисы в которые мы идем и он так я уже говорил поддерживает парсинг олсен протокола то есть на новый на этом уровне тоже можно делать хорошие вещи которые мы сейчас еще посмотрим чем то нужно первое это поддержка локальности в-ingo есть много различных решений до 3 на самом деле для того чтобы соблюдать локальность обращений мы используем подход проиграть или в лс что это за подход на самом деле этот подход это по сути обработка отказов такой failover механизм который нам позволяет сделать что он позволяет нам поделить нашу всю систему на несколько зон в которых сказать что у нас у каждой из зон есть свои приоритеты причем эти приоритеты ставятся со стороны как бы клиента того откуда мы идем то есть мы сейчас например in вайда я январь еду в какой-то другой сервис у этого сервиса есть endpoint и в случае если все эти in point и хелси да то есть иного их прочекал и сказал что они все здоровы и то абсолютно весь трафик направляется в группу in point of который находится с приоритетом самым высоким это вот п 0 до то есть весь трафик уходит 100 процентов по 0 далее есть специальный параметр который стандартно зашит в-ingo и который называется а верка мид специальным коэффициентом который говорит о том что он по дефолту район 14 который говорит то что вот даже если 72 процента and point of только живы там и все равно 100 процентов трафика даем на зону с приоритетом 0 и только вот случай когда уже только 71 процент in point of останется здоровыми у какого-то сервиса только в этом случае мы начнем часть процент трафика один процент давать на зону с приоритетом в единицу ну и так далее да если у нас будут приоритеты там два три четыре что не будут так вот перетекать постепенно вот случай если там например 50 процентов отказала то уже будем 70 30 процентов проектировать вот такой способ он сочетает себе как failover да то есть это обработки хто отказов так и в том числе позволяет не просто там переключиться на какую-то другую систему случае деградации текущей он позволяет сделать как бы плавно перетекая по процентам вот в итоге мы получаем такую достаточно гибкую систему вот есть другие подходы такие как зоны в роутер и специальную весовая балансировка с учетом локальности вот весовая балансировка с учетом локальности к сожалению нормально не работает в январе то есть мы не настроили там есть некоторые проблемы данные имплементации января вот зоны в роутинг это немножко другой подход когда мы делим наш пирожок как бы всю систему на специальные еще такие зоны регионы до этого терминах которым все привыкли кто использует публичные облака там можно оперировать вот этими зонами но там нет вот такую гибкой настройки с процентами в процентной балансировкой в случае отказа до какой-то части системы все на более такая straightforward реализация окей что какое еще момента в случае с балансировкой на транспортном уровне на это стандартная проблема когда вы балансируете например по кому сервису биллинга на транспортном уровне у вас балансируется простоте цепи connect и если вы используете протокол прикладного уровня которой например там использует queen keep alive вычитываешь степи или это tanger писи протокол то у вас велика вероятность что ваш сервис down прибьется к одному из инстансов и будет его мучить пока тот не задохнется и либо не умрет от того что он принимает нам всю нагрузку вот для того чтобы решить эту проблему просто парсим и чтить и протокол на уровне января ян го и разбирает он смотрит что сейчас у нас в тисе пи протоколе внутри летит 1 теперь запрос 2 3 раскидывает их честно по той стратегии балансировки которая нам нужна итоге эта проблема решается окей что еще канареечное deployment и это такая уже бонус тема да то есть мы ее реализовали уже следующей итерации да когда поняли что всей этой системе можно добавить такую возможность как она работает первое что мы до такое отступление что мы хотели до получить мы хотели поддержку мульти кластер а то есть мы хотели чтобы если мы примем применяем какое-то процентную балансировку то она должна работать сразу по всей системе они просто в каком-то одном кусочке да как это вот уже умеет имплементировать различные операторы вот конкретные до решение под как она реечные дипломаты хотели использовать тот же инвойс сайт кардане добавлять какие-то еще решения например на х прокси есть достаточно в принципе хорошее решение для канареечный дипломантов вот но хотелось использовать уже тот сектор который нас есть и естественно единый control plain через который можно настраивать все в том числе и весовую балансировку то есть не делать еще какое-то еще решение не носить систему который бы настраивалось все канарейки и дипломаты в итоге у нас получился вот такое описание это коннелли рис до который говорит что на сервис пойман мы должны давать трафик не стопроцентно на весь этот payments а только 70 процентов до на тот же самый пойман namespace payments а 30 процентов дать на новую версию пойман 22 вот это вот сервис сущности кубер найти создан который мы теперь просто у льем трафик в нужном процентном соотношении вот причем это необязательно процента это на самом деле просто веса но они не обязательно должны давать сумме с а здесь есть такой очень важный момент как это все деплоить если это сделать неправильно то у вас будут такие моменты когда у вас будет трафик скакать из стороны в сторону поэтому здесь как надо делать это хорошо у нас есть клиент который ходит в поймать в один он сейчас настроен на сервис сущностью на endpoint и сервиса пмс в один мы диплом рядом новую версию payments v2 затем применяем конри релиз на и вот в этот момент когда у нас применён к на релиз это уже тот момент когда все правила которые действовали стандартные кубер на тисовые они перестают действовать у нас уже применен в сканере релиз далее в этот момент очень важно вот именно когда у нас применен канарис именно изменить лейбла до поставить чтобы сервис сущность указывало на новую версию в2 и только потом удалить канарис иначе у нас будет такая ситуация когда у нас пойдет трафик сначала на новую версию в два тридцать процентов затем вернется полностью на v1 а потом обратно на v2 вот чтобы этого избежать мы должны еще в момент действия к на ривере за обновить лейблы и затем уже обновить в один достаточно простой момент но о нем нужно помнить следующее это связи до связи выглядит следующим образом этот кастомный ресурс которым мы описываем что например сервис юзер в namespace мы можем ходить любые до сервис сущности которые есть на и спейси юзер овна и спейси биллинг мы можем ходить только в сервис у которого или просто sing да и соответственно этот payments получит уже информацию именно по вот этим сервисом и ни по каким другим то есть он не будет знать и не будет иметь возможности хоть какие-то другие сервисы какой есть важный момент а связь здесь на самом деле тоже такой небольшой горький опыт да как мы тепло или вместе с этими связями сервисы как это делать правильно чтобы не было проблем мы держим сразу же связи предыдущего релиза и нового сейчас я проиллюстрирую почему вот делаем и таким образом когда у нас в navi space и плавится этих nexus сущности навигатор просто смотрит по об найму да и видит то что для такого сервиса есть такой-то nexus и такой-то еще один nexus имеет все сервисы которые есть прям нескольких вот этих вот nexus сущностях в итоге здесь в чем может быть проблема зачем мы это делаем дело в том что система она распределена да естественно на консистентной становится только в конце концов довершили и может быть такая ситуация когда у нас сервис ходят какие-то два другие сервисы например там зеленый там розовый а в новой версии в 2 разработчик взял и например что тасс оптимизировал перестал ходить в розовый сервис и теперь ходит только в зеленый и что происходит мы плавим nexus релиз прямо напрямую да например заменяя что теперь у нас розовый сервис не должно быть доступа в этот момент еще завершается сервис фоне сервис и он не может сходить в этот сервис да там вот розовый сервис потому что его больше нет его больше нет связях вот эта проблема поэтому мы сразу же держим предыдущий и текущий релиз дав связи которые являются вот в итоге с помощью вот этих вот связи получаем красот эту картину с маленьким потребление оперативной памяти in воем потому что он знает только нужную информацию вот что еще получаю на самом деле так мы используем его и мы получаем все его там фич ipad рейсингу роутинга там мониторингу и так далее вот но важный момент который мы еще также получили с таким подходом это возможность обновления кубер notice не inplace то есть мы на самом деле давно уже не обновляем коберна this на горячую потому что в версии 15 на 16 мы каждого очень сильно так ошпарились когда получили большой downtime системы то только там были несовместимы изменений на стороне базы данных ведь и сиди и теперь мы обновляем их следующим образом мы ставим рядом в кластер новый кубер найти сада перетаскиваем постепенно физический но ты снова кластер в другой объединяем их в один контур с помощью навигатора то есть они начинают видеть себя полностью прозрачна все сервисы затем как бы рипли не реплицируется просто переносим все сущности из одного кластер в другой который уже на новой версии кубер nights а гасим старый кластер все когда по уже полностью перенесена и после этого уже у нас новый кластер с новой версии каберне tissot без каких-либо непредсказуемых отказов при чем здесь можно обновлять очень гладко и плавно то есть там по каким-то небольшим кусочком да по сервисам сделать сразу же большого in place обновления который может принести проблемы но я обычно приносят большой системе и важный еще один момент по поводу навигатор и вообще всех написания control play но в подобного рода мы используем такую систему как к ент для тестирования этого всего канта так убираете сам докер это достаточно уже популярный продукт для того чтобы поднимать губер найти с ноды в докере с помощью коянды мы поднимаем сразу же да там буквально там 1 команды несколько кубер на диск кластеров настраиваем между ними маршрутизацию и далее проводим тесты всей этой системы поста в нашем pipeline да там коней релизы проверяем что и связи все вся доступность и есть из одного сервиса в другой то есть все эти вещи которые делает навигатор обязательно тестируем потому что на самом деле если посмотреть на эту систему the navigator это по сути штука которая отвечает за все взаимодействия в кластере если вдруг там есть какой-то баг какая-то проблема то это деградация сразу же всей системы ну и это вещь которую нужно очень качество тестировать то есть вот таким подходом по сути intent с там с помощью каинды и давайте подведем итоги и у нас выводы первое это вообще сам сервер смеешь подход он достаточно гибкий да он возможно достаточно сложен дата первого такого входа в него но он позволяет управлять действительно гибко любым трафиком извне и приложение то есть вы добавляете кусочек логики к сервису и дальше можете делать все что угодно с этими взаимодействиями то есть это все прямо из коробки сразу же у вас работает сразу же видите все что происходит по сети и можете носить любую логику мы решили действительно с помощью такого подхода наши проблемы до которые возникли с несколькими мастерами то есть мы безболезненно используемых несколько в одном окружении прямо в породе у нас несколько строф разных версий да мы их обновляем мы там постоянно их там перемещаем они в разных dc это все работает и в общем да это это это решает эту проблему мы получаем возможность внедрения этого все в гетерогенной среде да потому что если мы это делали на библиотеку каких-то таких еще instrumentation сервисов то скорее всего это бы не взлетела и либо взлетал очень долго потому что нужно каждый сервис про инструмен тировать это сложно вот к сожалению популярные инструменты еще они позволяют за как бы с легкостью внедрить вот но я бы сейчас прямо рекомендовал посмотреть еще на проект консулу connect да он достаточно неплохо развивается и по дизайну да он достаточно хорош он также перешёл в последних версиях на январь прокси надо посмотреть как он решает эту проблему до которые есть в из тела но в целом выглядит сейчас очень перспективно вот и на самом деле так если заключительно вообще подвести итог ко всему тому что я сказал вот сейчас в 2019 году в принципе большинство вообще логике который нужно вот сервис миша на самом деле экспериментировала но уже в январе и когда вам нужно построить какое-то подобное взаимодействие подобную систему в принципе вы можете взять и двое и написать достаточно маленькое количество исходного кода для того чтобы настроить их таким образом которые вам нужны вот мы это сделали с навигатором он есть у нас на гитхабе авито тех репозитории можно посмотреть его вот и там попробовать либо взять оттуда уже имплементации потому что там уже пройдено много кораблей исправлено много всяких косяков и она у нас полностью работает в праге вот на этом все спасибо и давайте переходить всех с вопрос спасибо александр и есть вопрос который задают в разных формах это как долго вы писали навигатор до на самом деле вот первая mvp версия до которую мы за тепло или уже в продакшен со стандартной функциональностью этого объединения нескольких кластеров да это был месяц то есть это месяц в котором мы писали 22 разработчика это было не там типа full-time разработки это просто ну как часть задачи которые мы делали по инфраструктуре это сначала написание до его выкладки в продакшен вот то есть там на самом деле если посмотреть на его объем это там буквально чуть больше там полутора тысяч строк на коленки не такая большая системы и я правильно услышал что на гитхабе лежит тот самый навигатор который вы используете у себя да да да здорово здорово это вот как раз 2 2 под вопрос и ещё интересуется про in vain вы их что-нибудь у нелли специально в нем или нет в инвалида есть несколько таких стандартных тюнинга в принципе это можно прочитать в рекомендациях то есть например там стандартные вещи вида уменьшения там количество потоков которые он использует для работы до обычно сервису нужно ян го и не нужно обрабатывать огромное количество соединений так он расположен рядом с каждым сервисом поэтому хватает одного потока исполнении это сразу же драматически уменьшает количество потребляемых им ресурсов вот плюс поотрубали еще различные in point и для отправки большого количества метрик да это тоже позволило достаточно сильно сократить его используем ресурсы а так в целом все остальные настройки более-менее стандартно их можно посмотреть репозитория но все лежат вот каких таких больше вещей с ума нет"
}