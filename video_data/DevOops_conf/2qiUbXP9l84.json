{
  "video_id": "2qiUbXP9l84",
  "channel": "DevOops_conf",
  "title": "Григорий Кошелев — В чём (ещё) польза распределённых трассировок?",
  "views": 315,
  "duration": 2791,
  "published": "2023-06-30T00:34:42-07:00",
  "text": "Здравствуйте меня зовут Сергей Сегодня я буду помогать григорию с его докладом еще раз напомню всем что вы можете задавать вопросы в чат и наверное только так а я их буду озвучивать и я думаю в конце у нас будет время и на самом деле Александр Григорий а приготовил отличный подарок для тех кто тогда самый интересный вопрос да еще раз Всем привет за интересный вопрос будет такая отличная книжечка с кабанчиком классическая книга Да ну давай начнем И мне кажется у тебя слишком много слайдов Да чтобы тебя отвлекать действительно можно начать Итак еще раз Всем спасибо что пришли и тоже хотите послушать про распределенные трассировки про пользу и вот тут мне еще есть еще какую-то пользу которую могут дать от трассировки Я хотел бы такой небольшой дисклеймер сделать идея этого доклада Она появилась в неровном месте 11 августа в чатике девупса может быть даже кто-то здесь присутствующих голосовал вот конь голосовал кстати в этом вопросе О отлично есть такие люди вот идея какая то что в докладе Я как раз хотел рассказать о том какие вещи можно делать при помощи распределенных трассировки и по сути не придумывать там из воздуха да такие вещи а все-таки посмотреть на опыт там людей которые очень много лет занимаются вот этими вещами и соответственно вот эти две главные книги трассировкам Ну и привести некоторые свой личный опыт построения вот этой инфраструктуры для телеметрии и для распределённых трассировка в частности личный опыт в целом наверное Ну не ограничивается но наверное основные вещи которые можно посмотреть это вот мы два выступления на jpoint которые были вот этой этим весной летом и там три года назад на дампе вот я рассказывал про систему телеметрии потом зачем мы делали мы делали вот самый последний доклад это больше такой ориентирован на создание ивент driven System про сложности про Какие задачи это все решает если говорить про две главные книги то это именно они соответственно первая из них это мастинг дистрибьютор tracing автор Юрий Шкуро и вторая это дистрибьютор tracing in precties причем обратить внимание книжки как бы 19-20 года и даже по меркам эти индустрии это в целом довольно свежая литература То есть это последние такие результаты которые есть на данный момент в этом направлении вот очевидно вся эта история не ограничивается этим из очень много компаний очень много инструментов которые там созданы и там стали часть опенсорса из Китая закрытые решения вот в частности приведу пример с егерем зипкиным о популярном инструментами для трассировок в Гугле в амазоне свои решения есть компании которые специализируются на апмх то есть на тузах который называется Application performs Мониторинг это вот степень релик вот мы вообще в целом эта штука так или иначе потихонечку стандартизируется и вот когда появился там Open tracing через некоторое время Вот он переродился в Open телеметрии об этом тоже мы сегодня немножко с вами поговорим но первый вопрос Вечер все устали Давайте немножко разомнемся небольшой зарядку проголосуем Вот вы уже применяете трассировки кто уже в своих проектах применяет Ага Типа так мало мало вас Здорово Ладно Хорошо теперь А давайте посмотрим на 7 вопросов которые будут непосредственно касаться моего доклада и помогут вам понять типа А нужны вообще вот распределенные трассировки если вы еще не используете или нет Вот давайте первый вопрос У вас есть биллинг инфраструктуры в компании То есть вы уже берите инфраструктуру Ага Окей давайте дальше у вас есть Slow там может быть Это там в одном проекте Может быть там в целом по компании и вот инструменты для автоматизации расчета вот этого есть такие люди не очень много а вот вы тестируете на продакшене Кто тестирует на продакшене лес Рокси с трассировками с плёными это может оказаться вполне такой нормальный план то есть не то что Казалось бы О Боже он тестирует на продакшене а нет так можно довольно безопасно это делать Кто применяет в своей работе Кел с engineering круто респект во всех ваших веб-сервисах единообразное покрытие htp метриками у кого это Ага вот тоже не очень много нормально идем вы автоматически управляете своими репликами на основе метрик здоровье Ну например там и сервис Discovery выпиливаете метрики если она как-то шалит вот такой есть ага Здорово Так и наконец вы так анализируете свою архитектуру высокого уровня то есть какие у вас сервисы как они взаимодействуют сколько их как они распределены Кто такую штуку делает Отлично вот эти все вопросы Мы постараемся понять как распрянуть трассировки могут сделать вашу жизнь проще если вы хотите что-то из этого делать основной тезис который пройдет Сквозь все мое выступление о том что с распределенными трассировками вот эти задачи Вот эти 7 пунктов их можно сделать проще то есть благодаря тому что у вас есть определенные трассировки завести вот те вещи окажется значительно проще чем если ту там инструментацию эти подходы делать с нуля но как известно У всего есть нюанс и про эти нюансы тоже стоит поговорить и начать это желательно самом начале вот прямо сейчас Первое Это история про сэмплирование о том что все наверняка знают что трассировки это дорого это очень много данных это правда и в этом смысле есть три варианта Первый Тогда вырабатываете весь поток спанов большой трафик и варианты 2 когда вы сэмплируете То есть вы не все трассировки собираете а только часть из них и там два подхода типа либо Head Base когда вы в момент когда приходит первый запрос сервис подбрасывает какую-то монетку из какой-то вероятностью вы там либо трассируете этот запросы либо не трассируете и наконец Tail Base Когда вы уже когда завершилась трассировка в конце как говорите а вот надо бы ее протрсировать и тогда сохраняете информацию они либо соответственно нет для большинства задач которые я буду сегодня рассказывать они хорошо работают на всем потоке спанов Когда вы обрабатываете всю статистику и допустим для контура для нашей компании где очень много продуктов большая распределенная микросервисная архитектура Вот таких спанов порядка двух с половиной 3 миллионов в секунду То есть это очень много действительно данных вот и это требует большую затратную инфраструктуру под это вот это существенный минус который нужно понимать если Мы вот идем по такому пути вот но как мы выяснится Профит он может оказаться все-таки значительно и даже для таких затрат второй момент связанный с инструментацией о том как это делать Вот когда у вас очень много кода и пойти в каждый сервис что-то делать возможно вам не захочется и вы там например захотите использовать подход с таким Black Box когда приложение ничего про трассировки не знают это все снаружи как это делается понятно там альтернативный вариант Когда вы всю инструментацию делаете в своем коде полностью контролируете и там имеете полный доступ к тому что и как должно работать вот и наконец третье это вот Агент бэст когда у вас код Про это ничего не знает но там тайма Специальный агент он модифицирует исполнение код и тоже аргументируется В итоге и тут важный момент что вот мы используем опять же инструментацию в коде Почему Потому что Даже несмотря на то что у вас там может быть сервис mesh и нормально работать вот эта инструментация с трассировками не будет потому что вам нужно копировать заголовки специально http заголовки при http взаимодействии вот из запроса который к Вам пришел и вот по всей дочерние которые подойдут дальше для этого все-таки нужна инструментация именно в коде вот такие ограничения у нас есть и Давайте подумаем вообще зачем нужны трассировки вот по моему как раз в одной из книг в первой книге Мастер дистрибьютон трейсинг Я нашел как раз стату из твиттера по-моему Она очень хорошо описывает для чего это делать Вот я просто немножко времени чтобы прочитали и согласились Да с тем что написано то есть когда у вас был Монолит все было хорошо и расследовали всякие разные инциденты быстрый Понятно когда переселена микросервис каждый такой инцидент это похоже на расследование убийства это действительно так и мне кажется это самое лучшее Объяснение для чего нужны трассировки Вот но наверное это вас не устроит поэтому Давайте поговорим о том какие все-таки задачи можно решать с помощью распиленных трассировок классический выделяется 5 задач Вот мы сейчас сперва смотрим первые четыре То есть это про мониторинг распределенных транзакций про оптимизацию производительности То есть как правило там истории пролетансе поиск причин ошибок деградации в системе Ну и также Вот анализ зависимости сервисов как правило такие вещи они решают использование визуализации то есть инструменты для визуального анализа вот здесь показан интерфейс зипкина некоторые там дерево трассировки в целом если посмотреть какие-то другие инструменты они выглядят очень похожи Вот например вот это наша собственные решения которые мы используем у себя в компании наш внутренний продукт Исходный код его тем не менее Вот если упростить все вот эти вот истории с визуализацией там украшательствами и прочее все сводится к тому что у вас есть некоторое дерево трассировки то есть там есть сервис а это Запрос который в него пришел он порождает запрос сервис B C и там C соответственно него еще два дочерних запроса Да и я и как вообще с визуализации такое можно работать Но самое первое это когда у вас допустим какая-то какая-то статистировок закончилась плохо например там ошибка и вы можете сразу в этом дереве увидеть ошибку и понятно отреагировать что надо искать вот конкретно проблема вот в этом сервисе и с ней разбираться это понятная история понятный маркер Вот еще один такой Когда у вас просто часть вашей трассировки она никак не отслеживается например потому что где-то там дальше было запрос базе данных он не попал в трассировку очевидно Не инструментируете вот эту часть не только http взаимодействие можете инструментировать трассировками например запросы к базе данных и например вас отсутствует вы увидите вот такие дыры инструментации и может соответственно их починить Иногда вы можете видеть вот такие вот штуки Когда у вас в запросах идут последовательно то есть не параллельно а прям закончился один начался следующий закончился начался следующий Вот такая вот своего рода лесенка и не всегда но можно посмотреть и попытаться понять А можно ли не пропоследок выполнять запросы а параллельно например оптимизировать таким образом и таким образом вся эта страховка становится меньше соответственно ваш сервис начинает работать быстрее и Только благодаря тому что вы увидели на этом такой визуализации можно такой оптимизацию применить вот на самом деле все не ограничивается Можно например увидеть такую ситуацию когда внезапно подозрительным образом несколько испанов которые дочерних Да они все завершаются в одно время почему это может быть подозрительно Ну например это может быть Лог контент который вызван транзакции в базе это может быть тайм-ауты которые вас срабатывают и например отменяют какие-нибудь таски то есть срабатывает ситуация такая штука может соответственно это повод посмотреть и разобраться как эту штуку можно починить вот в целом когда мы говорим про оптимизацию можно посмотреть да и пойти и оптимизировать вот там А запрос он какой-то слишком длинная прям пойти сразу туда но есть такой подход называется Critical PES или критический путь это пришло термин пришел из теории управления проектами если здесь среди вас есть менеджеры То могли Наверняка про это слышать вот суть его в том что выделяете некоторый путь который как раз подсвечивает вам Какие компоненты этого пути ответственность за его длину то есть грубо говоря Если вы какой-то из вот этих компонентов начинаете менять в размерах увеличивать или уменьшать то скорее всего это будет отражено на общую продолжительности всего запроса и благодаря этому можете например построить такую табличку что вклад сервис а 40 процентов вообще время выполнения там сервисы B 20 процентов сервисы собственное время тоже 20 процентов и ставший сервис как тоже распределились Ну и таким образом понятно что там наибольший вклад вносит А B и C там соответственно одинаковые вклад и поэтому равноценно идти попытаться их оптимизировать и так далее все-таки оптимизации можно делать вот когда мы говорим про визуализацию очень часто хочется вот не только саму трассировку Да посмотреть а также посмотреть влоги Зачем идти в какой-то другой инструмент Когда у нас есть один общий инструмент и там все это есть и действительно такие же инструменты уже есть вот тоже небезызвестная графа на который сегодня рассказывали там она поддерживает несколько бэкендов свой собственный Темп игры поддерживает zipkin поддерживает и таким образом строит не только дерево трассировки но и также вот здесь вот есть ссылочка налоги То есть можно сразу логике открыть и посмотреть логику по конкретному спам или по всей трассировке в целом эта концепция Она приводит к такой идеологии я не скажу что прям разделяют идеологию но тем не менее Она имеет право существование это про то что логики вообще не нужны Ну и возмутились как так как мы поймем что что-то идет не так там же все написано на слогах А дело в том что эти логи они прямо попадают в спальны То есть у нас есть вот он тилями 3 вот эти лок-записи они называются events А Open tracing то есть предшественники Open Ted называлось Локс там все понятно было вот логин логи пишем как вот логи Да и таким образом получается что у вас эта вся система она какая-то такая цельная то есть у вас нет существования логов где-то Отдельно Ну понятно чтобы по-прежнему Может там и стыда вот их писать но в целом такая концепция Тоже имеет право на жизнь и тоже благодаря трассировкам вы всегда можете посмотреть блогером на те логики которые относятся конкретно к вашему запросу развивая тему визуализации можно смотреть чуть шире Ни на одну трассировку а на множество трассировок и вот эта штука называется сервисный Граф то есть чем ее суть она внешне очень похожа на то дерево трассировала которое вы видели до этого но Разница в том что это не какая-то отдельно взятая трассировка это множество трассировок то есть грубо говоря мы рисуем все вот это взаимодействие между всеми всеми нашими микросервисами на основе всех спавнов которые приходили нам пришел миллион с Панов мы по ним построили вот такой граф для чего это может быть нужно у этой штуки может быть разные применение вот я расскажу про один обнаружение архитектурных проблем Итак попытался обозначить эту задачу которую можно решить с помощью этого вот смотрите вот этот рисунок три рисунка и подумайте что это может значить Как вы думаете что такое вот что такое слева Что такое справа что такое посредине Киева с версии есть на что похоже картинка справа седана сети Похоже что еще на Граф Ну да Похоже на Граф действительно так вот Представьте что слева это некоторый ваш микросервис то есть вот один процесс Да его там какие-то в нем действия происходят на выходе результат выполнения запроса Типа все понятно как-то живем так вот когда вы там распилите какой-то Монолит на отдельные части вы хотите увидеть картинку похожую на справа когда у вас там все аккуратно разнесено подменным областям в каждом сервисе там как-то между собой связаны и все замечательно Вот Но как правило когда мы распиливаем Монолит на микросервис у нас получается картинка посредине это распределенный Монолит и как раз когда мы вот на сервисном графике видим такую картину это Повод задуматься а правильно ли мы поделили на отдельные сервисы правильно ли мы разбили на доменной области Почему эта штука так иначе помогает это делать и есть инструменты которые позволяют это все визуализировать есть такой инструмент называется netflix serral вот здесь пример после того как эта штука может визуализировать потоки данных вот тут вот такие какие-то пакетики ходят между какими-то узлами выглядит очень залипательно красиво может быть может что-то даже взлететь в этом где-то прям много трафика где мало Трафика вот Это пример тот внизу футоре страницы У меня есть ссылка на вот статью про это вот поэтому когда на сайте на презентацию можно будет зайти Вот по всяким ссылочкам и посмотреть дополнительно какие-то материалы очень классная штука Всем рекомендую и наконец Мы добрались до пятой задачи про распространение контекста и Казалось бы мы сейчас уже сами так четыре задачи очень легко пробежали у нас осталось еще кучу времени а всего одна вот эта задача Так вот внезапно вот этой маленькой штуке вот этой маленькой задачей распространения текста кроется очень большая мощь и Давайте об этом поговорим но первое надо сделать отступление что вообще говоря вот этот рейс контекст он с некоторых с некоторых стал стандартом то есть в отрица его стандартизовал то есть на статус рекомендует получила в ноябре прошлого года То есть даже еще год не прошло с тех пор Вот и вот этот commination то есть по разъяснениям в 3C консорциума это нужно считать именно стандартом для Веба вот ну и таким образом всякие инструменты которые вот собственно есть они так или иначе уже поддерживают вот этот стандарт То есть можно отправлять трассировки вот отправлять контекст трассировок между своими запросами между сервисами вот таким образом и уже там инструменты они будут подхватывать это и будут с этим работать это кажется очень здорово помогает решить проблему Когда у нас там 13 конкурирующих стандартов вот тот самый четырнадцатый стандарт который решает эту проблему теперь он сдал 14 14 стандартов Но для C Это первый такой Ну и Давайте тогда поговорим о том как вообще вот этот трафик который у нас идет в наших распиленных системах тегировать как раз посмотрим как и зачем навешивать ярлычки на наши спаны Ну первое это разметка спанов например центром в куденом хостом Вы можете там продукт свой помаркировать и соответственно эта информация распространиться по всему дереву трассировки там можете клиента пользователя прокинуть то есть грубо говоря у вас самый первый сервис пришел запрос этого пользователя а будет информацию протянули вообще во все во все дальние уголки вашей системы и даже какая-то отдаленная инфраструктура совсем не связанная с вашим продуктом она тоже узнает о том что запрос пришёл по инициативе конкретного пользователя Ну и понятно таких примеров можно массу придумать вот все что вам кажется разумным или фантастическим можно попытаться отсюда занести и подумать А можно ли это как-то использовать и вот сейчас мы с вами попробуем посмотреть но перед тем как реально пошли это все делать важно отметить что вот эта штука должна быть консистентна то есть Смотрите если вы в своем продукте решили что у вас вершин там или Operation это что-то одно а в соседнем продукте это решили что что-то другое конечно вас ничего не получится Поэтому нужно будет завести на уровне там компании всех продуктов некоторую конвенцию без конвенции ничего не получится и должно быть она консистентно на всех продуктах так вот что потом можно дальше с этим делать Ну первое самое очевидное решение которое приходит голову это просто потом искать трассировки по тегам и вот допустим в том же зимние там есть специальное поле когда мы ищем трассировку где можно перечислить теги которые мы хотим найти и отфильтровать список трассировок которые подходят под наши критерии самые такие интересные трассировки Давайте их с вами разберем 1 это там ошибки у нас что-то сломала сервисе неплохо быть ошибки уметь профильтровать и посмотреть То есть там 400 500-е годы можем посмотреть там долгие запросы например там если ваш сервис работает там за 50 100 миллисекунд вам интересно посмотреть в те случаи когда он работает больше секунды понятно как бы задача и таким образом мы можем пытаться уже диагностировать работу нашего сервиса работу нашей инфраструктуры Каким образом Ну строить некоторые гипотезы и легко проверять Просто смотря на то Как устроены эти трассировки вот Представьте что у вас иногда какие-то запросы происходят очень долго и вы хотите проверить быструю гипотезу А может быть из-за того что где-то внутри системы происходит Рая соответственно у вас есть тег retrike значение True означает что если так присутствует то Вот вы сразу отфильтруете вот эти вот трассировок и наоборот где вот этого тега нет И можно сравнить Действительно ли причина Долгих запросов в этом или нет второй пример это отсутствие данных в кэше тоже влияет на летосина что из этого очень время выполнения становится долгим так это или нет У вас есть тег что вы промахнулись мимо каша и тоже посмотреть на это тоже понятным образом вот еще третий пример приведу о том что там у вас долгие запросы могут быть из-за того что у вас какие-то тайм-ауты внутри промежуточные То есть где-то вы отправляете запрос не дожидаетесь ответа и поэтому общее время выполнения запроса но тормозит то есть вроде система работает какой-то компонент системы долго отвечал из этого вся трассировка задержалась тоже очень легко проверить по тегу статус код ваших http-запросов Вот Но это пример был какой-то один который касался времени длительности времени выполнения запроса и вот такие вот истории их можно придумать какие-то свои новые но о том какие гипотезы еще можно строить мы поговорим чуть позже когда немножко математику ударимся чуть-чуть совсем но будет вот я уже говорил про тестирование в продакшене очень много людей подняли руки Вот давай Давайте посмотрим как трассировки могут помочь вот этой задаче То есть вы берете для своих тестовых аккаунтов навешиваете специальный Так это что означает что если в какой-то сервис получил такой тег что аккаунт который пришел к нему Это тестовый Ну например переводить систему ridonly Это означает что Вы точно не сломаете продакшн данные Здорово а второй пример это то что вы можете управлять вашим вот этим тестовым синтетическим трафиком например таким образом не отправлять его в какие-то продакшн сервисы А вот маршрутизировать в какую-то Station площадку чтобы например не генерировать лишнюю нагрузку на те сервисы которые не хотели бы чтобы им отправлялась вот это вот синтетическая нагрузка по понятная история то есть там на уровне сервис это можно будет реализовать наконец ситуация когда вас продукт которым много пользователей вы явно хотите чтобы пользователи друг друга не эффектерии то есть они один пользуется например не сломал другого другого пользователя например не сожрал там есть CPU вот если вы мыслите вот именно такими категориями скорее всего у вас там настроены различные аллерты на то что кто-то стал слишком много чего потреблять и за этом сразу будет паника там как-то инженеры начнут активизироваться что-то делать ситуация когда мы явно целенаправленно делаем какой-то нагрузочное тестирование очевидно уже это делается под контролем поэтому не надо будить всех остальных инженеров правильно Поэтому вот вы сами занимаетесь поэтому можно изолировать и например там тоже для таких тестовых аккаунтов можно такие соответственно ленты не чтобы не срабатывали и не беспокоить людей Почему зря вот развивая тему такого тестирования поговорить немножко про caus engineering тоже были люди которые подняли свои руки Давайте посмотрим как это все работает про что это когда вы в своей системе случайным образом условно случайным образом ломаете какие-то части и смотрите работает ли все дальше или нет Правильно ли он ведет как вы ожидаете себя или нет И внезапно тоже можно делать при помощи тегов которые будут распространяться через контекст это Например инструкция которая говорит надо увеличить какой-то сервисов вас увеличивает естественно вся система в целом будет должна как-то отработать ситуации когда какой-то сервис стал медленным может быть ситуация что вообще у вас какой-то компонент должен поработать поработать а потом типа упасть с ошибкой что там ну тайм-ауда типа не успел и тоже посмотреть как В целом система будет работать наконец Вы можете сказать своему сервису тоже опять через специальный тег такой caus engineingtack А давай так ты будешь завершаться с какой-то определенной ошибкой соответственно какой-то компонент завершается с ошибкой И мы смотрим а Правильно ли у нас системе отрабатывает Рае в целом там система остается доступна или нет деградирует Или там перформанс все это Можно будет увидеть никаких примеров кажется можно придумать действительно очень много то есть мы взяли несколько и поняли какую пользу от этого можно принести с точки зрения того как продакшене реально будет система себя вести не обязательно Это можно в целом делать и на стриженге Но самое главное что можем увидеть реальную работу системы в тех ситуациях которую очень сложно смоделировать То есть это там мог тестированием не очень удобно делать а здесь это прям на реа по системе можно делать можно пойти дальше и заняться отладкой на проде Вот но Сразу говорю я не сторонник этого Поэтому отнеситесь этому с пониманием просто не мог не сказать о том что такое возможно вот есть инструмент сквозь дибагер который позволяет отлаживать разработчику микросервисы которые прямо в губернатосе работают концептуально Это примерно работает так же как выглядит разработка прямо на продакшене вот кто-нибудь разрабатывает на продакшене есть такие люди понимают руки им не стыдно за это так вот как эта штука устроена У вас есть Дефо окружение там и доежка де багер у нее и некоторые сервисы которые подняли Да и теперь она сообщает в Control Plane сервис Миша о том что если придут данные по такому-то пользователю X то перенаправь запросы вот в ту реплику сервиса D который находится на стороне соответственно разработчика И вот так оно будет работать у нас получается не когда поднимаете вот такой сервис в продакшене не для всех пользователей а только например для того у которого проблема или для тестового пользователя то есть понятно чтобы изолировать и не навредить другим вашим пользователям особенно когда не знают кто сталкивает ситуацию есть такой пользователь один такой вредный вот которого все время чуть не работает вот один такой пользователь есть вот есть такое Вот видите вот есть такая штука вот так что разработка в продакшене может быть это и не самое большое зло которое можем сделать с помощью трассировок Есть действительно такие масштабные вещи которые можно делать на уровне всей компании при помощи трассировок Это история про биллинг Когда Вы начинаете фиксировать утилизацию ресурсов в разрезе какого-то тега организация пользователь сессия подписка какой-то грунтовый сервис который определяет продукт благодаря вот этому Вы можете сразу сказать кто больше всех ест баз данных просто используя распределенную трассировку допустим в плане CPU или там много пользуется кашом То есть это можно сразу будет отследить вот ну понятно это можно использовать с точки зрения того что переложить затраты на инфраструктуру прямо на проекты То есть это в идеале Но вообще говоря эта штука помогает планировать Каким образом вот у вас есть там гипотеза от маркетологов что некоторые сервисы у вас там вырастет на будущий год на 30 процентов А насколько нужно заложить архитектуры инфраструктуру с точки зрения там железа в целом то есть для от этого продукта и для там других сервисов которые продукт пользуются Ну вот вы когда получается планируете ресурсы на сам проект и также вы планируете на затраты этот сервис в инфраструктуре вообще говорят инфраструктура очень условно потому что можно Для любой другой сервис Если у вас есть там условно компонент который отвечает за аутентификацию авторизацию то понятно что пользуются все другие продукты Ну вот можете понять какую там нагрузку каждый из этих сервисов будет создавать на вот этот вот эту часть системы То есть можно будет благодаря этому планировать вот эта история про беллинг это вообще для меня это оказалось таким самым таким главным откровением что пилинг это как правило очень сложный процесс очень сложно организуемый в компании но внезапно когда есть трассировки его можно сделать на первый взгляд с минимальными затратами для разработчиков которые должны на своей стране что-то поделать вот это все были истории про такие задачи Давайте немножко копнем глубже и поговорим про метрики Почему я хочу поговорить про метрики вроде бы логично мы с вами на конференции принято говорить про метрики Вот Но трассировки вот до этого это все были Вещи которые нам позволяли провести какую-то диагностику что-то сломалась мы вот трассировкам Пошли смотреть изучать А метрики как правило все-таки используется для инструмента обнаружения Ну если вы конечно не сидите все время перед мониторами и не тратите в графике то все-таки вы как-то летинг настраиваете таким образом метрики это у вас инструмент такого обнаружения То есть как можно раньше увидеть какую-то проблему и поэтому Давайте подумаем А можно ли из трассировка получать метки то есть сразу метрику получили и можно как-то отреагировать Что с этим сделать Давайте посмотрим как это можно сделать Давайте Какие метрики нужно Вот давайте такие фундаментальные вещи вот четыре золотых сигнала Вот кто может шифровать какие там четыре золотых сигнала вот сложно расшифровывается вот я аббревиатуру придумал который помогает называется Тесла трафик error's saturation и leton 7 Вот но может быть аббревиатура не очень хорошая есть получше Вот redmiot то есть Rate roars duration и use метод э телезейшен saturation errors у меня под каждый из них там внизу опять же говорю ссылочка есть можно подробнее почитать про мотивацию как это делать В каждой штуку закладывается Вот Но что самое главное Вот касательно вот этих вот базовых метрик которые там ну Возможно вы захотите у себя в сервисе делать это то что стандартные теги которые есть у спана они уже закрывают эту потребность смотрите у вас есть спам у него время начала когда начался запрос и когда он закончился знаете продолжительность вы знаете размер тела запроса то есть сколько улетела данных туда и сколько соответственно вернулось обратно тело ответа знаете код ответ там успешно завершилось там с 200 кодом там или с каким-то другим это тоже знаете и таким образом если посмотреть Вот эти метрики то есть каждого из этой истории график error's Raid и прочее что каждый из них по смыслу значит выходит что больше половины вот этих метрик можно сделать из построить из трассировки уберете поток трассировок и просто на этом потоке вычисляете значение то есть допустим там вы берете СПА на считаете их продолжительность для конкретного сервиса и Можете посчитать для конкретной реплики например распределение letones кажется вещь действительно стоящая вот можно пойти еще дальше И когда Вы прям самом приложении считаете тоже какие-то метрики то есть история про трассировки когда на основе трассировка считаете метрики Это история когда метрики где-то снаружи считаете то Используйте даже вообще ничего не знает ваш разработчик который что-то делает Он даже не знает про эти метрики вы сами там втихаря считаете а потом мы готовы график даете или там уже даже алименты для него настроили Это по-моему бомба Ну так вот а можно прямо пойти и попробовать прокачать те метрики которые есть у пользователя у разработчиков в своём сервисе то есть Вы прям обогатите каким-то контекстом эти метрики Ну это стало возможным когда там популярность приобрели тегированные метрики то есть исторически вот графит который плоские метрики там нельзя было это сделать И то сейчас уже в граффити там поддерживаются основа основ так вот как вот это можно обогатить как какую задачу можно сделать самый простой пример У вас есть Метрика request letonsi А вы к ней добавите теги там версия сервиса и там с кастом текс дата-центром и Теперь смотрите если у вас что-то пошло не так вы можете понять это из-за того что за тепло или новый код то есть версия сервиса Да какая-то другая стала Или например то что на конкретном Хосте то есть какой-то хвост заболел и надо его изолировать или там проблема там на уровне одного какого-то центра это Можно будет увидеть по вот этим метрикам надо только добавлять соответствующие теги то есть распространять контекст уже внутри какого-то приложения и внезапно тоже уже есть вот такие вот реализации в той же графане там с некоторых пор появилась такая штука Как экземпляры Когда вы можете там ткнуть вот здесь график и на нем есть экземпляры То есть это некоторые точечки которые соответствуют некоторому запросу некоторым испану в котором там данном случае здесь время показывается поэтому там точка которая соответствует какому-то какой-то трассировке которая продолжалась соответственно заданное время и можно вот таким образом выбрать какие-то выбросы То есть когда это типичный запросы он не может не очень интересно те которые слишком быстрые да Либо наоборот который слишком долгие и вот пытаться на них что-то делать Ну вот как раз здесь мы подбираемся к немножко к математике вот когда там в университете там не знаю могли задаваться вопросом Зачем мне вот этот Матан Зачем мне от статистика и прочего внезапно есть вещи где эта штука неплохо себя показывает и имеет место ее применение первое про что хотел говорить это про гистограмму летансе вот все знают да там какие-то вот перцентили там 99 понятная история Давайте посмотрим Зачем можно строить гистограмму Вот Первое это что надо понимать что вот сервис который у вас работает скорее всего Скорее всего у вас разные параметры можно подавать в этот сервис и скорее всего они будут работать за разное время и скорее всего вот эти вот методы которые есть у этого сервиса они еще будут в разном количестве дергаться какой-то будет разные перформанс профиль для них Но и в этом плане здесь хорошо вот это иллюстрирует вот этот вид про выделенные серваки для Джастина Бибера в Твиттере по моему довольно забавно и как раз в целом это как раз говорит о том что есть пользователи которые ведут себя стандартным образом понятную нагрузку А есть те которые выбиваются довольно сильно из вот этой всей истории помню туда какой-то период фоточки на которых там серваки с подписью там Джастин Бибер Леди Гага там и прочее вот такие вот выделенные сервера Что называется так вот в этой истории Когда разные у нас перформанс профили нужно поэтому смотреть именно на распределение То есть как это распределяется по частотности Ну вот пример Вот это гистограммы здесь у нас внизу Это идет letency А это частота То есть как как часто Вот в такой багет попадает соответственно время выполнения запроса и вот тут можно увидеть что на этом графике он не модальный А вот три моды и Если вот мы пойдем Вот для этого сервиса начнем раскапывать А почему так то там действительно выяснится что природа то в этих запросов разная то есть там вот этих 33 вот эти горбатый соответственно Три разных типа запроса и вот это надо уметь как-то отслеживать и как это мы делаем мы Просто берем и ищем такие типичные примеры в каждом из этих вот модальности то есть сравниваем запросы которые попадают туда и туда и туда это дело вот в частности довольно неплохой инструмент Вы можете выбрать кусочек вот этой вот этой получается гистограммы и посмотреть там внизу показываются примеры трассировка которая заполняются за это время таким образом можете там выбрать вот один кусочек другой кусочек третий кусочек и в каждом из него выбрать такие типичные примеры и пытаться по сравнивать А про что вот эти запросы попытаться там соответственно придумать может быть какой-то дополнительное на вешать теги Да чтобы как-то их дифференцировать друг от друга и разделять он продолжает тему от статистики можно еще говорить про тренды вот в чем их суть когда мы там говорили обнаружение когда проблема но вот случается или вот или уже случилось Здорово Когда мы можем видеть деградацию не в тот момент когда она произошла А вот сказать что она случится Да и как можно это продемонстрировать самый простой вариант это когда мы сравниваем там не знаю 99 999.9 допустим сейчас Да И там месяц назад и смотрим поменялось что-то или нет хуже стало или лучше Вот Но также можно смотреть на гистограмму летансе то есть вот сейчас и месяц назад Давайте посмотрим на пару примеров Вот это график зависимости от времени времени это вот получается за сутки взята график за сегодня тут странное произошло и вчера вчера там вроде как все ровненько без каких-то аномалий И тут если вам зададут вопрос типа А чуть-чуть здесь пошло не так наверное все обратят внимание на то что что-то тут оно вверх пошло Вот время стало выполнение запросов какой-то большой Когда вам зададут вопрос типа А почему скорее всего прям сразу ответить не сможете Но если у вас есть гистограмма летанси Вы можете построить ее для вчера или сегодня и увидеть например что вот здесь явно появилась какая-то дополнительная Вот такая вот дополнительный горб то есть какие-то запросы внезапно стали работать дольше но потом дальше когда обращаетесь к трассировкам то например выясняется что диплоили Новый сервис до новую версию и какой-то конкретный метод просто в нем деградировал это Можно будет увидеть по крайней мере понять что есть Вот это какая-то проблема с конкретным сервисом конкретном месте благодаря вот таким таким графиком трендом Ну смотрите здесь в целом о том что есть проблема мы это увидели без гистограммы Да увидели по вот этому хвосту который стал вести себя плохо Вот как он такой Маск тренды в таком ключе что вот так же идет гистограмма lege кстати так иллюстрация взята из книжки как раз дистрибьютор tracing practies смотрите вот слева это как было это как стало в целом распределение это незаметно поменялось и понятно что если мы будем смотреть на перцентили скорее всего они будут те же самые вот действительно там хвост самое он как раз там в районе 1000 миллисекунд Что там Что там в другом в том и другом случае а проблема в том что там делать стрелочкой подсвечена там маленький маленький столбик он стал выше он прям явно там выше стал А почему он стал выше то есть изменение на лицо а что могло произойти значит запросы стали около нуля То есть он очень часто происходит но с маленьким временем выполнение Какие гипотезы могут родиться Давайте просто какой-нибудь вариант набросите как что действительно Да самый простой Типа все сломался он начал быстро 500 быстро шипки но это негативный сценарий А хороший Мы например за релизили новый код где например добавили кэширование и внезапно там куча куча запросов стало разрабатывать быстрее Скорее всего на хвосте этих запросов мы это не увидим Но вот на начальном столбик будет на который можно будет обратить внимание и подумать Вот но разглядывать такие графики вот это один столбик какой-то безумно тоненький и высокий может быть очень сложно Правда ведь поэтому можем обратиться прям к от статистике по серьезному и начать считать корреляцию какого Каким образом вот у нас есть перформанс как правило наиболее важен и посмотреть какая между ним зависимость ошибки вот для летности как это может работать вот связь между высоким интенси и тегами Для каких тегов вот большой Вот и таким образом мы перебирая различные теги можем видеть что вот если вот этот набор тегов время запросов выполнения большое вот этот набор тегов время выполнения хорошее и таким образом мы можем придумать о каких-то гипотезах которые по тем потом хотим дальше проверить там по коду или по каким-то другим метрикам по каким-то другим графиком это можно действительно сделать То есть вы на основе анализа от статистики сделали гипотезы проверили их Ну и поняли в чем проблема Вот давайте двигаться дальше Вот кто знает про TD Ага А вот и не знаете потому что это трейс дривен девелопмент Да с подвохом в чем суть То есть это примерно как ТДД классическая только тут у вас во главе угла не не тесты А трассировки в чем суть Вот вы как правило когда начинаете что-то новое делать были ваши коллеги они начинают проектировать что да вот какие-то такие схемы рисуют может быть даже кто-то из вас догадается вообще что это за архитектура что она похожа там ключевые слова всякие разные есть Можете разглядеть еще ссылочка она внизу есть Поэтому можно будет посмотреть что это такое так вот эта схема она очень похожа на тот сервисный Граф тонировку которую мы до этого Смотрели очень похоже да ведь действительно если так оно происходит Мы можем во-первых проектировать как бы заглядываясь на трассировки то есть мыслить именно тем как именно сервиса между собой взаимодействует с точки зрения там результат Такой сценарий отрабатывать и при этом мы можем прям свой сценарий который хотим проверить что он должен работать описывать не вот этими скучными тестами на языке спанов что у нас запрос должен сходить вот туда туда и там получить какой-то результат и даже пойти дальше И вот лончик лист дополнить Вот кто использует лончи чек-лист в своей работе Это типа чек-лист для запуска сервис Новый сервис на Новый год версию кода Запустить вот чек-лист типа Что нужно сделать чтобы запустить там не знаю на балансировщик Да там нужно конфиги прокинуть там завести namespace в кубери там правильно requesto лимиттер статью вот это все в чек-лист да да короче сюда попадает вот Может быть там у вас там куча пунктов Есть у кого есть чеки кто-то настраивает чеки Вот значит у вас есть чек-лист все там находится вот а теперь смотрите мы берем и вот этот вот наш чек-лист такой еще добавляем не знаю там чек не Health Check его можно по-разному трактовать что система запустили делаем тестовый запрос и смотрим А вот какая у нас трассировка получилась похоже на ту которую там изначально это проектировали да в самом начале или нет Если похоже значит всё типа система работает как ожидается и все работает хорошо то есть никакой компонент у нас системе после такого обновления не сломался это можно будет проверять благодаря этому В общем такими чек-листами конечно здоровье наших сервисов стоит Что сколько мы там качественно проверили перед тем как запустится настолько хорошо там будем спать последующем по-моему такое непонятное связь с этим Ну вот и вот таких историй там продолжал продолжать можно довольно много вот смотрели 5 вот этих задач Но на самом деле там вот там распространение контекста на кучу других декомпозировалась там N задач каких-то Да еще их Некоторое количество я вот несколько дней думал а какой же заключительный слайд сделать потому что вообще Вот таких идей истории довольно много которые еще можно так отсюда набрасывать набрасывать и приводить примеры А где действительно трассировки могут помочь Поэтому я решил ограничить тем что пригласить пообсуждать это и может быть поговорить про какие-то ваши интересные сценарии и посмотреть насколько Вот именно таировка Она натягивается на вот эту историю но только должно быть это полезно для всех поэтому спасибо за внимание Я готов ответить на вопросы Да спасибо рыб на самом деле было прикольно К сожалению времени у нас осталось очень мало Я еще раз напомню что мы тут хотели подарить небольшую книжку с кабанчиком популярная книжка а единственный момент что наверное эту книжку мы сможем подарить только тем кто оффлайн Простите Если вы вдруг онлайн не задавали вопросы но у нас будет сейчас дискуссионка после доклада можно там как раз эту книгу вручить Если вдруг вы сейчас этого вопроса У нас есть маленький вопрос то на самом деле много там про клиентов про микро сервисы еще что-то понравился вопрос внезапно про разные подходы к инструментации вообще А зачем нам вот эти всякие трассировки Да как-то встраивать нельзя ли сделать как-то так чтобы можно было по модели Да по самой модели приложения понять что происходило все эти трассировки предполагают какой-то внешнее хранилище для информации это правда Ну вот я не знаю того что такое модель А какой именно речь Понятно В целом что мы можем прям в самих данных хранить какую-то информацию но мне кажется дичайший верха для данных все-таки У нас есть данные нашего приложения и мы храним специализированном хранилище которое Хорошо подходит под наши данные от трассировки какой-то другой тип данных мы там под них выбираем соответствующий инструмент например там хорошо для Таких данных подходит внезапно клип хаус это сказал Да просто ты начал говорить про то что можно информацию по биллингу ещё что-то строить Мне тоже немножко смутило что мы трассировку используем настолько глубоко и встраиваемые какие-то другие процессы нашего приложения к этому тоже наверное ну лично у меня есть вопросы да то есть вот честно скажу вот Что вот многие из этих вещей они как бы являются перспективными То есть даже ещё там аутсорс реализации для некоторых задач нет Вот но в целом вот по биллингу Вот пока на данный момент мы вот так вот не используем как вот это здесь то есть часть задач которая рассказывала у нас прямо вот там уже много лет используется какие-то вот там недавно запустились Production вот А вот некоторые вещи этого то что кажется действительно классным было бы делать Ну понятно Ладно К сожалению время у нас закончилось ещё раз хочу напомнить что сейчас будет дискуссионная зона которую можно том числе из онлайн подключиться Мы как разберёмся с нашей замечательной подарком и в конце Ну после того как всё это закончится через полчаса тут будет закрытие что-то еще через полчаса будет закрытие 18:30 Окей вот там же кто-то задал этот вопрос Вот кто автор здесь человек который задал этот вопрос или нет отлично отлично это замечательную книгу Вам замечательные пакетиком с надписью реклама все дела Поздравляю там стикеры есть Спасибо Всем спасибо"
}