{
  "video_id": "QKc67O583YU",
  "channel": "DevOops_conf",
  "title": "Сергей Канибор — Network Policy для разработчиков: как, зачем и почему",
  "views": 426,
  "duration": 1877,
  "published": "2024-09-13T02:26:35-07:00",
  "text": "Всем привет Меня зовут Павел пахус Я сегодня в роли эксперта на докладе про сетевую безопасность в кубернетес А в роли спикера сегодня специалист по безопас Конте сред из компании Сергей кобор Сергей Насколько часто тебе самому приходится взаимодействовать с курсом и в роли кого сети инженера администратора или разработчика Да привет Мы так как мы занимаемся разработкой решения по безопасности для кубера то я каждый день как бы с ним сталкиваюсь и работаю Но наверно как в качестве секюрити инженера вот поэтому Это основное чем я занимаюсь и специализируюсь на этом я понял спасибо дорогие зрители вопросы по докладу Вы можете задавать в конце доклада либо Прямо во время доклада в чатик в телеграме отсканировал QR код Сергей передаю тебе слово спасибо да ещё раз Всем привет давайте начинать мой доклад называется как Network polic для разработчиков Как зачем и почему вот сегодня мой доклад как бы нацелен как уже могли понять именно на разработчика Я постараюсь убедить Почему именно разработчики должны заниматься написанием сетевых политик Вот но для начала пару слов обо мне Вот я из компании lry мы делаем решение по безопасности для кубес Вот сам я как уже сказал Павел специализируюсь на безопасности контейнеров и кубернетес вот кое-где Я выступаю и являюсь редактором Telegram канала Security вот план моего доклада примерно такой а опять же так как я подразумевал что доклад будет нацелен на разработчиков Для начала я вкратце расскажу что такое кубер какие-то его основные особенности вот потом уже более подробно остановимся на ресурсе Network polic и затем затронул моменты с созданием сетевых политик и с контролем ресурсов Вот Но прежде чем начать хотелось бы ответить на вос зачем вы сюда пришли почему зачем разработчикам нужно знать про net вот Я вывел несколько таких поинтов вот во-первых неправильно написанная сетевая политика может сломать логику работы вашего сервиса Например если у вас там сервис а ходит в сервис Б А вы в сетевой политике пишете что у вас сервис а ходит в сервис с всё ломается ничего не работает ВС плохо во-вторых контро сам по себе он способен уменьшить поверхность атаки вот ну то есть если даже ваше приложение уязвима что никогда не стоит исключать и злоумышленник проэк какую-то уязвимость точнее пытается это сделать скорее всего дальше как-то развить атаку у него не получится там словить какой-то отст или шел куда-то к себе на тачку у него это просто не выйдет из-за того что опять же есть сетевые политики Так что такое куртис Ну думаю многие Кто здесь сталкивались с ним знают что это такое слышали и работали но тем не менее как мы до этого Дошли Ну то есть изначально все запускали свои приложения там у себя на машинах вот вскоре поняли что это всё не оптимально по ресурсам и не очень это удобно Вот потом начали использовать гипервизор там который полностью Элит к Ну вскоре все перешли на контейнер ранта где у нас контейнер по сути это изолированный процесс с помощью там некоторых механизмов ядра Вот и в качестве контейнера н тайма у нас могут выступать всякие типа докеры Пома крио и так далее Вот ещё раз Почему кубернетес есть такой такое мнение что кубернетес Вообще является ядром линуса века Вот Согласно свежему исследованию там компании Ну почти в 60% компаний в России используют кубернетес в качестве оркестратор поэтому рассказ сегодня именно про него вот ну остальные думаю как бы не имеет смысла особо затрагивать Вот кубернетес сам по себе декларативная система То есть у нас всё задаётся через ял файлы Вот они выстраивают определённый там набор абстракций вот и по сути кубе является системой с большим количеством сущностей сегодня наверное я ну затронутой нужно знать там чтобы понимать вообще примерно какую-то логику Как это работает вот одни из таких основных сущностей - это поды под это такая минимальная исполняемая единица в кубе в поде Может у нас существовать один или несколько контейнеров вот для того чтобы поды могли между собой общаться нужен такой сервис какя сущность как сервис Вот она нам позволяет как раз таки выстроить общение и ингресс для того чтобы заводить трафик снаружи как-то его ну то есть распределять по нашим контейнерам Вот Но прежде тем начать хотелось бы сделать ряд оговорок я вот сказал что кубер декларативная система мы как бы сдаём всё в ям и ну по сути ничего сложного нет для того чтобы написать сетевую политику надо просто посмотреть забрать оттуда какие-то значения лейблы порты протоколы и так далее ну но есть но э например рассмотрим такой кейс у нас э в компании К примеру используется gitops подход То есть все файлы лежат в гите git единственный источник Правды есть какое-то такое простое приложение вымышленное которое состоит там из э двух деплой двух сервисов там как-то одно приложение с помощью другого общается с другим общается через сервис и in Вот Но вот Какие особенности могут быть например наши приложения могут существовать в разных пейсах и иметь разные лейблы опять же То есть это надо учитывать там если мы Обращаемся к лейблу из другого спейса во-вторых у нас в кластере может стоять такой класс решений как сервис который ко всем нашим подам добавляет Конте что уже накладывает определённые нюансы и наш Вот это сетевое взаимодействие оно меняется то есть оно не напрямую от сервиса к сервису А уже через этот сака контейнер во-вторых у нас может быть какая-то реализация Ingress там кастомная или какая-то ещё опять же это может как-то изменять трафик и наше сетевое взаимодействие между приложениями вот ну и ещё не стоит забывать что всё просто так не работает собирается логи трейс что как бы опять же накладывает определённые ограничения и нюансы вот отсюда немного промежуточных выводов Ну в реальных окружения сетевое взаимодействие между контейнерами ваших микросервисов оно значительно сложнее чем то что видит разработчик и то что лежит в его ответственности вот по сути итоговый Нетворк которая будет в кластере это труд нескольких департаментов как условно там работ The WS там не знаю платформенных инженеров безопасни ков это такое комплексное Решение вот ну и такой главный Поинт наверное э почему именно разработчик должен это делать потому что по сути именно он лучше всех должен и знает и понимает бизнес-курс Виса он знает куда он ходит что Он забирает что отправляет поэтому как бы это в его зоне ответственности вот дальше небольшой ликбез по тому как устроен куне Network А во-первых у всех подов есть IP адреса но IP адреса ничего не значат на самом деле это такие эфемерные сущности они могут там перетекать от пода к поду в зависимости от того там убивается под переезжает он с ноды на ноду или птся что-то новое вот у нас есть какой-то под сидер на каждой ноде У нас есть сервис для ланга чтобы распределять нашу нагрузку и в куре очень важно ДНС потому что именно с помощью него как бы работая Discovery и ну на IP нельзя завязывать поэтому завязываются на DNS на имена сервисов вот если говорить про подов то по умолчанию в кубе поды могут коммуницировать друг с другом без ограничений То есть у нас нет никаких ограничений любой под из любого спейса может Достучаться до любого пода из любого другого вот в целом весь трафик можно как бы разделить на два это ну трафик в кластере это трафик который с ресурсами за пределами кубера там например какие-то базы данных виртуальные машины которые стоят за кластером ии с другими приложениями внутри кубера то есть там с другими пейсами и прочее то что внутри кластера Вот ещё важный нюанс трафик по умолчанию никак не шифруется Вот например если вы хотите чтобы он шифровалка оговорку я вот сказал что по умолчанию поды в кубе могут там коммуницировать со всеми без ограничений Но вот например был классный доклад от Александра Кожемякина там он рассказывал как внедрить default Den кластере то есть по дефолту у нас всё запрещено и дальше мы уже там белыми списками разрешаем что нам нужно вот ещё важная оговорка то что по умолчанию когда мы раскатываем кубер у нас в сети Как таковой нету И чтобы она появилась нам нужно использовать сторонние штуки так Нава Вот они как раз таки предоставляют интерфейс Их достаточно большое количество это скриншот Ну то есть такие довольно все популярные Но вот два из них самых популярных это Калика и силиум думаю многие именно Их используют тут важно что отметить что не все живые Окей Вы можете задеплоить эту политику но она по сути работать не будет Вот поэтому как бы на это надо обращать внимание дальше про контроль сети и концепцию микросели вообще сетевые политики Сами как по себе довольно хорошо ложатся вот в концепцию ust как раз-таки это про то что я говорил в начале то есть даже если злоумышленник каким-то образом пробился эксплуатировался такой а Ключевое то что сюда Нужно извлечь А если будем так рассуждать о том как вообще Можно контролировать трафик э сетевое взаимодействия в кубе я тут привёл несколько вариантов первый вариант как это можно сделать например на уровне приложений у нас может быть какая-то там сторонняя библиотека а которую мы там добавляем при сборке или через inject это всё работает как-то в userspace само собой накладывает там дополнительные оверхеды Ну и вообще так делать не надо И не знаю кто так в кубе делает но как вариант возможно А следующий вариант это на уровне сервис MH это ещё такой отдельный класс решений я его уже упоминал сегодня вот например там и или linkerd то есть там каждому поду представляется ещё один S Car контейнер вместе с тем сес там предоставляют отдельные кастомные ресурсы вот один из них это policy где мы можем уже разрулить наш трафик там на L7 уровне вот всё это работает в US Space Также можно рассмотреть как альтернативу но опять же это всё накладные расходы оверхеды Ну довольно много ресурсов отъедается вот ну и вариант на котором Мы остановимся это на уровне sin то есть мы можем писать наши ресурсы сетевые политики как нативные которые нам предоставляет кубер либо кастомные которые нам предоставляют сами си провайдеры вот мы можем контролировать сетевое взаимодействие там на l34 так и на L7 уровнях всё это работает в Space поэтому довольно быстро и как бы мы не замечаем никаких просадок е важно отметить что сами технологии которые используют это раньше все там использовали сечас все переезжают на вот это как бы тоже так можно учитывать при выборе синае вот тут пример того как может выглядеть сетевая политика Я разбил это на три слайда потому что она довольно большая вот в целом можно выделить как бы три таких мы там задаём наше имя политики какое там нам нужно Space в котором она будет действовать вот дальше мы в под селекторе указываем лейблы по которым она должна быть привязана к поду тут Важно опять же отметить что политика привязывается именно к поду там а не к сервису или ещё какой-нибудь сущности вот а дальше мы задаём типы правил в политики вот по умолчанию если у нас ничего не будет выставлено у нас политика будет и дальше я про это расскажу дальше Мы описываем например блок и правил там мы задам типа откуда может приходить трафик С каких адресов там с каких селекторов селекторы можем задавать под селекторы То есть это всё довольно гибко и делав можно привязывать также указывать порты там протоколы и про вот эти все штуки вот для в принципе всё тоже самое также можем задавать там порты протоколы адреса селекторы и прочее вот про полиси types как раз-таки то что я говорил тут такой важный момент э если у нас никакой policy types не будет проставлен для нативной политики для Калика то по умолчанию у нас будет выставлен ингресс политика вот в силиум если мы ничего не выставим У нас ничего работать не будет Ну тут такая небольшая таблица чтобы понятно было вот я уже вкратце как бы затрагивал момент что у нас есть нативные есть кастомные сетевые политики вот сейчас немного более подробно остановлюсь Какие вообще преимущества есть у сетевых политик кастомных чем они отличается от нативных вот во-первых кастомные политики позволяют нам ограничивать доступ не только к подам как это делают нативные но и к другим различным сущностям как и там стоящими за пределами так и внутри кубера вот во-вторых у нас появляется новый уровень на котором мы можем контролировать наше поведение сетевое это L7 есть политики там dsb и прочие штуки во-вторых Мы можем написать политику не конкретно на какой-то в котором там действуют приложение а в целом на весь кластер это бывает очень удобно например Когда нужно написать или разреши фи Ласт чтобы он афек все наший Все наши поды вот во-вторых мы можем довольно гибко использовать селекторы наши которые привязываются к подам там например у Калика они встроили ещё дополнительный Такой типа язык как можно там гибко указывать лейблы Ну И в тоже время можем привязываться не только к пом уже сказано сервисам сервисным аккаунтам там по лейлам по немам и прочее вот а про создание сетевых политик теперь так как опять же мой доклад был нацелен на разработчиков я подумал что разработчики не очень наверное захотят писать это всё руками э и но в то же время им всё равно когда-то придётся их писать потому что Shift Left так или иначе доберётся до них Вот поэтому я рассмотрел только как бы такие автоматизированные варианты вот Первое - это silum Editor думаю многие про него слышали видели ээ Ну Web интерфейс там висит у нас там на на на сайте штуку э придумали силиум значит как это выглядит у нас есть такой интерфейс мы можем просто накликать всё что нам нужно то есть там указать э лейблы у пода указать куда он может ходить в какой mspace там на какой айпишник и прочее вот из особенностей мы можем легко накликать нужные нам политики нам вообще там не нужно знать синтаксиса что-то там отступы и прочее просто мышкой накли пишем буквы всё готово во-вторых У нас есть возможность автоматической генерации по логам Ну силиум - это такая довольно вообще большая экосистема у них там много всяких лов есть один из них - этол вот соответственно Мы можем с помощью ла собрать логи с нашего net вот дальше это всё отгрузить в и загрузить на этот сайт и он нам сгенерить политики вот из минусов что здесь во-первых сервис висит в интернете поэтому он по-любому собирает там какую-то интри во у на доступна только в конкретный момент времени вот это то что третьим пунктом то есть мы собрали да последние ты там А там если какой-то жизненный цикл приложения довольно большой допустим оно там в начале уходит куда-то в одно место потом отгружает логи в другое через какое-то время и мы не захватили вот этот промежуток будет Из очевидных минусов это завязка на конкретный си хоть и silum Editor позволяет там как бы генерировать политику для Ну натив ную но тем не менее только натив ную и только силиум ну и плюс нам нужны дополнительные ресурсы на нашей ноде для хаббла а он ест немало вот следующий вариант Инспектор Гаджет такая довольно большая туза для кубера позволяет делать много чего Но сегодня вот ос работае чере ста поставляется как для ля Вот тамп вот так вот собственно Она что делает Тоже позволяет нам собрать логи с нашего там как наши приложения общаются и дальше по этим логам щего пункта вот нам также нужны дополнительные ресурсы Хоть это и работает там и но тем не менее там ряд датов Нужно ещё какие-то деплой в общем дополнительные ресурсы нам необходимы вот ну и тако тоже ключевой момент что вся генерация нам доступна только в определённый момент времени опять же если у нас там жизненный цикл приложения какой-то большой и там что-то происходит то что мы не успели за захватить то у нас политика будет неправильно всё сломается но тут Важно отметить что есть инструменты где получение политик автоматизировано Вот Но как правило они платные но тем не менее эта проблема решена теперь про контроль ресурсов То есть у нас есть политики мы их написали мы знаем что это такое пер нам нужно как-то за этим следить Какие есть варианты использовать owners опять же если у вас там gitlab или ещё какая-то подобная такая система где есть cers мы можем его использовать он есть платной версии вот в чём его суть мы создаём там определённый файл указываем Там по маске расширения И когда кто-то захочет см ветку тот назначаться автоматически пока вот это владелец файла не одобрит так это примерно выглядит но опять же В чём суть это удобно Если у нас тамп подход Всё лежит в гите и вот это как вариант вот следующий вариант жде чем я про него расскажу такая небольшая схема это так называе запрос после п App через какую цепочку он проходит вот ну то есть для начала он там нам прилетает на хендлер потом мы проверяем Может ли этот пользователь который сделал этот запрос сервис аккаунт вообще совершить эти действия вот потом э у нас попадает наш ресурс на mutation admission там мы можем как-то мутировать нашу наш ресурс потом проверяется схема не нарушилась ли она после мутации и дальше мы можем его проваливать как нам надо вот а затем ресурс закрепляется vcd Вот как раз таки предпоследний этап для нас более интересен будет Вот есть такой класс решений называется который как раз таки позволяет нам валидировать но в том числе и мутировать вобще любые ресурсы в кубе и мы только захотим вот этон изх ста наверное один из самых популярных там есть возможность писать validation рул учитывая наличие подписи у ресурса Вот как это можно сделать например есть ign который с помощью которой мы можем сгенерировать пару ключей и собственно подпись для них вот поэтому на Первом шаге генерируем пару ключей затем есть ещё одна такая туза cstore через которую мы можем подписать наш сам yam manifest закрытым ключом на выходе мы получим наш подписанный манифест вот а затем нам нужно написать политику для policy Engine в которой мы указываем открытый ключ который мы получили на первом этапе вот если это всё соединить у нас получится примерно такая политика А ну то есть мы указываем что мы хотим чтобы у нас деплоить ресурс Network policy Ну например Здесь нативно указан и мы вставляем наш публичный ключ Вот соответственно по этой политике у нас могут зате только те Network polic которые имеют подпись так вс всё это ещё можно накрутить на ПС подход кивер отлично встраивается в c там есть отдельная Кле тоза такая вот и с помощью неё Можно например подписывать наши я ресурсы через бес ключевую подпись так называе соответственно если у нас там используется Мы например берм и настраиваем его таким образом чтобы наши ресурсы делось только из подписанной ветки вот если на схеме это выглядит примерно так то есть у нас есть какой-то разработчик который у которого есть не подписанный яф РС с подписью складывается в мей ветку и оттуда Ар уже вытягивает его в кластер а затем этот ресурс проверяется через кивер тем самым как бы у нас это всё оказывается в кубе вот у меня наверное Всё я уже так плавно подхожу к выводам что хотелось бы сказать в реальных как бы окружения сетевое взаимодействие намного сложнее тем что видит разработчик то что лежит в его ответственно вот итоговые Нетворк полиси как я уже говорил это труд нескольких департаментов то что мы получим В итоге Это будет ну довольно большое количество сетевых политик вот разработчик лучше всех должен Ну как Вроде бы да понимать логику бизнес логику микросервиса Именно поэтому я как бы считаю что в целом когда-нибудь им придётся этим заниматься вот Ну и с помощью сетевых политик можно довольно гибко ограничивать сетевое взаимодействие ваших сервисов Как вы уже видели то есть никакие там файр волы или ещё какие-то сторонние штуки использовать не надо всё есть в кубе нативно либо использую какие-то сторонние Синай провайдеры вот ну и микросели Э довольно важный Аспект безопасности Как кубера так и в целом и ну и концепция zust вот у меня на этом всё вот тут ссылка на наш Telegram канал там по безопасности кубера Вот Всем спасибо Буду рад ответить на вопросы есть у кого-то вопросы может так Давай я наверное тебе зачитаю первый вопрос у тебя а в докладе было процентное соотношение компании которые вели используют у себя кубернетес и процентное снижение там было такое что по-моему 58 да ну да около 6 а есть какая-то какая-то оценка того какой процент из этих 58% используют у себя нар polic потому что кажется что Задача В целом внедрения а потом ещё поддержки она как бы не тривиальная Угу Ну вообще вот как бы компании стараются сразу если там пережать в кубер то как бы сразу вот обращать на эти моменты по безопасности вот один из главных как раз таки аспектов наверное ключевых который может быть это вот ну создание поддержания полисе поэтому я бы сказал что наверное все кто переезжает в кубер его использует так или иначе как бы применяет сетевые политики Ну я ну я думаю по процентному соотношению не знаю проценты 80 видимо мы с тобой просто в разных мирах живём хорошо а вот сколько нужно примерно человек чтобы поддерживать атуа Ну актуальное состояние всех этих политик и Верно ли что количество человек которое ВС это поддерживает пропорционально либо количеству команд разработки либо количеству сервисов которые задело Ну вот да как бы всё зависит от количества вообще сервисов и от то Ну от того как вообще разделены у вас там зоны ответственности то есть там ну обычно как бы под приложение выделяет Там какой-то отдельный Вот я думаю что зави вот команд разработки как бы от количества самих вот проектов Спасибо тут у нас ещё вопрос есть из зало задашь или мне зачитать Ага Что лучше использовать C Network polic плю vl или классический Network po Ну в принципе вот бы всё зависит от того там что нужно закрыть в принципе нативные политики позволяют довольно гибко это всё сделать ноли нужны там какие-нибудь политики или ДНС Вот и без них никак то в принципе да можно использовать кастомные Но их можно использовать как бы и в совокупности то есть одно другому там не мешает вот е вопрос может какой-нибудь так есть ещ вопрос смотри если выбирать между наме ти Калика У тебя на4 есть фильтрация либо какой-нибудь сер см где ты по сервисно можешь выдавать Ну какой сервис какой анфи В какую сторону ты бы пошл и почему вот именно для разграничения трафика наверное лучше здесь подходит опять же меньше потребляет ресурсов работает многие лют из того что ки мно РСО поэтому как бы именно для этой проблемы я бы выбрал Синай Спасибо кажется что у нас вопросов больше нет Если у кого-то появится то можно будет их задать в кулуарах Да всё спасибо спасибо"
}