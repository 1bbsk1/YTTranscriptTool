{
  "video_id": "VSgAcpRTCdA",
  "channel": "DevOops_conf",
  "title": "Виталий Слободин — Антропоориентированный мониторинг инфраструктуры в GitLab",
  "views": 1137,
  "duration": 4462,
  "published": "2020-10-07T00:39:10-07:00",
  "text": "привет привет всем вам всем кто смотрит эту замечательную конференция посмотрел пару докладов было безумно интересно давайте мы теперь немножко переместимся на мой доклад и он называется антропо ориентированный мониторинг компании гид лад и прежде чем я перейду к самому докладу я хочу немножко рассказать о себе обо мне уже сказали ведущие о том что меня зовут детали слободян я работаю сеньор инженером в компании girl at я считаю себя фанатом чистого кода и верю в цитату стабильный production спокойный инженер но давайте сегодня поговорим про антропо ориентированный мониторинг что же она в себя это понятие включает и что же она значит начнем мы с первого слова с андропов ориентированного что же она значит если мы посмотрим толковый словарь русского языка мы найдём там слова антропоморфный она значит что это по форме устройство схожи с человеком или его телом или значения человекообразного а также основаны на таком сходстве от на таком подразумевается на сходстве с человеком и это история о том как мы а человечьего ли нашу систему мониторинга как мы добавляли человеческие качества в нашей системы мониторинга и давайте немножечко начнем и прежде я хочу сказать о том что было до всего этого до всего этого сценария это был 2017 год мы только только закончили переезд на prometheus у нас было всего 5 инженеров инфраструктуры у нас была настроена 24 правила для уведомлений у нас было 10 правил для записи для prometheus а у нас был всего лишь 21 dashboard графа не и около 2000 различных метрик и собирали мы всего 100000 часа плод секунду то есть на тот момент у нас продукт был среднего размера и вот такая вот система мониторинга было в принципе нам подходящий но мы уже живем 2017 году мы же живем 2020 году что же изменилось на текущий момент чтобы до что есть сейчас на данный на март 2020 года то есть к чему мы пришли после очеловечивания нашего системы мониторинга и так prometheus до сих пор с нами он никуда не делся наоборот мы его любим очень сильно и используем везде где только можно потому что это простое стабильное решение которое удовлетворяет нашим требованиям каждое окружении у нас теперь содержит свои собственные серверы про месяц то есть у нас есть пейджинг у нас есть продакшен и от каждое то окружение теперь реже свои собственные серверы про миссию сани какие-то общие у нас теперь отдел инфраструктуры в котором уже 40 инженеров работает но на текущий момент я не ошибаюсь еще больше где-то 50 человек у нас уже стало 280 провел для уведомлений у нас появилась 800 правил сбора данных для prometheus мы собираем около 80 тысяч различных метрик у нас стало 431 даже была игра фаны и мы теперь собираем 10 миллионов данных в секунду но как вы пришли к этому зачем мы вообще пришли к этому зачем нам допустим 431 dashboard графа не зачем нам все это зачем нам такой большой л инфраструктуры да действительно зачем и давайте я вам расскажу зачем и как мы к этому приходили итак начнем с того что система мониторинга которая была у нас 2017 году она была довольно простая но у неё была очень большая проблема которую предполагалось что мы можем решить при помощи cabernet оса но про губернатор моем складе вообще ничего не будет потому что мы не стали его даже использовать да и понятно дело что ничто не вечно кроме hp и поскольку наш продукт развивался очень быстро развивался очень стремительно какой-то момент мы начали понимать что нашей текущей системы мониторинга и нашей инфраструктуры уже недостаточно мы не справляемся с выросший нагрузкой мы не справляемся с высшим количеством инженеров например за 2019 год мы выросли с 300 человек до тысячи человек то есть теперь у нас в компании работает 1000 человек больше тысячи человек и понятное дело что когда у вас есть очень простая система мониторинга она не будет даже банально не справляться с наплывом ваших коллег и у нас была поставлена задача модернизировать нашу систему мониторинга но не просто модернизировать а улучшить ее кардинальным образом улучшить ее почти во всех аспектах и сделать таким образом чтобы мы ее считали еще одним инженером в нашей команде и я люблю цитату о том что оптимизация это постоянный процесс то есть невозможно начать что-то оптимизировать закончить и на этом успокоиться нет оптимизация это постоянный непрерывный процесс то есть вы постоянно можете что-то улучшать что-то совершенствовать и зачем зачем нам нужно было улучшать наши системы мониторинга во-первых это конечно же масштабирование приложение как горизонтально так и вертикально и потому что продукт развивается стремительно у него появляется очень много пользователей очень много дополнительных peach и все это нужно как-то дело масштабировать из за всем этим наблюдать и все это контролировать затем система мониторинга не должна мешать работе то есть она не должна ни каким образом отвлекать инженеров от того что они должны делать и она должна быть помощником то есть все наши сотрудники или сотрудники допустимо дело инфраструктуре должны знать что система мониторинга наш друг она нам помогает и до нее можно положиться как же мы пришли к этому и что в результате получилось первая проблема цель постоянно двигалась то есть цель постоянно перемещалась и менялась у нас была проблема того чтобы каждый инцидент имел новую причину то есть падал там допустим web-сервер это была одна причина на следующий день он мог опять упасть и это было еще новая причина и каждый раз она приходилось записывать о том что причина этого инцидента стало какая новые причины которое дает а вообще нигде не упоминалось и каждая диплом это же новые места отказом и все это прекрасно с вами знаем то есть когда отменяется код добавляются фичи удаляются фичи все это дело deep ловится меняется код и это привносит еще новые места отказов вашему приложению вашем продукте и инфраструктура тоже ведь меняется под кого она адаптируется под каждый диплом или вы ее адаптируйте под каждую диплом и когда меняется инфраструктура это тоже новые места отказа и вот такая вот плавающая цель я была довольно сложно поймать и каким-то образом настроить мониторим чтобы он следил за этим что если цель где-то меняется появляется новая причина появляется новое место отказа или появляется какой-то пробел инфраструктуре что система мониторинга могла это увидеть и могла это обнаружить и следующая проблема которая у нас была это было низкое качество уведомлений здесь на скриншоте изображён день до 2 февраля это когда у нас был очень сильный сбой в компании гель-лак и это скриншот из сервиса пейджер duty которые мы используем для уведомлений и мониторинга ошибок и вот даже если посмотреть на этот скриншот на именно эти ошибки они не говорят нам ничего по сути они просто говорят что что-то прошло не так то есть какая-то 400 ошибка на фронт индия и все и помимо того что у нас было низкое качество уведомлений уведомлений были еще и другие проблемы они постоянно срабатывали то есть вот это очень серьезная проблема о том что постоянно срабатывают алерта постоянно ними вспыхивают и если инженер будет отвлекаться на каждый alert то нам скоро в штате нужно будет просто вводить новую должен человека который следить за овертайме и кого-то там потом пинга если к их сложно было определить их критичность то есть даже если посмотреть на этот скриншот и на самую ошибку не совсем понятно а критичная она или нет вроде это на фронте вроде всего лишь 400 и непонятно важная она и неважно и а нужно посмотреть нее не нужно на него смотреть и это все приводило к тому что наши уведомления уставали то есть было просто доходило такое в абсурд а что инженера просто легче было кликнуть и так ночь ждите что-то я знаю про эту ошибку и просто пойти дальше лечь спать мы знаем про эту ошибку она у нас часто возникает ничего страшного это обычное дело все давайте мы кликнем как resort и можно идти дальше спать или дальше идти работать и какой-то момент можно подумать о давайте просто сделаем систему уведомлений на пользователях действительно кто не как к не пользователи первыми обнаруживают что у вашего продукта или у вашего приложения проблемы давайте просто сделаем систему уведомлений на них например будем следить за twitter когда кто-то спрашивает о гепарда у нее или нет потому что у меня появляется 503 ошибка можем просто использовать сообщение collects like даже когда ваши коллеги спрашивали у меня гид лап сегодня что-то тормозит а у нас на все нормально все хорошо можно смотреть twitter можно следить за инстаграмом кто будет постить фоточки о том что vitlab дауни конечно же это все шутка не воспринимайте это буквально не надо не нужно делать систему уведомлений на пользователях наоборот система мониторинга и или система в ваших уведомлений она должна быть проактивной то есть пользователи не должны знать что у вас что-то идет не так что у вас какая то ошибка и проблема-то в том что система уведомлений по крайней мере наша она не масштабировались вместе с бизнесом как я уже говорил то есть у нас рост пророк продукт очень быстро а система водолей не успевала масштабироваться вместе с тем то есть она где-то была позади постоянно и это добавляло трудности возникали проблемы которых я щас чуть дальше расскажу и помимо всего прочего мы вскрыли другие проблемы когда начали собирать данные о том а как там улучшить систему мониторинга какие у нас сейчас есть проблемы в ней в текущей как нам и и масштабировать как там сделать так чтобы все люди считали ее инженером у нас были устаревающие сигналы то есть те самые alert и которые никогда не срабатывали то есть у таких вы сигналов был такой такое пороговое значение установлено что они никогда не срабатывали а ведь этот сигнал этот лед он ведь мог быть критичным или они работали допустим на метриках которых уж и давно нет то есть где то что то поменяли метрика пропала и сигнал уже не сработает потому что никаких данных у него нет и конечно же огромное количество этих долго то самое слово которым сейчас пугают почти всех то есть у нас накопилось такое огромное количество этих долго и она продолжала накапливаться вода примеру те сигналы которые не срабатывает тем сигналы которые работали на метрика которых уже давно нет это всего превращалась тех долг или душах где-то обновить алес где-то нужно подправить чуть-чуть метрику и все это дело нужно за тепло и каким-то образом это все превращалось в тег долг который рано или поздно всегда нужно было решать иначе все мы знаем что происходит потом просто приходит этих долг и бьет вас мешком по голове и все и вы даже не можете ничего не делать и и была такая проблема даже банально то сломанной даже борды то есть во время инцидента приходим инженер лезет в графа ну смотрит на дашборд а данных нет и возникает вопрос а каким образом этот дашборд может помочь инженеров решение инцидента если у него вообще нет данных вдруг это действительно вот на этом дашборде можно было бы увидеть проблему и таких сломаны дашбордов у нас на самом деле было довольно много которые часть которых кстати получалось в результате тех долга и почему почему у нас появлялись сломанной даже борды во-первых менялись метрики и забывали просто обновить вы даже лорды в grafana то есть где то там смотри какая то поменялось а граф дашборд забыли обновить все это на 100 штук не работает потому что у него нет данных просто банально забыли обновить сам дашборд и это все потом просто обнаруживали время инцидента и это ни к чему не приводило наоборот все сдали году теперь мы знаем что у нас есть еще и сломай dashboard и вот будьте посмотреть на все это и неужели все плохо настолько неужели мы не можем развивать наш продукт разрабатывать таким образом чтобы все было хорошо и конечно же нет все на самом деле не так плохо но находится где-то вот по шаг позади развития основного продукта и что же можно сделать каким образом мы решали все эти наши проблемы до во-первых мы провели анализ и мы знаем наши проблемы мы знаем где они и мы знаем что нам нужно искать давайте структуре немножко и соберем проблемы на один слайд это метрики приложения и платформы то есть мы знаем что проблема у нас там у нас проблемы с сигналами и уведомлениями и у нас есть наши дашбордов граждане которые там сломаны не обновляются или еще что-то давайте вот пройдемся по порядочку и я расскажу вам как и что мы делали для того чтобы решить эти проблемы и к чему мы пришли и не забудьте про цели которые мы ставили в самом начале перед тем как мы решили масштабировать и добавлять человеческие качества нашу систему мониторинга первое она должна масштабироваться вместе с приложением как горизонтально так и вертикально система мониторинга не должна мешать работе то есть не должно быть таких вот быть постоянных абортов которые мешают ведь постоянного постоянно fire отца и система мониторинга должна быть помощником она должна быть еще один дополнительным инженером в команде и так давайте начнем с метрик есть очень классная книга от компании google до оссоры которая посвящена тому как делать мониторинг распределенных систем и они пишут свои книги о том что у них есть четыре золотых сигнала корпорации google это они меряют в тенте они меряют трафик они меряют количество ошибок в процентном соотношении и у них есть такое еще понятие насыщенность я чуть дальше сейчас подробнее об этом немножко расскажу мы взяли те же самые сигналы золотые сигналы компании google и просто адаптировали их под себя адаптировали под наш продукт и в результате у нас получилась система которая называется арес 1 метрика которую мы собираем и показывал это яндекс яндекс в процентном соотношении я тоже про каждую из них я чуть дальше потом подробнее расскажу это не изменит неизменная сигнал который был компании google это рпс количество запросов в секунду это количество ошибок опять же в процентном соотношении и яндекс насыщенности тоже опять процентном соотношении давайте начнем с otdyx а каким образом вообще читаете яндекс яндекс как он строится и как вообще нужно использовать там энди сандерс считается довольно просто то есть у нас есть три переменные в нашем уравнении которые мы используем для вычисления его это количество удовлетворенных запросов количество запросов кто находится в жёлтой зоне деленное на двоих мы все это делим на количество сэмплов которые мы собрали а как же это выглядит схематично она выглядит вот так у нас есть 2 порога и три значения 1 порог это так называемая зеленая зона то есть когда например запрос выполняется за нужное нам количество времени и его не превышает и если запрос находится в зеленой зоне то у пользователя все хорошо и мы рады следующий порог это талер рейтинг это желтая зона то есть когда запрос вроде бы выполнялся долго и может быть что то идет не так ну и соответственно конечно красная зона это когда запрос выполняется очень много очень долго по времени и пользователь расстраивается да и это все пони понятное дело показывает среднее значение за какой то определенный отрезок времени и чем прелесть индекса объект в том что пороговые значения могут быть разные мы ставим их самостоятельно они могут быть как для сервиса какого-то отдельно взятого так для какого-то and point а например у нас есть наш сервис детали который является сервисом для взаимодействия с гидом и у него мы ставим otdyx пороговое значение там несколько миллисекунд потому что это внутренний сервис он должен работать очень быстро а например если мы возьмем какой-нибудь on point например в приложении сама кто там пороговое значение для яндекса яндекс мы можем поставить немножечко повыше и каким образом можно улучшить качество уведомлений мы знаем что у нас низкое качество уведомлений вам нужно как-то кардинально их улучшить вот арес уже дает нам 4 главных сигнала четыре главные метрики которые мы можем использовать для мониторинга сервиса либо области нашего приложения или продукта и их можно разделить условно на две группы первые два сигнала это которые показывают это уведомление симптом бийск которые указывают нам на симптом и два других которые указывают на причину гаусс bass и какие же из них являются симптомами и что вообще подразумевается под симптом и причиной я сейчас расскажу итак первый это когда индекс яндекса ниже нашего порогового значения начиная с этого слоя и чуть дальше я буду показывать вам графики которые я взял за наш инцидент от 22 февраля то есть это все реально в конце на последнем шаге я предоставил вам ссылочку где вы можете залезть в наш даже было grafana и посмотреть дальше с этим можно быть упомянуть о том что все все наши даже горды графа да они следуют нашим нашему правил кредит и частности нашему transparency жилье и вы можете зайти на dash force тетки слаб dot com и посмотреть все наши dash города графина в режиме реального времени то есть как она все происходит итак это у нас график индекса otdyx у него можно увидеть два пороговых значений а это вот 90 процентов и 95 процентов от красной красными точками пунктирными линиями и мы знаем что когда допустим яндекс яндекс падает допустим ниже 90 процентов значит уже что-то плохо то есть что пользователи испытывают какую-то проблему например у них приложение долга открывается и это можно назвать симптом то есть мы знаем что если какое-то значение падает ниже это указывает на симптом на симптом того что у пользователя проблемы и например здесь мы можем задать индекс мы задали яндекс яндекс 1 в сервис а что если он значение находится ниже 99,9 процентов течение 5 минут там и фай remover то есть что-то у нас пошло не так и это является симптомом потому что мы знаем что если один из 99 процентов допустим там или 70 процентов запросов получается очень долго там свыше 10 секунд мы знаем что у пользователя уже есть проблемы это симптом а если мы возьмем например следующий сигнал это orbeez наш который опять же все тот же график за saints ident от 22 февраля зеленая зона здесь обозначено наша сигма то есть наше стандартное отклонение это здесь мы используем сигну как значение которое мы знаем которые мы вычисляем на каждый конкретный день на каждую конкретную неделю и мы знаем что если наш orbeez выходит за предел этой зеленой зоны то у нас уже то у пользователя могут быть проблемы то есть если рпс внезапно вырос допустим трафик это еще не значит что пользователя проблемы то есть это означает что у него могут быть проблемы и вот напустим на том рынке было видно что количество запросов было вне зоны тройного стандартного отклонения и это являлось причиной то есть количество запросов возросло по какой-то причине например какая то выбирая новость на hacker news или еще что-то и просто вырос трафик но это не значит что пользователи проблемы и следующий сигнал 3 это когда ошибок выше крыши то есть окончив все тот же самый инцидент от 22 февраля и здесь мы видим у нас есть наши пороговые значения которые находятся в пределах там 0 процентов то есть мы знаем что если наше значение внезапно превышает порог то наши ален срабатывает то есть мы знаем что количество ошибок внезапно выросла там на 70 до семидесяти процентов и значит что где где-то проблемы и вот мы знаем что количество ошибок выше нашего порога в течение 5 минут значит у нас где то есть проблемы и это опять же это является еще причиной потому что нужно под нужно понять что послужило причиной этих ошибок но если ошибок много они могут быть например ком так отдельно взятом маленьком сервисе или они могут быть незначительными не критичными и пользователь никак не ощутить на себе этого то есть это является причиной они симптомам и например график насыщенность и сатурн тоже самое когда он выше порога например когда он получается находится выше порога до графита сущностью что он вообще показывает он показывает насколько близко система к тому что у нее случится ботаник то есть что у нее сейчас случится затык и или что-то сейчас у где-то упадет то есть чем выше значение тем ближе системы к тому что что-то у нас может пойти не так и график насыщенности тоже опять же является причине он не отображает того значение что у пользователя сейчас проблемы он просто показывает насколько близки мы к тому что у пользователя начнутся симптомы того что они начнут введите ли испытывать ошибки или еще что-нибудь и вот у нас наша система арес дает нам два сигнала симптома это наш яндекс яндекс это наш рейд и они дают нам даст понять что у пользователя проблемы и это вот два главных сигнала к тому что инженеру нужно нужно будеть инженера или он должен просыпаться и он должен смотреть что-то пошло не так и где у нас проблема и у нас есть еще два сигнала причины это количество запросов в секунду и график насыщенности они показывают что у пользователя могут быть проблемы и что мы делать для вот подходы как мы улучшали наши over the наши сигналы у нас изначально была все довольно просто вот здесь у нас есть наш яндекс яндекс который мы строим для одного из компонентов вычисляем то есть и мы знаем что внуков заму oversight симптом что это симптомы устанавливаем пороговое значение 99,9 процента и указа что что если он упал и держится значение держится в течение 5 минут когда мы полирам а лед вот если смотреть на этот это описать описание over the сигнала вроде выглядите довольно просто то есть а если все просто то она должна просто работать но на самом деле есть проблема с которой мы столкнулись и даже не только мы индустрия сталкивается может быть проблема в этом и от проблем и конечно же не в этом проблема в том что метрики могут быть хитрые даст что это значит то есть когда мы начинали когда мы проводили анализ мы увидели что есть хитрые метрики на которые вот те наши простые alert и не срабатывают они не работают на них или работают как то очень странно наша команда сыр я выделила их три типа это дабл deeper луркер и flappy bird как они говорят что эти три названия являются стандартом промышленным стандартом поэтому они придумали самостоятельно я попытался их немножко перевести на русский язык что было понятнее о чем идет речь и сейчас я немножко расскажу чем проблема и так первое это дабл гипер или неуловимый джо на этом графике схематично изображена понятие это этого сигнала этой метрики этой ошибки то есть у нас есть наше пороговое значение и метрика наша она превышает пороговое значение но она например ошибка работает или срабатывать в течение трех-четырех минут но не 5 как мы прописали допустим в нашем провели три минуты она есть ошибка потом ее нет потом опять на 3 минут есть и потом опять ее нет то есть и она вот так вот по синусоиде постоянно идет и происходит такая ситуация что наша лед он просто не успевает срабатывает и вот вроде ошибка есть вроде пользователи пишут что у меня все сломалось инжинеры то у него все хорошо и 2 метра к которая тоже возникает на можно перевести как не до перепил она заключается в том что есть ошибка и мы поставили такое пороговое значение высокое что это ошибка рука количество этих ошибок например являются значение она просто не превышает от пара а вот постоянно находится ниже или чуть-чуть подходит к этого порогового значения и это на самом деле одна из самых опасных потому что про проблему можно даже вообще не знать что она есть потому что поставили слишком большое пороговое значение и вот эберт если вы думаете что это вот что-то про эту клыка горд игру то почти угадали это вот та ошибка которая похожа на первую на wp на неуловимого джо но она просто возникает периодичны то есть она вот возникает первый раз пять минут ошибка есть есть есть потом опять unit и потом они опять пять минут срабатывает и потом опять ее нет и что же нужно сделать как можно разрешить или что можно сделать чтобы побороть эти три хитрые метрики опять же корпорация google уже все придумала за нас уже все это описала они придумали описали такую штуку как давайте мы вместо сингал windows и фиксированного но это будем использовать множественные рок на и множество добавляет я не было тут вдаваться в подробности того как это что сделано я скажу что мы в компании дятлов взяли эту технику и активно ее у себя используем и она нам пока очень нравится если рассказать это очень коротенечко то с и в том что мы определяем множественные бинбин light и который мы закладывать наш бюджет на бочок и свои в том что мы знаем что если у нас допустим 1 builder рейд находится высоко высоко нас постоянно срабатывает и мы можем сделать предположение о том что если это даже так и дальше будет работать то наш бюджет будет израсходован уже за первую неделю а мы допустим поставили его на месяц и вот если вы хотите почитать подетальнее вот есть ссылочка по которой все что очень хорошо написана и можно почитать но мы переходим дальше система мониторинга она не должна мешать работе что мы вкладываем в это понятие и как мы это сделали у нас была проблема что мы смотрим на наши метрики мы смотрим на наши даже борды граф анны и проблема в том что если мы где-то что-то по вине ликуд и метрику надо было не забыть там ага ну надо же было графон и обновить и проблема в том что если мы не поменяли то где-то что-то маленькое значение мы поменяли во многих местах нужно было пойти все эти многие места которые от них зависят и поменять там тоже значение это и вот ты сидишь на это все это дело и смотришь вроде и метрики похоже на чуть-чуть отличаются одним значением вроде дашборд игра фаны тоже похожи друг на друга но отличаются чем-нибудь они вроде бы похоже то в то же время чуть-чуть разные вот как вот это вот чуть-чуть разное мы можем решить чтобы нам не нужно было инженером вспоминать ага мне нужно сейчас пойти туда и поменять там обновить даже дура графон и потому что я вот там от обновил культа метрику нужно это как-то автоматизировать скорее всего и придумали такую штуку который называется сасово выйти сингл сороса трав единый источник правды для всех наших сигналов и всех наших дашбордов граф анны то есть что это значит это значит то что мы решили давайте мы соберем все наши сигналы все наши источники этих сигналов данные для всегда на все наши данные даже вардов и всего все все просто в единое место пусть она будет в одном месте то есть мы всегда знаем что если нам нужно что-то посмотреть что-то проверить мы можем использовать этот сингл спрос соусов труб и каким образом можно собрать сигналы даже борды источники метрики наш выбор остановился то есть мы решили все это понятно дело описывать декларативно сучком мы все прекрасно знаем что у нас есть популярный способ для того чтобы быстренько быстренько что-то повторяющиеся повторяю делать повторяющийся результат производить его это конечно генерации мы поняли что мы а давайте мы просто возьмем сигналы даже городе все-все-все опишем на каком-нибудь языке и пусть это все дело авто генерируется и когда мы начали изучать мы нашли опять же решение от компании google называется джейсон нет это это над множество языка джейсон но как отдельный язык они как структура данных у него есть функции есть импорт и есть циклы и он там является функциональным и в чем его прелесть в том что уже любой 600 является валидным валидным исходником для чосон это и мы уже сам эти мы описываем что-то ну то что нам требуется которая потом превращается в наш же сончик и это джейсон это является функциональным языком для шаблонов то есть это тот же самый джейсон иными словами через сон с комментариями циклами функциями и импорта me давайте я чуть-чуть покажу почему мы выбрали его и чему нам оказался полезен во первых у него есть очень крутая вещь это импорт и и я не говорю что в других языках тоже нет но я говорю что нам она поправилась вот потому что есть импорт и то есть суть чем мы берем все наши метрики и засовываем их в одно место и прелесть в том что мы можем сделать даже стандартную библиотеку а мы ее сделали в которых уже содержится все наши метрики все частоиспользуемые функции все это мы описано как и мы все это можем потом переиспользовать мы же знаем да популярную цитату что хороший программист этой лиге вы программист потому что она будет автоматизировать все напиши 1 перри используя везде и вот импорт и позволяют нам это очень классно все сделать то есть мы что-то описали отдельно и потом просто импортируют и перри используя но прелесть джейсон это еще заключается в том что ребята из граф анны запилили свою штуку которая называется графон нет это генерация дашбордов граф анны при помощи джейсон это пока и выглядит это все вот так это опять же реальный пример из нашей кодовой базы где просто мы описываем на языке джейсон нет генерацию панели grafana допустим для нашего балансировщика х прокси и указываю там какие-то значения это тип и указываем стейдж и все остальное и это все потом от превращается до превращается вот в такую штуку она превращается в дашбордов она не совсем даже параграф она превращается в данные который мы потом можем через rest api grove on и отправить в rest api граф она и самая одна из самых клевых вещей это о том что 600 лет игра фонд предоставляет очень интересные вещи которые можно делать на них например что мы делаем мы добавили такую крутую возможность что с графика в графа не вот на какой-то определенной конкретный момент времени можно улететь кабану для просмотра логов которые мы там собирали то есть вот например это выглядит так то есть ему нас есть какой-то нашим поимке банды у нас есть какие-то столбцы которые мы там собираем и суть в том что все мы знаем полости всё ещё у них есть свой формат данных или язык райс и помогут толь толь только-только-только ластик его используют и мы написали специальную библиотеку по джейсон нет которая позволяет на генерировать запросы власти кассиршей отправлять сразу там инженеров икебану когда он кликает там на график да и вот как мы это дело потом используя вот мы добавляем вызов функции today the link и указываем ту самую наша функция которая потупив при помощи который пользователь точнее инженер улетает киба ну а вот так это выглядит реальной жизни то есть мы кликаем где-то на на точку и у нас уже есть два новых пункта меню которые позволяют сразу улететь наш наша система логирования власти каких-либо ну у нас есть посмотреть графики посмотреть логи и такое можно добавлять почти везде и мы придумали все это засунуть в единое место мы взяли джейсон нет мы взяли графон нет а что дальше мы же хотим сделать единый единое место правда то есть единое место и стены которого можно доверять и опять же уже все придумано за нас уже все готово уже все есть давайте просто возьмем тот же самый warhol который сейчас которому сейчас следую все наши инженеры мы же можно просто все это дело запихнуть в гид репозиторий пусть все наши метрики все наши потеют исходники джейсон это все все все будет находиться в git репозиторий мы туда еще при крутимся чтоб можно было тестировать эти метрики а потом и что прикрутим континиус deployment и получается очень прелестная вещь очень автоматизированная и крутая когда кто-то делает наши квест который где-то что-то меняет он попадает наш метр x каталог наш git репозиторий при помощи кисло psy ai это все выполняется и раскатывается сразу вот везде где только можно генерировать автоматически дашбордов графа но через rest api сразу генерируется правило наши для кроме философ генерируются даже наши дашборде встроены в бит лобби который правда еще на стадии весе у нас находится и все в том что мы еще туда можно прикрутить тесты то есть мы сразу можно проверить что нет реки будут сгенерированы они будут рабочие то есть у нас не будет проблем с тем что мы зайдем а там данных нет потому что мы до этого уже проверили наши медики или наши даже было отыграв анны и мы взяли этот git репозиторий и он называется metrics каталог что там находится что вообще мы тогда решили засунуть во-первых это все наши ключевые метрики которые мы описали на языке джейсон нет там же у нас есть соло для обозначения для каждого сервиса все это там у нас объявлена мы там же объявляем все межсервисные зависимости ли чего я потом покажу подробно там есть вы очень крутая вещь которую я постоянно смотрю даже когда она когда просто даже можно посмотреть и все у нас уже там есть и основании того что мы определяем дефайны в нашем каталоге мы можем генерировать что мы можем генерировать мы может генерировать все конфигурации prometheus мы можем генерировать дашбордов для граф анны и мы можем генерировать наши даже городом samom dele обе как это выглядит и минут на языке джейсона это у нас кусочек кусочек что у нас тут workhorse а наши вода для бак запросов что у нас тут есть во первых как я говорю вот у нас мы это делаем нашего села мы определяем пороговое значение для otdyx а мы определяем пороговое значение количество ошибок и бы говорим что 99 целых 9 99 сотых всех бед запросов должны выполнится успешно затем мы уже именно вызываем нашу функцию перри используем histogram а бликса который которая которая потом превратится допустим прикол frame assy и мы там указываем код наши пороговые значения там сочи стоит . мы потом делаем нашу вторую метрику рпс тоже тут же указываем и потом там дальше ещё есть наша третья мультика рейд и так далее и во что это потом вообще все превращается то есть код на предыдущем слайде он превращается вот в такую вещь это поправила для promise и вался и самая главная вещь если вы помните я говорил о том что какая у нас была проблема была проблема в том что вот если несколько правил для про милиуса но они чуть чуть отличаются или есть дашборд игра фаны но не чуть чуть чуть отличается и благодаря тому что мы все описали на языке джейсон нет мы все это дело можем автоматизировать настолько что как видно здесь мы можем сгенерировать сразу несколько чуть-чуть отличающихся правил нашем случае мы указали разные-разные window разные временные промежутки это наших правил пять минут 30 минут и 1 час и такие значения может быть много там неделя может быть что-то вообще из ряда вон выходящее на примерно месяц и мы можем генерировать наши даже борды в графа нею вот все наши даже борды теперь выглядят под примерно так они просто чуть-чуть отличается отличается значениями которые они показывают но все наши даже годы выглядят примерно вот так вы можете как я уже говорит зайти на дашбордов beetle ободком и посмотреть все это баллончик живую вот и у нас вот наверху вы можете видеть даже четыре главные метрики это otdyx количество ошибок рпс ее срываешь график насыщенности а ниже уже идут те же самые метрики но для каждого сервиса отдельно взятых допустим для пумы нашего веб-сервера и так далее но и но и на этом еще мы не остановились мы еще можем генерировать вот такие штучки тоже моих описан языке джейсон нет это у нас график для нашего сайдкика и наверху вы можете видеть что мы выводим дополнительную информацию например как я смотр максимальное количество выполнения там какой-то одной учебы и так далее и опять же мы и на этом еще не остановились потому что оказывается при помощи джейсон это ее графон нет можно делать куда более клевые вещи например вот такая штука это диаграмма из граф анны на который режиме реального времени отображается текущее состояние всех наших сервисах виде архитектуры архетип виде схемы архитектурной здесь можно увидеть у нас есть наш веб сервис у нас есть радиус у нас есть кэш redis а вы и так далее и она все это дело тоже описывается на языке же сам нет и рисуется при помощи норме джесс и вот это на самом деле такая система диаграмма очень очень крутая вещь и хотя он еще и очень наглядно и и возникает вопрос вот когда мы все это сделали то есть мы взяли и сделали кит репозитории куда положили все наши метрики который теперь там прикрученный сиай прикручивая continues дипломы который все автоматически болиде руется проверяется лениться и потом автоматически рассказывается можем ли мы вот такое решение называть еще одним инженером можно ли сказать что такая система мониторинга или по такой подход стал человечнее стал человечным или стал человеком инженером на самом деле к ней ответ конечно же нет нельзя потому что мы знаем что человеческий глаз и человеческий мозг пока еще пока по пока еще думают немного иначе в отличие от машины но за счет того что вы превратили наш мониторинг из непонятно чего вы что-то понятно для наших инженеров мы взяли убрали огромное количество ведь и которые никому не интересны мы видели четыре основные метрики которые показывают нашим инженерам что хорошо ли что-то идет или все плохо мы взяли допустим 2 медики которые длятся симптомами то есть мы знаем что если адрес обыскал упал все значит у пользователи проблемы нам нужно быстренько будет наши инженеры которые там например дети находятся и пусть он проверяет все это дело и смотрим чем проблема мы давали делаем фокус на симптомах то есть причина это хорошо но когда пользователь нет этого еще не видят а мы не можем сместить наш акцент мы вели наши метрики не не где то там разбросанные по котам разным репозиторием по каким-то сниппет там там или еще что то она все лежит у нас в виде на месте все в одном и если нам нужно что-то поменять что-то посмотреть что-то посчитать но сюда знаем куда идти и где искать он все находится в одном месте и берешь планируешь себе там на рабочую машину и смотришь и мы знаем что даже можно всегда будут одни и те же то есть у нас есть генерация даже воротов мы суть в том что у нас на дашборде можно зайти например у наш сервис для графа ну и поменять даже борды но проблема в том что если у вас там один очков команде который следит за даже борды он может это дело адаптировать под себя но как только у вас становится все больше и больше инженеров то являются проблемы что кто-то заходит меня и дашборд потом заходит второй человек меняет дашборд и потом когда инженер которая начинается с из альянса ходят такие даже борды на графа ну и смотришь что то вообще все как-то там стало по-другому все стало иначе и он ничего не может понять возникают проблемы а теперь даже если кто-то поменял дашборд все равно когда будет ножки квест наш каталог все даже городе вернуться к изначальному состоянию и у инженера который сейчас находится на на посту не будет потом проблем с устранением инцидента или поиском причин и и опять же оптимизация это постоянный процесс то есть нужно помнить это и не забывать о том что даже вот все что мы проделали это всего лишь только начало пути или середины пути и мы можем и мы будем идти дальше и нужно постоянно что-то менять что-то подкручивать чтобы потом все таки наша система мониторинга могла масштабировать вместе старших продуктом вместе с нашим бизнесом чтобы у нее потом не было проблем чтобы у инженеров потом не было с ней проблем чтобы они могли постоянной хорошо использовать хорошо находить смотреть и и изучать и чтобы ее всегда считали дополнительным инженером своей команде поэтому посмотрите на вашу систему мониторинга может быть вы уже знаете что там где-то нужно поменять и попробуйте просто попробуйте и посмотрите что получится спасибо спасибо виталий еще что-то давай да как раз как я говорил есть полезные ссылочки всего три штучки 1 как обычно у нас все открыто то есть весь этот metrics каталог наши один из очень про вы можете посмотреть у нас на гитхабе тот самый инцидент про который я говорил вам опять же можете перейти потом посылочки посмотреть то есть наш тоже была игра паны и третье само собою ссылочка на наши даже барда которую вы можете зайти и посмотреть что как бы там считаем спасибо спасибо vittoria интересный доклад и у нас есть вопросы давай их обсудим сергей интересный вопрос создается начала ты говоришь про dex про метрики которым вы настраиваете целевые показатели при этом не очень понятно как вы подбираете пороге вы их берете живого продакшена или с экспериментов и как вы поддерживаете их в актуальном состоянии да это очень хороший вопрос сожалению сейчас да мы используем такой смешанный метод то есть мы берем либо x продакшна даль и потом как берем значение оксана запускаем эта форме эксперимент и смотрим если все хорошо то мы оставляем это значения иначе мы уже подбираем другое значение да тут еще опять же вопрос оптимизации есть куда стремиться бывало такое что вы какую-то метрику настраивали настраивали там каждый релиз и она все никак не настраивалась то не работает тот слишком мало дает и конечно у нас были такие случаи и как раз таки вот прелесть того что у нас все наши метрики все наши исходники все что мы томится находится под контролем версии мы сюда можно даже поставить истории как что мы меняли зачем чтобы понять а вдруг на каком-то этапе ошиблись или еще что-нибудь но таких конечно случаи были а с другой стороны он бывают ошибки которые наверное не совсем ошибки но может быть ошибки сергей и несли до сергей тоже пишет про напишите те 400 на то есть файл не найден и прочее это пол будете например или нет нет это не повод потому что такие ошибки мы их вот как раз таки относим к причинам то есть 400 404 ошибка возникла потому что там файла нет причина есть есть пользователю может быть не очень хорошо чтобы файла нет но это же не повод что другие пользователи тоже испытывают ту же самую проблему поэтому да это та ошибка такая ошибка это не повод их будить инженера если у нас пропал главного гостинки club а как с этим бороться представляешь на основной странице пропала главная картинка у всех 4 на 4 ом и orijen ну зависит от того какая то метрикам и что не такая уж и важно на самом деле то есть опять тут пятак тут нужно срочно нужно смотреть и вот опять это вот подошли к тому вопросу о том когда я говорил о стало ли систем мониторинга человеком я ответил нет тут как раз таки и это есть прекрасный пример того что человек видит что нет логотипа и он видит это же главные страницы и то же лицо как это может быть не быть логотипа поэтому понятное дело дженнер который на посту он пойдет и начнет там разбираться в чем дело вот ты про up teks очень много говорил и там есть такая получается ловушка что по сути метрика учитывать только 2 и пир стиля но почти да то есть мы смотрим количество запросов которые ложились в одно время и во второе если у нас поменялось как-то характер распределения внутри то мы этого не видим если у вас появились какие-то большие выбросы то есть мы тоже не видим у вас не было проблем в этом плане это замечательный вопрос на самом деле да у нас есть эти небольшие проблемы что даже использовать вводят какие там техники пороговое значение все равно есть проблемы и мы над этим поработаем и пытаемся как-то это дело решить так ну хорошо допустим мы настроили облигационном что-то показывает здесь кофе вопрос вот были а лед и который никогда не срабатывали вы как-нибудь их обнаруживать элемент то есть как вы решаете поиск ни разу не сработали ртов вот вам подходе у нас тесты есть на это дело теперь то есть у нас есть прикручена наш собственный готовься к нашим репозитории в которой мы теперь еще и тестируем все это дело то есть мы все это дело теперь еще и можем протестировать но я думаю скорее всего могли быть ситуации когда даже такие тесты пропускали фальшивые alert и а можешь поподробнее рассказать про тестирования то есть вы там муллер уйти падение системы смотрите что лед возник и или как нет эмуляцию мы не делаем к сожалению сейчас это больше похоже на статический анализ конечно хотелось бы делать это прямо как поднимать кластер и смотреть и тестировать но это очень дорого и долго на что вы смотрите можешь пояснить у вас да ну самые банальные примерно до 90 мм топчик весь которую проверяю что допустим это метрикам действительно существует допустим когда мы генерируем даже было grafana мы проверяем что вот эта метрика у нас есть то есть как статический анализ кода это строим что-то встроенном джейсон нет или это вы поверх написали это к сожалению не тем что этот встроенным же со мной это уже поверх мы описали то есть если хочется посмотреть подробнее тут как обычно добро пожало депозитарий там все это есть можно посмотреть и паспорт ацидоза да и здесь никому не лекторе он интересуется а что делать если она все-таки там зак зашкалил то есть он оказался в красной зоне все беда что какие дальнейшие место а тут уже у нас как раз таки есть инженер который у нас напасть на посту который начинает выяснять смотреть что что происходит то есть он лезет пойдете со мной какие там ошибки были последние но обычно она может зайти поздно должен был граф анны там это у нас есть специальные так dash горка называется он сотрешь куда можно зайти и там посмотреть overview всей системы в том числе даже и последнее ошибки и уже понять в каком компоненте где что беда и когда уже известно беда и у нас есть опять же в том репозитории в ран books есть че кресты что инженер должен делать какой последовательности то есть есть чек-лист как-то по которому мы проходим и разрешаем те или иные ошибки правильно там не то что чек-листа как разрешать те или иные ошибки там checklist что делать если случился инцидент тот то есть когда адрес оскалил и понятное дело чтобы пользователи проблемы не знали все и спрашивает а хватает ли вам движков алерта в город с графами или стоит еще на что то посмотреть а мы мамы не используем let this go плана мы используем prometheus он и потому что она просто я как пробка и нам пока достаточно то есть того хватает им больше никаких вас проблем с этим не было ну и не скажу что проблем не было проблем есть всегда даже самого идеального решения но мы пока не рассматривали переезд на over the grove on и а можешь назвать что тебе больше всего не нравится летом какой какой функционал наиболее так сказать неприятием в работе да то что вы упираетесь если брать персональном не мне не нравится что граф она тормозит вот когда заходишь на страницу где много-много графиков она начинает жестко тормозить и это является проблемой потому что зайдет расследование инцидента тебя идет счет может идти то на секунды на минуты и а ты сидишь ты не можешь построить не страничку потому что тебя дико все тормозит отчасти мы решили это тем что начали разбивать большие графики граф анны на более мелких чтоб она хоть как-то нормально работала а если брать глобальными что не нравится не нравится что довольно даже несмотря на то что мы все это теперь ханин репозитории можете посмотреть и поменять все равно еще очень малое количество инженеров обычных не острое а просто от инженера разработчики они как-то не очень сильно хотят заходить и что-то там под себя корректировать ну потому что даже инженер мониторинга не можешь знать все досконально подробно про сервис какой-то специфично например и вот хотелось бы чтобы даже разработчики приходили и помогали ещё вопросы есть или нет я похож вернуться до владимир вопрос еще в продолжение в таких людей которые встраивают метрики ты говоришь люди не любят кастомизировать графа но даже борды и прочее но и пропадет а надо в конце концов ты настроишь потом мириться все настраивать пороге их настраивать специально обученный инженер который поддерживает или те разработчики которые пишут нет это ставит инженеры все-таки то есть он уже не даром и целый штат инфраструктуры которые он занимается тем что они ставят про обозначения но конечно вопрос консультации никто никогда не отменял допустим если есть какой-то специфической график допустим мы делаем там запрос в какой-то там сервис 3 стороны и инженеры про структуры не знает о том что некоторые запросы могут падать это является нормально потому что вам допустим dataset по терапии оно плохое и он поставить что и вот значение пороговая что если хотя бы один запрос упал все у нас полет давай то он просто может подойти к нужному стоит же встреча называется у нас эта команда разработки который отвечает за ту или иную часть продукта и спросить а будет уместным если я поставлю там пороговое значение в девяносто девять и девять процентов например ему скажу да да это будет хорошо и и он идет и поставить принципе разработчики сами герои от на поддержке своих решений или это специальная команда а это кстати очень интересный механизм да у нас есть практика что инженеры должны дежурить как это на самом деле очень интересные практике 1 практика да каждый ничего не ровности журит определенно time слот то есть там допустим раз в месяц он 4 часа сидит как инженер на пейджер юте то есть как инженер на посту это случай если что-то пойдет не так он будет доступен и в принципе туда записывают он опять же по желанию но достать или рекомендуют всех кто записок потому что писать код хорошо следить за ним продакшене никто не любит особо и 2 у нас есть очень интересная практика о том что любой инженер может стать как это тенью а сергей то есть он может посмотреть как то как инженерной инфраструктуры работает то есть в режиме тени и здесь как раз у сергея вопрос как вы новых инженера входите в команду то есть как вы учителю инвестировать или разбираться с ошибками у нас на это дело есть огромный handbook в котором у нас есть огромный раздел по мониторингу там куча всяких диаграмм инфраструктуры и все все все то есть понятное дело что датчик талмуд и сказать им вот сиди читай это одно дело и это на самом деле довольно скучно но обычно я знаю что я такая практика о том что просто этому инженеры как только же слова использовал режим тени включают вот но обычно доесть я бы тебе бы назвал все-таки что есть небольшая проблема у нас вот как по-русски называется ассимиляции новый инженер основа инфраструктуры потому что непонятно где что куда что смотреть но опять же тут у нас выручает вот тот самый наш сингл сорос авторов то есть если что то ты не знаешь что-то тебе нужно посмотреть идешь туда там есть огромный файл ридми куча всяких сынок куда что идти смотреть кому что писать и вот туда нужно лезть в первую очередь из чего-то не знаешь уже что то очень срочно узнать вы подобное мониторинг делайте на всех контурах то есть например тестирование нагрузочное тестирование она по таким же правилам проходит или там немножко другие про олега про нагрузочное тестирование к сожалению не скажу я не не осведомлен вот про тестирование я не знаю я помню совсем понял вопрос но смотри есть тестовый сервер наверняка или нет то есть каким рукава и значение допустим для другого окружения до если пороговое значение если там мониторинг или нет потому что зачастую есть такая история проблема или возражения что ну это тестовый сервер не мощность поменьше он и будет тормозить что вы жалуетесь да у нас есть то есть опять же можно зайти в ту же самую нашу графа ну и там у нас есть переключение нашего эдуар матэ перди это наш продакшн и есть еще из тучи это наша стоит zheng и мы тоже самое для дела и мониторе и понятное дело что там нет от такого огромного количества абортов как на основном продукте тут скорее всего накладывает отпечаток вот что мы диплом продукт раз в две недели ой два раза в неделю извините ошибся это не очень если что-то пойдет не так или какой-то метрика не очень правильно этого ее поправить и уже там но меньше чем киндера да да все так ну и плюс бы тот разработка же ведется при помощи fitch и флагов поэтому здорово а фича флаги в том числе для мониторинга для графа не нет я имею ввиду фичи флаги для разработки то есть потому что мы это к вопросу о том что наше тестовое окружение оно отличается от того что у нас есть на продакшене даже лаги мониторинга я понял и осмотреть ты еще упоминал про вас нам бизнес метрики как количество ошибок которые у вас были и ты не затронул тему операционной системы и ресурсы который внизу находится вы их мониторить и или вы говорите также мониторить и по-другому или вообще не моей карте мониторинг также то есть да у нас есть мы же самый турник операционной системой все остальное да пример самой банальной проверки таковым не центом что места на диске есть конечно тоже мониторить и сердюк что только он не получилось записать или там точнее пороговое значение то меньше допустим мы знаем что осталось на месте просто на свободного места мы получаем уведомление конечно мы все это за следим и мы даже следим за тем что как и все порядочные люди мы следим что если вышел какой-то новый свои проблемы с безопасностью то это тоже надо решать здорово а там объекты есть какие-нибудь да да то есть четыре основные медики мы используем везде и если зайти на даже два графа на то где то можно найти именно по моему какой-нибудь гитаре например выбрать даже uart который взаимодействие с жестким диском кто-то может или под подвес может посмотреть там есть будут индексы и для допустим жесткого диска здорово а вот смотри ты варишь 1 диска я так сейчас потому там будет лобби наверное столько дисков что пруд пруди вы получается каждую каждую метрику так дробите и если возможность потом их как-то группировать по машинам стойкам дата-центром как а как это вообще делается да конечно вполне логичное решение что как допустим когда у вас есть там 50 но то если вы будете показывать каждое надо отдельно то вы не получите общую картину и понятное дело что нужно такие данные агрегировать и поэтому у нас тоже есть графики игра фаны где отображены агрегированные данные то есть допустим состояние всех текущих not там допустим по загрузке циpкa то есть это та же все если можно можно посмотреть и есть агрегированные данные для других метрик приходилось исследовать такие ситуации когда метрика я не вышло еще за порог но вот подтормаживает до случае светлана такое частенько происходит потому что вот когда я шутил насчет того что используйте систему уведомлений на пользу я-то как это называется в каждой шутке есть доля правды и когда у нас коллеги в стэке пишу чтобы у нас тут что-то по-моему не работает то инженеры конечно обращают на это внимание потому что пока бедет это коллеги это еще является ошибкой смотри мы поговорили про бэкон часть но современном мире без браузера никуда их браузера зачастую код гораздо более долги по времени выполняется может подсказать как вы отслеживаете а признательность фронт с части он смысле у конечного пользователя у это больная тема потому что мы но не только начали новый как раз сейчас активно развиваем развиваемся в этом направлении в этом отношении потому что мы знаем что ну и все принципе знают что встречают по одежке уже все остальное и поэтому когда упадет долго загружается страница то это является проблемой и мы сейчас используем решение основанная на сайт спит которая позволяет нам оказывать тоже самый латинице с точки зрения пользователя с точки зрения user agent браузера то бишь и мы сейчас активно как это активно стараемся делать так чтобы наш frontend тоже грузился очень быстро например из недавнего мы прям если не ошибаюсь там чуть ли не двоих три раза ускорили допустим запуск запуск загрузку главной странице репозитория то есть прием что мы отображается как картинка информация репозитории и список файлов и прям очень сильно ускорили как раз таки за счет того что вы теперь следим за тем чтобы наш frontend тоже работал быстро но эта система мониторинга фронтэнда она еще я бы не сказал что она и я послал так что до дни еще очень много работать и мы будем над ней работать а я понял но вы наверное разработка как слабовидящих beetle ага да конечно там есть даже есть даже шутка о том что 70 процентов нашего всего сердцах наших радаров они только и делают что собирают ножки так направь если у вас что-то такое просочиться во front-end вы это увидите в первую очередь если говорить честно то нет потому что это тоже одна из больных тем к сожалению часто что-то просачивается и даже мы об этом не успеваем увидеть ок видят пользователи есть такое к сожалению бывает но такое означают что у нас проблема где-то с тестами то есть если мы нашли эту проблему давайте мы эту проблему устраним и потом покроем ее тестами что такой проблемы больше не было наверное одна из самых главных проблем у нас в частности как раз уж мы затронули front and am все остальное что у нас нет визуального регрессионного тестирования то есть у нас есть тестирование только intent и unit тесты на фронт энди от такого идеального идеального берега сиона тестер на фронте нди у нас еще пока к сожалению нет но я должна части рад но это уже тема для совсем другого разговора потому что на эту тему я могу очень долго рассказывать спасибо спасибо виталий за и интересный доклад из за подробные ответы на вопросы спасибо владимир мне почему то кажется что это был просто феерически огненный разговор . есть очень полезный для всех и я приглашаю всех слушателей проследовать за виталий владимиром в дискуссионную зону потому что обсчета мне кажется что есть еще о чем поговорить опять же вы можете продолжать задавать вопросы либо в чать либо уже в зуме ссылка на который сейчас должна появиться а мы продолжаем соответственно нашу мы даже уже завершаем сегодняшний день потихонечку мне честно говоря было очень интересно слышать про то большое количество документации которая была да наверное действительно уже рак переводить на наших спикеров зум я прощаюсь с вами господа спасибо вам ещё раз большое"
}