{
  "video_id": "xF__KxtbSIA",
  "channel": "DevOops_conf",
  "title": "Денис Золотарев — Приключения с Envoy: как построить свой Service Mesh и не наступить на грабли",
  "views": 361,
  "duration": 2829,
  "published": "2025-04-03T23:36:59-07:00",
  "text": "Здравствуйте дорогие друзья вы находитесь в 2024 году в городе санкт-петербург на конференции иго с нами замечательный ведущий разработчик команды инфраструктуры Яндекса Денис золотарёв Привет Денис Денис расскажет замечательный доклад по поводу того как можно из маленькой идеи сделать большую классную штуку уровня Яндекса верно всё так всё так начинался как маленький стартап точно и вы сможете собственно говоря повторить тоже самое У себя и сделать такую же классную штуку кто-нибудь использует супер значит Пришли по по делу Да вы готовы отлично поехали Спасибо Давайте начнём и поговорим о том как мы строим свой серс ш на какие грабли мы наступили Те кто уже в зале работал своем Возможно на них наступали но возможно я уберегу вас где-то от инцидентов продакшене о чём мы поговорим как уже много раз говорили вчера и сегодня на разных докладах прежде чем что-то делать Давайте разберёмся зачем мы хотим это делать Какие цели мы поставим Какие задачи Мы хотим решить поймём кака тура нам нужна для этого Какие возможности мы предоставим нашим пользователям Какие боли Мы у них закроем поговорим о том как интегрировать Наше новое решение в уже сложившуюся инфраструктуру такой большой компании как Яндекс ну и в конце как мы вообще это внедряем нашим клиентам и Что нас ждёт ещё впереди Давайте начинать наши цели и задачи прежде чем что-то решать что-то делать надо понять зачем мы это делаем Какие основные особенности есть если например вы дите сервис в каком-то Облаке в нашем случае во внутреннем облаке Яндекса в первую очередь это супер динамичная супер быстро меняющаяся среда пришла новая нагрузка вы запускаете новые поды вылетел диск или планка оперативки под исчез приехал экскаватор исчез дата-центр надо уметь Жизнь во всех этих ситуациях и быть к ними готовым чтобы не проливать трафик Ну либо как минимум минимизировать все эти потери при этом будет круто если мы всё это будем каким-то образом наблюдать на графиках рейсах логах чтобы в целом понимать что же происходит с нашими сервисами мы должны обеспечивать какую-то базовую надежность этих взаимодействия если у нас произошел таймаут возможно его надо потравить если нас начинают заливать трафиком и досить возможно часть трафика Надо убрать чтобы сервис не сложился при этом все эти взаимодействия должны быть безопасными есть чувствительные Данные есть платёжные данные сервисы взаимодействуют между собой они дож контролировать что ним приходят толь тето что данные нельзя украсть где-то посередине всё это мы хотим нашим клиентам предоставлять И что самое важное наверное то что сервисы Яндексе пишутся на разных языках программирования на разных фреймворка и одна альтернатива - это 10 раз написать 10 велосипедов для каждого языка для каждого фреймворка а другая альтернатива найть какое-то решение которое позволит ничего этого не делать и в целом позволить сервисам решать свои продуктовые задачи а об инфраструктурных задачах особо не задумываться Итак вот у нас есть такие задачи и мы попробуем сейчас как-то решить с помощью той системы которую мы пишем она называется кибол если кто-то в зале увлекается химией то вы знаете что молекула углерода с60 - это бакминстер фулерен и это вот собственно моделька этой молекулы она в виде такого вот шарика и это некоторая аллюзия на серию СШ где Каждый атом - это сервис а межатомное взаимодействие - это сетевой поход от одного сервиса к другому Кто хохочет освежить знания по химии есть ссылочка на Википедию А мы подумаем о том как строить архитектуру нашей системы чтобы решить наши задачи начнём с такого понятия которому я буду всегда обращаться это карта сети достаточно Просто у нас есть какой-то сервис например в КиноПоиске есть сервис А и мы для него напишем некоторую спецификацию для простоты у нас будет всего два поля в этой спецификации это окружение Вот это типа окружение прода этого сервиса и некоторое поле не так важно что это внутри но будем знать что это просто некоторые метаданные для нашего Discovery который позволяет из вот этого идентификатора получить список пар IP адресы порт куда мы можем уже отправлять Запроси помимо этого сервис а не работает Скорее всего в изоляции он взаимодействует с соседними сервисами например с сервисом б и мы явно декларативное напишем вот эту связь от сервиса А в сервисе б в секции taret нашей спецификации мы напишем что сервис а ходит в сервис что важно в сервисе гдето есть ровно такая же спецификация в которой указан сервиса B то есть данные для се Discovery Как нам сходить из сервиса А в сервиса B и на самом деле что здесь самое важное это знание в первую очередь нужно не сервису B ему не очень нужно знать какие у него IP адреса это знани нужно сервису А чтобы послать запрос в IP адрес сервиса б поэтому мы должны провести стрелочку назад от БК А чтобы собрать ВНО взаимодействие между двумя сервисами так дальше мы цепляем туда строим весь такой граф спецификации связи между ними и научимся от клиентов обратно на сервер на вызывающую сторону передавать нужную часть спецификации мы построим то что мы картой сети и называем как уложить эту карту в некоторую архитектуру и доставить её до наших пользователей Ну как в наши дни возьмём куне сделаем там crd положим туда нашу спецификацию это даёт достаточно быстрый Старт У нас есть I сервер ADM вебхуки cli библиотеки для контроллеров очень быстро можно писать код и достаточно удобно напишем наш Control Plane это его задача очень простая он знает все спецификации нашей crd в кубе и Может именно построить вот эту карту сети как все сервисы взаимодействуют друг с другом дальше запустим подик в нашем внутреннем облаке это вот наш большой ренже квадратик важно что сам подик куром не управляется подик управляется внутренним облаком и в нём запущен процесс какого-то сервиса а рядом с этим сервисом мы запускаем Да наш некоторый клиентский секар балансировщик который будет собственно отвечать за все наши сетевые взаимодействия и нам нужно как-то этот сконфигурировать поэтому мы запускаем ещё один процесс нашего сервиса bub это маленький Demon Buck B D который делает немного важных вещей во-первых он взаимодействует с самим Корол пном и получает оттуда тот кусочек карты сети который необходим для работы сервиса А ну и параллельно он ещё взаимодействует как раз-таки с нашим serv Discovery чтобы зачитывать оттуда IP адреса порты по тем метаданным которые есть спецификации далее ивой конфигурирован таким образом чтобы запрашивать у bbd конфигурацию по протоколу xds Это grpc протокол который реализован вво мы реализуем его на своей стороне и отдаём вво всю необходимую конфигурацию все необходимые знания о том как можно обрабатывать запросы предназначенные сервису А и также как можно обрабатывать запросы которые сервис А пытается отправить в каких-то своих соседей с которы Кому надо взаимодействовать если мы картинку укрупнительная которые запущены рядом в том же контейнере что и они А уже ивой взаимодействуют между собой и вот именно на связи й ивой мы должны решать все те наши задачи которые собственно Мы перед собой поставили Ну и у нас есть вот эта архитектура конфигурации в виде демонов баки бола которые запущены в подах и в видя нашего Контрол плейна который отвечает непосредственно за карту сети попробуем понять как в такой архитектуре можно решать наши основные задачи Ну и Первое - это именно балансировка трафика Мы говорили о том что нам надо понимать На какие поды мы можем отправлять запросы вот у нас есть сервис А у него есть подик А1 и три пода сервиса б нам надо понять на какие поды сервиса B мы можем запрос отправить в этом нам помогут в первую очередь проверки здоровья хески НВО и мы в баки боле поддерживаем два варианта во-первых это активные хлс чеки Вы можете просто раз в 10-15 или в одну секунду отправлять запросы пин если мым ответили понг то всё хорошо под Здоров туда Запроси можно отправлять Если он отвечает пятисотка значит скорее всего ему плохо или Он вообще может не ответить тогда лучше конечно его вывез из под балансировки пока он не почини мы это проверим просто на следующей итерации наших проверок но у этого есть недостаток потому что это периодически и если вы раз Пингу то вот на п секундах вы не знаете на самом деле сломалась Та сторона или не сломалась поэтому есть вторая сущность это пассивные проверки или они также называются часто алами это статистическая проверка если в какой-то момент запрос с определённого пода начали тисо таймаут и он поток этих ошибок пересёк некоторую границу то вы просто выкидывает под из-под балансировки опять же дате ему время восстановиться и потом аккуратненько проверяете ли он Можно ли туда возвращать трафик это поведение которое часто называют себ и в целом такой паттерн который реализуется во многих разных фреймворка библиотеках Вот они могут работать вместе потому что часть часть сценариев удобнее решать активными проверками например Это шада при репях Ну а часть хорошо защищают пассивными проверками например Это внезапные пятки обрыв связи обрыв оптоволоконного кабеля и так далее другой нюанс Вы можете ошибиться в конфигурации наме сде активную проверку с ручкой Pink а такой ручки у сервиса нет Все поды отвечают 404 и вы просто не понимаете живы олени не жет они все не живы вы не понимаете куда надо отправлять трафик хотя на самом деле все они трафик принимать Могут просто не могут вам сказать об этом Ну либо Например у сервиса сломалась база данных и у него все поды опять же начинают пятисот пробивают настроенные пороги и с точки зрения вызывающей стороны все поды красненькие хотя на самом деле проблема не в сервисе А где-то дальше и возможно часть функционала всё ещё работает и Вы можете обслуживать пользователей на этот случай вво есть предохранитель который называется Пак Mode который игнорирует статус здоровья хостов в кластере если количество нездоровых подов превышает некоторый порог умолчанию это 50% если половина подов вашем кластере вылетело то считает что либо Вы ошиблись в конфигурации либо что-то произошло что он никак не может починить и он пытается по умолчанию просто восстановить вашу систему дать возможность хоть как-то обслуживать запросы и просто разлива трафик на все поды в надежде что что-то хорошее случится и эти запросы будут обработаны это поведение можно менять поча может распределять трафик либо между всеми узлами и это вот скорее предохранитель от микон в вашей системе либо он может наоборот закрыть трафик и никуда его не отправлять это вот поведение которое больше всего похоже на сет брейкеры это то что даёт возможность сервису B восстановиться подчиниться после этого начать обслуживать клиентов дальше к сожалению второй сценарий работает не всегда и не везде потом по Q можно найти ссылочки на гитхабе там возможность закрыть трафик в случае включения паник мода работает лишь для определённых сценариев балансировки много раз разработчиков НВО и мы и коллеги Наши в орсе спрашивали почему же так и как бы сделать так чтобы это работало везде но к сожалению пока Ответа нет другой вариант смотрим вот такую ситуацию у нас есть три пода B все эти поды мы отдали в конфигурации все эти поды что важно прошли проверку здоровья и и мы начинаем направлять туда трафик Всё хорошо всё работает в какой-то момент мы хотим убрать трафик с пода B2 Ну для какой-то наших экспериментов может быть мы его хотим обновить не знаю что сделать Ну логично просто поменять конфигурацию в ивой сказать что теперь у нас только два под B1 B3 и ожидать что запросы с B2 тоже уйдут поднимите пожалуйста руку Кто считает что это вот так сработает все относятся с подозрением Это хорошо мы поверили что так сработал на самом деле так не работает трафик всё равно идёт не очевидная картина кажется что конфигурация обновлена пода В списках нет трафик идёт Почему Потому что считает что это ошибка на нашей стороне что на самом деле под существует под зелёный мы не будем убирать его из-под балансировки Это скорее всего сломался либо серс Discovery Либо сервис который доставляет конфиги для НВО Возможно это отключить есть специальный параметр которые позволяют собственно игнорировать здоровье узла при выводе его из кластера Ну мы у себя в итоге это включили и теперь можем управлять списком подов уже снаружи из нашей конфигурации предусмотрев все необходимые дополнительные проверки как например эту поломку се Discovery просто уже на нашей стороне конфигурационного сервиса помимо того что мы должны думать о здоровье подов Наверняка есть другие критерии как мы выбираем куда трафик отправлять для нас ответ был достаточно простой это географическое расположение пода в случае Яндекса это дата-центры в первом случае мы можем приоритетно отправлять запросы в том же дата-центре в котором находится под который собственно запрос совершает это уменьшает количество Крос DC трафика Это улучшает тайминги Это улучшает а нагрузку на сеть между DC просто меньше запросов туда ходит но при этом если в нашем дата центре какие-то проблемы если не хватает мощности поды B2 например вылетел и он там обновляется в ходе релиза мы просто прозрачно вводим нагрузку в другие локации в поды B1 B3 они просто имеют меньши приоритет чем B2 А когда B2 становится с точки зрения проверок здоровья о которых мы говорили то мы вернём нагрузку и опять будем работать непосредственно внутри одной локации в целом есть альтернатива можно не использовать знания о локации и просто разливать трафик по всем локациям Возможно с какими-то Весами возможно просто раунд Робином по всем подам которые есть для этого есть свои сценарии и третий вариант Самый наверное редкий самый сложный это когда вы работаете только непосредственно в одной локации вы в принципе не делаете Cross DC запросы А есть сервис для которых это критично и с точки зрения latency есть сервисы для которых это критично просто по их инфраструктуре когда они рассчитаны что в каждом д центре у вас развёрнуто отдельная полностью независимая копия этого сервиса они соответственно Крос DC запросы никогда не делают зонная балансировка по нашему опыту подходит практически для всех клиентских приложений Это самый оптимальный вариант Когда вы делаете максимум усилий для того чтобы сохранить трафик локальный но в случае проблем просто вводит его в ossd обычный размазанный Робин чаще всего по нашему опыту подходит для всяких джебов по крону или прочем Почему которые почему-то хотят выкачивать по http grpc очень много данных это отдельный вопрос Почему они так делают но такое бывает и если вы используете зон ную балансировку то эта А задача запущенная по крону просто вам где-то в 2:00 ночи примерно в одном дата-центре создаёт пик нагрузки и от этого просыпаются сырье А если не просыпаются ночью они потом очень недовольны вот если мы размажет в этом случае нагрузку по всем в целом для дба Это не так важно что там будет повышен и так далее то мы спокойно просто переживём она поработает и закончит свою работу ну и соответственно балансировка только внутри локального дата центра Это вот приложение с очень низкими сла на время ответа либо у которых такая вот супер локальная архитектура Окей мы поняли как трафик балансировать мы понимаем Как настроить проки здоровье как учитывать наш локацию хочется видеть это на каких-то графиках Мы все знаем что это метрики это ВС что составляет на попробуем ВС это поддержать и дать нашим клиентам начнём сри всё очень просто специальная ручка stats где можно попросить метрики в формате проте и построить красивые графики пса ошибок таймингов каких-то системных метрия всё работает всё красиво важный момент мы видим что мы явно указываем формат что намекает на то что внутри на самом деле не хранит в формате в прое а форми момент запроса если попросить просто статься то вот тут есть какой-то списочек метрик по-моему Это счётчик пяти соток внутри нашего кластера в целом видно что есть простой паттерн все метрики внутри НВО хранятся в формате кластер точка имя кластера точка имя метрики и дальше он налету этот формат парсит выделяет оттуда имя кластера имя метрики трансформирует это в имя сенсора и л кластера и отдаёт вам в формате прометеус всё было бы хорошо кроме того что если у вас вы кластера есть точка Всё разваливается потому что уже сколько-то лет в Иво висит бак что если в мини кластере стоит точка Они парся эту строчку неправильно и часть имини кластера на самом деле прилипает у вас к имини метрике вы не можете потом построить ни один стандартный алер потому что метрики в документации написаны одни А вы видите какую-то вообще абсолютно бессмысленную штуку к счастью можно обойти напишем простой метод который меняет все точки на нижнее подчёркивание и будем в конфигурации Иво передавать вот этот Save CL специальное поле alst name кластера соответственно именно вот этот alst name будет использоваться вво для отдачи в мерик И после этого у нас всё работает мы можем строить графики и не бояться что внезапно просто потеряем метрики и алерты потому что й не смог правильно сформировать нам метку имени кластера идём дальше у нас есть логи ну здесь всё очень просто вот это интерфейс который предоставляет наше внутреннее облако мы можем отправлять гиф можем просто отливать их если инфраструктура вашего облак поддерживает съём логов Соу можно писать файл и хранить прямо на подике это наверное самое надёжное Если всё остальное сломалось всегда можно зайти на пот и почитать Там просто грепан Файлик всё работает всё отлично Аналогично с рейсами пример нашего Трей во внутреннем инструменте мониторинга отправляем и трейс в формате Open telemetry всё прекрасно работает openet поддержали в одном из последних релизов эя по-моему Это был 1.3 или 129 если мне память не изменяет но есть нюанс они там забыли пробросить влоги с ID из рейсов и поэтому Если вы хотите использовать фишку о Когда в каждой строчке Лога У вас есть TR ID и span ID и вы можете по ним перейти в трейсинг и посмотреть соответствующий трейс и ваш коллектор жёстко требует чтобы был ID span ID то в этой версии вы к сожалению получите ошибку они починили это по-моему в 131 и соответственно Если вы хоте включать то вам надо обновляться всегда на последнюю версию они постоянно чинят много интересных багов И тем самым как будто вы просто стимулируют нас постоянно постоянно обновлять версии Потому что постоянно что-то иногда не работает отлично мы балансируя трафик мы уже видим как он работает мы видим ошибки мы видим нагрузки попробуем понять что мы можем сконфигурировать чтобы опять же возвращаясь к началу решить наши задачи ну самое простое Давайте настроим тайма есть таты которые называются Time и наверно самые простые таймаут которы мы все привыкли например Это просто таймаут на запрос от момента инициализации до момента когда вы прочитали весь ответ очень простой Тау А есть Вторые таймаут это Stream timeouts которые нужны для разных grpc стримов Когда у вас есть один Стрим в нём уходит кучу кучу запросив и там есть например Timeout Max Stream duration то есть обычный та та один запрос stream duration на целый Стрим и Здесь начинается конфликт между этими таймаута которые до сих пор не разрешили в какой-то момент обычный Тайт игнорировали если у вас стоял Stream duration потом решили что это неправильно поменяли всю эту логику наоборот и теперь Тайт у него приоритет выше чем у таймаута Stream duration а потом короче они вообще запутались и теперь не знают как правильно на гитхабе висит кучу открытых ию что же приоритет не обычный таймаут или таймаут на Стрим время от времени меняется видимо может быть разработчик который отвечает за это и постояно меняется ше поэтому Когда вы ещё версию обновляется вы проверьте что ребята не передумали наоборот и теперь не другие тайм-ауты будут приоритетнее вашей конфигурации Мы у себя просто стараемся пользователей немножко предостерегать мы явно знаем http или jpc взаимодействие у сервиса настроено Поэтому в случае http мы просто вырубаем все стримов тайм-ауты говорим о том что ребят лучше Вам их не настраивать А вот если вы уже включаете grpc то Будьте аккуратны и понимайте что происходит с вашими сервисами rety Трай та штука которую мы все хотим настраивать потому что это кажется что это средство которое поможет нам сделать наш сервис более надёжным и устойчивым но при этом я наверное не знаю ни одного сервиса который Хоть раз бы не сложился от шторма Трай поэтому вопрос нужны Лени для надёжности он пока ещё для меня открытый Но что важно настраивать в важно понимать Какие запросы Вы травите если запрос ваш пишет например в базу пишет в каку или ещё куда-то то возможно вы не захотите орать либо вам надо явно размечается мы по умолчанию ретра только один патентный httpget либо те запросы которые пользователь явно разметили специальным заголовком надо понимать что мы ретра можно трать пяти сотки из Чер сох кодов кажется трать практически нет смысла Иво по умолчанию например ретрай только 429 потому что это может быть ответ именно от перегруженной НВО который можно потрать но если му ответили 4 404 делать смысл трая просто нет Ну и понятно самое важное надо настраивать бюджет трав количество ретра процент запросов который вы трате Потому что если вы это не настроили и например Вы трате весь поток вы увеличиваете просто на одном отрезке вот нашего графа взаимодействия от сервиса а к сервису б можете увеличить нагрузку в два раза если за сервисом стоит сервис она увеличится ещё в два раза Ну и в какой-то момент Однажды я видел как нагрузка увеличилась в 10 раз после чего сервис у дальше им понятно Ещё есть безопасность хочется чтобы все данные ходили по зашифрованного каналу особенно если как раз-таки это у нас рос DC запросы где мы не контролируем а сетевые условия через которые идут наши данные и хочется включать TS не хочется тащить эти в сервисы но благо inice умеет и в TS originating и в TS termination поэтому мы между эвоян ий TS канал но при этом сами сервисы никак про это не знают им не надо знать про сертификаты им не надо конфигурировать свои внутренние веб-сервера они также работают по http и grpc мы скрываем от них всю эту магию novoy прекрасно справляется с тлм с тлм там есть достаточно богатые возможности настройки чего мы не нашли Чего нам пришлось закрутить на нашей стороне это во-первых автоматическое обновление сертификатов мы сами следим наше облако умеет следить за сертификатами перевыпускать их и мы дальше следим за этими сертификатами и Как только они обновляются мы пинаем ивой чтобы он тоже эти сертификаты у себя обновил и почему-то мы не нашли в Иво такой важный На мой взгляд метрики как метрики устаревания сертификатов сколько же дней осталось до того момента когда сертификат который загружен Навой протухнет и станет не актуальным поэтому эту метрику Мы тоже собираем на нашей стороне и следим за тем что автоматика нигде не сломалась и все наши поды вовремя получают новые сертификаты вовремя отдают их в ивой и всегда готовы к тому что предыдущий сертификат будет выведен из эксплуатации О'кей есть какие-то базовые настройки конфигурации которые у нас закрывают возможности настройки надёжности настройки безопасности настройки каких-то базовых вещей для балансировки понятно что сам ивой предоставляют куда больше возможностей какие-то из них нужны какие-то из них возможно ненужные и даже опасные здесь надо смотреть от того что именно Вы хотите решить А мы поговорим немножко о другом это интеграция со смежными сервисами которые уже есть в компании и которые вы не можете заменить Вы должны их использовать потому что все ваши пользователи уже привыкли просто их использовать И вам тоже надо их поддерживать пример это rps limiter Это достаточно простая идея в Яндексе есть внешний сервис который может на каждый запрос по каким-то специальным правилам они могут быть очень сложно настроенными сложносочинёнными сказать можно этот запрос обрабатывать то есть вернуть 200 или запрос превысил квоту и соответственно мы возвращаем 429 эти запросы не обрабатывают решаются этим разные сценарии это просто защита от де Досов это защиты Возможно не только нас но и каких-то наших внешних партнёров которые не готовы к высокой нагрузке это возможно Какие лимиты по разным корзинка пользователей это всё настраивается на стране ПС литера Мы в целом про это ничего не знаем но должны с этим интегрироваться понятно что сам ничего не знает про rps тер который написали внутри Яндекса единственная его интеграция с коробки по-моему это лимитер который предоставляется в качестве сервиса в Google клауде Поэтому нам надо эту интеграцию сделать самим к счастью у нас есть классный ответ Это плагины которые можно написать на мы просто берём и на каждый запрос просим у нашего внешнего rps лимите квоту Скажи пожалуйста можно этот запрос обрабатывать или нет И если rps лимитер ответил 429 мы возвращаем этот код ошибки нашему клиенту потом он его может кстати потрать или нет в зависимости от его конфигурации как мы говорили но мы дальше этот запрос у себя не обрабатываем если заглянуть как внутри мы получаем квоту то всё очень просто мы трансформируем пришедший запрос в некоторый наш внутренний формат мы используем для этого cgi параметры запроса заголовки ки тело запрос мы не используем при квотировании отправляем это в rps limit и собственно получаем от них ответ что здесь важно отметить Если вы будете делать какие-то подобные штуки на своей стороне это вот две строчки которые сейчас выделены на экране первое что мы делаем специальный вызов метода http Call это то что написано красными жирными буквами документации оп документации НВО то что вы в ваших скриптах не должны делать никакие блокирующие операции потому что все фильтры все обработка http запросов выполняются в отдельных синхронных рутина и если вы там заблокируется то у вас просто начнёт деградировать производительность поэтому всегда надо отдавать это но сторону самого НВО который умеет аккуратно обрабатывать те Запроси которые Вы хотите сделать из фильтра А второе что важно здесь есть rps limit CL name мы до этого уже говорили что у нас есть кластера с именами с сетами и прочими и это очень удобно что на самом деле это ровно точно такой же сервис ровно точно такой же кластер который мог бы сконфигурировать пользователь Но просто в этом случае мы делаем это за него мы сами знаем по инсет rps лимите мы са вами знаем те параметры запросов которые мы должны туда делать поэтому мы полностью переиспользовать просто для клиентского описанного запроса от одного сервиса к другом и делаем то же самое только внутри для специального сервиса rps литера и это даёт нам все возможности того что например мы можем построить метрики этих запросов ровно тем же механизмом как мы строим любые другие метрики по запросам нашего сервиса Аналогично все настройки твитов тай все возможности которые у нас есть мы можем применять и для наших внутренних интеграций дальше мы всё ещё помним что у нас есть требования безопасности и у нас есть в Яндексе система межсервисный аутентификации она называется TM ticket vending машин заключается в том что когда сервисы есть между собой они должны передать два специальных заголовка севи ticket и User ticket Ну соответственно Понятно серс ticket отвечает за то что этот запрос действительно пришёл от сервиса а для сервиса Б User ticket внутри себя содержит информацию о том какой запрос какой пользователь инициировал запрос в сервисе а опять же это решение для которого есть там библиотеки под разные клиенты но неудобно тащить это во все сервисы У нас есть хорошее решение давайте это сделаем на уровне эво й на сервис а тикеты будет выписывать й на сервисе б эти тикеты проверять и отдавать их уже в сервис б раскрытую информацию чтобы Какой это был пользователь Какой это был сервис потому что между м и сервисом взаимодей дест происходит внутри контейнера и оно в целом безопасно там эту информацию можно передавать в открытом видео И тем самым мы опять же снимаем всю боль интеграции с ТВМ непосредственно с разработчиков сервиса и уносим это на нашу сторону кому интересно про ТВМ класс и до класс достаточно старого Яка но всё ещё актуальный от авторов собственно всей этой системы можно почитать посмотреть кому интересно а внешние сервисы как бы мы не хотели чтобы наш сервис Smash захватил весь Яндекс эта цель на нени какое-то продолжительное время и всегда есть сервисы которые пока внутри мишани живут и мы можем обращаться к ним по обычному доменному имени вот какой-то blackbox Yandex steam.ru сервис который за своим ДНС именем скрывает какую-то свою инфраструктуру мы там К сожалению ничего не знаем там пока не стоит кибол Можем ли мы использовать ивой для этих возможностей и что нам это даст кажется ответ что можем и кажется что может дать всё ещё очень многое как мы будем использовать расширим наше описание спецификации добавим Да возможность указывать в целях в тех сервисах куда мы ходим не только соседние узлы нашего меша но и просто какой-то произвольный хост порт и потом с конфигурируется имеет тип strict DNS и вот там собственно вот две строчки которые выделены внизу просто укажем там напрямую эти Host и пор классно работает нужно и удобно кажется что да это возвращает нас к тому вопросу что опять же на вызывающей стороне мы можем переиспользовать всю нашу инфраструктуру Вот здесь мы например мы видим параметр tvm Check Input tickets то есть мы всё ещё на N можем выписывать тикеты которые нам надо отправить непосредственно в этот сервис Даже несмотря на то что он с той стороны он как-то сам разбирается как эти тикеты проверять можем также снимать все те же метрики логи трейс опять же снимаем всё это с боле с нашего сервиса мы делаем Это всё за них и вот например сервис получает график пса С каким он ходит в blackbox Хотя с той стороны вот просто какой-то Black B и мы на самом деле не знаем что это такое Итак мы поняли как мы можем строиться в нашу инфраструктуру внутри компании э настало наверное время уже идти клиентам понятно что вы сначала поднимали какие-то mvp всё это начиналось вообще с одного маленького сервиса который просто была нужна jpc балансировка другого решения в Яндексе на тот момент не было но теперь мы хотим захватывать всю компанию захватывать крупные сервисы как это можно сделать А мы пошли По пути infrastructure CDE уже до того как мы начали активное внедрение ша infrastructure стал расползаться По всему Яндекс у нас появились многочисленные ял файлы в которых мы описали инфраструктуру наших сервисов поэтому самое простое что мы могли сделать это возможность Дописать туда вот ещё 22 строчки Яла для того чтобы сервис стал частью нашего сервис Миша он описывает там какие-то базовые параметры порты настройки проверок здоровья может описать тай и всё прочее примерки которые я приводил до этого может указать вот в секции она называется здесь consumes на девятнадцатой строке описать те сервисы м в которые он хочет совершать запросы Ну и дальше всё остальное мы сделаем под капотом мы привезём нужные Клод мы поднимем процессы Мы настроим мы создадим все объекты в кубе чтобы эта конфигурация срослась и дальше пользователь может просто использовать инфраструктуру совершать запросы всё остальное с одной стороны за него настроено с другой стороны лежит непосредственно в коде почему это круто Потому что если у вас есть Например базовый шаблон ваших микросервисов как например Сделано в каких-то серс Яндекса когда один шаблон на самом деле является базовым для сотен микросервисов вы добавляете туда вот эти строчки и оно раскатывается сразу везде вам не надо ходить бегать по разным сервисам вам не надо проверять какой сервис вы пропустили А какой сервис Вы забыли у вас просто гарантированно везде раскат меш гарантированно поднимутся эти процессы и всё что вам нужно это пом начать просто использовать вы следуете общим принципам и для кода и для инфраструктуры внутри одного порек вы пишете код на Джаве плюсах питоне Go так далее который совершает запросы который обрабатывает ответы и сразу же в этом квесте Вы можете написать тот кусочек инфраструктуры который собственно обеспечивает вам возможность этот запрос совершить Вы можете это проверять на ревю и как человеческими глазами Вы можете это проверять какими-то тестами которые проверят что такой запрос вообще Например можно совершать или по каким-то например архитектурным принципам из этого сервиса в этот сервис там лучше не ходить варианты могут быть разные но поскольку у нас есть вот это непосредственно декларативное описание которое мы выражаем намерение ходить из одного сервиса в другой сервис совершается htpc запросы то мы вот и получаем те возможности для анализа которые Дальше можно нять на самые разные сценарии ну самое простое что можно с этим сделать что придёт наверно в голову каждому И что в голову пришло нам это нарисовать какую-то карту как сервисы взаимодействуют между собой это вот был первый вариант самый яркий слайд моей презентации потому что мы не осилили сделать тёмную тему и он был такой корвей но это вот очень крупно заумные изображение Потому что если бы мы его я уменьшил вы увидели бы такой спутанный клубок в котором ничего не понятно потому что сервисов много стрелочек тоже очень много но тем не мене Если красиво пофиксили это вот уже второй подход и тут есть Тёмная Тема и есть видно текущий сервис сервисы которые в него ходят сервисы в которые он ходит можно смотреть как устроена система Как устроена её архитектуры дать какую-то дополнительную Мета информацию в виде ссылок в виде каких-то светофоров и прочее чтобы можно было взглянув на одну схему в целом понять что происходит с сервисом Как он себя чувствует Какая на него нагрузка Какие запросы идут мы стараемся Вот как раз таки в рамках отдельного проекта всю эту информацию обобщить и выложить в виде какой-то вот такой красивой диаграмм которую пользователь может смотреть Ну и дальше Можно бесконечно в целом развивать эту идею можно использовать какие-то автоматические средства для валидации например поискать что у вас нет циклов когда вопрос идёт от сервиса к сервису и потом возвращается в начальную точку например Это можно допустить просто по ошибке потому что разные сервисы делают разные люди но будет круто что какой-то Тулин это подсветить и вы сможете например спми Зро ваши сервисы либо найти критический путь в ходе инцидента Когда вам среди всех всего дерева вызовов какого-то запроса который порождён одним пользовательским запросом важно понять Какое именно взаимодействие приносит больше всего проблем лежит на критическом пути и является вот проблемо которую если починим то дальше Всё будет хорошо в сумме мы получаем то что вот Мы научились конфигурировать inv мы поняли как он работает мы поняли как с ним работаеть мы вот прошли по всем тем граблям о которые мы с вами говорили и какие-то мы наступили в тестинг на какие-то мы наступили в продакшене бывало по-разному Мы научились это визуализировать мы смогли это визуализировать сначала в виде я спецификации для того чтобы положить в репозиторий а потом выкатывать в ходе релиза вме с кодом Мы научились это визуализировать на красивых картинках и теперь мы понимаем что на самом деле это возможно было меньшая часть того что нам предстоит потому что дальше Вот то что я называл сес me за се дальше начинается очень большой этап сопровождения клиентов которых вы это внедрили Теперь они полностью зависят за вас скорее всего Вы заходите каким-то образом стандартизировать их архитектуру Да потому что очень тяжело поддерживать бесконечные варианты как люди могут настраивать ваши сервисы мы стараемся прийти к какой-то унификации то что все сервисы взаимодействуют между собой по некоторым стандартным образом и именно благодаря тому что у нас есть сервис smh и то что мы отделили всю эту логику от самих сервисов это делать гораздо проще Не надо вносить изменения в 25 разных фреймворка на пяти языках программирования вы делаете Это Центрально например на уровне баки бола nvo потом дальше как-то проверить что ваши клиенты собственно сконфигурировано и Настрои так как вы считаете правильным в целом тоже для этого есть все возможности потому что всё это лежит Ну в нашем случае в кубе вы можете написать и какие-то аудиты можете если используете кубер написать аминки о которых вот вчера рассказывали ребята и в целом полностью закрыть клиентов от возможности выстрелить себе в ногу без документации поддержки вы тоже не проживёте потому что чем больше клиентов это тем больше вопросов и Либо вы целый день отвечаете в телеграме на бесконечные вопросы либо вы всё-таки пишете код делаете ещ что-то новое и полезное поэтому очень важно разделять эти стримы очень важно понимать что без хорошей документации без хорошей базы знаний без построения какого-то коммьюнити и без обучения возможно каких-то таких процессов вы никогда нельзя раскатить это на Большой флот сервисов самый важный вопрос который все у нас задают вот у вас есть метрики а что нам дальше с ними делать люди чтобы могут совершать раз за разом какие-то типовые ошибки себе собственные дашборды алерты с нашей точки зрения мы стараемся давать это в виде некоторого Стандарта в Яндексе это называется инфраструктура сервис провайдера когда крупный сервис который предоставляет свои возможности конечным сервисам Яндекса он также может предоставить им набор стандартных метрик дашбордов и алертов который он считает правильным За который он отвечает за который он несёт ответственность и клиенты просто подключают их к себе и пользуются И тем самым они сразу из коробки ровно так как они получили возможность сетевого взаимодействия получили возможность Рик Они получают уже вот готовые настройки которые они просто используют И на самом деле дальше уже только по ходу опыта по ходу эксплуатации они начнут понимать зачем эти дашборды алерты им нужны просто потому что Изначально этот опыт уже был пройден этот опыт был уже собран мы просто отдали это клиентам чтобы их Старт был как можно менее болезненным как можно меньше инцидентов у них было в том числе в продакшене Итак собственно мы начали с целей и зада мы поняли что мы хотим сделать зачем нам это надо у разные команд могут быть разные цели и задачи мы выбрали то подмножество проблем которые вот в первую очередь мы хотели решить мы поняли как это решать в архитектуре сервис ша мы поняли как это решать на уровне НВО Мы научились делать нужные конфигурации мы интегрировать это всё в нашу внутреннюю инфраструктуру Ну и в конце смогли раскатить это на крупные сервисы Потому что есть механизмы Иа есть механизмы которые позволяют делать массовые из пройдя тем самым путь от маленького стартапи до внедрений в крупные сервисы Яндекса А здесь Я буду заканчивать Я надеюсь что это было полезно у Вас могут быть свои цели свои задачи Может быть вы хотите строить большой звездолёт как мы может быть вы хотите решать какую-то небольшую задачку jpc балансировки и те те задачи важные интересные Если вы вспомните когда-то мой доклад и не наступите на одни из граблей о которых я рассказывал то я буду считать что не зря здесь выступал сегодня Спасибо вам большое спасибо Денис есть вопросы у нас даже есть время у нас ещё буквально чуть-чуть Слушай вопрос на самом деле примерно одинаковые благодаря за доклад Спасибо за доклад вопрос Почему вы пропал Навой Почему не amb затонул кажется что когда начинали делать Этот проект это было уже наверное лет пять назад ивой тогда оказался самым зрелым решением собственно мы все знали что есть там ИО которые использует под капотом й есть разные другие технологии сервис Смеша например там есть Консул сервис Smash который всё работает в инфраструктуре но под капотом там всё равно ивой это супер большая База знаний это куча ищю на гитхабе даже если не открытые и не решённые Но по крайней мере мы знаем что Проблема не только у нас А проблема у всех это значит что как бы она На той стороне мы можем придумать только как е например либо обойти либо починить это просто даёт возможность быстрого хорошего старта вместо того что мы бы Например писали свой велосипед там какие-то 5 лет и закопали туда кучу экспертизы А здесь мы получаем экспертизу в целом там со всего мира есть другие прокси например есть linkerd который написали свой сайдкар и гордятся тем что он кажется самый быстрый Но вот они буквально только новые модные и не только недавно научились работать вне кубера а Для нас это критично потому что внутреннее облако не построено само собой поверх кубернетес Поэтому пока вот мы сели на ивой Но что самое важное поскольку у нас есть некоторая абстракция в виде нашего покебола наша спецификация в целом никак не зависит от самого Эн воя и мы оперируем такими вещами как вот Трай Тай out - это вещь которая справедлива для любого балансировщика то в целом ничто не мешает намм потом й на что-то другое поменять никак не повлиявших клиентов Ну если только мы не на багаем где-то мы меняем двой на другой балансировщик меняем внутренний код конфигурации и в целом всё будет работать дальше ну здесь полный вопрос звучал что последние тенденции свидетельствует что от НВО отказывается согласен с этим не могу сказать что вот я ну не видел наверное их тенденции Ну может быть если там есть кто-нибудь я почитаю теперь ка у нас пока скорее тот этап когда мы видим что й предоставляет нам Ну большую часть тех возможностей которые вот нам нужны и наши задачу решает Если бы ты сейчас бы снова начинал Ты бы взял истио или что-то ещё ивой бы и взял а-а скорее всего мы бы сейчас просто провели ещё раз вот это исследование Да это вот возвращает к нашему первому пункту что когда ты хочешь что-то сделать надо сначала подумать Зачем ты это делаешь потом подумать Вот как лучше это сделать по потом начитать писать код то есть вот я бы сейчас просто ещё раз это исследование прогнал возможно Мы это сделаем в какой-то момент запланируй переезд но пока вот прямо необходимости Я правда не вижу Понятно А ещё вопрос второй под второй подход карты сервиса как рисовали Что за второй подход карта сервиса А да там была просто красивая картинка это мы просто уже как бы первую картинку рисовали бэнде поэтому она получилась не очень вторую картинку рисовали фронтендер которые это умеют и у них Она получилась гораздо красивее здесь мы именно отдаём специальный сервис просто все наши знания о том какие есть сервисы как они взаимодействуют между собой ребята на своей стороне Ну мы знаем только про сеть Да мы не знаем про другие аспекты этих сервисов ребята на своей стороне собирают дополнительную информацию с таких же сервиспро Они получают её из облака из пло из какой-то внутренней инфраструктуры прав доступов ролей и так далее агрегирующие de platform и вот то про что на этой конференции есть куча разных докладов с примерно с одинаковыми подходами там был Светофор чем его рисова я я бы Эндер не фронтендер я не знаю как Светофор нарисовать понятно Ну мы можем уточнить Я думаю потом ответить если это ну да я могу ещё в чатике там потом что-нибудь принести е интересного А какие метрики рекомендуешь выводить на типовой дашборд а самые стандартные rps ошибки тайминги важный метрик - это лимиты коннекто эво есть умолча значения не достаточно большие но важно понимать что например если у вас куча взаимодействий в один и тот же подик то дефолт это 1024 коннекта они могут закончиться и вот такие штучки тоже очень важно контролировать потому что Ну к сожалению вот это минус Иво на любой ошибку он отдаёт 503 нет правила Фае воли 503 закончились коннекты 503 сервис не работает 503 и понять А что же вот это за 503 и на какой стороне проблема Это один из вызовов работы своем и вот Метрика например того же коннекто и Или например валидация что если вы декларативное про верить что правила фаер вола есть и правда запрос пройдёт Это очень сильно может помочь когда вы будете разбирать ошибки в сервисах Привет Спасибо за классный доклад было интересно но вот такой вопрос А чем был обусловлен выбор э Агента в сайт каре Почему Control Plane сам не не не стали Корол пном настраивать ивой А хороший вопрос действительно можно было бы отправлять всю конфигурацию непосредственно с материнского корабля я для себя выделяю две основных причины почему мы это делали потому что демон помимо получения конфигурации с кол плейна получает актуальную информацию serv Discovery даже если Ctrl Plane сломается по какой-то причине мы не можем получить новую конфигурацию Мы просто работаем на текущем конфиге но всё ещё получаем информацию SE Discovery Да это отдельная супер надёжная система и мы можем работать на текущей конфигурации Но если подики меняются меняются их айпишник мы вот эту информацию сможем актуализировать отдельно мы как бы просто разделяем зону ответственности И чуть-чуть тем самым повышаем Надёжность системы с другой стороны к сам опять же ничего не знает провой он достаточно абстрактен мы можем его по-своему там переписывать менять архитектуру и так далее провой знает только маленький демон баки бола И как я уже говорил в какой-то момент мы можем переписать Этот демон поменять просто то есть мы оставим связь Ctrl п на Демона в неизменном виде там вот одна архитектура другая архитектура неважно Мы её не трогаем меняем просто связь между демоном и прокси И тем самым Например можно подменять прокси спасибо спасибо за доклад я хотел в Исторический перспективе спросить вроде в Яндексе был другой сервис меш об host который в дзене использовался до его переезда и ещё где-то Почему почему новый стали делать это человек который Да знает много про Яндекс сразу видно Слушай это очень большой вопрос Мы можем сейчас дискуссионный уровень это вот правильно отправить запрос его потравить обст более сложная доменная вещь как который может сходить в кучу сервисов через бабол собрать обратно ответ смр Это в один Ну похоже на чем-то и дать это клиенту вот мы стараемся просто здесь зона ответственности раз сейчас они оба существуют и взаимодействуют просто зона разделенной ответственности Да всё так всё так мы просто разделяем зону ответственности спасибо спасибо большо налево Спасибо"
}