{
  "video_id": "un2Ld3uctMM",
  "channel": "DevOops_conf",
  "title": "Миржан Иркегулов — Что я хотел бы знать об MLOps год назад",
  "views": 892,
  "duration": 2802,
  "published": "2024-06-28T07:00:07-07:00",
  "text": "Всем привет Меня зовут хамбар сегодня здесь со мной биржан последний год работы вместе поэтому многие вьетнамские флешбеки мы с ним разделяем и первое что хотел бы спросить это биржан откуда такое название полный рефлексии Да что я хотел бы знать Расскажи немножко об этом Пожалуйста так Привет амбар Да название берется от того что мл лопс Это такая вещь которая Я про не никогда не слышал всю свою жизнь сколько я себя помню я был кэндером питанистом И вот год назад появляется вакансия типа хочешь заниматься мл опсом классная новое направление я ничего не знал про это Но начал заниматься и Выяснилось что такая вещь которая движется семимильными шагами что в ней все каждый раз меняется вся каждый раз новая и очень часто приходится прокладывает собственный путь набивать шишки и у меня возникло такое ощущение что название доклада говорит о том что если бы у меня была Машина времени и отправился в прошлое и молодой версии себя сказал Сказал бы вот ты будешь заниматься им лоб сам я тебе сообщу некоторые знания которые получил на своем опыте и как они могут тебе сократить какую-то боль или какие-то страдания понял спасибо большое скажи Нужно ли понимать Насколько нужно хорошо понимать мышеленник чтобы понять твой доклад или это не очень обязательно нет абсолютно не требуется никаких знаний мыши Learning это доклад рассчитан для тех кто либо имеет очень большой опыт либо не имеет никакого опыта вообще все необходимые термины необходимые понятия я буду снять по ходу дела идут очень высоком уровне абстракции поэтому вообще не требуется Ну тогда продолжая этот вопрос Для кого как ты думаешь будет наиболее большой Импакт для кого наиболее большая польза будет послушать твой доклад начала до конца Да хороший вопрос я думаю что так как mlps имеет отношение ко всему что связано с инфраструктурой диплоименту сборки вокруг машин лернига с одной стороны доклад будет полезен любому инженеру который уже съел собаку на тренировки моделей на обучение моделей но во всем что касается сборки и теплопродакшен внезапно у него возникает какая-то проблема внезапно возникает какие-то препятствия и вот здесь я надеюсь что смогу поделиться полезным опытом либо может быть человек слушающий доклад это либо тех Лид либо backer либо технический менеджер который только задумывается о том чтобы внедрять мышелек и хочет заранее знать о тех препятствиях с которыми Спасибо большое Ну тогда желаете удачи Буду помогать с вопросами какие-то озвучить в конце может быть что-то отвечать а ты можешь приступать Итак всем привет Меня зовут миржан повторюсь доклад об млос я backender с инженер в компании колеса Group Я вам сегодня хочу поделиться своими впечатлениями лопса пройденном пути за последний год и рассказать о своем опыте Итак представим себе такую ситуацию лето 2022 года я ищу новую работу приходит вакансия в компанию колеса групп и говорят о том что вот мы предлагаем вакансию Я подаю на неё меня берут на работу и я оказываюсь в новой команде Итак меня знакомит с новыми людьми у нас новая команда в компании У нас есть инженера и у нас есть два инженер включая меня и команда абсолютно новая То есть даже люди которые пришли раньше меня пришли немного раньше вся команда была собрана в 2022 году и нам компания говорит Вот ребята Мы создали новую команду Дело в том что мошенник Мы уже внедряли у нас уже был опыт внедрение машинка и у нас уже существует какие-то сервисы которые существуют их примерно 10-15 разные степени зрелости в каждом сервисе может крутиться от одной до нескольких моделей они все написаны на питоне большинство из них использует библиотеку по итог и нам говорят Ну а собственно зачем Мы создали новую команду email Дело в том что когда мы внедряли eml сервисы Это был очень большой успех и многие сервисы были внедрены в другие продукты компании были интегрированы с ними то есть от email а компания оказывается не хочет он приносит пользу бизнесу но у нас со временем начали появляться проблемы во-первых у нас начал расти показатель так называемый Time to Market время от постановки задачи до собственно выкатывания какого-то результата про начал разрастаться бы клок То есть у нас все больше и больше сервисов их нужно улучшать нужно писать новые сервисы количество задач растет и становится все больше выполнять и становится все труднее время выполнения задач начинает расти очень сильно и со временем рук начинает не хватать все это становится труднее поддерживать все это ломается все это вертится это надо чинить возникла проблема компания хочет решить хочет применить какой-то другой подход мы собираемся смотрим на все зависит на все эти задачи перед нами и мы понимаем Если мы хотим как-то выработать стратегию как-то придумать как бы нам все это решить какая у нас должна быть главная цель какая у нас должна быть мы понимаем что для нас главной задачей является снизить тот самый тайный туман в этой презентации Я хочу рассказать вам о нашем наших приключениях как мы этого добились на примере 4 кейсов у нас будут вот такие 4 кейса в относительно хронологическом порядке и каждый кейс будет построен примерно так то есть я вам сначала покажу о том как ситуация была до и каким проблемам это привело Какие мы решения искали Какие внедрили и как ситуация изменилась после и получилось Итак я думаю можно начать давайте начнем с первого кейса реестр моделей что же это такое причем здесь есть модель сначала расскажу как было до В общем у нас есть питон у питона очень сильная экосистема для разработки машин лернинга поэтому все сервисы были написаны наверное используешь какой-нибудь фреймворд большинство из наших сервисов используют фреймворк пай торч для так называемого глубокого обучения но раз речь идет об глубоком изучении мы говорим с Вами скорее всего нейросетях и очень часто я буду упоминать нашем докладе слово модели Что такое модель во-первых это просто нейросеть которая или какой-то другой который уже был обучен который готов продаж и модель у нее интересная особенность заключается в том чтобы это всего лишь функция то есть мы модели можем что-то спросить она нам что-то ответит но отличается математические функции тем что ее можно реализовать и вот например в контексте пой торчим мы терроризируем файл с расширением для тех кто пользовался питоном они сразу знают что речь идет о сериализации используя библиотеку Итак модели сериализируется А для чего вот e-mail инженер начинает тренировать какую-то модель тренировать нейросеть для того чтобы выполнять какие-то бизнес задачи он и стерилизует у него на выходе получается файл Этот файл может 10 десятки мегабайт сотни мегабайт и даже гигабайты Разумеется Невозможно его положить гид Потому что дети не предназначен для хранения и версионирования больших файлов мы будем его хранить хранилище у нас в компании используется распределенное хранилище данных которая называется может вести себя как объектное хранилище как файловое хранилище в зависимости от того как вы его настроите у него есть интерфейс Amazon S3 у него есть интерфейс Вы можете также как например как будто у вас есть и примерно процесс выглядит так то есть машин Learning инженер использует Pay torch получает на выходе какую-то модель он может сериализировать у себя на компьютере загрузить его в хранилище данных и потом эту же модель из хранилища данных загрузить у себя в ML сервисе который все замечательно Проблема нету но на самом деле проблема есть мы приступаем к работе начинаем разгребать и выясняется погоди-ка вот есть те самые мыл сервисы которые крутятся на продакшене они подгружают при запуске какие-то модели из хранилища Но подгружает из разных мест и нету никакой логики там где эти модели хранятся более того мы хранилищем начинаем находить целую кучу разных моделей которые отношение к какому сервису которые достались нам как легасе то есть это Что это бэкапы Это какие-то предыдущие версии это они нам нужны Не нужны вдруг нельзя их удалять Вдруг их нужно удалить и так далее более того сам процесс выглядит так что именем инженер тренирует какую-то нейросеть получает на выходе какую-то модель загружает это цех он должен все это делать вручную то есть если он создал быка то замечательно если забыл это сделать то Back потеря то есть мы не можем откатиться мы не можем выбрать какую-то другую версию мы на все это смотрим дело и понимаем что одним словом или одним выражением это можно выразить Так у нас нет единого источника Правды во всем что касается состояния наших моделей мы начинаем читать литературу на эту тему мы начинаем читать литературу по НЛО пытаемся разобраться как это принято решать и мы встречаем такой термин который называется реестр модель мы говорим Нам нужен реестр модель Вы должны все модели собрать единое место Вы должны как-то вести централизированный учет чтобы четко знали Какая модель актуальна Какая нет Какая является бэкапом Какую можно смело удалять и так далее мы начинаем читать дальше и видим что нам говорят реестр модели обычно реализуется каким-нибудь инструментом мы начинаем изучать Какие мыло инструменты существуют на рынке и выясняется что их целая куча они очень разные они решают разные задачи Они приоритизируют разные вещи и они абсолютно не являются взаимозаменяемыми то есть нельзя просто вынуть инструменты заменить его другим они все как-то по-разному приоритизируют решение проблем Мы начинаем рассматривать мы рассматриваем здесь абсолютно не полный список MLP с инструментов которые мы рассматривали и который в принципе существует сейчас на рынке у каждого из них есть свои плюсы и минусы нельзя сказать что какой-то из них является плохим но на тот момент он не решал те задачи которые и мы смотрели взвешивали и остановились как что по сути Ты поднимаешь выделенном сервере и он дает тебе простой веб-интерфейс для млнженер по сути его задача стандартизировать и говорит вот я натренировал эту модель Я хочу трекать все эксперименты с этой моделью почему это важно потому что работаем инженеры она итеративно по своей природе то есть инженер натренировал на каких-то данных свою модель она ведет себя определенным образом и выясняется что примеру У нас есть модель которая распознает автомобили на фотографиях и она распознает на этой фотографии с вероятностью 80 процентов находится автомобиль и бизнес говорит 80 процентов это недостаточно можно как-то улучшить показатели улучшить метрики этой модели значит ее надо тренировать это новый эксперимент и вот этот оперативный процесс обучения моделей он все время происходит у мене инженера и было бы замечательно это отслеживать и млн позволяет делать более того есть интеграция с огромным количеством существующих и поэтому мы решаем эту проблему за счет внедрения вот такой замечательный инструмент перейдем ко второму на этом вообще даже близко ничего не заканчивается немного для лирического отступления поговорим еще немножко нейросетях То есть я упоминал такой термин что модель нужно обучать Что это значит Дело в том что когда мы говорим с Вами термине машины обучение есть слово обучение модель по умолчанию она является очень глупо она ничего не понимает не может ответить ни на один вопрос корректно значит ее нужно обучить нейросети обычно в большинстве случаев находятся в двух стадиях стадия обучения и стадия когда она уже обучена она уже умная Мы хотим вы хотите Продакшен и тогда мы говорим что находится в стадии а как мы обучаем нейросеть нам нужны входные данные нам нужны тренировочные данные допустим та же самая модель которая распознает автомобили на фотографиях мы должны дать ей огромное количество фотографий речь идет не о сотнях и даже иной раз не тысячах А может быть о десятках тысяч фотографий и у нас должны быть такие фотографии на каких-то фотографиях нарисован автомобиль на каких-то не нарисован автомобилем вот на этой фотографии есть автомобиль Научись определять автомобили на эти фотографии более того мы должны дать ей самые разные фотографии на которых разные марки автомобилей разного цвета под разным углом чтобы модель могла распознавать самые разные фотографии на которых изображен автомобиль то есть Нам нужно очень много данных если это представить другими словами получается что модель без данных абсолютно бесполезна потому что нейросеть по своей природе это черный ящик если мы заглянем внутрь нейросети мы увидим что это гигантский многомерный массив чисел который сам по себе ничего не означает и eml инженеры ни о чем не говорит дать инженеру нейросеть без данных и спросить его Слушай разберись что это нейросе делает Хорошо ли она работает правильно ли она выдает результаты Это то же самое чтобы дать машинный код и сказать без комментариев из документации Просто спросить как программа работает если у нас нету данных и поэтому мы не можем интерпретировать модели Значит у нас нарушается версионирование у нас нарушается мы не можем никак понять что это модель делает Значит мы не можем никаких нет Откуда мы знаем хорошо ли это модель работает или плохо более того у нас часто возникает такой момент когда модель нужно все время улучшать то есть модели со временем начинает работать хуже и хуже к примеру представим что выпустили новую марку автомобиля которая радикально по форме И по цвету отличается от всех автомобилей которые существовали ранее и наша модель ее распознает очень плохо значит нашу модель нужно до обучить или переобучить опять нужны новые данные Итак начинаем разбираться Где наши данные лежат и мы начинаем видеть ту же проблему что и с моделями какие-то данные у нас лежат на отдельных машинах выделены для того чтобы тренировать нейронную сеть какие-то у нас лежат в хранилищах данных и размазаны по разным хранилищам разным дата-центрам И даже если мы находим эти данные то мы понимаем что эти данные может быть устарели может быть они не полные может быть они некорректны и то есть у нас та же самая проблема отсутствия версия данных и отсутствие единого источника Правды если мы версионируем модели значит мы должны заценировать тренировочные которые идут вместе с моделями потому что они идут в тандеме друг с другом Ну возникает вопрос хорошо мы начнем версии данные А как мы это будем делать где мы эти данные будем хранить Ну что мы используем например кода люди в большинстве случаев используют кто-то использует Меркурий кто-то использует базар или вены так далее но для этого существуют инструменты но данный мы же не можем хранить во-первых речь идет о бинарных файлах например фотографиях формате jpe может быть речь идет о звуковых файлах их не имеет смысла хранить более того они могут 10 мегабайты а сами могут весить сотни мегабайт гигабайт и так есть конечно существующие инструменты для хранения данных и версионирование но они нам не подходят потому что в них есть некие ограничения которые существуют просто потому что изначально эти инструменты не задумывались для дата сайнс и мы такие думаем Ну логически данные нужно хранить там где и они собственно и должны храниться то есть хранилищах данных будь то ходу или Amazon S3 или в нашем случае C и мы внедряем такое решение как dvc она так и переводится дата вершин Контру dvc решает эту проблему тем что он сохраняет этот компромисс что данные хранятся на хранилище Да нашем случае но при этом версии через гид он как бы объединяет хорошие стороны обеих обоих инструментов То есть как себя ведет dvc он эмулирует во многих отношениях повторяет его функционал Но для данных при этом он не хранит данные тела хранит их удаленно Но в самом дети он хранит метаданные в частности к примеру он в вашем гид репозитории метода файл метаданных который называется точка dvc его мы добавляем сами данные лежат там как Где нам удобно где у нас настроена репликация где у нас настроены где мы не боимся того что машина сгорела и все данные пропали и выглядит эта схема чуть-чуть посложнее но она выглядит примерно так ML инженер собирает какой-то dataset для того чтобы натренировать модель используют фреймворк пайторчик получает какую-то модель это модель кладется в C она версия не растут а данные версии через 9 и метаданных кладутся а сами данные тоже хранятся там где они должны храниться Казалось бы мы проделали большую работу Мы решили проблему персоналированием и решили проблему версии армирования да Но те Тем не снижается наши проблемы не решается налаживается работа у них налаживается сглаживается их workflow они начинают создавать новые модели решать старые задачи но почему-то течение снижается потому что они натыкается на еще одну бутылочное горлышко которое уничтожает Наши достижения производительности какой-то препятствие до сих пор мешает в чем же оно заключается теперь давайте рассмотрим немного другую сторону разработки чтобы но он тоже существовать наверное в виде какого-нибудь микросервиса Например если у нас есть кубернетесь и мы хотим чтобы внутри губернатора у нас микросервис архитектура и сервисы друг с другом общаются может быть они общаются паресту Может они общаются через кафку это неважно Но главное в том что нас много-много сервиса и допустим в нашей компании email инженер выкатили какой-то мл сервис Он должен быть интегрирован в какой-то уже существующий продукт чтобы этот продукт мог общаться с этим сервисом одной модели недостаточно нужно проделать еще дополнительную работу Итак сервис и внутри него может быть от одной до нескольких моделей более того у нас может быть в коде какая-то нетривиальная без услуги например для того чтобы модели эффективно работала нужно сначала какие-то дополнительные данные взять допустим из базы данных мы скилл или пост допустим что-то временно положить в редис или что-то взять Ну раз если мы пишем какой-то код на питоне мы пишем микросервис Нам нужен какой-то фреймворк на питоне Существует множество разных фреймворков для питона мы все это хотим поднять таком-то веб-сервере и мы хотим дать ему какие-то поинты чтобы он в будущем когда мы его запустим когда мы его поднимем был доступен и видим другим сервер более того ему значит нужно запаковать в докер образ чтобы туда подкрутить все нужные зависимости чтобы он везде запускался одинаково нужно настроить в нашем случае мы используем atlasing bambook и все это отправить губернатос и вот здесь возникает закономерный вопрос этим всем должен инженеры заниматься ведь задача заключается в том что он должен использовать все свои знания линейной алгебре статистики математического анализа он должен разбираться в архитектурах нейронных сетей он должен настраивать количество слоев и как эти слои нейронных сетях обмениваются информацией Он собирает с помощью данных тренирует эту модель навешивает на нее метрики И помимо всего этого он реализует нетривиальную бизнес логику он пишет микросервис прикручивает к нему and Point и он пишет докер файл он настраивает Билд планы и диплоинмент планы для того чтобы диплоид работал и все это должно в губернации заработать Скорее всего будет писать либо Ямал манифесты вручную либо использовать что-то вроде кастом айс или хэллом и должен настроить мониторинг и все такое И короче у него целая куча работы и кто-то из вас наверняка скажет подойти к но так сегодня выглядит программирование современном мире все бы кэндиды с этим сталкиваются да Раньше были времена когда ты просто написал какой-то Код и по FTP загружаешь его на удаленный сервер и у тебя вот поднимается сейчас ты должен разбираться и так далее В чем проблема проблема заключается в том что у нас отдел пэкенда в компании больше 50 человек и у них очень хорошо налаженный бизнес-процессы связанные с тем как распределять между собой задачи и Как эффективно их решать наше дело млн operations всего 5 человек 3 мыло инженера 2 млпса и мы пытаемся разгрести этот гигантский бэк Лок и мы хотим резко снизить и тем мы просто физически не будем успевать выполнять всю эту работу и мы пытаемся думать именно с точки зрения методологии Мы хотим как можно больше автоматизировать как можно больше сгладить процесс любой повторяющийся труд мы хотим автоматизировать более того еще возникает такая проблема что раз мы пишем модели на питоне и от питоны от пайтор чем и отказываться не хотим Но изначально мы логически подумали Ну раз мы пишем модели на питоне наверное микросервисы будут вписаться на питоне Возможно они тривиальная логика будет писаться на питоне и так далее но основная компетенция нашей компании в двух языках вопросов и большинство брендеров знает либо один либо другой чаще всего знают оба и они с этими языками на ты они этих языков совершенно не боятся они на нем собаку съесть и нам сервисы Они же не должны быть отправлены наружу Они же не должны смотреть в сторону пользователя они внутренние сервисы которые мы интегрируем с нашими мы Обращаемся к вашим микро сервисам задаем какие-то вопросы получаем какие-то ответы поэтому почему бы вам как-то не сделать вашу структуру ваших сервисов модульный и мы тогда можно взять на себя часть работы мы можем интегрировать их свои сервисы и мы можем писать вот этот оберточный код вокруг ваших моделей ногой или на ПХП и тогда мы снижаем Pass Factor и не надо чтобы кто-то знал питон Когда нужно допустим резко подключить новых людей какой-то задаче связаны которые допустим горит Но это значит что мы должны как-то раздербанить наши мл сервисы и снизить количество питона в этих мл сервисах настолько насколько это возможно оставить только необходимую часть А все остальное сделать модульным и так чтобы другие люди могли подключиться к решению Итак Мы возвращаемся к тому что мы уже видели ранее У нас есть инструмент который до этого решал немного другую задачу но когда мы его внедряли он привлеклась и дополнительными еще плюсами которые на данный момент внезапно стали актуальны mlc может делать две вещи во-первых Он может автоматически сгенерировать микросервис вокруг вашей ml-модели То есть если мы все нетривиальный бизнес логику из ML сервисов вытаскиваем мы внезапно замечаем что наше мл сервисы вокруг наших мышелек моделей становится однотипными повторяющимися монотонными очень примитивными это же можно автоматизировать и действительно выполняет эту задачу он может взять вашу модель и просто поверх неё навешать необходимый код для того чтобы запустился как микросервис и он сразу дает ему 2 стандартных один и один Обычный стандартный который в данном случае называется которым мы Обращаемся к модели почему это нормально Почему не нужно много разных но и дело в том что как я говорил ранее В абстрактном смысле слова модель Это всего лишь функция ты ее что-то спрашиваешь она тебе что-то отвечает ты показываешь фотографию она может быть отвечает тебе каким-то Джейсоном в котором есть поле которое говорит с вероятностью 90 процентов на этой фотографии находится автомобиль то есть по сути нам не нужно много импоинтов нам достаточно всего лишь одного просто чтобы общаться с этой моделью более того выполняет вторую задачу млфло может автоматически взять этот микросервис и обернуть его в доке образ Он просто сразу дает тебе готовый докер со всеми запакованными рекламе всеми зависимость и говорит Ты можешь его как сам считаешь нужным Казалось бы монетизирует целую кучу нашей работы и мы можем за счет этого резко снизить и тем мы обрадовались но не тут-то было мы начинаем выполнять нашу задачу и у нас бывает самые разные препятствия Итак посмотрим выделенный сервер значит в нашем случае мы его крутим kubernety у нас несколько реплик этого флоу и он крутится в губернатосе как контейнер как собственно докерезированный контейнер если мы еще и молоко попросим собрать новый докер образ это значит он собирает докер в докере А это тоже сама по себе такая довольно интересная фича но тут другая Проблема в том что у нас компании есть выделенные машины для того чтобы на них собирать докер образы на них настроены кэширование слоев На них все настроено так как нужно и выделено большое количество ресурсов для того чтобы все докер образы которые в компании собирается собирается именно удаленно на эти выделенных машинах А тут у себя в клубе с каким-то маленьким количеством ресурсом ресурсов пытается собирать и выделенные агенты не используются это не оптимально но проблема даже не в этом это мелкая проблема есть хуже проблем Мы просим собрать докер образ и полученные образ не работает Что значит не работает мы отправляем в kubernet Он вроде как запускается но наша мл модель не садится на видеокарты А видеокартах мы поговорим чуть попозже но Достаточно знать что видеокарты очень важны для машин при том что проблема исчезает когда мы собираем наши докер-образы вручную если мы просто пишем докер файл сами прописываем базовый образ прописываем Какие зависимости нам нужны он прекрасно садится на видеокарты и наши mail сервис работает наш eml модель отвечает очень быстро все замечательно в чем проблема непонятно выясняется что просто у нас почему-то образ работает наш А тот который для нас ML Flow специально подготовил у нас не устраивает может быть мы что-то не так сделали не так настроили чего-то в документации не дочитали но проблемы не решается мы не можем подружить ему и мы говорим слушаем погоди давай нам готовый докер образ не собираем у себя локально ты нам сгенерирует докер файл мы там для себя какие-то строчки подменим так как нам удобно так как мы знаем что оно заработает И мы сами это докер образа берем на удаленной машине и Мы открываем наша команда открывает в частности присутствующие сегодня Эксперт хамбардуслив открывает и будет такой новый фича новый патч который позволяет генерировать теперь по запросу может сгенерировать которым можно подменить какие-то значения и это существует версия 1.29 мы решаем эту проблему за счет дает нам вместо готового докер образа дает нам всего лишь докер файл Где мы что-то можем подменить дает нам какие-то артефакты то есть тот самый микросервис который он собрал и мы можем отправить на диплоинд все замечательно но погодите-ка здесь остается одна маленькая деталь Что значит отправить на диплоид то есть мы отправляем его вручную то есть ну мы получили какой-то докер образ или какой-то докер файл а потом что с ними сделать у нас настроен какой-то связь закономерный вопрос Но какой же это ты вопс если мы продолжаем какой-то этап делать вручную Можем ли мы это как-то автоматизировать И вот здесь больше не может нас выручить Дело в том что не понимает что такое не понимает что такое губернатор не знает таких терминов как дженкинс или бамбул не может сгенерировать вам яму манифест и он не понимает что такое он не понимает Что такое объекты cubernets такие как диплоид ингресс сервис и так далее дает тебе докер образ или в нашем случае докер файл и говорит все моя работа здесь завершена дело с ним все что хочешь и получается что между нашим уже существующим стандартным стеком csd и между ML Flow Существует такой разрыв нам этот разрыв Нужно чем-то заполнить то есть я могу умеет все до генерации Докера Она вся сидит все что связано с нахождением какого-то изменения репозитории и триггерингом Как соединить эти две вещи между собой Мы возвращаемся к тому как есть собственно реестр моделей который мы внедряли изначально но дело в том что во всем что касается трекинга экспериментов Он решает проблемы инженеров просто замечательно У него интерфейс там можно навешивать параметры и так далее Что касается дипломы когда ты заходишь в раздел реестр моделей в интерфейсе Там есть такая картиночка появляется такая табличка которая горит вот у тебя список каких-то моделей Ты можешь перевести Production но когда ты нажимаешь на эти кнопки ничего не происходит ничего не три делится это просто информационный табло и мы подумали что если мы прикрутим функционал поэтому как это должно выглядеть то есть мы хотим чтобы что-то три делилось когда мы инженер нажимает кнопочку и говорит Я хочу перевести эту модель Production что-то три единицы у нас генерируется манифесты для губерната со с нужными настройками и нужным потреблением памяти процессорной мощности с нужным количеством реплик и это куда кладется в гитрепозитории все это автоматически и вот на этом моменте наш вся сидит три делится и запускает процесс сборки и диплом и вот здесь мы начинаем с нашей командой задумываться Хорошо один раз мы публиковать сделали Мы хотим добавить еще один функционал Flow но этот функционал нам кажется намного более сложным если мы откроем Full request А вдруг ML Flow скажет ребята ну Pull request мы принимаем давайте вы вот это добавите вот это добавить над этим поработайте потому что у вас такой очень узкий искейса может быть мы хотим чтобы умел больше может быть это параноидальная мысль может мы думаем блин хватит ли у нас ресурсов для того чтобы создать еще один пудри квест У нас сроки горят у нас тем до сих пор не снижается нам нужно решать эту проблему очень срочно Хорошо Давайте фотки Ну а что мы будем спортом делать будем ли мы со стрима постоянно какие-то новые изменения и мы думали думали и принимаем решение что да мы хотим всегда открыты но на данный момент самое практичное самым практичным решением будет написание своего внешнего костыля который добавляет функционал домов этот очень просто он поле забирает у него какие-то изменения в реестре моделей на основе полученных данных генерирует какой-то манифест забирает еще сгенерированный докер файл тот самый функционал который мы внедрили ранее собирает докер образа удаленно отправляет на губернатос и весь этот процесс автоматизирован Итак наконец-то мы получили полную автоматизацию полный тот самый Continuous integration Continuous Delivery который настолько важен и у нас возникает новая проблема прежде чем мы о ней поговорим Я хочу немного поговорить про видеокарты я упоминал тот факт что мошенник использует видеокарты используют их очень мощно Почему при чем здесь видеокарты Казалось бы для любого человека который никогда в жизни не сталкивался может возникнуть закономерный вопрос причем здесь работа с Ритой графикой или что-то в этом роде но дело в том что видеокарта это как параллельные вычисления в миниатюре видеокарты радикально архитектурно отличается от центрального процессора и если мы посмотрим на то как устроен под капотом он использует какие-то вещи взятые из линии в частности используют перемножение матриц под капотом когда машина Learning модель либо обучается в частности если мы особенно говорим про ней если нейронные сети чего-то обучаются происходит огромное количество перемножения матриц И если мы просто уже готовы модель о чем-то спрашиваем Передаем какую-то информацию хотим получить какой-то ответ тоже происходит огромное количество перемножения матриц проблема перемножения матриц в том что этот алгоритм очень затратный и очень медленный он работает от отель даже больше чем в квадрате N там 2.3 степени и так далее То есть это очень медленный алгоритм который выполняется очень долго и очень ресурсозатраты но у него есть преимущество он очень замечательно параллелизируется а видеокарты это параллельные вычисления в миниатюры если мы будем выполнять перемножение матриц на видеокартах мы внезапно получим колоссальный прирост эффективности консольный прирост производительности мы с вами говорим о таких числах как наша мл модель посажены на видеокарты может работать в 10 раз быстрее в 20 раз быстрее 50 раз быстрее запросто Но для того чтобы посадить ее на видеокарты мы должны использовать Generals computing на видеокартах мы должны как-то Достучаться до видеокарт и как-то сказать Я хочу тебя использовать как центра процесса но только параллелизировали в частности в нашей компании мы используем видеокарты NVIDIA Поэтому нам нужна такая программная настройка которая называется куда Итак вернемся к нашим кейсом изначально мы хотели снизить эти темы мы хотели снизить его как можно быстрее как можно лучше и были готовы за это заплатить высокую цену мы внедрили ему Flow версионировали моделей не особо помогло но сделала немножко лучше мы внедрили dvc версионировали данные инженеры довольные у них работа тоже наладилась но какой-то еще остался и мы наладили Весь процесс диплом это через который мы поверх него навесили и внезапно все заработало и у нас начали выкатываться модели и начали выкатываться быстро ttm начал резко снижать внезапно выясняется что мыло инженеры успевает с большой скоростью разгребать тот самый бык который вырос до раз меров целый год они начали решать одну задачу другую одну за другой улучшать старые сервисы клепать новые сервисы и у нас начали появляться новые модели на продакшене новые сервисы и интегрироваться очень быстро уже существующими сервисами в компании у нас моделей стало так много что мы испытали то самое головокружение от успеха и сейчас мы с вами поговорим так прошу прощения в чем возникла проблема мы радуемся собой радуемся тем что у нас все замечательно мы выкатываем новые модели У нас их целая куча новые сервисы решаем задачи бизнес нами доволен мы приносим пользу бизнесу мы такие счастливые радостные пьем чай прибегает разработчики соседней команды говорит ребята у вас все попадала вот выкатили новый ML сервис вот он упал и сыпется логи в трилогии сыпятся ничего не работает мы не можем с ним интегрироваться сейчас мы все починим мы посмотрим откатим на нужную версию Там разберемся потом выкатим заново он говорит Ребята вы не понимаете Ладно черт с этим новым сервисом старые сервисы начали падать с которыми Мы уже давно интегрированы которые до сих пор работали Нормально мы бежим к нашим компьютерам смотрим в чем проблема смотрим графа ну смотрим ноги выясняется что у нас кончилась память на видеокартах Что же это за такая проблема Дело в том что мы все с вами знаем что такое метрики Да мы знаем poolbase метрики Push Base метрики там Стас ди графа и с одной стороны прометиус Виктория метрик с другой стороны собираешь метрики и рисуешь это все визуализируешь где-нибудь графа не У тебя такие красивые графики вот там модель или там какой-то сервис ведет себя так но почему-то в литературе про млпс очень мало говорится про мониторинг самого железа Тех самых видеокарта мы были к этой проблеме готовы То есть нам подсказали Мы сами в том числе догадались что нужно мониторить и сами видеокарты тоже Мы навешали через задник с кучу метрик выбили графа Ну состояние наших видеокарты были готовы к тому что у нас видеокарт в нашем железе ограниченное количество а модели будет все больше больше рано или поздно они все выделены ресурсы следят и нужно будет докупать новые ты из-за того что мы достигли такой огромной скорости Мы просто не ожидали Как быстро это проблема нас настигнет Мы просто недооценили масштабы этой проблемы и мы начали разбираться думайте смотреть что мы можем сделать подметили одну такую маленькую вещь что не все видеокарты у нас потребляются одинаковые что у нас есть небольшой запас но мы почему-то не можем им воспользоваться Итак давайте сначала поставим проблем У нас заканчивается память на видеокартах мы такие говорим ладно Не проблема пойдем к админам говорим товарищи админы у нас кончается железо у нас не хватает ресурсов можете нам докупить видеокарту съездить в автоцентры и воткнуться наши стойки они говорят без проблем эту проблему сейчас решим подпишем пару документов начальство одобрит бюджет будет выделен Мы купим видеокарту вам поставят Мы спрашиваем хорошо каких сроках идет речь Ну может быть неделю займет а может быть месяц А мы говорим У нас нет таких сроков хорошо новая железо будет но оно будет не скоро а проблемы нужно решать сейчас К сожалению большинство сервисов мы не можем просто временно отключить они подвязаны к продакшну они используются на них идет высокая нагрузка не может просто их выдернуть все что мы смогли по скейлить вниз убрать количество реплик заставить потреблять меньше ресурсов мы как могли сделали но у этого тоже есть предел Потому что почему делаем какие-то сервисы в нескольких Потому что есть нагрузка на них и мы принимаем полевое решение мораторий на новые релизы Ничего нового не выкатываем нужно любой ценой избежать резких Скачков потреблений если там какой-то новый подсоздался при новом диплоименте А старый еще не успел удалиться у нас резко скакнула и у нас одна модель пытается воткнуться А места нету Она выпивает какой-то другой модель и у нас появляется эффект Домино из-за чего все сервисы начинают вылетать видеокарта если возможно Давайте масштабировать в ручном режиме настолько насколько возможно где-то сэкономить какую-то память но опять же у этого есть предел и всего лишь совсем ничего сможем на этом сэкономить То есть это не решение долгосрочное это не долгосрочное решение проблемы Но мы изначально заметили тот момент видеокартой потребляется неравномерно память То есть просто не там где надо Можно ли научить сажать наши мл сервисы на видеокарты динамический и мы начинаем разбираться и смотрим у библиотеки по итог честь такая проблема поэтому в принципе не умеет как-то выбирать видеокарту в нем выбор видеокарты нужно захардкодить Если Вы посмотрите на такое Вот минималистичный пример кода из Pay torch мы допустим сажаем его на куда двоеточие 0 то есть грубо говоря на первую видеокарту мы это Хард котим мы не можем по торчу сказать Слушай ты сам подбери какую-нибудь оптимальную видеокарту для себя он этого не умеет и поэтому мы хотим научить не хардкович видеокарту а Выбирай ту которая наименее загружена И для этого мы пишем очень маленькую утилитку которая называется библиотека которую ты Подключаешь свой мл проект и Она позволяет тебе динамически выбрать ту видеокарту которая наименее загружена под капотом она использует NVIDIA библиотеку очень низкого уровня для того чтобы общаться с вашими видеокартами и таким образом мы решаем эту проблему Итак подытожим чтобы я хотел знать об ммопс год назад если у меня была Машина времени Я мог бы отправиться в прошлые сказать молодой версии себя Слушай ты сейчас будешь заниматься млапсом это очень много шишек на этом набьешь Давай я тебе заранее подготовлю почву для того чтобы все у тебя прошло гладко чтобы я сам себе сказал я бы сказал себе во-первых у тебя всегда должен быть единый источник Правды у тебя не должно быть такого что у тебя все разбросано И ты нигде не знаешь Что актуально что устарело что можно удалить что нельзя удалить для данных и для модели у тебя должен быть единый источник Правды какой-то Центральный реестр который идет учет всему этому во-вторых если у тебя не налаженные данные мл становится бесполезен сначала наладить все Data line которые существуют у тебя в отделе или в компании разберись Откуда ты берешь данные как ты будешь подготавливать какие-то будешь в результате где они будут храниться если для бэкендира важно версия код например с помощью Гита ты внес какой-то патч закамметил у тебя новая версия Где ты можешь откатиться для работы СМЛ у тебя внезапно появляется необходимость версий мира не только код но и данные и модели для того чтобы капиться на какую-то другую версию и так далее Но самое главное На мой взгляд очень субъективный взгляд вещь движущийся колоссальной скоростью И в нем нет ярко выраженного лидера и поэтому для меня первую очередь потому что серебряные пули не существует и писать код придется Может быть ты будешь дописывать какие-то вспомогательные сервисы какие-то свои тузы что-то будешь внедрять Но ты должен разбираться в классическом железо днем нужно разбираться Зачем нужны видеокарты Почему они важны без этого никуда и на мой взгляд самая важная вещь на планете это то что ты всегда всю ситуацию должен мониторить настолько насколько это возможно Я благодарю вас всех за выделенное время меня зовут миржан и Я с удовольствием с Вами еще раз поговорил Всем спасибо"
}