{
  "video_id": "7vMSyXhE1w4",
  "channel": "DevOops_conf",
  "title": "Сергей Бывшев — Применение Grafana stack для централизованного логирования и трейсинга",
  "views": 517,
  "duration": 2615,
  "published": "2023-06-30T00:34:42-07:00",
  "text": "Всем привет радость тут видеть меня зовут Роман сегодняшнем спикером будет Сергей он расскажет о графа на стеке о том как мы на графона стек переходили с классического ялка С какими проблемами столкнулись что у нас получилось и какой Профит В итоге получили Мы работаем в компании метра квадратный Сергей у нас ведущий инженер по автоматизации те слова а вопросики задавать Telegram канальчики по QR коду к нему подключиться Спасибо Давайте начинать в общем-то буквально пару слов о себе да то есть помимо того что я являюсь ведущим инженером компании метра квадратной также занимаясь преподавательской деятельностью на платформе otus То есть все что связано с инфраструктурой войти где-то более 10 лет из них последние 5-6 лет занимаюсь вопросами Как раз таки автоматизации внедрения различных девапср и Практик в тех местах где в общем-то работы буквально немножко о нашей компании метр квадратный это проб техпроект который строит экосистему недвижимости мы помогаем нашим клиентам покупать квартиры да то есть проверять их находить в общем-то оформлять безопасные сделки ипотеку оформлять так далее А после покупки уже соответственно принимать квартиру страховать ее возможно заказывать ремонт Ну и также делаем какие-то удобные сервисы для наших партнеров в виде банков застройщиков риэлторов и всего такого плана и Давайте потихоньку переходить непосредственно к нашей теме как уже сказал Рома в общем-то сегодня хотелось рассказать о нашем кейсе миграции с Елка селастик стека Да на графа нас так то есть какие предпосылки были для этой миграции для систем централизованного логирования и распределенного трейсинга да то есть какие проблемы у нас были в процессе миграции Какие узкие места с чем мы сталкивались как мы это решали вот ну и наконец уже в конце рассказать о том какой Профит мы от этого дела получили вот и наверное один из основных профитов которые мы хотели в общем-то добиться это снизить сократить стоимость нашей системы и для системы логирования у нас удалось сократить эту стоимость примерно 8 раз и для системы трейсинга примерно в пять раз вот такие вот цифры получились и давайте начнем с предпосылок миграции система логирования схема изначально выглядела у нас следующим образом то есть у нас практически подавляющее большинство сервисов работает кластерку брендатс соответственно основной поток логов был именно там вот в качестве агентов сборщиков логов у нас выступал флюинбит далее он перенаправлял логи в кафку топики были нарезанные соразмерностным спейсами спейсом далее из них уже вычитывали пулы lockstage развернутые также в кубере и соответственно все это дело агрегировалось парсилась и записывалась кластер ластик Search и далее мы уже использовали кибану для визуализации наших логов В общем-то какие Сначала да по цифрам немножечко расскажу то есть число микросервисов у нас достигала примерно 350 развернутых там в одной из двух и более репликах далее число запросов в секунду к сервису составляла примерно 600 rps затем объем логов составлял в сутки около 800 гигабайт пиках до полутора терабайт доходило число сообщений в секунду было около 3000 да то есть сообщение в систему логирования поступало и наконец размер кластера составлял 10 datanot да то есть без учета нот мастеров координаторов вот такого вот всего то есть я так как-то так вот и в общем-то С каким проблем Мы сталкивались с данной схемой Ну во-первых это довольно серьезное потребление ресурсов да то есть эластики лак спеши потребляет действительно достаточно много CPU памяти и в целом сторон же Да вот конечно хотелось это дело как-то снизить с учетом того что логов меньше не становится как правило Да и становится только больше вот вторая проблема это доступность продуктов То есть где-то к весне этого года мы все наверное работает с эластиками столкнулись с невозможности например скачать какие-то продукты компании Да конечно это можно порешать вопросами там зеркалирования да это с других мест скачивает токер хаб опять-таки никто не отменял если у нас контейнерах Да мы разворачиваем наши системы но была у нас еще одна проблема то есть у нас был лицензионный ластик Да там для фича авторизация идентификации леркинга и каких-то прочих вещей и соответственно Вот это уже была проблема то есть покупка лицензии Возможно это могло принести какие-то проблемы либо покупка через третьих лиц Еще бы сильно еще более увеличило стоимость этой системы конечно хотелось как-то вот уйти от этих вот проблем привязанностей к лицензированию и в общем-то доступности продуктов далее были проблемы потерями логов причем такого рандомного достаточно характера то есть на каком-то Хосте kubernets of какой-то момент с какого-то определенного тампода переставали просто-напросто доходить логи то есть вот каким-то таким не особо частым это было явление но тем не менее оно было Мы в общем-то как-то анализировали флинбит в общем-то в этом был виноват на самом деле они эластик по итогу как-то смотрели дебаглоги пытались общем-то тюнить буферы прочие какие-то вещи обновляли флюин биты в общем-то чему какому-то хорошему это не приводило да то есть проблема оставалась и хотелось ее конечно же тоже в новой схеме как-то порешать далее были некоторые более с написанием авертов да то есть конечно же кебана позволяет нам создавать альерты можно веб-интерфейсе довольно просто накликать любые там нужные нам оллерты Но конечно же хотелось подхода configuration за кода где у нас есть код какого-то авертом и скарбля vpi соответственно эластика или там кебаны Вот и у нас соответственно Все работает но Конечно же это позволяет делать пластик но там проблема в том что во-первых это Джейсон это уже не очень красиво с точки зрения человека такой довольно вырвиглазый и когда их довольно много этих авертов можно легко запутаться с этими огромными портянками Джейсона где-то что-то не так поставить и в общем хотелось примерно того же Как это сделано прометеосе да то есть там довольно все логично явно формате вот работает и вот что-то такое хотелось тоже привнести далее были некоторые костыли из deadlatorque немножечко расскажу что это такое соответственно это некоторые плагин внутри блок Стеша которые нам позволяет сообщения которые по какой-то причине отбились эластиком то есть например довольно частый случай когда у нас идет сообщение в нем есть какое-то поле вот и оно например сначала приходило допустим Вале level Да приходила в виде текста потом в какой-то момент каком-то сообщении оно стало приходить в виде числа соответственно это конфликт типов соответственно ластик в индекс один и тот же так и сообщение не пропустит и в обычном случае у нас этот блок просто-напросто дропнется с помощью мы можем как бы второй шанс дать этому сообщению через эту очередь прогнав и соответственно допустим не парсить сообщение просто в виде текста загнать какой-нибудь другой индекс а потом проанализировать посмотреть почему у нас осталось в правильной ну и соответственно при работе такой очереди rockstage складывает все эти сообщения рядом под собой да то есть прямо на диске И к сожалению он не умеет это дело ротировать то есть у нас вот это вот штука постоянно Копится размер диска соответственно увеличивается то есть размер этих файлов соответственно увеличивается просто так их к сожалению удалить нельзя потому что там проверяет какую-то целостность То есть он сразу начинает ругаться и в общем-то чуть ли там не официальный варкраундом было это типа Напишите в Pay плане там волшебную строчку которая Просто каждый раз проверяет занятое место если оно больше какого-то условия Удалите нафиг директорию и рестартаните blackstage то есть И тогда все будет классно Ну соответственно решение не очень красивое Особенно это в кубе Мы заходим Там постоянно рестарты растут ухода флокс США и можно просто как-то иногда может реальная ошибка затеряться где-то да то есть у нас почему-то под А может быть по какой-то реальной прямо проблеме далее Это индексация лейблов имеющих точек это опять-таки тоже связано с предыдущим пунктом то есть ну приведу такой простой Пример например у вас лейблов губернации есть допустим лейбл АПП там двоеточие какой-нибудь там слово да то есть это портится как текст это поле Вот но например если у нас есть лейбл там App точка cubernets.io там слышно им в таком случае вот это вот уже АПП сообщение с таким вот он будет уже распознаваться как object и соответственно опять-таки произойдет У нас конфликт типа в полей опять-таки и так далее Что здесь мы пытались сделать соответственно как-то получить разработчиков все-таки писать лейблы без там точек Ну то есть чтобы не с конфигурации не было добавляли различные плагинчики блок Station Да там есть которые там позволяет в общем-то точки в определенных лейблах поудалять точнее поудалять а заменить на что-нибудь это отчасти он это опять-таки руками нужно заносить Ну либо возможно какие-то делать политики в кабинетси которые будут валидировать до наши ресурсы прежде чем их туда задеплоид Но это отдельная работа это нужно впереди плаевать там приложение и так далее То есть тоже какое-то целый процесс и время отнимает вот собственно говоря вот этот весь набор проблем побудил нас поискать какое-то другое Решение вот этот этим другим решением у нас явилась графа на Локи справедливости ради сразу скажу мы не проводили прям какого-то основательного сравнительного анализа различных систем то есть там как минимум хотелось иметь какой-то Open Source систему Да без необходимости лицензирования и возможных проблем с ней да то есть здесь ну не так много хороших серьезных продуктов которые Это позволяет сделать агрофана Локи Несмотря на то что довольно молодая но уже достаточно зрелая то есть зрелая система Ее уже используют и поэтому почему бы нет Она нас нам понравилась что было в принципе Она нас удовлетворяла немножечко расскажу про блоки да то есть как Какие особенности у него как он устроен соответственно Локи Это примерно так же как прометеос только прологи в том смысле что он работает с данными очень похожим образом Да если у нас Метрика прометеосе состоит из названия метрики набора лейблов значение какого-то но и временной метки то в локе у нас соответственно это идет само сообщение в виде текста набора лейблов которые также являются и индексами да Ну И в общем-то тоже какое-то временной метки Вот это делается на самом деле процесс доступа к логом очень похожим на Прометей с аллерты забегая вперед тоже довольно похожими и так далее это у нас опенсорб продукт да то есть часть проекта под Апач 2.0 часть проекта под hpl находится поэтому здесь вроде проблем нет в плане использования никаких фич докупать не нужно Все работает в общем-то бесплатно далее мы индексируем действительно не весь не все наше сообщение в отличие от ластика Да а только какие-то определенные поля которые мы выбираем сами это могут быть как раз таки метаданные то есть название например Хоста название нам Space А название подано в принципе все что вам нужно Почему вы часто ищете Вы можете загнать в эти самые метаданные тем самым индекс у вас будет не очень большой в отличие от эластика Да где например индекс может занимать каких-то случаях больше чем сами данные Каким образом мы уже экономим немножечко место далее Локи у нас хранит данные в чанках в сжатом виде на каком-то сторон соответственно это сжатие позволяет нам тоже сэкономить место они говорят Там примерно от 10 раз по сравнению с эластиком у нас на практике где-то раз шесть семь получилось сэкономить при том же объеме до сообщений они как в прометеосе дальше покажу примерчик прям очень сильно похоже и наконец это микросервисная архитектура то есть Локи можно запускать скажем так двух режимах в режиме Монолита где у нас бинарник отвечает прям за все все Ну примерно как прометеосе да то есть он принимает сообщение Он и нам отдаёт сообщение работает со сторожем обслуживает аллер ты все все делает как бы сам также есть дистрибьютор вариант где каждому бинарнику можно задать определенную роль и в такой собственно в таком варианте мы стали инсталлировать Локи собственно немножко про архитектуру как он как она выглядит я оставлю буквально за скобками вернусь него в конце начну с цепочки записи это вот Верхняя верхний слой это дистрибьюторы а дистрибьюторы у нас принимают сообщения нарезают эти сообщения на стримы так называемый Стрим это по сути уникальная уникальный набор лейблов и их значение то есть из этого берется Хеш и присваивается соответственно айдишник в виде этого хешат стриму далее дистрибьютора У нас занимается ограничением полосы то есть мы можем для разных клиентов например настроить определенную полосу пропускания чтобы они там не аффектили друг друга в случае там какого-то увеличения потока Да например после этого дистрибьюторы передают эти данные на инвесторы придает они с определенным replication фактором Да чтобы в случае если инжектор у нас помирает блок все равно у нас сохранился никуда не пропал инвесторы занимаются у нас тем что во-первых нарезает начанки сообщения сжимают их кладут в кэш если это необходимо да то есть конечно в оперативной памяти находится рядом с инжектором И после этого естественно конечно же сохраняет на storage наши данные в качестве сторожа может выступать любой обжиг сторож да то есть это ис-3 там какой-нибудь Google storage Мы например используем яндекс.обжак storage так как у нас инфраструктура находится там также это может быть Кассандра это может быть Дай Немо де би Если вы и добавил S Используйте как-то так соответственно цепочки чтения у нас работают два компонента это акваре франтент и кювер соответственно ему приходит запрос он нарезает его на небольшие под запросы тем самым давая возможность распараллерить данным запрос чтобы кювера каждый подзапрос брал себе и соответственно ходил в кэш если это необходимо если у нас в крыше действительно находится данные за это время также конечно в сторону архивирует все это дело отдает кларе фронтендоре фронтенд слепляет и соответственно отдает ответ помимо этого у нас есть еще два компонента это рулер который как раз таки следит за тем выполняется у нас или нет триггеры по которым мы уже отправляем allertы aler ты мы можем отсылать на самом деле в тот же самый Alert Manager Это довольно удобно Если у нас уже есть например инсталляция premitels А ничего выдумывать не надо отправляем валят менеджер он дальше уже отсылает там по нужным каналам и последний компонент это compactor который выполняет функции lifecial Management а то есть по сути просто-напросто удаляет нам старые сообщения старше там определенного периода со стороны и наконец Gateway он не является компонентом как бы Локи Да это просто на самом деле же X но он выполняет одну важную функцию просто единое некоторой точки входа единого прокси где у нас и клиенты к нему ходят и соответственно клиенты смысле на запись клиент На чтение к ним уходит и это некоторые такая вот единый поезд скры там всю архитектуру нашего Локи Вот кроме этого еще на самом деле есть крыши и их на самом деле очень хорошо бы использовать если мы хотим получить больно если мы хотим получить Ну вменяемую скорость до запросов соответственно мы можем кэшировать чанки мы можем кэшировать сами запросы можем кэшировать индексы Вот для этого можем использовать HD можем использовать радиус соответственно можно дополнять эту схему движемся дальше так немножечко про то как нам обращаться к данным блоке для этого придуман собственный язык который называется loql вот здесь простой достаточно пример обращения Запрос к нашим логом по например индексируемым полям то есть индексированные поля это по сути дела лейблы И как мы видим здесь очень похожий такой момент с тем же прометеосом да то есть мы фигурный скобках что задаем какие-то лейблы получаем ответ Мы конечно же можем задавать значение по маске как-то Да ну то есть примерно так же как выбрано это все После этого мы занимаемся уже каким-то поиском в тех текстовых сообщениях которые уже Нашлись по индексу да то есть Локи у нас хранит данные по сути дела в тексте в отличие от ластика где-то Джейсон объект соответственно полна текстовый поиск может выглядеть таким образом Да здесь мы ищем любое вхождение API то что у нас нашлось далее мы можем применять некоторые модификаторы к нашим текстовым сообщением То есть например если мы знаем что наше сообщение в формате Lock fmt находится там же со в каком-то таком мы можем применить соответствующий модификатор и далее уже искать по полям да то есть уже Прямо как кибани например по полям прямо производить поиск если у нас значение полей например числовые мы можем еще использовать какие-то математические операторы сравнения там больше меньше и так далее Вот как то так вот это выглядит аллер ты как выглядит аллер ты но я думаю те кто хоть раз писал Alfa для прометеуса тут в общем-то скажешь что Ага прям что-то очень сильно знакомое и будут правы потому что они абсолютно такие же то есть мы можем точно также применять гравитационные функции правда не все конечно как промете Но тем не менее нашим логам да то есть Считать какие-то рейты Считать количество документов которые у нас подпала под наш запрос соответственно суммировать Вычитать делить складывать так далее Ну и понятно дело сравнивать чем-то что будет являться нашим триггером вот собственно Это довольно Прикольно Это довольно удобно Как выглядит интерфейс в общем-то как визуализируется логин вот так они визуализируются в общем-то примерно как и бане ничего сильно нового да то есть каждый Блок Мы можем развернуть посмотреть что там внутри чего состоит в общем-то тут довольно Все просто помимо этого помимо этого у нас появляется возможность например встроить наши логи в дашборды да то есть например как просто в виде портянки логов так и например строить целые графики Да из наших логов используя агрегационные функции тем самым мы совмещаем и соответственно и метрики и логи в каких-то единых даже бардак То есть у нас система становится как бы полнее в одном наблюдаемость скажем так в рамках одного дошборда Собственно как то так немножечко вернемся к тому как мы производили миграцию Теперь мы производили следующим образом то есть у нас по-прежнему логи собирались сподов в кафку И после этого у нас работала какое-то время параллельно две схемы то есть та схема которая показывал предыдущем предыдущих слайдах и соответственно новая схема где локсте уступил место вектору да то есть Вектор агрегатор Здесь нам это позволило довольно неплохо снизить требования к ресурсам примерно в два раза меньше при том же объеме потребляет Вектор при тех же собственно манипуляциях после этого Вектор соответственно у нас уже записывает данный блоки дистрибьюторы это все дело мы видим графане Вот кроме этого мы заменили бит точно также на Вектор называемый Вот это нам действительно позволило вот этих вот не доставок каких-то логов с каких-то поводов рандомных и там тоже на самом деле были кое-какие проблемы действительно Вектор тоже в какой-то момент приставал отсылать Локи сподов там с новых таких особенно на некоторых астах но эта штука она была пофикшена в апреле этого года версии 0.21 и соответственно с тех пор как мы обновились на неё там было перепили на библиотечка другую Они использовали для взаимодействия с губернатосом так если интересно можно найти в общем почитать и соответственно все заработало в нашей схеме проблемы больше с доставкой логов каких-то не имели используя вектор и какие в общем-то еще проблемы мы такие шишки мы собрали по пути собственно миграции по пути тестирования нашей схемы Но и первое недостаточная пропускная способность на запись действительно Сначала мы ее пытались решить вертикальным масштабированием горизонтальным увеличивали количество наших компонентов дистрибьюторов инвесторов и так далее То есть отчасти Это помогало отчасти конечно же есть ряд программных ограничений на которые стоит точно обратить внимание Вот так вот они выглядят да то есть это ingation Raid все это в мегабайтах То есть это вот дефолтовое значение какие есть и их очевидно Будет не хватать для какой-то серьезной продакшн инсталляции их соответственно нужно увеличивать то есть прям Смотреть насколько у вас трафик упирается в полку там да этих значений на Потах далее Это дропы чанков когда мы используем как раз таки кэш и например скажешь происходит какие-то проблемы он становится какой-то допустим недоступен либо он начинает отвечать медленно по идее по-хорошему должен вроде как срабатывать какой-то Rocket Breaker который Ну как бы нет кэша Ну и ладно я все равно буду записывать данные в storage буду ругаться но тем не менее работать буду но к сожалению не так хорошо Это отрабатывается в инжестере и действительно у нас были потери из-за этого в общем-то чанков сообщений порешали таким вот образом довольно нехитрым просто-напросто увеличили тайм-аут мы используем радист поэтому крутые тайм-аут рейса по умолчанию 500 миллисекунд это довольно немного то есть увеличение где-то до секунды нам эти проблемы с него То есть если подтупливает то можно Вполне себе это увеличить и проблемы уйдут далее были проблемы конечно же и с запросами были у нас тайм-ауты которые мы также пытались обходить вертикальным горизонтальным масштабированием соответственно компонентов которые за это отвечают но и программные штуки есть которые тоже стоит подтянуть стоит обратить внимание на параллелизм это параметр very frontendo да то есть по умолчанию он стоит 10 Это довольно таки немного То есть можно выкручивать там несколько раз целом больше Вот и уже будет более производительный поиск происходить есть лимиты разбиения на подзапросы то есть по временному интервалу да то есть мы можем нарубить под запросики там по 10 минут например и соответственно параллельно это все обработать этот параметр тоже можно подкрутить чтобы у нас быстрее происходили запросы Ну и конечно же это шикаши то есть Локи Действительно это его слабое место по сравнению с тем же ластиком он не очень быстро в целом на чтение да то есть наших логов не может занимать там полтора-два раза больше соответственно пиши этот момент снимают какие-то более старые данные Да действительно будет отдаваться тем не менее медленнее потому что Ну понятно за кэшировать все невозможно Да там за месяц памяти не хватит что еще тюнили это конечно же все возможные тайм-ауты по умолчанию они в локе не очень большие то есть 30 секунд реально могут выполняться запросы и дольше То есть это нужно иметь ввиду Соответственно мы тянем http различные тайм-ауты тайм-ауты на query да то есть тоже стоит увеличить также не стоит забывать если мы используем их сапотюнить тайм-ауты на нем Да так как это прокси и конечно же по тюнинг тайм-аут из самой графа не там есть да это прокси такой как бы блок и соответственно там есть глобальный параметр тайм-аутов на все Data Source входящие в него и он там тоже около 60 секунд это тоже может не хватать соответственно быть каким-то бутылочным горлышком далее Это превышение лимита размера сообщений вот выглядела Это примерно таким вот образом то есть при поиске например в какой-то момент мы сталкиваемся с ошибкой что наше сообщение довольно большое оказывается и не пролазит просто-напросто это было и при записи на самом деле всю эту штуку можно потюнить опять-таки в конфигурации Локи есть вот такие вот параметры соответственно отправку на прием сообщений по умолчанию не очень большие Если вы понимаете что ваше сообщение реально могут быть размером больше то тоже стоит обратить внимание это дело увеличить и последняя проблема с которой мы столкнулись и которая скажем так пока полностью нам не поддалась в плане решения используем некоторые ворка раунды это проблема с агрегацией на Большом временном диапазоне да то есть например если мы хотим какие-то посчитать аналитические данные например там со слогов до нашего балансировщика по например какому-то не индексируемому Полю за там какой-то большой промежуток времени там не знаю за неделю за месяц там Тем более это может происходить Ну типа бесконечно может происходить покинуть это ну вот кошами тоже вроде бы такой кэш не сделаешь каким-то еще образом пока думаем и пока слава Богу кейсов было таких немного буквально всего один для этого у нас просто напросто развернут один маленький кластер ластика без лицензии там буквально с минимальной конфигурацией чтобы вот только с этим кейсом работать только с этими логами вот Пока так собственно это что касается системы логирования Вот про плюсы Я уже скажу в конце Вот пока пока поговорим немножко про трейсинг соответственно Как выглядел трейсинг у нас в начале нашей миграции тут со слайдов к сожалению у нас пропал Игорь Агент то есть мы используем егер для трейсов агенты отправляют точно также перенаправляет наши трейсы соответственно в кафку оттуда инжекторы опять-таки егеря их берут и сохраняет кластер эластик Search соответственно кластер естественно другой как бы отдельный отлогов был далее мы это все визуализировали в первую очередь через ебаное еще можно было сделать а собственно какие здесь основные цифры можно привести Это примерно 300 Гб соответственно трейсов в сутки набегала Это примерно 5000 спавнов в секунду валилась наша система трейсинга и где-то около 5 Data not использовалась на кластере немного не мало соответственно Какие проблемы были но опять-таки проблема очень похожие да то есть это и потребление ресурсов ластиком довольно серьезные это конечно же и доступность продуктов все примерно похоже Ну и все-таки разные интерфейсы да то есть мы для метрик использовали для визуализации метрик использовали графа Ну там смотрели для локов использовали кебану для трейсов использовали егерюай соответственно это не очень удобно Это увеличивает время в общем-то разбора инцидентов когда мы постоянно должны прыгать из одной системы в другую хотелось какой-то связности иметь плюс К тому что мы уже логики и метрики по сути дела объединили в одном месте в общем-то Почему бы и нет Попробовать еще один продукт и соответственно этим продуктом стала графа на темпа он еще такой прям более свежий чем блоки буквально два года назад и в общем-то решили попробовать его да то есть первое что мы поняли что темпы не только шоколад Да но и система распределенного трейсинга система хранения чем она Какие особенности у нее чем она характерна Ну во-первых она совместима со всеми популярными открытыми протоколами трейсинга То есть это тот же Егерь это zipkin это Open телеметрии соответственно принцип работы очень сильно похож на Локи то есть мы точно также данные храним в чанках точно также режим точно также храним на обжиг сторожем и там сжатие на самом деле работает даже получше то есть примерно реально в 10 раз по сравнению с ластиком место у нас уменьшилось занимаемое и конечно же он хорошо интегрируется с прометеосом в плане метрик своих для отдачи конечно же с Локи с логами потом покажу как это выглядит Ну и конечно же с графаной тут как бы понятно по архитектуре примерно Один в один что и Локи это тоже круто То есть можно не изучать с нуля какой-то новую систему здесь все очень похоже и даже компоненты называется как бы однообразно поэтому здесь я сильно Останавливаться не буду они выполняют все те же самые на самом деле функции только не троллера Да потому что у нас нет аиртов потрейсом здесь вот так вот выглядит у нас Trace с помощью графаны выведены развертка здесь временная Да ну выглядит на самом деле примерно так же как и в любом другом любой другой системе трейсинга здесь на самом деле ничего особенного также мы можем конечно же смотреть notgraph который показывает нам Граф прохождения запросов по компонентам время этих запросов и так далее но в целом тоже ничего как бы нового ничего Сверхъестественного искать Мы также Можем по 3 сойди можем искать по названию сервиса как-то фильтровать да наши трейсы и так далее и так далее и в общем-то какая прикольная фича есть именно когда мы используем Локи и используем соответственно темпа вместе мы можем настроить в логах где у нас присутствует Trace ID до поля привязку собственно ссылку на поиск темпа то есть вот можно слайде видеть есть там такое поле 31 рядом с ним такая голубенькая Синенькая кнопочка которая появляется автоматически мы допустим находим какой-то Лог и хотим посмотреть связанные с ним трэйс то есть нам не нужно идти в какую-то другую систему её там открывать мы просто тыкаем на кнопочку рядом в том же рабочем пространстве у нас возникает в общем-то наш трейс и мы можем сразу же вот видеть в Едином рабочем пространстве и Трейси Лок и в общем-то это ну довольно удобно довольно быстро позволяет там инциденты например какие-то решать теперь немножечко как схема у нас стало выглядеть опять же мы делали такой же вариант миграции как слогами да то есть мы параллельно разворачивали две схемы точно также у нас Игорь агенты остались в качестве отправщиков наших спадов наших трейсов кафку и после Кафки рядом со старой схемой начала работать новая то есть здесь уже графа на агенты как консилеры выступали соответственно они собирают рейсы сказки перенаправляли их темпа Ну и далее уже графане Мы это дело смотрели также дистрибьюторы в темпа могут выступать консилмерами на самом деле для Кафки И вероятно такой вариант мы будем использовать в будущем Да чтоб отказаться от какого-то лишнего момента венерофана агентов Посмотрим это приведет пока схема выглядит примерно следующим образом Ну естественно и здесь не Обошлось без каких-то шишек без каких-то проблем узких мест Ну и наверное самая такая большая проблема которая нас Возникала это достаточно низкая производительность на запись собственно прямо приходилось очень сильно масштабировать компоненты дистрибьюторов и инжекторов и например сравнение с инженерами егеря То есть это Примерно там ну там с 10 примерно егерских около 60 дистрибьюторов у нас получилось в темпа довольно много но тем не менее это все равно меньше мало ресурсов чем кластер ластиком надо понимать Ну и топиков и партийцы соответственно тоже пришлось довольно сильно раскукожить в Кафки для этого чтобы прореализм этот самый сработал также мы в общем-то тюнин или некоторые параметры Но вот так вот например у меня начиналось утро да то есть когда я заходил в кафку начинал смотреть лак собственно который постоянно рос да то есть консилеры реально не успевали разгребать очередь в Кафки и она вот прям устремлялась вверх каждый раз масштабирование какой-то тюнинг более пологим график становился но это дело у нас выправлялась в общем то что я еще тюнил чисто с программной точки зрения это опять-таки полосы пропускания Да вот эти вот enges шины bersize рейты максимальное количество байт пертрейс также нам посоветовали еще один параметр который кстати почему-то упущен в официальной документации уже разработчики потянуть это вот ремоу тайм-аут то есть тайм-аут между дистрибьютором и инжектором то есть его тоже стоит увеличивать потому что инженеры не всегда за 5 секунд реально успевает отвечать и это возникает и дропы проблемы соответственно вот нам в одной из ишью предложили это увеличить это тоже в принципе отчасти нам помогло вот собственно это такая наверно основная проблема которая вот у нас была все остальное в принципе решалось теми же кашами то есть ну поезд не такой долгий как пологам все-таки и здесь принципе кэшей нам достаточно неплохо хватало в плане поиска по Trace как то так и собственно заключение хочется подвести немножко итог Какие плюсы у нас удалось каких плюсов удалось достичь Ну во-первых это конечно же уменьшить стоимость системы как я уже говорил в самом начале Это примерно около 8 раз для системы логирования около пяти раз для системы трейсинга неплохой целом результат далее мы отвязались от проблем с лицензированием Так как эти проекты полностью опенсорсные пока вроде платными не собираются становиться плюсом здесь еще маячит возможность использования в качестве хранилища метрик еще один продукт это графа на мир некоторые такой замена прометелся Ну это уже может быть следующих на следующей конференции что-нибудь такое расскажем вот Идем дальше это все-таки объединение всех аспектов мониторинга основных метрик трейсов и логов каком в Едином месте в Едином пространстве именно в графане Это довольно Круто Это довольно действительно удобно альертинг сделали Как в прометеосе да то есть aler ты полностью такие же ими удобно управлять писать И общем-то как-то поддерживать ну и наконец это настройка автомасштабирования компонентов так как это все микросервисное легко запускается в cubernets и соответственно Да можно накрутить различные горизонтальные автоскейлеры которые будут у нас там например по нагрузке потому масштабировать наши компоненты и соответственно система будет жить и увеличиваться по необходимости конечно же остались минусы вот ну во-первых это действительно время выдачи не за кэшированных данных Но прежде всего логов да то есть если мы Обращаемся к тем данным которые у нас не в кэше это будет Ну раза в два в полтора может быть больше чем пластике да то есть там не 10 секунд условно 20 секунд придется подождать но здесь можно немножко изменить подход например и помочь Локи в плане выбора временного диапазона для поиска да то есть если власти мы допустим знаем что при инцидент произошел на прошлой неделе можем бахнуть просто за прошлую неделю запрос и он нам в целом довольно быстро ответит в локе же Ну если он примерно знаем В какой день инцидент произошел лучше Вот сузить этот Круг поиска там например в среду какое-то время произошел То есть Не стоит искать за неделю поискать за какой-то все-таки более узкий диапазон и это ну каким-то образом все-таки поможет это время выдачи агрегационных данных про это я уже говорил К сожалению по опять-таки большим временным периодом агрегации строятся довольно проблемно как бы это пока есть вероятно как-то они с этим будут Надеюсь бороться в будущих версиях Ну и производительность сохранения спанов Пока действительно оставляет желать лучшего приходится действительно очень сильно горизонтально масштабироваться и тоже есть какие-то надежды что в темпа это поправят тем более что продукт достаточно молодой и будем ждать надеяться на лучшее собственно я думаю это все что хотел рассказать Всем спасибо за внимание и вопросики Сергей спасибо еще хотел бы отметить что Локи это наверное такой гриб по распределенным файлам Когда у вас на сервер лежит 10 тысяч файлов текстовых И вам нужно что-то найти его делать сгреб регулярку и звездочку что-то похожее вопросы есть Можем на какие-то попробовать ответить на остальные лучше в дискуссионные комнате Какие еще мы систему рассматривать в качестве замена Елка и ФК и смотрели мы в opensearch тогда не было но мы смотрели опендиста да мы смотрели опендистрей Даже внедряли его но были там некоторые проблемки опять-таки не очень хорошо там Сделано кебана в плане Нет там например автодополнения Но это все конечно вкусовщина можно и без этого прожить плюс некоторые проблемки с работой Асема да то есть это лайфхакл менеджмент Open дистара не так он все-таки хорошо работает и не весь функционал реализован например блоксты Шеф в том же и так далее и так далее То есть были некоторые нюансы И после этого мы все-таки до решили перейти на лицензионный ластик других систем как я в принципе уже говорил особо мы не рассматривали как то так у нас были приведены суммы затрат и вопрос откуда они у нас есть стоимость чего в Яндекс облаке поэтому стоимость это собственно стоимость виртуальных машин Ну да виртуальных ресурсов CPU памяти сторожа там это все можно посчитать действительно и сравнить Я не знаю лучше как реализована ролевая модель доступа к логам если разным командам нужно предоставлять доступ к разным Можно ли это сделать в Локи Да это можно сделать осуществляется это на организачно Найди да то есть графа не у нас есть организации на которых мы можем поделить доступ Точно также мы можем наши логи соответственно помечать определенным организация Найди при записи и потом если пользователи имеет соответственно доступ к нему он будет соответственно получать доступ к блогам соответствующим на основе а какие у нас размер ноты использовались эластика что-то в районе 8 пью там 32 ГБ памяти но и где-то по 4 ТБ по моему это вот я имею ввиду то есть мастера понятно похудее там координаторы похудеем Вот это так вот по размеру документов ничего не могу сказать помню этих данных У нас они записаны форматы логов никак не регламентированы более того с разработчиками не раз проводили общение на эту тему но это все дружно забивали делали логи так как Им удобно из-за чего собственно возникало очень много проблем В общем все я думаю досталось буквально здесь кто хочет пообсуждать Локи темпа приходите с удовольствием поговорим пообсуждаем и расскажем дополнительные вещи которыми нам удалось поработать"
}