{
  "video_id": "oS2FaPGcKko",
  "channel": "DevOops_conf",
  "title": "Евгений Дехтярёв — Есть ли дружба между железом и облаком?",
  "views": 146,
  "duration": 3510,
  "published": "2022-07-06T04:09:03-07:00",
  "text": "привет друзья спасибо что присоединились к нам сегодня меня зовут алексей и я отвечаю за инфраструктуру в контуре сегодня я буду вашим экспертом на этом докладе я буду передавать ваши вопросы к докладчику пишите их в чате я за всем буду следить и мы потом обсудим это все в дискуссии и со мной сегодня мой можно сказать коллега он тоже отвечает за инфраструктуру и работать тем же дом инфраструктурной команде но в компании 2гис бенедиктов привет жене я шпет всем привет зрение у нас сегодня не впервые он уже можно сказать наш постоянный докладчик он был у нас год назад с докладом тоже про губернатор на своем железе он назывался кубинцы с вами железе плюсы и минусы и котики если я правильно помню вот замечательный был доклад это же был на нем экспертом мне очень понравилось и потом было по моим довольно продуктивную дискуссии вот а сегодня через год примерно мы встречаемся снова и эта тема это такое логическое продолжение как мне кажется то и тему потому что тогда это было речь про поверни таз на своем железо да сейчас эта речь про купер нас не только на своем железе но и кулер не тот который немножко краешком или большой даже частью своей вылезает в облака это доклад про гибридные облака по сути и я с нетерпением жду послушать его и потом пообщаться с женей женя тебе слово далер спасибо большое очень здорово все подвел да это именно та тема я сегодня поговорю о том почему нам пришлось дружить нашу всю железную инфраструктуру большую с облачными технологиями давайте начнем всем привет давайте я сначала расскажу общая команде которая этим всем занималась и о наших ребятах которые получили опыт и вот это все развивали наша инфраструктурная команда она поддерживает общее большое облако кубера в нашем 2 gessi мы его очень любим хотим туда процентов 90 всех внешних приложений уже почти большинство внутренних перевели также мы очень любим под груз у нас большие кластером ребята имеют опыт эксплуатации и обслуживания и обновлениях понятно что как и все мы логе елка стеком собираем метрики прометеем но к сожалению примет ее уже не было возят и мы с него начинаем переезжать может будущем об этом расскажу между делом любим что-то походит на питоне нога лэнге и всю эту инфраструктуру как кот мы храним в git лобби и очень любим раскатывать все автоматическим pipeline нами и то в конце у нас давайте вообще о чем мы сегодня поговорим такой небольшая карта мы сегодня поговорим есть любовь у нас между тем что у вас например очень большая собственная железная инфраструктура и вам понадобилось что-то из облаков туда подтянуть и как это все вместе свести чтобы это было недорого чтобы это было недорого нет несложная операционно и какие проблемы могут у вас при этом возникнуть ну естественно будет когда постановка задачи я расскажу вообще о нашей инфраструктуры чуть больше чтобы у всех было понимание и они могли сравниться своей инфраструктурой это дело то как мы решали задачи расскажу я расскажу о том какие мы решения выработали чтобы унифицировать работу виртуальной и физической инфраструктуры и сделаю выводы какие сделали мы каждый сделает их сам для себя давайте собственно задачей начнем как многие знают к нам год назад пришел большой заказчик и поставил четкую задачу ребята вам нужна гарантированный солей три девятки в принципе у нас слой всегда был сто процентов на гарантирован от пятки не было поэтому пришлось эту задачу порешать вместе с тем он собственно сказал что к вам придет трафика в несколько раз больше то есть и тафты в пять раз больше на некоторые сервисы это примерные цифры я привел чтобы вы могли сравниться со своими явно проговорили мы заказчиком требования к надежности скорости ответа то что при увеличении трафика явно ничего не должна снижаться и все должно работать как как будто трафика и нету и также нам была поставлена такая одна из целей это выдерживать ситуационную нагрузку от сервисов экосистемы заказчика то есть например когда в москве неожиданно выпадает снег и все начинают заказывать такси такси и не выдерживают мы должны выдерживать ну или как-то так и ну и чтобы вся все работали это все хорошо но мы как бы любим за составить себе задача дополнительные поэтому мы которые задачи за собой три девятки такую задачу со звездочкой себе еще поставили чтобы это все в рамках нашего 2 дес опровергнуть естественно можно было решить эту задачу легко у вас просто есть много железа вы покупаете еще много железа добавляете его у вас все хорошо и даже если что-то падает вас все продолжает работает на к сожалению безлимитных денег у нас нету и такую задачу провернуть мы не можем мы для себя поставили что у нас дата-центров много покупать железо во все дата-центра довольно таки дорого поэтому мы выбрали 2 и должны переживать как минимум выход 1 дата-центра из работ ну и понятно что нельзя нельзя скажем так downshift это то есть мы можем в принципе а не давать где-то ресурсы далеко от клиентов это будет дешево для нас удобно для нас но для клиентов это будет довольно таки плохо и поэтому мы не можем там в юар и взять сервера и сказать вот теперь вы ходите туда зато нам дешево и там все отказоустойчивых окей канал и там между россией и аромата уже неважно не наши проблемы как перец и самое главное для команды собственно кто поддерживает всю эту штуку ей это должно должно быть удобно то есть нам нельзя растить операционку которой в принципе с нашей инфраструктуры и так достаточно то есть мы не можем взять и нанять себе еще еще одну команду инфраструктурой которая будет поддерживать вот вот эту всю вот эту всю новую инфраструктуру для достижения цели давайте более конкретики перейдем какие у нас вообще вводные были по паном то есть с чем мы с чем мы с чего с чего мы начинали какая наша инфраструктура у нас получается есть пять дата-центров это ну не собственный дата-центр это colocation в каждом мы арендуем стойки и вставляем туда свои купленные сервера на все эти пять дата-центров у нас растянута наше облако openstack где мы можем где мы можем заказывать виртуальные иисус и то есть нас в принципе гибридная гибридная схема работа она уже она уже была только она была между нашими ресурсами и нашими ресурсами сейчас мы подключаем внешне в каждом в каждом дата центре у нас есть независимый классов куперов который тепло ятса приложение эти люди планеты туда куда им нужно и также в каждом в каждом дата центре у нас есть база база на полюсе о которых мы сегодня поговорим и вот из этих пяти дата-центров нам нужно выбрать два конкретных где мы будем развивать наши ресурсы чтобы достигать поставленной цели понятно что хотелось бы достичь эту цель в рамках всех дата-центров но давайте начнем хотя бы с малого как только достигнем в этих двух тогда уже будем раскладываться на остальные мы выбрали два конкретных дата центра и в рамках них можно нарастить ресурсы и в том и в другом в принципе это вполне нормальная такая схема эта схема чтобы переживать нагрузку которая просто придет к нам для ситуационные нагрузки нужно еще уметь быстро стартовать новые ресурсы то есть если у нас став железного сервера составляет там например полчаса-час от момента получения этими я до ввода серверов пластик куба то здесь нам нужно за две минуты стартовать уже ресурсы которые готовы принимать на себя приложение трафик и между делом еще решая эту задачу нам нужны иногда спать по ночам то есть не растить операционку и не умеете в потоке новых задач давайте вообще притянем возможности что мы можем сделать то есть нам нужно арендовать нам нам нужно именно приобрести железо какое-то и арендовать виртуальные ресурсы чтобы получить железо быстро понятно что я в прошлом году рассказывал дакар плюшева не упоминал там есть pipeline такой скорость доставки железо от заказа до поставки к вам и это идеальный случай когда там за 60 90 дней к вам придет купленная вами железо к сожалению в наш пьют когда у нас с полупроводниками проблемы и даже гранты заканчиваются на производстве этот pipeline сейчас растягивается до полугода и может растягиваться еще дальше это это это реальная проблема и на заказ железо сейчас очень сложно положиться поэтому мы выбрали такой путь что мы это железо арендуем и здесь получилось так удобно что в одном из дата-центров где мы постимся есть возможность арендовать железо прямо арендуем соседней стойке с нами делают коммутацию с нашим же с нашим же сетевым оборудованием то есть там и железо и сетевые сетевые железки тоже на предоставляют и мы пользуемся этим делом прям вот как своим как будто купили она приехала и мы прям flow не меняется вот как мы этим пользовались год назад так мы пользуемся сейчас и на самом деле вот голое железо сыпь имеем это по-моему это самое дешевое вообще что возможно взять то есть там никаких накладных расходов у провайдера кто вам предоставляет от оборудование поэтому она максимально дешевой для аренды и это решать задачу со звездочкой в экономии если мы хотим если говорить о том что мы хотим ресурсы предоставлять получать очень быстро то понятно у нас путь заказан в какие-то облака так повезло что в нашей экосистеме есть один из провайдеров этот мир клауд с кем мы успешно начали проводить эту историю во втором дата-центре где собственно нам необходимо было селить наше приложение мы договорились коммутировать на ну договорились на напрямую коммутацию между их центрами и нашими и получается что никакого вы point соединения никаких потерь на шифровки и дешифровки или лишних потерь на каналах у нас нету здесь подключились тоже может быть как своему openstack у вот примерно это так выглядела ну естественно в облаке получается ресурсов ребят много и мы можем заказывать их в любой момент но платим мы только когда эти ресурсы нужны ну собственно либо стандартная схема для облаков и когда мы получается выбрали когда мы получается выбрали два вида ресурсов которые нам нужны это железные виртуальные надо понять как нам это дело распыляет трафик в нем давайте посмотрим на вот от рисуночек если нас пользователь есть два наших дата-центра которые которым идет трафик если прикинуть наши возможности для скажем так и для отказоустойчивости и для задача со звездочкой виде экономии средств это мы мы договорились что вот так будем делать в одном дата-центре мы арендуем только железные ресурсы наращивая емкость до необходимых размеров которые обеспечат проход того трафика которая нам заказчик обещал а во втором дата-центре мы чуть-чуть максимум нарастим ресурса своими серверами которые к нам придут когда-то там например там через три месяца полгода и основная основной flow работа того дата-центра это будет переживать ситуационную нагрузку то есть он должен максимально быстро стартовать наши серверы серверы куба наши сервера баз данных чтобы принимать обрабатывать тот трафик который приходит в часы пик в часы когда ну когда какое-то событие происходит и трафик очень-очень лавинообразно растёт и собственно с таким мы договорились что раз у нас два дата-центра в принципе в обоих из них уже есть наше железо и она готова обрабатывать какой-то трафик и мы сделали распределение 2 когда два к одному чтобы 2 дата-центр тоже всегда был более менее теплым мы знали что в нем все приложения работают и в любой момент он был готов принимать остальной трафик на самом деле это выглядит как стандартная классическая схема мастер backup то есть у нас есть мастер который может обрабатывать почти все и backup на которые в случае чего мы с вич не мся и так же продолжим там работать но при том backup активный на котором за которой мы уверены давайте еще чуть-чуть упростим задачу потому что если говорить в рамках всего 2 дес где у нас там не знаю 500 сервисов 10000 кодов это это звучит довольно сложным потому что тут же работа не только за инфраструктурные вещей с приложениями поэтому нам нужно выбрать конкретное количество приложений которые мы будем для которого мы будем обеспечивать отказоустойчивость но это 56 приложений мы заказчиком их обговорили мы про них знаем и на них мы сфокусированы очень здорово что все эти приложения работают в кубе это прямо упрощает нашу работу потому что скелет мы будем только куб в куб я уже будут стелется приложения самостоятельным стандартными механизмами куба и часть из этих приложений они stateless но часть из них держат свои данные в подписи и получается что от производительности полюса тоже зависит производительность приложений то есть нам нужно что-то сделать с подвесом чтобы обрабатывать пользовательский трафик о master master data center что нам нужно добавить о чем вообще будем сегодня говорить нам нужно добавить в куб две сущности это worker ноды на которой собственно крутятся все приложения это такая общий котел где крутятся все приложения и мы просто в этот котел добавляем еще там дров и и приложение самостоятельно стелятся наверное в этом котле там там все легко и понятно и надо добавить еще роутер но трогать равно да это это ноды что-то типа где энгр с контроллера ваш крутятся и через эти ноты проходят весь трафик там проходит терминация с цель там проходят сжатии разжатия трафика и вот это вот все потому что это довольно таки ресурсоемкие вещи если туда приходят там 50 тысяч fps вам нужно там не несколько десятков роутеров чтобы сжатием заниматься ее соли терминации это ну довольно довольно ресурсоемкая штука на мастер также где мы арендуем железо нам нужно разобраться сколько нам добавить поздним с серверов мы их просто арендуем добавим в пул и все и по ним будут раскидываться трафик если будет не хватать мы будем в фоне проверять и добавлять по необходимости еще арендовать железки также когда к вам приходят к вам приходит задачи с тем что трафик на вас увеличится в несколько раз вам нужно задуматься не только о том кто у вас будет обрабатывать этот трафик но и о том обо всей вот этой вот обвязки вокруг ваших приложений на которую тоже будет сыпаться дополнительный трафик например к нам пришло дополнительно 10 тысяч fps понятно это 10 тысяч сообщений в секунду влоги но то есть если у вас система логирования держат там сто тысяч сообщений в секунду то к вам прилетит и счетом плюс 100 и возможно у вас будут какие то проблема здесь надо тоже за ложится на то чтобы система логирование система мониторинга были подготовлены к тому что у вас увеличится нагрузка увеличится трафик вот поэтому мы еще на всякий случай заложили дополнительные ресурсы чтобы эти система подпереть и они работали а вот это то что касалось это мастер сервера а вот мама мастер дата центра а вот в бэкапе мы не можем по понятным причинам закупить все заранее но чтобы это было дешевле поэтому нам нужно именно добавляет эти ресурсы автоматически и добавлять ресурсы автоматически мы на самом деле надо добавлять те ресурсы которые за которые отвечают пользовательские приложения ну то есть добавлять в пул добавляет ресурсов пул где крутится пользовательские приложения то есть если у нас немного притормозит инфраструктурной обвязка это не так страшно как если у нас приложение будет 500 в течение там не знаю получаса поэтому об автоматических добавлениях мы сужаем задачу только до трех компонентов это worker но ты где крутятся все приложения это роутер через который проходит весь трафик и эта база данных на которых собственно лежат данные которые мы отдаем через некоторые фишки давайте вообще начнем решать эту задачу с чего мы начинали вот еще прям вот еще конкретные на этих пяти дата-центрах у нас крутится безопаности к это где-то 300 железок 300 железок это именно куб базы данных монетами планирования все остальное все эти железки мы изначально загружали через но запускали через месяц то есть у нас есть собранные под нашу инфраструктуру образом и просто их монтируем вейпе имя и запускаем система устанавливается и мы дальше накатываем там тепло и анти блам что позор 100 куб в принципе это нормальная рабочая схема присед там 20 минут ставится еще там 20 30 минут идет тепло и какого-нибудь pipeline а который вам раскатает роль на ноду то есть добавление железки одно это около часа ну понятно что в наших масштабах когда на ситуационную преднагрузку переживать это вообще не дело то есть часа у нас нету и вот к этим 300 железкам нам нужно добавить что нам нужно добавить сотню железок мы но мы посчитали примерно что около сотни нам потребуется добавить вот один в один конкретный дата-центр нам нужно будет додуматься как делать автозапуска железок в другой железо по виртуальных ресурсов другом дата-центре а также когда у вас вот этот весь запах там в 400 железок на все во всех дата-центрах будет обслуживаться вам нужно добавить туда уметь обновлять весь этот зоопарк то есть добавить туда еще вот эту обезьяну которая будет ходить и гореть и ты постарел давай-ка обновись мы ну просто напросто мы сейчас говорим не о том что нам нужно обслуживать только вот эти вот 2 дата-центра нам нужно все равно мы от от оставшихся трех не откажемся поэтому нам нужно делать такие решения которые подойдут какой к этим двум dc так и к трём оставшимся иначе мы в операционке по грязным если у нас будет где-то по одному где-то по-другому где-то по третьему это реальная проблема так так не нужно делать надо стараться делать одинаково то есть мы добавляем такую-то такой обновляться not который будет ходить говорить а ты слишком постарел у тебя убунта там 2004 1 а сейчас уже 24 2 на дворе давай-ка и but nice и будь неси загрузить новые ubuntu и он это будет делать самостоятельно чуть-чуть попозже расскажу о нём подробнее и самое главное вот из того что у нас есть 5 дата-центров у нас есть минимум три разных корневых инфраструктуры это железные сервера это нашу pan stik и это сбер файл где мы будем брать виртуальные ресурсов со всеми с ними надо работать одинаково надо стараться работать одинаково иначе если у вас будет где-то висит где-то тира форм где-то анти был диплом и вам все эти три места надо как-то синхронизировать но кажется у вас проблема давайте решать наконец - конкретика закончились давайте к нашей задаче перейдем и посмотрим какие у нас вообще из варианты решения и и есть вариант простой мы оставляем все как есть ну просто вот в лоб то есть там при sit on se был диплом все остальное из плюсов это реально ничего делать не надо но проблема в том что тепло и нанси были масштабируются очень отвратительно то есть если у вас там сотня нот в диплом у вас уже ну и там и роли еще там 20 некоторые накатывает куб и все остальное то у вас проблемы с тем что у вас анти был проходит уже там около часа например если вы добавляете еще туда сотни not to как вы будете обновлять какой-нибудь один несчастный параметр на этих всех но дохну это либо очень пилить диплом сильно оптимизировать там упарываться в него но это сложно это реально много времени которая может быть потрачена впустую если вы перейдёте на какое-то другое потом решение тут же естественно если мы все оставляем как есть мы добавляем ноты руками там плюс 100 но ты-то плюс там месяца работой например неспешные инженеры который будет фоне добавлять эти но да если заказчик скажут что сейчас еще x3 от текущего трафика то это еще там плюс 300 not ну короче это выглядит как очень долгая и нудная работа и когда мы добавляем это все делаю руками тут получается такая штука что в мае мы мы сделали мы добавили там пять нот в июне еще шесть в августе 20 яна всех этих новых короче разные версии пакетов ядра и всего такого конечно это все можно обернуть то манси будем запилить версии ядра запилить версии пакетов но это все нужно делать и получается что и за этим нужно следить если там где то что то обновление не так пойдет вам еще нужны инциденты разбирать что с этим делать и получается такой лифт конфигурации not когда у вас в одном кластере ноты они вроде бы одинаковые но на самом деле разные под капотом и если мы оставляем процесс как есть то у нас есть как бы в кубе общий котел нот для каких-то команд мы иногда выделяем где стоит в приложении мы выделяем конкретные ноты и например процесс обновления здесь тоже довольно-таки тяжелый и долгий когда мы хотим обновить но ты какой-то команды мы идем в команде говорим что ребята в среду там с 9 до 10 утра мы будем проводить работы по на наших серверах вроде бы ничего страшного не должно быть но имейте в виду команда скажет о нет мы не можем надо подождать три дня тут или ступки и данный заливается но crochet вот это сложная штука нужно согласовывать потом нужно в правильном порядке прожать кнопки чтобы ничего не положить и заготовить команду чтобы обновить только их надо например это все также можно оборачивать в pipeline и делать там вот такой вот огромный список из этих кнопок но это такой рабочий путь но тяжелый в поддержке на мой взгляд есть еще один вариант который мы обсуждали это тоже оставляем все как есть но для авто скиллинга то есть для поднятия ресурсов за несколько минут для принятия на них трафика мы будем использовать не свой куб а куб как сервис то есть облака предоставляет нам возможность использовать кубка сервис прямо дает доступ до worker not где можно располагать свои ресурсы в принципе это рабочий вариант мы его обсуждали и сейчас проговорим про него удобно здесь то что мы оставляем все так же как есть это плюс то есть нам работы меню авто скейл получается можно сказать из коробки то есть нам ничего изобретать не нужно облако уже самостоятельно все изобрело там тоже работают инженеры которые все варианты проверили мы им доверяем и просто напросто когда не сможем защиту лить свое приложение или ноты будут перегружены облака самостоятельно будет увеличивать свой размер это здорово она просто в этом разобраться как это работает и все будет окей но на самом деле мы нисколько не несколько таких вещей посмотрели почему почему нам это может быть не очень хорошо во-первых так как это будет дополнительный кластер куба то а у нас кубы все независимые друг от друга каждые тепло лицу нужны нужный куб в основном тепло это все но если тебе нужно там только в один дата-центр это тепло из туда и один дата-центр не знают про второй ничего и тут получается еще плюс 1 куб то есть у нас их уже 5 боевых + 6 еще добавляется и нужно во-первых всем командам разработки донести о том что появился такой клуб как туда deep ловится зачем туда тепло и ца почему он появился где креды брать там как айпишник указывать данные с охоты то вот все короче говоря это дополнительная марокко что разработки что нам по документации обслуживанию есть также вопросы с аутентификацией у нас используются аутентификация через связка там лтп dex который нам так и она выдает для доступа в куб и это связка требует насколько я помню доступа к pi server как к письма миром куба а так у нас мы на джуд куб нам доступ к пенсионерам предоставить не могут по понятным причинам иначе если они предоставят они не смогут асала его исполнять то здесь вопросы возникают типа как нам сделать ту же самую авторизацию и не глядите этом еще одну авторизацию ну потому что две технологии в одном месте это не всегда хорошо и понятно что мы куб обновляем сами когда нам нужно до нужных версии можем очень можем очень плавно мигрировать там с минами норм можем перескочить там на следующий когда нам нужно если мы видим что какие-то патча приходят а timeline обновление куба в облаке он совершенно другой то есть ребята могут тоже ну а нам очень сложно будет синхронизировать наши версии а если нам сложно синхронизировать нашей версии значит это будет говорить о том что у нас могут быть разные тепло и в разные кубы у нас может сервисы по разному работать или там где-то deeply кей шин уже какая-то опция в манифесте а у нас например она еще не пике шин или наоборот или наоборот да поэтому вот это вот рассинхрон в но до в кубах версиях куба это проблема который довольно сложно будет решить и мы этот вариант тоже не взяли понятно что раз такие варианты в лоб не подходят надо что-то менять довольно таки кардинально и мы договорились вообще уйти в сторону от наших deploy a fancy blood приседа и все остальное и провести небольшую эволюцию нас во первых мы договорились что все железки и все ресурсы мы будем грузить по сети по сети чтобы это минимум человеческого участия было то есть человек бы писал те образы которые загружать по сети роботы бы сами их загружали для этого нужно понятно что для этого нужно собрать свой образ которого мы будем запускаться и этим из о выступит тот анти был deploy который которую мы диплом сейчас просто надо докупать то есть там можно через пакиром запустить тот же самый ansi был диплом и это дело соберет вам такой же образ как если бы вы просто не было пригоняли на машинке и такие образа они могут стартовать и быстро запускаться подключаясь кластер автоматически и нам нужно это говорится что чтобы убрать вот эту операционную работу по обновлению всех четырех сотен not to их еще будет больше нам нужно сделать какой-то оператор который будет ходить по нодам проверяет нужно ли их обновить или нет и обновлять когда нужно и собственно of those келлер который который будет который будет принимать решения когда нам нужно расширить наш кластер когда к нам пришла ситуационная нагрузка когда к нам пришла нагрузка и какие-то под они могут за скейлится то есть он будет знать что внутри происходит и принимать решения когда вам а швец и здесь я плюсы-минусы не поставил потому что это довольно сложно оценить это типа это может быть как и хорошим вариантом так и плохим это просто другой это другой вариант совершенно переход на другую на другое мышление на другой диплом и поэтому мы решили попробовать его и посмотреть как получится потому что лучших вариантов пока не было давайте про образа и сети поговорим как как у нас чё там грузится технология на самом деле давно отработана это паек среза и пикси загрузка вдыхаться по серверам это ftp-сервером на котором лежит образ единственное участие инженера здесь заключается в том чтобы при получении сервера через api меня и зайти в bios запустить сказать ему что ты загружаешь ся по сети и сходи там вдыхаться по сервера получить нему настройки здесь и большая сложность возникает со образами но в принципе с этим надо просто разобраться то есть мы разобрались это анти был плюс паки он собирает нам примерно то же самое что у нас есть на бою и в конечном итоге мы перейдем именно вот с нашего тепло и анселом на сборку образов покером и не будем ничего деплоить уже анти блам в куб и здесь когда вы задумаетесь о том как бы эту штуку тоже не дайте себя если у вас есть какая-то большая развесистая железная инфраструктура вам нужно посмотреть на ваши сетевые железки на ваши коммутаторы потому что они могут по разному работать то есть какие-то коммутаторы могут без проблем там с пикси работать и отдавать там по обоим бортам ну то есть у вас железка подключена по двум портам два порта в разные коммутаторы и главное чтобы коммутаторами ли договориться какой из команд но по ком из коммутаторов там сигнал идёт и так как зоопарк коммутатором довольно большой тут нужно просто взять и такой маленький пилот провести проверить загрузку poppixie с каждым из ваших коммутаторов если с каким-то будут непонятки он будет плохо работать надо просто сесть и понять типа можем ли мы себе это позволить и не нужно поменять коммутатор или нужно поменять подход если вас все коммутатору например не дают poppixie загружаться здесь стандартная схемка то есть чтобы люди представлена что вы представляли как как это все работает в bios меняем загрузку poppixie сетевая железка ходит и ищет их отца по себе отдыхать по сервер смотрит на mac адрес этой железке кто это такая и какой конфиг отдать это будет там кубер воровки в кубе роутера или база данных или еще что-нибудь отдает ей адрес tftp сервера с именем образа которые она загрузить она просто загружает себе этот образ стартует с него и у вас получается уже операционная система которая готова работать ну это это все упрощенно на самом деле там все сложнее если вам это интересно можем после доклада списаться со мной я инженеров моих ребят кто этим занимался попрошу более подробно рассказать все вроде бы хорошо железом у нас все получилось наши коммутатор все хорошо поддерживают sapan стеком возникли некоторые сложности потому что либерт который в основе умеет в основе лежит в основе его понс т.к. он умеет в пикси а сама pan stik пикси не умеет и здесь получается такая проблема вроде технология до технологии умеет но верхнего уровня обвязка нет и здесь мы пошли тем что мы стартуем в пластике машинки с образом а и пикси которая собственно эмулирует вот эту загрузку по сети она также ходит выдыхаться по серверу получает какой-то стандартный образ подменяет а у себя и стартует уже нормальная машинка здесь в принципе суть то же самое просто добавляется еще один шаг еще один дополнительный шаг который ну не сильно влияет на весь pipeline и операционки он добавляет только вот именно на этот шаг это не другая технология это здорово вот допустим этот зоопарк уже весь обули все наши 400 железок они уже работают в кластерах все там крутятся и теперь надо вот с ними что-то делать надо их каким-то образом обновлять давайте посмотрим какие мы вообще требования поставили к тому обновляться в которые мы выбирали чтобы он работал с нашими нотами понятно что эта штука должна определять вообще требует но до обновления или не требует то есть у нее должна быть какая-то логика они просто так возьми и будь ним не все подряд эта штука должна уметь работать с железками которые загружены по сети и говорить что при следующей загрузке загрузки тебе надо тебе надо загрузить другой образ то есть она должна это сказать там оператору который отвечает за то ну там отдыха цапа сервируют зато какой образ отдать железки или в самой жилетке что-то поменять ну то есть это от атаки и верхне уровневые требования которые мы для себя описали и естественно виртуальной машины тоже не надо забывать если они долго не и пытаются система не обновляется то это тоже дэвид конфигурация not эта проблема с безопасностью из призов из с проблемами производительности то что на разных новых может быть все по-разному еще из дополнительных вещей которые было бы интересно нам видеть это запуск ну то есть указание когда мы можем производить обновление ну типа не очень здорово если ваша система контроля версий будет обновляться с 12 до часу дня а вы всем скажите и детей дата на обед мы пока обновимся вас вас не поймут наверно и понятно что нужны какие-то реакции на ошибки и за из этой системы то есть она она будет работать автоматически мы туда вообще них мы хотим ее один раз за деплоить пусть она работает это будет прям огонь и она должна как-то реагировать на ошибки сообщать нам что есть какие то проблемы то есть ей нужные реакции на ошибки и когда мы исследовали рынок там буквально 5 или 7 продуктов мы нашли и всем всем нашим требованиям удовлетворяет такая штука как лефортс курит и так обернется ебут демон в принципе штука интересная сейчас чуть-чуть по боль по большая расскажу также из дополнительных решений которые нам понравились и то есть решение от фланта они сделали примерно вот то же самое что мы хотим мы бы взяли их но нас испугал на самом деле количество башен описанного в этом обновлять и он весь практически написано баши аккуратно биллинге поэтому мы взяли решение с более верхней уровнем языком но если она вдруг не зайдёт то решение от фланта это скажем так на втором месте после него что эта штука умеет вообще как она работает она deep ловится demons а там ваш куб на каждой ноги собственно на стартует и запускает какую-то стандартную ну написанную вами проверку типа что нужно проверить чтобы сказать что надо обновить эту ноту или нет если проверка происходит с нулевым ответом то есть проверка прошла значит поэтому надо обновить она планирует и обновление понятно что она может затруднить ноту перед обновлениями может сказать что и будто и не весь кластер разом пожалуйста а только по одной ноги и то там аннотациями в диман сети тоже рулится типа я сейчас работаю вот эту ноту остальные не трогай очень здорово что они из метрики в прометее она умеет отправлять уведомления куда-нибудь то есть там можно канал вселаки настроить и просто смотреть как как там роботы сами что-то делают это интересно и очень крутая фича то что можно можно попросить не обновлять конкретную ноду если на ней запущен конкретный под например у вас раз в неделю запускается кран jopa которая работает четыре часа и в это время к этой ноте пришел обновляться и сказал джо бы ты проработал от и 50 но сейчас эти обновлю и это короче проблема к вам придут разъяренные пользователей будут с вами общаться то есть можно запретить такие обновления в целом эта штука очень классная и мы преследовали и готовы уже брать просто не нашли на нее пока что время но это вот тот кандидат который мы будем брать внедрять и потом рассказывать о том как это все работает особенно больших инфраструктурах по kei с обновлением not мы разобрались черном делает сорта скиллинга понятно что с келли мся мы только в облаке облаке есть такая возможность как группа авто скиллинга где вы просто указываете из какого образа машинки создаются и то количество какого на доске ли загрузка машин ну как мы и раньше говорили то что у нас унифицированная загрузка должна быть на железо нового pants т.к. на сбер клауд оно так и есть то есть это тот же самый механизм старта машинок как у как железок то есть мы запускаемся посетив образов и для и для собственно то есть мы сейчас скажем так изобретаем немного свой авто скейл в свой авто скейл managed кубера в облаке в чужом блоке нашего кубер и чтобы нам давать команды вот этой группе of the spelling которая на самом деле там просто оцифровка переключается типа надо одну ноту надо твена до 5 и она самостоятельно поднимает уже по заданным правилам количество нот вот переключать оцифровку это будет это это вам необходимо делать именно изнутри вашего куба то есть никто не знает лучше состояние в вашем кубе чем собственно кто-то внутри вашего куба нельзя и снаружи со светлого до постучаться и спросить типа можно обновляться или нет поэтому вам нужно внутрь внедрить кластеров то скейлер ну собственно дефолтный который откуда есть у сбер клауда уже есть провайдер к этому кластером в тоске леру и мы надеемся что он заработает этот провайдер будет проверять там есть ли у нас под и в пенке всё ли у нас там нормально понте affinity кодов то есть может быть тот не может защиту лиц а потому что вас количество нот просто кончилось как у вас там с нагрузкой в классе если какие-то вот эти правила срабатывают он просто переключает циферку в группе авто скейлера и количество нот у вас увеличивается чё по результатам скиллинга как это вообще все работает мы бы хотели знать но на самом деле мы еще не знаем потому что также исследования проведены работа проведена но до конца она еще не реализовано здесь несколько факторов почему это еще не получилось сделать но мы на самом деле это делаем от этой идеи совершенно не отказываемся это вот тот путь куда мы идем во первых облака молодое и мы реально первый кто с таким пришел ну насколько мы поняли ребята сбера нам для работы но собственно для той необходимой для работы авто скиллинга которые мы хотим на самом деле надо было пропатчить то облако кого-то облака которой ребята предоставляют мы с ними очень близко контактируем и через техподдержку и через телегу можно с ними пообщаться и просто рассказываем о том чего нам не хватает то есть ребята вот у себя что-то патч от мы у себя проверки проводим и говорим их результатам вот из последний патч который у нас сейчас блокирует от того чтобы это дело запустить он должен приехать буквально на днях после него мы сразу ноги в руки берем и пробуем все ли у нас работает на самом деле эта штука уже работает то есть у нас of those келин группа переключается но до запускаются они готовы принимать приложение трафик но проблема в патче в том что там не можем запустить трафик на эти ноты у нас на ногах калека там внутренняя сеть и кубера и патч заключается в том что там security group и нельзя поставить дефолтные чтобы запускать трафик на ноды с айтишниками внутренними ну то есть трафик просто не доходит облака не дает запустить этот трафик туда нужно security group и подкрутить по автоматам мы это не можем сделать без патч и на самом деле очень здорово что ребята идут на контакт и мы можем с ними договориться сказать там чего нам не хватает в их облаке они говорят что-то типа это у нас либо в планах либо давайте мы вас выслушаем посмотрим если у других такие потребности либо просто обговорим какие-то технические решения и предложим вам например другой путь давайте подведем такие пред итоге по обновляться not у нас все понятно то есть решение исследована надо просто найти время на него взяться сделать внедрить и следить за эксплуатации как она работает по авто скейлеры буквально несколько дней ждём патчей и так же начинаем внедрять проверяем что с ним сек и на самом деле наша задача основная которое которая от заказчика пришла сосала этой девятки гарантированным она уже выполняется но пока что она выполняется без звездочки то есть она выполняется дорого но на наш взгляд мы надули наши кластера ресурсами и 1 месяц чекаем что ресурсов хватает там настроили мониторинге на конкретное значение если мониторинге срабатывает смотрим что можно сделать с этим окей с кубом мы разобрались но у нас же там еще в начале была какая-то су б д которую тоже надо на доске лить на доске лить на лету и очень быстро что у нас здесь какие варианты понятно что можно взять какой-то vds или аналог донбасс там что такое и очень и в ус не дуть потому что типа она все уже сделано до нас давайте возьмем но проблема-то у нас в том что у нас старая инфраструктура мы не можем от нее просто так отказаться нам ее все равно придется использовать и таким образом у нас получается 2 разных инфраструктуры и они совсем не унифицированы а это значит издержки в поддержке в эксплуатации чего мы хотим из максимально избежать поэтому это не очень подходит нам второй такой момент по использованию the base of r&d saw это реально очень дорогие технологию то есть 80 рублей за 1 instance по сбился облачного или 20 рублей за 1 instance виртуальной машины с теми же самыми параметрами но просто который будет будем мы на джип мы и накид на и и добавлять туда ресурсов мы тоже в целом сыр десантов должно все заработать но проблема в том что мы реально остаемся поддерживать те же самые наши другие кластером подгорцы и это для нас непозволительная роскошь поддерживать две системы поэтому мы его не взяли вообще у нас если так говорить более конкретно у нас 200 гиговая база куба то сотниковой оба запас гарса на который с которой надо работать и надо задаться вопросами там сможем не перелить мы эти данные так быстро работает ли это вообще как там к мастеру подключаться и вот это вот все давайте кратко поэтому пройдемся как вообще это работает там используется вот в точности та же самый of those келлер группа как как для кубера то есть мы заводим авто скейлер группу там стартуют машинки стартуют машинки из каких-то образовав заряжаются по сети и там до двух минут занимает старт этой машинки чтобы перелить туда данные вот эти 200 гигабайт понятно что за две минуты или даже меньше у вас эти данные 200 голов не переведутся кроме не знаю на какой сети они могут перелиться для получения там данных мы делаем snapshots работающие референсной машинки которая постоянно мы на постоянку ее подняли и просто с ней делаем snapshot данных перед поднятием новой то есть в поднятии новой машинке есть в клауд инете написанный на 100 строк питона скриптик которые ходят в api сбер клауда говорит вот тебе от к этой машинке сходи постучись возьми я от нее снапшоты подложи ее сюда на лету и таким образом у вас получается 200 гигов очень быстро после старта мы сразу же можем завести ну то есть у нас уже старта стартанула машинка с нужным образом под колеса у нас появились там данные мы можем уже запускать туда запрос и запускать туда трафик и у вас эти данные уже будут то есть лак между snapshot а мы стартом машинки это две минуты то есть за эти две минуты с учетом профиля конкретной базы когда у нее основная нагрузка там основная загрузка данных происходят 1 сутки в течение дня у нее подгружаются не большие дельты лак между данными очень минимален это для бизнеса окей то что это то что он даже есть и в любом случае те валы которые между между референсной машинкой но между текущим мастером и вот этой новой of those келина я машинка и они приезжают буквально за пару минут и никто даже не замечает что у вас там поднялась база не поднялась дополнительная с этим проблем нет в общем такое увеличение мы взяли но у него все равно есть еще некоторые подводные камни давайте сразу у вас к нему подготовлю так как у нас есть группа авто скейлера то у этой группы у свободы есть у нас нету автоматически в на наш к прокси через который ходит трафик приложения к нашим позже сам не добавляются автоматически и печники каждого полюса мы добавили туда печник of those келлер группы а затем я печника может скрываться 125 10 полюсов и таким образом у вас получается нормальное распределение трафика когда у вас на постоянно работающие под гарса трафик идет там один к одному она вот в эту группу 1 10 например и получается там машинки не до загружены и это не полноценная работает схема здесь нужно доработать и сделать of the discovery и добавление в наших a proxy уже конкретных и печников машин тогда эта проблема будет решена есть также момент что снапшоты данных у нас берутся с конкретной референсной машинки если машинка умирает то данные не берутся и в этом проблема но здесь понятно можно несколько таких машинах сделать несколько of those келлер групп но это решается просто технически технические моменты для кого то может быть здесь проблемой то что стартующая база она прохладная то есть в ней конечный прогрет и какие-то запросы могут тормозить у нас такого нету поэтому я просто предупреждаю о таких проблемах и также когда у вас становится очень много слоев у мастера баз данных например там больше 10 10 20 и какой-то поток во влогах есть то вы можете столкнуться с такой проблемой что вас забьется сеть сеть намасте и вы просто на просто не сможете отдавать володе или принимать обновление данных у себя и за этим нужно следить но понятно что вопрос решается либо более толстой сети скай намасте как костыль либо нормальный вопрос решается о господи каскадные аппликации между под колесами когда с одного слова оспариваться данные на только и окей ближе к итогам что у нас вообще получилось ли у нас дружба такая вот между нашей железной инфраструктурой и облаком в принципе мы считаем что да и что вот то инфраструктура которая у нас получилась она очень гибкая то есть мы не платим очень много денег за железо который мы арендуем наше железо оно в принципе амортизируется очень быстро там за полтора-два года буквально моего окупаем ресурсы облака которые нам предоставляют мы за них платим только в моменте когда они нужны и от именно с вопросов экономии гетерогенная инфраструктура просто огонь она позволяет очень гибко быстро принимать много трафика мало платить и и только когда нужно и в процессе исследования вот этого всего то есть мы боялись основного момента мы боялись что когда когда мы будем делать виртуальную физическую инфраструктуру в одном то мы не найдем каких-то решений которые будут работать и там и там но по исследовав в интернете на самом деле эти решения есть мы их применили о них я сегодня вам рассказал то есть симбиоз облака и железо на этих решениях возможен и что самое прикольное мы практически ничего не изобретали какие-то мелочи там сами написали но это все все что мы делали есть в пан source ссылки в презентации есть презентация будет вращая на позже сможете посмотреть давайте окей по результатам наша задача состоит и девятки она завершена здесь все отлично с наша задача со звезды к сожалению еще нет мы ждем буквально последние вещи почистив клауда мы ждем когда у нас найдётся время на наш на работу с обновляться рам и завершим и ее со скиллом су б.д. разобрались здесь все работает все хорошо по триггером он самостоятельно уже переключается это уже в работе штука со скиллом world cup of роутеров кубера ну собственно я уже сказал надо подождать очень здорово что у нас получилось унифицировать работу с виртуальными физическими ресурсами а ребята которые ребята которые все это про копы вали они просто узнали такие кишки и я надеюсь что для них это реально бесценное знание как от которой порадовали их в процессе их работы что нам дальше ну окей ждем по четверг лауда проверяем внедряем наши обновления нод и потом просто дальше живем к метим инфраструктура как кот роботы в pipeline их пусть сами разбираются спасибо спасибо женя спасибо было было супер интересно я думаю что все кто к заказу железо хоть какое-то отношение имеют они все чувствуют боли тут это вот полугодового ожидания про которые ты говорил но я по крайней мере абсолютно почувствовал да когда мне мне предлагают купить сервера уже где-нибудь там феврале или в марте следующего года это конечно ну супер актуально только что ты рассказываешь вот у нас есть временный один вопросик от меня который я заготовил ну и самая мякотка конечно будет в дискуссии там по технические всякие кишочки пообсуждаем а скажи пожалуйста вот у вас как ты аккуратно сказал у вас естественным образом было интеграция с конкретным облаком ссср клаудин да там по понятным причинам вам нужно было именно туда а но зато вы получили плюшки в виде того что там как-то охотнее на контакт идут с вами менеджеры техподдержка инженеры готовы там это патче может быть для вас вставить а скажи пожалуйста на сколько ну вот как по твоя цен кино сколько для вас это было критично то есть сколько вы реально сэкономь получилось бы у вас сделать такое же эффективное решение если бы это был не было дружественным облаком было просто каким-то коммерческим решением или может быть вообще не смогли бы сделать то что сделали хороший вопрос спасибо лишь на него довольно сложно ответить потому что опыт работы с облаками у нас можно сказать это первый и с другими облаками у нас есть опыт только и инженеров с прошлых мест работы потому что но сбер клауд это первое внешнее облако которая у нас есть возможно в каких-то облаках уже мы бы просто читали то большое количество документации которая написана за годы работы этого облака и самостоятельно бы нашли решение а если вы не нашли это решение то скорее всего вообще бы ничего не нашли потому что не факт что мы добились до тех поддержки я честно не знаю вот ребятам из amazon и интересным и например как заказчик и ли они про нас вообще ничего не знают и если бы это мы к ним пришли возможно бы ничего не ответили здесь как бы с ребятами у них есть довольно развесистой документация мы все всю ее узнали у них под капотом на самом деле под капотом их облака сбер клауд advance это тоже окон стек и на самом деле здесь очень повезло что у нас и минуты и понс так и снаружи такой и у нас переход более-менее плавный и какие-то фичи мы уже знаем что тепло понс таки это можно по строке то нельзя и мы уже четко шли вот по этой дорожке если мы натыкались на какие-то проблемы мы общались с ребятами ребята со стороны с их технических специалистов уже говорите можно так сделать или нет или например ставили тикеты внутри чтобы эту эти доработки внести я полагаю так что создал клаудом мы эту историю доведем до конца и здесь ну как бы она закончится хорошо если брать другое облако здесь нужно прямо общаться с ребятами и смотреть получится или нет и папой пойдут ли на контакт они пойдут ли на контакт другие облака если у нас что-то пойдет не так вот этого опыта у нас еще нет понятно спасибо друзья если кто то смотрит нас и у вас есть опыт построения гибридного облака с другим провайдером интересно будет сравнить наши ощущения может быть позадавать вопросы может быть даже женя по задает кому-то из вас вопросы если ему будет интересно ваш опыт получить ну что переходим в дискуссию тогда всем всем пока встретимся зуме спасибо всем увидимся в доме"
}